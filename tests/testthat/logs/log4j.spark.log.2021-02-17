21/02/17 00:32:56 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
21/02/17 00:32:57 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
21/02/17 00:32:58 INFO SparkContext: Running Spark version 2.3.0
21/02/17 00:32:58 INFO SparkContext: Submitted application: sparklyr
21/02/17 00:32:58 INFO SecurityManager: Changing view acls to: yitaoli
21/02/17 00:32:58 INFO SecurityManager: Changing modify acls to: yitaoli
21/02/17 00:32:58 INFO SecurityManager: Changing view acls groups to: 
21/02/17 00:32:58 INFO SecurityManager: Changing modify acls groups to: 
21/02/17 00:32:58 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(yitaoli); groups with view permissions: Set(); users  with modify permissions: Set(yitaoli); groups with modify permissions: Set()
21/02/17 00:32:58 INFO Utils: Successfully started service 'sparkDriver' on port 33875.
21/02/17 00:32:58 INFO SparkEnv: Registering MapOutputTracker
21/02/17 00:32:58 INFO SparkEnv: Registering BlockManagerMaster
21/02/17 00:32:58 INFO BlockManagerMasterEndpoint: Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
21/02/17 00:32:58 INFO BlockManagerMasterEndpoint: BlockManagerMasterEndpoint up
21/02/17 00:32:58 INFO DiskBlockManager: Created local directory at /tmp/blockmgr-0f472309-5090-4ea3-8a8d-cc2e9ba06de0
21/02/17 00:32:58 INFO MemoryStore: MemoryStore started with capacity 912.3 MB
21/02/17 00:32:58 INFO SparkEnv: Registering OutputCommitCoordinator
21/02/17 00:32:58 INFO Utils: Successfully started service 'SparkUI' on port 4040.
21/02/17 00:32:58 INFO SparkUI: Bound SparkUI to 127.0.0.1, and started at http://localhost:4040
21/02/17 00:32:58 INFO SparkContext: Added JAR file:///home/yitaoli/R/x86_64-pc-linux-gnu-library/4.0/sparkxgb/java/sparkxgb-2.3-2.11.jar at spark://localhost:33875/jars/sparkxgb-2.3-2.11.jar with timestamp 1613521978680
21/02/17 00:32:58 INFO SparkContext: Added JAR file:///home/yitaoli/.ivy2/jars/ml.dmlc_xgboost4j-spark-0.81.jar at spark://localhost:33875/jars/ml.dmlc_xgboost4j-spark-0.81.jar with timestamp 1613521978681
21/02/17 00:32:58 INFO SparkContext: Added JAR file:///home/yitaoli/.ivy2/jars/ml.dmlc_xgboost4j-0.81.jar at spark://localhost:33875/jars/ml.dmlc_xgboost4j-0.81.jar with timestamp 1613521978681
21/02/17 00:32:58 INFO SparkContext: Added JAR file:///home/yitaoli/.ivy2/jars/com.esotericsoftware.kryo_kryo-2.21.jar at spark://localhost:33875/jars/com.esotericsoftware.kryo_kryo-2.21.jar with timestamp 1613521978681
21/02/17 00:32:58 INFO SparkContext: Added JAR file:///home/yitaoli/.ivy2/jars/org.scala-lang_scala-compiler-2.11.12.jar at spark://localhost:33875/jars/org.scala-lang_scala-compiler-2.11.12.jar with timestamp 1613521978681
21/02/17 00:32:58 INFO SparkContext: Added JAR file:///home/yitaoli/.ivy2/jars/org.scala-lang_scala-reflect-2.11.12.jar at spark://localhost:33875/jars/org.scala-lang_scala-reflect-2.11.12.jar with timestamp 1613521978681
21/02/17 00:32:58 INFO SparkContext: Added JAR file:///home/yitaoli/.ivy2/jars/commons-logging_commons-logging-1.2.jar at spark://localhost:33875/jars/commons-logging_commons-logging-1.2.jar with timestamp 1613521978681
21/02/17 00:32:58 INFO SparkContext: Added JAR file:///home/yitaoli/.ivy2/jars/com.typesafe.akka_akka-actor_2.11-2.3.11.jar at spark://localhost:33875/jars/com.typesafe.akka_akka-actor_2.11-2.3.11.jar with timestamp 1613521978681
21/02/17 00:32:58 INFO SparkContext: Added JAR file:///home/yitaoli/.ivy2/jars/com.typesafe_config-1.2.1.jar at spark://localhost:33875/jars/com.typesafe_config-1.2.1.jar with timestamp 1613521978681
21/02/17 00:32:58 ERROR SparkContext: Failed to add file:/home/yitaoli/.ivy2/jars/com.esotericsoftware.reflectasm_reflectasm-1.07.jar to Spark environment
java.io.FileNotFoundException: Jar /home/yitaoli/.ivy2/jars/com.esotericsoftware.reflectasm_reflectasm-1.07.jar not found
	at org.apache.spark.SparkContext.addJarFile$1(SparkContext.scala:1807)
	at org.apache.spark.SparkContext.addJar(SparkContext.scala:1837)
	at org.apache.spark.SparkContext$$anonfun$12.apply(SparkContext.scala:457)
	at org.apache.spark.SparkContext$$anonfun$12.apply(SparkContext.scala:457)
	at scala.collection.immutable.List.foreach(List.scala:381)
	at org.apache.spark.SparkContext.<init>(SparkContext.scala:457)
	at org.apache.spark.SparkContext$.getOrCreate(SparkContext.scala:2486)
	at org.apache.spark.sql.SparkSession$Builder$$anonfun$7.apply(SparkSession.scala:930)
	at org.apache.spark.sql.SparkSession$Builder$$anonfun$7.apply(SparkSession.scala:921)
	at scala.Option.getOrElse(Option.scala:121)
	at org.apache.spark.sql.SparkSession$Builder.getOrCreate(SparkSession.scala:921)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at sparklyr.Invoke.invoke(invoke.scala:147)
	at sparklyr.StreamHandler.handleMethodCall(stream.scala:136)
	at sparklyr.StreamHandler.read(stream.scala:61)
	at sparklyr.BackendHandler$$anonfun$channelRead0$1.apply$mcV$sp(handler.scala:58)
	at scala.util.control.Breaks.breakable(Breaks.scala:38)
	at sparklyr.BackendHandler.channelRead0(handler.scala:38)
	at sparklyr.BackendHandler.channelRead0(handler.scala:14)
	at io.netty.channel.SimpleChannelInboundHandler.channelRead(SimpleChannelInboundHandler.java:105)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:362)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:348)
	at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:340)
	at io.netty.handler.codec.MessageToMessageDecoder.channelRead(MessageToMessageDecoder.java:102)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:362)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:348)
	at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:340)
	at io.netty.handler.codec.ByteToMessageDecoder.fireChannelRead(ByteToMessageDecoder.java:310)
	at io.netty.handler.codec.ByteToMessageDecoder.channelRead(ByteToMessageDecoder.java:284)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:362)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:348)
	at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:340)
	at io.netty.channel.DefaultChannelPipeline$HeadContext.channelRead(DefaultChannelPipeline.java:1359)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:362)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:348)
	at io.netty.channel.DefaultChannelPipeline.fireChannelRead(DefaultChannelPipeline.java:935)
	at io.netty.channel.nio.AbstractNioByteChannel$NioByteUnsafe.read(AbstractNioByteChannel.java:138)
	at io.netty.channel.nio.NioEventLoop.processSelectedKey(NioEventLoop.java:645)
	at io.netty.channel.nio.NioEventLoop.processSelectedKeysOptimized(NioEventLoop.java:580)
	at io.netty.channel.nio.NioEventLoop.processSelectedKeys(NioEventLoop.java:497)
	at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:459)
	at io.netty.util.concurrent.SingleThreadEventExecutor$5.run(SingleThreadEventExecutor.java:858)
	at io.netty.util.concurrent.DefaultThreadFactory$DefaultRunnableDecorator.run(DefaultThreadFactory.java:138)
	at java.lang.Thread.run(Thread.java:748)
21/02/17 00:32:58 INFO SparkContext: Added JAR file:///home/yitaoli/.ivy2/jars/com.esotericsoftware.minlog_minlog-1.2.jar at spark://localhost:33875/jars/com.esotericsoftware.minlog_minlog-1.2.jar with timestamp 1613521978684
21/02/17 00:32:58 INFO SparkContext: Added JAR file:///home/yitaoli/.ivy2/jars/org.objenesis_objenesis-1.2.jar at spark://localhost:33875/jars/org.objenesis_objenesis-1.2.jar with timestamp 1613521978684
21/02/17 00:32:58 INFO SparkContext: Added JAR file:///home/yitaoli/.ivy2/jars/org.ow2.asm_asm-4.0.jar at spark://localhost:33875/jars/org.ow2.asm_asm-4.0.jar with timestamp 1613521978684
21/02/17 00:32:58 INFO SparkContext: Added JAR file:///home/yitaoli/.ivy2/jars/org.scala-lang.modules_scala-xml_2.11-1.0.5.jar at spark://localhost:33875/jars/org.scala-lang.modules_scala-xml_2.11-1.0.5.jar with timestamp 1613521978684
21/02/17 00:32:58 INFO SparkContext: Added JAR file:///home/yitaoli/.ivy2/jars/org.scala-lang.modules_scala-parser-combinators_2.11-1.0.4.jar at spark://localhost:33875/jars/org.scala-lang.modules_scala-parser-combinators_2.11-1.0.4.jar with timestamp 1613521978684
21/02/17 00:32:58 INFO SparkContext: Added JAR file:/home/yitaoli/R/x86_64-pc-linux-gnu-library/4.0/sparklyr/java/sparklyr-2.3-2.11.jar at spark://localhost:33875/jars/sparklyr-2.3-2.11.jar with timestamp 1613521978684
21/02/17 00:32:58 INFO Executor: Starting executor ID driver on host localhost
21/02/17 00:32:58 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 37629.
21/02/17 00:32:58 INFO NettyBlockTransferService: Server created on localhost:37629
21/02/17 00:32:58 INFO BlockManager: Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
21/02/17 00:32:58 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, localhost, 37629, None)
21/02/17 00:32:58 INFO BlockManagerMasterEndpoint: Registering block manager localhost:37629 with 912.3 MB RAM, BlockManagerId(driver, localhost, 37629, None)
21/02/17 00:32:58 INFO BlockManagerMaster: Registered BlockManager BlockManagerId(driver, localhost, 37629, None)
21/02/17 00:32:58 INFO BlockManager: Initialized BlockManager: BlockManagerId(driver, localhost, 37629, None)
21/02/17 00:32:58 INFO SharedState: loading hive config file: file:/home/yitaoli/spark/spark-2.3.0-bin-hadoop2.7/conf/hive-site.xml
21/02/17 00:32:58 INFO SharedState: Setting hive.metastore.warehouse.dir ('null') to the value of spark.sql.warehouse.dir ('file:/home/yitaoli/sparkxgb/tests/testthat/spark-warehouse').
21/02/17 00:32:58 INFO SharedState: Warehouse path is 'file:/home/yitaoli/sparkxgb/tests/testthat/spark-warehouse'.
21/02/17 00:32:59 INFO StateStoreCoordinatorRef: Registered StateStoreCoordinator endpoint
21/02/17 00:33:00 INFO HiveUtils: Initializing HiveMetastoreConnection version 1.2.1 using Spark classes.
21/02/17 00:33:01 INFO HiveMetaStore: 0: Opening raw store with implemenation class:org.apache.hadoop.hive.metastore.ObjectStore
21/02/17 00:33:01 INFO ObjectStore: ObjectStore, initialize called
21/02/17 00:33:01 INFO Persistence: Property hive.metastore.integral.jdo.pushdown unknown - will be ignored
21/02/17 00:33:01 INFO Persistence: Property datanucleus.cache.level2 unknown - will be ignored
21/02/17 00:33:02 INFO ObjectStore: Setting MetaStore object pin classes with hive.metastore.cache.pinobjtypes="Table,StorageDescriptor,SerDeInfo,Partition,Database,Type,FieldSchema,Order"
21/02/17 00:33:02 INFO Datastore: The class "org.apache.hadoop.hive.metastore.model.MFieldSchema" is tagged as "embedded-only" so does not have its own datastore table.
21/02/17 00:33:02 INFO Datastore: The class "org.apache.hadoop.hive.metastore.model.MOrder" is tagged as "embedded-only" so does not have its own datastore table.
21/02/17 00:33:03 INFO Datastore: The class "org.apache.hadoop.hive.metastore.model.MFieldSchema" is tagged as "embedded-only" so does not have its own datastore table.
21/02/17 00:33:03 INFO Datastore: The class "org.apache.hadoop.hive.metastore.model.MOrder" is tagged as "embedded-only" so does not have its own datastore table.
21/02/17 00:33:03 INFO MetaStoreDirectSql: Using direct SQL, underlying DB is DERBY
21/02/17 00:33:03 INFO ObjectStore: Initialized ObjectStore
21/02/17 00:33:03 WARN ObjectStore: Version information not found in metastore. hive.metastore.schema.verification is not enabled so recording the schema version 1.2.0
21/02/17 00:33:03 WARN ObjectStore: Failed to get database default, returning NoSuchObjectException
21/02/17 00:33:03 INFO HiveMetaStore: Added admin role in metastore
21/02/17 00:33:03 INFO HiveMetaStore: Added public role in metastore
21/02/17 00:33:03 INFO HiveMetaStore: No user is added in admin role, since config is empty
21/02/17 00:33:03 INFO HiveMetaStore: 0: get_all_databases
21/02/17 00:33:03 INFO audit: ugi=yitaoli	ip=unknown-ip-addr	cmd=get_all_databases	
21/02/17 00:33:03 INFO HiveMetaStore: 0: get_functions: db=default pat=*
21/02/17 00:33:03 INFO audit: ugi=yitaoli	ip=unknown-ip-addr	cmd=get_functions: db=default pat=*	
21/02/17 00:33:03 INFO Datastore: The class "org.apache.hadoop.hive.metastore.model.MResourceUri" is tagged as "embedded-only" so does not have its own datastore table.
21/02/17 00:33:04 INFO SessionState: Created HDFS directory: /tmp/hive/yitaoli
21/02/17 00:33:04 INFO SessionState: Created local directory: /tmp/yitaoli
21/02/17 00:33:04 INFO SessionState: Created local directory: /tmp/3e8fc110-9e08-4a54-ae62-bb0b8acddfc3_resources
21/02/17 00:33:04 INFO SessionState: Created HDFS directory: /tmp/hive/yitaoli/3e8fc110-9e08-4a54-ae62-bb0b8acddfc3
21/02/17 00:33:04 INFO SessionState: Created local directory: /tmp/yitaoli/3e8fc110-9e08-4a54-ae62-bb0b8acddfc3
21/02/17 00:33:04 INFO SessionState: Created HDFS directory: /tmp/hive/yitaoli/3e8fc110-9e08-4a54-ae62-bb0b8acddfc3/_tmp_space.db
21/02/17 00:33:04 INFO HiveClientImpl: Warehouse location for Hive client (version 1.2.2) is file:/home/yitaoli/sparkxgb/tests/testthat/spark-warehouse
21/02/17 00:33:04 INFO HiveMetaStore: 0: get_database: default
21/02/17 00:33:04 INFO audit: ugi=yitaoli	ip=unknown-ip-addr	cmd=get_database: default	
21/02/17 00:33:04 INFO HiveMetaStore: 0: get_database: global_temp
21/02/17 00:33:04 INFO audit: ugi=yitaoli	ip=unknown-ip-addr	cmd=get_database: global_temp	
21/02/17 00:33:04 WARN ObjectStore: Failed to get database global_temp, returning NoSuchObjectException
21/02/17 00:33:04 INFO HiveMetaStore: 0: get_table : db=default tbl=iris
21/02/17 00:33:04 INFO audit: ugi=yitaoli	ip=unknown-ip-addr	cmd=get_table : db=default tbl=iris	
21/02/17 00:33:04 INFO HiveMetaStore: 0: get_database: default
21/02/17 00:33:04 INFO audit: ugi=yitaoli	ip=unknown-ip-addr	cmd=get_database: default	
21/02/17 00:33:04 INFO HiveMetaStore: 0: get_database: default
21/02/17 00:33:04 INFO audit: ugi=yitaoli	ip=unknown-ip-addr	cmd=get_database: default	
21/02/17 00:33:04 INFO HiveMetaStore: 0: get_tables: db=default pat=*
21/02/17 00:33:04 INFO audit: ugi=yitaoli	ip=unknown-ip-addr	cmd=get_tables: db=default pat=*	
21/02/17 00:33:04 INFO SparkContext: Starting job: collect at utils.scala:61
21/02/17 00:33:04 INFO DAGScheduler: Got job 0 (collect at utils.scala:61) with 1 output partitions
21/02/17 00:33:04 INFO DAGScheduler: Final stage: ResultStage 0 (collect at utils.scala:61)
21/02/17 00:33:04 INFO DAGScheduler: Parents of final stage: List()
21/02/17 00:33:04 INFO DAGScheduler: Missing parents: List()
21/02/17 00:33:04 INFO DAGScheduler: Submitting ResultStage 0 (MapPartitionsRDD[4] at map at utils.scala:54), which has no missing parents
21/02/17 00:33:04 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 5.9 KB, free 912.3 MB)
21/02/17 00:33:04 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 3.3 KB, free 912.3 MB)
21/02/17 00:33:04 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on localhost:37629 (size: 3.3 KB, free: 912.3 MB)
21/02/17 00:33:04 INFO SparkContext: Created broadcast 0 from broadcast at DAGScheduler.scala:1039
21/02/17 00:33:04 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 0 (MapPartitionsRDD[4] at map at utils.scala:54) (first 15 tasks are for partitions Vector(0))
21/02/17 00:33:04 INFO TaskSchedulerImpl: Adding task set 0.0 with 1 tasks
21/02/17 00:33:04 INFO TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0, localhost, executor driver, partition 0, PROCESS_LOCAL, 7880 bytes)
21/02/17 00:33:04 INFO Executor: Running task 0.0 in stage 0.0 (TID 0)
21/02/17 00:33:04 INFO Executor: Fetching spark://localhost:33875/jars/ml.dmlc_xgboost4j-spark-0.81.jar with timestamp 1613521978681
21/02/17 00:33:04 INFO TransportClientFactory: Successfully created connection to localhost/127.0.0.1:33875 after 16 ms (0 ms spent in bootstraps)
21/02/17 00:33:04 INFO Utils: Fetching spark://localhost:33875/jars/ml.dmlc_xgboost4j-spark-0.81.jar to /tmp/spark-afa8e139-2ae1-4d38-85a9-7608b3a1c6e8/userFiles-9ec9a139-fd01-46bd-8e16-9c41d3817787/fetchFileTemp5109012191499567496.tmp
21/02/17 00:33:04 INFO Executor: Adding file:/tmp/spark-afa8e139-2ae1-4d38-85a9-7608b3a1c6e8/userFiles-9ec9a139-fd01-46bd-8e16-9c41d3817787/ml.dmlc_xgboost4j-spark-0.81.jar to class loader
21/02/17 00:33:04 INFO Executor: Fetching spark://localhost:33875/jars/sparklyr-2.3-2.11.jar with timestamp 1613521978684
21/02/17 00:33:04 INFO Utils: Fetching spark://localhost:33875/jars/sparklyr-2.3-2.11.jar to /tmp/spark-afa8e139-2ae1-4d38-85a9-7608b3a1c6e8/userFiles-9ec9a139-fd01-46bd-8e16-9c41d3817787/fetchFileTemp2510582630173610222.tmp
21/02/17 00:33:04 INFO Executor: Adding file:/tmp/spark-afa8e139-2ae1-4d38-85a9-7608b3a1c6e8/userFiles-9ec9a139-fd01-46bd-8e16-9c41d3817787/sparklyr-2.3-2.11.jar to class loader
21/02/17 00:33:04 INFO Executor: Fetching spark://localhost:33875/jars/org.ow2.asm_asm-4.0.jar with timestamp 1613521978684
21/02/17 00:33:04 INFO Utils: Fetching spark://localhost:33875/jars/org.ow2.asm_asm-4.0.jar to /tmp/spark-afa8e139-2ae1-4d38-85a9-7608b3a1c6e8/userFiles-9ec9a139-fd01-46bd-8e16-9c41d3817787/fetchFileTemp6087967616410754765.tmp
21/02/17 00:33:04 INFO Executor: Adding file:/tmp/spark-afa8e139-2ae1-4d38-85a9-7608b3a1c6e8/userFiles-9ec9a139-fd01-46bd-8e16-9c41d3817787/org.ow2.asm_asm-4.0.jar to class loader
21/02/17 00:33:04 INFO Executor: Fetching spark://localhost:33875/jars/com.typesafe.akka_akka-actor_2.11-2.3.11.jar with timestamp 1613521978681
21/02/17 00:33:04 INFO Utils: Fetching spark://localhost:33875/jars/com.typesafe.akka_akka-actor_2.11-2.3.11.jar to /tmp/spark-afa8e139-2ae1-4d38-85a9-7608b3a1c6e8/userFiles-9ec9a139-fd01-46bd-8e16-9c41d3817787/fetchFileTemp8025611699329363780.tmp
21/02/17 00:33:04 INFO Executor: Adding file:/tmp/spark-afa8e139-2ae1-4d38-85a9-7608b3a1c6e8/userFiles-9ec9a139-fd01-46bd-8e16-9c41d3817787/com.typesafe.akka_akka-actor_2.11-2.3.11.jar to class loader
21/02/17 00:33:04 INFO Executor: Fetching spark://localhost:33875/jars/org.scala-lang.modules_scala-xml_2.11-1.0.5.jar with timestamp 1613521978684
21/02/17 00:33:04 INFO Utils: Fetching spark://localhost:33875/jars/org.scala-lang.modules_scala-xml_2.11-1.0.5.jar to /tmp/spark-afa8e139-2ae1-4d38-85a9-7608b3a1c6e8/userFiles-9ec9a139-fd01-46bd-8e16-9c41d3817787/fetchFileTemp7194034272118436826.tmp
21/02/17 00:33:04 INFO Executor: Adding file:/tmp/spark-afa8e139-2ae1-4d38-85a9-7608b3a1c6e8/userFiles-9ec9a139-fd01-46bd-8e16-9c41d3817787/org.scala-lang.modules_scala-xml_2.11-1.0.5.jar to class loader
21/02/17 00:33:04 INFO Executor: Fetching spark://localhost:33875/jars/commons-logging_commons-logging-1.2.jar with timestamp 1613521978681
21/02/17 00:33:04 INFO Utils: Fetching spark://localhost:33875/jars/commons-logging_commons-logging-1.2.jar to /tmp/spark-afa8e139-2ae1-4d38-85a9-7608b3a1c6e8/userFiles-9ec9a139-fd01-46bd-8e16-9c41d3817787/fetchFileTemp8377427436689664951.tmp
21/02/17 00:33:04 INFO Executor: Adding file:/tmp/spark-afa8e139-2ae1-4d38-85a9-7608b3a1c6e8/userFiles-9ec9a139-fd01-46bd-8e16-9c41d3817787/commons-logging_commons-logging-1.2.jar to class loader
21/02/17 00:33:04 INFO Executor: Fetching spark://localhost:33875/jars/ml.dmlc_xgboost4j-0.81.jar with timestamp 1613521978681
21/02/17 00:33:04 INFO Utils: Fetching spark://localhost:33875/jars/ml.dmlc_xgboost4j-0.81.jar to /tmp/spark-afa8e139-2ae1-4d38-85a9-7608b3a1c6e8/userFiles-9ec9a139-fd01-46bd-8e16-9c41d3817787/fetchFileTemp4550158159975328886.tmp
21/02/17 00:33:05 INFO Executor: Adding file:/tmp/spark-afa8e139-2ae1-4d38-85a9-7608b3a1c6e8/userFiles-9ec9a139-fd01-46bd-8e16-9c41d3817787/ml.dmlc_xgboost4j-0.81.jar to class loader
21/02/17 00:33:05 INFO Executor: Fetching spark://localhost:33875/jars/com.esotericsoftware.minlog_minlog-1.2.jar with timestamp 1613521978684
21/02/17 00:33:05 INFO Utils: Fetching spark://localhost:33875/jars/com.esotericsoftware.minlog_minlog-1.2.jar to /tmp/spark-afa8e139-2ae1-4d38-85a9-7608b3a1c6e8/userFiles-9ec9a139-fd01-46bd-8e16-9c41d3817787/fetchFileTemp4794255065387605053.tmp
21/02/17 00:33:05 INFO Executor: Adding file:/tmp/spark-afa8e139-2ae1-4d38-85a9-7608b3a1c6e8/userFiles-9ec9a139-fd01-46bd-8e16-9c41d3817787/com.esotericsoftware.minlog_minlog-1.2.jar to class loader
21/02/17 00:33:05 INFO Executor: Fetching spark://localhost:33875/jars/com.esotericsoftware.kryo_kryo-2.21.jar with timestamp 1613521978681
21/02/17 00:33:05 INFO Utils: Fetching spark://localhost:33875/jars/com.esotericsoftware.kryo_kryo-2.21.jar to /tmp/spark-afa8e139-2ae1-4d38-85a9-7608b3a1c6e8/userFiles-9ec9a139-fd01-46bd-8e16-9c41d3817787/fetchFileTemp3844288642178373816.tmp
21/02/17 00:33:05 INFO Executor: Adding file:/tmp/spark-afa8e139-2ae1-4d38-85a9-7608b3a1c6e8/userFiles-9ec9a139-fd01-46bd-8e16-9c41d3817787/com.esotericsoftware.kryo_kryo-2.21.jar to class loader
21/02/17 00:33:05 INFO Executor: Fetching spark://localhost:33875/jars/org.objenesis_objenesis-1.2.jar with timestamp 1613521978684
21/02/17 00:33:05 INFO Utils: Fetching spark://localhost:33875/jars/org.objenesis_objenesis-1.2.jar to /tmp/spark-afa8e139-2ae1-4d38-85a9-7608b3a1c6e8/userFiles-9ec9a139-fd01-46bd-8e16-9c41d3817787/fetchFileTemp2331192349264300185.tmp
21/02/17 00:33:05 INFO Executor: Adding file:/tmp/spark-afa8e139-2ae1-4d38-85a9-7608b3a1c6e8/userFiles-9ec9a139-fd01-46bd-8e16-9c41d3817787/org.objenesis_objenesis-1.2.jar to class loader
21/02/17 00:33:05 INFO Executor: Fetching spark://localhost:33875/jars/org.scala-lang.modules_scala-parser-combinators_2.11-1.0.4.jar with timestamp 1613521978684
21/02/17 00:33:05 INFO Utils: Fetching spark://localhost:33875/jars/org.scala-lang.modules_scala-parser-combinators_2.11-1.0.4.jar to /tmp/spark-afa8e139-2ae1-4d38-85a9-7608b3a1c6e8/userFiles-9ec9a139-fd01-46bd-8e16-9c41d3817787/fetchFileTemp8257837604039331269.tmp
21/02/17 00:33:05 INFO Executor: Adding file:/tmp/spark-afa8e139-2ae1-4d38-85a9-7608b3a1c6e8/userFiles-9ec9a139-fd01-46bd-8e16-9c41d3817787/org.scala-lang.modules_scala-parser-combinators_2.11-1.0.4.jar to class loader
21/02/17 00:33:05 INFO Executor: Fetching spark://localhost:33875/jars/com.typesafe_config-1.2.1.jar with timestamp 1613521978681
21/02/17 00:33:05 INFO Utils: Fetching spark://localhost:33875/jars/com.typesafe_config-1.2.1.jar to /tmp/spark-afa8e139-2ae1-4d38-85a9-7608b3a1c6e8/userFiles-9ec9a139-fd01-46bd-8e16-9c41d3817787/fetchFileTemp3261620493398077885.tmp
21/02/17 00:33:05 INFO Executor: Adding file:/tmp/spark-afa8e139-2ae1-4d38-85a9-7608b3a1c6e8/userFiles-9ec9a139-fd01-46bd-8e16-9c41d3817787/com.typesafe_config-1.2.1.jar to class loader
21/02/17 00:33:05 INFO Executor: Fetching spark://localhost:33875/jars/org.scala-lang_scala-compiler-2.11.12.jar with timestamp 1613521978681
21/02/17 00:33:05 INFO Utils: Fetching spark://localhost:33875/jars/org.scala-lang_scala-compiler-2.11.12.jar to /tmp/spark-afa8e139-2ae1-4d38-85a9-7608b3a1c6e8/userFiles-9ec9a139-fd01-46bd-8e16-9c41d3817787/fetchFileTemp1867579218122338774.tmp
21/02/17 00:33:05 INFO Executor: Adding file:/tmp/spark-afa8e139-2ae1-4d38-85a9-7608b3a1c6e8/userFiles-9ec9a139-fd01-46bd-8e16-9c41d3817787/org.scala-lang_scala-compiler-2.11.12.jar to class loader
21/02/17 00:33:05 INFO Executor: Fetching spark://localhost:33875/jars/org.scala-lang_scala-reflect-2.11.12.jar with timestamp 1613521978681
21/02/17 00:33:05 INFO Utils: Fetching spark://localhost:33875/jars/org.scala-lang_scala-reflect-2.11.12.jar to /tmp/spark-afa8e139-2ae1-4d38-85a9-7608b3a1c6e8/userFiles-9ec9a139-fd01-46bd-8e16-9c41d3817787/fetchFileTemp2963996137193391280.tmp
21/02/17 00:33:05 INFO Executor: Adding file:/tmp/spark-afa8e139-2ae1-4d38-85a9-7608b3a1c6e8/userFiles-9ec9a139-fd01-46bd-8e16-9c41d3817787/org.scala-lang_scala-reflect-2.11.12.jar to class loader
21/02/17 00:33:05 INFO Executor: Fetching spark://localhost:33875/jars/sparkxgb-2.3-2.11.jar with timestamp 1613521978680
21/02/17 00:33:05 INFO Utils: Fetching spark://localhost:33875/jars/sparkxgb-2.3-2.11.jar to /tmp/spark-afa8e139-2ae1-4d38-85a9-7608b3a1c6e8/userFiles-9ec9a139-fd01-46bd-8e16-9c41d3817787/fetchFileTemp8242306236550825036.tmp
21/02/17 00:33:05 INFO Executor: Adding file:/tmp/spark-afa8e139-2ae1-4d38-85a9-7608b3a1c6e8/userFiles-9ec9a139-fd01-46bd-8e16-9c41d3817787/sparkxgb-2.3-2.11.jar to class loader
21/02/17 00:33:05 INFO CodeGenerator: Code generated in 298.823012 ms
21/02/17 00:33:05 INFO Executor: Finished task 0.0 in stage 0.0 (TID 0). 1056 bytes result sent to driver
21/02/17 00:33:05 INFO TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in 590 ms on localhost (executor driver) (1/1)
21/02/17 00:33:05 INFO TaskSchedulerImpl: Removed TaskSet 0.0, whose tasks have all completed, from pool 
21/02/17 00:33:05 INFO DAGScheduler: ResultStage 0 (collect at utils.scala:61) finished in 0.691 s
21/02/17 00:33:05 INFO DAGScheduler: Job 0 finished: collect at utils.scala:61, took 0.728780 s
21/02/17 00:33:05 INFO CodeGenerator: Code generated in 10.660485 ms
21/02/17 00:33:05 INFO CodeGenerator: Code generated in 15.135472 ms
21/02/17 00:33:05 INFO SparkContext: Starting job: collect at utils.scala:135
21/02/17 00:33:05 INFO DAGScheduler: Got job 1 (collect at utils.scala:135) with 1 output partitions
21/02/17 00:33:05 INFO DAGScheduler: Final stage: ResultStage 1 (collect at utils.scala:135)
21/02/17 00:33:05 INFO DAGScheduler: Parents of final stage: List()
21/02/17 00:33:05 INFO DAGScheduler: Missing parents: List()
21/02/17 00:33:05 INFO DAGScheduler: Submitting ResultStage 1 (MapPartitionsRDD[9] at collect at utils.scala:135), which has no missing parents
21/02/17 00:33:05 INFO MemoryStore: Block broadcast_1 stored as values in memory (estimated size 6.4 KB, free 912.3 MB)
21/02/17 00:33:05 INFO MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 3.2 KB, free 912.3 MB)
21/02/17 00:33:05 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on localhost:37629 (size: 3.2 KB, free: 912.3 MB)
21/02/17 00:33:05 INFO SparkContext: Created broadcast 1 from broadcast at DAGScheduler.scala:1039
21/02/17 00:33:05 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 1 (MapPartitionsRDD[9] at collect at utils.scala:135) (first 15 tasks are for partitions Vector(0))
21/02/17 00:33:05 INFO TaskSchedulerImpl: Adding task set 1.0 with 1 tasks
21/02/17 00:33:05 INFO TaskSetManager: Starting task 0.0 in stage 1.0 (TID 1, localhost, executor driver, partition 0, PROCESS_LOCAL, 8067 bytes)
21/02/17 00:33:05 INFO Executor: Running task 0.0 in stage 1.0 (TID 1)
21/02/17 00:33:05 INFO CodeGenerator: Code generated in 8.34602 ms
21/02/17 00:33:05 INFO Executor: Finished task 0.0 in stage 1.0 (TID 1). 1329 bytes result sent to driver
21/02/17 00:33:05 INFO TaskSetManager: Finished task 0.0 in stage 1.0 (TID 1) in 22 ms on localhost (executor driver) (1/1)
21/02/17 00:33:05 INFO TaskSchedulerImpl: Removed TaskSet 1.0, whose tasks have all completed, from pool 
21/02/17 00:33:05 INFO DAGScheduler: ResultStage 1 (collect at utils.scala:135) finished in 0.028 s
21/02/17 00:33:05 INFO DAGScheduler: Job 1 finished: collect at utils.scala:135, took 0.031247 s
21/02/17 00:33:05 INFO CodeGenerator: Code generated in 16.095004 ms
21/02/17 00:33:05 INFO CodeGenerator: Code generated in 12.472694 ms
21/02/17 00:33:06 INFO SparkContext: Starting job: count at utils.scala:135
21/02/17 00:33:06 INFO DAGScheduler: Registering RDD 12 (count at utils.scala:135)
21/02/17 00:33:06 INFO DAGScheduler: Got job 2 (count at utils.scala:135) with 1 output partitions
21/02/17 00:33:06 INFO DAGScheduler: Final stage: ResultStage 3 (count at utils.scala:135)
21/02/17 00:33:06 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 2)
21/02/17 00:33:06 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 2)
21/02/17 00:33:06 INFO DAGScheduler: Submitting ShuffleMapStage 2 (MapPartitionsRDD[12] at count at utils.scala:135), which has no missing parents
21/02/17 00:33:06 INFO MemoryStore: Block broadcast_2 stored as values in memory (estimated size 8.9 KB, free 912.3 MB)
21/02/17 00:33:06 INFO MemoryStore: Block broadcast_2_piece0 stored as bytes in memory (estimated size 4.5 KB, free 912.3 MB)
21/02/17 00:33:06 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on localhost:37629 (size: 4.5 KB, free: 912.3 MB)
21/02/17 00:33:06 INFO SparkContext: Created broadcast 2 from broadcast at DAGScheduler.scala:1039
21/02/17 00:33:06 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 2 (MapPartitionsRDD[12] at count at utils.scala:135) (first 15 tasks are for partitions Vector(0))
21/02/17 00:33:06 INFO TaskSchedulerImpl: Adding task set 2.0 with 1 tasks
21/02/17 00:33:06 INFO TaskSetManager: Starting task 0.0 in stage 2.0 (TID 2, localhost, executor driver, partition 0, PROCESS_LOCAL, 8056 bytes)
21/02/17 00:33:06 INFO Executor: Running task 0.0 in stage 2.0 (TID 2)
21/02/17 00:33:06 INFO Executor: Finished task 0.0 in stage 2.0 (TID 2). 1542 bytes result sent to driver
21/02/17 00:33:06 INFO TaskSetManager: Finished task 0.0 in stage 2.0 (TID 2) in 28 ms on localhost (executor driver) (1/1)
21/02/17 00:33:06 INFO TaskSchedulerImpl: Removed TaskSet 2.0, whose tasks have all completed, from pool 
21/02/17 00:33:06 INFO DAGScheduler: ShuffleMapStage 2 (count at utils.scala:135) finished in 0.039 s
21/02/17 00:33:06 INFO DAGScheduler: looking for newly runnable stages
21/02/17 00:33:06 INFO DAGScheduler: running: Set()
21/02/17 00:33:06 INFO DAGScheduler: waiting: Set(ResultStage 3)
21/02/17 00:33:06 INFO DAGScheduler: failed: Set()
21/02/17 00:33:06 INFO DAGScheduler: Submitting ResultStage 3 (MapPartitionsRDD[15] at count at utils.scala:135), which has no missing parents
21/02/17 00:33:06 INFO MemoryStore: Block broadcast_3 stored as values in memory (estimated size 7.3 KB, free 912.3 MB)
21/02/17 00:33:06 INFO MemoryStore: Block broadcast_3_piece0 stored as bytes in memory (estimated size 3.8 KB, free 912.3 MB)
21/02/17 00:33:06 INFO BlockManagerInfo: Added broadcast_3_piece0 in memory on localhost:37629 (size: 3.8 KB, free: 912.3 MB)
21/02/17 00:33:06 INFO SparkContext: Created broadcast 3 from broadcast at DAGScheduler.scala:1039
21/02/17 00:33:06 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 3 (MapPartitionsRDD[15] at count at utils.scala:135) (first 15 tasks are for partitions Vector(0))
21/02/17 00:33:06 INFO TaskSchedulerImpl: Adding task set 3.0 with 1 tasks
21/02/17 00:33:06 INFO TaskSetManager: Starting task 0.0 in stage 3.0 (TID 3, localhost, executor driver, partition 0, NODE_LOCAL, 7754 bytes)
21/02/17 00:33:06 INFO Executor: Running task 0.0 in stage 3.0 (TID 3)
21/02/17 00:33:06 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
21/02/17 00:33:06 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 3 ms
21/02/17 00:33:06 INFO Executor: Finished task 0.0 in stage 3.0 (TID 3). 1782 bytes result sent to driver
21/02/17 00:33:06 INFO TaskSetManager: Finished task 0.0 in stage 3.0 (TID 3) in 28 ms on localhost (executor driver) (1/1)
21/02/17 00:33:06 INFO TaskSchedulerImpl: Removed TaskSet 3.0, whose tasks have all completed, from pool 
21/02/17 00:33:06 INFO DAGScheduler: ResultStage 3 (count at utils.scala:135) finished in 0.036 s
21/02/17 00:33:06 INFO DAGScheduler: Job 2 finished: count at utils.scala:135, took 0.090184 s
21/02/17 00:33:06 INFO SparkContext: Starting job: collect at utils.scala:135
21/02/17 00:33:06 INFO DAGScheduler: Got job 3 (collect at utils.scala:135) with 1 output partitions
21/02/17 00:33:06 INFO DAGScheduler: Final stage: ResultStage 4 (collect at utils.scala:135)
21/02/17 00:33:06 INFO DAGScheduler: Parents of final stage: List()
21/02/17 00:33:06 INFO DAGScheduler: Missing parents: List()
21/02/17 00:33:06 INFO DAGScheduler: Submitting ResultStage 4 (MapPartitionsRDD[20] at collect at utils.scala:135), which has no missing parents
21/02/17 00:33:06 INFO MemoryStore: Block broadcast_4 stored as values in memory (estimated size 6.4 KB, free 912.3 MB)
21/02/17 00:33:06 INFO MemoryStore: Block broadcast_4_piece0 stored as bytes in memory (estimated size 3.2 KB, free 912.2 MB)
21/02/17 00:33:06 INFO BlockManagerInfo: Added broadcast_4_piece0 in memory on localhost:37629 (size: 3.2 KB, free: 912.3 MB)
21/02/17 00:33:06 INFO SparkContext: Created broadcast 4 from broadcast at DAGScheduler.scala:1039
21/02/17 00:33:06 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 4 (MapPartitionsRDD[20] at collect at utils.scala:135) (first 15 tasks are for partitions Vector(0))
21/02/17 00:33:06 INFO TaskSchedulerImpl: Adding task set 4.0 with 1 tasks
21/02/17 00:33:06 INFO TaskSetManager: Starting task 0.0 in stage 4.0 (TID 4, localhost, executor driver, partition 0, PROCESS_LOCAL, 8067 bytes)
21/02/17 00:33:06 INFO Executor: Running task 0.0 in stage 4.0 (TID 4)
21/02/17 00:33:06 INFO Executor: Finished task 0.0 in stage 4.0 (TID 4). 1286 bytes result sent to driver
21/02/17 00:33:06 INFO TaskSetManager: Finished task 0.0 in stage 4.0 (TID 4) in 5 ms on localhost (executor driver) (1/1)
21/02/17 00:33:06 INFO TaskSchedulerImpl: Removed TaskSet 4.0, whose tasks have all completed, from pool 
21/02/17 00:33:06 INFO DAGScheduler: ResultStage 4 (collect at utils.scala:135) finished in 0.011 s
21/02/17 00:33:06 INFO DAGScheduler: Job 3 finished: collect at utils.scala:135, took 0.013070 s
21/02/17 00:33:06 INFO SparkContext: Starting job: count at utils.scala:135
21/02/17 00:33:06 INFO DAGScheduler: Registering RDD 23 (count at utils.scala:135)
21/02/17 00:33:06 INFO DAGScheduler: Got job 4 (count at utils.scala:135) with 1 output partitions
21/02/17 00:33:06 INFO DAGScheduler: Final stage: ResultStage 6 (count at utils.scala:135)
21/02/17 00:33:06 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 5)
21/02/17 00:33:06 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 5)
21/02/17 00:33:06 INFO DAGScheduler: Submitting ShuffleMapStage 5 (MapPartitionsRDD[23] at count at utils.scala:135), which has no missing parents
21/02/17 00:33:06 INFO MemoryStore: Block broadcast_5 stored as values in memory (estimated size 8.9 KB, free 912.2 MB)
21/02/17 00:33:06 INFO MemoryStore: Block broadcast_5_piece0 stored as bytes in memory (estimated size 4.5 KB, free 912.2 MB)
21/02/17 00:33:06 INFO BlockManagerInfo: Added broadcast_5_piece0 in memory on localhost:37629 (size: 4.5 KB, free: 912.3 MB)
21/02/17 00:33:06 INFO SparkContext: Created broadcast 5 from broadcast at DAGScheduler.scala:1039
21/02/17 00:33:06 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 5 (MapPartitionsRDD[23] at count at utils.scala:135) (first 15 tasks are for partitions Vector(0))
21/02/17 00:33:06 INFO TaskSchedulerImpl: Adding task set 5.0 with 1 tasks
21/02/17 00:33:06 INFO TaskSetManager: Starting task 0.0 in stage 5.0 (TID 5, localhost, executor driver, partition 0, PROCESS_LOCAL, 8056 bytes)
21/02/17 00:33:06 INFO Executor: Running task 0.0 in stage 5.0 (TID 5)
21/02/17 00:33:06 INFO Executor: Finished task 0.0 in stage 5.0 (TID 5). 1499 bytes result sent to driver
21/02/17 00:33:06 INFO TaskSetManager: Finished task 0.0 in stage 5.0 (TID 5) in 6 ms on localhost (executor driver) (1/1)
21/02/17 00:33:06 INFO TaskSchedulerImpl: Removed TaskSet 5.0, whose tasks have all completed, from pool 
21/02/17 00:33:06 INFO DAGScheduler: ShuffleMapStage 5 (count at utils.scala:135) finished in 0.012 s
21/02/17 00:33:06 INFO DAGScheduler: looking for newly runnable stages
21/02/17 00:33:06 INFO DAGScheduler: running: Set()
21/02/17 00:33:06 INFO DAGScheduler: waiting: Set(ResultStage 6)
21/02/17 00:33:06 INFO DAGScheduler: failed: Set()
21/02/17 00:33:06 INFO DAGScheduler: Submitting ResultStage 6 (MapPartitionsRDD[26] at count at utils.scala:135), which has no missing parents
21/02/17 00:33:06 INFO MemoryStore: Block broadcast_6 stored as values in memory (estimated size 7.3 KB, free 912.2 MB)
21/02/17 00:33:06 INFO MemoryStore: Block broadcast_6_piece0 stored as bytes in memory (estimated size 3.8 KB, free 912.2 MB)
21/02/17 00:33:06 INFO BlockManagerInfo: Added broadcast_6_piece0 in memory on localhost:37629 (size: 3.8 KB, free: 912.3 MB)
21/02/17 00:33:06 INFO SparkContext: Created broadcast 6 from broadcast at DAGScheduler.scala:1039
21/02/17 00:33:06 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 6 (MapPartitionsRDD[26] at count at utils.scala:135) (first 15 tasks are for partitions Vector(0))
21/02/17 00:33:06 INFO TaskSchedulerImpl: Adding task set 6.0 with 1 tasks
21/02/17 00:33:06 INFO TaskSetManager: Starting task 0.0 in stage 6.0 (TID 6, localhost, executor driver, partition 0, NODE_LOCAL, 7754 bytes)
21/02/17 00:33:06 INFO Executor: Running task 0.0 in stage 6.0 (TID 6)
21/02/17 00:33:06 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
21/02/17 00:33:06 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
21/02/17 00:33:06 INFO Executor: Finished task 0.0 in stage 6.0 (TID 6). 1782 bytes result sent to driver
21/02/17 00:33:06 INFO TaskSetManager: Finished task 0.0 in stage 6.0 (TID 6) in 5 ms on localhost (executor driver) (1/1)
21/02/17 00:33:06 INFO TaskSchedulerImpl: Removed TaskSet 6.0, whose tasks have all completed, from pool 
21/02/17 00:33:06 INFO DAGScheduler: ResultStage 6 (count at utils.scala:135) finished in 0.011 s
21/02/17 00:33:06 INFO DAGScheduler: Job 4 finished: count at utils.scala:135, took 0.026655 s
21/02/17 00:33:07 INFO CodeGenerator: Code generated in 42.072846 ms
21/02/17 00:33:07 INFO RabitTracker$TrackerProcessLogger: 2021-02-17 00:33:07,185 INFO start listen on 192.168.2.12:9091
21/02/17 00:33:07 INFO SparkContext: Starting job: foreachPartition at XGBoost.scala:287
21/02/17 00:33:07 INFO DAGScheduler: Got job 5 (foreachPartition at XGBoost.scala:287) with 1 output partitions
21/02/17 00:33:07 INFO DAGScheduler: Final stage: ResultStage 7 (foreachPartition at XGBoost.scala:287)
21/02/17 00:33:07 INFO DAGScheduler: Parents of final stage: List()
21/02/17 00:33:07 INFO DAGScheduler: Missing parents: List()
21/02/17 00:33:07 INFO DAGScheduler: Submitting ResultStage 7 (MapPartitionsRDD[34] at mapPartitions at XGBoost.scala:275), which has no missing parents
21/02/17 00:33:07 INFO MemoryStore: Block broadcast_7 stored as values in memory (estimated size 33.1 KB, free 912.2 MB)
21/02/17 00:33:07 INFO MemoryStore: Block broadcast_7_piece0 stored as bytes in memory (estimated size 13.8 KB, free 912.2 MB)
21/02/17 00:33:07 INFO BlockManagerInfo: Added broadcast_7_piece0 in memory on localhost:37629 (size: 13.8 KB, free: 912.3 MB)
21/02/17 00:33:07 INFO SparkContext: Created broadcast 7 from broadcast at DAGScheduler.scala:1039
21/02/17 00:33:07 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 7 (MapPartitionsRDD[34] at mapPartitions at XGBoost.scala:275) (first 15 tasks are for partitions Vector(0))
21/02/17 00:33:07 INFO TaskSchedulerImpl: Adding task set 7.0 with 1 tasks
21/02/17 00:33:07 INFO TaskSetManager: Starting task 0.0 in stage 7.0 (TID 7, localhost, executor driver, partition 0, PROCESS_LOCAL, 18998 bytes)
21/02/17 00:33:07 INFO Executor: Running task 0.0 in stage 7.0 (TID 7)
21/02/17 00:33:07 INFO CodeGenerator: Code generated in 11.113667 ms
21/02/17 00:33:07 INFO MemoryStore: Block rdd_17_0 stored as values in memory (estimated size 5.6 KB, free 912.2 MB)
21/02/17 00:33:07 INFO BlockManagerInfo: Added rdd_17_0 in memory on localhost:37629 (size: 5.6 KB, free: 912.3 MB)
21/02/17 00:33:07 INFO CodeGenerator: Code generated in 3.682529 ms
21/02/17 00:33:07 INFO CodeGenerator: Code generated in 25.836016 ms
21/02/17 00:33:07 INFO CodeGenerator: Code generated in 9.625914 ms
21/02/17 00:33:07 INFO RabitTracker$TrackerProcessLogger: /tmp/tracker3215206467252935949.py:330: DeprecationWarning: isAlive() is deprecated, use is_alive() instead
21/02/17 00:33:07 INFO RabitTracker$TrackerProcessLogger:   while self.thread.isAlive():
21/02/17 00:33:07 INFO RabitTracker$TrackerProcessLogger: 2021-02-17 00:33:07,480 DEBUG Recieve start signal from 192.168.2.12; assign rank 0
21/02/17 00:33:07 INFO RabitTracker$TrackerProcessLogger: 2021-02-17 00:33:07,480 INFO @tracker All of 1 nodes getting started
21/02/17 00:33:07 INFO RabitTracker$TrackerProcessLogger: 2021-02-17 00:33:07,489 INFO [0]	train-rmse:2.633044
21/02/17 00:33:07 INFO RabitTracker$TrackerProcessLogger: 2021-02-17 00:33:07,491 DEBUG Recieve shutdown signal from 0
21/02/17 00:33:07 INFO RabitTracker$TrackerProcessLogger: 2021-02-17 00:33:07,491 INFO @tracker All nodes finishes job
21/02/17 00:33:07 INFO RabitTracker$TrackerProcessLogger: 2021-02-17 00:33:07,491 INFO @tracker 0.010442018508911133 secs between node start and job finish
21/02/17 00:33:07 INFO MemoryStore: Block rdd_34_0 stored as values in memory (estimated size 192.0 B, free 912.2 MB)
21/02/17 00:33:07 INFO BlockManagerInfo: Added rdd_34_0 in memory on localhost:37629 (size: 192.0 B, free: 912.3 MB)
21/02/17 00:33:07 INFO RabitTracker$TrackerProcessLogger: Tracker Process ends with exit code 0
21/02/17 00:33:07 INFO Executor: 1 block locks were not released by TID = 7:
[rdd_34_0]
21/02/17 00:33:07 INFO Executor: Finished task 0.0 in stage 7.0 (TID 7). 1260 bytes result sent to driver
21/02/17 00:33:07 INFO TaskSetManager: Finished task 0.0 in stage 7.0 (TID 7) in 231 ms on localhost (executor driver) (1/1)
21/02/17 00:33:07 INFO TaskSchedulerImpl: Removed TaskSet 7.0, whose tasks have all completed, from pool 
21/02/17 00:33:07 INFO DAGScheduler: ResultStage 7 (foreachPartition at XGBoost.scala:287) finished in 0.279 s
21/02/17 00:33:07 INFO DAGScheduler: Job 5 finished: foreachPartition at XGBoost.scala:287, took 0.286885 s
21/02/17 00:33:07 INFO ContextCleaner: Cleaned accumulator 35
21/02/17 00:33:07 INFO ContextCleaner: Cleaned accumulator 64
21/02/17 00:33:07 INFO ContextCleaner: Cleaned accumulator 180
21/02/17 00:33:07 INFO ContextCleaner: Cleaned accumulator 229
21/02/17 00:33:07 INFO ContextCleaner: Cleaned accumulator 131
21/02/17 00:33:07 INFO ContextCleaner: Cleaned accumulator 167
21/02/17 00:33:07 INFO ContextCleaner: Cleaned accumulator 203
21/02/17 00:33:07 INFO ContextCleaner: Cleaned accumulator 36
21/02/17 00:33:07 INFO ContextCleaner: Cleaned accumulator 221
21/02/17 00:33:07 INFO BlockManagerInfo: Removed broadcast_3_piece0 on localhost:37629 in memory (size: 3.8 KB, free: 912.3 MB)
21/02/17 00:33:07 INFO ContextCleaner: Cleaned accumulator 54
21/02/17 00:33:07 INFO ContextCleaner: Cleaned accumulator 145
21/02/17 00:33:07 INFO ContextCleaner: Cleaned accumulator 227
21/02/17 00:33:07 INFO ContextCleaner: Cleaned accumulator 53
21/02/17 00:33:07 INFO ContextCleaner: Cleaned accumulator 120
21/02/17 00:33:07 INFO ContextCleaner: Cleaned accumulator 144
21/02/17 00:33:07 INFO ContextCleaner: Cleaned accumulator 78
21/02/17 00:33:07 INFO ContextCleaner: Cleaned accumulator 80
21/02/17 00:33:07 INFO ContextCleaner: Cleaned accumulator 217
21/02/17 00:33:07 INFO ContextCleaner: Cleaned accumulator 154
21/02/17 00:33:07 INFO ContextCleaner: Cleaned accumulator 209
21/02/17 00:33:07 INFO ContextCleaner: Cleaned accumulator 195
21/02/17 00:33:07 INFO ContextCleaner: Cleaned accumulator 111
21/02/17 00:33:07 INFO ContextCleaner: Cleaned accumulator 137
21/02/17 00:33:07 INFO ContextCleaner: Cleaned accumulator 206
21/02/17 00:33:07 INFO ContextCleaner: Cleaned accumulator 82
21/02/17 00:33:07 INFO ContextCleaner: Cleaned accumulator 157
21/02/17 00:33:07 INFO ContextCleaner: Cleaned accumulator 40
21/02/17 00:33:07 INFO ContextCleaner: Cleaned accumulator 216
21/02/17 00:33:07 INFO ContextCleaner: Cleaned accumulator 47
21/02/17 00:33:07 INFO ContextCleaner: Cleaned accumulator 31
21/02/17 00:33:07 INFO ContextCleaner: Cleaned accumulator 68
21/02/17 00:33:07 INFO ContextCleaner: Cleaned accumulator 172
21/02/17 00:33:07 INFO ContextCleaner: Cleaned accumulator 191
21/02/17 00:33:07 INFO ContextCleaner: Cleaned accumulator 188
21/02/17 00:33:07 INFO ContextCleaner: Cleaned accumulator 83
21/02/17 00:33:07 INFO ContextCleaner: Cleaned accumulator 135
21/02/17 00:33:07 INFO ContextCleaner: Cleaned accumulator 143
21/02/17 00:33:07 INFO ContextCleaner: Cleaned accumulator 146
21/02/17 00:33:07 INFO ContextCleaner: Cleaned accumulator 121
21/02/17 00:33:07 INFO ContextCleaner: Cleaned accumulator 86
21/02/17 00:33:07 INFO ContextCleaner: Cleaned accumulator 113
21/02/17 00:33:07 INFO ContextCleaner: Cleaned accumulator 117
21/02/17 00:33:07 INFO ContextCleaner: Cleaned accumulator 185
21/02/17 00:33:07 INFO ContextCleaner: Cleaned accumulator 60
21/02/17 00:33:07 INFO ContextCleaner: Cleaned accumulator 72
21/02/17 00:33:07 INFO ContextCleaner: Cleaned accumulator 196
21/02/17 00:33:07 INFO ContextCleaner: Cleaned accumulator 138
21/02/17 00:33:07 INFO BlockManagerInfo: Removed broadcast_1_piece0 on localhost:37629 in memory (size: 3.2 KB, free: 912.3 MB)
21/02/17 00:33:07 INFO ContextCleaner: Cleaned accumulator 200
21/02/17 00:33:07 INFO ContextCleaner: Cleaned accumulator 112
21/02/17 00:33:07 INFO ContextCleaner: Cleaned accumulator 69
21/02/17 00:33:07 INFO ContextCleaner: Cleaned accumulator 104
21/02/17 00:33:07 INFO ContextCleaner: Cleaned accumulator 134
21/02/17 00:33:07 INFO ContextCleaner: Cleaned accumulator 179
21/02/17 00:33:07 INFO ContextCleaner: Cleaned accumulator 81
21/02/17 00:33:07 INFO ContextCleaner: Cleaned accumulator 98
21/02/17 00:33:07 INFO ContextCleaner: Cleaned accumulator 94
21/02/17 00:33:07 INFO ContextCleaner: Cleaned accumulator 122
21/02/17 00:33:07 INFO ContextCleaner: Cleaned accumulator 153
21/02/17 00:33:07 INFO ContextCleaner: Cleaned accumulator 159
21/02/17 00:33:07 INFO ContextCleaner: Cleaned accumulator 108
21/02/17 00:33:07 INFO ContextCleaner: Cleaned accumulator 228
21/02/17 00:33:07 INFO ContextCleaner: Cleaned accumulator 70
21/02/17 00:33:07 INFO BlockManagerInfo: Removed broadcast_6_piece0 on localhost:37629 in memory (size: 3.8 KB, free: 912.3 MB)
21/02/17 00:33:07 INFO ContextCleaner: Cleaned accumulator 235
21/02/17 00:33:07 INFO ContextCleaner: Cleaned accumulator 218
21/02/17 00:33:07 INFO ContextCleaner: Cleaned accumulator 237
21/02/17 00:33:07 INFO ContextCleaner: Cleaned accumulator 41
21/02/17 00:33:07 INFO ContextCleaner: Cleaned accumulator 133
21/02/17 00:33:07 INFO ContextCleaner: Cleaned accumulator 124
21/02/17 00:33:07 INFO ContextCleaner: Cleaned accumulator 37
21/02/17 00:33:07 INFO ContextCleaner: Cleaned accumulator 29
21/02/17 00:33:07 INFO ContextCleaner: Cleaned accumulator 32
21/02/17 00:33:07 INFO ContextCleaner: Cleaned accumulator 48
21/02/17 00:33:07 INFO ContextCleaner: Cleaned accumulator 100
21/02/17 00:33:07 INFO ContextCleaner: Cleaned accumulator 150
21/02/17 00:33:07 INFO ContextCleaner: Cleaned accumulator 52
21/02/17 00:33:07 INFO ContextCleaner: Cleaned accumulator 107
21/02/17 00:33:07 INFO ContextCleaner: Cleaned accumulator 166
21/02/17 00:33:07 INFO ContextCleaner: Cleaned accumulator 128
21/02/17 00:33:07 INFO ContextCleaner: Cleaned accumulator 51
21/02/17 00:33:07 INFO ContextCleaner: Cleaned accumulator 65
21/02/17 00:33:07 INFO ContextCleaner: Cleaned accumulator 142
21/02/17 00:33:07 INFO ContextCleaner: Cleaned accumulator 33
21/02/17 00:33:07 INFO ContextCleaner: Cleaned accumulator 34
21/02/17 00:33:07 INFO ContextCleaner: Cleaned accumulator 57
21/02/17 00:33:07 INFO ContextCleaner: Cleaned accumulator 74
21/02/17 00:33:07 INFO ContextCleaner: Cleaned accumulator 202
21/02/17 00:33:07 INFO ContextCleaner: Cleaned accumulator 43
21/02/17 00:33:07 INFO ContextCleaner: Cleaned accumulator 197
21/02/17 00:33:07 INFO ContextCleaner: Cleaned accumulator 220
21/02/17 00:33:07 INFO ContextCleaner: Cleaned accumulator 93
21/02/17 00:33:07 INFO ContextCleaner: Cleaned accumulator 30
21/02/17 00:33:07 INFO ContextCleaner: Cleaned accumulator 89
21/02/17 00:33:07 INFO ContextCleaner: Cleaned accumulator 123
21/02/17 00:33:07 INFO ContextCleaner: Cleaned accumulator 106
21/02/17 00:33:07 INFO ContextCleaner: Cleaned accumulator 56
21/02/17 00:33:07 INFO ContextCleaner: Cleaned accumulator 168
21/02/17 00:33:07 INFO ContextCleaner: Cleaned accumulator 170
21/02/17 00:33:07 INFO ContextCleaner: Cleaned accumulator 127
21/02/17 00:33:07 INFO ContextCleaner: Cleaned accumulator 28
21/02/17 00:33:07 INFO ContextCleaner: Cleaned accumulator 187
21/02/17 00:33:07 INFO ContextCleaner: Cleaned accumulator 116
21/02/17 00:33:07 INFO ContextCleaner: Cleaned accumulator 105
21/02/17 00:33:07 INFO ContextCleaner: Cleaned accumulator 130
21/02/17 00:33:07 INFO ContextCleaner: Cleaned accumulator 183
21/02/17 00:33:07 INFO BlockManagerInfo: Removed broadcast_4_piece0 on localhost:37629 in memory (size: 3.2 KB, free: 912.3 MB)
21/02/17 00:33:07 INFO ContextCleaner: Cleaned accumulator 177
21/02/17 00:33:07 INFO ContextCleaner: Cleaned accumulator 129
21/02/17 00:33:07 INFO ContextCleaner: Cleaned accumulator 151
21/02/17 00:33:07 INFO ContextCleaner: Cleaned accumulator 223
21/02/17 00:33:07 INFO ContextCleaner: Cleaned accumulator 39
21/02/17 00:33:07 INFO ContextCleaner: Cleaned accumulator 110
21/02/17 00:33:07 INFO ContextCleaner: Cleaned accumulator 192
21/02/17 00:33:07 INFO ContextCleaner: Cleaned accumulator 233
21/02/17 00:33:07 INFO ContextCleaner: Cleaned accumulator 189
21/02/17 00:33:07 INFO ContextCleaner: Cleaned accumulator 232
21/02/17 00:33:07 INFO ContextCleaner: Cleaned accumulator 136
21/02/17 00:33:07 INFO ContextCleaner: Cleaned accumulator 194
21/02/17 00:33:07 INFO ContextCleaner: Cleaned accumulator 207
21/02/17 00:33:07 INFO ContextCleaner: Cleaned accumulator 97
21/02/17 00:33:07 INFO ContextCleaner: Cleaned accumulator 26
21/02/17 00:33:07 INFO ContextCleaner: Cleaned accumulator 27
21/02/17 00:33:07 INFO ContextCleaner: Cleaned accumulator 174
21/02/17 00:33:07 INFO ContextCleaner: Cleaned accumulator 50
21/02/17 00:33:07 INFO ContextCleaner: Cleaned accumulator 184
21/02/17 00:33:07 INFO ContextCleaner: Cleaned accumulator 165
21/02/17 00:33:07 INFO ContextCleaner: Cleaned accumulator 147
21/02/17 00:33:07 INFO ContextCleaner: Cleaned accumulator 155
21/02/17 00:33:07 INFO BlockManagerInfo: Removed broadcast_2_piece0 on localhost:37629 in memory (size: 4.5 KB, free: 912.3 MB)
21/02/17 00:33:07 INFO ContextCleaner: Cleaned accumulator 77
21/02/17 00:33:07 INFO ContextCleaner: Cleaned accumulator 55
21/02/17 00:33:07 INFO ContextCleaner: Cleaned accumulator 114
21/02/17 00:33:07 INFO ContextCleaner: Cleaned accumulator 44
21/02/17 00:33:07 INFO ContextCleaner: Cleaned accumulator 186
21/02/17 00:33:07 INFO ContextCleaner: Cleaned accumulator 46
21/02/17 00:33:07 INFO ContextCleaner: Cleaned accumulator 45
21/02/17 00:33:07 INFO ContextCleaner: Cleaned accumulator 58
21/02/17 00:33:07 INFO ContextCleaner: Cleaned accumulator 140
21/02/17 00:33:07 INFO ContextCleaner: Cleaned accumulator 148
21/02/17 00:33:07 INFO ContextCleaner: Cleaned accumulator 66
21/02/17 00:33:07 INFO ContextCleaner: Cleaned accumulator 231
21/02/17 00:33:07 INFO ContextCleaner: Cleaned accumulator 103
21/02/17 00:33:07 INFO ContextCleaner: Cleaned accumulator 163
21/02/17 00:33:07 INFO ContextCleaner: Cleaned accumulator 132
21/02/17 00:33:07 INFO ContextCleaner: Cleaned accumulator 162
21/02/17 00:33:07 INFO ContextCleaner: Cleaned accumulator 181
21/02/17 00:33:07 INFO ContextCleaner: Cleaned accumulator 171
21/02/17 00:33:07 INFO ContextCleaner: Cleaned accumulator 73
21/02/17 00:33:07 INFO ContextCleaner: Cleaned accumulator 42
21/02/17 00:33:07 INFO ContextCleaner: Cleaned accumulator 230
21/02/17 00:33:07 INFO ContextCleaner: Cleaned accumulator 190
21/02/17 00:33:07 INFO ContextCleaner: Cleaned accumulator 90
21/02/17 00:33:07 INFO ContextCleaner: Cleaned accumulator 156
21/02/17 00:33:07 INFO ContextCleaner: Cleaned accumulator 125
21/02/17 00:33:07 INFO ContextCleaner: Cleaned accumulator 95
21/02/17 00:33:07 INFO ContextCleaner: Cleaned accumulator 160
21/02/17 00:33:07 INFO ContextCleaner: Cleaned accumulator 101
21/02/17 00:33:07 INFO ContextCleaner: Cleaned shuffle 1
21/02/17 00:33:07 INFO ContextCleaner: Cleaned accumulator 76
21/02/17 00:33:07 INFO ContextCleaner: Cleaned accumulator 152
21/02/17 00:33:07 INFO ContextCleaner: Cleaned accumulator 173
21/02/17 00:33:07 INFO ContextCleaner: Cleaned accumulator 176
21/02/17 00:33:07 INFO ContextCleaner: Cleaned accumulator 79
21/02/17 00:33:07 INFO ContextCleaner: Cleaned accumulator 236
21/02/17 00:33:07 INFO ContextCleaner: Cleaned accumulator 149
21/02/17 00:33:07 INFO ContextCleaner: Cleaned accumulator 215
21/02/17 00:33:07 INFO ContextCleaner: Cleaned accumulator 201
21/02/17 00:33:07 INFO ContextCleaner: Cleaned accumulator 239
21/02/17 00:33:07 INFO ContextCleaner: Cleaned accumulator 225
21/02/17 00:33:07 INFO ContextCleaner: Cleaned accumulator 141
21/02/17 00:33:07 INFO ContextCleaner: Cleaned accumulator 49
21/02/17 00:33:07 INFO ContextCleaner: Cleaned accumulator 210
21/02/17 00:33:07 INFO ContextCleaner: Cleaned accumulator 91
21/02/17 00:33:07 INFO ContextCleaner: Cleaned accumulator 88
21/02/17 00:33:07 INFO ContextCleaner: Cleaned accumulator 222
21/02/17 00:33:07 INFO ContextCleaner: Cleaned accumulator 208
21/02/17 00:33:07 INFO BlockManagerInfo: Removed broadcast_7_piece0 on localhost:37629 in memory (size: 13.8 KB, free: 912.3 MB)
21/02/17 00:33:07 INFO ContextCleaner: Cleaned accumulator 158
21/02/17 00:33:07 INFO BlockManagerInfo: Removed broadcast_5_piece0 on localhost:37629 in memory (size: 4.5 KB, free: 912.3 MB)
21/02/17 00:33:07 INFO ContextCleaner: Cleaned accumulator 109
21/02/17 00:33:07 INFO ContextCleaner: Cleaned accumulator 182
21/02/17 00:33:07 INFO ContextCleaner: Cleaned accumulator 61
21/02/17 00:33:07 INFO ContextCleaner: Cleaned accumulator 169
21/02/17 00:33:07 INFO ContextCleaner: Cleaned accumulator 62
21/02/17 00:33:07 INFO ContextCleaner: Cleaned accumulator 85
21/02/17 00:33:07 INFO ContextCleaner: Cleaned accumulator 84
21/02/17 00:33:07 INFO ContextCleaner: Cleaned accumulator 102
21/02/17 00:33:07 INFO ContextCleaner: Cleaned accumulator 126
21/02/17 00:33:07 INFO ContextCleaner: Cleaned accumulator 198
21/02/17 00:33:07 INFO ContextCleaner: Cleaned accumulator 238
21/02/17 00:33:07 INFO ContextCleaner: Cleaned accumulator 234
21/02/17 00:33:07 INFO ContextCleaner: Cleaned accumulator 75
21/02/17 00:33:07 INFO ContextCleaner: Cleaned accumulator 211
21/02/17 00:33:07 INFO ContextCleaner: Cleaned shuffle 0
21/02/17 00:33:07 INFO ContextCleaner: Cleaned accumulator 96
21/02/17 00:33:07 INFO ContextCleaner: Cleaned accumulator 38
21/02/17 00:33:07 INFO ContextCleaner: Cleaned accumulator 71
21/02/17 00:33:07 INFO ContextCleaner: Cleaned accumulator 204
21/02/17 00:33:07 INFO ContextCleaner: Cleaned accumulator 164
21/02/17 00:33:07 INFO ContextCleaner: Cleaned accumulator 193
21/02/17 00:33:07 INFO ContextCleaner: Cleaned accumulator 115
21/02/17 00:33:07 INFO ContextCleaner: Cleaned accumulator 199
21/02/17 00:33:07 INFO ContextCleaner: Cleaned accumulator 224
21/02/17 00:33:07 INFO ContextCleaner: Cleaned accumulator 99
21/02/17 00:33:07 INFO ContextCleaner: Cleaned accumulator 161
21/02/17 00:33:07 INFO ContextCleaner: Cleaned accumulator 178
21/02/17 00:33:07 INFO ContextCleaner: Cleaned accumulator 63
21/02/17 00:33:07 INFO ContextCleaner: Cleaned accumulator 205
21/02/17 00:33:07 INFO ContextCleaner: Cleaned accumulator 87
21/02/17 00:33:07 INFO ContextCleaner: Cleaned accumulator 139
21/02/17 00:33:07 INFO ContextCleaner: Cleaned accumulator 219
21/02/17 00:33:07 INFO ContextCleaner: Cleaned accumulator 67
21/02/17 00:33:07 INFO ContextCleaner: Cleaned accumulator 175
21/02/17 00:33:07 INFO ContextCleaner: Cleaned accumulator 92
21/02/17 00:33:07 INFO ContextCleaner: Cleaned accumulator 226
21/02/17 00:33:07 INFO ContextCleaner: Cleaned accumulator 59
21/02/17 00:33:08 INFO RabitTracker: Tracker Process ends with exit code 0
21/02/17 00:33:08 INFO XGBoostSpark: Rabit returns with exit code 0
21/02/17 00:33:08 INFO SparkContext: Starting job: first at XGBoost.scala:352
21/02/17 00:33:08 INFO DAGScheduler: Got job 6 (first at XGBoost.scala:352) with 1 output partitions
21/02/17 00:33:08 INFO DAGScheduler: Final stage: ResultStage 8 (first at XGBoost.scala:352)
21/02/17 00:33:08 INFO DAGScheduler: Parents of final stage: List()
21/02/17 00:33:08 INFO DAGScheduler: Missing parents: List()
21/02/17 00:33:08 INFO DAGScheduler: Submitting ResultStage 8 (MapPartitionsRDD[34] at mapPartitions at XGBoost.scala:275), which has no missing parents
21/02/17 00:33:08 INFO MemoryStore: Block broadcast_8 stored as values in memory (estimated size 33.1 KB, free 912.3 MB)
21/02/17 00:33:08 INFO MemoryStore: Block broadcast_8_piece0 stored as bytes in memory (estimated size 13.9 KB, free 912.2 MB)
21/02/17 00:33:08 INFO BlockManagerInfo: Added broadcast_8_piece0 in memory on localhost:37629 (size: 13.9 KB, free: 912.3 MB)
21/02/17 00:33:08 INFO SparkContext: Created broadcast 8 from broadcast at DAGScheduler.scala:1039
21/02/17 00:33:08 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 8 (MapPartitionsRDD[34] at mapPartitions at XGBoost.scala:275) (first 15 tasks are for partitions Vector(0))
21/02/17 00:33:08 INFO TaskSchedulerImpl: Adding task set 8.0 with 1 tasks
21/02/17 00:33:08 INFO TaskSetManager: Starting task 0.0 in stage 8.0 (TID 8, localhost, executor driver, partition 0, PROCESS_LOCAL, 18998 bytes)
21/02/17 00:33:08 INFO Executor: Running task 0.0 in stage 8.0 (TID 8)
21/02/17 00:33:08 INFO BlockManager: Found block rdd_34_0 locally
21/02/17 00:33:08 INFO Executor: 1 block locks were not released by TID = 8:
[rdd_34_0]
21/02/17 00:33:08 INFO Executor: Finished task 0.0 in stage 8.0 (TID 8). 2437 bytes result sent to driver
21/02/17 00:33:08 INFO TaskSetManager: Finished task 0.0 in stage 8.0 (TID 8) in 8 ms on localhost (executor driver) (1/1)
21/02/17 00:33:08 INFO TaskSchedulerImpl: Removed TaskSet 8.0, whose tasks have all completed, from pool 
21/02/17 00:33:08 INFO DAGScheduler: ResultStage 8 (first at XGBoost.scala:352) finished in 0.015 s
21/02/17 00:33:08 INFO DAGScheduler: Job 6 finished: first at XGBoost.scala:352, took 0.016975 s
21/02/17 00:33:08 INFO MapPartitionsRDD: Removing RDD 34 from persistence list
21/02/17 00:33:08 INFO BlockManager: Removing RDD 34
21/02/17 00:33:08 INFO MemoryStore: Block broadcast_9 stored as values in memory (estimated size 64.0 B, free 912.2 MB)
21/02/17 00:33:08 INFO MemoryStore: Block broadcast_9_piece0 stored as bytes in memory (estimated size 427.0 B, free 912.2 MB)
21/02/17 00:33:08 INFO BlockManagerInfo: Added broadcast_9_piece0 in memory on localhost:37629 (size: 427.0 B, free: 912.3 MB)
21/02/17 00:33:08 INFO SparkContext: Created broadcast 9 from broadcast at XGBoostRegressor.scala:266
21/02/17 00:33:08 INFO CodeGenerator: Code generated in 25.600275 ms
21/02/17 00:33:08 INFO CodeGenerator: Code generated in 5.767698 ms
21/02/17 00:33:08 INFO CodeGenerator: Code generated in 4.767068 ms
21/02/17 00:33:08 INFO SparkContext: Starting job: collect at utils.scala:135
21/02/17 00:33:08 INFO DAGScheduler: Got job 7 (collect at utils.scala:135) with 1 output partitions
21/02/17 00:33:08 INFO DAGScheduler: Final stage: ResultStage 9 (collect at utils.scala:135)
21/02/17 00:33:08 INFO DAGScheduler: Parents of final stage: List()
21/02/17 00:33:08 INFO DAGScheduler: Missing parents: List()
21/02/17 00:33:08 INFO DAGScheduler: Submitting ResultStage 9 (MapPartitionsRDD[45] at collect at utils.scala:135), which has no missing parents
21/02/17 00:33:08 INFO MemoryStore: Block broadcast_10 stored as values in memory (estimated size 6.5 KB, free 912.2 MB)
21/02/17 00:33:08 INFO MemoryStore: Block broadcast_10_piece0 stored as bytes in memory (estimated size 3.2 KB, free 912.2 MB)
21/02/17 00:33:08 INFO BlockManagerInfo: Added broadcast_10_piece0 in memory on localhost:37629 (size: 3.2 KB, free: 912.3 MB)
21/02/17 00:33:08 INFO SparkContext: Created broadcast 10 from broadcast at DAGScheduler.scala:1039
21/02/17 00:33:08 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 9 (MapPartitionsRDD[45] at collect at utils.scala:135) (first 15 tasks are for partitions Vector(0))
21/02/17 00:33:08 INFO TaskSchedulerImpl: Adding task set 9.0 with 1 tasks
21/02/17 00:33:08 INFO TaskSetManager: Starting task 0.0 in stage 9.0 (TID 9, localhost, executor driver, partition 0, PROCESS_LOCAL, 8067 bytes)
21/02/17 00:33:08 INFO Executor: Running task 0.0 in stage 9.0 (TID 9)
21/02/17 00:33:08 INFO Executor: Finished task 0.0 in stage 9.0 (TID 9). 1286 bytes result sent to driver
21/02/17 00:33:08 INFO TaskSetManager: Finished task 0.0 in stage 9.0 (TID 9) in 6 ms on localhost (executor driver) (1/1)
21/02/17 00:33:08 INFO TaskSchedulerImpl: Removed TaskSet 9.0, whose tasks have all completed, from pool 
21/02/17 00:33:08 INFO DAGScheduler: ResultStage 9 (collect at utils.scala:135) finished in 0.010 s
21/02/17 00:33:08 INFO DAGScheduler: Job 7 finished: collect at utils.scala:135, took 0.011370 s
21/02/17 00:33:08 INFO SparkContext: Starting job: count at utils.scala:135
21/02/17 00:33:08 INFO DAGScheduler: Registering RDD 48 (count at utils.scala:135)
21/02/17 00:33:08 INFO DAGScheduler: Got job 8 (count at utils.scala:135) with 1 output partitions
21/02/17 00:33:08 INFO DAGScheduler: Final stage: ResultStage 11 (count at utils.scala:135)
21/02/17 00:33:08 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 10)
21/02/17 00:33:08 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 10)
21/02/17 00:33:08 INFO DAGScheduler: Submitting ShuffleMapStage 10 (MapPartitionsRDD[48] at count at utils.scala:135), which has no missing parents
21/02/17 00:33:08 INFO MemoryStore: Block broadcast_11 stored as values in memory (estimated size 8.9 KB, free 912.2 MB)
21/02/17 00:33:08 INFO MemoryStore: Block broadcast_11_piece0 stored as bytes in memory (estimated size 4.5 KB, free 912.2 MB)
21/02/17 00:33:08 INFO BlockManagerInfo: Added broadcast_11_piece0 in memory on localhost:37629 (size: 4.5 KB, free: 912.3 MB)
21/02/17 00:33:08 INFO SparkContext: Created broadcast 11 from broadcast at DAGScheduler.scala:1039
21/02/17 00:33:08 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 10 (MapPartitionsRDD[48] at count at utils.scala:135) (first 15 tasks are for partitions Vector(0))
21/02/17 00:33:08 INFO TaskSchedulerImpl: Adding task set 10.0 with 1 tasks
21/02/17 00:33:08 INFO TaskSetManager: Starting task 0.0 in stage 10.0 (TID 10, localhost, executor driver, partition 0, PROCESS_LOCAL, 8056 bytes)
21/02/17 00:33:08 INFO Executor: Running task 0.0 in stage 10.0 (TID 10)
21/02/17 00:33:08 INFO Executor: Finished task 0.0 in stage 10.0 (TID 10). 1499 bytes result sent to driver
21/02/17 00:33:08 INFO TaskSetManager: Finished task 0.0 in stage 10.0 (TID 10) in 4 ms on localhost (executor driver) (1/1)
21/02/17 00:33:08 INFO TaskSchedulerImpl: Removed TaskSet 10.0, whose tasks have all completed, from pool 
21/02/17 00:33:08 INFO DAGScheduler: ShuffleMapStage 10 (count at utils.scala:135) finished in 0.010 s
21/02/17 00:33:08 INFO DAGScheduler: looking for newly runnable stages
21/02/17 00:33:08 INFO DAGScheduler: running: Set()
21/02/17 00:33:08 INFO DAGScheduler: waiting: Set(ResultStage 11)
21/02/17 00:33:08 INFO DAGScheduler: failed: Set()
21/02/17 00:33:08 INFO DAGScheduler: Submitting ResultStage 11 (MapPartitionsRDD[51] at count at utils.scala:135), which has no missing parents
21/02/17 00:33:08 INFO MemoryStore: Block broadcast_12 stored as values in memory (estimated size 7.3 KB, free 912.2 MB)
21/02/17 00:33:08 INFO MemoryStore: Block broadcast_12_piece0 stored as bytes in memory (estimated size 3.8 KB, free 912.2 MB)
21/02/17 00:33:08 INFO BlockManagerInfo: Added broadcast_12_piece0 in memory on localhost:37629 (size: 3.8 KB, free: 912.3 MB)
21/02/17 00:33:08 INFO SparkContext: Created broadcast 12 from broadcast at DAGScheduler.scala:1039
21/02/17 00:33:08 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 11 (MapPartitionsRDD[51] at count at utils.scala:135) (first 15 tasks are for partitions Vector(0))
21/02/17 00:33:08 INFO TaskSchedulerImpl: Adding task set 11.0 with 1 tasks
21/02/17 00:33:08 INFO TaskSetManager: Starting task 0.0 in stage 11.0 (TID 11, localhost, executor driver, partition 0, NODE_LOCAL, 7754 bytes)
21/02/17 00:33:08 INFO Executor: Running task 0.0 in stage 11.0 (TID 11)
21/02/17 00:33:08 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
21/02/17 00:33:08 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
21/02/17 00:33:08 INFO Executor: Finished task 0.0 in stage 11.0 (TID 11). 1782 bytes result sent to driver
21/02/17 00:33:08 INFO TaskSetManager: Finished task 0.0 in stage 11.0 (TID 11) in 5 ms on localhost (executor driver) (1/1)
21/02/17 00:33:08 INFO TaskSchedulerImpl: Removed TaskSet 11.0, whose tasks have all completed, from pool 
21/02/17 00:33:08 INFO DAGScheduler: ResultStage 11 (count at utils.scala:135) finished in 0.008 s
21/02/17 00:33:08 INFO DAGScheduler: Job 8 finished: count at utils.scala:135, took 0.019894 s
21/02/17 00:33:09 INFO CodeGenerator: Code generated in 5.686342 ms
21/02/17 00:33:09 INFO CodeGenerator: Code generated in 7.681015 ms
21/02/17 00:33:09 INFO SparkContext: Starting job: collect at utils.scala:135
21/02/17 00:33:09 INFO DAGScheduler: Got job 9 (collect at utils.scala:135) with 1 output partitions
21/02/17 00:33:09 INFO DAGScheduler: Final stage: ResultStage 12 (collect at utils.scala:135)
21/02/17 00:33:09 INFO DAGScheduler: Parents of final stage: List()
21/02/17 00:33:09 INFO DAGScheduler: Missing parents: List()
21/02/17 00:33:09 INFO DAGScheduler: Submitting ResultStage 12 (MapPartitionsRDD[54] at collect at utils.scala:135), which has no missing parents
21/02/17 00:33:09 INFO MemoryStore: Block broadcast_13 stored as values in memory (estimated size 58.0 KB, free 912.1 MB)
21/02/17 00:33:09 INFO MemoryStore: Block broadcast_13_piece0 stored as bytes in memory (estimated size 24.0 KB, free 912.1 MB)
21/02/17 00:33:09 INFO BlockManagerInfo: Added broadcast_13_piece0 in memory on localhost:37629 (size: 24.0 KB, free: 912.2 MB)
21/02/17 00:33:09 INFO SparkContext: Created broadcast 13 from broadcast at DAGScheduler.scala:1039
21/02/17 00:33:09 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 12 (MapPartitionsRDD[54] at collect at utils.scala:135) (first 15 tasks are for partitions Vector(0))
21/02/17 00:33:09 INFO TaskSchedulerImpl: Adding task set 12.0 with 1 tasks
21/02/17 00:33:09 INFO TaskSetManager: Starting task 0.0 in stage 12.0 (TID 12, localhost, executor driver, partition 0, PROCESS_LOCAL, 18998 bytes)
21/02/17 00:33:09 INFO Executor: Running task 0.0 in stage 12.0 (TID 12)
21/02/17 00:33:09 INFO BlockManager: Found block rdd_17_0 locally
21/02/17 00:33:09 INFO CodeGenerator: Code generated in 10.920139 ms
21/02/17 00:33:09 INFO CodeGenerator: Code generated in 16.069759 ms
21/02/17 00:33:09 INFO CodeGenerator: Code generated in 40.46115 ms
21/02/17 00:33:09 INFO Executor: Finished task 0.0 in stage 12.0 (TID 12). 1815 bytes result sent to driver
21/02/17 00:33:09 INFO TaskSetManager: Finished task 0.0 in stage 12.0 (TID 12) in 127 ms on localhost (executor driver) (1/1)
21/02/17 00:33:09 INFO TaskSchedulerImpl: Removed TaskSet 12.0, whose tasks have all completed, from pool 
21/02/17 00:33:09 INFO DAGScheduler: ResultStage 12 (collect at utils.scala:135) finished in 0.135 s
21/02/17 00:33:09 INFO DAGScheduler: Job 9 finished: collect at utils.scala:135, took 0.137363 s
21/02/17 00:33:09 INFO CodeGenerator: Code generated in 6.80319 ms
21/02/17 00:33:09 INFO SparkContext: Starting job: count at utils.scala:135
21/02/17 00:33:09 INFO DAGScheduler: Registering RDD 57 (count at utils.scala:135)
21/02/17 00:33:09 INFO DAGScheduler: Got job 10 (count at utils.scala:135) with 1 output partitions
21/02/17 00:33:09 INFO DAGScheduler: Final stage: ResultStage 14 (count at utils.scala:135)
21/02/17 00:33:09 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 13)
21/02/17 00:33:09 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 13)
21/02/17 00:33:09 INFO DAGScheduler: Submitting ShuffleMapStage 13 (MapPartitionsRDD[57] at count at utils.scala:135), which has no missing parents
21/02/17 00:33:09 INFO MemoryStore: Block broadcast_14 stored as values in memory (estimated size 58.9 KB, free 912.1 MB)
21/02/17 00:33:09 INFO MemoryStore: Block broadcast_14_piece0 stored as bytes in memory (estimated size 24.4 KB, free 912.0 MB)
21/02/17 00:33:09 INFO BlockManagerInfo: Added broadcast_14_piece0 in memory on localhost:37629 (size: 24.4 KB, free: 912.2 MB)
21/02/17 00:33:09 INFO SparkContext: Created broadcast 14 from broadcast at DAGScheduler.scala:1039
21/02/17 00:33:09 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 13 (MapPartitionsRDD[57] at count at utils.scala:135) (first 15 tasks are for partitions Vector(0))
21/02/17 00:33:09 INFO TaskSchedulerImpl: Adding task set 13.0 with 1 tasks
21/02/17 00:33:09 INFO TaskSetManager: Starting task 0.0 in stage 13.0 (TID 13, localhost, executor driver, partition 0, PROCESS_LOCAL, 18987 bytes)
21/02/17 00:33:09 INFO Executor: Running task 0.0 in stage 13.0 (TID 13)
21/02/17 00:33:09 INFO BlockManager: Found block rdd_17_0 locally
21/02/17 00:33:09 INFO Executor: Finished task 0.0 in stage 13.0 (TID 13). 1933 bytes result sent to driver
21/02/17 00:33:09 INFO TaskSetManager: Finished task 0.0 in stage 13.0 (TID 13) in 30 ms on localhost (executor driver) (1/1)
21/02/17 00:33:09 INFO TaskSchedulerImpl: Removed TaskSet 13.0, whose tasks have all completed, from pool 
21/02/17 00:33:09 INFO DAGScheduler: ShuffleMapStage 13 (count at utils.scala:135) finished in 0.036 s
21/02/17 00:33:09 INFO DAGScheduler: looking for newly runnable stages
21/02/17 00:33:09 INFO DAGScheduler: running: Set()
21/02/17 00:33:09 INFO DAGScheduler: waiting: Set(ResultStage 14)
21/02/17 00:33:09 INFO DAGScheduler: failed: Set()
21/02/17 00:33:09 INFO DAGScheduler: Submitting ResultStage 14 (MapPartitionsRDD[60] at count at utils.scala:135), which has no missing parents
21/02/17 00:33:09 INFO MemoryStore: Block broadcast_15 stored as values in memory (estimated size 7.3 KB, free 912.0 MB)
21/02/17 00:33:09 INFO MemoryStore: Block broadcast_15_piece0 stored as bytes in memory (estimated size 3.8 KB, free 912.0 MB)
21/02/17 00:33:09 INFO BlockManagerInfo: Added broadcast_15_piece0 in memory on localhost:37629 (size: 3.8 KB, free: 912.2 MB)
21/02/17 00:33:09 INFO SparkContext: Created broadcast 15 from broadcast at DAGScheduler.scala:1039
21/02/17 00:33:09 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 14 (MapPartitionsRDD[60] at count at utils.scala:135) (first 15 tasks are for partitions Vector(0))
21/02/17 00:33:09 INFO TaskSchedulerImpl: Adding task set 14.0 with 1 tasks
21/02/17 00:33:09 INFO TaskSetManager: Starting task 0.0 in stage 14.0 (TID 14, localhost, executor driver, partition 0, NODE_LOCAL, 7754 bytes)
21/02/17 00:33:09 INFO Executor: Running task 0.0 in stage 14.0 (TID 14)
21/02/17 00:33:09 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
21/02/17 00:33:09 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
21/02/17 00:33:09 INFO Executor: Finished task 0.0 in stage 14.0 (TID 14). 1782 bytes result sent to driver
21/02/17 00:33:09 INFO TaskSetManager: Finished task 0.0 in stage 14.0 (TID 14) in 4 ms on localhost (executor driver) (1/1)
21/02/17 00:33:09 INFO TaskSchedulerImpl: Removed TaskSet 14.0, whose tasks have all completed, from pool 
21/02/17 00:33:09 INFO DAGScheduler: ResultStage 14 (count at utils.scala:135) finished in 0.009 s
21/02/17 00:33:09 INFO DAGScheduler: Job 10 finished: count at utils.scala:135, took 0.048925 s
21/02/17 00:33:09 INFO deprecation: mapred.output.dir is deprecated. Instead, use mapreduce.output.fileoutputformat.outputdir
21/02/17 00:33:09 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
21/02/17 00:33:09 INFO SparkContext: Starting job: runJob at SparkHadoopWriter.scala:78
21/02/17 00:33:09 INFO DAGScheduler: Got job 11 (runJob at SparkHadoopWriter.scala:78) with 1 output partitions
21/02/17 00:33:09 INFO DAGScheduler: Final stage: ResultStage 15 (runJob at SparkHadoopWriter.scala:78)
21/02/17 00:33:09 INFO DAGScheduler: Parents of final stage: List()
21/02/17 00:33:09 INFO DAGScheduler: Missing parents: List()
21/02/17 00:33:09 INFO DAGScheduler: Submitting ResultStage 15 (MapPartitionsRDD[62] at saveAsTextFile at ReadWrite.scala:283), which has no missing parents
21/02/17 00:33:09 INFO MemoryStore: Block broadcast_16 stored as values in memory (estimated size 71.0 KB, free 912.0 MB)
21/02/17 00:33:09 INFO MemoryStore: Block broadcast_16_piece0 stored as bytes in memory (estimated size 25.3 KB, free 911.9 MB)
21/02/17 00:33:09 INFO BlockManagerInfo: Added broadcast_16_piece0 in memory on localhost:37629 (size: 25.3 KB, free: 912.2 MB)
21/02/17 00:33:09 INFO SparkContext: Created broadcast 16 from broadcast at DAGScheduler.scala:1039
21/02/17 00:33:09 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 15 (MapPartitionsRDD[62] at saveAsTextFile at ReadWrite.scala:283) (first 15 tasks are for partitions Vector(0))
21/02/17 00:33:09 INFO TaskSchedulerImpl: Adding task set 15.0 with 1 tasks
21/02/17 00:33:09 INFO TaskSetManager: Starting task 0.0 in stage 15.0 (TID 15, localhost, executor driver, partition 0, PROCESS_LOCAL, 8142 bytes)
21/02/17 00:33:09 INFO Executor: Running task 0.0 in stage 15.0 (TID 15)
21/02/17 00:33:09 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
21/02/17 00:33:09 INFO FileOutputCommitter: Saved output of task 'attempt_20210217003309_0062_m_000000_0' to file:/tmp/RtmptF6Khl/file1ecf155f3fa56/metadata/_temporary/0/task_20210217003309_0062_m_000000
21/02/17 00:33:09 INFO SparkHadoopMapRedUtil: attempt_20210217003309_0062_m_000000_0: Committed
21/02/17 00:33:09 INFO Executor: Finished task 0.0 in stage 15.0 (TID 15). 1072 bytes result sent to driver
21/02/17 00:33:09 INFO TaskSetManager: Finished task 0.0 in stage 15.0 (TID 15) in 39 ms on localhost (executor driver) (1/1)
21/02/17 00:33:09 INFO TaskSchedulerImpl: Removed TaskSet 15.0, whose tasks have all completed, from pool 
21/02/17 00:33:09 INFO DAGScheduler: ResultStage 15 (runJob at SparkHadoopWriter.scala:78) finished in 0.054 s
21/02/17 00:33:09 INFO DAGScheduler: Job 11 finished: runJob at SparkHadoopWriter.scala:78, took 0.055386 s
21/02/17 00:33:09 INFO SparkHadoopWriter: Job job_20210217003309_0062 committed.
21/02/17 00:33:09 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
21/02/17 00:33:09 INFO SparkContext: Starting job: runJob at SparkHadoopWriter.scala:78
21/02/17 00:33:09 INFO DAGScheduler: Got job 12 (runJob at SparkHadoopWriter.scala:78) with 1 output partitions
21/02/17 00:33:09 INFO DAGScheduler: Final stage: ResultStage 16 (runJob at SparkHadoopWriter.scala:78)
21/02/17 00:33:09 INFO DAGScheduler: Parents of final stage: List()
21/02/17 00:33:09 INFO DAGScheduler: Missing parents: List()
21/02/17 00:33:09 INFO DAGScheduler: Submitting ResultStage 16 (MapPartitionsRDD[64] at saveAsTextFile at ReadWrite.scala:283), which has no missing parents
21/02/17 00:33:09 INFO MemoryStore: Block broadcast_17 stored as values in memory (estimated size 71.1 KB, free 911.9 MB)
21/02/17 00:33:09 INFO MemoryStore: Block broadcast_17_piece0 stored as bytes in memory (estimated size 25.4 KB, free 911.8 MB)
21/02/17 00:33:09 INFO BlockManagerInfo: Added broadcast_17_piece0 in memory on localhost:37629 (size: 25.4 KB, free: 912.2 MB)
21/02/17 00:33:09 INFO SparkContext: Created broadcast 17 from broadcast at DAGScheduler.scala:1039
21/02/17 00:33:09 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 16 (MapPartitionsRDD[64] at saveAsTextFile at ReadWrite.scala:283) (first 15 tasks are for partitions Vector(0))
21/02/17 00:33:09 INFO TaskSchedulerImpl: Adding task set 16.0 with 1 tasks
21/02/17 00:33:09 INFO TaskSetManager: Starting task 0.0 in stage 16.0 (TID 16, localhost, executor driver, partition 0, PROCESS_LOCAL, 8216 bytes)
21/02/17 00:33:09 INFO Executor: Running task 0.0 in stage 16.0 (TID 16)
21/02/17 00:33:09 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
21/02/17 00:33:09 INFO FileOutputCommitter: Saved output of task 'attempt_20210217003309_0064_m_000000_0' to file:/tmp/RtmptF6Khl/file1ecf155f3fa56/stages/0_r_formula__707e5573_ac38_4d87_8d8e_2fb1f36d9f08/metadata/_temporary/0/task_20210217003309_0064_m_000000
21/02/17 00:33:09 INFO SparkHadoopMapRedUtil: attempt_20210217003309_0064_m_000000_0: Committed
21/02/17 00:33:09 INFO Executor: Finished task 0.0 in stage 16.0 (TID 16). 1029 bytes result sent to driver
21/02/17 00:33:09 INFO TaskSetManager: Finished task 0.0 in stage 16.0 (TID 16) in 16 ms on localhost (executor driver) (1/1)
21/02/17 00:33:09 INFO TaskSchedulerImpl: Removed TaskSet 16.0, whose tasks have all completed, from pool 
21/02/17 00:33:09 INFO DAGScheduler: ResultStage 16 (runJob at SparkHadoopWriter.scala:78) finished in 0.026 s
21/02/17 00:33:09 INFO DAGScheduler: Job 12 finished: runJob at SparkHadoopWriter.scala:78, took 0.027690 s
21/02/17 00:33:09 INFO SparkHadoopWriter: Job job_20210217003309_0064 committed.
21/02/17 00:33:09 INFO ParquetFileFormat: Using default output committer for Parquet: org.apache.parquet.hadoop.ParquetOutputCommitter
21/02/17 00:33:09 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
21/02/17 00:33:09 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
21/02/17 00:33:09 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
21/02/17 00:33:09 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
21/02/17 00:33:09 INFO CodeGenerator: Code generated in 7.295487 ms
21/02/17 00:33:09 INFO SparkContext: Starting job: parquet at RFormula.scala:421
21/02/17 00:33:09 INFO DAGScheduler: Registering RDD 67 (parquet at RFormula.scala:421)
21/02/17 00:33:09 INFO DAGScheduler: Got job 13 (parquet at RFormula.scala:421) with 1 output partitions
21/02/17 00:33:09 INFO DAGScheduler: Final stage: ResultStage 18 (parquet at RFormula.scala:421)
21/02/17 00:33:09 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 17)
21/02/17 00:33:09 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 17)
21/02/17 00:33:09 INFO DAGScheduler: Submitting ShuffleMapStage 17 (MapPartitionsRDD[67] at parquet at RFormula.scala:421), which has no missing parents
21/02/17 00:33:09 INFO MemoryStore: Block broadcast_18 stored as values in memory (estimated size 4.8 KB, free 911.8 MB)
21/02/17 00:33:09 INFO MemoryStore: Block broadcast_18_piece0 stored as bytes in memory (estimated size 2.9 KB, free 911.8 MB)
21/02/17 00:33:09 INFO BlockManagerInfo: Added broadcast_18_piece0 in memory on localhost:37629 (size: 2.9 KB, free: 912.2 MB)
21/02/17 00:33:09 INFO SparkContext: Created broadcast 18 from broadcast at DAGScheduler.scala:1039
21/02/17 00:33:09 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 17 (MapPartitionsRDD[67] at parquet at RFormula.scala:421) (first 15 tasks are for partitions Vector(0))
21/02/17 00:33:09 INFO TaskSchedulerImpl: Adding task set 17.0 with 1 tasks
21/02/17 00:33:09 INFO TaskSetManager: Starting task 0.0 in stage 17.0 (TID 17, localhost, executor driver, partition 0, PROCESS_LOCAL, 8164 bytes)
21/02/17 00:33:09 INFO Executor: Running task 0.0 in stage 17.0 (TID 17)
21/02/17 00:33:09 INFO Executor: Finished task 0.0 in stage 17.0 (TID 17). 1247 bytes result sent to driver
21/02/17 00:33:09 INFO TaskSetManager: Finished task 0.0 in stage 17.0 (TID 17) in 4 ms on localhost (executor driver) (1/1)
21/02/17 00:33:09 INFO TaskSchedulerImpl: Removed TaskSet 17.0, whose tasks have all completed, from pool 
21/02/17 00:33:09 INFO DAGScheduler: ShuffleMapStage 17 (parquet at RFormula.scala:421) finished in 0.010 s
21/02/17 00:33:09 INFO DAGScheduler: looking for newly runnable stages
21/02/17 00:33:09 INFO DAGScheduler: running: Set()
21/02/17 00:33:09 INFO DAGScheduler: waiting: Set(ResultStage 18)
21/02/17 00:33:09 INFO DAGScheduler: failed: Set()
21/02/17 00:33:09 INFO DAGScheduler: Submitting ResultStage 18 (ShuffledRowRDD[68] at parquet at RFormula.scala:421), which has no missing parents
21/02/17 00:33:09 INFO MemoryStore: Block broadcast_19 stored as values in memory (estimated size 149.2 KB, free 911.7 MB)
21/02/17 00:33:09 INFO MemoryStore: Block broadcast_19_piece0 stored as bytes in memory (estimated size 53.1 KB, free 911.6 MB)
21/02/17 00:33:09 INFO BlockManagerInfo: Added broadcast_19_piece0 in memory on localhost:37629 (size: 53.1 KB, free: 912.1 MB)
21/02/17 00:33:09 INFO SparkContext: Created broadcast 19 from broadcast at DAGScheduler.scala:1039
21/02/17 00:33:09 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 18 (ShuffledRowRDD[68] at parquet at RFormula.scala:421) (first 15 tasks are for partitions Vector(0))
21/02/17 00:33:09 INFO TaskSchedulerImpl: Adding task set 18.0 with 1 tasks
21/02/17 00:33:09 INFO TaskSetManager: Starting task 0.0 in stage 18.0 (TID 18, localhost, executor driver, partition 0, NODE_LOCAL, 7754 bytes)
21/02/17 00:33:09 INFO Executor: Running task 0.0 in stage 18.0 (TID 18)
21/02/17 00:33:09 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
21/02/17 00:33:09 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
21/02/17 00:33:09 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
21/02/17 00:33:09 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
21/02/17 00:33:09 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
21/02/17 00:33:09 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
21/02/17 00:33:09 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:
{
  "type" : "struct",
  "fields" : [ {
    "name" : "label",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "terms",
    "type" : {
      "type" : "array",
      "elementType" : {
        "type" : "array",
        "elementType" : "string",
        "containsNull" : true
      },
      "containsNull" : true
    },
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "hasIntercept",
    "type" : "boolean",
    "nullable" : false,
    "metadata" : { }
  } ]
}
and corresponding Parquet message type:
message spark_schema {
  optional binary label (UTF8);
  optional group terms (LIST) {
    repeated group list {
      optional group element (LIST) {
        repeated group list {
          optional binary element (UTF8);
        }
      }
    }
  }
  required boolean hasIntercept;
}

       
21/02/17 00:33:09 INFO CodecPool: Got brand-new compressor [.snappy]
21/02/17 00:33:10 INFO FileOutputCommitter: Saved output of task 'attempt_20210217003309_0018_m_000000_0' to file:/tmp/RtmptF6Khl/file1ecf155f3fa56/stages/0_r_formula__707e5573_ac38_4d87_8d8e_2fb1f36d9f08/data/_temporary/0/task_20210217003309_0018_m_000000
21/02/17 00:33:10 INFO SparkHadoopMapRedUtil: attempt_20210217003309_0018_m_000000_0: Committed
21/02/17 00:33:10 INFO Executor: Finished task 0.0 in stage 18.0 (TID 18). 2351 bytes result sent to driver
21/02/17 00:33:10 INFO TaskSetManager: Finished task 0.0 in stage 18.0 (TID 18) in 224 ms on localhost (executor driver) (1/1)
21/02/17 00:33:10 INFO TaskSchedulerImpl: Removed TaskSet 18.0, whose tasks have all completed, from pool 
21/02/17 00:33:10 INFO DAGScheduler: ResultStage 18 (parquet at RFormula.scala:421) finished in 0.245 s
21/02/17 00:33:10 INFO DAGScheduler: Job 13 finished: parquet at RFormula.scala:421, took 0.257830 s
21/02/17 00:33:10 INFO FileFormatWriter: Job null committed.
21/02/17 00:33:10 INFO FileFormatWriter: Finished processing stats for job null.
21/02/17 00:33:10 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
21/02/17 00:33:10 INFO SparkContext: Starting job: runJob at SparkHadoopWriter.scala:78
21/02/17 00:33:10 INFO DAGScheduler: Got job 14 (runJob at SparkHadoopWriter.scala:78) with 1 output partitions
21/02/17 00:33:10 INFO DAGScheduler: Final stage: ResultStage 19 (runJob at SparkHadoopWriter.scala:78)
21/02/17 00:33:10 INFO DAGScheduler: Parents of final stage: List()
21/02/17 00:33:10 INFO DAGScheduler: Missing parents: List()
21/02/17 00:33:10 INFO DAGScheduler: Submitting ResultStage 19 (MapPartitionsRDD[71] at saveAsTextFile at ReadWrite.scala:283), which has no missing parents
21/02/17 00:33:10 INFO MemoryStore: Block broadcast_20 stored as values in memory (estimated size 71.1 KB, free 911.6 MB)
21/02/17 00:33:10 INFO MemoryStore: Block broadcast_20_piece0 stored as bytes in memory (estimated size 25.5 KB, free 911.5 MB)
21/02/17 00:33:10 INFO BlockManagerInfo: Added broadcast_20_piece0 in memory on localhost:37629 (size: 25.5 KB, free: 912.1 MB)
21/02/17 00:33:10 INFO SparkContext: Created broadcast 20 from broadcast at DAGScheduler.scala:1039
21/02/17 00:33:10 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 19 (MapPartitionsRDD[71] at saveAsTextFile at ReadWrite.scala:283) (first 15 tasks are for partitions Vector(0))
21/02/17 00:33:10 INFO TaskSchedulerImpl: Adding task set 19.0 with 1 tasks
21/02/17 00:33:10 INFO TaskSetManager: Starting task 0.0 in stage 19.0 (TID 19, localhost, executor driver, partition 0, PROCESS_LOCAL, 8147 bytes)
21/02/17 00:33:10 INFO Executor: Running task 0.0 in stage 19.0 (TID 19)
21/02/17 00:33:10 INFO ContextCleaner: Cleaned accumulator 296
21/02/17 00:33:10 INFO ContextCleaner: Cleaned accumulator 548
21/02/17 00:33:10 INFO ContextCleaner: Cleaned accumulator 370
21/02/17 00:33:10 INFO ContextCleaner: Cleaned accumulator 402
21/02/17 00:33:10 INFO ContextCleaner: Cleaned accumulator 514
21/02/17 00:33:10 INFO ContextCleaner: Cleaned accumulator 365
21/02/17 00:33:10 INFO ContextCleaner: Cleaned accumulator 442
21/02/17 00:33:10 INFO ContextCleaner: Cleaned accumulator 469
21/02/17 00:33:10 INFO ContextCleaner: Cleaned accumulator 244
21/02/17 00:33:10 INFO ContextCleaner: Cleaned accumulator 386
21/02/17 00:33:10 INFO ContextCleaner: Cleaned accumulator 470
21/02/17 00:33:10 INFO ContextCleaner: Cleaned accumulator 288
21/02/17 00:33:10 INFO ContextCleaner: Cleaned accumulator 242
21/02/17 00:33:10 INFO ContextCleaner: Cleaned accumulator 457
21/02/17 00:33:10 INFO ContextCleaner: Cleaned accumulator 304
21/02/17 00:33:10 INFO ContextCleaner: Cleaned accumulator 241
21/02/17 00:33:10 INFO ContextCleaner: Cleaned accumulator 502
21/02/17 00:33:10 INFO ContextCleaner: Cleaned accumulator 517
21/02/17 00:33:10 INFO ContextCleaner: Cleaned accumulator 522
21/02/17 00:33:10 INFO ContextCleaner: Cleaned accumulator 412
21/02/17 00:33:10 INFO ContextCleaner: Cleaned accumulator 403
21/02/17 00:33:10 INFO ContextCleaner: Cleaned accumulator 393
21/02/17 00:33:10 INFO ContextCleaner: Cleaned accumulator 367
21/02/17 00:33:10 INFO BlockManagerInfo: Removed broadcast_19_piece0 on localhost:37629 in memory (size: 53.1 KB, free: 912.1 MB)
21/02/17 00:33:10 INFO ContextCleaner: Cleaned accumulator 297
21/02/17 00:33:10 INFO ContextCleaner: Cleaned accumulator 421
21/02/17 00:33:10 INFO ContextCleaner: Cleaned accumulator 498
21/02/17 00:33:10 INFO ContextCleaner: Cleaned accumulator 240
21/02/17 00:33:10 INFO ContextCleaner: Cleaned accumulator 542
21/02/17 00:33:10 INFO ContextCleaner: Cleaned accumulator 270
21/02/17 00:33:10 INFO ContextCleaner: Cleaned accumulator 458
21/02/17 00:33:10 INFO ContextCleaner: Cleaned accumulator 254
21/02/17 00:33:10 INFO ContextCleaner: Cleaned accumulator 549
21/02/17 00:33:10 INFO ContextCleaner: Cleaned accumulator 283
21/02/17 00:33:10 INFO ContextCleaner: Cleaned accumulator 277
21/02/17 00:33:10 INFO BlockManagerInfo: Removed broadcast_11_piece0 on localhost:37629 in memory (size: 4.5 KB, free: 912.1 MB)
21/02/17 00:33:10 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
21/02/17 00:33:10 INFO ContextCleaner: Cleaned accumulator 488
21/02/17 00:33:10 INFO ContextCleaner: Cleaned accumulator 257
21/02/17 00:33:10 INFO ContextCleaner: Cleaned accumulator 261
21/02/17 00:33:10 INFO ContextCleaner: Cleaned accumulator 303
21/02/17 00:33:10 INFO ContextCleaner: Cleaned accumulator 546
21/02/17 00:33:10 INFO ContextCleaner: Cleaned accumulator 246
21/02/17 00:33:10 INFO ContextCleaner: Cleaned accumulator 328
21/02/17 00:33:10 INFO ContextCleaner: Cleaned accumulator 308
21/02/17 00:33:10 INFO ContextCleaner: Cleaned accumulator 318
21/02/17 00:33:10 INFO ContextCleaner: Cleaned accumulator 394
21/02/17 00:33:10 INFO ContextCleaner: Cleaned accumulator 350
21/02/17 00:33:10 INFO ContextCleaner: Cleaned accumulator 405
21/02/17 00:33:10 INFO BlockManagerInfo: Removed broadcast_12_piece0 on localhost:37629 in memory (size: 3.8 KB, free: 912.1 MB)
21/02/17 00:33:10 INFO ContextCleaner: Cleaned accumulator 529
21/02/17 00:33:10 INFO ContextCleaner: Cleaned accumulator 372
21/02/17 00:33:10 INFO ContextCleaner: Cleaned accumulator 292
21/02/17 00:33:10 INFO ContextCleaner: Cleaned accumulator 388
21/02/17 00:33:10 INFO ContextCleaner: Cleaned accumulator 519
21/02/17 00:33:10 INFO ContextCleaner: Cleaned accumulator 322
21/02/17 00:33:10 INFO ContextCleaner: Cleaned accumulator 416
21/02/17 00:33:10 INFO ContextCleaner: Cleaned accumulator 530
21/02/17 00:33:10 INFO ContextCleaner: Cleaned shuffle 3
21/02/17 00:33:10 INFO ContextCleaner: Cleaned accumulator 347
21/02/17 00:33:10 INFO ContextCleaner: Cleaned accumulator 290
21/02/17 00:33:10 INFO ContextCleaner: Cleaned accumulator 463
21/02/17 00:33:10 INFO ContextCleaner: Cleaned accumulator 259
21/02/17 00:33:10 INFO ContextCleaner: Cleaned accumulator 501
21/02/17 00:33:10 INFO BlockManager: Removing RDD 34
21/02/17 00:33:10 INFO ContextCleaner: Cleaned RDD 34
21/02/17 00:33:10 INFO ContextCleaner: Cleaned accumulator 521
21/02/17 00:33:10 INFO ContextCleaner: Cleaned accumulator 275
21/02/17 00:33:10 INFO ContextCleaner: Cleaned accumulator 314
21/02/17 00:33:10 INFO ContextCleaner: Cleaned accumulator 433
21/02/17 00:33:10 INFO ContextCleaner: Cleaned accumulator 554
21/02/17 00:33:10 INFO ContextCleaner: Cleaned accumulator 286
21/02/17 00:33:10 INFO ContextCleaner: Cleaned accumulator 446
21/02/17 00:33:10 INFO ContextCleaner: Cleaned accumulator 454
21/02/17 00:33:10 INFO BlockManagerInfo: Removed broadcast_10_piece0 on localhost:37629 in memory (size: 3.2 KB, free: 912.1 MB)
21/02/17 00:33:10 INFO ContextCleaner: Cleaned accumulator 419
21/02/17 00:33:10 INFO ContextCleaner: Cleaned accumulator 251
21/02/17 00:33:10 INFO ContextCleaner: Cleaned accumulator 273
21/02/17 00:33:10 INFO ContextCleaner: Cleaned accumulator 391
21/02/17 00:33:10 INFO ContextCleaner: Cleaned accumulator 357
21/02/17 00:33:10 INFO ContextCleaner: Cleaned accumulator 474
21/02/17 00:33:10 INFO ContextCleaner: Cleaned accumulator 525
21/02/17 00:33:10 INFO ContextCleaner: Cleaned accumulator 335
21/02/17 00:33:10 INFO ContextCleaner: Cleaned accumulator 443
21/02/17 00:33:10 INFO ContextCleaner: Cleaned accumulator 311
21/02/17 00:33:10 INFO ContextCleaner: Cleaned accumulator 336
21/02/17 00:33:10 INFO ContextCleaner: Cleaned accumulator 471
21/02/17 00:33:10 INFO ContextCleaner: Cleaned accumulator 298
21/02/17 00:33:10 INFO ContextCleaner: Cleaned accumulator 301
21/02/17 00:33:10 INFO ContextCleaner: Cleaned accumulator 355
21/02/17 00:33:10 INFO ContextCleaner: Cleaned accumulator 284
21/02/17 00:33:10 INFO ContextCleaner: Cleaned accumulator 422
21/02/17 00:33:10 INFO ContextCleaner: Cleaned accumulator 307
21/02/17 00:33:10 INFO FileOutputCommitter: Saved output of task 'attempt_20210217003310_0071_m_000000_0' to file:/tmp/RtmptF6Khl/file1ecf155f3fa56/stages/0_r_formula__707e5573_ac38_4d87_8d8e_2fb1f36d9f08/pipelineModel/metadata/_temporary/0/task_20210217003310_0071_m_000000
21/02/17 00:33:10 INFO ContextCleaner: Cleaned accumulator 302
21/02/17 00:33:10 INFO ContextCleaner: Cleaned accumulator 537
21/02/17 00:33:10 INFO SparkHadoopMapRedUtil: attempt_20210217003310_0071_m_000000_0: Committed
21/02/17 00:33:10 INFO ContextCleaner: Cleaned accumulator 441
21/02/17 00:33:10 INFO ContextCleaner: Cleaned accumulator 332
21/02/17 00:33:10 INFO ContextCleaner: Cleaned accumulator 411
21/02/17 00:33:10 INFO ContextCleaner: Cleaned accumulator 361
21/02/17 00:33:10 INFO ContextCleaner: Cleaned accumulator 415
21/02/17 00:33:10 INFO ContextCleaner: Cleaned accumulator 260
21/02/17 00:33:10 INFO ContextCleaner: Cleaned accumulator 329
21/02/17 00:33:10 INFO ContextCleaner: Cleaned accumulator 526
21/02/17 00:33:10 INFO ContextCleaner: Cleaned accumulator 279
21/02/17 00:33:10 INFO ContextCleaner: Cleaned accumulator 492
21/02/17 00:33:10 INFO ContextCleaner: Cleaned accumulator 533
21/02/17 00:33:10 INFO ContextCleaner: Cleaned accumulator 449
21/02/17 00:33:10 INFO ContextCleaner: Cleaned accumulator 497
21/02/17 00:33:10 INFO ContextCleaner: Cleaned accumulator 535
21/02/17 00:33:10 INFO ContextCleaner: Cleaned accumulator 544
21/02/17 00:33:10 INFO ContextCleaner: Cleaned accumulator 323
21/02/17 00:33:10 INFO ContextCleaner: Cleaned accumulator 489
21/02/17 00:33:10 INFO ContextCleaner: Cleaned accumulator 408
21/02/17 00:33:10 INFO ContextCleaner: Cleaned accumulator 448
21/02/17 00:33:10 INFO ContextCleaner: Cleaned accumulator 385
21/02/17 00:33:10 INFO ContextCleaner: Cleaned accumulator 320
21/02/17 00:33:10 INFO ContextCleaner: Cleaned accumulator 404
21/02/17 00:33:10 INFO ContextCleaner: Cleaned accumulator 339
21/02/17 00:33:10 INFO ContextCleaner: Cleaned accumulator 418
21/02/17 00:33:10 INFO ContextCleaner: Cleaned accumulator 363
21/02/17 00:33:10 INFO ContextCleaner: Cleaned accumulator 538
21/02/17 00:33:10 INFO ContextCleaner: Cleaned accumulator 287
21/02/17 00:33:10 INFO ContextCleaner: Cleaned accumulator 349
21/02/17 00:33:10 INFO ContextCleaner: Cleaned accumulator 330
21/02/17 00:33:10 INFO ContextCleaner: Cleaned accumulator 379
21/02/17 00:33:10 INFO ContextCleaner: Cleaned accumulator 276
21/02/17 00:33:10 INFO ContextCleaner: Cleaned accumulator 371
21/02/17 00:33:10 INFO Executor: Finished task 0.0 in stage 19.0 (TID 19). 1029 bytes result sent to driver
21/02/17 00:33:10 INFO ContextCleaner: Cleaned accumulator 539
21/02/17 00:33:10 INFO ContextCleaner: Cleaned accumulator 459
21/02/17 00:33:10 INFO ContextCleaner: Cleaned accumulator 440
21/02/17 00:33:10 INFO ContextCleaner: Cleaned accumulator 409
21/02/17 00:33:10 INFO ContextCleaner: Cleaned accumulator 309
21/02/17 00:33:10 INFO ContextCleaner: Cleaned accumulator 269
21/02/17 00:33:10 INFO ContextCleaner: Cleaned accumulator 503
21/02/17 00:33:10 INFO ContextCleaner: Cleaned accumulator 295
21/02/17 00:33:10 INFO ContextCleaner: Cleaned accumulator 545
21/02/17 00:33:10 INFO ContextCleaner: Cleaned accumulator 482
21/02/17 00:33:10 INFO ContextCleaner: Cleaned accumulator 366
21/02/17 00:33:10 INFO ContextCleaner: Cleaned accumulator 392
21/02/17 00:33:10 INFO ContextCleaner: Cleaned accumulator 424
21/02/17 00:33:10 INFO ContextCleaner: Cleaned accumulator 507
21/02/17 00:33:10 INFO ContextCleaner: Cleaned accumulator 420
21/02/17 00:33:10 INFO ContextCleaner: Cleaned accumulator 426
21/02/17 00:33:10 INFO ContextCleaner: Cleaned accumulator 352
21/02/17 00:33:10 INFO ContextCleaner: Cleaned accumulator 509
21/02/17 00:33:10 INFO ContextCleaner: Cleaned accumulator 534
21/02/17 00:33:10 INFO ContextCleaner: Cleaned accumulator 551
21/02/17 00:33:10 INFO ContextCleaner: Cleaned accumulator 326
21/02/17 00:33:10 INFO TaskSetManager: Finished task 0.0 in stage 19.0 (TID 19) in 16 ms on localhost (executor driver) (1/1)
21/02/17 00:33:10 INFO TaskSchedulerImpl: Removed TaskSet 19.0, whose tasks have all completed, from pool 
21/02/17 00:33:10 INFO ContextCleaner: Cleaned shuffle 4
21/02/17 00:33:10 INFO ContextCleaner: Cleaned accumulator 258
21/02/17 00:33:10 INFO ContextCleaner: Cleaned accumulator 483
21/02/17 00:33:10 INFO ContextCleaner: Cleaned accumulator 305
21/02/17 00:33:10 INFO ContextCleaner: Cleaned accumulator 444
21/02/17 00:33:10 INFO ContextCleaner: Cleaned accumulator 540
21/02/17 00:33:10 INFO ContextCleaner: Cleaned accumulator 452
21/02/17 00:33:10 INFO ContextCleaner: Cleaned accumulator 340
21/02/17 00:33:10 INFO ContextCleaner: Cleaned accumulator 345
21/02/17 00:33:10 INFO DAGScheduler: ResultStage 19 (runJob at SparkHadoopWriter.scala:78) finished in 0.046 s
21/02/17 00:33:10 INFO DAGScheduler: Job 14 finished: runJob at SparkHadoopWriter.scala:78, took 0.047980 s
21/02/17 00:33:10 INFO BlockManagerInfo: Removed broadcast_17_piece0 on localhost:37629 in memory (size: 25.4 KB, free: 912.2 MB)
21/02/17 00:33:10 INFO BlockManagerInfo: Removed broadcast_18_piece0 on localhost:37629 in memory (size: 2.9 KB, free: 912.2 MB)
21/02/17 00:33:10 INFO ContextCleaner: Cleaned accumulator 490
21/02/17 00:33:10 INFO ContextCleaner: Cleaned accumulator 399
21/02/17 00:33:10 INFO ContextCleaner: Cleaned accumulator 310
21/02/17 00:33:10 INFO ContextCleaner: Cleaned accumulator 324
21/02/17 00:33:10 INFO ContextCleaner: Cleaned accumulator 550
21/02/17 00:33:10 INFO ContextCleaner: Cleaned accumulator 465
21/02/17 00:33:10 INFO ContextCleaner: Cleaned accumulator 432
21/02/17 00:33:10 INFO ContextCleaner: Cleaned accumulator 484
21/02/17 00:33:10 INFO ContextCleaner: Cleaned accumulator 369
21/02/17 00:33:10 INFO ContextCleaner: Cleaned accumulator 300
21/02/17 00:33:10 INFO ContextCleaner: Cleaned accumulator 428
21/02/17 00:33:10 INFO ContextCleaner: Cleaned accumulator 331
21/02/17 00:33:10 INFO ContextCleaner: Cleaned accumulator 536
21/02/17 00:33:10 INFO ContextCleaner: Cleaned accumulator 555
21/02/17 00:33:10 INFO ContextCleaner: Cleaned accumulator 464
21/02/17 00:33:10 INFO ContextCleaner: Cleaned accumulator 343
21/02/17 00:33:10 INFO ContextCleaner: Cleaned accumulator 438
21/02/17 00:33:10 INFO ContextCleaner: Cleaned accumulator 321
21/02/17 00:33:10 INFO ContextCleaner: Cleaned accumulator 346
21/02/17 00:33:10 INFO ContextCleaner: Cleaned accumulator 456
21/02/17 00:33:10 INFO ContextCleaner: Cleaned accumulator 342
21/02/17 00:33:10 INFO BlockManagerInfo: Removed broadcast_14_piece0 on localhost:37629 in memory (size: 24.4 KB, free: 912.2 MB)
21/02/17 00:33:10 INFO ContextCleaner: Cleaned accumulator 381
21/02/17 00:33:10 INFO ContextCleaner: Cleaned accumulator 547
21/02/17 00:33:10 INFO ContextCleaner: Cleaned accumulator 558
21/02/17 00:33:10 INFO ContextCleaner: Cleaned accumulator 431
21/02/17 00:33:10 INFO ContextCleaner: Cleaned accumulator 511
21/02/17 00:33:10 INFO ContextCleaner: Cleaned accumulator 351
21/02/17 00:33:10 INFO ContextCleaner: Cleaned accumulator 407
21/02/17 00:33:10 INFO ContextCleaner: Cleaned accumulator 480
21/02/17 00:33:10 INFO ContextCleaner: Cleaned accumulator 264
21/02/17 00:33:10 INFO ContextCleaner: Cleaned accumulator 467
21/02/17 00:33:10 INFO ContextCleaner: Cleaned accumulator 255
21/02/17 00:33:10 INFO ContextCleaner: Cleaned accumulator 477
21/02/17 00:33:10 INFO ContextCleaner: Cleaned accumulator 344
21/02/17 00:33:10 INFO ContextCleaner: Cleaned accumulator 327
21/02/17 00:33:10 INFO ContextCleaner: Cleaned accumulator 398
21/02/17 00:33:10 INFO ContextCleaner: Cleaned accumulator 472
21/02/17 00:33:10 INFO ContextCleaner: Cleaned accumulator 486
21/02/17 00:33:10 INFO BlockManagerInfo: Removed broadcast_15_piece0 on localhost:37629 in memory (size: 3.8 KB, free: 912.2 MB)
21/02/17 00:33:10 INFO ContextCleaner: Cleaned accumulator 496
21/02/17 00:33:10 INFO ContextCleaner: Cleaned accumulator 280
21/02/17 00:33:10 INFO ContextCleaner: Cleaned accumulator 429
21/02/17 00:33:10 INFO ContextCleaner: Cleaned accumulator 500
21/02/17 00:33:10 INFO ContextCleaner: Cleaned accumulator 523
21/02/17 00:33:10 INFO ContextCleaner: Cleaned accumulator 552
21/02/17 00:33:10 INFO ContextCleaner: Cleaned accumulator 515
21/02/17 00:33:10 INFO ContextCleaner: Cleaned accumulator 374
21/02/17 00:33:10 INFO ContextCleaner: Cleaned accumulator 447
21/02/17 00:33:10 INFO ContextCleaner: Cleaned accumulator 414
21/02/17 00:33:10 INFO ContextCleaner: Cleaned accumulator 263
21/02/17 00:33:10 INFO ContextCleaner: Cleaned accumulator 316
21/02/17 00:33:10 INFO ContextCleaner: Cleaned accumulator 368
21/02/17 00:33:10 INFO ContextCleaner: Cleaned accumulator 364
21/02/17 00:33:10 INFO BlockManagerInfo: Removed broadcast_13_piece0 on localhost:37629 in memory (size: 24.0 KB, free: 912.2 MB)
21/02/17 00:33:10 INFO SparkHadoopWriter: Job job_20210217003310_0071 committed.
21/02/17 00:33:10 INFO ContextCleaner: Cleaned accumulator 382
21/02/17 00:33:10 INFO ContextCleaner: Cleaned accumulator 468
21/02/17 00:33:10 INFO ContextCleaner: Cleaned accumulator 243
21/02/17 00:33:10 INFO ContextCleaner: Cleaned accumulator 427
21/02/17 00:33:10 INFO ContextCleaner: Cleaned accumulator 353
21/02/17 00:33:10 INFO ContextCleaner: Cleaned accumulator 325
21/02/17 00:33:10 INFO ContextCleaner: Cleaned accumulator 466
21/02/17 00:33:10 INFO ContextCleaner: Cleaned accumulator 491
21/02/17 00:33:10 INFO ContextCleaner: Cleaned accumulator 475
21/02/17 00:33:10 INFO ContextCleaner: Cleaned accumulator 272
21/02/17 00:33:10 INFO ContextCleaner: Cleaned accumulator 478
21/02/17 00:33:10 INFO ContextCleaner: Cleaned accumulator 510
21/02/17 00:33:10 INFO ContextCleaner: Cleaned accumulator 312
21/02/17 00:33:10 INFO ContextCleaner: Cleaned accumulator 401
21/02/17 00:33:10 INFO ContextCleaner: Cleaned accumulator 479
21/02/17 00:33:10 INFO ContextCleaner: Cleaned accumulator 450
21/02/17 00:33:10 INFO ContextCleaner: Cleaned accumulator 378
21/02/17 00:33:10 INFO ContextCleaner: Cleaned accumulator 436
21/02/17 00:33:10 INFO ContextCleaner: Cleaned accumulator 384
21/02/17 00:33:10 INFO ContextCleaner: Cleaned accumulator 376
21/02/17 00:33:10 INFO ContextCleaner: Cleaned accumulator 390
21/02/17 00:33:10 INFO ContextCleaner: Cleaned accumulator 375
21/02/17 00:33:10 INFO ContextCleaner: Cleaned accumulator 380
21/02/17 00:33:10 INFO ContextCleaner: Cleaned accumulator 213
21/02/17 00:33:10 INFO ContextCleaner: Cleaned accumulator 252
21/02/17 00:33:10 INFO ContextCleaner: Cleaned accumulator 425
21/02/17 00:33:10 INFO ContextCleaner: Cleaned accumulator 377
21/02/17 00:33:10 INFO ContextCleaner: Cleaned accumulator 439
21/02/17 00:33:10 INFO ContextCleaner: Cleaned accumulator 317
21/02/17 00:33:10 INFO ContextCleaner: Cleaned accumulator 395
21/02/17 00:33:10 INFO ContextCleaner: Cleaned accumulator 557
21/02/17 00:33:10 INFO ContextCleaner: Cleaned accumulator 253
21/02/17 00:33:10 INFO ContextCleaner: Cleaned accumulator 299
21/02/17 00:33:10 INFO ContextCleaner: Cleaned accumulator 282
21/02/17 00:33:10 INFO ContextCleaner: Cleaned accumulator 543
21/02/17 00:33:10 INFO ContextCleaner: Cleaned accumulator 362
21/02/17 00:33:10 INFO ContextCleaner: Cleaned accumulator 356
21/02/17 00:33:10 INFO ContextCleaner: Cleaned accumulator 512
21/02/17 00:33:10 INFO ContextCleaner: Cleaned accumulator 462
21/02/17 00:33:10 INFO ContextCleaner: Cleaned accumulator 338
21/02/17 00:33:10 INFO ContextCleaner: Cleaned accumulator 513
21/02/17 00:33:10 INFO ContextCleaner: Cleaned accumulator 262
21/02/17 00:33:10 INFO ContextCleaner: Cleaned accumulator 541
21/02/17 00:33:10 INFO ContextCleaner: Cleaned accumulator 451
21/02/17 00:33:10 INFO ContextCleaner: Cleaned accumulator 358
21/02/17 00:33:10 INFO ContextCleaner: Cleaned accumulator 495
21/02/17 00:33:10 INFO ContextCleaner: Cleaned accumulator 430
21/02/17 00:33:10 INFO ContextCleaner: Cleaned accumulator 271
21/02/17 00:33:10 INFO ContextCleaner: Cleaned accumulator 281
21/02/17 00:33:10 INFO ContextCleaner: Cleaned accumulator 493
21/02/17 00:33:10 INFO ContextCleaner: Cleaned accumulator 413
21/02/17 00:33:10 INFO ContextCleaner: Cleaned accumulator 248
21/02/17 00:33:10 INFO ContextCleaner: Cleaned accumulator 423
21/02/17 00:33:10 INFO ContextCleaner: Cleaned accumulator 520
21/02/17 00:33:10 INFO BlockManagerInfo: Removed broadcast_8_piece0 on localhost:37629 in memory (size: 13.9 KB, free: 912.2 MB)
21/02/17 00:33:10 INFO ContextCleaner: Cleaned accumulator 315
21/02/17 00:33:10 INFO ContextCleaner: Cleaned accumulator 387
21/02/17 00:33:10 INFO ContextCleaner: Cleaned accumulator 247
21/02/17 00:33:10 INFO ContextCleaner: Cleaned accumulator 214
21/02/17 00:33:10 INFO ContextCleaner: Cleaned accumulator 410
21/02/17 00:33:10 INFO ContextCleaner: Cleaned accumulator 289
21/02/17 00:33:10 INFO ContextCleaner: Cleaned accumulator 453
21/02/17 00:33:10 INFO ContextCleaner: Cleaned accumulator 383
21/02/17 00:33:10 INFO ContextCleaner: Cleaned accumulator 359
21/02/17 00:33:10 INFO ContextCleaner: Cleaned accumulator 460
21/02/17 00:33:10 INFO ContextCleaner: Cleaned accumulator 504
21/02/17 00:33:10 INFO ContextCleaner: Cleaned accumulator 337
21/02/17 00:33:10 INFO ContextCleaner: Cleaned accumulator 294
21/02/17 00:33:10 INFO ContextCleaner: Cleaned accumulator 524
21/02/17 00:33:10 INFO ContextCleaner: Cleaned accumulator 249
21/02/17 00:33:10 INFO ContextCleaner: Cleaned accumulator 293
21/02/17 00:33:10 INFO ContextCleaner: Cleaned accumulator 445
21/02/17 00:33:10 INFO ContextCleaner: Cleaned accumulator 278
21/02/17 00:33:10 INFO ContextCleaner: Cleaned accumulator 285
21/02/17 00:33:10 INFO ContextCleaner: Cleaned accumulator 485
21/02/17 00:33:10 INFO ContextCleaner: Cleaned accumulator 212
21/02/17 00:33:10 INFO BlockManagerInfo: Removed broadcast_16_piece0 on localhost:37629 in memory (size: 25.3 KB, free: 912.3 MB)
21/02/17 00:33:10 INFO ContextCleaner: Cleaned accumulator 341
21/02/17 00:33:10 INFO ContextCleaner: Cleaned accumulator 348
21/02/17 00:33:10 INFO ContextCleaner: Cleaned accumulator 527
21/02/17 00:33:10 INFO ContextCleaner: Cleaned accumulator 481
21/02/17 00:33:10 INFO ContextCleaner: Cleaned accumulator 461
21/02/17 00:33:10 INFO ContextCleaner: Cleaned accumulator 487
21/02/17 00:33:10 INFO ContextCleaner: Cleaned accumulator 319
21/02/17 00:33:10 INFO ContextCleaner: Cleaned accumulator 360
21/02/17 00:33:10 INFO ContextCleaner: Cleaned accumulator 528
21/02/17 00:33:10 INFO ContextCleaner: Cleaned accumulator 455
21/02/17 00:33:10 INFO ContextCleaner: Cleaned accumulator 518
21/02/17 00:33:10 INFO ContextCleaner: Cleaned accumulator 434
21/02/17 00:33:10 INFO ContextCleaner: Cleaned accumulator 354
21/02/17 00:33:10 INFO ContextCleaner: Cleaned accumulator 531
21/02/17 00:33:10 INFO ContextCleaner: Cleaned accumulator 306
21/02/17 00:33:10 INFO ContextCleaner: Cleaned accumulator 553
21/02/17 00:33:10 INFO ContextCleaner: Cleaned accumulator 313
21/02/17 00:33:10 INFO ContextCleaner: Cleaned accumulator 506
21/02/17 00:33:10 INFO ContextCleaner: Cleaned accumulator 476
21/02/17 00:33:10 INFO ContextCleaner: Cleaned accumulator 406
21/02/17 00:33:10 INFO ContextCleaner: Cleaned accumulator 532
21/02/17 00:33:10 INFO ContextCleaner: Cleaned accumulator 245
21/02/17 00:33:10 INFO ContextCleaner: Cleaned accumulator 334
21/02/17 00:33:10 INFO ContextCleaner: Cleaned accumulator 256
21/02/17 00:33:10 INFO ContextCleaner: Cleaned accumulator 499
21/02/17 00:33:10 INFO ContextCleaner: Cleaned accumulator 435
21/02/17 00:33:10 INFO ContextCleaner: Cleaned accumulator 274
21/02/17 00:33:10 INFO ContextCleaner: Cleaned accumulator 508
21/02/17 00:33:10 INFO ContextCleaner: Cleaned accumulator 291
21/02/17 00:33:10 INFO ContextCleaner: Cleaned accumulator 333
21/02/17 00:33:10 INFO ContextCleaner: Cleaned shuffle 2
21/02/17 00:33:10 INFO ContextCleaner: Cleaned accumulator 268
21/02/17 00:33:10 INFO ContextCleaner: Cleaned accumulator 473
21/02/17 00:33:10 INFO ContextCleaner: Cleaned accumulator 373
21/02/17 00:33:10 INFO ContextCleaner: Cleaned accumulator 397
21/02/17 00:33:10 INFO ContextCleaner: Cleaned accumulator 437
21/02/17 00:33:10 INFO ContextCleaner: Cleaned accumulator 494
21/02/17 00:33:10 INFO ContextCleaner: Cleaned accumulator 516
21/02/17 00:33:10 INFO ContextCleaner: Cleaned accumulator 250
21/02/17 00:33:10 INFO ContextCleaner: Cleaned accumulator 400
21/02/17 00:33:10 INFO ContextCleaner: Cleaned accumulator 556
21/02/17 00:33:10 INFO ContextCleaner: Cleaned accumulator 389
21/02/17 00:33:10 INFO ContextCleaner: Cleaned accumulator 396
21/02/17 00:33:10 INFO ContextCleaner: Cleaned accumulator 505
21/02/17 00:33:10 INFO ContextCleaner: Cleaned accumulator 417
21/02/17 00:33:10 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
21/02/17 00:33:10 INFO SparkContext: Starting job: runJob at SparkHadoopWriter.scala:78
21/02/17 00:33:10 INFO DAGScheduler: Got job 15 (runJob at SparkHadoopWriter.scala:78) with 1 output partitions
21/02/17 00:33:10 INFO DAGScheduler: Final stage: ResultStage 20 (runJob at SparkHadoopWriter.scala:78)
21/02/17 00:33:10 INFO DAGScheduler: Parents of final stage: List()
21/02/17 00:33:10 INFO DAGScheduler: Missing parents: List()
21/02/17 00:33:10 INFO DAGScheduler: Submitting ResultStage 20 (MapPartitionsRDD[73] at saveAsTextFile at ReadWrite.scala:283), which has no missing parents
21/02/17 00:33:10 INFO MemoryStore: Block broadcast_21 stored as values in memory (estimated size 71.3 KB, free 912.1 MB)
21/02/17 00:33:10 INFO MemoryStore: Block broadcast_21_piece0 stored as bytes in memory (estimated size 25.5 KB, free 912.1 MB)
21/02/17 00:33:10 INFO BlockManagerInfo: Added broadcast_21_piece0 in memory on localhost:37629 (size: 25.5 KB, free: 912.2 MB)
21/02/17 00:33:10 INFO SparkContext: Created broadcast 21 from broadcast at DAGScheduler.scala:1039
21/02/17 00:33:10 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 20 (MapPartitionsRDD[73] at saveAsTextFile at ReadWrite.scala:283) (first 15 tasks are for partitions Vector(0))
21/02/17 00:33:10 INFO TaskSchedulerImpl: Adding task set 20.0 with 1 tasks
21/02/17 00:33:10 INFO TaskSetManager: Starting task 0.0 in stage 20.0 (TID 20, localhost, executor driver, partition 0, PROCESS_LOCAL, 8097 bytes)
21/02/17 00:33:10 INFO Executor: Running task 0.0 in stage 20.0 (TID 20)
21/02/17 00:33:10 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
21/02/17 00:33:10 INFO FileOutputCommitter: Saved output of task 'attempt_20210217003310_0073_m_000000_0' to file:/tmp/RtmptF6Khl/file1ecf155f3fa56/stages/0_r_formula__707e5573_ac38_4d87_8d8e_2fb1f36d9f08/pipelineModel/stages/0_r_formula__707e5573_ac38_4d87_8d8e_2fb1f36d9f08/metadata/_temporary/0/task_20210217003310_0073_m_000000
21/02/17 00:33:10 INFO SparkHadoopMapRedUtil: attempt_20210217003310_0073_m_000000_0: Committed
21/02/17 00:33:10 INFO Executor: Finished task 0.0 in stage 20.0 (TID 20). 1029 bytes result sent to driver
21/02/17 00:33:10 INFO TaskSetManager: Finished task 0.0 in stage 20.0 (TID 20) in 12 ms on localhost (executor driver) (1/1)
21/02/17 00:33:10 INFO TaskSchedulerImpl: Removed TaskSet 20.0, whose tasks have all completed, from pool 
21/02/17 00:33:10 INFO DAGScheduler: ResultStage 20 (runJob at SparkHadoopWriter.scala:78) finished in 0.021 s
21/02/17 00:33:10 INFO DAGScheduler: Job 15 finished: runJob at SparkHadoopWriter.scala:78, took 0.022339 s
21/02/17 00:33:10 INFO SparkHadoopWriter: Job job_20210217003310_0073 committed.
21/02/17 00:33:10 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
21/02/17 00:33:10 INFO SparkContext: Starting job: runJob at SparkHadoopWriter.scala:78
21/02/17 00:33:10 INFO DAGScheduler: Got job 16 (runJob at SparkHadoopWriter.scala:78) with 1 output partitions
21/02/17 00:33:10 INFO DAGScheduler: Final stage: ResultStage 21 (runJob at SparkHadoopWriter.scala:78)
21/02/17 00:33:10 INFO DAGScheduler: Parents of final stage: List()
21/02/17 00:33:10 INFO DAGScheduler: Missing parents: List()
21/02/17 00:33:10 INFO DAGScheduler: Submitting ResultStage 21 (MapPartitionsRDD[75] at saveAsTextFile at ReadWrite.scala:283), which has no missing parents
21/02/17 00:33:10 INFO MemoryStore: Block broadcast_22 stored as values in memory (estimated size 71.2 KB, free 912.0 MB)
21/02/17 00:33:10 INFO MemoryStore: Block broadcast_22_piece0 stored as bytes in memory (estimated size 25.6 KB, free 912.0 MB)
21/02/17 00:33:10 INFO BlockManagerInfo: Added broadcast_22_piece0 in memory on localhost:37629 (size: 25.6 KB, free: 912.2 MB)
21/02/17 00:33:10 INFO SparkContext: Created broadcast 22 from broadcast at DAGScheduler.scala:1039
21/02/17 00:33:10 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 21 (MapPartitionsRDD[75] at saveAsTextFile at ReadWrite.scala:283) (first 15 tasks are for partitions Vector(0))
21/02/17 00:33:10 INFO TaskSchedulerImpl: Adding task set 21.0 with 1 tasks
21/02/17 00:33:10 INFO TaskSetManager: Starting task 0.0 in stage 21.0 (TID 21, localhost, executor driver, partition 0, PROCESS_LOCAL, 8024 bytes)
21/02/17 00:33:10 INFO Executor: Running task 0.0 in stage 21.0 (TID 21)
21/02/17 00:33:10 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
21/02/17 00:33:10 INFO FileOutputCommitter: Saved output of task 'attempt_20210217003310_0075_m_000000_0' to file:/tmp/RtmptF6Khl/file1ecf155f3fa56/stages/0_r_formula__707e5573_ac38_4d87_8d8e_2fb1f36d9f08/pipelineModel/stages/1_vectorAttrRewriter_9b40dc492122/metadata/_temporary/0/task_20210217003310_0075_m_000000
21/02/17 00:33:10 INFO SparkHadoopMapRedUtil: attempt_20210217003310_0075_m_000000_0: Committed
21/02/17 00:33:10 INFO Executor: Finished task 0.0 in stage 21.0 (TID 21). 1029 bytes result sent to driver
21/02/17 00:33:10 INFO TaskSetManager: Finished task 0.0 in stage 21.0 (TID 21) in 12 ms on localhost (executor driver) (1/1)
21/02/17 00:33:10 INFO TaskSchedulerImpl: Removed TaskSet 21.0, whose tasks have all completed, from pool 
21/02/17 00:33:10 INFO DAGScheduler: ResultStage 21 (runJob at SparkHadoopWriter.scala:78) finished in 0.022 s
21/02/17 00:33:10 INFO DAGScheduler: Job 16 finished: runJob at SparkHadoopWriter.scala:78, took 0.022666 s
21/02/17 00:33:10 INFO SparkHadoopWriter: Job job_20210217003310_0075 committed.
21/02/17 00:33:10 INFO ParquetFileFormat: Using default output committer for Parquet: org.apache.parquet.hadoop.ParquetOutputCommitter
21/02/17 00:33:10 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
21/02/17 00:33:10 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
21/02/17 00:33:10 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
21/02/17 00:33:10 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
21/02/17 00:33:10 INFO CodeGenerator: Code generated in 11.558441 ms
21/02/17 00:33:10 INFO SparkContext: Starting job: parquet at RFormula.scala:586
21/02/17 00:33:10 INFO DAGScheduler: Registering RDD 78 (parquet at RFormula.scala:586)
21/02/17 00:33:10 INFO DAGScheduler: Got job 17 (parquet at RFormula.scala:586) with 1 output partitions
21/02/17 00:33:10 INFO DAGScheduler: Final stage: ResultStage 23 (parquet at RFormula.scala:586)
21/02/17 00:33:10 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 22)
21/02/17 00:33:10 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 22)
21/02/17 00:33:10 INFO DAGScheduler: Submitting ShuffleMapStage 22 (MapPartitionsRDD[78] at parquet at RFormula.scala:586), which has no missing parents
21/02/17 00:33:10 INFO MemoryStore: Block broadcast_23 stored as values in memory (estimated size 4.8 KB, free 912.0 MB)
21/02/17 00:33:10 INFO MemoryStore: Block broadcast_23_piece0 stored as bytes in memory (estimated size 2.8 KB, free 912.0 MB)
21/02/17 00:33:10 INFO BlockManagerInfo: Added broadcast_23_piece0 in memory on localhost:37629 (size: 2.8 KB, free: 912.2 MB)
21/02/17 00:33:10 INFO SparkContext: Created broadcast 23 from broadcast at DAGScheduler.scala:1039
21/02/17 00:33:10 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 22 (MapPartitionsRDD[78] at parquet at RFormula.scala:586) (first 15 tasks are for partitions Vector(0))
21/02/17 00:33:10 INFO TaskSchedulerImpl: Adding task set 22.0 with 1 tasks
21/02/17 00:33:10 INFO TaskSetManager: Starting task 0.0 in stage 22.0 (TID 22, localhost, executor driver, partition 0, PROCESS_LOCAL, 8060 bytes)
21/02/17 00:33:10 INFO Executor: Running task 0.0 in stage 22.0 (TID 22)
21/02/17 00:33:10 INFO Executor: Finished task 0.0 in stage 22.0 (TID 22). 1247 bytes result sent to driver
21/02/17 00:33:10 INFO TaskSetManager: Finished task 0.0 in stage 22.0 (TID 22) in 3 ms on localhost (executor driver) (1/1)
21/02/17 00:33:10 INFO TaskSchedulerImpl: Removed TaskSet 22.0, whose tasks have all completed, from pool 
21/02/17 00:33:10 INFO DAGScheduler: ShuffleMapStage 22 (parquet at RFormula.scala:586) finished in 0.007 s
21/02/17 00:33:10 INFO DAGScheduler: looking for newly runnable stages
21/02/17 00:33:10 INFO DAGScheduler: running: Set()
21/02/17 00:33:10 INFO DAGScheduler: waiting: Set(ResultStage 23)
21/02/17 00:33:10 INFO DAGScheduler: failed: Set()
21/02/17 00:33:10 INFO DAGScheduler: Submitting ResultStage 23 (ShuffledRowRDD[79] at parquet at RFormula.scala:586), which has no missing parents
21/02/17 00:33:10 INFO MemoryStore: Block broadcast_24 stored as values in memory (estimated size 149.2 KB, free 911.8 MB)
21/02/17 00:33:10 INFO MemoryStore: Block broadcast_24_piece0 stored as bytes in memory (estimated size 53.2 KB, free 911.8 MB)
21/02/17 00:33:10 INFO BlockManagerInfo: Added broadcast_24_piece0 in memory on localhost:37629 (size: 53.2 KB, free: 912.2 MB)
21/02/17 00:33:10 INFO SparkContext: Created broadcast 24 from broadcast at DAGScheduler.scala:1039
21/02/17 00:33:10 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 23 (ShuffledRowRDD[79] at parquet at RFormula.scala:586) (first 15 tasks are for partitions Vector(0))
21/02/17 00:33:10 INFO TaskSchedulerImpl: Adding task set 23.0 with 1 tasks
21/02/17 00:33:10 INFO TaskSetManager: Starting task 0.0 in stage 23.0 (TID 23, localhost, executor driver, partition 0, NODE_LOCAL, 7754 bytes)
21/02/17 00:33:10 INFO Executor: Running task 0.0 in stage 23.0 (TID 23)
21/02/17 00:33:10 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
21/02/17 00:33:10 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
21/02/17 00:33:10 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
21/02/17 00:33:10 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
21/02/17 00:33:10 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
21/02/17 00:33:10 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
21/02/17 00:33:10 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:
{
  "type" : "struct",
  "fields" : [ {
    "name" : "vectorCol",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "prefixesToRewrite",
    "type" : {
      "type" : "map",
      "keyType" : "string",
      "valueType" : "string",
      "valueContainsNull" : true
    },
    "nullable" : true,
    "metadata" : { }
  } ]
}
and corresponding Parquet message type:
message spark_schema {
  optional binary vectorCol (UTF8);
  optional group prefixesToRewrite (MAP) {
    repeated group key_value {
      required binary key (UTF8);
      optional binary value (UTF8);
    }
  }
}

       
21/02/17 00:33:10 INFO FileOutputCommitter: Saved output of task 'attempt_20210217003310_0023_m_000000_0' to file:/tmp/RtmptF6Khl/file1ecf155f3fa56/stages/0_r_formula__707e5573_ac38_4d87_8d8e_2fb1f36d9f08/pipelineModel/stages/1_vectorAttrRewriter_9b40dc492122/data/_temporary/0/task_20210217003310_0023_m_000000
21/02/17 00:33:10 INFO SparkHadoopMapRedUtil: attempt_20210217003310_0023_m_000000_0: Committed
21/02/17 00:33:10 INFO Executor: Finished task 0.0 in stage 23.0 (TID 23). 2308 bytes result sent to driver
21/02/17 00:33:10 INFO TaskSetManager: Finished task 0.0 in stage 23.0 (TID 23) in 24 ms on localhost (executor driver) (1/1)
21/02/17 00:33:10 INFO TaskSchedulerImpl: Removed TaskSet 23.0, whose tasks have all completed, from pool 
21/02/17 00:33:10 INFO DAGScheduler: ResultStage 23 (parquet at RFormula.scala:586) finished in 0.039 s
21/02/17 00:33:10 INFO DAGScheduler: Job 17 finished: parquet at RFormula.scala:586, took 0.048177 s
21/02/17 00:33:10 INFO FileFormatWriter: Job null committed.
21/02/17 00:33:10 INFO FileFormatWriter: Finished processing stats for job null.
21/02/17 00:33:10 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
21/02/17 00:33:10 INFO SparkContext: Starting job: runJob at SparkHadoopWriter.scala:78
21/02/17 00:33:10 INFO DAGScheduler: Got job 18 (runJob at SparkHadoopWriter.scala:78) with 1 output partitions
21/02/17 00:33:10 INFO DAGScheduler: Final stage: ResultStage 24 (runJob at SparkHadoopWriter.scala:78)
21/02/17 00:33:10 INFO DAGScheduler: Parents of final stage: List()
21/02/17 00:33:10 INFO DAGScheduler: Missing parents: List()
21/02/17 00:33:10 INFO DAGScheduler: Submitting ResultStage 24 (MapPartitionsRDD[82] at saveAsTextFile at ReadWrite.scala:283), which has no missing parents
21/02/17 00:33:10 INFO MemoryStore: Block broadcast_25 stored as values in memory (estimated size 71.2 KB, free 911.7 MB)
21/02/17 00:33:10 INFO MemoryStore: Block broadcast_25_piece0 stored as bytes in memory (estimated size 25.6 KB, free 911.7 MB)
21/02/17 00:33:10 INFO BlockManagerInfo: Added broadcast_25_piece0 in memory on localhost:37629 (size: 25.6 KB, free: 912.1 MB)
21/02/17 00:33:10 INFO SparkContext: Created broadcast 25 from broadcast at DAGScheduler.scala:1039
21/02/17 00:33:10 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 24 (MapPartitionsRDD[82] at saveAsTextFile at ReadWrite.scala:283) (first 15 tasks are for partitions Vector(0))
21/02/17 00:33:10 INFO TaskSchedulerImpl: Adding task set 24.0 with 1 tasks
21/02/17 00:33:10 INFO TaskSetManager: Starting task 0.0 in stage 24.0 (TID 24, localhost, executor driver, partition 0, PROCESS_LOCAL, 8007 bytes)
21/02/17 00:33:10 INFO Executor: Running task 0.0 in stage 24.0 (TID 24)
21/02/17 00:33:10 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
21/02/17 00:33:10 INFO FileOutputCommitter: Saved output of task 'attempt_20210217003310_0082_m_000000_0' to file:/tmp/RtmptF6Khl/file1ecf155f3fa56/stages/0_r_formula__707e5573_ac38_4d87_8d8e_2fb1f36d9f08/pipelineModel/stages/2_columnPruner_a6c91fdc8e44/metadata/_temporary/0/task_20210217003310_0082_m_000000
21/02/17 00:33:10 INFO SparkHadoopMapRedUtil: attempt_20210217003310_0082_m_000000_0: Committed
21/02/17 00:33:10 INFO Executor: Finished task 0.0 in stage 24.0 (TID 24). 1029 bytes result sent to driver
21/02/17 00:33:10 INFO TaskSetManager: Finished task 0.0 in stage 24.0 (TID 24) in 11 ms on localhost (executor driver) (1/1)
21/02/17 00:33:10 INFO TaskSchedulerImpl: Removed TaskSet 24.0, whose tasks have all completed, from pool 
21/02/17 00:33:10 INFO DAGScheduler: ResultStage 24 (runJob at SparkHadoopWriter.scala:78) finished in 0.019 s
21/02/17 00:33:10 INFO DAGScheduler: Job 18 finished: runJob at SparkHadoopWriter.scala:78, took 0.020806 s
21/02/17 00:33:10 INFO SparkHadoopWriter: Job job_20210217003310_0082 committed.
21/02/17 00:33:10 INFO ParquetFileFormat: Using default output committer for Parquet: org.apache.parquet.hadoop.ParquetOutputCommitter
21/02/17 00:33:10 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
21/02/17 00:33:10 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
21/02/17 00:33:10 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
21/02/17 00:33:10 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
21/02/17 00:33:10 INFO CodeGenerator: Code generated in 5.555485 ms
21/02/17 00:33:10 INFO SparkContext: Starting job: parquet at RFormula.scala:495
21/02/17 00:33:10 INFO DAGScheduler: Registering RDD 85 (parquet at RFormula.scala:495)
21/02/17 00:33:10 INFO DAGScheduler: Got job 19 (parquet at RFormula.scala:495) with 1 output partitions
21/02/17 00:33:10 INFO DAGScheduler: Final stage: ResultStage 26 (parquet at RFormula.scala:495)
21/02/17 00:33:10 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 25)
21/02/17 00:33:10 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 25)
21/02/17 00:33:10 INFO DAGScheduler: Submitting ShuffleMapStage 25 (MapPartitionsRDD[85] at parquet at RFormula.scala:495), which has no missing parents
21/02/17 00:33:10 INFO MemoryStore: Block broadcast_26 stored as values in memory (estimated size 4.7 KB, free 911.7 MB)
21/02/17 00:33:10 INFO MemoryStore: Block broadcast_26_piece0 stored as bytes in memory (estimated size 2.8 KB, free 911.7 MB)
21/02/17 00:33:10 INFO BlockManagerInfo: Added broadcast_26_piece0 in memory on localhost:37629 (size: 2.8 KB, free: 912.1 MB)
21/02/17 00:33:10 INFO SparkContext: Created broadcast 26 from broadcast at DAGScheduler.scala:1039
21/02/17 00:33:10 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 25 (MapPartitionsRDD[85] at parquet at RFormula.scala:495) (first 15 tasks are for partitions Vector(0))
21/02/17 00:33:10 INFO TaskSchedulerImpl: Adding task set 25.0 with 1 tasks
21/02/17 00:33:10 INFO TaskSetManager: Starting task 0.0 in stage 25.0 (TID 25, localhost, executor driver, partition 0, PROCESS_LOCAL, 8028 bytes)
21/02/17 00:33:10 INFO Executor: Running task 0.0 in stage 25.0 (TID 25)
21/02/17 00:33:10 INFO Executor: Finished task 0.0 in stage 25.0 (TID 25). 1204 bytes result sent to driver
21/02/17 00:33:10 INFO TaskSetManager: Finished task 0.0 in stage 25.0 (TID 25) in 3 ms on localhost (executor driver) (1/1)
21/02/17 00:33:10 INFO TaskSchedulerImpl: Removed TaskSet 25.0, whose tasks have all completed, from pool 
21/02/17 00:33:10 INFO DAGScheduler: ShuffleMapStage 25 (parquet at RFormula.scala:495) finished in 0.008 s
21/02/17 00:33:10 INFO DAGScheduler: looking for newly runnable stages
21/02/17 00:33:10 INFO DAGScheduler: running: Set()
21/02/17 00:33:10 INFO DAGScheduler: waiting: Set(ResultStage 26)
21/02/17 00:33:10 INFO DAGScheduler: failed: Set()
21/02/17 00:33:10 INFO DAGScheduler: Submitting ResultStage 26 (ShuffledRowRDD[86] at parquet at RFormula.scala:495), which has no missing parents
21/02/17 00:33:10 INFO MemoryStore: Block broadcast_27 stored as values in memory (estimated size 149.0 KB, free 911.5 MB)
21/02/17 00:33:10 INFO MemoryStore: Block broadcast_27_piece0 stored as bytes in memory (estimated size 53.1 KB, free 911.5 MB)
21/02/17 00:33:10 INFO BlockManagerInfo: Added broadcast_27_piece0 in memory on localhost:37629 (size: 53.1 KB, free: 912.1 MB)
21/02/17 00:33:10 INFO SparkContext: Created broadcast 27 from broadcast at DAGScheduler.scala:1039
21/02/17 00:33:10 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 26 (ShuffledRowRDD[86] at parquet at RFormula.scala:495) (first 15 tasks are for partitions Vector(0))
21/02/17 00:33:10 INFO TaskSchedulerImpl: Adding task set 26.0 with 1 tasks
21/02/17 00:33:10 INFO TaskSetManager: Starting task 0.0 in stage 26.0 (TID 26, localhost, executor driver, partition 0, NODE_LOCAL, 7754 bytes)
21/02/17 00:33:10 INFO Executor: Running task 0.0 in stage 26.0 (TID 26)
21/02/17 00:33:10 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
21/02/17 00:33:10 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
21/02/17 00:33:10 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
21/02/17 00:33:10 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
21/02/17 00:33:10 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
21/02/17 00:33:10 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
21/02/17 00:33:10 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:
{
  "type" : "struct",
  "fields" : [ {
    "name" : "columnsToPrune",
    "type" : {
      "type" : "array",
      "elementType" : "string",
      "containsNull" : true
    },
    "nullable" : true,
    "metadata" : { }
  } ]
}
and corresponding Parquet message type:
message spark_schema {
  optional group columnsToPrune (LIST) {
    repeated group list {
      optional binary element (UTF8);
    }
  }
}

       
21/02/17 00:33:10 INFO FileOutputCommitter: Saved output of task 'attempt_20210217003310_0026_m_000000_0' to file:/tmp/RtmptF6Khl/file1ecf155f3fa56/stages/0_r_formula__707e5573_ac38_4d87_8d8e_2fb1f36d9f08/pipelineModel/stages/2_columnPruner_a6c91fdc8e44/data/_temporary/0/task_20210217003310_0026_m_000000
21/02/17 00:33:10 INFO SparkHadoopMapRedUtil: attempt_20210217003310_0026_m_000000_0: Committed
21/02/17 00:33:10 INFO Executor: Finished task 0.0 in stage 26.0 (TID 26). 2308 bytes result sent to driver
21/02/17 00:33:10 INFO TaskSetManager: Finished task 0.0 in stage 26.0 (TID 26) in 16 ms on localhost (executor driver) (1/1)
21/02/17 00:33:10 INFO TaskSchedulerImpl: Removed TaskSet 26.0, whose tasks have all completed, from pool 
21/02/17 00:33:10 INFO DAGScheduler: ResultStage 26 (parquet at RFormula.scala:495) finished in 0.034 s
21/02/17 00:33:10 INFO DAGScheduler: Job 19 finished: parquet at RFormula.scala:495, took 0.044388 s
21/02/17 00:33:10 INFO FileFormatWriter: Job null committed.
21/02/17 00:33:10 INFO FileFormatWriter: Finished processing stats for job null.
21/02/17 00:33:10 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
21/02/17 00:33:10 INFO SparkContext: Starting job: runJob at SparkHadoopWriter.scala:78
21/02/17 00:33:10 INFO DAGScheduler: Got job 20 (runJob at SparkHadoopWriter.scala:78) with 1 output partitions
21/02/17 00:33:10 INFO DAGScheduler: Final stage: ResultStage 27 (runJob at SparkHadoopWriter.scala:78)
21/02/17 00:33:10 INFO DAGScheduler: Parents of final stage: List()
21/02/17 00:33:10 INFO DAGScheduler: Missing parents: List()
21/02/17 00:33:10 INFO DAGScheduler: Submitting ResultStage 27 (MapPartitionsRDD[89] at saveAsTextFile at DefaultXGBoostParamsWriter.scala:52), which has no missing parents
21/02/17 00:33:10 INFO MemoryStore: Block broadcast_28 stored as values in memory (estimated size 71.1 KB, free 911.4 MB)
21/02/17 00:33:10 INFO MemoryStore: Block broadcast_28_piece0 stored as bytes in memory (estimated size 25.4 KB, free 911.4 MB)
21/02/17 00:33:10 INFO BlockManagerInfo: Added broadcast_28_piece0 in memory on localhost:37629 (size: 25.4 KB, free: 912.1 MB)
21/02/17 00:33:10 INFO SparkContext: Created broadcast 28 from broadcast at DAGScheduler.scala:1039
21/02/17 00:33:10 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 27 (MapPartitionsRDD[89] at saveAsTextFile at DefaultXGBoostParamsWriter.scala:52) (first 15 tasks are for partitions Vector(0))
21/02/17 00:33:10 INFO TaskSchedulerImpl: Adding task set 27.0 with 1 tasks
21/02/17 00:33:10 INFO TaskSetManager: Starting task 0.0 in stage 27.0 (TID 27, localhost, executor driver, partition 0, PROCESS_LOCAL, 8936 bytes)
21/02/17 00:33:10 INFO Executor: Running task 0.0 in stage 27.0 (TID 27)
21/02/17 00:33:10 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
21/02/17 00:33:10 INFO FileOutputCommitter: Saved output of task 'attempt_20210217003310_0089_m_000000_0' to file:/tmp/RtmptF6Khl/file1ecf155f3fa56/stages/1_xgboost_regressor__60249f5c_5cc1_4ff3_98e6_27a65c8f804b/metadata/_temporary/0/task_20210217003310_0089_m_000000
21/02/17 00:33:10 INFO SparkHadoopMapRedUtil: attempt_20210217003310_0089_m_000000_0: Committed
21/02/17 00:33:10 INFO Executor: Finished task 0.0 in stage 27.0 (TID 27). 1029 bytes result sent to driver
21/02/17 00:33:10 INFO TaskSetManager: Finished task 0.0 in stage 27.0 (TID 27) in 9 ms on localhost (executor driver) (1/1)
21/02/17 00:33:10 INFO TaskSchedulerImpl: Removed TaskSet 27.0, whose tasks have all completed, from pool 
21/02/17 00:33:10 INFO DAGScheduler: ResultStage 27 (runJob at SparkHadoopWriter.scala:78) finished in 0.017 s
21/02/17 00:33:10 INFO DAGScheduler: Job 20 finished: runJob at SparkHadoopWriter.scala:78, took 0.018065 s
21/02/17 00:33:10 INFO SparkHadoopWriter: Job job_20210217003310_0089 committed.
21/02/17 00:33:10 INFO HiveMetaStore: 0: get_database: default
21/02/17 00:33:10 INFO audit: ugi=yitaoli	ip=unknown-ip-addr	cmd=get_database: default	
21/02/17 00:33:10 INFO HiveMetaStore: 0: get_database: default
21/02/17 00:33:10 INFO audit: ugi=yitaoli	ip=unknown-ip-addr	cmd=get_database: default	
21/02/17 00:33:10 INFO HiveMetaStore: 0: get_tables: db=default pat=*
21/02/17 00:33:10 INFO audit: ugi=yitaoli	ip=unknown-ip-addr	cmd=get_tables: db=default pat=*	
21/02/17 00:33:10 INFO CodeGenerator: Code generated in 4.499664 ms
21/02/17 00:33:10 INFO SparkContext: Starting job: collect at utils.scala:61
21/02/17 00:33:10 INFO DAGScheduler: Got job 21 (collect at utils.scala:61) with 2 output partitions
21/02/17 00:33:10 INFO DAGScheduler: Final stage: ResultStage 28 (collect at utils.scala:61)
21/02/17 00:33:10 INFO DAGScheduler: Parents of final stage: List()
21/02/17 00:33:10 INFO DAGScheduler: Missing parents: List()
21/02/17 00:33:10 INFO DAGScheduler: Submitting ResultStage 28 (MapPartitionsRDD[94] at map at utils.scala:54), which has no missing parents
21/02/17 00:33:10 INFO MemoryStore: Block broadcast_29 stored as values in memory (estimated size 5.9 KB, free 911.4 MB)
21/02/17 00:33:10 INFO MemoryStore: Block broadcast_29_piece0 stored as bytes in memory (estimated size 3.3 KB, free 911.4 MB)
21/02/17 00:33:10 INFO BlockManagerInfo: Added broadcast_29_piece0 in memory on localhost:37629 (size: 3.3 KB, free: 912.1 MB)
21/02/17 00:33:10 INFO SparkContext: Created broadcast 29 from broadcast at DAGScheduler.scala:1039
21/02/17 00:33:10 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 28 (MapPartitionsRDD[94] at map at utils.scala:54) (first 15 tasks are for partitions Vector(0, 1))
21/02/17 00:33:10 INFO TaskSchedulerImpl: Adding task set 28.0 with 2 tasks
21/02/17 00:33:10 INFO TaskSetManager: Starting task 0.0 in stage 28.0 (TID 28, localhost, executor driver, partition 0, PROCESS_LOCAL, 8039 bytes)
21/02/17 00:33:10 INFO TaskSetManager: Starting task 1.0 in stage 28.0 (TID 29, localhost, executor driver, partition 1, PROCESS_LOCAL, 8087 bytes)
21/02/17 00:33:10 INFO Executor: Running task 0.0 in stage 28.0 (TID 28)
21/02/17 00:33:10 INFO Executor: Running task 1.0 in stage 28.0 (TID 29)
21/02/17 00:33:10 INFO Executor: Finished task 1.0 in stage 28.0 (TID 29). 1022 bytes result sent to driver
21/02/17 00:33:10 INFO Executor: Finished task 0.0 in stage 28.0 (TID 28). 977 bytes result sent to driver
21/02/17 00:33:10 INFO TaskSetManager: Finished task 1.0 in stage 28.0 (TID 29) in 4 ms on localhost (executor driver) (1/2)
21/02/17 00:33:10 INFO TaskSetManager: Finished task 0.0 in stage 28.0 (TID 28) in 5 ms on localhost (executor driver) (2/2)
21/02/17 00:33:10 INFO TaskSchedulerImpl: Removed TaskSet 28.0, whose tasks have all completed, from pool 
21/02/17 00:33:10 INFO DAGScheduler: ResultStage 28 (collect at utils.scala:61) finished in 0.009 s
21/02/17 00:33:10 INFO DAGScheduler: Job 21 finished: collect at utils.scala:61, took 0.009686 s
21/02/17 00:33:10 INFO FileSourceStrategy: Pruning directories with: 
21/02/17 00:33:10 INFO FileSourceStrategy: Post-Scan Filters: 
21/02/17 00:33:10 INFO FileSourceStrategy: Output Data Schema: struct<value: string>
21/02/17 00:33:10 INFO FileSourceScanExec: Pushed Filters: 
21/02/17 00:33:10 INFO CodeGenerator: Code generated in 3.295362 ms
21/02/17 00:33:10 INFO MemoryStore: Block broadcast_30 stored as values in memory (estimated size 288.4 KB, free 911.1 MB)
21/02/17 00:33:10 INFO MemoryStore: Block broadcast_30_piece0 stored as bytes in memory (estimated size 24.5 KB, free 911.1 MB)
21/02/17 00:33:10 INFO BlockManagerInfo: Added broadcast_30_piece0 in memory on localhost:37629 (size: 24.5 KB, free: 912.0 MB)
21/02/17 00:33:10 INFO SparkContext: Created broadcast 30 from json at NativeMethodAccessorImpl.java:0
21/02/17 00:33:10 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
21/02/17 00:33:10 INFO SparkContext: Starting job: json at NativeMethodAccessorImpl.java:0
21/02/17 00:33:10 INFO DAGScheduler: Got job 22 (json at NativeMethodAccessorImpl.java:0) with 1 output partitions
21/02/17 00:33:10 INFO DAGScheduler: Final stage: ResultStage 29 (json at NativeMethodAccessorImpl.java:0)
21/02/17 00:33:10 INFO DAGScheduler: Parents of final stage: List()
21/02/17 00:33:10 INFO DAGScheduler: Missing parents: List()
21/02/17 00:33:10 INFO DAGScheduler: Submitting ResultStage 29 (MapPartitionsRDD[98] at json at NativeMethodAccessorImpl.java:0), which has no missing parents
21/02/17 00:33:10 INFO MemoryStore: Block broadcast_31 stored as values in memory (estimated size 9.4 KB, free 911.1 MB)
21/02/17 00:33:10 INFO MemoryStore: Block broadcast_31_piece0 stored as bytes in memory (estimated size 5.1 KB, free 911.1 MB)
21/02/17 00:33:10 INFO BlockManagerInfo: Added broadcast_31_piece0 in memory on localhost:37629 (size: 5.1 KB, free: 912.0 MB)
21/02/17 00:33:10 INFO SparkContext: Created broadcast 31 from broadcast at DAGScheduler.scala:1039
21/02/17 00:33:10 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 29 (MapPartitionsRDD[98] at json at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
21/02/17 00:33:10 INFO TaskSchedulerImpl: Adding task set 29.0 with 1 tasks
21/02/17 00:33:10 INFO TaskSetManager: Starting task 0.0 in stage 29.0 (TID 30, localhost, executor driver, partition 0, PROCESS_LOCAL, 8325 bytes)
21/02/17 00:33:10 INFO Executor: Running task 0.0 in stage 29.0 (TID 30)
21/02/17 00:33:10 INFO FileScanRDD: Reading File path: file:///tmp/RtmptF6Khl/file1ecf155f3fa56/metadata/part-00000, range: 0-285, partition values: [empty row]
21/02/17 00:33:10 INFO CodeGenerator: Code generated in 4.081183 ms
21/02/17 00:33:10 INFO Executor: Finished task 0.0 in stage 29.0 (TID 30). 2138 bytes result sent to driver
21/02/17 00:33:10 INFO TaskSetManager: Finished task 0.0 in stage 29.0 (TID 30) in 29 ms on localhost (executor driver) (1/1)
21/02/17 00:33:10 INFO TaskSchedulerImpl: Removed TaskSet 29.0, whose tasks have all completed, from pool 
21/02/17 00:33:10 INFO DAGScheduler: ResultStage 29 (json at NativeMethodAccessorImpl.java:0) finished in 0.032 s
21/02/17 00:33:10 INFO DAGScheduler: Job 22 finished: json at NativeMethodAccessorImpl.java:0, took 0.035895 s
21/02/17 00:33:10 INFO HiveMetaStore: 0: get_database: default
21/02/17 00:33:10 INFO audit: ugi=yitaoli	ip=unknown-ip-addr	cmd=get_database: default	
21/02/17 00:33:10 INFO HiveMetaStore: 0: get_database: default
21/02/17 00:33:10 INFO audit: ugi=yitaoli	ip=unknown-ip-addr	cmd=get_database: default	
21/02/17 00:33:10 INFO HiveMetaStore: 0: get_tables: db=default pat=*
21/02/17 00:33:10 INFO audit: ugi=yitaoli	ip=unknown-ip-addr	cmd=get_tables: db=default pat=*	
21/02/17 00:33:10 INFO CodeGenerator: Code generated in 4.607316 ms
21/02/17 00:33:10 INFO CodeGenerator: Code generated in 3.515899 ms
21/02/17 00:33:10 INFO SparkContext: Starting job: count at utils.scala:135
21/02/17 00:33:10 INFO DAGScheduler: Registering RDD 102 (count at utils.scala:135)
21/02/17 00:33:10 INFO DAGScheduler: Got job 23 (count at utils.scala:135) with 1 output partitions
21/02/17 00:33:10 INFO DAGScheduler: Final stage: ResultStage 31 (count at utils.scala:135)
21/02/17 00:33:10 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 30)
21/02/17 00:33:10 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 30)
21/02/17 00:33:10 INFO DAGScheduler: Submitting ShuffleMapStage 30 (MapPartitionsRDD[102] at count at utils.scala:135), which has no missing parents
21/02/17 00:33:10 INFO MemoryStore: Block broadcast_32 stored as values in memory (estimated size 8.0 KB, free 911.1 MB)
21/02/17 00:33:10 INFO MemoryStore: Block broadcast_32_piece0 stored as bytes in memory (estimated size 4.2 KB, free 911.1 MB)
21/02/17 00:33:10 INFO BlockManagerInfo: Added broadcast_32_piece0 in memory on localhost:37629 (size: 4.2 KB, free: 912.0 MB)
21/02/17 00:33:10 INFO SparkContext: Created broadcast 32 from broadcast at DAGScheduler.scala:1039
21/02/17 00:33:10 INFO DAGScheduler: Submitting 2 missing tasks from ShuffleMapStage 30 (MapPartitionsRDD[102] at count at utils.scala:135) (first 15 tasks are for partitions Vector(0, 1))
21/02/17 00:33:10 INFO TaskSchedulerImpl: Adding task set 30.0 with 2 tasks
21/02/17 00:33:10 INFO TaskSetManager: Starting task 0.0 in stage 30.0 (TID 31, localhost, executor driver, partition 0, PROCESS_LOCAL, 8004 bytes)
21/02/17 00:33:10 INFO TaskSetManager: Starting task 1.0 in stage 30.0 (TID 32, localhost, executor driver, partition 1, PROCESS_LOCAL, 8004 bytes)
21/02/17 00:33:10 INFO Executor: Running task 0.0 in stage 30.0 (TID 31)
21/02/17 00:33:10 INFO Executor: Running task 1.0 in stage 30.0 (TID 32)
21/02/17 00:33:10 INFO Executor: Finished task 1.0 in stage 30.0 (TID 32). 1499 bytes result sent to driver
21/02/17 00:33:10 INFO Executor: Finished task 0.0 in stage 30.0 (TID 31). 1499 bytes result sent to driver
21/02/17 00:33:10 INFO TaskSetManager: Finished task 1.0 in stage 30.0 (TID 32) in 3 ms on localhost (executor driver) (1/2)
21/02/17 00:33:10 INFO TaskSetManager: Finished task 0.0 in stage 30.0 (TID 31) in 5 ms on localhost (executor driver) (2/2)
21/02/17 00:33:10 INFO TaskSchedulerImpl: Removed TaskSet 30.0, whose tasks have all completed, from pool 
21/02/17 00:33:10 INFO DAGScheduler: ShuffleMapStage 30 (count at utils.scala:135) finished in 0.008 s
21/02/17 00:33:10 INFO DAGScheduler: looking for newly runnable stages
21/02/17 00:33:10 INFO DAGScheduler: running: Set()
21/02/17 00:33:10 INFO DAGScheduler: waiting: Set(ResultStage 31)
21/02/17 00:33:10 INFO DAGScheduler: failed: Set()
21/02/17 00:33:10 INFO DAGScheduler: Submitting ResultStage 31 (MapPartitionsRDD[105] at count at utils.scala:135), which has no missing parents
21/02/17 00:33:10 INFO MemoryStore: Block broadcast_33 stored as values in memory (estimated size 7.3 KB, free 911.1 MB)
21/02/17 00:33:10 INFO MemoryStore: Block broadcast_33_piece0 stored as bytes in memory (estimated size 3.8 KB, free 911.1 MB)
21/02/17 00:33:10 INFO BlockManagerInfo: Added broadcast_33_piece0 in memory on localhost:37629 (size: 3.8 KB, free: 912.0 MB)
21/02/17 00:33:10 INFO SparkContext: Created broadcast 33 from broadcast at DAGScheduler.scala:1039
21/02/17 00:33:10 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 31 (MapPartitionsRDD[105] at count at utils.scala:135) (first 15 tasks are for partitions Vector(0))
21/02/17 00:33:10 INFO TaskSchedulerImpl: Adding task set 31.0 with 1 tasks
21/02/17 00:33:10 INFO TaskSetManager: Starting task 0.0 in stage 31.0 (TID 33, localhost, executor driver, partition 0, NODE_LOCAL, 7754 bytes)
21/02/17 00:33:10 INFO Executor: Running task 0.0 in stage 31.0 (TID 33)
21/02/17 00:33:10 INFO ShuffleBlockFetcherIterator: Getting 2 non-empty blocks out of 2 blocks
21/02/17 00:33:10 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
21/02/17 00:33:10 INFO Executor: Finished task 0.0 in stage 31.0 (TID 33). 1782 bytes result sent to driver
21/02/17 00:33:10 INFO TaskSetManager: Finished task 0.0 in stage 31.0 (TID 33) in 4 ms on localhost (executor driver) (1/1)
21/02/17 00:33:10 INFO TaskSchedulerImpl: Removed TaskSet 31.0, whose tasks have all completed, from pool 
21/02/17 00:33:10 INFO DAGScheduler: ResultStage 31 (count at utils.scala:135) finished in 0.009 s
21/02/17 00:33:10 INFO DAGScheduler: Job 23 finished: count at utils.scala:135, took 0.019260 s
21/02/17 00:33:11 INFO FileSourceStrategy: Pruning directories with: 
21/02/17 00:33:11 INFO FileSourceStrategy: Post-Scan Filters: 
21/02/17 00:33:11 INFO FileSourceStrategy: Output Data Schema: struct<class: string, paramMap: struct<stageUids: array<string>>, sparkVersion: string, timestamp: bigint, uid: string ... 3 more fields>
21/02/17 00:33:11 INFO FileSourceScanExec: Pushed Filters: 
21/02/17 00:33:11 INFO MemoryStore: Block broadcast_34 stored as values in memory (estimated size 288.4 KB, free 910.8 MB)
21/02/17 00:33:11 INFO MemoryStore: Block broadcast_34_piece0 stored as bytes in memory (estimated size 24.5 KB, free 910.7 MB)
21/02/17 00:33:11 INFO BlockManagerInfo: Added broadcast_34_piece0 in memory on localhost:37629 (size: 24.5 KB, free: 912.0 MB)
21/02/17 00:33:11 INFO SparkContext: Created broadcast 34 from sql at <unknown>:0
21/02/17 00:33:11 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
21/02/17 00:33:11 INFO SparkContext: Starting job: sql at <unknown>:0
21/02/17 00:33:11 INFO DAGScheduler: Registering RDD 113 (sql at <unknown>:0)
21/02/17 00:33:11 INFO DAGScheduler: Got job 24 (sql at <unknown>:0) with 1 output partitions
21/02/17 00:33:11 INFO DAGScheduler: Final stage: ResultStage 33 (sql at <unknown>:0)
21/02/17 00:33:11 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 32)
21/02/17 00:33:11 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 32)
21/02/17 00:33:11 INFO DAGScheduler: Submitting ShuffleMapStage 32 (MapPartitionsRDD[113] at sql at <unknown>:0), which has no missing parents
21/02/17 00:33:11 INFO MemoryStore: Block broadcast_35 stored as values in memory (estimated size 19.7 KB, free 910.7 MB)
21/02/17 00:33:11 INFO MemoryStore: Block broadcast_35_piece0 stored as bytes in memory (estimated size 9.4 KB, free 910.7 MB)
21/02/17 00:33:11 INFO BlockManagerInfo: Added broadcast_35_piece0 in memory on localhost:37629 (size: 9.4 KB, free: 912.0 MB)
21/02/17 00:33:11 INFO SparkContext: Created broadcast 35 from broadcast at DAGScheduler.scala:1039
21/02/17 00:33:11 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 32 (MapPartitionsRDD[113] at sql at <unknown>:0) (first 15 tasks are for partitions Vector(0))
21/02/17 00:33:11 INFO TaskSchedulerImpl: Adding task set 32.0 with 1 tasks
21/02/17 00:33:11 INFO TaskSetManager: Starting task 0.0 in stage 32.0 (TID 34, localhost, executor driver, partition 0, PROCESS_LOCAL, 8314 bytes)
21/02/17 00:33:11 INFO Executor: Running task 0.0 in stage 32.0 (TID 34)
21/02/17 00:33:11 INFO FileScanRDD: Reading File path: file:///tmp/RtmptF6Khl/file1ecf155f3fa56/metadata/part-00000, range: 0-285, partition values: [empty row]
21/02/17 00:33:11 INFO CodeGenerator: Code generated in 7.079444 ms
21/02/17 00:33:11 INFO MemoryStore: Block rdd_108_0 stored as values in memory (estimated size 1296.0 B, free 910.7 MB)
21/02/17 00:33:11 INFO BlockManagerInfo: Added rdd_108_0 in memory on localhost:37629 (size: 1296.0 B, free: 912.0 MB)
21/02/17 00:33:11 INFO CodeGenerator: Code generated in 7.38329 ms
21/02/17 00:33:11 INFO Executor: Finished task 0.0 in stage 32.0 (TID 34). 1871 bytes result sent to driver
21/02/17 00:33:11 INFO TaskSetManager: Finished task 0.0 in stage 32.0 (TID 34) in 44 ms on localhost (executor driver) (1/1)
21/02/17 00:33:11 INFO TaskSchedulerImpl: Removed TaskSet 32.0, whose tasks have all completed, from pool 
21/02/17 00:33:11 INFO DAGScheduler: ShuffleMapStage 32 (sql at <unknown>:0) finished in 0.049 s
21/02/17 00:33:11 INFO DAGScheduler: looking for newly runnable stages
21/02/17 00:33:11 INFO DAGScheduler: running: Set()
21/02/17 00:33:11 INFO DAGScheduler: waiting: Set(ResultStage 33)
21/02/17 00:33:11 INFO DAGScheduler: failed: Set()
21/02/17 00:33:11 INFO DAGScheduler: Submitting ResultStage 33 (MapPartitionsRDD[116] at sql at <unknown>:0), which has no missing parents
21/02/17 00:33:11 INFO MemoryStore: Block broadcast_36 stored as values in memory (estimated size 7.3 KB, free 910.7 MB)
21/02/17 00:33:11 INFO MemoryStore: Block broadcast_36_piece0 stored as bytes in memory (estimated size 3.8 KB, free 910.7 MB)
21/02/17 00:33:11 INFO BlockManagerInfo: Added broadcast_36_piece0 in memory on localhost:37629 (size: 3.8 KB, free: 912.0 MB)
21/02/17 00:33:11 INFO SparkContext: Created broadcast 36 from broadcast at DAGScheduler.scala:1039
21/02/17 00:33:11 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 33 (MapPartitionsRDD[116] at sql at <unknown>:0) (first 15 tasks are for partitions Vector(0))
21/02/17 00:33:11 INFO TaskSchedulerImpl: Adding task set 33.0 with 1 tasks
21/02/17 00:33:11 INFO TaskSetManager: Starting task 0.0 in stage 33.0 (TID 35, localhost, executor driver, partition 0, NODE_LOCAL, 7754 bytes)
21/02/17 00:33:11 INFO Executor: Running task 0.0 in stage 33.0 (TID 35)
21/02/17 00:33:11 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
21/02/17 00:33:11 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
21/02/17 00:33:11 INFO Executor: Finished task 0.0 in stage 33.0 (TID 35). 1782 bytes result sent to driver
21/02/17 00:33:11 INFO TaskSetManager: Finished task 0.0 in stage 33.0 (TID 35) in 3 ms on localhost (executor driver) (1/1)
21/02/17 00:33:11 INFO TaskSchedulerImpl: Removed TaskSet 33.0, whose tasks have all completed, from pool 
21/02/17 00:33:11 INFO DAGScheduler: ResultStage 33 (sql at <unknown>:0) finished in 0.007 s
21/02/17 00:33:11 INFO DAGScheduler: Job 24 finished: sql at <unknown>:0, took 0.059210 s
21/02/17 00:33:11 INFO HiveMetaStore: 0: get_database: default
21/02/17 00:33:11 INFO audit: ugi=yitaoli	ip=unknown-ip-addr	cmd=get_database: default	
21/02/17 00:33:11 INFO CodeGenerator: Code generated in 3.957289 ms
21/02/17 00:33:11 INFO SparkContext: Starting job: collect at utils.scala:135
21/02/17 00:33:11 INFO DAGScheduler: Registering RDD 121 (collect at utils.scala:135)
21/02/17 00:33:11 INFO DAGScheduler: Got job 25 (collect at utils.scala:135) with 1 output partitions
21/02/17 00:33:11 INFO DAGScheduler: Final stage: ResultStage 35 (collect at utils.scala:135)
21/02/17 00:33:11 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 34)
21/02/17 00:33:11 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 34)
21/02/17 00:33:11 INFO DAGScheduler: Submitting ShuffleMapStage 34 (MapPartitionsRDD[121] at collect at utils.scala:135), which has no missing parents
21/02/17 00:33:11 INFO MemoryStore: Block broadcast_37 stored as values in memory (estimated size 19.7 KB, free 910.7 MB)
21/02/17 00:33:11 INFO MemoryStore: Block broadcast_37_piece0 stored as bytes in memory (estimated size 9.4 KB, free 910.7 MB)
21/02/17 00:33:11 INFO BlockManagerInfo: Added broadcast_37_piece0 in memory on localhost:37629 (size: 9.4 KB, free: 912.0 MB)
21/02/17 00:33:11 INFO SparkContext: Created broadcast 37 from broadcast at DAGScheduler.scala:1039
21/02/17 00:33:11 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 34 (MapPartitionsRDD[121] at collect at utils.scala:135) (first 15 tasks are for partitions Vector(0))
21/02/17 00:33:11 INFO TaskSchedulerImpl: Adding task set 34.0 with 1 tasks
21/02/17 00:33:11 INFO TaskSetManager: Starting task 0.0 in stage 34.0 (TID 36, localhost, executor driver, partition 0, PROCESS_LOCAL, 8314 bytes)
21/02/17 00:33:11 INFO Executor: Running task 0.0 in stage 34.0 (TID 36)
21/02/17 00:33:11 INFO BlockManager: Found block rdd_108_0 locally
21/02/17 00:33:11 INFO Executor: Finished task 0.0 in stage 34.0 (TID 36). 1871 bytes result sent to driver
21/02/17 00:33:11 INFO TaskSetManager: Finished task 0.0 in stage 34.0 (TID 36) in 5 ms on localhost (executor driver) (1/1)
21/02/17 00:33:11 INFO TaskSchedulerImpl: Removed TaskSet 34.0, whose tasks have all completed, from pool 
21/02/17 00:33:11 INFO DAGScheduler: ShuffleMapStage 34 (collect at utils.scala:135) finished in 0.010 s
21/02/17 00:33:11 INFO DAGScheduler: looking for newly runnable stages
21/02/17 00:33:11 INFO DAGScheduler: running: Set()
21/02/17 00:33:11 INFO DAGScheduler: waiting: Set(ResultStage 35)
21/02/17 00:33:11 INFO DAGScheduler: failed: Set()
21/02/17 00:33:11 INFO DAGScheduler: Submitting ResultStage 35 (MapPartitionsRDD[124] at collect at utils.scala:135), which has no missing parents
21/02/17 00:33:11 INFO MemoryStore: Block broadcast_38 stored as values in memory (estimated size 7.3 KB, free 910.7 MB)
21/02/17 00:33:11 INFO MemoryStore: Block broadcast_38_piece0 stored as bytes in memory (estimated size 3.8 KB, free 910.7 MB)
21/02/17 00:33:11 INFO BlockManagerInfo: Added broadcast_38_piece0 in memory on localhost:37629 (size: 3.8 KB, free: 912.0 MB)
21/02/17 00:33:11 INFO SparkContext: Created broadcast 38 from broadcast at DAGScheduler.scala:1039
21/02/17 00:33:11 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 35 (MapPartitionsRDD[124] at collect at utils.scala:135) (first 15 tasks are for partitions Vector(0))
21/02/17 00:33:11 INFO TaskSchedulerImpl: Adding task set 35.0 with 1 tasks
21/02/17 00:33:11 INFO TaskSetManager: Starting task 0.0 in stage 35.0 (TID 37, localhost, executor driver, partition 0, NODE_LOCAL, 7754 bytes)
21/02/17 00:33:11 INFO Executor: Running task 0.0 in stage 35.0 (TID 37)
21/02/17 00:33:11 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
21/02/17 00:33:11 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
21/02/17 00:33:11 INFO Executor: Finished task 0.0 in stage 35.0 (TID 37). 1782 bytes result sent to driver
21/02/17 00:33:11 INFO TaskSetManager: Finished task 0.0 in stage 35.0 (TID 37) in 4 ms on localhost (executor driver) (1/1)
21/02/17 00:33:11 INFO TaskSchedulerImpl: Removed TaskSet 35.0, whose tasks have all completed, from pool 
21/02/17 00:33:11 INFO DAGScheduler: ResultStage 35 (collect at utils.scala:135) finished in 0.006 s
21/02/17 00:33:11 INFO DAGScheduler: Job 25 finished: collect at utils.scala:135, took 0.018332 s
21/02/17 00:33:11 INFO CodeGenerator: Code generated in 6.313776 ms
21/02/17 00:33:11 INFO CodeGenerator: Code generated in 5.868127 ms
21/02/17 00:33:11 INFO SparkContext: Starting job: count at utils.scala:135
21/02/17 00:33:11 INFO DAGScheduler: Registering RDD 129 (count at utils.scala:135)
21/02/17 00:33:11 INFO DAGScheduler: Got job 26 (count at utils.scala:135) with 1 output partitions
21/02/17 00:33:11 INFO DAGScheduler: Final stage: ResultStage 37 (count at utils.scala:135)
21/02/17 00:33:11 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 36)
21/02/17 00:33:11 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 36)
21/02/17 00:33:11 INFO DAGScheduler: Submitting ShuffleMapStage 36 (MapPartitionsRDD[129] at count at utils.scala:135), which has no missing parents
21/02/17 00:33:11 INFO MemoryStore: Block broadcast_39 stored as values in memory (estimated size 18.7 KB, free 910.6 MB)
21/02/17 00:33:11 INFO MemoryStore: Block broadcast_39_piece0 stored as bytes in memory (estimated size 9.0 KB, free 910.6 MB)
21/02/17 00:33:11 INFO BlockManagerInfo: Added broadcast_39_piece0 in memory on localhost:37629 (size: 9.0 KB, free: 912.0 MB)
21/02/17 00:33:11 INFO SparkContext: Created broadcast 39 from broadcast at DAGScheduler.scala:1039
21/02/17 00:33:11 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 36 (MapPartitionsRDD[129] at count at utils.scala:135) (first 15 tasks are for partitions Vector(0))
21/02/17 00:33:11 INFO TaskSchedulerImpl: Adding task set 36.0 with 1 tasks
21/02/17 00:33:11 INFO TaskSetManager: Starting task 0.0 in stage 36.0 (TID 38, localhost, executor driver, partition 0, PROCESS_LOCAL, 8314 bytes)
21/02/17 00:33:11 INFO Executor: Running task 0.0 in stage 36.0 (TID 38)
21/02/17 00:33:11 INFO BlockManager: Found block rdd_108_0 locally
21/02/17 00:33:11 INFO Executor: Finished task 0.0 in stage 36.0 (TID 38). 1871 bytes result sent to driver
21/02/17 00:33:11 INFO TaskSetManager: Finished task 0.0 in stage 36.0 (TID 38) in 6 ms on localhost (executor driver) (1/1)
21/02/17 00:33:11 INFO TaskSchedulerImpl: Removed TaskSet 36.0, whose tasks have all completed, from pool 
21/02/17 00:33:11 INFO DAGScheduler: ShuffleMapStage 36 (count at utils.scala:135) finished in 0.011 s
21/02/17 00:33:11 INFO DAGScheduler: looking for newly runnable stages
21/02/17 00:33:11 INFO DAGScheduler: running: Set()
21/02/17 00:33:11 INFO DAGScheduler: waiting: Set(ResultStage 37)
21/02/17 00:33:11 INFO DAGScheduler: failed: Set()
21/02/17 00:33:11 INFO DAGScheduler: Submitting ResultStage 37 (MapPartitionsRDD[132] at count at utils.scala:135), which has no missing parents
21/02/17 00:33:11 INFO MemoryStore: Block broadcast_40 stored as values in memory (estimated size 9.8 KB, free 910.6 MB)
21/02/17 00:33:11 INFO MemoryStore: Block broadcast_40_piece0 stored as bytes in memory (estimated size 4.2 KB, free 910.6 MB)
21/02/17 00:33:11 INFO BlockManagerInfo: Added broadcast_40_piece0 in memory on localhost:37629 (size: 4.2 KB, free: 912.0 MB)
21/02/17 00:33:11 INFO SparkContext: Created broadcast 40 from broadcast at DAGScheduler.scala:1039
21/02/17 00:33:11 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 37 (MapPartitionsRDD[132] at count at utils.scala:135) (first 15 tasks are for partitions Vector(0))
21/02/17 00:33:11 INFO TaskSchedulerImpl: Adding task set 37.0 with 1 tasks
21/02/17 00:33:11 INFO TaskSetManager: Starting task 0.0 in stage 37.0 (TID 39, localhost, executor driver, partition 0, NODE_LOCAL, 7754 bytes)
21/02/17 00:33:11 INFO Executor: Running task 0.0 in stage 37.0 (TID 39)
21/02/17 00:33:11 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
21/02/17 00:33:11 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
21/02/17 00:33:11 INFO Executor: Finished task 0.0 in stage 37.0 (TID 39). 2098 bytes result sent to driver
21/02/17 00:33:11 INFO TaskSetManager: Finished task 0.0 in stage 37.0 (TID 39) in 6 ms on localhost (executor driver) (1/1)
21/02/17 00:33:11 INFO TaskSchedulerImpl: Removed TaskSet 37.0, whose tasks have all completed, from pool 
21/02/17 00:33:11 INFO DAGScheduler: ResultStage 37 (count at utils.scala:135) finished in 0.010 s
21/02/17 00:33:11 INFO DAGScheduler: Job 26 finished: count at utils.scala:135, took 0.023754 s
21/02/17 00:33:11 INFO SparkContext: Starting job: collect at utils.scala:135
21/02/17 00:33:11 INFO DAGScheduler: Got job 27 (collect at utils.scala:135) with 1 output partitions
21/02/17 00:33:11 INFO DAGScheduler: Final stage: ResultStage 38 (collect at utils.scala:135)
21/02/17 00:33:11 INFO DAGScheduler: Parents of final stage: List()
21/02/17 00:33:11 INFO DAGScheduler: Missing parents: List()
21/02/17 00:33:11 INFO DAGScheduler: Submitting ResultStage 38 (MapPartitionsRDD[135] at collect at utils.scala:135), which has no missing parents
21/02/17 00:33:11 INFO MemoryStore: Block broadcast_41 stored as values in memory (estimated size 6.4 KB, free 910.6 MB)
21/02/17 00:33:11 INFO MemoryStore: Block broadcast_41_piece0 stored as bytes in memory (estimated size 3.2 KB, free 910.6 MB)
21/02/17 00:33:11 INFO BlockManagerInfo: Added broadcast_41_piece0 in memory on localhost:37629 (size: 3.2 KB, free: 912.0 MB)
21/02/17 00:33:11 INFO SparkContext: Created broadcast 41 from broadcast at DAGScheduler.scala:1039
21/02/17 00:33:11 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 38 (MapPartitionsRDD[135] at collect at utils.scala:135) (first 15 tasks are for partitions Vector(0))
21/02/17 00:33:11 INFO TaskSchedulerImpl: Adding task set 38.0 with 1 tasks
21/02/17 00:33:11 INFO TaskSetManager: Starting task 0.0 in stage 38.0 (TID 40, localhost, executor driver, partition 0, PROCESS_LOCAL, 8067 bytes)
21/02/17 00:33:11 INFO Executor: Running task 0.0 in stage 38.0 (TID 40)
21/02/17 00:33:11 INFO Executor: Finished task 0.0 in stage 38.0 (TID 40). 1243 bytes result sent to driver
21/02/17 00:33:11 INFO TaskSetManager: Finished task 0.0 in stage 38.0 (TID 40) in 3 ms on localhost (executor driver) (1/1)
21/02/17 00:33:11 INFO TaskSchedulerImpl: Removed TaskSet 38.0, whose tasks have all completed, from pool 
21/02/17 00:33:11 INFO DAGScheduler: ResultStage 38 (collect at utils.scala:135) finished in 0.006 s
21/02/17 00:33:11 INFO DAGScheduler: Job 27 finished: collect at utils.scala:135, took 0.007519 s
21/02/17 00:33:11 INFO SparkContext: Starting job: count at utils.scala:135
21/02/17 00:33:11 INFO DAGScheduler: Registering RDD 138 (count at utils.scala:135)
21/02/17 00:33:11 INFO DAGScheduler: Got job 28 (count at utils.scala:135) with 1 output partitions
21/02/17 00:33:11 INFO DAGScheduler: Final stage: ResultStage 40 (count at utils.scala:135)
21/02/17 00:33:11 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 39)
21/02/17 00:33:11 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 39)
21/02/17 00:33:11 INFO DAGScheduler: Submitting ShuffleMapStage 39 (MapPartitionsRDD[138] at count at utils.scala:135), which has no missing parents
21/02/17 00:33:11 INFO MemoryStore: Block broadcast_42 stored as values in memory (estimated size 8.9 KB, free 910.6 MB)
21/02/17 00:33:11 INFO MemoryStore: Block broadcast_42_piece0 stored as bytes in memory (estimated size 4.5 KB, free 910.6 MB)
21/02/17 00:33:11 INFO BlockManagerInfo: Added broadcast_42_piece0 in memory on localhost:37629 (size: 4.5 KB, free: 911.9 MB)
21/02/17 00:33:11 INFO SparkContext: Created broadcast 42 from broadcast at DAGScheduler.scala:1039
21/02/17 00:33:11 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 39 (MapPartitionsRDD[138] at count at utils.scala:135) (first 15 tasks are for partitions Vector(0))
21/02/17 00:33:11 INFO TaskSchedulerImpl: Adding task set 39.0 with 1 tasks
21/02/17 00:33:11 INFO TaskSetManager: Starting task 0.0 in stage 39.0 (TID 41, localhost, executor driver, partition 0, PROCESS_LOCAL, 8056 bytes)
21/02/17 00:33:11 INFO Executor: Running task 0.0 in stage 39.0 (TID 41)
21/02/17 00:33:11 INFO Executor: Finished task 0.0 in stage 39.0 (TID 41). 1499 bytes result sent to driver
21/02/17 00:33:11 INFO TaskSetManager: Finished task 0.0 in stage 39.0 (TID 41) in 3 ms on localhost (executor driver) (1/1)
21/02/17 00:33:11 INFO TaskSchedulerImpl: Removed TaskSet 39.0, whose tasks have all completed, from pool 
21/02/17 00:33:11 INFO DAGScheduler: ShuffleMapStage 39 (count at utils.scala:135) finished in 0.008 s
21/02/17 00:33:11 INFO DAGScheduler: looking for newly runnable stages
21/02/17 00:33:11 INFO DAGScheduler: running: Set()
21/02/17 00:33:11 INFO DAGScheduler: waiting: Set(ResultStage 40)
21/02/17 00:33:11 INFO DAGScheduler: failed: Set()
21/02/17 00:33:11 INFO DAGScheduler: Submitting ResultStage 40 (MapPartitionsRDD[141] at count at utils.scala:135), which has no missing parents
21/02/17 00:33:11 INFO MemoryStore: Block broadcast_43 stored as values in memory (estimated size 7.3 KB, free 910.6 MB)
21/02/17 00:33:11 INFO MemoryStore: Block broadcast_43_piece0 stored as bytes in memory (estimated size 3.8 KB, free 910.6 MB)
21/02/17 00:33:11 INFO BlockManagerInfo: Added broadcast_43_piece0 in memory on localhost:37629 (size: 3.8 KB, free: 911.9 MB)
21/02/17 00:33:11 INFO SparkContext: Created broadcast 43 from broadcast at DAGScheduler.scala:1039
21/02/17 00:33:11 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 40 (MapPartitionsRDD[141] at count at utils.scala:135) (first 15 tasks are for partitions Vector(0))
21/02/17 00:33:11 INFO TaskSchedulerImpl: Adding task set 40.0 with 1 tasks
21/02/17 00:33:11 INFO TaskSetManager: Starting task 0.0 in stage 40.0 (TID 42, localhost, executor driver, partition 0, NODE_LOCAL, 7754 bytes)
21/02/17 00:33:11 INFO Executor: Running task 0.0 in stage 40.0 (TID 42)
21/02/17 00:33:11 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
21/02/17 00:33:11 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
21/02/17 00:33:11 INFO Executor: Finished task 0.0 in stage 40.0 (TID 42). 1739 bytes result sent to driver
21/02/17 00:33:11 INFO TaskSetManager: Finished task 0.0 in stage 40.0 (TID 42) in 4 ms on localhost (executor driver) (1/1)
21/02/17 00:33:11 INFO TaskSchedulerImpl: Removed TaskSet 40.0, whose tasks have all completed, from pool 
21/02/17 00:33:11 INFO DAGScheduler: ResultStage 40 (count at utils.scala:135) finished in 0.007 s
21/02/17 00:33:11 INFO DAGScheduler: Job 28 finished: count at utils.scala:135, took 0.017918 s
21/02/17 00:33:11 INFO CodeGenerator: Code generated in 6.147477 ms
21/02/17 00:33:11 INFO SparkContext: Starting job: collect at utils.scala:135
21/02/17 00:33:11 INFO DAGScheduler: Got job 29 (collect at utils.scala:135) with 1 output partitions
21/02/17 00:33:11 INFO DAGScheduler: Final stage: ResultStage 41 (collect at utils.scala:135)
21/02/17 00:33:11 INFO DAGScheduler: Parents of final stage: List()
21/02/17 00:33:11 INFO DAGScheduler: Missing parents: List()
21/02/17 00:33:11 INFO DAGScheduler: Submitting ResultStage 41 (MapPartitionsRDD[145] at collect at utils.scala:135), which has no missing parents
21/02/17 00:33:11 INFO MemoryStore: Block broadcast_44 stored as values in memory (estimated size 15.7 KB, free 910.6 MB)
21/02/17 00:33:11 INFO MemoryStore: Block broadcast_44_piece0 stored as bytes in memory (estimated size 7.9 KB, free 910.6 MB)
21/02/17 00:33:11 INFO BlockManagerInfo: Added broadcast_44_piece0 in memory on localhost:37629 (size: 7.9 KB, free: 911.9 MB)
21/02/17 00:33:11 INFO SparkContext: Created broadcast 44 from broadcast at DAGScheduler.scala:1039
21/02/17 00:33:11 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 41 (MapPartitionsRDD[145] at collect at utils.scala:135) (first 15 tasks are for partitions Vector(0))
21/02/17 00:33:11 INFO TaskSchedulerImpl: Adding task set 41.0 with 1 tasks
21/02/17 00:33:11 INFO TaskSetManager: Starting task 0.0 in stage 41.0 (TID 43, localhost, executor driver, partition 0, PROCESS_LOCAL, 8325 bytes)
21/02/17 00:33:11 INFO Executor: Running task 0.0 in stage 41.0 (TID 43)
21/02/17 00:33:11 INFO BlockManager: Found block rdd_108_0 locally
21/02/17 00:33:11 INFO CodeGenerator: Code generated in 11.158503 ms
21/02/17 00:33:11 INFO Executor: Finished task 0.0 in stage 41.0 (TID 43). 1615 bytes result sent to driver
21/02/17 00:33:11 INFO TaskSetManager: Finished task 0.0 in stage 41.0 (TID 43) in 18 ms on localhost (executor driver) (1/1)
21/02/17 00:33:11 INFO TaskSchedulerImpl: Removed TaskSet 41.0, whose tasks have all completed, from pool 
21/02/17 00:33:11 INFO DAGScheduler: ResultStage 41 (collect at utils.scala:135) finished in 0.024 s
21/02/17 00:33:11 INFO DAGScheduler: Job 29 finished: collect at utils.scala:135, took 0.025499 s
21/02/17 00:33:11 INFO SparkContext: Starting job: count at utils.scala:135
21/02/17 00:33:11 INFO DAGScheduler: Registering RDD 150 (count at utils.scala:135)
21/02/17 00:33:11 INFO DAGScheduler: Got job 30 (count at utils.scala:135) with 1 output partitions
21/02/17 00:33:11 INFO DAGScheduler: Final stage: ResultStage 43 (count at utils.scala:135)
21/02/17 00:33:11 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 42)
21/02/17 00:33:11 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 42)
21/02/17 00:33:11 INFO DAGScheduler: Submitting ShuffleMapStage 42 (MapPartitionsRDD[150] at count at utils.scala:135), which has no missing parents
21/02/17 00:33:11 INFO MemoryStore: Block broadcast_45 stored as values in memory (estimated size 19.7 KB, free 910.6 MB)
21/02/17 00:33:11 INFO MemoryStore: Block broadcast_45_piece0 stored as bytes in memory (estimated size 9.4 KB, free 910.5 MB)
21/02/17 00:33:11 INFO BlockManagerInfo: Added broadcast_45_piece0 in memory on localhost:37629 (size: 9.4 KB, free: 911.9 MB)
21/02/17 00:33:11 INFO SparkContext: Created broadcast 45 from broadcast at DAGScheduler.scala:1039
21/02/17 00:33:11 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 42 (MapPartitionsRDD[150] at count at utils.scala:135) (first 15 tasks are for partitions Vector(0))
21/02/17 00:33:11 INFO TaskSchedulerImpl: Adding task set 42.0 with 1 tasks
21/02/17 00:33:11 INFO TaskSetManager: Starting task 0.0 in stage 42.0 (TID 44, localhost, executor driver, partition 0, PROCESS_LOCAL, 8314 bytes)
21/02/17 00:33:11 INFO Executor: Running task 0.0 in stage 42.0 (TID 44)
21/02/17 00:33:11 INFO BlockManager: Found block rdd_108_0 locally
21/02/17 00:33:11 INFO Executor: Finished task 0.0 in stage 42.0 (TID 44). 1871 bytes result sent to driver
21/02/17 00:33:11 INFO TaskSetManager: Finished task 0.0 in stage 42.0 (TID 44) in 6 ms on localhost (executor driver) (1/1)
21/02/17 00:33:11 INFO TaskSchedulerImpl: Removed TaskSet 42.0, whose tasks have all completed, from pool 
21/02/17 00:33:11 INFO DAGScheduler: ShuffleMapStage 42 (count at utils.scala:135) finished in 0.011 s
21/02/17 00:33:11 INFO DAGScheduler: looking for newly runnable stages
21/02/17 00:33:11 INFO DAGScheduler: running: Set()
21/02/17 00:33:11 INFO DAGScheduler: waiting: Set(ResultStage 43)
21/02/17 00:33:11 INFO DAGScheduler: failed: Set()
21/02/17 00:33:11 INFO DAGScheduler: Submitting ResultStage 43 (MapPartitionsRDD[153] at count at utils.scala:135), which has no missing parents
21/02/17 00:33:11 INFO MemoryStore: Block broadcast_46 stored as values in memory (estimated size 7.3 KB, free 910.5 MB)
21/02/17 00:33:11 INFO MemoryStore: Block broadcast_46_piece0 stored as bytes in memory (estimated size 3.8 KB, free 910.5 MB)
21/02/17 00:33:11 INFO BlockManagerInfo: Added broadcast_46_piece0 in memory on localhost:37629 (size: 3.8 KB, free: 911.9 MB)
21/02/17 00:33:11 INFO SparkContext: Created broadcast 46 from broadcast at DAGScheduler.scala:1039
21/02/17 00:33:11 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 43 (MapPartitionsRDD[153] at count at utils.scala:135) (first 15 tasks are for partitions Vector(0))
21/02/17 00:33:11 INFO TaskSchedulerImpl: Adding task set 43.0 with 1 tasks
21/02/17 00:33:11 INFO TaskSetManager: Starting task 0.0 in stage 43.0 (TID 45, localhost, executor driver, partition 0, NODE_LOCAL, 7754 bytes)
21/02/17 00:33:11 INFO Executor: Running task 0.0 in stage 43.0 (TID 45)
21/02/17 00:33:11 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
21/02/17 00:33:11 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
21/02/17 00:33:11 INFO Executor: Finished task 0.0 in stage 43.0 (TID 45). 1782 bytes result sent to driver
21/02/17 00:33:11 INFO TaskSetManager: Finished task 0.0 in stage 43.0 (TID 45) in 4 ms on localhost (executor driver) (1/1)
21/02/17 00:33:11 INFO TaskSchedulerImpl: Removed TaskSet 43.0, whose tasks have all completed, from pool 
21/02/17 00:33:11 INFO DAGScheduler: ResultStage 43 (count at utils.scala:135) finished in 0.007 s
21/02/17 00:33:11 INFO DAGScheduler: Job 30 finished: count at utils.scala:135, took 0.021024 s
21/02/17 00:33:11 INFO MapPartitionsRDD: Removing RDD 108 from persistence list
21/02/17 00:33:11 INFO BlockManager: Removing RDD 108
21/02/17 00:33:11 INFO MemoryStore: Block broadcast_47 stored as values in memory (estimated size 239.4 KB, free 910.3 MB)
21/02/17 00:33:11 INFO ContextCleaner: Cleaned accumulator 584
21/02/17 00:33:11 INFO ContextCleaner: Cleaned accumulator 740
21/02/17 00:33:11 INFO ContextCleaner: Cleaned accumulator 713
21/02/17 00:33:11 INFO ContextCleaner: Cleaned accumulator 924
21/02/17 00:33:11 INFO ContextCleaner: Cleaned accumulator 575
21/02/17 00:33:11 INFO ContextCleaner: Cleaned accumulator 775
21/02/17 00:33:11 INFO ContextCleaner: Cleaned accumulator 916
21/02/17 00:33:11 INFO ContextCleaner: Cleaned accumulator 1273
21/02/17 00:33:11 INFO ContextCleaner: Cleaned accumulator 810
21/02/17 00:33:11 INFO ContextCleaner: Cleaned accumulator 1024
21/02/17 00:33:11 INFO ContextCleaner: Cleaned accumulator 925
21/02/17 00:33:11 INFO ContextCleaner: Cleaned accumulator 1213
21/02/17 00:33:11 INFO ContextCleaner: Cleaned accumulator 1146
21/02/17 00:33:11 INFO ContextCleaner: Cleaned accumulator 1016
21/02/17 00:33:11 INFO ContextCleaner: Cleaned accumulator 795
21/02/17 00:33:11 INFO ContextCleaner: Cleaned accumulator 1102
21/02/17 00:33:11 INFO ContextCleaner: Cleaned accumulator 615
21/02/17 00:33:11 INFO ContextCleaner: Cleaned accumulator 1063
21/02/17 00:33:11 INFO ContextCleaner: Cleaned accumulator 732
21/02/17 00:33:11 INFO ContextCleaner: Cleaned accumulator 1173
21/02/17 00:33:11 INFO ContextCleaner: Cleaned accumulator 616
21/02/17 00:33:11 INFO ContextCleaner: Cleaned accumulator 1046
21/02/17 00:33:11 INFO ContextCleaner: Cleaned accumulator 1155
21/02/17 00:33:11 INFO ContextCleaner: Cleaned accumulator 1250
21/02/17 00:33:11 INFO ContextCleaner: Cleaned accumulator 951
21/02/17 00:33:11 INFO ContextCleaner: Cleaned accumulator 889
21/02/17 00:33:11 INFO MemoryStore: Block broadcast_47_piece0 stored as bytes in memory (estimated size 23.2 KB, free 910.3 MB)
21/02/17 00:33:11 INFO BlockManagerInfo: Removed broadcast_29_piece0 on localhost:37629 in memory (size: 3.3 KB, free: 911.9 MB)
21/02/17 00:33:11 INFO BlockManagerInfo: Added broadcast_47_piece0 in memory on localhost:37629 (size: 23.2 KB, free: 911.9 MB)
21/02/17 00:33:11 INFO ContextCleaner: Cleaned accumulator 744
21/02/17 00:33:11 INFO ContextCleaner: Cleaned accumulator 1143
21/02/17 00:33:11 INFO ContextCleaner: Cleaned accumulator 662
21/02/17 00:33:11 INFO ContextCleaner: Cleaned accumulator 697
21/02/17 00:33:11 INFO ContextCleaner: Cleaned accumulator 1116
21/02/17 00:33:11 INFO ContextCleaner: Cleaned accumulator 1226
21/02/17 00:33:11 INFO ContextCleaner: Cleaned shuffle 6
21/02/17 00:33:11 INFO ContextCleaner: Cleaned accumulator 938
21/02/17 00:33:11 INFO ContextCleaner: Cleaned accumulator 1019
21/02/17 00:33:11 INFO ContextCleaner: Cleaned accumulator 890
21/02/17 00:33:11 INFO ContextCleaner: Cleaned accumulator 1013
21/02/17 00:33:11 INFO ContextCleaner: Cleaned accumulator 960
21/02/17 00:33:11 INFO ContextCleaner: Cleaned accumulator 967
21/02/17 00:33:11 INFO SparkContext: Created broadcast 47 from textFile at ReadWrite.scala:387
21/02/17 00:33:11 INFO BlockManagerInfo: Removed broadcast_37_piece0 on localhost:37629 in memory (size: 9.4 KB, free: 911.9 MB)
21/02/17 00:33:11 INFO ContextCleaner: Cleaned accumulator 1313
21/02/17 00:33:11 INFO ContextCleaner: Cleaned accumulator 634
21/02/17 00:33:11 INFO ContextCleaner: Cleaned accumulator 715
21/02/17 00:33:11 INFO ContextCleaner: Cleaned accumulator 1082
21/02/17 00:33:11 INFO ContextCleaner: Cleaned accumulator 570
21/02/17 00:33:11 INFO ContextCleaner: Cleaned accumulator 923
21/02/17 00:33:11 INFO ContextCleaner: Cleaned accumulator 675
21/02/17 00:33:11 INFO ContextCleaner: Cleaned accumulator 1121
21/02/17 00:33:11 INFO ContextCleaner: Cleaned accumulator 1079
21/02/17 00:33:11 INFO ContextCleaner: Cleaned accumulator 873
21/02/17 00:33:11 INFO ContextCleaner: Cleaned accumulator 1151
21/02/17 00:33:11 INFO ContextCleaner: Cleaned accumulator 1239
21/02/17 00:33:11 INFO ContextCleaner: Cleaned accumulator 1031
21/02/17 00:33:11 INFO ContextCleaner: Cleaned accumulator 957
21/02/17 00:33:11 INFO ContextCleaner: Cleaned accumulator 1169
21/02/17 00:33:11 INFO ContextCleaner: Cleaned accumulator 1305
21/02/17 00:33:11 INFO ContextCleaner: Cleaned accumulator 1034
21/02/17 00:33:11 INFO ContextCleaner: Cleaned accumulator 1071
21/02/17 00:33:11 INFO ContextCleaner: Cleaned accumulator 818
21/02/17 00:33:11 INFO ContextCleaner: Cleaned accumulator 920
21/02/17 00:33:11 INFO ContextCleaner: Cleaned accumulator 1126
21/02/17 00:33:11 INFO ContextCleaner: Cleaned accumulator 1206
21/02/17 00:33:11 INFO BlockManagerInfo: Removed broadcast_35_piece0 on localhost:37629 in memory (size: 9.4 KB, free: 911.9 MB)
21/02/17 00:33:11 INFO ContextCleaner: Cleaned accumulator 1043
21/02/17 00:33:11 INFO ContextCleaner: Cleaned accumulator 612
21/02/17 00:33:11 INFO BlockManagerInfo: Removed broadcast_21_piece0 on localhost:37629 in memory (size: 25.5 KB, free: 911.9 MB)
21/02/17 00:33:11 INFO ContextCleaner: Cleaned accumulator 625
21/02/17 00:33:11 INFO ContextCleaner: Cleaned accumulator 1029
21/02/17 00:33:11 INFO ContextCleaner: Cleaned accumulator 726
21/02/17 00:33:11 INFO ContextCleaner: Cleaned accumulator 621
21/02/17 00:33:11 INFO ContextCleaner: Cleaned accumulator 1140
21/02/17 00:33:11 INFO ContextCleaner: Cleaned accumulator 678
21/02/17 00:33:11 INFO ContextCleaner: Cleaned accumulator 959
21/02/17 00:33:11 INFO ContextCleaner: Cleaned accumulator 643
21/02/17 00:33:11 INFO ContextCleaner: Cleaned accumulator 1085
21/02/17 00:33:11 INFO ContextCleaner: Cleaned accumulator 720
21/02/17 00:33:11 INFO ContextCleaner: Cleaned accumulator 786
21/02/17 00:33:11 INFO ContextCleaner: Cleaned accumulator 1318
21/02/17 00:33:11 INFO ContextCleaner: Cleaned accumulator 1097
21/02/17 00:33:11 INFO ContextCleaner: Cleaned accumulator 1027
21/02/17 00:33:11 INFO ContextCleaner: Cleaned accumulator 956
21/02/17 00:33:11 INFO ContextCleaner: Cleaned accumulator 1059
21/02/17 00:33:11 INFO ContextCleaner: Cleaned accumulator 999
21/02/17 00:33:11 INFO ContextCleaner: Cleaned accumulator 1215
21/02/17 00:33:11 INFO ContextCleaner: Cleaned accumulator 1004
21/02/17 00:33:11 INFO ContextCleaner: Cleaned accumulator 1257
21/02/17 00:33:11 INFO ContextCleaner: Cleaned accumulator 725
21/02/17 00:33:11 INFO ContextCleaner: Cleaned accumulator 1020
21/02/17 00:33:11 INFO ContextCleaner: Cleaned accumulator 1142
21/02/17 00:33:11 INFO ContextCleaner: Cleaned accumulator 815
21/02/17 00:33:11 INFO ContextCleaner: Cleaned accumulator 1095
21/02/17 00:33:11 INFO BlockManagerInfo: Removed broadcast_20_piece0 on localhost:37629 in memory (size: 25.5 KB, free: 912.0 MB)
21/02/17 00:33:11 INFO ContextCleaner: Cleaned accumulator 673
21/02/17 00:33:11 INFO ContextCleaner: Cleaned accumulator 589
21/02/17 00:33:11 INFO ContextCleaner: Cleaned accumulator 650
21/02/17 00:33:11 INFO ContextCleaner: Cleaned accumulator 1053
21/02/17 00:33:11 INFO ContextCleaner: Cleaned accumulator 623
21/02/17 00:33:11 INFO ContextCleaner: Cleaned accumulator 979
21/02/17 00:33:11 INFO ContextCleaner: Cleaned accumulator 886
21/02/17 00:33:11 INFO ContextCleaner: Cleaned accumulator 834
21/02/17 00:33:11 INFO ContextCleaner: Cleaned accumulator 857
21/02/17 00:33:11 INFO ContextCleaner: Cleaned accumulator 841
21/02/17 00:33:11 INFO ContextCleaner: Cleaned accumulator 696
21/02/17 00:33:11 INFO ContextCleaner: Cleaned accumulator 976
21/02/17 00:33:11 INFO ContextCleaner: Cleaned accumulator 1172
21/02/17 00:33:11 INFO ContextCleaner: Cleaned accumulator 1113
21/02/17 00:33:11 INFO ContextCleaner: Cleaned accumulator 1152
21/02/17 00:33:11 INFO ContextCleaner: Cleaned accumulator 1256
21/02/17 00:33:11 INFO ContextCleaner: Cleaned accumulator 661
21/02/17 00:33:11 INFO ContextCleaner: Cleaned accumulator 624
21/02/17 00:33:11 INFO ContextCleaner: Cleaned accumulator 1089
21/02/17 00:33:11 INFO ContextCleaner: Cleaned accumulator 1192
21/02/17 00:33:11 INFO ContextCleaner: Cleaned accumulator 568
21/02/17 00:33:11 INFO ContextCleaner: Cleaned accumulator 777
21/02/17 00:33:11 INFO ContextCleaner: Cleaned accumulator 1147
21/02/17 00:33:11 INFO ContextCleaner: Cleaned accumulator 1138
21/02/17 00:33:11 INFO ContextCleaner: Cleaned accumulator 702
21/02/17 00:33:11 INFO BlockManagerInfo: Removed broadcast_26_piece0 on localhost:37629 in memory (size: 2.8 KB, free: 912.0 MB)
21/02/17 00:33:11 INFO ContextCleaner: Cleaned accumulator 790
21/02/17 00:33:11 INFO ContextCleaner: Cleaned accumulator 1219
21/02/17 00:33:11 INFO ContextCleaner: Cleaned accumulator 1061
21/02/17 00:33:11 INFO ContextCleaner: Cleaned accumulator 878
21/02/17 00:33:11 INFO ContextCleaner: Cleaned accumulator 1018
21/02/17 00:33:11 INFO ContextCleaner: Cleaned accumulator 1150
21/02/17 00:33:11 INFO ContextCleaner: Cleaned accumulator 1098
21/02/17 00:33:11 INFO ContextCleaner: Cleaned accumulator 793
21/02/17 00:33:11 INFO ContextCleaner: Cleaned accumulator 1202
21/02/17 00:33:11 INFO ContextCleaner: Cleaned accumulator 792
21/02/17 00:33:11 INFO ContextCleaner: Cleaned accumulator 723
21/02/17 00:33:11 INFO ContextCleaner: Cleaned accumulator 995
21/02/17 00:33:11 INFO ContextCleaner: Cleaned accumulator 670
21/02/17 00:33:11 INFO ContextCleaner: Cleaned accumulator 592
21/02/17 00:33:11 INFO ContextCleaner: Cleaned accumulator 848
21/02/17 00:33:11 INFO ContextCleaner: Cleaned accumulator 809
21/02/17 00:33:11 INFO ContextCleaner: Cleaned accumulator 1175
21/02/17 00:33:11 INFO ContextCleaner: Cleaned accumulator 745
21/02/17 00:33:11 INFO ContextCleaner: Cleaned accumulator 820
21/02/17 00:33:11 INFO ContextCleaner: Cleaned accumulator 1107
21/02/17 00:33:11 INFO ContextCleaner: Cleaned accumulator 1094
21/02/17 00:33:11 INFO ContextCleaner: Cleaned accumulator 698
21/02/17 00:33:11 INFO ContextCleaner: Cleaned accumulator 903
21/02/17 00:33:11 INFO ContextCleaner: Cleaned accumulator 1010
21/02/17 00:33:11 INFO ContextCleaner: Cleaned accumulator 1294
21/02/17 00:33:11 INFO ContextCleaner: Cleaned accumulator 893
21/02/17 00:33:11 INFO ContextCleaner: Cleaned accumulator 619
21/02/17 00:33:11 INFO ContextCleaner: Cleaned accumulator 770
21/02/17 00:33:11 INFO ContextCleaner: Cleaned accumulator 1128
21/02/17 00:33:11 INFO ContextCleaner: Cleaned accumulator 583
21/02/17 00:33:11 INFO ContextCleaner: Cleaned accumulator 580
21/02/17 00:33:11 INFO ContextCleaner: Cleaned accumulator 1238
21/02/17 00:33:11 INFO ContextCleaner: Cleaned accumulator 794
21/02/17 00:33:11 INFO ContextCleaner: Cleaned accumulator 1050
21/02/17 00:33:11 INFO ContextCleaner: Cleaned accumulator 867
21/02/17 00:33:11 INFO ContextCleaner: Cleaned accumulator 668
21/02/17 00:33:11 INFO ContextCleaner: Cleaned accumulator 1247
21/02/17 00:33:11 INFO ContextCleaner: Cleaned accumulator 927
21/02/17 00:33:11 INFO ContextCleaner: Cleaned accumulator 749
21/02/17 00:33:11 INFO ContextCleaner: Cleaned accumulator 1096
21/02/17 00:33:11 INFO ContextCleaner: Cleaned accumulator 1227
21/02/17 00:33:11 INFO ContextCleaner: Cleaned accumulator 767
21/02/17 00:33:11 INFO ContextCleaner: Cleaned accumulator 763
21/02/17 00:33:11 INFO ContextCleaner: Cleaned accumulator 1042
21/02/17 00:33:11 INFO ContextCleaner: Cleaned accumulator 1290
21/02/17 00:33:11 INFO ContextCleaner: Cleaned accumulator 990
21/02/17 00:33:11 INFO BlockManagerInfo: Removed broadcast_39_piece0 on localhost:37629 in memory (size: 9.0 KB, free: 912.0 MB)
21/02/17 00:33:11 INFO ContextCleaner: Cleaned accumulator 768
21/02/17 00:33:11 INFO ContextCleaner: Cleaned accumulator 887
21/02/17 00:33:11 INFO ContextCleaner: Cleaned accumulator 919
21/02/17 00:33:11 INFO ContextCleaner: Cleaned accumulator 1220
21/02/17 00:33:11 INFO ContextCleaner: Cleaned accumulator 1298
21/02/17 00:33:11 INFO ContextCleaner: Cleaned accumulator 1000
21/02/17 00:33:11 INFO ContextCleaner: Cleaned accumulator 567
21/02/17 00:33:11 INFO ContextCleaner: Cleaned accumulator 1165
21/02/17 00:33:11 INFO ContextCleaner: Cleaned accumulator 989
21/02/17 00:33:11 INFO ContextCleaner: Cleaned accumulator 561
21/02/17 00:33:11 INFO ContextCleaner: Cleaned accumulator 684
21/02/17 00:33:11 INFO ContextCleaner: Cleaned accumulator 1240
21/02/17 00:33:11 INFO ContextCleaner: Cleaned accumulator 647
21/02/17 00:33:11 INFO ContextCleaner: Cleaned accumulator 966
21/02/17 00:33:11 INFO ContextCleaner: Cleaned accumulator 892
21/02/17 00:33:11 INFO ContextCleaner: Cleaned accumulator 564
21/02/17 00:33:11 INFO ContextCleaner: Cleaned accumulator 1310
21/02/17 00:33:11 INFO ContextCleaner: Cleaned accumulator 911
21/02/17 00:33:11 INFO ContextCleaner: Cleaned accumulator 917
21/02/17 00:33:11 INFO ContextCleaner: Cleaned accumulator 1260
21/02/17 00:33:11 INFO ContextCleaner: Cleaned accumulator 1277
21/02/17 00:33:11 INFO ContextCleaner: Cleaned accumulator 1135
21/02/17 00:33:11 INFO ContextCleaner: Cleaned accumulator 1167
21/02/17 00:33:11 INFO ContextCleaner: Cleaned accumulator 771
21/02/17 00:33:11 INFO ContextCleaner: Cleaned accumulator 1023
21/02/17 00:33:11 INFO ContextCleaner: Cleaned accumulator 1196
21/02/17 00:33:11 INFO ContextCleaner: Cleaned accumulator 1229
21/02/17 00:33:11 INFO ContextCleaner: Cleaned accumulator 628
21/02/17 00:33:11 INFO ContextCleaner: Cleaned accumulator 868
21/02/17 00:33:11 INFO ContextCleaner: Cleaned accumulator 754
21/02/17 00:33:11 INFO BlockManagerInfo: Removed broadcast_36_piece0 on localhost:37629 in memory (size: 3.8 KB, free: 912.0 MB)
21/02/17 00:33:11 INFO ContextCleaner: Cleaned accumulator 1184
21/02/17 00:33:11 INFO ContextCleaner: Cleaned accumulator 1005
21/02/17 00:33:11 INFO ContextCleaner: Cleaned accumulator 872
21/02/17 00:33:11 INFO ContextCleaner: Cleaned accumulator 602
21/02/17 00:33:11 INFO ContextCleaner: Cleaned accumulator 613
21/02/17 00:33:11 INFO ContextCleaner: Cleaned accumulator 869
21/02/17 00:33:11 INFO ContextCleaner: Cleaned accumulator 802
21/02/17 00:33:11 INFO ContextCleaner: Cleaned accumulator 664
21/02/17 00:33:11 INFO ContextCleaner: Cleaned accumulator 699
21/02/17 00:33:11 INFO ContextCleaner: Cleaned accumulator 1021
21/02/17 00:33:11 INFO ContextCleaner: Cleaned accumulator 764
21/02/17 00:33:11 INFO ContextCleaner: Cleaned accumulator 1153
21/02/17 00:33:11 INFO BlockManagerInfo: Removed broadcast_24_piece0 on localhost:37629 in memory (size: 53.2 KB, free: 912.0 MB)
21/02/17 00:33:11 INFO ContextCleaner: Cleaned accumulator 1093
21/02/17 00:33:11 INFO ContextCleaner: Cleaned accumulator 854
21/02/17 00:33:11 INFO ContextCleaner: Cleaned accumulator 601
21/02/17 00:33:11 INFO ContextCleaner: Cleaned accumulator 1210
21/02/17 00:33:11 INFO ContextCleaner: Cleaned accumulator 573
21/02/17 00:33:11 INFO ContextCleaner: Cleaned accumulator 606
21/02/17 00:33:11 INFO ContextCleaner: Cleaned accumulator 582
21/02/17 00:33:11 INFO ContextCleaner: Cleaned accumulator 1245
21/02/17 00:33:11 INFO ContextCleaner: Cleaned accumulator 1236
21/02/17 00:33:11 INFO ContextCleaner: Cleaned accumulator 1070
21/02/17 00:33:11 INFO ContextCleaner: Cleaned accumulator 847
21/02/17 00:33:11 INFO ContextCleaner: Cleaned accumulator 1032
21/02/17 00:33:11 INFO ContextCleaner: Cleaned accumulator 717
21/02/17 00:33:11 INFO ContextCleaner: Cleaned accumulator 724
21/02/17 00:33:11 INFO ContextCleaner: Cleaned accumulator 1110
21/02/17 00:33:11 INFO ContextCleaner: Cleaned accumulator 571
21/02/17 00:33:11 INFO BlockManagerInfo: Removed broadcast_46_piece0 on localhost:37629 in memory (size: 3.8 KB, free: 912.0 MB)
21/02/17 00:33:11 INFO ContextCleaner: Cleaned accumulator 1088
21/02/17 00:33:11 INFO ContextCleaner: Cleaned accumulator 737
21/02/17 00:33:11 INFO ContextCleaner: Cleaned accumulator 850
21/02/17 00:33:11 INFO ContextCleaner: Cleaned accumulator 1086
21/02/17 00:33:11 INFO ContextCleaner: Cleaned accumulator 1057
21/02/17 00:33:11 INFO ContextCleaner: Cleaned accumulator 655
21/02/17 00:33:11 INFO ContextCleaner: Cleaned accumulator 703
21/02/17 00:33:11 INFO ContextCleaner: Cleaned accumulator 1242
21/02/17 00:33:11 INFO ContextCleaner: Cleaned accumulator 1163
21/02/17 00:33:11 INFO ContextCleaner: Cleaned accumulator 1207
21/02/17 00:33:11 INFO ContextCleaner: Cleaned accumulator 996
21/02/17 00:33:11 INFO ContextCleaner: Cleaned accumulator 646
21/02/17 00:33:11 INFO ContextCleaner: Cleaned accumulator 756
21/02/17 00:33:11 INFO ContextCleaner: Cleaned accumulator 896
21/02/17 00:33:11 INFO ContextCleaner: Cleaned accumulator 897
21/02/17 00:33:11 INFO ContextCleaner: Cleaned accumulator 590
21/02/17 00:33:11 INFO ContextCleaner: Cleaned accumulator 969
21/02/17 00:33:11 INFO ContextCleaner: Cleaned accumulator 985
21/02/17 00:33:11 INFO ContextCleaner: Cleaned accumulator 837
21/02/17 00:33:11 INFO ContextCleaner: Cleaned accumulator 885
21/02/17 00:33:11 INFO ContextCleaner: Cleaned accumulator 1011
21/02/17 00:33:11 INFO ContextCleaner: Cleaned accumulator 1297
21/02/17 00:33:11 INFO ContextCleaner: Cleaned accumulator 586
21/02/17 00:33:11 INFO ContextCleaner: Cleaned accumulator 609
21/02/17 00:33:11 INFO ContextCleaner: Cleaned accumulator 1180
21/02/17 00:33:11 INFO ContextCleaner: Cleaned accumulator 1208
21/02/17 00:33:11 INFO ContextCleaner: Cleaned accumulator 1282
21/02/17 00:33:11 INFO ContextCleaner: Cleaned accumulator 776
21/02/17 00:33:11 INFO ContextCleaner: Cleaned accumulator 1287
21/02/17 00:33:11 INFO ContextCleaner: Cleaned accumulator 588
21/02/17 00:33:11 INFO ContextCleaner: Cleaned accumulator 622
21/02/17 00:33:11 INFO ContextCleaner: Cleaned accumulator 1183
21/02/17 00:33:11 INFO ContextCleaner: Cleaned accumulator 1261
21/02/17 00:33:11 INFO ContextCleaner: Cleaned accumulator 1040
21/02/17 00:33:11 INFO BlockManagerInfo: Removed broadcast_33_piece0 on localhost:37629 in memory (size: 3.8 KB, free: 912.0 MB)
21/02/17 00:33:11 INFO BlockManagerInfo: Removed broadcast_43_piece0 on localhost:37629 in memory (size: 3.8 KB, free: 912.0 MB)
21/02/17 00:33:11 INFO ContextCleaner: Cleaned accumulator 1203
21/02/17 00:33:11 INFO ContextCleaner: Cleaned accumulator 894
21/02/17 00:33:11 INFO ContextCleaner: Cleaned accumulator 1223
21/02/17 00:33:11 INFO ContextCleaner: Cleaned accumulator 597
21/02/17 00:33:11 INFO ContextCleaner: Cleaned accumulator 965
21/02/17 00:33:11 INFO ContextCleaner: Cleaned accumulator 1262
21/02/17 00:33:11 INFO ContextCleaner: Cleaned accumulator 1296
21/02/17 00:33:11 INFO ContextCleaner: Cleaned accumulator 797
21/02/17 00:33:11 INFO ContextCleaner: Cleaned accumulator 964
21/02/17 00:33:11 INFO ContextCleaner: Cleaned accumulator 782
21/02/17 00:33:11 INFO ContextCleaner: Cleaned accumulator 845
21/02/17 00:33:11 INFO ContextCleaner: Cleaned accumulator 997
21/02/17 00:33:11 INFO ContextCleaner: Cleaned accumulator 566
21/02/17 00:33:11 INFO ContextCleaner: Cleaned accumulator 1200
21/02/17 00:33:11 INFO ContextCleaner: Cleaned accumulator 626
21/02/17 00:33:11 INFO ContextCleaner: Cleaned accumulator 1106
21/02/17 00:33:11 INFO ContextCleaner: Cleaned accumulator 858
21/02/17 00:33:11 INFO ContextCleaner: Cleaned accumulator 1001
21/02/17 00:33:11 INFO ContextCleaner: Cleaned accumulator 700
21/02/17 00:33:11 INFO BlockManager: Removing RDD 108
21/02/17 00:33:11 INFO ContextCleaner: Cleaned RDD 108
21/02/17 00:33:11 INFO ContextCleaner: Cleaned accumulator 1048
21/02/17 00:33:11 INFO ContextCleaner: Cleaned accumulator 1171
21/02/17 00:33:11 INFO ContextCleaner: Cleaned accumulator 608
21/02/17 00:33:11 INFO ContextCleaner: Cleaned accumulator 620
21/02/17 00:33:11 INFO ContextCleaner: Cleaned accumulator 578
21/02/17 00:33:11 INFO ContextCleaner: Cleaned accumulator 914
21/02/17 00:33:11 INFO ContextCleaner: Cleaned accumulator 752
21/02/17 00:33:11 INFO ContextCleaner: Cleaned accumulator 785
21/02/17 00:33:11 INFO ContextCleaner: Cleaned accumulator 1129
21/02/17 00:33:11 INFO ContextCleaner: Cleaned accumulator 1280
21/02/17 00:33:11 INFO ContextCleaner: Cleaned accumulator 591
21/02/17 00:33:11 INFO ContextCleaner: Cleaned accumulator 686
21/02/17 00:33:11 INFO ContextCleaner: Cleaned accumulator 1230
21/02/17 00:33:11 INFO ContextCleaner: Cleaned accumulator 953
21/02/17 00:33:11 INFO ContextCleaner: Cleaned accumulator 1099
21/02/17 00:33:11 INFO ContextCleaner: Cleaned accumulator 819
21/02/17 00:33:11 INFO ContextCleaner: Cleaned accumulator 1286
21/02/17 00:33:11 INFO ContextCleaner: Cleaned accumulator 987
21/02/17 00:33:11 INFO ContextCleaner: Cleaned accumulator 1025
21/02/17 00:33:11 INFO ContextCleaner: Cleaned accumulator 1214
21/02/17 00:33:11 INFO ContextCleaner: Cleaned accumulator 1028
21/02/17 00:33:11 INFO ContextCleaner: Cleaned accumulator 1306
21/02/17 00:33:11 INFO ContextCleaner: Cleaned accumulator 633
21/02/17 00:33:11 INFO ContextCleaner: Cleaned accumulator 1278
21/02/17 00:33:11 INFO ContextCleaner: Cleaned accumulator 1162
21/02/17 00:33:11 INFO ContextCleaner: Cleaned accumulator 905
21/02/17 00:33:11 INFO ContextCleaner: Cleaned accumulator 1275
21/02/17 00:33:11 INFO ContextCleaner: Cleaned accumulator 704
21/02/17 00:33:11 INFO ContextCleaner: Cleaned accumulator 690
21/02/17 00:33:11 INFO ContextCleaner: Cleaned accumulator 658
21/02/17 00:33:11 INFO ContextCleaner: Cleaned accumulator 659
21/02/17 00:33:11 INFO ContextCleaner: Cleaned accumulator 1221
21/02/17 00:33:11 INFO ContextCleaner: Cleaned accumulator 1145
21/02/17 00:33:11 INFO ContextCleaner: Cleaned accumulator 978
21/02/17 00:33:11 INFO ContextCleaner: Cleaned accumulator 1060
21/02/17 00:33:11 INFO ContextCleaner: Cleaned shuffle 10
21/02/17 00:33:11 INFO ContextCleaner: Cleaned accumulator 1133
21/02/17 00:33:11 INFO ContextCleaner: Cleaned accumulator 921
21/02/17 00:33:11 INFO ContextCleaner: Cleaned accumulator 1067
21/02/17 00:33:11 INFO ContextCleaner: Cleaned accumulator 707
21/02/17 00:33:11 INFO ContextCleaner: Cleaned accumulator 1189
21/02/17 00:33:11 INFO ContextCleaner: Cleaned accumulator 943
21/02/17 00:33:11 INFO ContextCleaner: Cleaned accumulator 669
21/02/17 00:33:11 INFO ContextCleaner: Cleaned accumulator 755
21/02/17 00:33:11 INFO ContextCleaner: Cleaned accumulator 657
21/02/17 00:33:11 INFO ContextCleaner: Cleaned accumulator 1197
21/02/17 00:33:11 INFO ContextCleaner: Cleaned accumulator 1118
21/02/17 00:33:11 INFO ContextCleaner: Cleaned accumulator 1069
21/02/17 00:33:11 INFO ContextCleaner: Cleaned accumulator 1033
21/02/17 00:33:11 INFO ContextCleaner: Cleaned accumulator 780
21/02/17 00:33:11 INFO ContextCleaner: Cleaned accumulator 852
21/02/17 00:33:11 INFO ContextCleaner: Cleaned accumulator 993
21/02/17 00:33:11 INFO ContextCleaner: Cleaned accumulator 1252
21/02/17 00:33:11 INFO ContextCleaner: Cleaned accumulator 846
21/02/17 00:33:11 INFO ContextCleaner: Cleaned accumulator 918
21/02/17 00:33:11 INFO ContextCleaner: Cleaned accumulator 692
21/02/17 00:33:11 INFO ContextCleaner: Cleaned accumulator 1301
21/02/17 00:33:11 INFO ContextCleaner: Cleaned accumulator 1231
21/02/17 00:33:11 INFO ContextCleaner: Cleaned accumulator 739
21/02/17 00:33:11 INFO ContextCleaner: Cleaned accumulator 808
21/02/17 00:33:11 INFO ContextCleaner: Cleaned accumulator 941
21/02/17 00:33:11 INFO ContextCleaner: Cleaned accumulator 1284
21/02/17 00:33:11 INFO ContextCleaner: Cleaned accumulator 605
21/02/17 00:33:11 INFO ContextCleaner: Cleaned accumulator 950
21/02/17 00:33:11 INFO ContextCleaner: Cleaned accumulator 825
21/02/17 00:33:11 INFO ContextCleaner: Cleaned accumulator 805
21/02/17 00:33:11 INFO ContextCleaner: Cleaned accumulator 1065
21/02/17 00:33:11 INFO ContextCleaner: Cleaned accumulator 958
21/02/17 00:33:11 INFO ContextCleaner: Cleaned accumulator 660
21/02/17 00:33:11 INFO ContextCleaner: Cleaned accumulator 1204
21/02/17 00:33:11 INFO ContextCleaner: Cleaned accumulator 799
21/02/17 00:33:11 INFO ContextCleaner: Cleaned accumulator 879
21/02/17 00:33:11 INFO ContextCleaner: Cleaned accumulator 1041
21/02/17 00:33:11 INFO ContextCleaner: Cleaned accumulator 1130
21/02/17 00:33:11 INFO BlockManagerInfo: Removed broadcast_40_piece0 on localhost:37629 in memory (size: 4.2 KB, free: 912.1 MB)
21/02/17 00:33:11 INFO ContextCleaner: Cleaned accumulator 1228
21/02/17 00:33:11 INFO ContextCleaner: Cleaned accumulator 1259
21/02/17 00:33:11 INFO ContextCleaner: Cleaned accumulator 691
21/02/17 00:33:11 INFO ContextCleaner: Cleaned accumulator 1080
21/02/17 00:33:11 INFO ContextCleaner: Cleaned accumulator 791
21/02/17 00:33:11 INFO ContextCleaner: Cleaned accumulator 1181
21/02/17 00:33:11 INFO ContextCleaner: Cleaned accumulator 1002
21/02/17 00:33:11 INFO ContextCleaner: Cleaned accumulator 665
21/02/17 00:33:11 INFO ContextCleaner: Cleaned shuffle 12
21/02/17 00:33:11 INFO ContextCleaner: Cleaned accumulator 562
21/02/17 00:33:11 INFO ContextCleaner: Cleaned accumulator 1194
21/02/17 00:33:11 INFO ContextCleaner: Cleaned accumulator 681
21/02/17 00:33:11 INFO ContextCleaner: Cleaned accumulator 1083
21/02/17 00:33:11 INFO ContextCleaner: Cleaned accumulator 1036
21/02/17 00:33:11 INFO ContextCleaner: Cleaned accumulator 685
21/02/17 00:33:11 INFO ContextCleaner: Cleaned accumulator 907
21/02/17 00:33:11 INFO ContextCleaner: Cleaned accumulator 637
21/02/17 00:33:11 INFO ContextCleaner: Cleaned accumulator 1168
21/02/17 00:33:11 INFO ContextCleaner: Cleaned accumulator 1224
21/02/17 00:33:11 INFO ContextCleaner: Cleaned accumulator 983
21/02/17 00:33:11 INFO ContextCleaner: Cleaned accumulator 1312
21/02/17 00:33:11 INFO ContextCleaner: Cleaned accumulator 667
21/02/17 00:33:11 INFO ContextCleaner: Cleaned accumulator 640
21/02/17 00:33:11 INFO ContextCleaner: Cleaned accumulator 1157
21/02/17 00:33:11 INFO BlockManagerInfo: Removed broadcast_22_piece0 on localhost:37629 in memory (size: 25.6 KB, free: 912.1 MB)
21/02/17 00:33:11 INFO ContextCleaner: Cleaned accumulator 861
21/02/17 00:33:11 INFO ContextCleaner: Cleaned accumulator 735
21/02/17 00:33:11 INFO ContextCleaner: Cleaned accumulator 1185
21/02/17 00:33:11 INFO ContextCleaner: Cleaned accumulator 1265
21/02/17 00:33:11 INFO ContextCleaner: Cleaned accumulator 1103
21/02/17 00:33:11 INFO ContextCleaner: Cleaned accumulator 736
21/02/17 00:33:11 INFO ContextCleaner: Cleaned accumulator 1101
21/02/17 00:33:11 INFO ContextCleaner: Cleaned accumulator 1134
21/02/17 00:33:11 INFO ContextCleaner: Cleaned accumulator 1131
21/02/17 00:33:11 INFO ContextCleaner: Cleaned accumulator 900
21/02/17 00:33:11 INFO ContextCleaner: Cleaned accumulator 1015
21/02/17 00:33:11 INFO ContextCleaner: Cleaned accumulator 1090
21/02/17 00:33:11 INFO ContextCleaner: Cleaned accumulator 1198
21/02/17 00:33:11 INFO ContextCleaner: Cleaned accumulator 719
21/02/17 00:33:11 INFO ContextCleaner: Cleaned accumulator 1117
21/02/17 00:33:11 INFO ContextCleaner: Cleaned accumulator 1188
21/02/17 00:33:11 INFO ContextCleaner: Cleaned accumulator 1100
21/02/17 00:33:11 INFO ContextCleaner: Cleaned accumulator 743
21/02/17 00:33:11 INFO ContextCleaner: Cleaned accumulator 1161
21/02/17 00:33:11 INFO ContextCleaner: Cleaned accumulator 829
21/02/17 00:33:11 INFO ContextCleaner: Cleaned accumulator 1122
21/02/17 00:33:11 INFO ContextCleaner: Cleaned accumulator 1136
21/02/17 00:33:11 INFO ContextCleaner: Cleaned accumulator 952
21/02/17 00:33:11 INFO ContextCleaner: Cleaned accumulator 971
21/02/17 00:33:11 INFO ContextCleaner: Cleaned accumulator 595
21/02/17 00:33:11 INFO ContextCleaner: Cleaned accumulator 933
21/02/17 00:33:11 INFO ContextCleaner: Cleaned accumulator 1249
21/02/17 00:33:11 INFO ContextCleaner: Cleaned accumulator 1237
21/02/17 00:33:11 INFO ContextCleaner: Cleaned shuffle 11
21/02/17 00:33:11 INFO ContextCleaner: Cleaned shuffle 7
21/02/17 00:33:11 INFO ContextCleaner: Cleaned accumulator 1225
21/02/17 00:33:11 INFO ContextCleaner: Cleaned accumulator 688
21/02/17 00:33:11 INFO ContextCleaner: Cleaned accumulator 961
21/02/17 00:33:11 INFO ContextCleaner: Cleaned accumulator 676
21/02/17 00:33:11 INFO ContextCleaner: Cleaned accumulator 968
21/02/17 00:33:11 INFO ContextCleaner: Cleaned accumulator 1307
21/02/17 00:33:11 INFO ContextCleaner: Cleaned accumulator 747
21/02/17 00:33:11 INFO ContextCleaner: Cleaned accumulator 1303
21/02/17 00:33:11 INFO ContextCleaner: Cleaned accumulator 1179
21/02/17 00:33:11 INFO ContextCleaner: Cleaned accumulator 652
21/02/17 00:33:11 INFO ContextCleaner: Cleaned accumulator 1022
21/02/17 00:33:11 INFO ContextCleaner: Cleaned accumulator 1074
21/02/17 00:33:11 INFO ContextCleaner: Cleaned accumulator 677
21/02/17 00:33:11 INFO ContextCleaner: Cleaned accumulator 992
21/02/17 00:33:11 INFO ContextCleaner: Cleaned accumulator 1119
21/02/17 00:33:11 INFO ContextCleaner: Cleaned accumulator 1164
21/02/17 00:33:11 INFO ContextCleaner: Cleaned accumulator 891
21/02/17 00:33:11 INFO ContextCleaner: Cleaned accumulator 1075
21/02/17 00:33:11 INFO ContextCleaner: Cleaned accumulator 1251
21/02/17 00:33:11 INFO ContextCleaner: Cleaned shuffle 5
21/02/17 00:33:11 INFO ContextCleaner: Cleaned accumulator 1314
21/02/17 00:33:11 INFO ContextCleaner: Cleaned accumulator 1176
21/02/17 00:33:11 INFO ContextCleaner: Cleaned accumulator 642
21/02/17 00:33:11 INFO ContextCleaner: Cleaned accumulator 830
21/02/17 00:33:11 INFO ContextCleaner: Cleaned accumulator 574
21/02/17 00:33:11 INFO BlockManagerInfo: Removed broadcast_32_piece0 on localhost:37629 in memory (size: 4.2 KB, free: 912.1 MB)
21/02/17 00:33:11 INFO ContextCleaner: Cleaned accumulator 876
21/02/17 00:33:11 INFO ContextCleaner: Cleaned accumulator 639
21/02/17 00:33:11 INFO ContextCleaner: Cleaned accumulator 765
21/02/17 00:33:11 INFO ContextCleaner: Cleaned accumulator 1137
21/02/17 00:33:11 INFO ContextCleaner: Cleaned accumulator 778
21/02/17 00:33:11 INFO ContextCleaner: Cleaned accumulator 679
21/02/17 00:33:11 INFO ContextCleaner: Cleaned accumulator 821
21/02/17 00:33:11 INFO ContextCleaner: Cleaned accumulator 569
21/02/17 00:33:11 INFO ContextCleaner: Cleaned accumulator 937
21/02/17 00:33:11 INFO ContextCleaner: Cleaned accumulator 932
21/02/17 00:33:11 INFO ContextCleaner: Cleaned accumulator 750
21/02/17 00:33:11 INFO ContextCleaner: Cleaned accumulator 627
21/02/17 00:33:11 INFO ContextCleaner: Cleaned accumulator 772
21/02/17 00:33:11 INFO ContextCleaner: Cleaned accumulator 728
21/02/17 00:33:11 INFO ContextCleaner: Cleaned accumulator 788
21/02/17 00:33:11 INFO ContextCleaner: Cleaned accumulator 1193
21/02/17 00:33:11 INFO ContextCleaner: Cleaned accumulator 632
21/02/17 00:33:11 INFO ContextCleaner: Cleaned accumulator 1309
21/02/17 00:33:11 INFO ContextCleaner: Cleaned accumulator 1045
21/02/17 00:33:11 INFO ContextCleaner: Cleaned accumulator 565
21/02/17 00:33:11 INFO ContextCleaner: Cleaned accumulator 838
21/02/17 00:33:11 INFO ContextCleaner: Cleaned accumulator 683
21/02/17 00:33:11 INFO ContextCleaner: Cleaned accumulator 611
21/02/17 00:33:11 INFO BlockManagerInfo: Removed broadcast_34_piece0 on localhost:37629 in memory (size: 24.5 KB, free: 912.1 MB)
21/02/17 00:33:11 INFO ContextCleaner: Cleaned accumulator 1195
21/02/17 00:33:11 INFO ContextCleaner: Cleaned accumulator 863
21/02/17 00:33:11 INFO ContextCleaner: Cleaned accumulator 1120
21/02/17 00:33:11 INFO ContextCleaner: Cleaned accumulator 1191
21/02/17 00:33:11 INFO ContextCleaner: Cleaned accumulator 1300
21/02/17 00:33:11 INFO ContextCleaner: Cleaned accumulator 722
21/02/17 00:33:11 INFO ContextCleaner: Cleaned accumulator 714
21/02/17 00:33:11 INFO ContextCleaner: Cleaned accumulator 758
21/02/17 00:33:11 INFO ContextCleaner: Cleaned accumulator 882
21/02/17 00:33:11 INFO ContextCleaner: Cleaned accumulator 1072
21/02/17 00:33:11 INFO ContextCleaner: Cleaned accumulator 729
21/02/17 00:33:11 INFO ContextCleaner: Cleaned accumulator 617
21/02/17 00:33:11 INFO ContextCleaner: Cleaned accumulator 1317
21/02/17 00:33:11 INFO ContextCleaner: Cleaned accumulator 1258
21/02/17 00:33:11 INFO ContextCleaner: Cleaned accumulator 906
21/02/17 00:33:11 INFO ContextCleaner: Cleaned accumulator 599
21/02/17 00:33:11 INFO ContextCleaner: Cleaned accumulator 1049
21/02/17 00:33:11 INFO ContextCleaner: Cleaned accumulator 1087
21/02/17 00:33:11 INFO ContextCleaner: Cleaned accumulator 741
21/02/17 00:33:11 INFO ContextCleaner: Cleaned accumulator 865
21/02/17 00:33:11 INFO ContextCleaner: Cleaned accumulator 991
21/02/17 00:33:11 INFO ContextCleaner: Cleaned accumulator 631
21/02/17 00:33:11 INFO ContextCleaner: Cleaned accumulator 816
21/02/17 00:33:11 INFO ContextCleaner: Cleaned accumulator 1156
21/02/17 00:33:11 INFO ContextCleaner: Cleaned accumulator 1233
21/02/17 00:33:11 INFO ContextCleaner: Cleaned accumulator 1170
21/02/17 00:33:11 INFO ContextCleaner: Cleaned accumulator 1092
21/02/17 00:33:11 INFO ContextCleaner: Cleaned accumulator 1270
21/02/17 00:33:11 INFO ContextCleaner: Cleaned accumulator 712
21/02/17 00:33:11 INFO ContextCleaner: Cleaned accumulator 1068
21/02/17 00:33:11 INFO ContextCleaner: Cleaned accumulator 663
21/02/17 00:33:11 INFO ContextCleaner: Cleaned accumulator 1062
21/02/17 00:33:11 INFO ContextCleaner: Cleaned accumulator 1051
21/02/17 00:33:11 INFO ContextCleaner: Cleaned accumulator 1212
21/02/17 00:33:11 INFO ContextCleaner: Cleaned accumulator 1217
21/02/17 00:33:11 INFO ContextCleaner: Cleaned accumulator 1044
21/02/17 00:33:11 INFO ContextCleaner: Cleaned accumulator 689
21/02/17 00:33:11 INFO ContextCleaner: Cleaned accumulator 1066
21/02/17 00:33:11 INFO ContextCleaner: Cleaned accumulator 636
21/02/17 00:33:11 INFO ContextCleaner: Cleaned accumulator 1295
21/02/17 00:33:11 INFO ContextCleaner: Cleaned accumulator 1211
21/02/17 00:33:11 INFO ContextCleaner: Cleaned accumulator 974
21/02/17 00:33:11 INFO ContextCleaner: Cleaned accumulator 730
21/02/17 00:33:11 INFO ContextCleaner: Cleaned accumulator 774
21/02/17 00:33:11 INFO ContextCleaner: Cleaned accumulator 1222
21/02/17 00:33:11 INFO ContextCleaner: Cleaned accumulator 648
21/02/17 00:33:11 INFO ContextCleaner: Cleaned accumulator 843
21/02/17 00:33:11 INFO ContextCleaner: Cleaned accumulator 1263
21/02/17 00:33:11 INFO ContextCleaner: Cleaned accumulator 910
21/02/17 00:33:11 INFO ContextCleaner: Cleaned accumulator 710
21/02/17 00:33:11 INFO ContextCleaner: Cleaned accumulator 875
21/02/17 00:33:11 INFO ContextCleaner: Cleaned accumulator 970
21/02/17 00:33:11 INFO ContextCleaner: Cleaned accumulator 1304
21/02/17 00:33:11 INFO ContextCleaner: Cleaned accumulator 579
21/02/17 00:33:11 INFO ContextCleaner: Cleaned accumulator 649
21/02/17 00:33:11 INFO ContextCleaner: Cleaned accumulator 1109
21/02/17 00:33:11 INFO ContextCleaner: Cleaned accumulator 766
21/02/17 00:33:11 INFO ContextCleaner: Cleaned accumulator 598
21/02/17 00:33:11 INFO ContextCleaner: Cleaned accumulator 884
21/02/17 00:33:11 INFO ContextCleaner: Cleaned accumulator 944
21/02/17 00:33:11 INFO ContextCleaner: Cleaned accumulator 618
21/02/17 00:33:11 INFO ContextCleaner: Cleaned accumulator 1253
21/02/17 00:33:11 INFO ContextCleaner: Cleaned accumulator 1232
21/02/17 00:33:11 INFO ContextCleaner: Cleaned accumulator 988
21/02/17 00:33:11 INFO ContextCleaner: Cleaned accumulator 638
21/02/17 00:33:11 INFO ContextCleaner: Cleaned accumulator 635
21/02/17 00:33:11 INFO ContextCleaner: Cleaned shuffle 9
21/02/17 00:33:11 INFO ContextCleaner: Cleaned accumulator 585
21/02/17 00:33:11 INFO ContextCleaner: Cleaned accumulator 807
21/02/17 00:33:11 INFO ContextCleaner: Cleaned accumulator 981
21/02/17 00:33:11 INFO ContextCleaner: Cleaned accumulator 594
21/02/17 00:33:11 INFO ContextCleaner: Cleaned accumulator 898
21/02/17 00:33:11 INFO ContextCleaner: Cleaned accumulator 909
21/02/17 00:33:11 INFO ContextCleaner: Cleaned accumulator 994
21/02/17 00:33:11 INFO ContextCleaner: Cleaned accumulator 701
21/02/17 00:33:11 INFO ContextCleaner: Cleaned accumulator 1026
21/02/17 00:33:11 INFO ContextCleaner: Cleaned accumulator 1055
21/02/17 00:33:11 INFO ContextCleaner: Cleaned accumulator 1115
21/02/17 00:33:11 INFO ContextCleaner: Cleaned accumulator 1125
21/02/17 00:33:11 INFO ContextCleaner: Cleaned accumulator 1003
21/02/17 00:33:11 INFO ContextCleaner: Cleaned accumulator 769
21/02/17 00:33:11 INFO ContextCleaner: Cleaned accumulator 954
21/02/17 00:33:11 INFO ContextCleaner: Cleaned accumulator 1038
21/02/17 00:33:11 INFO ContextCleaner: Cleaned accumulator 796
21/02/17 00:33:11 INFO ContextCleaner: Cleaned accumulator 787
21/02/17 00:33:11 INFO ContextCleaner: Cleaned accumulator 1199
21/02/17 00:33:11 INFO ContextCleaner: Cleaned accumulator 654
21/02/17 00:33:11 INFO ContextCleaner: Cleaned accumulator 716
21/02/17 00:33:11 INFO ContextCleaner: Cleaned accumulator 773
21/02/17 00:33:11 INFO ContextCleaner: Cleaned accumulator 1037
21/02/17 00:33:11 INFO ContextCleaner: Cleaned accumulator 840
21/02/17 00:33:11 INFO ContextCleaner: Cleaned accumulator 883
21/02/17 00:33:11 INFO ContextCleaner: Cleaned accumulator 1289
21/02/17 00:33:11 INFO ContextCleaner: Cleaned accumulator 1009
21/02/17 00:33:11 INFO BlockManagerInfo: Removed broadcast_45_piece0 on localhost:37629 in memory (size: 9.4 KB, free: 912.1 MB)
21/02/17 00:33:11 INFO ContextCleaner: Cleaned accumulator 709
21/02/17 00:33:11 INFO ContextCleaner: Cleaned accumulator 899
21/02/17 00:33:11 INFO ContextCleaner: Cleaned accumulator 812
21/02/17 00:33:11 INFO ContextCleaner: Cleaned accumulator 731
21/02/17 00:33:11 INFO ContextCleaner: Cleaned accumulator 1012
21/02/17 00:33:11 INFO BlockManagerInfo: Removed broadcast_42_piece0 on localhost:37629 in memory (size: 4.5 KB, free: 912.1 MB)
21/02/17 00:33:11 INFO ContextCleaner: Cleaned accumulator 674
21/02/17 00:33:11 INFO ContextCleaner: Cleaned accumulator 842
21/02/17 00:33:11 INFO ContextCleaner: Cleaned accumulator 572
21/02/17 00:33:11 INFO ContextCleaner: Cleaned accumulator 1283
21/02/17 00:33:11 INFO ContextCleaner: Cleaned accumulator 1084
21/02/17 00:33:11 INFO ContextCleaner: Cleaned accumulator 947
21/02/17 00:33:11 INFO ContextCleaner: Cleaned accumulator 1234
21/02/17 00:33:11 INFO ContextCleaner: Cleaned accumulator 708
21/02/17 00:33:11 INFO ContextCleaner: Cleaned accumulator 705
21/02/17 00:33:11 INFO ContextCleaner: Cleaned shuffle 8
21/02/17 00:33:11 INFO ContextCleaner: Cleaned accumulator 1291
21/02/17 00:33:11 INFO ContextCleaner: Cleaned accumulator 855
21/02/17 00:33:11 INFO ContextCleaner: Cleaned accumulator 1017
21/02/17 00:33:11 INFO ContextCleaner: Cleaned accumulator 1148
21/02/17 00:33:11 INFO ContextCleaner: Cleaned accumulator 1006
21/02/17 00:33:11 INFO ContextCleaner: Cleaned accumulator 783
21/02/17 00:33:11 INFO ContextCleaner: Cleaned accumulator 629
21/02/17 00:33:11 INFO ContextCleaner: Cleaned accumulator 738
21/02/17 00:33:11 INFO ContextCleaner: Cleaned accumulator 922
21/02/17 00:33:11 INFO ContextCleaner: Cleaned accumulator 600
21/02/17 00:33:11 INFO ContextCleaner: Cleaned accumulator 672
21/02/17 00:33:11 INFO ContextCleaner: Cleaned accumulator 881
21/02/17 00:33:11 INFO ContextCleaner: Cleaned accumulator 734
21/02/17 00:33:11 INFO ContextCleaner: Cleaned accumulator 1264
21/02/17 00:33:11 INFO ContextCleaner: Cleaned accumulator 940
21/02/17 00:33:11 INFO ContextCleaner: Cleaned accumulator 563
21/02/17 00:33:11 INFO ContextCleaner: Cleaned accumulator 851
21/02/17 00:33:11 INFO ContextCleaner: Cleaned accumulator 1268
21/02/17 00:33:11 INFO ContextCleaner: Cleaned accumulator 844
21/02/17 00:33:11 INFO ContextCleaner: Cleaned accumulator 1190
21/02/17 00:33:11 INFO ContextCleaner: Cleaned accumulator 1216
21/02/17 00:33:11 INFO ContextCleaner: Cleaned accumulator 902
21/02/17 00:33:11 INFO ContextCleaner: Cleaned accumulator 759
21/02/17 00:33:11 INFO FileInputFormat: Total input paths to process : 1
21/02/17 00:33:11 INFO BlockManagerInfo: Removed broadcast_44_piece0 on localhost:37629 in memory (size: 7.9 KB, free: 912.1 MB)
21/02/17 00:33:11 INFO ContextCleaner: Cleaned accumulator 1160
21/02/17 00:33:11 INFO ContextCleaner: Cleaned accumulator 798
21/02/17 00:33:11 INFO ContextCleaner: Cleaned accumulator 1111
21/02/17 00:33:11 INFO ContextCleaner: Cleaned accumulator 727
21/02/17 00:33:11 INFO ContextCleaner: Cleaned accumulator 853
21/02/17 00:33:11 INFO ContextCleaner: Cleaned accumulator 1077
21/02/17 00:33:11 INFO ContextCleaner: Cleaned accumulator 784
21/02/17 00:33:11 INFO ContextCleaner: Cleaned accumulator 1112
21/02/17 00:33:11 INFO ContextCleaner: Cleaned accumulator 871
21/02/17 00:33:11 INFO ContextCleaner: Cleaned accumulator 593
21/02/17 00:33:11 INFO ContextCleaner: Cleaned accumulator 653
21/02/17 00:33:11 INFO BlockManagerInfo: Removed broadcast_27_piece0 on localhost:37629 in memory (size: 53.1 KB, free: 912.2 MB)
21/02/17 00:33:11 INFO ContextCleaner: Cleaned accumulator 671
21/02/17 00:33:11 INFO ContextCleaner: Cleaned accumulator 1104
21/02/17 00:33:11 INFO ContextCleaner: Cleaned accumulator 1186
21/02/17 00:33:11 INFO ContextCleaner: Cleaned accumulator 706
21/02/17 00:33:11 INFO ContextCleaner: Cleaned accumulator 859
21/02/17 00:33:11 INFO ContextCleaner: Cleaned accumulator 973
21/02/17 00:33:11 INFO ContextCleaner: Cleaned accumulator 1073
21/02/17 00:33:11 INFO ContextCleaner: Cleaned accumulator 833
21/02/17 00:33:11 INFO ContextCleaner: Cleaned accumulator 935
21/02/17 00:33:11 INFO ContextCleaner: Cleaned accumulator 576
21/02/17 00:33:11 INFO ContextCleaner: Cleaned accumulator 687
21/02/17 00:33:11 INFO ContextCleaner: Cleaned accumulator 1244
21/02/17 00:33:11 INFO ContextCleaner: Cleaned accumulator 1058
21/02/17 00:33:11 INFO ContextCleaner: Cleaned accumulator 1187
21/02/17 00:33:11 INFO ContextCleaner: Cleaned accumulator 1064
21/02/17 00:33:11 INFO ContextCleaner: Cleaned accumulator 693
21/02/17 00:33:11 INFO ContextCleaner: Cleaned accumulator 748
21/02/17 00:33:11 INFO ContextCleaner: Cleaned accumulator 1035
21/02/17 00:33:11 INFO ContextCleaner: Cleaned accumulator 803
21/02/17 00:33:11 INFO ContextCleaner: Cleaned accumulator 1114
21/02/17 00:33:11 INFO ContextCleaner: Cleaned accumulator 614
21/02/17 00:33:11 INFO ContextCleaner: Cleaned accumulator 849
21/02/17 00:33:11 INFO ContextCleaner: Cleaned accumulator 694
21/02/17 00:33:11 INFO ContextCleaner: Cleaned accumulator 1144
21/02/17 00:33:11 INFO ContextCleaner: Cleaned accumulator 930
21/02/17 00:33:11 INFO ContextCleaner: Cleaned accumulator 800
21/02/17 00:33:11 INFO ContextCleaner: Cleaned accumulator 1154
21/02/17 00:33:11 INFO ContextCleaner: Cleaned accumulator 761
21/02/17 00:33:11 INFO ContextCleaner: Cleaned accumulator 1293
21/02/17 00:33:11 INFO ContextCleaner: Cleaned accumulator 1076
21/02/17 00:33:11 INFO ContextCleaner: Cleaned accumulator 1254
21/02/17 00:33:11 INFO ContextCleaner: Cleaned accumulator 1274
21/02/17 00:33:11 INFO ContextCleaner: Cleaned accumulator 912
21/02/17 00:33:11 INFO ContextCleaner: Cleaned accumulator 1281
21/02/17 00:33:11 INFO ContextCleaner: Cleaned accumulator 581
21/02/17 00:33:11 INFO ContextCleaner: Cleaned accumulator 760
21/02/17 00:33:11 INFO ContextCleaner: Cleaned accumulator 1124
21/02/17 00:33:11 INFO ContextCleaner: Cleaned accumulator 1271
21/02/17 00:33:11 INFO ContextCleaner: Cleaned accumulator 877
21/02/17 00:33:11 INFO ContextCleaner: Cleaned accumulator 804
21/02/17 00:33:11 INFO ContextCleaner: Cleaned accumulator 680
21/02/17 00:33:11 INFO ContextCleaner: Cleaned accumulator 1141
21/02/17 00:33:11 INFO ContextCleaner: Cleaned accumulator 1091
21/02/17 00:33:11 INFO ContextCleaner: Cleaned accumulator 977
21/02/17 00:33:11 INFO ContextCleaner: Cleaned accumulator 874
21/02/17 00:33:11 INFO ContextCleaner: Cleaned accumulator 1056
21/02/17 00:33:11 INFO ContextCleaner: Cleaned accumulator 936
21/02/17 00:33:11 INFO ContextCleaner: Cleaned accumulator 1159
21/02/17 00:33:11 INFO ContextCleaner: Cleaned accumulator 908
21/02/17 00:33:11 INFO ContextCleaner: Cleaned accumulator 1246
21/02/17 00:33:11 INFO ContextCleaner: Cleaned accumulator 806
21/02/17 00:33:11 INFO ContextCleaner: Cleaned accumulator 1047
21/02/17 00:33:11 INFO ContextCleaner: Cleaned accumulator 1255
21/02/17 00:33:11 INFO ContextCleaner: Cleaned accumulator 963
21/02/17 00:33:11 INFO ContextCleaner: Cleaned accumulator 1266
21/02/17 00:33:11 INFO ContextCleaner: Cleaned accumulator 1235
21/02/17 00:33:11 INFO ContextCleaner: Cleaned accumulator 753
21/02/17 00:33:11 INFO ContextCleaner: Cleaned accumulator 826
21/02/17 00:33:11 INFO ContextCleaner: Cleaned accumulator 757
21/02/17 00:33:11 INFO ContextCleaner: Cleaned accumulator 718
21/02/17 00:33:11 INFO ContextCleaner: Cleaned accumulator 904
21/02/17 00:33:11 INFO ContextCleaner: Cleaned accumulator 864
21/02/17 00:33:11 INFO ContextCleaner: Cleaned accumulator 931
21/02/17 00:33:11 INFO ContextCleaner: Cleaned accumulator 1241
21/02/17 00:33:11 INFO ContextCleaner: Cleaned accumulator 811
21/02/17 00:33:11 INFO ContextCleaner: Cleaned accumulator 1158
21/02/17 00:33:11 INFO ContextCleaner: Cleaned accumulator 651
21/02/17 00:33:11 INFO ContextCleaner: Cleaned accumulator 962
21/02/17 00:33:11 INFO ContextCleaner: Cleaned accumulator 1299
21/02/17 00:33:11 INFO ContextCleaner: Cleaned accumulator 604
21/02/17 00:33:11 INFO ContextCleaner: Cleaned accumulator 1279
21/02/17 00:33:11 INFO ContextCleaner: Cleaned accumulator 832
21/02/17 00:33:11 INFO BlockManagerInfo: Removed broadcast_41_piece0 on localhost:37629 in memory (size: 3.2 KB, free: 912.2 MB)
21/02/17 00:33:11 INFO ContextCleaner: Cleaned accumulator 1308
21/02/17 00:33:11 INFO ContextCleaner: Cleaned accumulator 928
21/02/17 00:33:11 INFO ContextCleaner: Cleaned accumulator 1269
21/02/17 00:33:11 INFO ContextCleaner: Cleaned accumulator 1201
21/02/17 00:33:11 INFO ContextCleaner: Cleaned accumulator 603
21/02/17 00:33:11 INFO ContextCleaner: Cleaned accumulator 607
21/02/17 00:33:11 INFO ContextCleaner: Cleaned accumulator 656
21/02/17 00:33:11 INFO ContextCleaner: Cleaned accumulator 1285
21/02/17 00:33:11 INFO ContextCleaner: Cleaned accumulator 1105
21/02/17 00:33:11 INFO ContextCleaner: Cleaned accumulator 781
21/02/17 00:33:11 INFO ContextCleaner: Cleaned accumulator 982
21/02/17 00:33:11 INFO ContextCleaner: Cleaned accumulator 939
21/02/17 00:33:11 INFO ContextCleaner: Cleaned accumulator 645
21/02/17 00:33:11 INFO ContextCleaner: Cleaned accumulator 560
21/02/17 00:33:11 INFO ContextCleaner: Cleaned accumulator 817
21/02/17 00:33:11 INFO ContextCleaner: Cleaned accumulator 1205
21/02/17 00:33:11 INFO ContextCleaner: Cleaned accumulator 742
21/02/17 00:33:11 INFO ContextCleaner: Cleaned accumulator 721
21/02/17 00:33:11 INFO ContextCleaner: Cleaned accumulator 1008
21/02/17 00:33:11 INFO ContextCleaner: Cleaned accumulator 746
21/02/17 00:33:11 INFO ContextCleaner: Cleaned accumulator 1288
21/02/17 00:33:11 INFO ContextCleaner: Cleaned accumulator 1315
21/02/17 00:33:11 INFO ContextCleaner: Cleaned accumulator 934
21/02/17 00:33:11 INFO ContextCleaner: Cleaned accumulator 1081
21/02/17 00:33:11 INFO ContextCleaner: Cleaned accumulator 975
21/02/17 00:33:11 INFO ContextCleaner: Cleaned accumulator 1174
21/02/17 00:33:11 INFO ContextCleaner: Cleaned accumulator 866
21/02/17 00:33:11 INFO ContextCleaner: Cleaned accumulator 1139
21/02/17 00:33:11 INFO ContextCleaner: Cleaned accumulator 762
21/02/17 00:33:11 INFO ContextCleaner: Cleaned accumulator 824
21/02/17 00:33:11 INFO ContextCleaner: Cleaned accumulator 1276
21/02/17 00:33:11 INFO ContextCleaner: Cleaned accumulator 682
21/02/17 00:33:11 INFO ContextCleaner: Cleaned accumulator 823
21/02/17 00:33:11 INFO ContextCleaner: Cleaned accumulator 955
21/02/17 00:33:11 INFO ContextCleaner: Cleaned accumulator 1292
21/02/17 00:33:11 INFO ContextCleaner: Cleaned accumulator 1311
21/02/17 00:33:11 INFO ContextCleaner: Cleaned accumulator 984
21/02/17 00:33:11 INFO ContextCleaner: Cleaned accumulator 1149
21/02/17 00:33:11 INFO ContextCleaner: Cleaned accumulator 870
21/02/17 00:33:11 INFO BlockManagerInfo: Removed broadcast_25_piece0 on localhost:37629 in memory (size: 25.6 KB, free: 912.2 MB)
21/02/17 00:33:11 INFO ContextCleaner: Cleaned accumulator 880
21/02/17 00:33:11 INFO ContextCleaner: Cleaned accumulator 789
21/02/17 00:33:11 INFO ContextCleaner: Cleaned accumulator 779
21/02/17 00:33:11 INFO ContextCleaner: Cleaned accumulator 998
21/02/17 00:33:11 INFO ContextCleaner: Cleaned accumulator 1014
21/02/17 00:33:11 INFO BlockManagerInfo: Removed broadcast_31_piece0 on localhost:37629 in memory (size: 5.1 KB, free: 912.2 MB)
21/02/17 00:33:11 INFO ContextCleaner: Cleaned accumulator 1272
21/02/17 00:33:11 INFO BlockManagerInfo: Removed broadcast_23_piece0 on localhost:37629 in memory (size: 2.8 KB, free: 912.2 MB)
21/02/17 00:33:11 INFO ContextCleaner: Cleaned accumulator 1127
21/02/17 00:33:11 INFO ContextCleaner: Cleaned accumulator 856
21/02/17 00:33:11 INFO ContextCleaner: Cleaned accumulator 1209
21/02/17 00:33:11 INFO ContextCleaner: Cleaned accumulator 1132
21/02/17 00:33:11 INFO ContextCleaner: Cleaned accumulator 641
21/02/17 00:33:11 INFO BlockManagerInfo: Removed broadcast_28_piece0 on localhost:37629 in memory (size: 25.4 KB, free: 912.2 MB)
21/02/17 00:33:11 INFO ContextCleaner: Cleaned accumulator 814
21/02/17 00:33:11 INFO ContextCleaner: Cleaned accumulator 577
21/02/17 00:33:11 INFO ContextCleaner: Cleaned accumulator 860
21/02/17 00:33:11 INFO ContextCleaner: Cleaned accumulator 888
21/02/17 00:33:11 INFO ContextCleaner: Cleaned accumulator 1267
21/02/17 00:33:11 INFO ContextCleaner: Cleaned accumulator 1243
21/02/17 00:33:11 INFO ContextCleaner: Cleaned accumulator 948
21/02/17 00:33:11 INFO ContextCleaner: Cleaned accumulator 1030
21/02/17 00:33:11 INFO ContextCleaner: Cleaned accumulator 596
21/02/17 00:33:11 INFO ContextCleaner: Cleaned accumulator 1123
21/02/17 00:33:11 INFO ContextCleaner: Cleaned accumulator 949
21/02/17 00:33:11 INFO ContextCleaner: Cleaned accumulator 972
21/02/17 00:33:11 INFO ContextCleaner: Cleaned accumulator 751
21/02/17 00:33:11 INFO ContextCleaner: Cleaned accumulator 1078
21/02/17 00:33:11 INFO ContextCleaner: Cleaned accumulator 1039
21/02/17 00:33:11 INFO ContextCleaner: Cleaned accumulator 587
21/02/17 00:33:11 INFO ContextCleaner: Cleaned accumulator 695
21/02/17 00:33:11 INFO BlockManagerInfo: Removed broadcast_38_piece0 on localhost:37629 in memory (size: 3.8 KB, free: 912.2 MB)
21/02/17 00:33:11 INFO BlockManagerInfo: Removed broadcast_30_piece0 on localhost:37629 in memory (size: 24.5 KB, free: 912.3 MB)
21/02/17 00:33:11 INFO ContextCleaner: Cleaned accumulator 929
21/02/17 00:33:11 INFO ContextCleaner: Cleaned accumulator 1178
21/02/17 00:33:11 INFO ContextCleaner: Cleaned accumulator 1054
21/02/17 00:33:11 INFO ContextCleaner: Cleaned accumulator 1182
21/02/17 00:33:11 INFO ContextCleaner: Cleaned accumulator 980
21/02/17 00:33:11 INFO ContextCleaner: Cleaned accumulator 1007
21/02/17 00:33:11 INFO ContextCleaner: Cleaned accumulator 822
21/02/17 00:33:11 INFO ContextCleaner: Cleaned accumulator 836
21/02/17 00:33:11 INFO ContextCleaner: Cleaned accumulator 1052
21/02/17 00:33:11 INFO ContextCleaner: Cleaned accumulator 839
21/02/17 00:33:11 INFO ContextCleaner: Cleaned accumulator 1108
21/02/17 00:33:11 INFO ContextCleaner: Cleaned accumulator 733
21/02/17 00:33:11 INFO ContextCleaner: Cleaned accumulator 831
21/02/17 00:33:11 INFO ContextCleaner: Cleaned accumulator 813
21/02/17 00:33:11 INFO ContextCleaner: Cleaned accumulator 1177
21/02/17 00:33:11 INFO ContextCleaner: Cleaned accumulator 828
21/02/17 00:33:11 INFO ContextCleaner: Cleaned accumulator 1166
21/02/17 00:33:11 INFO ContextCleaner: Cleaned accumulator 1218
21/02/17 00:33:11 INFO ContextCleaner: Cleaned accumulator 711
21/02/17 00:33:11 INFO ContextCleaner: Cleaned accumulator 666
21/02/17 00:33:11 INFO ContextCleaner: Cleaned accumulator 901
21/02/17 00:33:11 INFO ContextCleaner: Cleaned accumulator 915
21/02/17 00:33:11 INFO ContextCleaner: Cleaned accumulator 644
21/02/17 00:33:11 INFO ContextCleaner: Cleaned accumulator 945
21/02/17 00:33:11 INFO ContextCleaner: Cleaned accumulator 986
21/02/17 00:33:11 INFO ContextCleaner: Cleaned accumulator 610
21/02/17 00:33:11 INFO ContextCleaner: Cleaned accumulator 559
21/02/17 00:33:11 INFO ContextCleaner: Cleaned accumulator 1302
21/02/17 00:33:11 INFO ContextCleaner: Cleaned accumulator 942
21/02/17 00:33:11 INFO ContextCleaner: Cleaned accumulator 1248
21/02/17 00:33:11 INFO ContextCleaner: Cleaned accumulator 630
21/02/17 00:33:11 INFO ContextCleaner: Cleaned accumulator 913
21/02/17 00:33:11 INFO ContextCleaner: Cleaned accumulator 1316
21/02/17 00:33:11 INFO ContextCleaner: Cleaned accumulator 926
21/02/17 00:33:11 INFO ContextCleaner: Cleaned accumulator 895
21/02/17 00:33:11 INFO ContextCleaner: Cleaned accumulator 946
21/02/17 00:33:11 INFO ContextCleaner: Cleaned accumulator 835
21/02/17 00:33:11 INFO ContextCleaner: Cleaned accumulator 827
21/02/17 00:33:11 INFO ContextCleaner: Cleaned accumulator 862
21/02/17 00:33:11 INFO ContextCleaner: Cleaned accumulator 801
21/02/17 00:33:11 INFO SparkContext: Starting job: first at ReadWrite.scala:387
21/02/17 00:33:11 INFO DAGScheduler: Got job 31 (first at ReadWrite.scala:387) with 1 output partitions
21/02/17 00:33:11 INFO DAGScheduler: Final stage: ResultStage 44 (first at ReadWrite.scala:387)
21/02/17 00:33:11 INFO DAGScheduler: Parents of final stage: List()
21/02/17 00:33:11 INFO DAGScheduler: Missing parents: List()
21/02/17 00:33:11 INFO DAGScheduler: Submitting ResultStage 44 (/tmp/RtmptF6Khl/file1ecf155f3fa56/metadata MapPartitionsRDD[155] at textFile at ReadWrite.scala:387), which has no missing parents
21/02/17 00:33:11 INFO MemoryStore: Block broadcast_48 stored as values in memory (estimated size 3.3 KB, free 912.0 MB)
21/02/17 00:33:11 INFO MemoryStore: Block broadcast_48_piece0 stored as bytes in memory (estimated size 2001.0 B, free 912.0 MB)
21/02/17 00:33:11 INFO BlockManagerInfo: Added broadcast_48_piece0 in memory on localhost:37629 (size: 2001.0 B, free: 912.3 MB)
21/02/17 00:33:11 INFO SparkContext: Created broadcast 48 from broadcast at DAGScheduler.scala:1039
21/02/17 00:33:11 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 44 (/tmp/RtmptF6Khl/file1ecf155f3fa56/metadata MapPartitionsRDD[155] at textFile at ReadWrite.scala:387) (first 15 tasks are for partitions Vector(0))
21/02/17 00:33:11 INFO TaskSchedulerImpl: Adding task set 44.0 with 1 tasks
21/02/17 00:33:11 INFO TaskSetManager: Starting task 0.0 in stage 44.0 (TID 46, localhost, executor driver, partition 0, PROCESS_LOCAL, 7905 bytes)
21/02/17 00:33:11 INFO Executor: Running task 0.0 in stage 44.0 (TID 46)
21/02/17 00:33:11 INFO HadoopRDD: Input split: file:/tmp/RtmptF6Khl/file1ecf155f3fa56/metadata/part-00000:0+285
21/02/17 00:33:11 INFO Executor: Finished task 0.0 in stage 44.0 (TID 46). 1084 bytes result sent to driver
21/02/17 00:33:11 INFO TaskSetManager: Finished task 0.0 in stage 44.0 (TID 46) in 23 ms on localhost (executor driver) (1/1)
21/02/17 00:33:11 INFO TaskSchedulerImpl: Removed TaskSet 44.0, whose tasks have all completed, from pool 
21/02/17 00:33:11 INFO DAGScheduler: ResultStage 44 (first at ReadWrite.scala:387) finished in 0.025 s
21/02/17 00:33:11 INFO DAGScheduler: Job 31 finished: first at ReadWrite.scala:387, took 0.027815 s
21/02/17 00:33:11 INFO MemoryStore: Block broadcast_49 stored as values in memory (estimated size 239.4 KB, free 911.8 MB)
21/02/17 00:33:11 INFO MemoryStore: Block broadcast_49_piece0 stored as bytes in memory (estimated size 23.2 KB, free 911.8 MB)
21/02/17 00:33:11 INFO BlockManagerInfo: Added broadcast_49_piece0 in memory on localhost:37629 (size: 23.2 KB, free: 912.2 MB)
21/02/17 00:33:11 INFO SparkContext: Created broadcast 49 from textFile at ReadWrite.scala:387
21/02/17 00:33:11 INFO FileInputFormat: Total input paths to process : 1
21/02/17 00:33:11 INFO SparkContext: Starting job: first at ReadWrite.scala:387
21/02/17 00:33:11 INFO DAGScheduler: Got job 32 (first at ReadWrite.scala:387) with 1 output partitions
21/02/17 00:33:11 INFO DAGScheduler: Final stage: ResultStage 45 (first at ReadWrite.scala:387)
21/02/17 00:33:11 INFO DAGScheduler: Parents of final stage: List()
21/02/17 00:33:11 INFO DAGScheduler: Missing parents: List()
21/02/17 00:33:11 INFO DAGScheduler: Submitting ResultStage 45 (/tmp/RtmptF6Khl/file1ecf155f3fa56/stages/0_r_formula__707e5573_ac38_4d87_8d8e_2fb1f36d9f08/metadata MapPartitionsRDD[157] at textFile at ReadWrite.scala:387), which has no missing parents
21/02/17 00:33:11 INFO MemoryStore: Block broadcast_50 stored as values in memory (estimated size 3.4 KB, free 911.8 MB)
21/02/17 00:33:11 INFO MemoryStore: Block broadcast_50_piece0 stored as bytes in memory (estimated size 2.0 KB, free 911.8 MB)
21/02/17 00:33:11 INFO BlockManagerInfo: Added broadcast_50_piece0 in memory on localhost:37629 (size: 2.0 KB, free: 912.2 MB)
21/02/17 00:33:11 INFO SparkContext: Created broadcast 50 from broadcast at DAGScheduler.scala:1039
21/02/17 00:33:11 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 45 (/tmp/RtmptF6Khl/file1ecf155f3fa56/stages/0_r_formula__707e5573_ac38_4d87_8d8e_2fb1f36d9f08/metadata MapPartitionsRDD[157] at textFile at ReadWrite.scala:387) (first 15 tasks are for partitions Vector(0))
21/02/17 00:33:11 INFO TaskSchedulerImpl: Adding task set 45.0 with 1 tasks
21/02/17 00:33:11 INFO TaskSetManager: Starting task 0.0 in stage 45.0 (TID 47, localhost, executor driver, partition 0, PROCESS_LOCAL, 7962 bytes)
21/02/17 00:33:11 INFO Executor: Running task 0.0 in stage 45.0 (TID 47)
21/02/17 00:33:11 INFO HadoopRDD: Input split: file:/tmp/RtmptF6Khl/file1ecf155f3fa56/stages/0_r_formula__707e5573_ac38_4d87_8d8e_2fb1f36d9f08/metadata/part-00000:0+359
21/02/17 00:33:11 INFO Executor: Finished task 0.0 in stage 45.0 (TID 47). 1158 bytes result sent to driver
21/02/17 00:33:11 INFO TaskSetManager: Finished task 0.0 in stage 45.0 (TID 47) in 5 ms on localhost (executor driver) (1/1)
21/02/17 00:33:11 INFO TaskSchedulerImpl: Removed TaskSet 45.0, whose tasks have all completed, from pool 
21/02/17 00:33:11 INFO DAGScheduler: ResultStage 45 (first at ReadWrite.scala:387) finished in 0.007 s
21/02/17 00:33:11 INFO DAGScheduler: Job 32 finished: first at ReadWrite.scala:387, took 0.008490 s
21/02/17 00:33:11 INFO MemoryStore: Block broadcast_51 stored as values in memory (estimated size 239.4 KB, free 911.5 MB)
21/02/17 00:33:11 INFO MemoryStore: Block broadcast_51_piece0 stored as bytes in memory (estimated size 23.2 KB, free 911.5 MB)
21/02/17 00:33:11 INFO BlockManagerInfo: Added broadcast_51_piece0 in memory on localhost:37629 (size: 23.2 KB, free: 912.2 MB)
21/02/17 00:33:11 INFO SparkContext: Created broadcast 51 from textFile at ReadWrite.scala:387
21/02/17 00:33:11 INFO FileInputFormat: Total input paths to process : 1
21/02/17 00:33:11 INFO SparkContext: Starting job: first at ReadWrite.scala:387
21/02/17 00:33:11 INFO DAGScheduler: Got job 33 (first at ReadWrite.scala:387) with 1 output partitions
21/02/17 00:33:11 INFO DAGScheduler: Final stage: ResultStage 46 (first at ReadWrite.scala:387)
21/02/17 00:33:11 INFO DAGScheduler: Parents of final stage: List()
21/02/17 00:33:11 INFO DAGScheduler: Missing parents: List()
21/02/17 00:33:11 INFO DAGScheduler: Submitting ResultStage 46 (/tmp/RtmptF6Khl/file1ecf155f3fa56/stages/0_r_formula__707e5573_ac38_4d87_8d8e_2fb1f36d9f08/metadata MapPartitionsRDD[159] at textFile at ReadWrite.scala:387), which has no missing parents
21/02/17 00:33:11 INFO MemoryStore: Block broadcast_52 stored as values in memory (estimated size 3.4 KB, free 911.5 MB)
21/02/17 00:33:11 INFO MemoryStore: Block broadcast_52_piece0 stored as bytes in memory (estimated size 2.0 KB, free 911.5 MB)
21/02/17 00:33:11 INFO BlockManagerInfo: Added broadcast_52_piece0 in memory on localhost:37629 (size: 2.0 KB, free: 912.2 MB)
21/02/17 00:33:11 INFO SparkContext: Created broadcast 52 from broadcast at DAGScheduler.scala:1039
21/02/17 00:33:11 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 46 (/tmp/RtmptF6Khl/file1ecf155f3fa56/stages/0_r_formula__707e5573_ac38_4d87_8d8e_2fb1f36d9f08/metadata MapPartitionsRDD[159] at textFile at ReadWrite.scala:387) (first 15 tasks are for partitions Vector(0))
21/02/17 00:33:11 INFO TaskSchedulerImpl: Adding task set 46.0 with 1 tasks
21/02/17 00:33:11 INFO TaskSetManager: Starting task 0.0 in stage 46.0 (TID 48, localhost, executor driver, partition 0, PROCESS_LOCAL, 7962 bytes)
21/02/17 00:33:11 INFO Executor: Running task 0.0 in stage 46.0 (TID 48)
21/02/17 00:33:11 INFO HadoopRDD: Input split: file:/tmp/RtmptF6Khl/file1ecf155f3fa56/stages/0_r_formula__707e5573_ac38_4d87_8d8e_2fb1f36d9f08/metadata/part-00000:0+359
21/02/17 00:33:11 INFO Executor: Finished task 0.0 in stage 46.0 (TID 48). 1158 bytes result sent to driver
21/02/17 00:33:11 INFO TaskSetManager: Finished task 0.0 in stage 46.0 (TID 48) in 4 ms on localhost (executor driver) (1/1)
21/02/17 00:33:11 INFO TaskSchedulerImpl: Removed TaskSet 46.0, whose tasks have all completed, from pool 
21/02/17 00:33:11 INFO DAGScheduler: ResultStage 46 (first at ReadWrite.scala:387) finished in 0.008 s
21/02/17 00:33:11 INFO DAGScheduler: Job 33 finished: first at ReadWrite.scala:387, took 0.009443 s
21/02/17 00:33:11 INFO SparkContext: Starting job: parquet at RFormula.scala:437
21/02/17 00:33:11 INFO DAGScheduler: Got job 34 (parquet at RFormula.scala:437) with 1 output partitions
21/02/17 00:33:11 INFO DAGScheduler: Final stage: ResultStage 47 (parquet at RFormula.scala:437)
21/02/17 00:33:11 INFO DAGScheduler: Parents of final stage: List()
21/02/17 00:33:11 INFO DAGScheduler: Missing parents: List()
21/02/17 00:33:11 INFO DAGScheduler: Submitting ResultStage 47 (MapPartitionsRDD[161] at parquet at RFormula.scala:437), which has no missing parents
21/02/17 00:33:11 INFO MemoryStore: Block broadcast_53 stored as values in memory (estimated size 73.1 KB, free 911.4 MB)
21/02/17 00:33:11 INFO MemoryStore: Block broadcast_53_piece0 stored as bytes in memory (estimated size 26.0 KB, free 911.4 MB)
21/02/17 00:33:11 INFO BlockManagerInfo: Added broadcast_53_piece0 in memory on localhost:37629 (size: 26.0 KB, free: 912.2 MB)
21/02/17 00:33:11 INFO SparkContext: Created broadcast 53 from broadcast at DAGScheduler.scala:1039
21/02/17 00:33:11 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 47 (MapPartitionsRDD[161] at parquet at RFormula.scala:437) (first 15 tasks are for partitions Vector(0))
21/02/17 00:33:11 INFO TaskSchedulerImpl: Adding task set 47.0 with 1 tasks
21/02/17 00:33:11 INFO TaskSetManager: Starting task 0.0 in stage 47.0 (TID 49, localhost, executor driver, partition 0, PROCESS_LOCAL, 8122 bytes)
21/02/17 00:33:11 INFO Executor: Running task 0.0 in stage 47.0 (TID 49)
21/02/17 00:33:11 INFO Executor: Finished task 0.0 in stage 47.0 (TID 49). 1686 bytes result sent to driver
21/02/17 00:33:11 INFO TaskSetManager: Finished task 0.0 in stage 47.0 (TID 49) in 21 ms on localhost (executor driver) (1/1)
21/02/17 00:33:11 INFO TaskSchedulerImpl: Removed TaskSet 47.0, whose tasks have all completed, from pool 
21/02/17 00:33:11 INFO DAGScheduler: ResultStage 47 (parquet at RFormula.scala:437) finished in 0.032 s
21/02/17 00:33:11 INFO DAGScheduler: Job 34 finished: parquet at RFormula.scala:437, took 0.033243 s
21/02/17 00:33:11 INFO FileSourceStrategy: Pruning directories with: 
21/02/17 00:33:11 INFO FileSourceStrategy: Post-Scan Filters: 
21/02/17 00:33:11 INFO FileSourceStrategy: Output Data Schema: struct<label: string, terms: array<array<string>>, hasIntercept: boolean ... 1 more fields>
21/02/17 00:33:11 INFO FileSourceScanExec: Pushed Filters: 
21/02/17 00:33:11 INFO CodeGenerator: Code generated in 12.840438 ms
21/02/17 00:33:11 INFO CodeGenerator: Code generated in 14.228713 ms
21/02/17 00:33:11 INFO MemoryStore: Block broadcast_54 stored as values in memory (estimated size 291.2 KB, free 911.1 MB)
21/02/17 00:33:11 INFO MemoryStore: Block broadcast_54_piece0 stored as bytes in memory (estimated size 25.1 KB, free 911.1 MB)
21/02/17 00:33:11 INFO BlockManagerInfo: Added broadcast_54_piece0 in memory on localhost:37629 (size: 25.1 KB, free: 912.2 MB)
21/02/17 00:33:11 INFO SparkContext: Created broadcast 54 from head at RFormula.scala:437
21/02/17 00:33:11 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
21/02/17 00:33:11 INFO SparkContext: Starting job: head at RFormula.scala:437
21/02/17 00:33:11 INFO DAGScheduler: Got job 35 (head at RFormula.scala:437) with 1 output partitions
21/02/17 00:33:11 INFO DAGScheduler: Final stage: ResultStage 48 (head at RFormula.scala:437)
21/02/17 00:33:11 INFO DAGScheduler: Parents of final stage: List()
21/02/17 00:33:11 INFO DAGScheduler: Missing parents: List()
21/02/17 00:33:11 INFO DAGScheduler: Submitting ResultStage 48 (MapPartitionsRDD[165] at head at RFormula.scala:437), which has no missing parents
21/02/17 00:33:11 INFO MemoryStore: Block broadcast_55 stored as values in memory (estimated size 11.9 KB, free 911.1 MB)
21/02/17 00:33:11 INFO MemoryStore: Block broadcast_55_piece0 stored as bytes in memory (estimated size 5.1 KB, free 911.1 MB)
21/02/17 00:33:11 INFO BlockManagerInfo: Added broadcast_55_piece0 in memory on localhost:37629 (size: 5.1 KB, free: 912.2 MB)
21/02/17 00:33:11 INFO SparkContext: Created broadcast 55 from broadcast at DAGScheduler.scala:1039
21/02/17 00:33:11 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 48 (MapPartitionsRDD[165] at head at RFormula.scala:437) (first 15 tasks are for partitions Vector(0))
21/02/17 00:33:11 INFO TaskSchedulerImpl: Adding task set 48.0 with 1 tasks
21/02/17 00:33:11 INFO TaskSetManager: Starting task 0.0 in stage 48.0 (TID 50, localhost, executor driver, partition 0, PROCESS_LOCAL, 8435 bytes)
21/02/17 00:33:11 INFO Executor: Running task 0.0 in stage 48.0 (TID 50)
21/02/17 00:33:11 INFO FileScanRDD: Reading File path: file:///tmp/RtmptF6Khl/file1ecf155f3fa56/stages/0_r_formula__707e5573_ac38_4d87_8d8e_2fb1f36d9f08/data/part-00000-8d5e9ce3-e122-448c-827e-4e6eecca73f2-c000.snappy.parquet, range: 0-1026, partition values: [empty row]
21/02/17 00:33:11 INFO ParquetReadSupport: Going to read the following fields from the Parquet file:

Parquet form:
message spark_schema {
  optional binary label (UTF8);
  optional group terms (LIST) {
    repeated group list {
      optional group element (LIST) {
        repeated group list {
          optional binary element (UTF8);
        }
      }
    }
  }
  required boolean hasIntercept;
}

Catalyst form:
StructType(StructField(label,StringType,true), StructField(terms,ArrayType(ArrayType(StringType,true),true),true), StructField(hasIntercept,BooleanType,true))
       
21/02/17 00:33:12 INFO CodeGenerator: Code generated in 6.162054 ms
21/02/17 00:33:12 INFO CodecPool: Got brand-new decompressor [.snappy]
21/02/17 00:33:12 INFO Executor: Finished task 0.0 in stage 48.0 (TID 50). 1278 bytes result sent to driver
21/02/17 00:33:12 INFO TaskSetManager: Finished task 0.0 in stage 48.0 (TID 50) in 78 ms on localhost (executor driver) (1/1)
21/02/17 00:33:12 INFO TaskSchedulerImpl: Removed TaskSet 48.0, whose tasks have all completed, from pool 
21/02/17 00:33:12 INFO DAGScheduler: ResultStage 48 (head at RFormula.scala:437) finished in 0.085 s
21/02/17 00:33:12 INFO DAGScheduler: Job 35 finished: head at RFormula.scala:437, took 0.085872 s
21/02/17 00:33:12 INFO MemoryStore: Block broadcast_56 stored as values in memory (estimated size 239.4 KB, free 910.8 MB)
21/02/17 00:33:12 INFO MemoryStore: Block broadcast_56_piece0 stored as bytes in memory (estimated size 23.2 KB, free 910.8 MB)
21/02/17 00:33:12 INFO BlockManagerInfo: Added broadcast_56_piece0 in memory on localhost:37629 (size: 23.2 KB, free: 912.1 MB)
21/02/17 00:33:12 INFO SparkContext: Created broadcast 56 from textFile at ReadWrite.scala:387
21/02/17 00:33:12 INFO FileInputFormat: Total input paths to process : 1
21/02/17 00:33:12 INFO SparkContext: Starting job: first at ReadWrite.scala:387
21/02/17 00:33:12 INFO DAGScheduler: Got job 36 (first at ReadWrite.scala:387) with 1 output partitions
21/02/17 00:33:12 INFO DAGScheduler: Final stage: ResultStage 49 (first at ReadWrite.scala:387)
21/02/17 00:33:12 INFO DAGScheduler: Parents of final stage: List()
21/02/17 00:33:12 INFO DAGScheduler: Missing parents: List()
21/02/17 00:33:12 INFO DAGScheduler: Submitting ResultStage 49 (/tmp/RtmptF6Khl/file1ecf155f3fa56/stages/0_r_formula__707e5573_ac38_4d87_8d8e_2fb1f36d9f08/pipelineModel/metadata MapPartitionsRDD[167] at textFile at ReadWrite.scala:387), which has no missing parents
21/02/17 00:33:12 INFO MemoryStore: Block broadcast_57 stored as values in memory (estimated size 3.4 KB, free 910.8 MB)
21/02/17 00:33:12 INFO MemoryStore: Block broadcast_57_piece0 stored as bytes in memory (estimated size 2.0 KB, free 910.8 MB)
21/02/17 00:33:12 INFO BlockManagerInfo: Added broadcast_57_piece0 in memory on localhost:37629 (size: 2.0 KB, free: 912.1 MB)
21/02/17 00:33:12 INFO SparkContext: Created broadcast 57 from broadcast at DAGScheduler.scala:1039
21/02/17 00:33:12 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 49 (/tmp/RtmptF6Khl/file1ecf155f3fa56/stages/0_r_formula__707e5573_ac38_4d87_8d8e_2fb1f36d9f08/pipelineModel/metadata MapPartitionsRDD[167] at textFile at ReadWrite.scala:387) (first 15 tasks are for partitions Vector(0))
21/02/17 00:33:12 INFO TaskSchedulerImpl: Adding task set 49.0 with 1 tasks
21/02/17 00:33:12 INFO TaskSetManager: Starting task 0.0 in stage 49.0 (TID 51, localhost, executor driver, partition 0, PROCESS_LOCAL, 7977 bytes)
21/02/17 00:33:12 INFO Executor: Running task 0.0 in stage 49.0 (TID 51)
21/02/17 00:33:12 INFO HadoopRDD: Input split: file:/tmp/RtmptF6Khl/file1ecf155f3fa56/stages/0_r_formula__707e5573_ac38_4d87_8d8e_2fb1f36d9f08/pipelineModel/metadata/part-00000:0+290
21/02/17 00:33:12 INFO Executor: Finished task 0.0 in stage 49.0 (TID 51). 1089 bytes result sent to driver
21/02/17 00:33:12 INFO TaskSetManager: Finished task 0.0 in stage 49.0 (TID 51) in 4 ms on localhost (executor driver) (1/1)
21/02/17 00:33:12 INFO TaskSchedulerImpl: Removed TaskSet 49.0, whose tasks have all completed, from pool 
21/02/17 00:33:12 INFO DAGScheduler: ResultStage 49 (first at ReadWrite.scala:387) finished in 0.007 s
21/02/17 00:33:12 INFO DAGScheduler: Job 36 finished: first at ReadWrite.scala:387, took 0.008789 s
21/02/17 00:33:12 INFO MemoryStore: Block broadcast_58 stored as values in memory (estimated size 239.4 KB, free 910.6 MB)
21/02/17 00:33:12 INFO MemoryStore: Block broadcast_58_piece0 stored as bytes in memory (estimated size 23.2 KB, free 910.6 MB)
21/02/17 00:33:12 INFO BlockManagerInfo: Added broadcast_58_piece0 in memory on localhost:37629 (size: 23.2 KB, free: 912.1 MB)
21/02/17 00:33:12 INFO SparkContext: Created broadcast 58 from textFile at ReadWrite.scala:387
21/02/17 00:33:12 INFO FileInputFormat: Total input paths to process : 1
21/02/17 00:33:12 INFO SparkContext: Starting job: first at ReadWrite.scala:387
21/02/17 00:33:12 INFO DAGScheduler: Got job 37 (first at ReadWrite.scala:387) with 1 output partitions
21/02/17 00:33:12 INFO DAGScheduler: Final stage: ResultStage 50 (first at ReadWrite.scala:387)
21/02/17 00:33:12 INFO DAGScheduler: Parents of final stage: List()
21/02/17 00:33:12 INFO DAGScheduler: Missing parents: List()
21/02/17 00:33:12 INFO DAGScheduler: Submitting ResultStage 50 (/tmp/RtmptF6Khl/file1ecf155f3fa56/stages/0_r_formula__707e5573_ac38_4d87_8d8e_2fb1f36d9f08/pipelineModel/stages/0_r_formula__707e5573_ac38_4d87_8d8e_2fb1f36d9f08/metadata MapPartitionsRDD[169] at textFile at ReadWrite.scala:387), which has no missing parents
21/02/17 00:33:12 INFO MemoryStore: Block broadcast_59 stored as values in memory (estimated size 3.4 KB, free 910.6 MB)
21/02/17 00:33:12 INFO MemoryStore: Block broadcast_59_piece0 stored as bytes in memory (estimated size 2.0 KB, free 910.6 MB)
21/02/17 00:33:12 INFO BlockManagerInfo: Added broadcast_59_piece0 in memory on localhost:37629 (size: 2.0 KB, free: 912.1 MB)
21/02/17 00:33:12 INFO SparkContext: Created broadcast 59 from broadcast at DAGScheduler.scala:1039
21/02/17 00:33:12 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 50 (/tmp/RtmptF6Khl/file1ecf155f3fa56/stages/0_r_formula__707e5573_ac38_4d87_8d8e_2fb1f36d9f08/pipelineModel/stages/0_r_formula__707e5573_ac38_4d87_8d8e_2fb1f36d9f08/metadata MapPartitionsRDD[169] at textFile at ReadWrite.scala:387) (first 15 tasks are for partitions Vector(0))
21/02/17 00:33:12 INFO TaskSchedulerImpl: Adding task set 50.0 with 1 tasks
21/02/17 00:33:12 INFO TaskSetManager: Starting task 0.0 in stage 50.0 (TID 52, localhost, executor driver, partition 0, PROCESS_LOCAL, 8037 bytes)
21/02/17 00:33:12 INFO Executor: Running task 0.0 in stage 50.0 (TID 52)
21/02/17 00:33:12 INFO HadoopRDD: Input split: file:/tmp/RtmptF6Khl/file1ecf155f3fa56/stages/0_r_formula__707e5573_ac38_4d87_8d8e_2fb1f36d9f08/pipelineModel/stages/0_r_formula__707e5573_ac38_4d87_8d8e_2fb1f36d9f08/metadata/part-00000:0+240
21/02/17 00:33:12 INFO Executor: Finished task 0.0 in stage 50.0 (TID 52). 1039 bytes result sent to driver
21/02/17 00:33:12 INFO TaskSetManager: Finished task 0.0 in stage 50.0 (TID 52) in 3 ms on localhost (executor driver) (1/1)
21/02/17 00:33:12 INFO TaskSchedulerImpl: Removed TaskSet 50.0, whose tasks have all completed, from pool 
21/02/17 00:33:12 INFO DAGScheduler: ResultStage 50 (first at ReadWrite.scala:387) finished in 0.006 s
21/02/17 00:33:12 INFO DAGScheduler: Job 37 finished: first at ReadWrite.scala:387, took 0.007118 s
21/02/17 00:33:12 INFO MemoryStore: Block broadcast_60 stored as values in memory (estimated size 239.4 KB, free 910.3 MB)
21/02/17 00:33:12 INFO MemoryStore: Block broadcast_60_piece0 stored as bytes in memory (estimated size 23.2 KB, free 910.3 MB)
21/02/17 00:33:12 INFO BlockManagerInfo: Added broadcast_60_piece0 in memory on localhost:37629 (size: 23.2 KB, free: 912.1 MB)
21/02/17 00:33:12 INFO SparkContext: Created broadcast 60 from textFile at ReadWrite.scala:387
21/02/17 00:33:12 INFO FileInputFormat: Total input paths to process : 1
21/02/17 00:33:12 INFO SparkContext: Starting job: first at ReadWrite.scala:387
21/02/17 00:33:12 INFO DAGScheduler: Got job 38 (first at ReadWrite.scala:387) with 1 output partitions
21/02/17 00:33:12 INFO DAGScheduler: Final stage: ResultStage 51 (first at ReadWrite.scala:387)
21/02/17 00:33:12 INFO DAGScheduler: Parents of final stage: List()
21/02/17 00:33:12 INFO DAGScheduler: Missing parents: List()
21/02/17 00:33:12 INFO DAGScheduler: Submitting ResultStage 51 (/tmp/RtmptF6Khl/file1ecf155f3fa56/stages/0_r_formula__707e5573_ac38_4d87_8d8e_2fb1f36d9f08/pipelineModel/stages/0_r_formula__707e5573_ac38_4d87_8d8e_2fb1f36d9f08/metadata MapPartitionsRDD[171] at textFile at ReadWrite.scala:387), which has no missing parents
21/02/17 00:33:12 INFO MemoryStore: Block broadcast_61 stored as values in memory (estimated size 3.4 KB, free 910.3 MB)
21/02/17 00:33:12 INFO MemoryStore: Block broadcast_61_piece0 stored as bytes in memory (estimated size 2.0 KB, free 910.3 MB)
21/02/17 00:33:12 INFO BlockManagerInfo: Added broadcast_61_piece0 in memory on localhost:37629 (size: 2.0 KB, free: 912.1 MB)
21/02/17 00:33:12 INFO SparkContext: Created broadcast 61 from broadcast at DAGScheduler.scala:1039
21/02/17 00:33:12 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 51 (/tmp/RtmptF6Khl/file1ecf155f3fa56/stages/0_r_formula__707e5573_ac38_4d87_8d8e_2fb1f36d9f08/pipelineModel/stages/0_r_formula__707e5573_ac38_4d87_8d8e_2fb1f36d9f08/metadata MapPartitionsRDD[171] at textFile at ReadWrite.scala:387) (first 15 tasks are for partitions Vector(0))
21/02/17 00:33:12 INFO TaskSchedulerImpl: Adding task set 51.0 with 1 tasks
21/02/17 00:33:12 INFO TaskSetManager: Starting task 0.0 in stage 51.0 (TID 53, localhost, executor driver, partition 0, PROCESS_LOCAL, 8037 bytes)
21/02/17 00:33:12 INFO Executor: Running task 0.0 in stage 51.0 (TID 53)
21/02/17 00:33:12 INFO HadoopRDD: Input split: file:/tmp/RtmptF6Khl/file1ecf155f3fa56/stages/0_r_formula__707e5573_ac38_4d87_8d8e_2fb1f36d9f08/pipelineModel/stages/0_r_formula__707e5573_ac38_4d87_8d8e_2fb1f36d9f08/metadata/part-00000:0+240
21/02/17 00:33:12 INFO Executor: Finished task 0.0 in stage 51.0 (TID 53). 1039 bytes result sent to driver
21/02/17 00:33:12 INFO TaskSetManager: Finished task 0.0 in stage 51.0 (TID 53) in 4 ms on localhost (executor driver) (1/1)
21/02/17 00:33:12 INFO TaskSchedulerImpl: Removed TaskSet 51.0, whose tasks have all completed, from pool 
21/02/17 00:33:12 INFO DAGScheduler: ResultStage 51 (first at ReadWrite.scala:387) finished in 0.006 s
21/02/17 00:33:12 INFO DAGScheduler: Job 38 finished: first at ReadWrite.scala:387, took 0.007177 s
21/02/17 00:33:12 INFO MemoryStore: Block broadcast_62 stored as values in memory (estimated size 239.4 KB, free 910.1 MB)
21/02/17 00:33:12 INFO MemoryStore: Block broadcast_62_piece0 stored as bytes in memory (estimated size 23.2 KB, free 910.0 MB)
21/02/17 00:33:12 INFO BlockManagerInfo: Added broadcast_62_piece0 in memory on localhost:37629 (size: 23.2 KB, free: 912.1 MB)
21/02/17 00:33:12 INFO SparkContext: Created broadcast 62 from textFile at ReadWrite.scala:387
21/02/17 00:33:12 INFO FileInputFormat: Total input paths to process : 1
21/02/17 00:33:12 INFO SparkContext: Starting job: first at ReadWrite.scala:387
21/02/17 00:33:12 INFO DAGScheduler: Got job 39 (first at ReadWrite.scala:387) with 1 output partitions
21/02/17 00:33:12 INFO DAGScheduler: Final stage: ResultStage 52 (first at ReadWrite.scala:387)
21/02/17 00:33:12 INFO DAGScheduler: Parents of final stage: List()
21/02/17 00:33:12 INFO DAGScheduler: Missing parents: List()
21/02/17 00:33:12 INFO DAGScheduler: Submitting ResultStage 52 (/tmp/RtmptF6Khl/file1ecf155f3fa56/stages/0_r_formula__707e5573_ac38_4d87_8d8e_2fb1f36d9f08/pipelineModel/stages/1_vectorAttrRewriter_9b40dc492122/metadata MapPartitionsRDD[173] at textFile at ReadWrite.scala:387), which has no missing parents
21/02/17 00:33:12 INFO MemoryStore: Block broadcast_63 stored as values in memory (estimated size 3.4 KB, free 910.0 MB)
21/02/17 00:33:12 INFO MemoryStore: Block broadcast_63_piece0 stored as bytes in memory (estimated size 2.1 KB, free 910.0 MB)
21/02/17 00:33:12 INFO BlockManagerInfo: Added broadcast_63_piece0 in memory on localhost:37629 (size: 2.1 KB, free: 912.1 MB)
21/02/17 00:33:12 INFO SparkContext: Created broadcast 63 from broadcast at DAGScheduler.scala:1039
21/02/17 00:33:12 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 52 (/tmp/RtmptF6Khl/file1ecf155f3fa56/stages/0_r_formula__707e5573_ac38_4d87_8d8e_2fb1f36d9f08/pipelineModel/stages/1_vectorAttrRewriter_9b40dc492122/metadata MapPartitionsRDD[173] at textFile at ReadWrite.scala:387) (first 15 tasks are for partitions Vector(0))
21/02/17 00:33:12 INFO TaskSchedulerImpl: Adding task set 52.0 with 1 tasks
21/02/17 00:33:12 INFO TaskSetManager: Starting task 0.0 in stage 52.0 (TID 54, localhost, executor driver, partition 0, PROCESS_LOCAL, 8021 bytes)
21/02/17 00:33:12 INFO Executor: Running task 0.0 in stage 52.0 (TID 54)
21/02/17 00:33:12 INFO HadoopRDD: Input split: file:/tmp/RtmptF6Khl/file1ecf155f3fa56/stages/0_r_formula__707e5573_ac38_4d87_8d8e_2fb1f36d9f08/pipelineModel/stages/1_vectorAttrRewriter_9b40dc492122/metadata/part-00000:0+167
21/02/17 00:33:12 INFO Executor: Finished task 0.0 in stage 52.0 (TID 54). 1006 bytes result sent to driver
21/02/17 00:33:12 INFO TaskSetManager: Finished task 0.0 in stage 52.0 (TID 54) in 3 ms on localhost (executor driver) (1/1)
21/02/17 00:33:12 INFO TaskSchedulerImpl: Removed TaskSet 52.0, whose tasks have all completed, from pool 
21/02/17 00:33:12 INFO DAGScheduler: ResultStage 52 (first at ReadWrite.scala:387) finished in 0.006 s
21/02/17 00:33:12 INFO DAGScheduler: Job 39 finished: first at ReadWrite.scala:387, took 0.007915 s
21/02/17 00:33:12 INFO MemoryStore: Block broadcast_64 stored as values in memory (estimated size 239.4 KB, free 909.8 MB)
21/02/17 00:33:12 INFO MemoryStore: Block broadcast_64_piece0 stored as bytes in memory (estimated size 23.2 KB, free 909.8 MB)
21/02/17 00:33:12 INFO BlockManagerInfo: Added broadcast_64_piece0 in memory on localhost:37629 (size: 23.2 KB, free: 912.0 MB)
21/02/17 00:33:12 INFO SparkContext: Created broadcast 64 from textFile at ReadWrite.scala:387
21/02/17 00:33:12 INFO FileInputFormat: Total input paths to process : 1
21/02/17 00:33:12 INFO SparkContext: Starting job: first at ReadWrite.scala:387
21/02/17 00:33:12 INFO DAGScheduler: Got job 40 (first at ReadWrite.scala:387) with 1 output partitions
21/02/17 00:33:12 INFO DAGScheduler: Final stage: ResultStage 53 (first at ReadWrite.scala:387)
21/02/17 00:33:12 INFO DAGScheduler: Parents of final stage: List()
21/02/17 00:33:12 INFO DAGScheduler: Missing parents: List()
21/02/17 00:33:12 INFO DAGScheduler: Submitting ResultStage 53 (/tmp/RtmptF6Khl/file1ecf155f3fa56/stages/0_r_formula__707e5573_ac38_4d87_8d8e_2fb1f36d9f08/pipelineModel/stages/1_vectorAttrRewriter_9b40dc492122/metadata MapPartitionsRDD[175] at textFile at ReadWrite.scala:387), which has no missing parents
21/02/17 00:33:12 INFO MemoryStore: Block broadcast_65 stored as values in memory (estimated size 3.4 KB, free 909.8 MB)
21/02/17 00:33:12 INFO MemoryStore: Block broadcast_65_piece0 stored as bytes in memory (estimated size 2.1 KB, free 909.8 MB)
21/02/17 00:33:12 INFO BlockManagerInfo: Added broadcast_65_piece0 in memory on localhost:37629 (size: 2.1 KB, free: 912.0 MB)
21/02/17 00:33:12 INFO SparkContext: Created broadcast 65 from broadcast at DAGScheduler.scala:1039
21/02/17 00:33:12 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 53 (/tmp/RtmptF6Khl/file1ecf155f3fa56/stages/0_r_formula__707e5573_ac38_4d87_8d8e_2fb1f36d9f08/pipelineModel/stages/1_vectorAttrRewriter_9b40dc492122/metadata MapPartitionsRDD[175] at textFile at ReadWrite.scala:387) (first 15 tasks are for partitions Vector(0))
21/02/17 00:33:12 INFO TaskSchedulerImpl: Adding task set 53.0 with 1 tasks
21/02/17 00:33:12 INFO TaskSetManager: Starting task 0.0 in stage 53.0 (TID 55, localhost, executor driver, partition 0, PROCESS_LOCAL, 8021 bytes)
21/02/17 00:33:12 INFO Executor: Running task 0.0 in stage 53.0 (TID 55)
21/02/17 00:33:12 INFO HadoopRDD: Input split: file:/tmp/RtmptF6Khl/file1ecf155f3fa56/stages/0_r_formula__707e5573_ac38_4d87_8d8e_2fb1f36d9f08/pipelineModel/stages/1_vectorAttrRewriter_9b40dc492122/metadata/part-00000:0+167
21/02/17 00:33:12 INFO Executor: Finished task 0.0 in stage 53.0 (TID 55). 963 bytes result sent to driver
21/02/17 00:33:12 INFO TaskSetManager: Finished task 0.0 in stage 53.0 (TID 55) in 3 ms on localhost (executor driver) (1/1)
21/02/17 00:33:12 INFO TaskSchedulerImpl: Removed TaskSet 53.0, whose tasks have all completed, from pool 
21/02/17 00:33:12 INFO DAGScheduler: ResultStage 53 (first at ReadWrite.scala:387) finished in 0.006 s
21/02/17 00:33:12 INFO DAGScheduler: Job 40 finished: first at ReadWrite.scala:387, took 0.007392 s
21/02/17 00:33:12 INFO SparkContext: Starting job: parquet at RFormula.scala:599
21/02/17 00:33:12 INFO DAGScheduler: Got job 41 (parquet at RFormula.scala:599) with 1 output partitions
21/02/17 00:33:12 INFO DAGScheduler: Final stage: ResultStage 54 (parquet at RFormula.scala:599)
21/02/17 00:33:12 INFO DAGScheduler: Parents of final stage: List()
21/02/17 00:33:12 INFO DAGScheduler: Missing parents: List()
21/02/17 00:33:12 INFO DAGScheduler: Submitting ResultStage 54 (MapPartitionsRDD[177] at parquet at RFormula.scala:599), which has no missing parents
21/02/17 00:33:12 INFO MemoryStore: Block broadcast_66 stored as values in memory (estimated size 73.1 KB, free 909.7 MB)
21/02/17 00:33:12 INFO MemoryStore: Block broadcast_66_piece0 stored as bytes in memory (estimated size 26.0 KB, free 909.7 MB)
21/02/17 00:33:12 INFO BlockManagerInfo: Added broadcast_66_piece0 in memory on localhost:37629 (size: 26.0 KB, free: 912.0 MB)
21/02/17 00:33:12 INFO SparkContext: Created broadcast 66 from broadcast at DAGScheduler.scala:1039
21/02/17 00:33:12 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 54 (MapPartitionsRDD[177] at parquet at RFormula.scala:599) (first 15 tasks are for partitions Vector(0))
21/02/17 00:33:12 INFO TaskSchedulerImpl: Adding task set 54.0 with 1 tasks
21/02/17 00:33:12 INFO TaskSetManager: Starting task 0.0 in stage 54.0 (TID 56, localhost, executor driver, partition 0, PROCESS_LOCAL, 8177 bytes)
21/02/17 00:33:12 INFO Executor: Running task 0.0 in stage 54.0 (TID 56)
21/02/17 00:33:12 INFO Executor: Finished task 0.0 in stage 54.0 (TID 56). 1620 bytes result sent to driver
21/02/17 00:33:12 INFO TaskSetManager: Finished task 0.0 in stage 54.0 (TID 56) in 6 ms on localhost (executor driver) (1/1)
21/02/17 00:33:12 INFO TaskSchedulerImpl: Removed TaskSet 54.0, whose tasks have all completed, from pool 
21/02/17 00:33:12 INFO DAGScheduler: ResultStage 54 (parquet at RFormula.scala:599) finished in 0.014 s
21/02/17 00:33:12 INFO DAGScheduler: Job 41 finished: parquet at RFormula.scala:599, took 0.014365 s
21/02/17 00:33:12 INFO FileSourceStrategy: Pruning directories with: 
21/02/17 00:33:12 INFO FileSourceStrategy: Post-Scan Filters: 
21/02/17 00:33:12 INFO FileSourceStrategy: Output Data Schema: struct<vectorCol: string, prefixesToRewrite: map<string,string>>
21/02/17 00:33:12 INFO FileSourceScanExec: Pushed Filters: 
21/02/17 00:33:12 INFO CodeGenerator: Code generated in 11.801007 ms
21/02/17 00:33:12 INFO CodeGenerator: Code generated in 7.614765 ms
21/02/17 00:33:12 INFO MemoryStore: Block broadcast_67 stored as values in memory (estimated size 290.9 KB, free 909.4 MB)
21/02/17 00:33:12 INFO MemoryStore: Block broadcast_67_piece0 stored as bytes in memory (estimated size 25.0 KB, free 909.4 MB)
21/02/17 00:33:12 INFO BlockManagerInfo: Added broadcast_67_piece0 in memory on localhost:37629 (size: 25.0 KB, free: 912.0 MB)
21/02/17 00:33:12 INFO SparkContext: Created broadcast 67 from head at RFormula.scala:599
21/02/17 00:33:12 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
21/02/17 00:33:12 INFO SparkContext: Starting job: head at RFormula.scala:599
21/02/17 00:33:12 INFO DAGScheduler: Got job 42 (head at RFormula.scala:599) with 1 output partitions
21/02/17 00:33:12 INFO DAGScheduler: Final stage: ResultStage 55 (head at RFormula.scala:599)
21/02/17 00:33:12 INFO DAGScheduler: Parents of final stage: List()
21/02/17 00:33:12 INFO DAGScheduler: Missing parents: List()
21/02/17 00:33:12 INFO DAGScheduler: Submitting ResultStage 55 (MapPartitionsRDD[181] at head at RFormula.scala:599), which has no missing parents
21/02/17 00:33:12 INFO MemoryStore: Block broadcast_68 stored as values in memory (estimated size 12.5 KB, free 909.4 MB)
21/02/17 00:33:12 INFO MemoryStore: Block broadcast_68_piece0 stored as bytes in memory (estimated size 5.2 KB, free 909.3 MB)
21/02/17 00:33:12 INFO BlockManagerInfo: Added broadcast_68_piece0 in memory on localhost:37629 (size: 5.2 KB, free: 912.0 MB)
21/02/17 00:33:12 INFO SparkContext: Created broadcast 68 from broadcast at DAGScheduler.scala:1039
21/02/17 00:33:12 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 55 (MapPartitionsRDD[181] at head at RFormula.scala:599) (first 15 tasks are for partitions Vector(0))
21/02/17 00:33:12 INFO TaskSchedulerImpl: Adding task set 55.0 with 1 tasks
21/02/17 00:33:12 INFO TaskSetManager: Starting task 0.0 in stage 55.0 (TID 57, localhost, executor driver, partition 0, PROCESS_LOCAL, 8490 bytes)
21/02/17 00:33:12 INFO Executor: Running task 0.0 in stage 55.0 (TID 57)
21/02/17 00:33:12 INFO FileScanRDD: Reading File path: file:///tmp/RtmptF6Khl/file1ecf155f3fa56/stages/0_r_formula__707e5573_ac38_4d87_8d8e_2fb1f36d9f08/pipelineModel/stages/1_vectorAttrRewriter_9b40dc492122/data/part-00000-8ecba51f-c1e0-4596-beb6-674643a96593-c000.snappy.parquet, range: 0-839, partition values: [empty row]
21/02/17 00:33:12 INFO ParquetReadSupport: Going to read the following fields from the Parquet file:

Parquet form:
message spark_schema {
  optional binary vectorCol (UTF8);
  optional group prefixesToRewrite (MAP) {
    repeated group key_value {
      required binary key (UTF8);
      optional binary value (UTF8);
    }
  }
}

Catalyst form:
StructType(StructField(vectorCol,StringType,true), StructField(prefixesToRewrite,MapType(StringType,StringType,true),true))
       
21/02/17 00:33:12 INFO Executor: Finished task 0.0 in stage 55.0 (TID 57). 1216 bytes result sent to driver
21/02/17 00:33:12 INFO TaskSetManager: Finished task 0.0 in stage 55.0 (TID 57) in 10 ms on localhost (executor driver) (1/1)
21/02/17 00:33:12 INFO TaskSchedulerImpl: Removed TaskSet 55.0, whose tasks have all completed, from pool 
21/02/17 00:33:12 INFO DAGScheduler: ResultStage 55 (head at RFormula.scala:599) finished in 0.013 s
21/02/17 00:33:12 INFO DAGScheduler: Job 42 finished: head at RFormula.scala:599, took 0.014434 s
21/02/17 00:33:12 INFO MemoryStore: Block broadcast_69 stored as values in memory (estimated size 239.4 KB, free 909.1 MB)
21/02/17 00:33:12 INFO MemoryStore: Block broadcast_69_piece0 stored as bytes in memory (estimated size 23.2 KB, free 909.1 MB)
21/02/17 00:33:12 INFO BlockManagerInfo: Added broadcast_69_piece0 in memory on localhost:37629 (size: 23.2 KB, free: 912.0 MB)
21/02/17 00:33:12 INFO SparkContext: Created broadcast 69 from textFile at ReadWrite.scala:387
21/02/17 00:33:12 INFO FileInputFormat: Total input paths to process : 1
21/02/17 00:33:12 INFO SparkContext: Starting job: first at ReadWrite.scala:387
21/02/17 00:33:12 INFO DAGScheduler: Got job 43 (first at ReadWrite.scala:387) with 1 output partitions
21/02/17 00:33:12 INFO DAGScheduler: Final stage: ResultStage 56 (first at ReadWrite.scala:387)
21/02/17 00:33:12 INFO DAGScheduler: Parents of final stage: List()
21/02/17 00:33:12 INFO DAGScheduler: Missing parents: List()
21/02/17 00:33:12 INFO DAGScheduler: Submitting ResultStage 56 (/tmp/RtmptF6Khl/file1ecf155f3fa56/stages/0_r_formula__707e5573_ac38_4d87_8d8e_2fb1f36d9f08/pipelineModel/stages/2_columnPruner_a6c91fdc8e44/metadata MapPartitionsRDD[183] at textFile at ReadWrite.scala:387), which has no missing parents
21/02/17 00:33:12 INFO MemoryStore: Block broadcast_70 stored as values in memory (estimated size 3.4 KB, free 909.1 MB)
21/02/17 00:33:12 INFO MemoryStore: Block broadcast_70_piece0 stored as bytes in memory (estimated size 2.1 KB, free 909.1 MB)
21/02/17 00:33:12 INFO BlockManagerInfo: Added broadcast_70_piece0 in memory on localhost:37629 (size: 2.1 KB, free: 912.0 MB)
21/02/17 00:33:12 INFO SparkContext: Created broadcast 70 from broadcast at DAGScheduler.scala:1039
21/02/17 00:33:12 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 56 (/tmp/RtmptF6Khl/file1ecf155f3fa56/stages/0_r_formula__707e5573_ac38_4d87_8d8e_2fb1f36d9f08/pipelineModel/stages/2_columnPruner_a6c91fdc8e44/metadata MapPartitionsRDD[183] at textFile at ReadWrite.scala:387) (first 15 tasks are for partitions Vector(0))
21/02/17 00:33:12 INFO TaskSchedulerImpl: Adding task set 56.0 with 1 tasks
21/02/17 00:33:12 INFO TaskSetManager: Starting task 0.0 in stage 56.0 (TID 58, localhost, executor driver, partition 0, PROCESS_LOCAL, 8012 bytes)
21/02/17 00:33:12 INFO Executor: Running task 0.0 in stage 56.0 (TID 58)
21/02/17 00:33:12 INFO HadoopRDD: Input split: file:/tmp/RtmptF6Khl/file1ecf155f3fa56/stages/0_r_formula__707e5573_ac38_4d87_8d8e_2fb1f36d9f08/pipelineModel/stages/2_columnPruner_a6c91fdc8e44/metadata/part-00000:0+150
21/02/17 00:33:12 INFO Executor: Finished task 0.0 in stage 56.0 (TID 58). 946 bytes result sent to driver
21/02/17 00:33:12 INFO TaskSetManager: Finished task 0.0 in stage 56.0 (TID 58) in 3 ms on localhost (executor driver) (1/1)
21/02/17 00:33:12 INFO TaskSchedulerImpl: Removed TaskSet 56.0, whose tasks have all completed, from pool 
21/02/17 00:33:12 INFO DAGScheduler: ResultStage 56 (first at ReadWrite.scala:387) finished in 0.006 s
21/02/17 00:33:12 INFO DAGScheduler: Job 43 finished: first at ReadWrite.scala:387, took 0.007253 s
21/02/17 00:33:12 INFO MemoryStore: Block broadcast_71 stored as values in memory (estimated size 239.4 KB, free 908.9 MB)
21/02/17 00:33:12 INFO MemoryStore: Block broadcast_71_piece0 stored as bytes in memory (estimated size 23.2 KB, free 908.8 MB)
21/02/17 00:33:12 INFO BlockManagerInfo: Added broadcast_71_piece0 in memory on localhost:37629 (size: 23.2 KB, free: 911.9 MB)
21/02/17 00:33:12 INFO SparkContext: Created broadcast 71 from textFile at ReadWrite.scala:387
21/02/17 00:33:12 INFO FileInputFormat: Total input paths to process : 1
21/02/17 00:33:12 INFO SparkContext: Starting job: first at ReadWrite.scala:387
21/02/17 00:33:12 INFO DAGScheduler: Got job 44 (first at ReadWrite.scala:387) with 1 output partitions
21/02/17 00:33:12 INFO DAGScheduler: Final stage: ResultStage 57 (first at ReadWrite.scala:387)
21/02/17 00:33:12 INFO DAGScheduler: Parents of final stage: List()
21/02/17 00:33:12 INFO DAGScheduler: Missing parents: List()
21/02/17 00:33:12 INFO DAGScheduler: Submitting ResultStage 57 (/tmp/RtmptF6Khl/file1ecf155f3fa56/stages/0_r_formula__707e5573_ac38_4d87_8d8e_2fb1f36d9f08/pipelineModel/stages/2_columnPruner_a6c91fdc8e44/metadata MapPartitionsRDD[185] at textFile at ReadWrite.scala:387), which has no missing parents
21/02/17 00:33:12 INFO MemoryStore: Block broadcast_72 stored as values in memory (estimated size 3.4 KB, free 908.8 MB)
21/02/17 00:33:12 INFO MemoryStore: Block broadcast_72_piece0 stored as bytes in memory (estimated size 2.1 KB, free 908.8 MB)
21/02/17 00:33:12 INFO BlockManagerInfo: Added broadcast_72_piece0 in memory on localhost:37629 (size: 2.1 KB, free: 911.9 MB)
21/02/17 00:33:12 INFO SparkContext: Created broadcast 72 from broadcast at DAGScheduler.scala:1039
21/02/17 00:33:12 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 57 (/tmp/RtmptF6Khl/file1ecf155f3fa56/stages/0_r_formula__707e5573_ac38_4d87_8d8e_2fb1f36d9f08/pipelineModel/stages/2_columnPruner_a6c91fdc8e44/metadata MapPartitionsRDD[185] at textFile at ReadWrite.scala:387) (first 15 tasks are for partitions Vector(0))
21/02/17 00:33:12 INFO TaskSchedulerImpl: Adding task set 57.0 with 1 tasks
21/02/17 00:33:12 INFO TaskSetManager: Starting task 0.0 in stage 57.0 (TID 59, localhost, executor driver, partition 0, PROCESS_LOCAL, 8012 bytes)
21/02/17 00:33:12 INFO Executor: Running task 0.0 in stage 57.0 (TID 59)
21/02/17 00:33:12 INFO HadoopRDD: Input split: file:/tmp/RtmptF6Khl/file1ecf155f3fa56/stages/0_r_formula__707e5573_ac38_4d87_8d8e_2fb1f36d9f08/pipelineModel/stages/2_columnPruner_a6c91fdc8e44/metadata/part-00000:0+150
21/02/17 00:33:12 INFO Executor: Finished task 0.0 in stage 57.0 (TID 59). 946 bytes result sent to driver
21/02/17 00:33:12 INFO TaskSetManager: Finished task 0.0 in stage 57.0 (TID 59) in 3 ms on localhost (executor driver) (1/1)
21/02/17 00:33:12 INFO TaskSchedulerImpl: Removed TaskSet 57.0, whose tasks have all completed, from pool 
21/02/17 00:33:12 INFO DAGScheduler: ResultStage 57 (first at ReadWrite.scala:387) finished in 0.007 s
21/02/17 00:33:12 INFO DAGScheduler: Job 44 finished: first at ReadWrite.scala:387, took 0.007911 s
21/02/17 00:33:12 INFO SparkContext: Starting job: parquet at RFormula.scala:508
21/02/17 00:33:12 INFO DAGScheduler: Got job 45 (parquet at RFormula.scala:508) with 1 output partitions
21/02/17 00:33:12 INFO DAGScheduler: Final stage: ResultStage 58 (parquet at RFormula.scala:508)
21/02/17 00:33:12 INFO DAGScheduler: Parents of final stage: List()
21/02/17 00:33:12 INFO DAGScheduler: Missing parents: List()
21/02/17 00:33:12 INFO DAGScheduler: Submitting ResultStage 58 (MapPartitionsRDD[187] at parquet at RFormula.scala:508), which has no missing parents
21/02/17 00:33:12 INFO MemoryStore: Block broadcast_73 stored as values in memory (estimated size 73.1 KB, free 908.8 MB)
21/02/17 00:33:12 INFO MemoryStore: Block broadcast_73_piece0 stored as bytes in memory (estimated size 26.0 KB, free 908.7 MB)
21/02/17 00:33:12 INFO BlockManagerInfo: Added broadcast_73_piece0 in memory on localhost:37629 (size: 26.0 KB, free: 911.9 MB)
21/02/17 00:33:12 INFO SparkContext: Created broadcast 73 from broadcast at DAGScheduler.scala:1039
21/02/17 00:33:12 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 58 (MapPartitionsRDD[187] at parquet at RFormula.scala:508) (first 15 tasks are for partitions Vector(0))
21/02/17 00:33:12 INFO TaskSchedulerImpl: Adding task set 58.0 with 1 tasks
21/02/17 00:33:12 INFO TaskSetManager: Starting task 0.0 in stage 58.0 (TID 60, localhost, executor driver, partition 0, PROCESS_LOCAL, 8171 bytes)
21/02/17 00:33:12 INFO Executor: Running task 0.0 in stage 58.0 (TID 60)
21/02/17 00:33:12 INFO Executor: Finished task 0.0 in stage 58.0 (TID 60). 1556 bytes result sent to driver
21/02/17 00:33:12 INFO TaskSetManager: Finished task 0.0 in stage 58.0 (TID 60) in 7 ms on localhost (executor driver) (1/1)
21/02/17 00:33:12 INFO TaskSchedulerImpl: Removed TaskSet 58.0, whose tasks have all completed, from pool 
21/02/17 00:33:12 INFO DAGScheduler: ResultStage 58 (parquet at RFormula.scala:508) finished in 0.015 s
21/02/17 00:33:12 INFO DAGScheduler: Job 45 finished: parquet at RFormula.scala:508, took 0.015537 s
21/02/17 00:33:12 INFO FileSourceStrategy: Pruning directories with: 
21/02/17 00:33:12 INFO FileSourceStrategy: Post-Scan Filters: 
21/02/17 00:33:12 INFO FileSourceStrategy: Output Data Schema: struct<columnsToPrune: array<string>>
21/02/17 00:33:12 INFO FileSourceScanExec: Pushed Filters: 
21/02/17 00:33:12 INFO CodeGenerator: Code generated in 7.871334 ms
21/02/17 00:33:12 INFO CodeGenerator: Code generated in 8.247581 ms
21/02/17 00:33:12 INFO MemoryStore: Block broadcast_74 stored as values in memory (estimated size 290.5 KB, free 908.4 MB)
21/02/17 00:33:12 INFO MemoryStore: Block broadcast_74_piece0 stored as bytes in memory (estimated size 24.9 KB, free 908.4 MB)
21/02/17 00:33:12 INFO BlockManagerInfo: Added broadcast_74_piece0 in memory on localhost:37629 (size: 24.9 KB, free: 911.9 MB)
21/02/17 00:33:12 INFO SparkContext: Created broadcast 74 from head at RFormula.scala:508
21/02/17 00:33:12 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
21/02/17 00:33:12 INFO SparkContext: Starting job: head at RFormula.scala:508
21/02/17 00:33:12 INFO DAGScheduler: Got job 46 (head at RFormula.scala:508) with 1 output partitions
21/02/17 00:33:12 INFO DAGScheduler: Final stage: ResultStage 59 (head at RFormula.scala:508)
21/02/17 00:33:12 INFO DAGScheduler: Parents of final stage: List()
21/02/17 00:33:12 INFO DAGScheduler: Missing parents: List()
21/02/17 00:33:12 INFO DAGScheduler: Submitting ResultStage 59 (MapPartitionsRDD[191] at head at RFormula.scala:508), which has no missing parents
21/02/17 00:33:12 INFO MemoryStore: Block broadcast_75 stored as values in memory (estimated size 10.0 KB, free 908.4 MB)
21/02/17 00:33:12 INFO MemoryStore: Block broadcast_75_piece0 stored as bytes in memory (estimated size 4.7 KB, free 908.4 MB)
21/02/17 00:33:12 INFO BlockManagerInfo: Added broadcast_75_piece0 in memory on localhost:37629 (size: 4.7 KB, free: 911.9 MB)
21/02/17 00:33:12 INFO SparkContext: Created broadcast 75 from broadcast at DAGScheduler.scala:1039
21/02/17 00:33:12 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 59 (MapPartitionsRDD[191] at head at RFormula.scala:508) (first 15 tasks are for partitions Vector(0))
21/02/17 00:33:12 INFO TaskSchedulerImpl: Adding task set 59.0 with 1 tasks
21/02/17 00:33:12 INFO TaskSetManager: Starting task 0.0 in stage 59.0 (TID 61, localhost, executor driver, partition 0, PROCESS_LOCAL, 8484 bytes)
21/02/17 00:33:12 INFO Executor: Running task 0.0 in stage 59.0 (TID 61)
21/02/17 00:33:12 INFO FileScanRDD: Reading File path: file:///tmp/RtmptF6Khl/file1ecf155f3fa56/stages/0_r_formula__707e5573_ac38_4d87_8d8e_2fb1f36d9f08/pipelineModel/stages/2_columnPruner_a6c91fdc8e44/data/part-00000-d486d687-dbf8-43fd-a3ad-1015b042eab5-c000.snappy.parquet, range: 0-470, partition values: [empty row]
21/02/17 00:33:12 INFO ParquetReadSupport: Going to read the following fields from the Parquet file:

Parquet form:
message spark_schema {
  optional group columnsToPrune (LIST) {
    repeated group list {
      optional binary element (UTF8);
    }
  }
}

Catalyst form:
StructType(StructField(columnsToPrune,ArrayType(StringType,true),true))
       
21/02/17 00:33:12 INFO Executor: Finished task 0.0 in stage 59.0 (TID 61). 1200 bytes result sent to driver
21/02/17 00:33:12 INFO TaskSetManager: Finished task 0.0 in stage 59.0 (TID 61) in 8 ms on localhost (executor driver) (1/1)
21/02/17 00:33:12 INFO TaskSchedulerImpl: Removed TaskSet 59.0, whose tasks have all completed, from pool 
21/02/17 00:33:12 INFO DAGScheduler: ResultStage 59 (head at RFormula.scala:508) finished in 0.012 s
21/02/17 00:33:12 INFO DAGScheduler: Job 46 finished: head at RFormula.scala:508, took 0.012968 s
21/02/17 00:33:12 INFO MemoryStore: Block broadcast_76 stored as values in memory (estimated size 239.4 KB, free 908.2 MB)
21/02/17 00:33:12 INFO MemoryStore: Block broadcast_76_piece0 stored as bytes in memory (estimated size 23.2 KB, free 908.1 MB)
21/02/17 00:33:12 INFO BlockManagerInfo: Added broadcast_76_piece0 in memory on localhost:37629 (size: 23.2 KB, free: 911.9 MB)
21/02/17 00:33:12 INFO SparkContext: Created broadcast 76 from textFile at ReadWrite.scala:387
21/02/17 00:33:12 INFO FileInputFormat: Total input paths to process : 1
21/02/17 00:33:12 INFO SparkContext: Starting job: first at ReadWrite.scala:387
21/02/17 00:33:12 INFO DAGScheduler: Got job 47 (first at ReadWrite.scala:387) with 1 output partitions
21/02/17 00:33:12 INFO DAGScheduler: Final stage: ResultStage 60 (first at ReadWrite.scala:387)
21/02/17 00:33:12 INFO DAGScheduler: Parents of final stage: List()
21/02/17 00:33:12 INFO DAGScheduler: Missing parents: List()
21/02/17 00:33:12 INFO DAGScheduler: Submitting ResultStage 60 (/tmp/RtmptF6Khl/file1ecf155f3fa56/stages/1_xgboost_regressor__60249f5c_5cc1_4ff3_98e6_27a65c8f804b/metadata MapPartitionsRDD[193] at textFile at ReadWrite.scala:387), which has no missing parents
21/02/17 00:33:12 INFO MemoryStore: Block broadcast_77 stored as values in memory (estimated size 3.4 KB, free 908.1 MB)
21/02/17 00:33:12 INFO MemoryStore: Block broadcast_77_piece0 stored as bytes in memory (estimated size 2.0 KB, free 908.1 MB)
21/02/17 00:33:12 INFO BlockManagerInfo: Added broadcast_77_piece0 in memory on localhost:37629 (size: 2.0 KB, free: 911.9 MB)
21/02/17 00:33:12 INFO SparkContext: Created broadcast 77 from broadcast at DAGScheduler.scala:1039
21/02/17 00:33:12 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 60 (/tmp/RtmptF6Khl/file1ecf155f3fa56/stages/1_xgboost_regressor__60249f5c_5cc1_4ff3_98e6_27a65c8f804b/metadata MapPartitionsRDD[193] at textFile at ReadWrite.scala:387) (first 15 tasks are for partitions Vector(0))
21/02/17 00:33:12 INFO TaskSchedulerImpl: Adding task set 60.0 with 1 tasks
21/02/17 00:33:12 INFO TaskSetManager: Starting task 0.0 in stage 60.0 (TID 62, localhost, executor driver, partition 0, PROCESS_LOCAL, 7970 bytes)
21/02/17 00:33:12 INFO Executor: Running task 0.0 in stage 60.0 (TID 62)
21/02/17 00:33:12 INFO HadoopRDD: Input split: file:/tmp/RtmptF6Khl/file1ecf155f3fa56/stages/1_xgboost_regressor__60249f5c_5cc1_4ff3_98e6_27a65c8f804b/metadata/part-00000:0+1079
21/02/17 00:33:12 INFO Executor: Finished task 0.0 in stage 60.0 (TID 62). 1837 bytes result sent to driver
21/02/17 00:33:12 INFO TaskSetManager: Finished task 0.0 in stage 60.0 (TID 62) in 4 ms on localhost (executor driver) (1/1)
21/02/17 00:33:12 INFO TaskSchedulerImpl: Removed TaskSet 60.0, whose tasks have all completed, from pool 
21/02/17 00:33:12 INFO DAGScheduler: ResultStage 60 (first at ReadWrite.scala:387) finished in 0.006 s
21/02/17 00:33:12 INFO DAGScheduler: Job 47 finished: first at ReadWrite.scala:387, took 0.007535 s
21/02/17 00:33:12 INFO MemoryStore: Block broadcast_78 stored as values in memory (estimated size 239.4 KB, free 907.9 MB)
21/02/17 00:33:12 INFO MemoryStore: Block broadcast_78_piece0 stored as bytes in memory (estimated size 23.2 KB, free 907.9 MB)
21/02/17 00:33:12 INFO BlockManagerInfo: Added broadcast_78_piece0 in memory on localhost:37629 (size: 23.2 KB, free: 911.8 MB)
21/02/17 00:33:12 INFO SparkContext: Created broadcast 78 from textFile at DefaultXGBoostParamsReader.scala:77
21/02/17 00:33:12 INFO FileInputFormat: Total input paths to process : 1
21/02/17 00:33:12 INFO SparkContext: Starting job: first at DefaultXGBoostParamsReader.scala:77
21/02/17 00:33:12 INFO DAGScheduler: Got job 48 (first at DefaultXGBoostParamsReader.scala:77) with 1 output partitions
21/02/17 00:33:12 INFO DAGScheduler: Final stage: ResultStage 61 (first at DefaultXGBoostParamsReader.scala:77)
21/02/17 00:33:12 INFO DAGScheduler: Parents of final stage: List()
21/02/17 00:33:12 INFO DAGScheduler: Missing parents: List()
21/02/17 00:33:12 INFO DAGScheduler: Submitting ResultStage 61 (/tmp/RtmptF6Khl/file1ecf155f3fa56/stages/1_xgboost_regressor__60249f5c_5cc1_4ff3_98e6_27a65c8f804b/metadata MapPartitionsRDD[195] at textFile at DefaultXGBoostParamsReader.scala:77), which has no missing parents
21/02/17 00:33:12 INFO MemoryStore: Block broadcast_79 stored as values in memory (estimated size 3.4 KB, free 907.9 MB)
21/02/17 00:33:12 INFO MemoryStore: Block broadcast_79_piece0 stored as bytes in memory (estimated size 2.0 KB, free 907.9 MB)
21/02/17 00:33:12 INFO BlockManagerInfo: Added broadcast_79_piece0 in memory on localhost:37629 (size: 2.0 KB, free: 911.8 MB)
21/02/17 00:33:12 INFO SparkContext: Created broadcast 79 from broadcast at DAGScheduler.scala:1039
21/02/17 00:33:12 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 61 (/tmp/RtmptF6Khl/file1ecf155f3fa56/stages/1_xgboost_regressor__60249f5c_5cc1_4ff3_98e6_27a65c8f804b/metadata MapPartitionsRDD[195] at textFile at DefaultXGBoostParamsReader.scala:77) (first 15 tasks are for partitions Vector(0))
21/02/17 00:33:12 INFO TaskSchedulerImpl: Adding task set 61.0 with 1 tasks
21/02/17 00:33:12 INFO TaskSetManager: Starting task 0.0 in stage 61.0 (TID 63, localhost, executor driver, partition 0, PROCESS_LOCAL, 7970 bytes)
21/02/17 00:33:12 INFO Executor: Running task 0.0 in stage 61.0 (TID 63)
21/02/17 00:33:12 INFO HadoopRDD: Input split: file:/tmp/RtmptF6Khl/file1ecf155f3fa56/stages/1_xgboost_regressor__60249f5c_5cc1_4ff3_98e6_27a65c8f804b/metadata/part-00000:0+1079
21/02/17 00:33:12 INFO Executor: Finished task 0.0 in stage 61.0 (TID 63). 1880 bytes result sent to driver
21/02/17 00:33:12 INFO TaskSetManager: Finished task 0.0 in stage 61.0 (TID 63) in 4 ms on localhost (executor driver) (1/1)
21/02/17 00:33:12 INFO TaskSchedulerImpl: Removed TaskSet 61.0, whose tasks have all completed, from pool 
21/02/17 00:33:12 INFO DAGScheduler: ResultStage 61 (first at DefaultXGBoostParamsReader.scala:77) finished in 0.006 s
21/02/17 00:33:12 INFO DAGScheduler: Job 48 finished: first at DefaultXGBoostParamsReader.scala:77, took 0.007914 s
21/02/17 00:33:12 INFO MemoryStore: Block broadcast_80 stored as values in memory (estimated size 64.0 B, free 907.9 MB)
21/02/17 00:33:12 INFO MemoryStore: Block broadcast_80_piece0 stored as bytes in memory (estimated size 428.0 B, free 907.9 MB)
21/02/17 00:33:12 INFO BlockManagerInfo: Added broadcast_80_piece0 in memory on localhost:37629 (size: 428.0 B, free: 911.8 MB)
21/02/17 00:33:12 INFO SparkContext: Created broadcast 80 from broadcast at XGBoostRegressor.scala:266
21/02/17 00:33:12 INFO SparkContext: Starting job: collect at utils.scala:135
21/02/17 00:33:12 INFO DAGScheduler: Got job 49 (collect at utils.scala:135) with 1 output partitions
21/02/17 00:33:12 INFO DAGScheduler: Final stage: ResultStage 62 (collect at utils.scala:135)
21/02/17 00:33:12 INFO DAGScheduler: Parents of final stage: List()
21/02/17 00:33:12 INFO DAGScheduler: Missing parents: List()
21/02/17 00:33:12 INFO DAGScheduler: Submitting ResultStage 62 (MapPartitionsRDD[206] at collect at utils.scala:135), which has no missing parents
21/02/17 00:33:12 INFO MemoryStore: Block broadcast_81 stored as values in memory (estimated size 6.5 KB, free 907.9 MB)
21/02/17 00:33:12 INFO MemoryStore: Block broadcast_81_piece0 stored as bytes in memory (estimated size 3.2 KB, free 907.9 MB)
21/02/17 00:33:12 INFO BlockManagerInfo: Added broadcast_81_piece0 in memory on localhost:37629 (size: 3.2 KB, free: 911.8 MB)
21/02/17 00:33:12 INFO SparkContext: Created broadcast 81 from broadcast at DAGScheduler.scala:1039
21/02/17 00:33:12 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 62 (MapPartitionsRDD[206] at collect at utils.scala:135) (first 15 tasks are for partitions Vector(0))
21/02/17 00:33:12 INFO TaskSchedulerImpl: Adding task set 62.0 with 1 tasks
21/02/17 00:33:12 INFO TaskSetManager: Starting task 0.0 in stage 62.0 (TID 64, localhost, executor driver, partition 0, PROCESS_LOCAL, 8067 bytes)
21/02/17 00:33:12 INFO Executor: Running task 0.0 in stage 62.0 (TID 64)
21/02/17 00:33:12 INFO Executor: Finished task 0.0 in stage 62.0 (TID 64). 1286 bytes result sent to driver
21/02/17 00:33:12 INFO TaskSetManager: Finished task 0.0 in stage 62.0 (TID 64) in 2 ms on localhost (executor driver) (1/1)
21/02/17 00:33:12 INFO TaskSchedulerImpl: Removed TaskSet 62.0, whose tasks have all completed, from pool 
21/02/17 00:33:12 INFO DAGScheduler: ResultStage 62 (collect at utils.scala:135) finished in 0.006 s
21/02/17 00:33:12 INFO DAGScheduler: Job 49 finished: collect at utils.scala:135, took 0.006762 s
21/02/17 00:33:12 INFO SparkContext: Starting job: count at utils.scala:135
21/02/17 00:33:12 INFO DAGScheduler: Registering RDD 209 (count at utils.scala:135)
21/02/17 00:33:12 INFO DAGScheduler: Got job 50 (count at utils.scala:135) with 1 output partitions
21/02/17 00:33:12 INFO DAGScheduler: Final stage: ResultStage 64 (count at utils.scala:135)
21/02/17 00:33:12 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 63)
21/02/17 00:33:12 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 63)
21/02/17 00:33:12 INFO DAGScheduler: Submitting ShuffleMapStage 63 (MapPartitionsRDD[209] at count at utils.scala:135), which has no missing parents
21/02/17 00:33:12 INFO MemoryStore: Block broadcast_82 stored as values in memory (estimated size 8.9 KB, free 907.9 MB)
21/02/17 00:33:12 INFO MemoryStore: Block broadcast_82_piece0 stored as bytes in memory (estimated size 4.5 KB, free 907.9 MB)
21/02/17 00:33:12 INFO BlockManagerInfo: Added broadcast_82_piece0 in memory on localhost:37629 (size: 4.5 KB, free: 911.8 MB)
21/02/17 00:33:12 INFO SparkContext: Created broadcast 82 from broadcast at DAGScheduler.scala:1039
21/02/17 00:33:12 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 63 (MapPartitionsRDD[209] at count at utils.scala:135) (first 15 tasks are for partitions Vector(0))
21/02/17 00:33:12 INFO TaskSchedulerImpl: Adding task set 63.0 with 1 tasks
21/02/17 00:33:12 INFO TaskSetManager: Starting task 0.0 in stage 63.0 (TID 65, localhost, executor driver, partition 0, PROCESS_LOCAL, 8056 bytes)
21/02/17 00:33:12 INFO Executor: Running task 0.0 in stage 63.0 (TID 65)
21/02/17 00:33:12 INFO Executor: Finished task 0.0 in stage 63.0 (TID 65). 1499 bytes result sent to driver
21/02/17 00:33:12 INFO TaskSetManager: Finished task 0.0 in stage 63.0 (TID 65) in 3 ms on localhost (executor driver) (1/1)
21/02/17 00:33:12 INFO TaskSchedulerImpl: Removed TaskSet 63.0, whose tasks have all completed, from pool 
21/02/17 00:33:12 INFO DAGScheduler: ShuffleMapStage 63 (count at utils.scala:135) finished in 0.006 s
21/02/17 00:33:12 INFO DAGScheduler: looking for newly runnable stages
21/02/17 00:33:12 INFO DAGScheduler: running: Set()
21/02/17 00:33:12 INFO DAGScheduler: waiting: Set(ResultStage 64)
21/02/17 00:33:12 INFO DAGScheduler: failed: Set()
21/02/17 00:33:12 INFO DAGScheduler: Submitting ResultStage 64 (MapPartitionsRDD[212] at count at utils.scala:135), which has no missing parents
21/02/17 00:33:12 INFO MemoryStore: Block broadcast_83 stored as values in memory (estimated size 7.3 KB, free 907.8 MB)
21/02/17 00:33:12 INFO MemoryStore: Block broadcast_83_piece0 stored as bytes in memory (estimated size 3.8 KB, free 907.8 MB)
21/02/17 00:33:12 INFO BlockManagerInfo: Added broadcast_83_piece0 in memory on localhost:37629 (size: 3.8 KB, free: 911.8 MB)
21/02/17 00:33:12 INFO SparkContext: Created broadcast 83 from broadcast at DAGScheduler.scala:1039
21/02/17 00:33:12 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 64 (MapPartitionsRDD[212] at count at utils.scala:135) (first 15 tasks are for partitions Vector(0))
21/02/17 00:33:12 INFO TaskSchedulerImpl: Adding task set 64.0 with 1 tasks
21/02/17 00:33:12 INFO TaskSetManager: Starting task 0.0 in stage 64.0 (TID 66, localhost, executor driver, partition 0, NODE_LOCAL, 7754 bytes)
21/02/17 00:33:12 INFO Executor: Running task 0.0 in stage 64.0 (TID 66)
21/02/17 00:33:12 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
21/02/17 00:33:12 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
21/02/17 00:33:12 INFO Executor: Finished task 0.0 in stage 64.0 (TID 66). 1739 bytes result sent to driver
21/02/17 00:33:12 INFO TaskSetManager: Finished task 0.0 in stage 64.0 (TID 66) in 4 ms on localhost (executor driver) (1/1)
21/02/17 00:33:12 INFO TaskSchedulerImpl: Removed TaskSet 64.0, whose tasks have all completed, from pool 
21/02/17 00:33:12 INFO DAGScheduler: ResultStage 64 (count at utils.scala:135) finished in 0.007 s
21/02/17 00:33:12 INFO DAGScheduler: Job 50 finished: count at utils.scala:135, took 0.015987 s
21/02/17 00:33:13 INFO SparkContext: Starting job: collect at utils.scala:135
21/02/17 00:33:13 INFO DAGScheduler: Got job 51 (collect at utils.scala:135) with 1 output partitions
21/02/17 00:33:13 INFO DAGScheduler: Final stage: ResultStage 65 (collect at utils.scala:135)
21/02/17 00:33:13 INFO DAGScheduler: Parents of final stage: List()
21/02/17 00:33:13 INFO DAGScheduler: Missing parents: List()
21/02/17 00:33:13 INFO DAGScheduler: Submitting ResultStage 65 (MapPartitionsRDD[215] at collect at utils.scala:135), which has no missing parents
21/02/17 00:33:13 INFO MemoryStore: Block broadcast_84 stored as values in memory (estimated size 57.9 KB, free 907.8 MB)
21/02/17 00:33:13 INFO MemoryStore: Block broadcast_84_piece0 stored as bytes in memory (estimated size 23.9 KB, free 907.8 MB)
21/02/17 00:33:13 INFO BlockManagerInfo: Added broadcast_84_piece0 in memory on localhost:37629 (size: 23.9 KB, free: 911.8 MB)
21/02/17 00:33:13 INFO SparkContext: Created broadcast 84 from broadcast at DAGScheduler.scala:1039
21/02/17 00:33:13 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 65 (MapPartitionsRDD[215] at collect at utils.scala:135) (first 15 tasks are for partitions Vector(0))
21/02/17 00:33:13 INFO TaskSchedulerImpl: Adding task set 65.0 with 1 tasks
21/02/17 00:33:13 INFO TaskSetManager: Starting task 0.0 in stage 65.0 (TID 67, localhost, executor driver, partition 0, PROCESS_LOCAL, 18998 bytes)
21/02/17 00:33:13 INFO Executor: Running task 0.0 in stage 65.0 (TID 67)
21/02/17 00:33:13 INFO BlockManager: Found block rdd_17_0 locally
21/02/17 00:33:13 INFO Executor: Finished task 0.0 in stage 65.0 (TID 67). 1858 bytes result sent to driver
21/02/17 00:33:13 INFO TaskSetManager: Finished task 0.0 in stage 65.0 (TID 67) in 31 ms on localhost (executor driver) (1/1)
21/02/17 00:33:13 INFO TaskSchedulerImpl: Removed TaskSet 65.0, whose tasks have all completed, from pool 
21/02/17 00:33:13 INFO DAGScheduler: ResultStage 65 (collect at utils.scala:135) finished in 0.036 s
21/02/17 00:33:13 INFO DAGScheduler: Job 51 finished: collect at utils.scala:135, took 0.037651 s
21/02/17 00:33:13 INFO SparkContext: Starting job: count at utils.scala:135
21/02/17 00:33:13 INFO DAGScheduler: Registering RDD 218 (count at utils.scala:135)
21/02/17 00:33:13 INFO DAGScheduler: Got job 52 (count at utils.scala:135) with 1 output partitions
21/02/17 00:33:13 INFO DAGScheduler: Final stage: ResultStage 67 (count at utils.scala:135)
21/02/17 00:33:13 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 66)
21/02/17 00:33:13 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 66)
21/02/17 00:33:13 INFO DAGScheduler: Submitting ShuffleMapStage 66 (MapPartitionsRDD[218] at count at utils.scala:135), which has no missing parents
21/02/17 00:33:13 INFO MemoryStore: Block broadcast_85 stored as values in memory (estimated size 58.8 KB, free 907.7 MB)
21/02/17 00:33:13 INFO MemoryStore: Block broadcast_85_piece0 stored as bytes in memory (estimated size 24.4 KB, free 907.7 MB)
21/02/17 00:33:13 INFO BlockManagerInfo: Added broadcast_85_piece0 in memory on localhost:37629 (size: 24.4 KB, free: 911.8 MB)
21/02/17 00:33:13 INFO SparkContext: Created broadcast 85 from broadcast at DAGScheduler.scala:1039
21/02/17 00:33:13 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 66 (MapPartitionsRDD[218] at count at utils.scala:135) (first 15 tasks are for partitions Vector(0))
21/02/17 00:33:13 INFO TaskSchedulerImpl: Adding task set 66.0 with 1 tasks
21/02/17 00:33:13 INFO TaskSetManager: Starting task 0.0 in stage 66.0 (TID 68, localhost, executor driver, partition 0, PROCESS_LOCAL, 18987 bytes)
21/02/17 00:33:13 INFO Executor: Running task 0.0 in stage 66.0 (TID 68)
21/02/17 00:33:13 INFO BlockManager: Found block rdd_17_0 locally
21/02/17 00:33:13 INFO Executor: Finished task 0.0 in stage 66.0 (TID 68). 1933 bytes result sent to driver
21/02/17 00:33:13 INFO TaskSetManager: Finished task 0.0 in stage 66.0 (TID 68) in 44 ms on localhost (executor driver) (1/1)
21/02/17 00:33:13 INFO TaskSchedulerImpl: Removed TaskSet 66.0, whose tasks have all completed, from pool 
21/02/17 00:33:13 INFO DAGScheduler: ShuffleMapStage 66 (count at utils.scala:135) finished in 0.050 s
21/02/17 00:33:13 INFO DAGScheduler: looking for newly runnable stages
21/02/17 00:33:13 INFO DAGScheduler: running: Set()
21/02/17 00:33:13 INFO DAGScheduler: waiting: Set(ResultStage 67)
21/02/17 00:33:13 INFO DAGScheduler: failed: Set()
21/02/17 00:33:13 INFO DAGScheduler: Submitting ResultStage 67 (MapPartitionsRDD[221] at count at utils.scala:135), which has no missing parents
21/02/17 00:33:13 INFO MemoryStore: Block broadcast_86 stored as values in memory (estimated size 7.3 KB, free 907.7 MB)
21/02/17 00:33:13 INFO MemoryStore: Block broadcast_86_piece0 stored as bytes in memory (estimated size 3.8 KB, free 907.7 MB)
21/02/17 00:33:13 INFO BlockManagerInfo: Added broadcast_86_piece0 in memory on localhost:37629 (size: 3.8 KB, free: 911.8 MB)
21/02/17 00:33:13 INFO SparkContext: Created broadcast 86 from broadcast at DAGScheduler.scala:1039
21/02/17 00:33:13 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 67 (MapPartitionsRDD[221] at count at utils.scala:135) (first 15 tasks are for partitions Vector(0))
21/02/17 00:33:13 INFO TaskSchedulerImpl: Adding task set 67.0 with 1 tasks
21/02/17 00:33:13 INFO TaskSetManager: Starting task 0.0 in stage 67.0 (TID 69, localhost, executor driver, partition 0, NODE_LOCAL, 7754 bytes)
21/02/17 00:33:13 INFO Executor: Running task 0.0 in stage 67.0 (TID 69)
21/02/17 00:33:13 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
21/02/17 00:33:13 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
21/02/17 00:33:13 INFO Executor: Finished task 0.0 in stage 67.0 (TID 69). 1782 bytes result sent to driver
21/02/17 00:33:13 INFO TaskSetManager: Finished task 0.0 in stage 67.0 (TID 69) in 4 ms on localhost (executor driver) (1/1)
21/02/17 00:33:13 INFO TaskSchedulerImpl: Removed TaskSet 67.0, whose tasks have all completed, from pool 
21/02/17 00:33:13 INFO DAGScheduler: ResultStage 67 (count at utils.scala:135) finished in 0.009 s
21/02/17 00:33:13 INFO DAGScheduler: Job 52 finished: count at utils.scala:135, took 0.061085 s
21/02/17 00:33:14 INFO SparkContext: Invoking stop() from shutdown hook
21/02/17 00:33:14 INFO SparkUI: Stopped Spark web UI at http://localhost:4040
21/02/17 00:33:14 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!
21/02/17 00:33:14 INFO MemoryStore: MemoryStore cleared
21/02/17 00:33:14 INFO BlockManager: BlockManager stopped
21/02/17 00:33:14 INFO BlockManagerMaster: BlockManagerMaster stopped
21/02/17 00:33:14 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!
21/02/17 00:33:14 INFO SparkContext: Successfully stopped SparkContext
21/02/17 00:33:14 INFO ShutdownHookManager: Shutdown hook called
21/02/17 00:33:14 INFO ShutdownHookManager: Deleting directory /tmp/spark-afa8e139-2ae1-4d38-85a9-7608b3a1c6e8
21/02/17 00:33:14 INFO ShutdownHookManager: Deleting directory /tmp/spark-8295e364-5165-499e-b8b1-1037a7c35497
21/02/17 00:50:53 INFO ShutdownHookManager: Shutdown hook called
21/02/17 00:50:53 INFO ShutdownHookManager: Deleting directory /tmp/spark-256f9116-26f2-4bde-90ff-6d543ca9d3be
21/02/17 00:54:17 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
21/02/17 00:54:18 INFO SparkContext: Running Spark version 2.3.0
21/02/17 00:54:18 INFO SparkContext: Submitted application: sparklyr
21/02/17 00:54:18 INFO SecurityManager: Changing view acls to: yitaoli
21/02/17 00:54:18 INFO SecurityManager: Changing modify acls to: yitaoli
21/02/17 00:54:18 INFO SecurityManager: Changing view acls groups to: 
21/02/17 00:54:18 INFO SecurityManager: Changing modify acls groups to: 
21/02/17 00:54:18 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(yitaoli); groups with view permissions: Set(); users  with modify permissions: Set(yitaoli); groups with modify permissions: Set()
21/02/17 00:54:18 INFO Utils: Successfully started service 'sparkDriver' on port 34197.
21/02/17 00:54:18 INFO SparkEnv: Registering MapOutputTracker
21/02/17 00:54:18 INFO SparkEnv: Registering BlockManagerMaster
21/02/17 00:54:18 INFO BlockManagerMasterEndpoint: Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
21/02/17 00:54:18 INFO BlockManagerMasterEndpoint: BlockManagerMasterEndpoint up
21/02/17 00:54:18 INFO DiskBlockManager: Created local directory at /tmp/blockmgr-5a6f7593-d221-40dc-b196-7a2e8e46a641
21/02/17 00:54:18 INFO MemoryStore: MemoryStore started with capacity 912.3 MB
21/02/17 00:54:18 INFO SparkEnv: Registering OutputCommitCoordinator
21/02/17 00:54:18 INFO Utils: Successfully started service 'SparkUI' on port 4040.
21/02/17 00:54:18 INFO SparkUI: Bound SparkUI to 127.0.0.1, and started at http://localhost:4040
21/02/17 00:54:18 INFO SparkContext: Added JAR file:///home/yitaoli/R/x86_64-pc-linux-gnu-library/4.0/sparkxgb/java/sparkxgb-2.3-2.11.jar at spark://localhost:34197/jars/sparkxgb-2.3-2.11.jar with timestamp 1613523258441
21/02/17 00:54:18 INFO SparkContext: Added JAR file:///home/yitaoli/.ivy2/jars/ml.dmlc_xgboost4j-spark_2.12-1.3.1.jar at spark://localhost:34197/jars/ml.dmlc_xgboost4j-spark_2.12-1.3.1.jar with timestamp 1613523258442
21/02/17 00:54:18 INFO SparkContext: Added JAR file:///home/yitaoli/.ivy2/jars/ml.dmlc_xgboost4j_2.12-1.3.1.jar at spark://localhost:34197/jars/ml.dmlc_xgboost4j_2.12-1.3.1.jar with timestamp 1613523258442
21/02/17 00:54:18 INFO SparkContext: Added JAR file:///home/yitaoli/.ivy2/jars/com.esotericsoftware_kryo-4.0.2.jar at spark://localhost:34197/jars/com.esotericsoftware_kryo-4.0.2.jar with timestamp 1613523258442
21/02/17 00:54:18 INFO SparkContext: Added JAR file:///home/yitaoli/.ivy2/jars/org.scala-lang_scala-compiler-2.12.8.jar at spark://localhost:34197/jars/org.scala-lang_scala-compiler-2.12.8.jar with timestamp 1613523258442
21/02/17 00:54:18 INFO SparkContext: Added JAR file:///home/yitaoli/.ivy2/jars/org.scala-lang_scala-reflect-2.12.8.jar at spark://localhost:34197/jars/org.scala-lang_scala-reflect-2.12.8.jar with timestamp 1613523258442
21/02/17 00:54:18 INFO SparkContext: Added JAR file:///home/yitaoli/.ivy2/jars/commons-logging_commons-logging-1.2.jar at spark://localhost:34197/jars/commons-logging_commons-logging-1.2.jar with timestamp 1613523258442
21/02/17 00:54:18 INFO SparkContext: Added JAR file:///home/yitaoli/.ivy2/jars/com.typesafe.akka_akka-actor_2.12-2.5.23.jar at spark://localhost:34197/jars/com.typesafe.akka_akka-actor_2.12-2.5.23.jar with timestamp 1613523258442
21/02/17 00:54:18 INFO SparkContext: Added JAR file:///home/yitaoli/.ivy2/jars/org.scalatest_scalatest_2.12-3.0.5.jar at spark://localhost:34197/jars/org.scalatest_scalatest_2.12-3.0.5.jar with timestamp 1613523258442
21/02/17 00:54:18 INFO SparkContext: Added JAR file:///home/yitaoli/.ivy2/jars/com.typesafe_config-1.3.3.jar at spark://localhost:34197/jars/com.typesafe_config-1.3.3.jar with timestamp 1613523258442
21/02/17 00:54:18 INFO SparkContext: Added JAR file:///home/yitaoli/.ivy2/jars/org.scala-lang.modules_scala-java8-compat_2.12-0.8.0.jar at spark://localhost:34197/jars/org.scala-lang.modules_scala-java8-compat_2.12-0.8.0.jar with timestamp 1613523258442
21/02/17 00:54:18 INFO SparkContext: Added JAR file:///home/yitaoli/.ivy2/jars/org.scalactic_scalactic_2.12-3.0.5.jar at spark://localhost:34197/jars/org.scalactic_scalactic_2.12-3.0.5.jar with timestamp 1613523258442
21/02/17 00:54:18 INFO SparkContext: Added JAR file:///home/yitaoli/.ivy2/jars/org.scala-lang.modules_scala-xml_2.12-1.0.6.jar at spark://localhost:34197/jars/org.scala-lang.modules_scala-xml_2.12-1.0.6.jar with timestamp 1613523258442
21/02/17 00:54:18 INFO SparkContext: Added JAR file:///home/yitaoli/.ivy2/jars/com.esotericsoftware_reflectasm-1.11.3.jar at spark://localhost:34197/jars/com.esotericsoftware_reflectasm-1.11.3.jar with timestamp 1613523258442
21/02/17 00:54:18 INFO SparkContext: Added JAR file:///home/yitaoli/.ivy2/jars/com.esotericsoftware_minlog-1.3.0.jar at spark://localhost:34197/jars/com.esotericsoftware_minlog-1.3.0.jar with timestamp 1613523258442
21/02/17 00:54:18 INFO SparkContext: Added JAR file:///home/yitaoli/.ivy2/jars/org.objenesis_objenesis-2.5.1.jar at spark://localhost:34197/jars/org.objenesis_objenesis-2.5.1.jar with timestamp 1613523258443
21/02/17 00:54:18 INFO SparkContext: Added JAR file:///home/yitaoli/.ivy2/jars/org.ow2.asm_asm-5.0.4.jar at spark://localhost:34197/jars/org.ow2.asm_asm-5.0.4.jar with timestamp 1613523258443
21/02/17 00:54:18 INFO SparkContext: Added JAR file:/home/yitaoli/R/x86_64-pc-linux-gnu-library/4.0/sparklyr/java/sparklyr-2.3-2.11.jar at spark://localhost:34197/jars/sparklyr-2.3-2.11.jar with timestamp 1613523258443
21/02/17 00:54:18 INFO Executor: Starting executor ID driver on host localhost
21/02/17 00:54:18 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 37741.
21/02/17 00:54:18 INFO NettyBlockTransferService: Server created on localhost:37741
21/02/17 00:54:18 INFO BlockManager: Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
21/02/17 00:54:18 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, localhost, 37741, None)
21/02/17 00:54:18 INFO BlockManagerMasterEndpoint: Registering block manager localhost:37741 with 912.3 MB RAM, BlockManagerId(driver, localhost, 37741, None)
21/02/17 00:54:18 INFO BlockManagerMaster: Registered BlockManager BlockManagerId(driver, localhost, 37741, None)
21/02/17 00:54:18 INFO BlockManager: Initialized BlockManager: BlockManagerId(driver, localhost, 37741, None)
21/02/17 00:54:18 INFO SharedState: loading hive config file: file:/home/yitaoli/spark/spark-2.3.0-bin-hadoop2.7/conf/hive-site.xml
21/02/17 00:54:18 INFO SharedState: Setting hive.metastore.warehouse.dir ('null') to the value of spark.sql.warehouse.dir ('file:/home/yitaoli/sparkxgb/tests/testthat/spark-warehouse').
21/02/17 00:54:18 INFO SharedState: Warehouse path is 'file:/home/yitaoli/sparkxgb/tests/testthat/spark-warehouse'.
21/02/17 00:54:18 INFO StateStoreCoordinatorRef: Registered StateStoreCoordinator endpoint
21/02/17 00:54:19 INFO HiveUtils: Initializing HiveMetastoreConnection version 1.2.1 using Spark classes.
21/02/17 00:54:20 INFO HiveMetaStore: 0: Opening raw store with implemenation class:org.apache.hadoop.hive.metastore.ObjectStore
21/02/17 00:54:20 INFO ObjectStore: ObjectStore, initialize called
21/02/17 00:54:20 INFO Persistence: Property hive.metastore.integral.jdo.pushdown unknown - will be ignored
21/02/17 00:54:20 INFO Persistence: Property datanucleus.cache.level2 unknown - will be ignored
21/02/17 00:54:21 INFO ObjectStore: Setting MetaStore object pin classes with hive.metastore.cache.pinobjtypes="Table,StorageDescriptor,SerDeInfo,Partition,Database,Type,FieldSchema,Order"
21/02/17 00:54:21 INFO Datastore: The class "org.apache.hadoop.hive.metastore.model.MFieldSchema" is tagged as "embedded-only" so does not have its own datastore table.
21/02/17 00:54:21 INFO Datastore: The class "org.apache.hadoop.hive.metastore.model.MOrder" is tagged as "embedded-only" so does not have its own datastore table.
21/02/17 00:54:22 INFO Datastore: The class "org.apache.hadoop.hive.metastore.model.MFieldSchema" is tagged as "embedded-only" so does not have its own datastore table.
21/02/17 00:54:22 INFO Datastore: The class "org.apache.hadoop.hive.metastore.model.MOrder" is tagged as "embedded-only" so does not have its own datastore table.
21/02/17 00:54:22 INFO MetaStoreDirectSql: Using direct SQL, underlying DB is DERBY
21/02/17 00:54:22 INFO ObjectStore: Initialized ObjectStore
21/02/17 00:54:22 WARN ObjectStore: Version information not found in metastore. hive.metastore.schema.verification is not enabled so recording the schema version 1.2.0
21/02/17 00:54:22 WARN ObjectStore: Failed to get database default, returning NoSuchObjectException
21/02/17 00:54:22 INFO HiveMetaStore: Added admin role in metastore
21/02/17 00:54:22 INFO HiveMetaStore: Added public role in metastore
21/02/17 00:54:22 INFO HiveMetaStore: No user is added in admin role, since config is empty
21/02/17 00:54:22 INFO HiveMetaStore: 0: get_all_databases
21/02/17 00:54:22 INFO audit: ugi=yitaoli	ip=unknown-ip-addr	cmd=get_all_databases	
21/02/17 00:54:22 INFO HiveMetaStore: 0: get_functions: db=default pat=*
21/02/17 00:54:22 INFO audit: ugi=yitaoli	ip=unknown-ip-addr	cmd=get_functions: db=default pat=*	
21/02/17 00:54:22 INFO Datastore: The class "org.apache.hadoop.hive.metastore.model.MResourceUri" is tagged as "embedded-only" so does not have its own datastore table.
21/02/17 00:54:22 INFO SessionState: Created local directory: /tmp/d377d4c7-40a4-49ed-b2d8-ae8027be8ead_resources
21/02/17 00:54:22 INFO SessionState: Created HDFS directory: /tmp/hive/yitaoli/d377d4c7-40a4-49ed-b2d8-ae8027be8ead
21/02/17 00:54:22 INFO SessionState: Created local directory: /tmp/yitaoli/d377d4c7-40a4-49ed-b2d8-ae8027be8ead
21/02/17 00:54:22 INFO SessionState: Created HDFS directory: /tmp/hive/yitaoli/d377d4c7-40a4-49ed-b2d8-ae8027be8ead/_tmp_space.db
21/02/17 00:54:22 INFO HiveClientImpl: Warehouse location for Hive client (version 1.2.2) is file:/home/yitaoli/sparkxgb/tests/testthat/spark-warehouse
21/02/17 00:54:22 INFO HiveMetaStore: 0: get_database: default
21/02/17 00:54:22 INFO audit: ugi=yitaoli	ip=unknown-ip-addr	cmd=get_database: default	
21/02/17 00:54:22 INFO HiveMetaStore: 0: get_database: global_temp
21/02/17 00:54:22 INFO audit: ugi=yitaoli	ip=unknown-ip-addr	cmd=get_database: global_temp	
21/02/17 00:54:22 WARN ObjectStore: Failed to get database global_temp, returning NoSuchObjectException
21/02/17 00:54:22 INFO HiveMetaStore: 0: get_table : db=default tbl=iris
21/02/17 00:54:22 INFO audit: ugi=yitaoli	ip=unknown-ip-addr	cmd=get_table : db=default tbl=iris	
21/02/17 00:54:23 INFO HiveMetaStore: 0: get_database: default
21/02/17 00:54:23 INFO audit: ugi=yitaoli	ip=unknown-ip-addr	cmd=get_database: default	
21/02/17 00:54:23 INFO HiveMetaStore: 0: get_database: default
21/02/17 00:54:23 INFO audit: ugi=yitaoli	ip=unknown-ip-addr	cmd=get_database: default	
21/02/17 00:54:23 INFO HiveMetaStore: 0: get_tables: db=default pat=*
21/02/17 00:54:23 INFO audit: ugi=yitaoli	ip=unknown-ip-addr	cmd=get_tables: db=default pat=*	
21/02/17 00:54:23 INFO SparkContext: Starting job: collect at utils.scala:61
21/02/17 00:54:23 INFO DAGScheduler: Got job 0 (collect at utils.scala:61) with 1 output partitions
21/02/17 00:54:23 INFO DAGScheduler: Final stage: ResultStage 0 (collect at utils.scala:61)
21/02/17 00:54:23 INFO DAGScheduler: Parents of final stage: List()
21/02/17 00:54:23 INFO DAGScheduler: Missing parents: List()
21/02/17 00:54:23 INFO DAGScheduler: Submitting ResultStage 0 (MapPartitionsRDD[4] at map at utils.scala:54), which has no missing parents
21/02/17 00:54:23 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 5.9 KB, free 912.3 MB)
21/02/17 00:54:23 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 3.3 KB, free 912.3 MB)
21/02/17 00:54:23 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on localhost:37741 (size: 3.3 KB, free: 912.3 MB)
21/02/17 00:54:23 INFO SparkContext: Created broadcast 0 from broadcast at DAGScheduler.scala:1039
21/02/17 00:54:23 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 0 (MapPartitionsRDD[4] at map at utils.scala:54) (first 15 tasks are for partitions Vector(0))
21/02/17 00:54:23 INFO TaskSchedulerImpl: Adding task set 0.0 with 1 tasks
21/02/17 00:54:23 INFO TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0, localhost, executor driver, partition 0, PROCESS_LOCAL, 7880 bytes)
21/02/17 00:54:23 INFO Executor: Running task 0.0 in stage 0.0 (TID 0)
21/02/17 00:54:23 INFO Executor: Fetching spark://localhost:34197/jars/org.scalactic_scalactic_2.12-3.0.5.jar with timestamp 1613523258442
21/02/17 00:54:23 INFO TransportClientFactory: Successfully created connection to localhost/127.0.0.1:34197 after 12 ms (0 ms spent in bootstraps)
21/02/17 00:54:23 INFO Utils: Fetching spark://localhost:34197/jars/org.scalactic_scalactic_2.12-3.0.5.jar to /tmp/spark-61c9bedd-e134-422c-be6d-73a272e20777/userFiles-024991e3-5278-4d40-99af-3b3e3bee74f3/fetchFileTemp1640581808277808912.tmp
21/02/17 00:54:23 INFO Executor: Adding file:/tmp/spark-61c9bedd-e134-422c-be6d-73a272e20777/userFiles-024991e3-5278-4d40-99af-3b3e3bee74f3/org.scalactic_scalactic_2.12-3.0.5.jar to class loader
21/02/17 00:54:23 INFO Executor: Fetching spark://localhost:34197/jars/com.typesafe.akka_akka-actor_2.12-2.5.23.jar with timestamp 1613523258442
21/02/17 00:54:23 INFO Utils: Fetching spark://localhost:34197/jars/com.typesafe.akka_akka-actor_2.12-2.5.23.jar to /tmp/spark-61c9bedd-e134-422c-be6d-73a272e20777/userFiles-024991e3-5278-4d40-99af-3b3e3bee74f3/fetchFileTemp8810969889494424504.tmp
21/02/17 00:54:23 INFO Executor: Adding file:/tmp/spark-61c9bedd-e134-422c-be6d-73a272e20777/userFiles-024991e3-5278-4d40-99af-3b3e3bee74f3/com.typesafe.akka_akka-actor_2.12-2.5.23.jar to class loader
21/02/17 00:54:23 INFO Executor: Fetching spark://localhost:34197/jars/com.esotericsoftware_reflectasm-1.11.3.jar with timestamp 1613523258442
21/02/17 00:54:23 INFO Utils: Fetching spark://localhost:34197/jars/com.esotericsoftware_reflectasm-1.11.3.jar to /tmp/spark-61c9bedd-e134-422c-be6d-73a272e20777/userFiles-024991e3-5278-4d40-99af-3b3e3bee74f3/fetchFileTemp6835817115599588813.tmp
21/02/17 00:54:23 INFO Executor: Adding file:/tmp/spark-61c9bedd-e134-422c-be6d-73a272e20777/userFiles-024991e3-5278-4d40-99af-3b3e3bee74f3/com.esotericsoftware_reflectasm-1.11.3.jar to class loader
21/02/17 00:54:23 INFO Executor: Fetching spark://localhost:34197/jars/com.esotericsoftware_minlog-1.3.0.jar with timestamp 1613523258442
21/02/17 00:54:23 INFO Utils: Fetching spark://localhost:34197/jars/com.esotericsoftware_minlog-1.3.0.jar to /tmp/spark-61c9bedd-e134-422c-be6d-73a272e20777/userFiles-024991e3-5278-4d40-99af-3b3e3bee74f3/fetchFileTemp620829947661465554.tmp
21/02/17 00:54:23 INFO Executor: Adding file:/tmp/spark-61c9bedd-e134-422c-be6d-73a272e20777/userFiles-024991e3-5278-4d40-99af-3b3e3bee74f3/com.esotericsoftware_minlog-1.3.0.jar to class loader
21/02/17 00:54:23 INFO Executor: Fetching spark://localhost:34197/jars/ml.dmlc_xgboost4j_2.12-1.3.1.jar with timestamp 1613523258442
21/02/17 00:54:23 INFO Utils: Fetching spark://localhost:34197/jars/ml.dmlc_xgboost4j_2.12-1.3.1.jar to /tmp/spark-61c9bedd-e134-422c-be6d-73a272e20777/userFiles-024991e3-5278-4d40-99af-3b3e3bee74f3/fetchFileTemp6075987445125681579.tmp
21/02/17 00:54:23 INFO Executor: Adding file:/tmp/spark-61c9bedd-e134-422c-be6d-73a272e20777/userFiles-024991e3-5278-4d40-99af-3b3e3bee74f3/ml.dmlc_xgboost4j_2.12-1.3.1.jar to class loader
21/02/17 00:54:23 INFO Executor: Fetching spark://localhost:34197/jars/sparkxgb-2.3-2.11.jar with timestamp 1613523258441
21/02/17 00:54:23 INFO Utils: Fetching spark://localhost:34197/jars/sparkxgb-2.3-2.11.jar to /tmp/spark-61c9bedd-e134-422c-be6d-73a272e20777/userFiles-024991e3-5278-4d40-99af-3b3e3bee74f3/fetchFileTemp7041717430393734348.tmp
21/02/17 00:54:23 INFO Executor: Adding file:/tmp/spark-61c9bedd-e134-422c-be6d-73a272e20777/userFiles-024991e3-5278-4d40-99af-3b3e3bee74f3/sparkxgb-2.3-2.11.jar to class loader
21/02/17 00:54:23 INFO Executor: Fetching spark://localhost:34197/jars/org.scalatest_scalatest_2.12-3.0.5.jar with timestamp 1613523258442
21/02/17 00:54:23 INFO Utils: Fetching spark://localhost:34197/jars/org.scalatest_scalatest_2.12-3.0.5.jar to /tmp/spark-61c9bedd-e134-422c-be6d-73a272e20777/userFiles-024991e3-5278-4d40-99af-3b3e3bee74f3/fetchFileTemp5119367673997016019.tmp
21/02/17 00:54:23 INFO Executor: Adding file:/tmp/spark-61c9bedd-e134-422c-be6d-73a272e20777/userFiles-024991e3-5278-4d40-99af-3b3e3bee74f3/org.scalatest_scalatest_2.12-3.0.5.jar to class loader
21/02/17 00:54:23 INFO Executor: Fetching spark://localhost:34197/jars/org.scala-lang.modules_scala-java8-compat_2.12-0.8.0.jar with timestamp 1613523258442
21/02/17 00:54:23 INFO Utils: Fetching spark://localhost:34197/jars/org.scala-lang.modules_scala-java8-compat_2.12-0.8.0.jar to /tmp/spark-61c9bedd-e134-422c-be6d-73a272e20777/userFiles-024991e3-5278-4d40-99af-3b3e3bee74f3/fetchFileTemp7519311697778718267.tmp
21/02/17 00:54:23 INFO Executor: Adding file:/tmp/spark-61c9bedd-e134-422c-be6d-73a272e20777/userFiles-024991e3-5278-4d40-99af-3b3e3bee74f3/org.scala-lang.modules_scala-java8-compat_2.12-0.8.0.jar to class loader
21/02/17 00:54:23 INFO Executor: Fetching spark://localhost:34197/jars/commons-logging_commons-logging-1.2.jar with timestamp 1613523258442
21/02/17 00:54:23 INFO Utils: Fetching spark://localhost:34197/jars/commons-logging_commons-logging-1.2.jar to /tmp/spark-61c9bedd-e134-422c-be6d-73a272e20777/userFiles-024991e3-5278-4d40-99af-3b3e3bee74f3/fetchFileTemp1561309287606567124.tmp
21/02/17 00:54:23 INFO Executor: Adding file:/tmp/spark-61c9bedd-e134-422c-be6d-73a272e20777/userFiles-024991e3-5278-4d40-99af-3b3e3bee74f3/commons-logging_commons-logging-1.2.jar to class loader
21/02/17 00:54:23 INFO Executor: Fetching spark://localhost:34197/jars/sparklyr-2.3-2.11.jar with timestamp 1613523258443
21/02/17 00:54:23 INFO Utils: Fetching spark://localhost:34197/jars/sparklyr-2.3-2.11.jar to /tmp/spark-61c9bedd-e134-422c-be6d-73a272e20777/userFiles-024991e3-5278-4d40-99af-3b3e3bee74f3/fetchFileTemp6151664170095036025.tmp
21/02/17 00:54:23 INFO Executor: Adding file:/tmp/spark-61c9bedd-e134-422c-be6d-73a272e20777/userFiles-024991e3-5278-4d40-99af-3b3e3bee74f3/sparklyr-2.3-2.11.jar to class loader
21/02/17 00:54:23 INFO Executor: Fetching spark://localhost:34197/jars/org.objenesis_objenesis-2.5.1.jar with timestamp 1613523258443
21/02/17 00:54:23 INFO Utils: Fetching spark://localhost:34197/jars/org.objenesis_objenesis-2.5.1.jar to /tmp/spark-61c9bedd-e134-422c-be6d-73a272e20777/userFiles-024991e3-5278-4d40-99af-3b3e3bee74f3/fetchFileTemp1632840280227379823.tmp
21/02/17 00:54:23 INFO Executor: Adding file:/tmp/spark-61c9bedd-e134-422c-be6d-73a272e20777/userFiles-024991e3-5278-4d40-99af-3b3e3bee74f3/org.objenesis_objenesis-2.5.1.jar to class loader
21/02/17 00:54:23 INFO Executor: Fetching spark://localhost:34197/jars/com.esotericsoftware_kryo-4.0.2.jar with timestamp 1613523258442
21/02/17 00:54:23 INFO Utils: Fetching spark://localhost:34197/jars/com.esotericsoftware_kryo-4.0.2.jar to /tmp/spark-61c9bedd-e134-422c-be6d-73a272e20777/userFiles-024991e3-5278-4d40-99af-3b3e3bee74f3/fetchFileTemp184623580280251328.tmp
21/02/17 00:54:23 INFO Executor: Adding file:/tmp/spark-61c9bedd-e134-422c-be6d-73a272e20777/userFiles-024991e3-5278-4d40-99af-3b3e3bee74f3/com.esotericsoftware_kryo-4.0.2.jar to class loader
21/02/17 00:54:23 INFO Executor: Fetching spark://localhost:34197/jars/com.typesafe_config-1.3.3.jar with timestamp 1613523258442
21/02/17 00:54:23 INFO Utils: Fetching spark://localhost:34197/jars/com.typesafe_config-1.3.3.jar to /tmp/spark-61c9bedd-e134-422c-be6d-73a272e20777/userFiles-024991e3-5278-4d40-99af-3b3e3bee74f3/fetchFileTemp7798361673052998479.tmp
21/02/17 00:54:23 INFO Executor: Adding file:/tmp/spark-61c9bedd-e134-422c-be6d-73a272e20777/userFiles-024991e3-5278-4d40-99af-3b3e3bee74f3/com.typesafe_config-1.3.3.jar to class loader
21/02/17 00:54:23 INFO Executor: Fetching spark://localhost:34197/jars/org.scala-lang.modules_scala-xml_2.12-1.0.6.jar with timestamp 1613523258442
21/02/17 00:54:23 INFO Utils: Fetching spark://localhost:34197/jars/org.scala-lang.modules_scala-xml_2.12-1.0.6.jar to /tmp/spark-61c9bedd-e134-422c-be6d-73a272e20777/userFiles-024991e3-5278-4d40-99af-3b3e3bee74f3/fetchFileTemp6481130757084822975.tmp
21/02/17 00:54:23 INFO Executor: Adding file:/tmp/spark-61c9bedd-e134-422c-be6d-73a272e20777/userFiles-024991e3-5278-4d40-99af-3b3e3bee74f3/org.scala-lang.modules_scala-xml_2.12-1.0.6.jar to class loader
21/02/17 00:54:23 INFO Executor: Fetching spark://localhost:34197/jars/org.scala-lang_scala-reflect-2.12.8.jar with timestamp 1613523258442
21/02/17 00:54:23 INFO Utils: Fetching spark://localhost:34197/jars/org.scala-lang_scala-reflect-2.12.8.jar to /tmp/spark-61c9bedd-e134-422c-be6d-73a272e20777/userFiles-024991e3-5278-4d40-99af-3b3e3bee74f3/fetchFileTemp2406130723313631555.tmp
21/02/17 00:54:23 INFO Executor: Adding file:/tmp/spark-61c9bedd-e134-422c-be6d-73a272e20777/userFiles-024991e3-5278-4d40-99af-3b3e3bee74f3/org.scala-lang_scala-reflect-2.12.8.jar to class loader
21/02/17 00:54:23 INFO Executor: Fetching spark://localhost:34197/jars/ml.dmlc_xgboost4j-spark_2.12-1.3.1.jar with timestamp 1613523258442
21/02/17 00:54:23 INFO Utils: Fetching spark://localhost:34197/jars/ml.dmlc_xgboost4j-spark_2.12-1.3.1.jar to /tmp/spark-61c9bedd-e134-422c-be6d-73a272e20777/userFiles-024991e3-5278-4d40-99af-3b3e3bee74f3/fetchFileTemp8064602861483816579.tmp
21/02/17 00:54:23 INFO Executor: Adding file:/tmp/spark-61c9bedd-e134-422c-be6d-73a272e20777/userFiles-024991e3-5278-4d40-99af-3b3e3bee74f3/ml.dmlc_xgboost4j-spark_2.12-1.3.1.jar to class loader
21/02/17 00:54:23 INFO Executor: Fetching spark://localhost:34197/jars/org.scala-lang_scala-compiler-2.12.8.jar with timestamp 1613523258442
21/02/17 00:54:23 INFO Utils: Fetching spark://localhost:34197/jars/org.scala-lang_scala-compiler-2.12.8.jar to /tmp/spark-61c9bedd-e134-422c-be6d-73a272e20777/userFiles-024991e3-5278-4d40-99af-3b3e3bee74f3/fetchFileTemp2229099977906131885.tmp
21/02/17 00:54:23 INFO Executor: Adding file:/tmp/spark-61c9bedd-e134-422c-be6d-73a272e20777/userFiles-024991e3-5278-4d40-99af-3b3e3bee74f3/org.scala-lang_scala-compiler-2.12.8.jar to class loader
21/02/17 00:54:23 INFO Executor: Fetching spark://localhost:34197/jars/org.ow2.asm_asm-5.0.4.jar with timestamp 1613523258443
21/02/17 00:54:23 INFO Utils: Fetching spark://localhost:34197/jars/org.ow2.asm_asm-5.0.4.jar to /tmp/spark-61c9bedd-e134-422c-be6d-73a272e20777/userFiles-024991e3-5278-4d40-99af-3b3e3bee74f3/fetchFileTemp4209483324069565761.tmp
21/02/17 00:54:23 INFO Executor: Adding file:/tmp/spark-61c9bedd-e134-422c-be6d-73a272e20777/userFiles-024991e3-5278-4d40-99af-3b3e3bee74f3/org.ow2.asm_asm-5.0.4.jar to class loader
21/02/17 00:54:24 INFO CodeGenerator: Code generated in 142.44283 ms
21/02/17 00:54:24 INFO Executor: Finished task 0.0 in stage 0.0 (TID 0). 970 bytes result sent to driver
21/02/17 00:54:24 INFO TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in 414 ms on localhost (executor driver) (1/1)
21/02/17 00:54:24 INFO TaskSchedulerImpl: Removed TaskSet 0.0, whose tasks have all completed, from pool 
21/02/17 00:54:24 INFO DAGScheduler: ResultStage 0 (collect at utils.scala:61) finished in 0.592 s
21/02/17 00:54:24 INFO DAGScheduler: Job 0 finished: collect at utils.scala:61, took 0.626739 s
21/02/17 00:54:24 INFO CodeGenerator: Code generated in 8.759584 ms
21/02/17 00:54:24 INFO CodeGenerator: Code generated in 14.531366 ms
21/02/17 00:54:24 INFO SparkContext: Starting job: collect at utils.scala:135
21/02/17 00:54:24 INFO DAGScheduler: Got job 1 (collect at utils.scala:135) with 1 output partitions
21/02/17 00:54:24 INFO DAGScheduler: Final stage: ResultStage 1 (collect at utils.scala:135)
21/02/17 00:54:24 INFO DAGScheduler: Parents of final stage: List()
21/02/17 00:54:24 INFO DAGScheduler: Missing parents: List()
21/02/17 00:54:24 INFO DAGScheduler: Submitting ResultStage 1 (MapPartitionsRDD[9] at collect at utils.scala:135), which has no missing parents
21/02/17 00:54:24 INFO MemoryStore: Block broadcast_1 stored as values in memory (estimated size 6.4 KB, free 912.3 MB)
21/02/17 00:54:24 INFO MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 3.2 KB, free 912.3 MB)
21/02/17 00:54:24 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on localhost:37741 (size: 3.2 KB, free: 912.3 MB)
21/02/17 00:54:24 INFO SparkContext: Created broadcast 1 from broadcast at DAGScheduler.scala:1039
21/02/17 00:54:24 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 1 (MapPartitionsRDD[9] at collect at utils.scala:135) (first 15 tasks are for partitions Vector(0))
21/02/17 00:54:24 INFO TaskSchedulerImpl: Adding task set 1.0 with 1 tasks
21/02/17 00:54:24 INFO TaskSetManager: Starting task 0.0 in stage 1.0 (TID 1, localhost, executor driver, partition 0, PROCESS_LOCAL, 8067 bytes)
21/02/17 00:54:24 INFO Executor: Running task 0.0 in stage 1.0 (TID 1)
21/02/17 00:54:24 INFO CodeGenerator: Code generated in 6.329174 ms
21/02/17 00:54:24 INFO Executor: Finished task 0.0 in stage 1.0 (TID 1). 1329 bytes result sent to driver
21/02/17 00:54:24 INFO TaskSetManager: Finished task 0.0 in stage 1.0 (TID 1) in 22 ms on localhost (executor driver) (1/1)
21/02/17 00:54:24 INFO TaskSchedulerImpl: Removed TaskSet 1.0, whose tasks have all completed, from pool 
21/02/17 00:54:24 INFO DAGScheduler: ResultStage 1 (collect at utils.scala:135) finished in 0.030 s
21/02/17 00:54:24 INFO DAGScheduler: Job 1 finished: collect at utils.scala:135, took 0.032720 s
21/02/17 00:54:24 INFO CodeGenerator: Code generated in 17.465809 ms
21/02/17 00:54:24 INFO CodeGenerator: Code generated in 14.748616 ms
21/02/17 00:54:24 INFO SparkContext: Starting job: count at utils.scala:135
21/02/17 00:54:24 INFO DAGScheduler: Registering RDD 12 (count at utils.scala:135)
21/02/17 00:54:24 INFO DAGScheduler: Got job 2 (count at utils.scala:135) with 1 output partitions
21/02/17 00:54:24 INFO DAGScheduler: Final stage: ResultStage 3 (count at utils.scala:135)
21/02/17 00:54:24 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 2)
21/02/17 00:54:24 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 2)
21/02/17 00:54:24 INFO DAGScheduler: Submitting ShuffleMapStage 2 (MapPartitionsRDD[12] at count at utils.scala:135), which has no missing parents
21/02/17 00:54:24 INFO MemoryStore: Block broadcast_2 stored as values in memory (estimated size 8.9 KB, free 912.3 MB)
21/02/17 00:54:24 INFO MemoryStore: Block broadcast_2_piece0 stored as bytes in memory (estimated size 4.5 KB, free 912.3 MB)
21/02/17 00:54:24 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on localhost:37741 (size: 4.5 KB, free: 912.3 MB)
21/02/17 00:54:24 INFO SparkContext: Created broadcast 2 from broadcast at DAGScheduler.scala:1039
21/02/17 00:54:24 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 2 (MapPartitionsRDD[12] at count at utils.scala:135) (first 15 tasks are for partitions Vector(0))
21/02/17 00:54:24 INFO TaskSchedulerImpl: Adding task set 2.0 with 1 tasks
21/02/17 00:54:24 INFO TaskSetManager: Starting task 0.0 in stage 2.0 (TID 2, localhost, executor driver, partition 0, PROCESS_LOCAL, 8056 bytes)
21/02/17 00:54:24 INFO Executor: Running task 0.0 in stage 2.0 (TID 2)
21/02/17 00:54:24 INFO Executor: Finished task 0.0 in stage 2.0 (TID 2). 1542 bytes result sent to driver
21/02/17 00:54:24 INFO TaskSetManager: Finished task 0.0 in stage 2.0 (TID 2) in 37 ms on localhost (executor driver) (1/1)
21/02/17 00:54:24 INFO TaskSchedulerImpl: Removed TaskSet 2.0, whose tasks have all completed, from pool 
21/02/17 00:54:24 INFO DAGScheduler: ShuffleMapStage 2 (count at utils.scala:135) finished in 0.050 s
21/02/17 00:54:24 INFO DAGScheduler: looking for newly runnable stages
21/02/17 00:54:24 INFO DAGScheduler: running: Set()
21/02/17 00:54:24 INFO DAGScheduler: waiting: Set(ResultStage 3)
21/02/17 00:54:24 INFO DAGScheduler: failed: Set()
21/02/17 00:54:24 INFO DAGScheduler: Submitting ResultStage 3 (MapPartitionsRDD[15] at count at utils.scala:135), which has no missing parents
21/02/17 00:54:24 INFO MemoryStore: Block broadcast_3 stored as values in memory (estimated size 7.3 KB, free 912.3 MB)
21/02/17 00:54:24 INFO MemoryStore: Block broadcast_3_piece0 stored as bytes in memory (estimated size 3.8 KB, free 912.3 MB)
21/02/17 00:54:24 INFO BlockManagerInfo: Added broadcast_3_piece0 in memory on localhost:37741 (size: 3.8 KB, free: 912.3 MB)
21/02/17 00:54:24 INFO SparkContext: Created broadcast 3 from broadcast at DAGScheduler.scala:1039
21/02/17 00:54:24 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 3 (MapPartitionsRDD[15] at count at utils.scala:135) (first 15 tasks are for partitions Vector(0))
21/02/17 00:54:24 INFO TaskSchedulerImpl: Adding task set 3.0 with 1 tasks
21/02/17 00:54:24 INFO TaskSetManager: Starting task 0.0 in stage 3.0 (TID 3, localhost, executor driver, partition 0, NODE_LOCAL, 7754 bytes)
21/02/17 00:54:24 INFO Executor: Running task 0.0 in stage 3.0 (TID 3)
21/02/17 00:54:24 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
21/02/17 00:54:24 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 4 ms
21/02/17 00:54:24 INFO Executor: Finished task 0.0 in stage 3.0 (TID 3). 1782 bytes result sent to driver
21/02/17 00:54:24 INFO TaskSetManager: Finished task 0.0 in stage 3.0 (TID 3) in 33 ms on localhost (executor driver) (1/1)
21/02/17 00:54:24 INFO TaskSchedulerImpl: Removed TaskSet 3.0, whose tasks have all completed, from pool 
21/02/17 00:54:24 INFO DAGScheduler: ResultStage 3 (count at utils.scala:135) finished in 0.042 s
21/02/17 00:54:24 INFO DAGScheduler: Job 2 finished: count at utils.scala:135, took 0.110577 s
21/02/17 00:54:25 INFO SparkContext: Starting job: collect at utils.scala:135
21/02/17 00:54:25 INFO DAGScheduler: Got job 3 (collect at utils.scala:135) with 1 output partitions
21/02/17 00:54:25 INFO DAGScheduler: Final stage: ResultStage 4 (collect at utils.scala:135)
21/02/17 00:54:25 INFO DAGScheduler: Parents of final stage: List()
21/02/17 00:54:25 INFO DAGScheduler: Missing parents: List()
21/02/17 00:54:25 INFO DAGScheduler: Submitting ResultStage 4 (MapPartitionsRDD[20] at collect at utils.scala:135), which has no missing parents
21/02/17 00:54:25 INFO MemoryStore: Block broadcast_4 stored as values in memory (estimated size 6.4 KB, free 912.3 MB)
21/02/17 00:54:25 INFO MemoryStore: Block broadcast_4_piece0 stored as bytes in memory (estimated size 3.2 KB, free 912.2 MB)
21/02/17 00:54:25 INFO BlockManagerInfo: Added broadcast_4_piece0 in memory on localhost:37741 (size: 3.2 KB, free: 912.3 MB)
21/02/17 00:54:25 INFO SparkContext: Created broadcast 4 from broadcast at DAGScheduler.scala:1039
21/02/17 00:54:25 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 4 (MapPartitionsRDD[20] at collect at utils.scala:135) (first 15 tasks are for partitions Vector(0))
21/02/17 00:54:25 INFO TaskSchedulerImpl: Adding task set 4.0 with 1 tasks
21/02/17 00:54:25 INFO TaskSetManager: Starting task 0.0 in stage 4.0 (TID 4, localhost, executor driver, partition 0, PROCESS_LOCAL, 8067 bytes)
21/02/17 00:54:25 INFO Executor: Running task 0.0 in stage 4.0 (TID 4)
21/02/17 00:54:25 INFO Executor: Finished task 0.0 in stage 4.0 (TID 4). 1286 bytes result sent to driver
21/02/17 00:54:25 INFO TaskSetManager: Finished task 0.0 in stage 4.0 (TID 4) in 4 ms on localhost (executor driver) (1/1)
21/02/17 00:54:25 INFO TaskSchedulerImpl: Removed TaskSet 4.0, whose tasks have all completed, from pool 
21/02/17 00:54:25 INFO DAGScheduler: ResultStage 4 (collect at utils.scala:135) finished in 0.008 s
21/02/17 00:54:25 INFO DAGScheduler: Job 3 finished: collect at utils.scala:135, took 0.010112 s
21/02/17 00:54:25 INFO SparkContext: Starting job: count at utils.scala:135
21/02/17 00:54:25 INFO DAGScheduler: Registering RDD 23 (count at utils.scala:135)
21/02/17 00:54:25 INFO DAGScheduler: Got job 4 (count at utils.scala:135) with 1 output partitions
21/02/17 00:54:25 INFO DAGScheduler: Final stage: ResultStage 6 (count at utils.scala:135)
21/02/17 00:54:25 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 5)
21/02/17 00:54:25 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 5)
21/02/17 00:54:25 INFO DAGScheduler: Submitting ShuffleMapStage 5 (MapPartitionsRDD[23] at count at utils.scala:135), which has no missing parents
21/02/17 00:54:25 INFO MemoryStore: Block broadcast_5 stored as values in memory (estimated size 8.9 KB, free 912.2 MB)
21/02/17 00:54:25 INFO MemoryStore: Block broadcast_5_piece0 stored as bytes in memory (estimated size 4.5 KB, free 912.2 MB)
21/02/17 00:54:25 INFO BlockManagerInfo: Added broadcast_5_piece0 in memory on localhost:37741 (size: 4.5 KB, free: 912.3 MB)
21/02/17 00:54:25 INFO SparkContext: Created broadcast 5 from broadcast at DAGScheduler.scala:1039
21/02/17 00:54:25 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 5 (MapPartitionsRDD[23] at count at utils.scala:135) (first 15 tasks are for partitions Vector(0))
21/02/17 00:54:25 INFO TaskSchedulerImpl: Adding task set 5.0 with 1 tasks
21/02/17 00:54:25 INFO TaskSetManager: Starting task 0.0 in stage 5.0 (TID 5, localhost, executor driver, partition 0, PROCESS_LOCAL, 8056 bytes)
21/02/17 00:54:25 INFO Executor: Running task 0.0 in stage 5.0 (TID 5)
21/02/17 00:54:25 INFO Executor: Finished task 0.0 in stage 5.0 (TID 5). 1499 bytes result sent to driver
21/02/17 00:54:25 INFO TaskSetManager: Finished task 0.0 in stage 5.0 (TID 5) in 5 ms on localhost (executor driver) (1/1)
21/02/17 00:54:25 INFO TaskSchedulerImpl: Removed TaskSet 5.0, whose tasks have all completed, from pool 
21/02/17 00:54:25 INFO DAGScheduler: ShuffleMapStage 5 (count at utils.scala:135) finished in 0.012 s
21/02/17 00:54:25 INFO DAGScheduler: looking for newly runnable stages
21/02/17 00:54:25 INFO DAGScheduler: running: Set()
21/02/17 00:54:25 INFO DAGScheduler: waiting: Set(ResultStage 6)
21/02/17 00:54:25 INFO DAGScheduler: failed: Set()
21/02/17 00:54:25 INFO DAGScheduler: Submitting ResultStage 6 (MapPartitionsRDD[26] at count at utils.scala:135), which has no missing parents
21/02/17 00:54:25 INFO MemoryStore: Block broadcast_6 stored as values in memory (estimated size 7.3 KB, free 912.2 MB)
21/02/17 00:54:25 INFO MemoryStore: Block broadcast_6_piece0 stored as bytes in memory (estimated size 3.8 KB, free 912.2 MB)
21/02/17 00:54:25 INFO BlockManagerInfo: Added broadcast_6_piece0 in memory on localhost:37741 (size: 3.8 KB, free: 912.3 MB)
21/02/17 00:54:25 INFO SparkContext: Created broadcast 6 from broadcast at DAGScheduler.scala:1039
21/02/17 00:54:25 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 6 (MapPartitionsRDD[26] at count at utils.scala:135) (first 15 tasks are for partitions Vector(0))
21/02/17 00:54:25 INFO TaskSchedulerImpl: Adding task set 6.0 with 1 tasks
21/02/17 00:54:25 INFO TaskSetManager: Starting task 0.0 in stage 6.0 (TID 6, localhost, executor driver, partition 0, NODE_LOCAL, 7754 bytes)
21/02/17 00:54:25 INFO Executor: Running task 0.0 in stage 6.0 (TID 6)
21/02/17 00:54:25 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
21/02/17 00:54:25 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
21/02/17 00:54:25 INFO Executor: Finished task 0.0 in stage 6.0 (TID 6). 1782 bytes result sent to driver
21/02/17 00:54:25 INFO TaskSetManager: Finished task 0.0 in stage 6.0 (TID 6) in 4 ms on localhost (executor driver) (1/1)
21/02/17 00:54:25 INFO TaskSchedulerImpl: Removed TaskSet 6.0, whose tasks have all completed, from pool 
21/02/17 00:54:25 INFO DAGScheduler: ResultStage 6 (count at utils.scala:135) finished in 0.009 s
21/02/17 00:54:25 INFO DAGScheduler: Job 4 finished: count at utils.scala:135, took 0.024407 s
21/02/17 00:54:26 INFO SparkContext: Invoking stop() from shutdown hook
21/02/17 00:54:26 INFO ContextCleaner: Cleaned accumulator 207
21/02/17 00:54:26 INFO ContextCleaner: Cleaned accumulator 168
21/02/17 00:54:26 INFO ContextCleaner: Cleaned accumulator 184
21/02/17 00:54:26 INFO ContextCleaner: Cleaned accumulator 34
21/02/17 00:54:26 INFO ContextCleaner: Cleaned accumulator 117
21/02/17 00:54:26 INFO ContextCleaner: Cleaned accumulator 60
21/02/17 00:54:26 INFO ContextCleaner: Cleaned accumulator 159
21/02/17 00:54:26 INFO ContextCleaner: Cleaned accumulator 143
21/02/17 00:54:26 INFO ContextCleaner: Cleaned accumulator 44
21/02/17 00:54:26 INFO ContextCleaner: Cleaned accumulator 155
21/02/17 00:54:26 INFO ContextCleaner: Cleaned accumulator 68
21/02/17 00:54:26 INFO ContextCleaner: Cleaned accumulator 81
21/02/17 00:54:26 INFO ContextCleaner: Cleaned accumulator 40
21/02/17 00:54:26 INFO ContextCleaner: Cleaned accumulator 82
21/02/17 00:54:26 INFO ContextCleaner: Cleaned accumulator 57
21/02/17 00:54:26 INFO ContextCleaner: Cleaned accumulator 90
21/02/17 00:54:26 INFO ContextCleaner: Cleaned accumulator 37
21/02/17 00:54:26 INFO ContextCleaner: Cleaned accumulator 42
21/02/17 00:54:26 INFO ContextCleaner: Cleaned accumulator 89
21/02/17 00:54:26 INFO ContextCleaner: Cleaned accumulator 129
21/02/17 00:54:26 INFO ContextCleaner: Cleaned accumulator 77
21/02/17 00:54:26 INFO ContextCleaner: Cleaned accumulator 211
21/02/17 00:54:26 INFO ContextCleaner: Cleaned accumulator 38
21/02/17 00:54:26 INFO ContextCleaner: Cleaned accumulator 116
21/02/17 00:54:26 INFO ContextCleaner: Cleaned accumulator 138
21/02/17 00:54:26 INFO ContextCleaner: Cleaned accumulator 59
21/02/17 00:54:26 INFO ContextCleaner: Cleaned accumulator 126
21/02/17 00:54:26 INFO ContextCleaner: Cleaned accumulator 187
21/02/17 00:54:26 INFO ContextCleaner: Cleaned accumulator 31
21/02/17 00:54:26 INFO ContextCleaner: Cleaned accumulator 162
21/02/17 00:54:26 INFO ContextCleaner: Cleaned accumulator 86
21/02/17 00:54:26 INFO ContextCleaner: Cleaned accumulator 200
21/02/17 00:54:26 INFO SparkUI: Stopped Spark web UI at http://localhost:4040
21/02/17 00:54:26 INFO BlockManagerInfo: Removed broadcast_3_piece0 on localhost:37741 in memory (size: 3.8 KB, free: 912.3 MB)
21/02/17 00:54:26 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!
21/02/17 00:54:26 INFO MemoryStore: MemoryStore cleared
21/02/17 00:54:26 INFO BlockManager: BlockManager stopped
21/02/17 00:54:26 INFO BlockManagerMaster: BlockManagerMaster stopped
21/02/17 00:54:26 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!
21/02/17 00:54:26 INFO SparkContext: Successfully stopped SparkContext
21/02/17 00:54:26 INFO ShutdownHookManager: Shutdown hook called
21/02/17 00:54:26 INFO ShutdownHookManager: Deleting directory /tmp/spark-61c9bedd-e134-422c-be6d-73a272e20777
21/02/17 00:54:26 INFO ShutdownHookManager: Deleting directory /tmp/spark-0b947613-9115-4879-8547-95a59e22f16d
21/02/17 01:03:21 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
21/02/17 01:03:21 INFO SecurityManager: Changing view acls to: yitaoli
21/02/17 01:03:21 INFO SecurityManager: Changing modify acls to: yitaoli
21/02/17 01:03:21 INFO SecurityManager: Changing view acls groups to: 
21/02/17 01:03:21 INFO SecurityManager: Changing modify acls groups to: 
21/02/17 01:03:21 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(yitaoli); groups with view permissions: Set(); users  with modify permissions: Set(yitaoli); groups with modify permissions: Set()
21/02/17 01:03:21 INFO HiveConf: Found configuration file file:/home/yitaoli/spark/spark-3.0.0-bin-hadoop3.2/conf/hive-site.xml
21/02/17 01:03:22 INFO SparkContext: Running Spark version 3.0.0
21/02/17 01:03:22 INFO ResourceUtils: ==============================================================
21/02/17 01:03:22 INFO ResourceUtils: Resources for spark.driver:

21/02/17 01:03:22 INFO ResourceUtils: ==============================================================
21/02/17 01:03:22 INFO SparkContext: Submitted application: sparklyr
21/02/17 01:03:22 INFO SecurityManager: Changing view acls to: yitaoli
21/02/17 01:03:22 INFO SecurityManager: Changing modify acls to: yitaoli
21/02/17 01:03:22 INFO SecurityManager: Changing view acls groups to: 
21/02/17 01:03:22 INFO SecurityManager: Changing modify acls groups to: 
21/02/17 01:03:22 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(yitaoli); groups with view permissions: Set(); users  with modify permissions: Set(yitaoli); groups with modify permissions: Set()
21/02/17 01:03:22 INFO Utils: Successfully started service 'sparkDriver' on port 39295.
21/02/17 01:03:22 INFO SparkEnv: Registering MapOutputTracker
21/02/17 01:03:22 INFO SparkEnv: Registering BlockManagerMaster
21/02/17 01:03:22 INFO BlockManagerMasterEndpoint: Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
21/02/17 01:03:22 INFO BlockManagerMasterEndpoint: BlockManagerMasterEndpoint up
21/02/17 01:03:22 INFO SparkEnv: Registering BlockManagerMasterHeartbeat
21/02/17 01:03:22 INFO DiskBlockManager: Created local directory at /tmp/blockmgr-719327c1-0306-4c54-a0c0-921da9cd5aa4
21/02/17 01:03:22 INFO MemoryStore: MemoryStore started with capacity 912.3 MiB
21/02/17 01:03:22 INFO SparkEnv: Registering OutputCommitCoordinator
21/02/17 01:03:22 INFO Utils: Successfully started service 'SparkUI' on port 4040.
21/02/17 01:03:22 INFO SparkUI: Bound SparkUI to 127.0.0.1, and started at http://localhost:4040
21/02/17 01:03:22 INFO SparkContext: Added JAR file:///home/yitaoli/.ivy2/jars/ml.dmlc_xgboost4j-spark_2.12-1.3.1.jar at spark://localhost:39295/jars/ml.dmlc_xgboost4j-spark_2.12-1.3.1.jar with timestamp 1613523802630
21/02/17 01:03:22 INFO SparkContext: Added JAR file:///home/yitaoli/.ivy2/jars/ml.dmlc_xgboost4j_2.12-1.3.1.jar at spark://localhost:39295/jars/ml.dmlc_xgboost4j_2.12-1.3.1.jar with timestamp 1613523802630
21/02/17 01:03:22 INFO SparkContext: Added JAR file:///home/yitaoli/.ivy2/jars/com.esotericsoftware_kryo-4.0.2.jar at spark://localhost:39295/jars/com.esotericsoftware_kryo-4.0.2.jar with timestamp 1613523802630
21/02/17 01:03:22 INFO SparkContext: Added JAR file:///home/yitaoli/.ivy2/jars/org.scala-lang_scala-compiler-2.12.8.jar at spark://localhost:39295/jars/org.scala-lang_scala-compiler-2.12.8.jar with timestamp 1613523802630
21/02/17 01:03:22 INFO SparkContext: Added JAR file:///home/yitaoli/.ivy2/jars/org.scala-lang_scala-reflect-2.12.8.jar at spark://localhost:39295/jars/org.scala-lang_scala-reflect-2.12.8.jar with timestamp 1613523802630
21/02/17 01:03:22 INFO SparkContext: Added JAR file:///home/yitaoli/.ivy2/jars/commons-logging_commons-logging-1.2.jar at spark://localhost:39295/jars/commons-logging_commons-logging-1.2.jar with timestamp 1613523802631
21/02/17 01:03:22 INFO SparkContext: Added JAR file:///home/yitaoli/.ivy2/jars/com.typesafe.akka_akka-actor_2.12-2.5.23.jar at spark://localhost:39295/jars/com.typesafe.akka_akka-actor_2.12-2.5.23.jar with timestamp 1613523802631
21/02/17 01:03:22 INFO SparkContext: Added JAR file:///home/yitaoli/.ivy2/jars/org.scalatest_scalatest_2.12-3.0.5.jar at spark://localhost:39295/jars/org.scalatest_scalatest_2.12-3.0.5.jar with timestamp 1613523802631
21/02/17 01:03:22 INFO SparkContext: Added JAR file:///home/yitaoli/.ivy2/jars/com.typesafe_config-1.3.3.jar at spark://localhost:39295/jars/com.typesafe_config-1.3.3.jar with timestamp 1613523802631
21/02/17 01:03:22 INFO SparkContext: Added JAR file:///home/yitaoli/.ivy2/jars/org.scala-lang.modules_scala-java8-compat_2.12-0.8.0.jar at spark://localhost:39295/jars/org.scala-lang.modules_scala-java8-compat_2.12-0.8.0.jar with timestamp 1613523802631
21/02/17 01:03:22 INFO SparkContext: Added JAR file:///home/yitaoli/.ivy2/jars/org.scalactic_scalactic_2.12-3.0.5.jar at spark://localhost:39295/jars/org.scalactic_scalactic_2.12-3.0.5.jar with timestamp 1613523802631
21/02/17 01:03:22 INFO SparkContext: Added JAR file:///home/yitaoli/.ivy2/jars/org.scala-lang.modules_scala-xml_2.12-1.0.6.jar at spark://localhost:39295/jars/org.scala-lang.modules_scala-xml_2.12-1.0.6.jar with timestamp 1613523802631
21/02/17 01:03:22 INFO SparkContext: Added JAR file:///home/yitaoli/.ivy2/jars/com.esotericsoftware_reflectasm-1.11.3.jar at spark://localhost:39295/jars/com.esotericsoftware_reflectasm-1.11.3.jar with timestamp 1613523802631
21/02/17 01:03:22 INFO SparkContext: Added JAR file:///home/yitaoli/.ivy2/jars/com.esotericsoftware_minlog-1.3.0.jar at spark://localhost:39295/jars/com.esotericsoftware_minlog-1.3.0.jar with timestamp 1613523802631
21/02/17 01:03:22 INFO SparkContext: Added JAR file:///home/yitaoli/.ivy2/jars/org.objenesis_objenesis-2.5.1.jar at spark://localhost:39295/jars/org.objenesis_objenesis-2.5.1.jar with timestamp 1613523802631
21/02/17 01:03:22 INFO SparkContext: Added JAR file:///home/yitaoli/.ivy2/jars/org.ow2.asm_asm-5.0.4.jar at spark://localhost:39295/jars/org.ow2.asm_asm-5.0.4.jar with timestamp 1613523802632
21/02/17 01:03:22 INFO SparkContext: Added JAR file:/home/yitaoli/R/x86_64-pc-linux-gnu-library/4.0/sparklyr/java/sparklyr-3.0-2.12.jar at spark://localhost:39295/jars/sparklyr-3.0-2.12.jar with timestamp 1613523802632
21/02/17 01:03:22 INFO DiskBlockManager: Shutdown hook called
21/02/17 01:03:22 INFO ShutdownHookManager: Shutdown hook called
21/02/17 01:03:22 INFO ShutdownHookManager: Deleting directory /tmp/spark-83713c90-1a96-418c-9b83-3571c9afd48d
21/02/17 01:03:22 INFO ShutdownHookManager: Deleting directory /tmp/spark-83713c90-1a96-418c-9b83-3571c9afd48d/userFiles-26b4393c-1ffc-4dcd-989d-6f06fe15fb6f
21/02/17 01:03:22 INFO ShutdownHookManager: Deleting directory /tmp/spark-2a16fb34-6669-4d41-b69b-3712dee1960f
21/02/17 01:03:27 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
21/02/17 01:03:27 INFO SecurityManager: Changing view acls to: yitaoli
21/02/17 01:03:27 INFO SecurityManager: Changing modify acls to: yitaoli
21/02/17 01:03:27 INFO SecurityManager: Changing view acls groups to: 
21/02/17 01:03:27 INFO SecurityManager: Changing modify acls groups to: 
21/02/17 01:03:27 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(yitaoli); groups with view permissions: Set(); users  with modify permissions: Set(yitaoli); groups with modify permissions: Set()
21/02/17 01:03:28 INFO HiveConf: Found configuration file file:/home/yitaoli/spark/spark-3.0.0-bin-hadoop3.2/conf/hive-site.xml
21/02/17 01:03:28 INFO SparkContext: Running Spark version 3.0.0
21/02/17 01:03:28 INFO ResourceUtils: ==============================================================
21/02/17 01:03:28 INFO ResourceUtils: Resources for spark.driver:

21/02/17 01:03:28 INFO ResourceUtils: ==============================================================
21/02/17 01:03:28 INFO SparkContext: Submitted application: sparklyr
21/02/17 01:03:28 INFO SecurityManager: Changing view acls to: yitaoli
21/02/17 01:03:28 INFO SecurityManager: Changing modify acls to: yitaoli
21/02/17 01:03:28 INFO SecurityManager: Changing view acls groups to: 
21/02/17 01:03:28 INFO SecurityManager: Changing modify acls groups to: 
21/02/17 01:03:28 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(yitaoli); groups with view permissions: Set(); users  with modify permissions: Set(yitaoli); groups with modify permissions: Set()
21/02/17 01:03:28 INFO Utils: Successfully started service 'sparkDriver' on port 44013.
21/02/17 01:03:28 INFO SparkEnv: Registering MapOutputTracker
21/02/17 01:03:28 INFO SparkEnv: Registering BlockManagerMaster
21/02/17 01:03:28 INFO BlockManagerMasterEndpoint: Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
21/02/17 01:03:28 INFO BlockManagerMasterEndpoint: BlockManagerMasterEndpoint up
21/02/17 01:03:28 INFO SparkEnv: Registering BlockManagerMasterHeartbeat
21/02/17 01:03:28 INFO DiskBlockManager: Created local directory at /tmp/blockmgr-f31f1b72-69aa-4427-829b-5e5cc0762e75
21/02/17 01:03:28 INFO MemoryStore: MemoryStore started with capacity 912.3 MiB
21/02/17 01:03:28 INFO SparkEnv: Registering OutputCommitCoordinator
21/02/17 01:03:28 INFO Utils: Successfully started service 'SparkUI' on port 4040.
21/02/17 01:03:28 INFO SparkUI: Bound SparkUI to 127.0.0.1, and started at http://localhost:4040
21/02/17 01:03:28 INFO SparkContext: Added JAR file:///home/yitaoli/.ivy2/jars/ml.dmlc_xgboost4j-spark_2.12-1.3.1.jar at spark://localhost:44013/jars/ml.dmlc_xgboost4j-spark_2.12-1.3.1.jar with timestamp 1613523808772
21/02/17 01:03:28 INFO SparkContext: Added JAR file:///home/yitaoli/.ivy2/jars/ml.dmlc_xgboost4j_2.12-1.3.1.jar at spark://localhost:44013/jars/ml.dmlc_xgboost4j_2.12-1.3.1.jar with timestamp 1613523808773
21/02/17 01:03:28 INFO SparkContext: Added JAR file:///home/yitaoli/.ivy2/jars/com.esotericsoftware_kryo-4.0.2.jar at spark://localhost:44013/jars/com.esotericsoftware_kryo-4.0.2.jar with timestamp 1613523808773
21/02/17 01:03:28 INFO SparkContext: Added JAR file:///home/yitaoli/.ivy2/jars/org.scala-lang_scala-compiler-2.12.8.jar at spark://localhost:44013/jars/org.scala-lang_scala-compiler-2.12.8.jar with timestamp 1613523808773
21/02/17 01:03:28 INFO SparkContext: Added JAR file:///home/yitaoli/.ivy2/jars/org.scala-lang_scala-reflect-2.12.8.jar at spark://localhost:44013/jars/org.scala-lang_scala-reflect-2.12.8.jar with timestamp 1613523808773
21/02/17 01:03:28 INFO SparkContext: Added JAR file:///home/yitaoli/.ivy2/jars/commons-logging_commons-logging-1.2.jar at spark://localhost:44013/jars/commons-logging_commons-logging-1.2.jar with timestamp 1613523808773
21/02/17 01:03:28 INFO SparkContext: Added JAR file:///home/yitaoli/.ivy2/jars/com.typesafe.akka_akka-actor_2.12-2.5.23.jar at spark://localhost:44013/jars/com.typesafe.akka_akka-actor_2.12-2.5.23.jar with timestamp 1613523808773
21/02/17 01:03:28 INFO SparkContext: Added JAR file:///home/yitaoli/.ivy2/jars/org.scalatest_scalatest_2.12-3.0.5.jar at spark://localhost:44013/jars/org.scalatest_scalatest_2.12-3.0.5.jar with timestamp 1613523808773
21/02/17 01:03:28 INFO SparkContext: Added JAR file:///home/yitaoli/.ivy2/jars/com.typesafe_config-1.3.3.jar at spark://localhost:44013/jars/com.typesafe_config-1.3.3.jar with timestamp 1613523808773
21/02/17 01:03:28 INFO SparkContext: Added JAR file:///home/yitaoli/.ivy2/jars/org.scala-lang.modules_scala-java8-compat_2.12-0.8.0.jar at spark://localhost:44013/jars/org.scala-lang.modules_scala-java8-compat_2.12-0.8.0.jar with timestamp 1613523808773
21/02/17 01:03:28 INFO SparkContext: Added JAR file:///home/yitaoli/.ivy2/jars/org.scalactic_scalactic_2.12-3.0.5.jar at spark://localhost:44013/jars/org.scalactic_scalactic_2.12-3.0.5.jar with timestamp 1613523808774
21/02/17 01:03:28 INFO SparkContext: Added JAR file:///home/yitaoli/.ivy2/jars/org.scala-lang.modules_scala-xml_2.12-1.0.6.jar at spark://localhost:44013/jars/org.scala-lang.modules_scala-xml_2.12-1.0.6.jar with timestamp 1613523808774
21/02/17 01:03:28 INFO SparkContext: Added JAR file:///home/yitaoli/.ivy2/jars/com.esotericsoftware_reflectasm-1.11.3.jar at spark://localhost:44013/jars/com.esotericsoftware_reflectasm-1.11.3.jar with timestamp 1613523808774
21/02/17 01:03:28 INFO SparkContext: Added JAR file:///home/yitaoli/.ivy2/jars/com.esotericsoftware_minlog-1.3.0.jar at spark://localhost:44013/jars/com.esotericsoftware_minlog-1.3.0.jar with timestamp 1613523808774
21/02/17 01:03:28 INFO SparkContext: Added JAR file:///home/yitaoli/.ivy2/jars/org.objenesis_objenesis-2.5.1.jar at spark://localhost:44013/jars/org.objenesis_objenesis-2.5.1.jar with timestamp 1613523808774
21/02/17 01:03:28 INFO SparkContext: Added JAR file:///home/yitaoli/.ivy2/jars/org.ow2.asm_asm-5.0.4.jar at spark://localhost:44013/jars/org.ow2.asm_asm-5.0.4.jar with timestamp 1613523808774
21/02/17 01:03:28 INFO SparkContext: Added JAR file:/home/yitaoli/R/x86_64-pc-linux-gnu-library/4.0/sparklyr/java/sparklyr-3.0-2.12.jar at spark://localhost:44013/jars/sparklyr-3.0-2.12.jar with timestamp 1613523808774
21/02/17 01:03:28 INFO Executor: Starting executor ID driver on host localhost
21/02/17 01:03:28 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 37167.
21/02/17 01:03:28 INFO NettyBlockTransferService: Server created on localhost:37167
21/02/17 01:03:28 INFO BlockManager: Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
21/02/17 01:03:28 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, localhost, 37167, None)
21/02/17 01:03:28 INFO BlockManagerMasterEndpoint: Registering block manager localhost:37167 with 912.3 MiB RAM, BlockManagerId(driver, localhost, 37167, None)
21/02/17 01:03:28 INFO BlockManagerMaster: Registered BlockManager BlockManagerId(driver, localhost, 37167, None)
21/02/17 01:03:28 INFO BlockManager: Initialized BlockManager: BlockManagerId(driver, localhost, 37167, None)
21/02/17 01:03:29 INFO SharedState: loading hive config file: file:/home/yitaoli/spark/spark-3.0.0-bin-hadoop3.2/conf/hive-site.xml
21/02/17 01:03:29 INFO SharedState: Setting hive.metastore.warehouse.dir ('null') to the value of spark.sql.warehouse.dir ('file:/home/yitaoli/sparkxgb/tests/testthat/spark-warehouse').
21/02/17 01:03:29 INFO SharedState: Warehouse path is 'file:/home/yitaoli/sparkxgb/tests/testthat/spark-warehouse'.
21/02/17 01:03:31 INFO HiveUtils: Initializing HiveMetastoreConnection version 2.3.7 using Spark classes.
21/02/17 01:03:31 INFO HiveConf: Found configuration file file:/home/yitaoli/spark/spark-3.0.0-bin-hadoop3.2/conf/hive-site.xml
21/02/17 01:03:31 INFO SessionState: Created HDFS directory: /tmp/hive/yitaoli/510fdd26-77e2-4879-8cbb-96b118a6e376
21/02/17 01:03:31 INFO SessionState: Created local directory: /tmp/yitaoli/510fdd26-77e2-4879-8cbb-96b118a6e376
21/02/17 01:03:31 INFO SessionState: Created HDFS directory: /tmp/hive/yitaoli/510fdd26-77e2-4879-8cbb-96b118a6e376/_tmp_space.db
21/02/17 01:03:31 INFO HiveClientImpl: Warehouse location for Hive client (version 2.3.7) is file:/home/yitaoli/sparkxgb/tests/testthat/spark-warehouse
21/02/17 01:03:32 WARN HiveConf: HiveConf of name hive.stats.jdbc.timeout does not exist
21/02/17 01:03:32 WARN HiveConf: HiveConf of name hive.stats.retries.wait does not exist
21/02/17 01:03:32 INFO HiveMetaStore: 0: Opening raw store with implementation class:org.apache.hadoop.hive.metastore.ObjectStore
21/02/17 01:03:32 INFO ObjectStore: ObjectStore, initialize called
21/02/17 01:03:32 INFO Persistence: Property hive.metastore.integral.jdo.pushdown unknown - will be ignored
21/02/17 01:03:32 INFO Persistence: Property datanucleus.cache.level2 unknown - will be ignored
21/02/17 01:03:33 INFO ObjectStore: Setting MetaStore object pin classes with hive.metastore.cache.pinobjtypes="Table,StorageDescriptor,SerDeInfo,Partition,Database,Type,FieldSchema,Order"
21/02/17 01:03:34 INFO MetaStoreDirectSql: Using direct SQL, underlying DB is DERBY
21/02/17 01:03:34 INFO ObjectStore: Initialized ObjectStore
21/02/17 01:03:34 WARN ObjectStore: Version information not found in metastore. hive.metastore.schema.verification is not enabled so recording the schema version 2.3.0
21/02/17 01:03:34 WARN ObjectStore: setMetaStoreSchemaVersion called but recording version is disabled: version = 2.3.0, comment = Set by MetaStore yitaoli@127.0.1.1
21/02/17 01:03:34 WARN ObjectStore: Failed to get database default, returning NoSuchObjectException
21/02/17 01:03:34 INFO HiveMetaStore: Added admin role in metastore
21/02/17 01:03:34 INFO HiveMetaStore: Added public role in metastore
21/02/17 01:03:34 INFO HiveMetaStore: No user is added in admin role, since config is empty
21/02/17 01:03:35 INFO HiveMetaStore: 0: get_all_functions
21/02/17 01:03:35 INFO audit: ugi=yitaoli	ip=unknown-ip-addr	cmd=get_all_functions	
21/02/17 01:03:35 INFO HiveMetaStore: 0: get_database: default
21/02/17 01:03:35 INFO audit: ugi=yitaoli	ip=unknown-ip-addr	cmd=get_database: default	
21/02/17 01:03:35 INFO HiveMetaStore: 0: get_database: default
21/02/17 01:03:35 INFO audit: ugi=yitaoli	ip=unknown-ip-addr	cmd=get_database: default	
21/02/17 01:03:35 INFO HiveMetaStore: 0: get_table : db=default tbl=iris
21/02/17 01:03:35 INFO audit: ugi=yitaoli	ip=unknown-ip-addr	cmd=get_table : db=default tbl=iris	
21/02/17 01:03:35 INFO HiveMetaStore: 0: get_database: global_temp
21/02/17 01:03:35 INFO audit: ugi=yitaoli	ip=unknown-ip-addr	cmd=get_database: global_temp	
21/02/17 01:03:35 WARN ObjectStore: Failed to get database global_temp, returning NoSuchObjectException
21/02/17 01:03:35 INFO HiveMetaStore: 0: get_database: default
21/02/17 01:03:35 INFO audit: ugi=yitaoli	ip=unknown-ip-addr	cmd=get_database: default	
21/02/17 01:03:35 INFO HiveMetaStore: 0: get_database: default
21/02/17 01:03:35 INFO audit: ugi=yitaoli	ip=unknown-ip-addr	cmd=get_database: default	
21/02/17 01:03:35 INFO HiveMetaStore: 0: get_tables: db=default pat=*
21/02/17 01:03:35 INFO audit: ugi=yitaoli	ip=unknown-ip-addr	cmd=get_tables: db=default pat=*	
21/02/17 01:03:36 INFO SparkContext: Starting job: collect at utils.scala:54
21/02/17 01:03:36 INFO DAGScheduler: Job 0 finished: collect at utils.scala:54, took 0.005140 s
21/02/17 01:03:36 INFO CodeGenerator: Code generated in 184.249584 ms
21/02/17 01:03:36 INFO SparkContext: Starting job: collect at utils.scala:137
21/02/17 01:03:36 INFO DAGScheduler: Got job 1 (collect at utils.scala:137) with 1 output partitions
21/02/17 01:03:36 INFO DAGScheduler: Final stage: ResultStage 0 (collect at utils.scala:137)
21/02/17 01:03:36 INFO DAGScheduler: Parents of final stage: List()
21/02/17 01:03:36 INFO DAGScheduler: Missing parents: List()
21/02/17 01:03:36 INFO DAGScheduler: Submitting ResultStage 0 (MapPartitionsRDD[9] at collect at utils.scala:137), which has no missing parents
21/02/17 01:03:36 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 6.5 KiB, free 912.3 MiB)
21/02/17 01:03:36 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 3.2 KiB, free 912.3 MiB)
21/02/17 01:03:36 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on localhost:37167 (size: 3.2 KiB, free: 912.3 MiB)
21/02/17 01:03:36 INFO SparkContext: Created broadcast 0 from broadcast at DAGScheduler.scala:1200
21/02/17 01:03:36 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 0 (MapPartitionsRDD[9] at collect at utils.scala:137) (first 15 tasks are for partitions Vector(0))
21/02/17 01:03:36 INFO TaskSchedulerImpl: Adding task set 0.0 with 1 tasks
21/02/17 01:03:36 INFO TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0, localhost, executor driver, partition 0, PROCESS_LOCAL, 7561 bytes)
21/02/17 01:03:36 INFO Executor: Running task 0.0 in stage 0.0 (TID 0)
21/02/17 01:03:36 INFO Executor: Fetching spark://localhost:44013/jars/com.typesafe.akka_akka-actor_2.12-2.5.23.jar with timestamp 1613523808773
21/02/17 01:03:36 INFO TransportClientFactory: Successfully created connection to localhost/127.0.0.1:44013 after 14 ms (0 ms spent in bootstraps)
21/02/17 01:03:36 INFO Utils: Fetching spark://localhost:44013/jars/com.typesafe.akka_akka-actor_2.12-2.5.23.jar to /tmp/spark-7830d85d-e99e-4157-9d39-45ea74c0872e/userFiles-e1d56abb-9b5d-47c2-92e3-ee296ce450fb/fetchFileTemp1010307066720661812.tmp
21/02/17 01:03:37 INFO Executor: Adding file:/tmp/spark-7830d85d-e99e-4157-9d39-45ea74c0872e/userFiles-e1d56abb-9b5d-47c2-92e3-ee296ce450fb/com.typesafe.akka_akka-actor_2.12-2.5.23.jar to class loader
21/02/17 01:03:37 INFO Executor: Fetching spark://localhost:44013/jars/commons-logging_commons-logging-1.2.jar with timestamp 1613523808773
21/02/17 01:03:37 INFO Utils: Fetching spark://localhost:44013/jars/commons-logging_commons-logging-1.2.jar to /tmp/spark-7830d85d-e99e-4157-9d39-45ea74c0872e/userFiles-e1d56abb-9b5d-47c2-92e3-ee296ce450fb/fetchFileTemp3179521943468349119.tmp
21/02/17 01:03:37 INFO Executor: Adding file:/tmp/spark-7830d85d-e99e-4157-9d39-45ea74c0872e/userFiles-e1d56abb-9b5d-47c2-92e3-ee296ce450fb/commons-logging_commons-logging-1.2.jar to class loader
21/02/17 01:03:37 INFO Executor: Fetching spark://localhost:44013/jars/org.scala-lang.modules_scala-xml_2.12-1.0.6.jar with timestamp 1613523808774
21/02/17 01:03:37 INFO Utils: Fetching spark://localhost:44013/jars/org.scala-lang.modules_scala-xml_2.12-1.0.6.jar to /tmp/spark-7830d85d-e99e-4157-9d39-45ea74c0872e/userFiles-e1d56abb-9b5d-47c2-92e3-ee296ce450fb/fetchFileTemp8646801592032535254.tmp
21/02/17 01:03:37 INFO Executor: Adding file:/tmp/spark-7830d85d-e99e-4157-9d39-45ea74c0872e/userFiles-e1d56abb-9b5d-47c2-92e3-ee296ce450fb/org.scala-lang.modules_scala-xml_2.12-1.0.6.jar to class loader
21/02/17 01:03:37 INFO Executor: Fetching spark://localhost:44013/jars/ml.dmlc_xgboost4j-spark_2.12-1.3.1.jar with timestamp 1613523808772
21/02/17 01:03:37 INFO Utils: Fetching spark://localhost:44013/jars/ml.dmlc_xgboost4j-spark_2.12-1.3.1.jar to /tmp/spark-7830d85d-e99e-4157-9d39-45ea74c0872e/userFiles-e1d56abb-9b5d-47c2-92e3-ee296ce450fb/fetchFileTemp5347569030857005540.tmp
21/02/17 01:03:37 INFO Executor: Adding file:/tmp/spark-7830d85d-e99e-4157-9d39-45ea74c0872e/userFiles-e1d56abb-9b5d-47c2-92e3-ee296ce450fb/ml.dmlc_xgboost4j-spark_2.12-1.3.1.jar to class loader
21/02/17 01:03:37 INFO Executor: Fetching spark://localhost:44013/jars/org.ow2.asm_asm-5.0.4.jar with timestamp 1613523808774
21/02/17 01:03:37 INFO Utils: Fetching spark://localhost:44013/jars/org.ow2.asm_asm-5.0.4.jar to /tmp/spark-7830d85d-e99e-4157-9d39-45ea74c0872e/userFiles-e1d56abb-9b5d-47c2-92e3-ee296ce450fb/fetchFileTemp9075289092145408944.tmp
21/02/17 01:03:37 INFO Executor: Adding file:/tmp/spark-7830d85d-e99e-4157-9d39-45ea74c0872e/userFiles-e1d56abb-9b5d-47c2-92e3-ee296ce450fb/org.ow2.asm_asm-5.0.4.jar to class loader
21/02/17 01:03:37 INFO Executor: Fetching spark://localhost:44013/jars/org.scala-lang_scala-compiler-2.12.8.jar with timestamp 1613523808773
21/02/17 01:03:37 INFO Utils: Fetching spark://localhost:44013/jars/org.scala-lang_scala-compiler-2.12.8.jar to /tmp/spark-7830d85d-e99e-4157-9d39-45ea74c0872e/userFiles-e1d56abb-9b5d-47c2-92e3-ee296ce450fb/fetchFileTemp5315198967428658424.tmp
21/02/17 01:03:37 INFO Executor: Adding file:/tmp/spark-7830d85d-e99e-4157-9d39-45ea74c0872e/userFiles-e1d56abb-9b5d-47c2-92e3-ee296ce450fb/org.scala-lang_scala-compiler-2.12.8.jar to class loader
21/02/17 01:03:37 INFO Executor: Fetching spark://localhost:44013/jars/com.esotericsoftware_minlog-1.3.0.jar with timestamp 1613523808774
21/02/17 01:03:37 INFO Utils: Fetching spark://localhost:44013/jars/com.esotericsoftware_minlog-1.3.0.jar to /tmp/spark-7830d85d-e99e-4157-9d39-45ea74c0872e/userFiles-e1d56abb-9b5d-47c2-92e3-ee296ce450fb/fetchFileTemp6002132554312154045.tmp
21/02/17 01:03:37 INFO Executor: Adding file:/tmp/spark-7830d85d-e99e-4157-9d39-45ea74c0872e/userFiles-e1d56abb-9b5d-47c2-92e3-ee296ce450fb/com.esotericsoftware_minlog-1.3.0.jar to class loader
21/02/17 01:03:37 INFO Executor: Fetching spark://localhost:44013/jars/org.scalactic_scalactic_2.12-3.0.5.jar with timestamp 1613523808774
21/02/17 01:03:37 INFO Utils: Fetching spark://localhost:44013/jars/org.scalactic_scalactic_2.12-3.0.5.jar to /tmp/spark-7830d85d-e99e-4157-9d39-45ea74c0872e/userFiles-e1d56abb-9b5d-47c2-92e3-ee296ce450fb/fetchFileTemp6400650909006145351.tmp
21/02/17 01:03:37 INFO Executor: Adding file:/tmp/spark-7830d85d-e99e-4157-9d39-45ea74c0872e/userFiles-e1d56abb-9b5d-47c2-92e3-ee296ce450fb/org.scalactic_scalactic_2.12-3.0.5.jar to class loader
21/02/17 01:03:37 INFO Executor: Fetching spark://localhost:44013/jars/sparklyr-3.0-2.12.jar with timestamp 1613523808774
21/02/17 01:03:37 INFO Utils: Fetching spark://localhost:44013/jars/sparklyr-3.0-2.12.jar to /tmp/spark-7830d85d-e99e-4157-9d39-45ea74c0872e/userFiles-e1d56abb-9b5d-47c2-92e3-ee296ce450fb/fetchFileTemp6991207496607927166.tmp
21/02/17 01:03:37 INFO Executor: Adding file:/tmp/spark-7830d85d-e99e-4157-9d39-45ea74c0872e/userFiles-e1d56abb-9b5d-47c2-92e3-ee296ce450fb/sparklyr-3.0-2.12.jar to class loader
21/02/17 01:03:37 INFO Executor: Fetching spark://localhost:44013/jars/org.scala-lang_scala-reflect-2.12.8.jar with timestamp 1613523808773
21/02/17 01:03:37 INFO Utils: Fetching spark://localhost:44013/jars/org.scala-lang_scala-reflect-2.12.8.jar to /tmp/spark-7830d85d-e99e-4157-9d39-45ea74c0872e/userFiles-e1d56abb-9b5d-47c2-92e3-ee296ce450fb/fetchFileTemp7009804579000495072.tmp
21/02/17 01:03:37 INFO Executor: Adding file:/tmp/spark-7830d85d-e99e-4157-9d39-45ea74c0872e/userFiles-e1d56abb-9b5d-47c2-92e3-ee296ce450fb/org.scala-lang_scala-reflect-2.12.8.jar to class loader
21/02/17 01:03:37 INFO Executor: Fetching spark://localhost:44013/jars/org.scala-lang.modules_scala-java8-compat_2.12-0.8.0.jar with timestamp 1613523808773
21/02/17 01:03:37 INFO Utils: Fetching spark://localhost:44013/jars/org.scala-lang.modules_scala-java8-compat_2.12-0.8.0.jar to /tmp/spark-7830d85d-e99e-4157-9d39-45ea74c0872e/userFiles-e1d56abb-9b5d-47c2-92e3-ee296ce450fb/fetchFileTemp616694196356911553.tmp
21/02/17 01:03:37 INFO Executor: Adding file:/tmp/spark-7830d85d-e99e-4157-9d39-45ea74c0872e/userFiles-e1d56abb-9b5d-47c2-92e3-ee296ce450fb/org.scala-lang.modules_scala-java8-compat_2.12-0.8.0.jar to class loader
21/02/17 01:03:37 INFO Executor: Fetching spark://localhost:44013/jars/org.scalatest_scalatest_2.12-3.0.5.jar with timestamp 1613523808773
21/02/17 01:03:37 INFO Utils: Fetching spark://localhost:44013/jars/org.scalatest_scalatest_2.12-3.0.5.jar to /tmp/spark-7830d85d-e99e-4157-9d39-45ea74c0872e/userFiles-e1d56abb-9b5d-47c2-92e3-ee296ce450fb/fetchFileTemp3934467558437540422.tmp
21/02/17 01:03:37 INFO Executor: Adding file:/tmp/spark-7830d85d-e99e-4157-9d39-45ea74c0872e/userFiles-e1d56abb-9b5d-47c2-92e3-ee296ce450fb/org.scalatest_scalatest_2.12-3.0.5.jar to class loader
21/02/17 01:03:37 INFO Executor: Fetching spark://localhost:44013/jars/ml.dmlc_xgboost4j_2.12-1.3.1.jar with timestamp 1613523808773
21/02/17 01:03:37 INFO Utils: Fetching spark://localhost:44013/jars/ml.dmlc_xgboost4j_2.12-1.3.1.jar to /tmp/spark-7830d85d-e99e-4157-9d39-45ea74c0872e/userFiles-e1d56abb-9b5d-47c2-92e3-ee296ce450fb/fetchFileTemp7148035629879259356.tmp
21/02/17 01:03:37 INFO Executor: Adding file:/tmp/spark-7830d85d-e99e-4157-9d39-45ea74c0872e/userFiles-e1d56abb-9b5d-47c2-92e3-ee296ce450fb/ml.dmlc_xgboost4j_2.12-1.3.1.jar to class loader
21/02/17 01:03:37 INFO Executor: Fetching spark://localhost:44013/jars/com.esotericsoftware_reflectasm-1.11.3.jar with timestamp 1613523808774
21/02/17 01:03:37 INFO Utils: Fetching spark://localhost:44013/jars/com.esotericsoftware_reflectasm-1.11.3.jar to /tmp/spark-7830d85d-e99e-4157-9d39-45ea74c0872e/userFiles-e1d56abb-9b5d-47c2-92e3-ee296ce450fb/fetchFileTemp9106232333647060933.tmp
21/02/17 01:03:37 INFO Executor: Adding file:/tmp/spark-7830d85d-e99e-4157-9d39-45ea74c0872e/userFiles-e1d56abb-9b5d-47c2-92e3-ee296ce450fb/com.esotericsoftware_reflectasm-1.11.3.jar to class loader
21/02/17 01:03:37 INFO Executor: Fetching spark://localhost:44013/jars/com.typesafe_config-1.3.3.jar with timestamp 1613523808773
21/02/17 01:03:37 INFO Utils: Fetching spark://localhost:44013/jars/com.typesafe_config-1.3.3.jar to /tmp/spark-7830d85d-e99e-4157-9d39-45ea74c0872e/userFiles-e1d56abb-9b5d-47c2-92e3-ee296ce450fb/fetchFileTemp3662208297540496328.tmp
21/02/17 01:03:37 INFO Executor: Adding file:/tmp/spark-7830d85d-e99e-4157-9d39-45ea74c0872e/userFiles-e1d56abb-9b5d-47c2-92e3-ee296ce450fb/com.typesafe_config-1.3.3.jar to class loader
21/02/17 01:03:37 INFO Executor: Fetching spark://localhost:44013/jars/com.esotericsoftware_kryo-4.0.2.jar with timestamp 1613523808773
21/02/17 01:03:37 INFO Utils: Fetching spark://localhost:44013/jars/com.esotericsoftware_kryo-4.0.2.jar to /tmp/spark-7830d85d-e99e-4157-9d39-45ea74c0872e/userFiles-e1d56abb-9b5d-47c2-92e3-ee296ce450fb/fetchFileTemp4042603988949622943.tmp
21/02/17 01:03:37 INFO Executor: Adding file:/tmp/spark-7830d85d-e99e-4157-9d39-45ea74c0872e/userFiles-e1d56abb-9b5d-47c2-92e3-ee296ce450fb/com.esotericsoftware_kryo-4.0.2.jar to class loader
21/02/17 01:03:37 INFO Executor: Fetching spark://localhost:44013/jars/org.objenesis_objenesis-2.5.1.jar with timestamp 1613523808774
21/02/17 01:03:37 INFO Utils: Fetching spark://localhost:44013/jars/org.objenesis_objenesis-2.5.1.jar to /tmp/spark-7830d85d-e99e-4157-9d39-45ea74c0872e/userFiles-e1d56abb-9b5d-47c2-92e3-ee296ce450fb/fetchFileTemp8516190549360479422.tmp
21/02/17 01:03:37 INFO Executor: Adding file:/tmp/spark-7830d85d-e99e-4157-9d39-45ea74c0872e/userFiles-e1d56abb-9b5d-47c2-92e3-ee296ce450fb/org.objenesis_objenesis-2.5.1.jar to class loader
21/02/17 01:03:37 INFO Executor: Finished task 0.0 in stage 0.0 (TID 0). 1397 bytes result sent to driver
21/02/17 01:03:37 INFO TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in 450 ms on localhost (executor driver) (1/1)
21/02/17 01:03:37 INFO TaskSchedulerImpl: Removed TaskSet 0.0, whose tasks have all completed, from pool 
21/02/17 01:03:37 INFO DAGScheduler: ResultStage 0 (collect at utils.scala:137) finished in 0.568 s
21/02/17 01:03:37 INFO DAGScheduler: Job 1 is finished. Cancelling potential speculative or zombie tasks for this job
21/02/17 01:03:37 INFO TaskSchedulerImpl: Killing all running tasks in stage 0: Stage finished
21/02/17 01:03:37 INFO DAGScheduler: Job 1 finished: collect at utils.scala:137, took 0.595428 s
21/02/17 01:03:37 INFO CodeGenerator: Code generated in 16.02165 ms
21/02/17 01:03:37 INFO CodeGenerator: Code generated in 15.809545 ms
21/02/17 01:03:37 INFO CodeGenerator: Code generated in 13.436391 ms
21/02/17 01:03:37 INFO SparkContext: Starting job: count at utils.scala:135
21/02/17 01:03:37 INFO DAGScheduler: Registering RDD 11 (count at utils.scala:135) as input to shuffle 0
21/02/17 01:03:37 INFO DAGScheduler: Got job 2 (count at utils.scala:135) with 1 output partitions
21/02/17 01:03:37 INFO DAGScheduler: Final stage: ResultStage 2 (count at utils.scala:135)
21/02/17 01:03:37 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 1)
21/02/17 01:03:37 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 1)
21/02/17 01:03:37 INFO DAGScheduler: Submitting ShuffleMapStage 1 (MapPartitionsRDD[11] at count at utils.scala:135), which has no missing parents
21/02/17 01:03:37 INFO MemoryStore: Block broadcast_1 stored as values in memory (estimated size 10.0 KiB, free 912.3 MiB)
21/02/17 01:03:37 INFO MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 5.2 KiB, free 912.3 MiB)
21/02/17 01:03:37 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on localhost:37167 (size: 5.2 KiB, free: 912.3 MiB)
21/02/17 01:03:37 INFO SparkContext: Created broadcast 1 from broadcast at DAGScheduler.scala:1200
21/02/17 01:03:37 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 1 (MapPartitionsRDD[11] at count at utils.scala:135) (first 15 tasks are for partitions Vector(0))
21/02/17 01:03:37 INFO TaskSchedulerImpl: Adding task set 1.0 with 1 tasks
21/02/17 01:03:37 INFO TaskSetManager: Starting task 0.0 in stage 1.0 (TID 1, localhost, executor driver, partition 0, PROCESS_LOCAL, 7550 bytes)
21/02/17 01:03:37 INFO Executor: Running task 0.0 in stage 1.0 (TID 1)
21/02/17 01:03:37 INFO Executor: Finished task 0.0 in stage 1.0 (TID 1). 1833 bytes result sent to driver
21/02/17 01:03:37 INFO TaskSetManager: Finished task 0.0 in stage 1.0 (TID 1) in 41 ms on localhost (executor driver) (1/1)
21/02/17 01:03:37 INFO TaskSchedulerImpl: Removed TaskSet 1.0, whose tasks have all completed, from pool 
21/02/17 01:03:37 INFO DAGScheduler: ShuffleMapStage 1 (count at utils.scala:135) finished in 0.056 s
21/02/17 01:03:37 INFO DAGScheduler: looking for newly runnable stages
21/02/17 01:03:37 INFO DAGScheduler: running: Set()
21/02/17 01:03:37 INFO DAGScheduler: waiting: Set(ResultStage 2)
21/02/17 01:03:37 INFO DAGScheduler: failed: Set()
21/02/17 01:03:37 INFO DAGScheduler: Submitting ResultStage 2 (MapPartitionsRDD[14] at count at utils.scala:135), which has no missing parents
21/02/17 01:03:37 INFO MemoryStore: Block broadcast_2 stored as values in memory (estimated size 10.1 KiB, free 912.3 MiB)
21/02/17 01:03:37 INFO MemoryStore: Block broadcast_2_piece0 stored as bytes in memory (estimated size 5.0 KiB, free 912.3 MiB)
21/02/17 01:03:37 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on localhost:37167 (size: 5.0 KiB, free: 912.3 MiB)
21/02/17 01:03:37 INFO SparkContext: Created broadcast 2 from broadcast at DAGScheduler.scala:1200
21/02/17 01:03:37 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 2 (MapPartitionsRDD[14] at count at utils.scala:135) (first 15 tasks are for partitions Vector(0))
21/02/17 01:03:37 INFO TaskSchedulerImpl: Adding task set 2.0 with 1 tasks
21/02/17 01:03:37 INFO TaskSetManager: Starting task 0.0 in stage 2.0 (TID 2, localhost, executor driver, partition 0, NODE_LOCAL, 7325 bytes)
21/02/17 01:03:37 INFO Executor: Running task 0.0 in stage 2.0 (TID 2)
21/02/17 01:03:37 INFO ShuffleBlockFetcherIterator: Getting 1 (60.0 B) non-empty blocks including 1 (60.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
21/02/17 01:03:37 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 5 ms
21/02/17 01:03:37 INFO Executor: Finished task 0.0 in stage 2.0 (TID 2). 2648 bytes result sent to driver
21/02/17 01:03:37 INFO TaskSetManager: Finished task 0.0 in stage 2.0 (TID 2) in 35 ms on localhost (executor driver) (1/1)
21/02/17 01:03:37 INFO TaskSchedulerImpl: Removed TaskSet 2.0, whose tasks have all completed, from pool 
21/02/17 01:03:37 INFO DAGScheduler: ResultStage 2 (count at utils.scala:135) finished in 0.043 s
21/02/17 01:03:37 INFO DAGScheduler: Job 2 is finished. Cancelling potential speculative or zombie tasks for this job
21/02/17 01:03:37 INFO TaskSchedulerImpl: Killing all running tasks in stage 2: Stage finished
21/02/17 01:03:37 INFO DAGScheduler: Job 2 finished: count at utils.scala:135, took 0.118244 s
21/02/17 01:03:37 INFO BlockManagerInfo: Removed broadcast_1_piece0 on localhost:37167 in memory (size: 5.2 KiB, free: 912.3 MiB)
21/02/17 01:03:37 INFO BlockManagerInfo: Removed broadcast_0_piece0 on localhost:37167 in memory (size: 3.2 KiB, free: 912.3 MiB)
21/02/17 01:03:37 INFO BlockManagerInfo: Removed broadcast_2_piece0 on localhost:37167 in memory (size: 5.0 KiB, free: 912.3 MiB)
21/02/17 01:03:37 INFO SparkContext: Starting job: collect at utils.scala:137
21/02/17 01:03:37 INFO DAGScheduler: Got job 3 (collect at utils.scala:137) with 1 output partitions
21/02/17 01:03:37 INFO DAGScheduler: Final stage: ResultStage 3 (collect at utils.scala:137)
21/02/17 01:03:37 INFO DAGScheduler: Parents of final stage: List()
21/02/17 01:03:37 INFO DAGScheduler: Missing parents: List()
21/02/17 01:03:37 INFO DAGScheduler: Submitting ResultStage 3 (MapPartitionsRDD[16] at collect at utils.scala:137), which has no missing parents
21/02/17 01:03:37 INFO MemoryStore: Block broadcast_3 stored as values in memory (estimated size 7.2 KiB, free 912.3 MiB)
21/02/17 01:03:37 INFO MemoryStore: Block broadcast_3_piece0 stored as bytes in memory (estimated size 3.7 KiB, free 912.3 MiB)
21/02/17 01:03:37 INFO BlockManagerInfo: Added broadcast_3_piece0 in memory on localhost:37167 (size: 3.7 KiB, free: 912.3 MiB)
21/02/17 01:03:37 INFO SparkContext: Created broadcast 3 from broadcast at DAGScheduler.scala:1200
21/02/17 01:03:37 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 3 (MapPartitionsRDD[16] at collect at utils.scala:137) (first 15 tasks are for partitions Vector(0))
21/02/17 01:03:37 INFO TaskSchedulerImpl: Adding task set 3.0 with 1 tasks
21/02/17 01:03:37 INFO TaskSetManager: Starting task 0.0 in stage 3.0 (TID 3, localhost, executor driver, partition 0, PROCESS_LOCAL, 7561 bytes)
21/02/17 01:03:37 INFO Executor: Running task 0.0 in stage 3.0 (TID 3)
21/02/17 01:03:37 INFO Executor: Finished task 0.0 in stage 3.0 (TID 3). 1354 bytes result sent to driver
21/02/17 01:03:37 INFO TaskSetManager: Finished task 0.0 in stage 3.0 (TID 3) in 5 ms on localhost (executor driver) (1/1)
21/02/17 01:03:37 INFO TaskSchedulerImpl: Removed TaskSet 3.0, whose tasks have all completed, from pool 
21/02/17 01:03:37 INFO DAGScheduler: ResultStage 3 (collect at utils.scala:137) finished in 0.011 s
21/02/17 01:03:37 INFO DAGScheduler: Job 3 is finished. Cancelling potential speculative or zombie tasks for this job
21/02/17 01:03:37 INFO TaskSchedulerImpl: Killing all running tasks in stage 3: Stage finished
21/02/17 01:03:37 INFO DAGScheduler: Job 3 finished: collect at utils.scala:137, took 0.013982 s
21/02/17 01:03:38 INFO SparkContext: Starting job: count at utils.scala:135
21/02/17 01:03:38 INFO DAGScheduler: Registering RDD 18 (count at utils.scala:135) as input to shuffle 1
21/02/17 01:03:38 INFO DAGScheduler: Got job 4 (count at utils.scala:135) with 1 output partitions
21/02/17 01:03:38 INFO DAGScheduler: Final stage: ResultStage 5 (count at utils.scala:135)
21/02/17 01:03:38 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 4)
21/02/17 01:03:38 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 4)
21/02/17 01:03:38 INFO DAGScheduler: Submitting ShuffleMapStage 4 (MapPartitionsRDD[18] at count at utils.scala:135), which has no missing parents
21/02/17 01:03:38 INFO MemoryStore: Block broadcast_4 stored as values in memory (estimated size 10.0 KiB, free 912.3 MiB)
21/02/17 01:03:38 INFO MemoryStore: Block broadcast_4_piece0 stored as bytes in memory (estimated size 5.2 KiB, free 912.3 MiB)
21/02/17 01:03:38 INFO BlockManagerInfo: Added broadcast_4_piece0 in memory on localhost:37167 (size: 5.2 KiB, free: 912.3 MiB)
21/02/17 01:03:38 INFO SparkContext: Created broadcast 4 from broadcast at DAGScheduler.scala:1200
21/02/17 01:03:38 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 4 (MapPartitionsRDD[18] at count at utils.scala:135) (first 15 tasks are for partitions Vector(0))
21/02/17 01:03:38 INFO TaskSchedulerImpl: Adding task set 4.0 with 1 tasks
21/02/17 01:03:38 INFO TaskSetManager: Starting task 0.0 in stage 4.0 (TID 4, localhost, executor driver, partition 0, PROCESS_LOCAL, 7550 bytes)
21/02/17 01:03:38 INFO Executor: Running task 0.0 in stage 4.0 (TID 4)
21/02/17 01:03:38 INFO Executor: Finished task 0.0 in stage 4.0 (TID 4). 1833 bytes result sent to driver
21/02/17 01:03:38 INFO TaskSetManager: Finished task 0.0 in stage 4.0 (TID 4) in 8 ms on localhost (executor driver) (1/1)
21/02/17 01:03:38 INFO TaskSchedulerImpl: Removed TaskSet 4.0, whose tasks have all completed, from pool 
21/02/17 01:03:38 INFO DAGScheduler: ShuffleMapStage 4 (count at utils.scala:135) finished in 0.015 s
21/02/17 01:03:38 INFO DAGScheduler: looking for newly runnable stages
21/02/17 01:03:38 INFO DAGScheduler: running: Set()
21/02/17 01:03:38 INFO DAGScheduler: waiting: Set(ResultStage 5)
21/02/17 01:03:38 INFO DAGScheduler: failed: Set()
21/02/17 01:03:38 INFO DAGScheduler: Submitting ResultStage 5 (MapPartitionsRDD[21] at count at utils.scala:135), which has no missing parents
21/02/17 01:03:38 INFO MemoryStore: Block broadcast_5 stored as values in memory (estimated size 10.1 KiB, free 912.3 MiB)
21/02/17 01:03:38 INFO MemoryStore: Block broadcast_5_piece0 stored as bytes in memory (estimated size 5.0 KiB, free 912.3 MiB)
21/02/17 01:03:38 INFO BlockManagerInfo: Added broadcast_5_piece0 in memory on localhost:37167 (size: 5.0 KiB, free: 912.3 MiB)
21/02/17 01:03:38 INFO SparkContext: Created broadcast 5 from broadcast at DAGScheduler.scala:1200
21/02/17 01:03:38 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 5 (MapPartitionsRDD[21] at count at utils.scala:135) (first 15 tasks are for partitions Vector(0))
21/02/17 01:03:38 INFO TaskSchedulerImpl: Adding task set 5.0 with 1 tasks
21/02/17 01:03:38 INFO TaskSetManager: Starting task 0.0 in stage 5.0 (TID 5, localhost, executor driver, partition 0, NODE_LOCAL, 7325 bytes)
21/02/17 01:03:38 INFO Executor: Running task 0.0 in stage 5.0 (TID 5)
21/02/17 01:03:38 INFO ShuffleBlockFetcherIterator: Getting 1 (60.0 B) non-empty blocks including 1 (60.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
21/02/17 01:03:38 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
21/02/17 01:03:38 INFO Executor: Finished task 0.0 in stage 5.0 (TID 5). 2648 bytes result sent to driver
21/02/17 01:03:38 INFO TaskSetManager: Finished task 0.0 in stage 5.0 (TID 5) in 7 ms on localhost (executor driver) (1/1)
21/02/17 01:03:38 INFO TaskSchedulerImpl: Removed TaskSet 5.0, whose tasks have all completed, from pool 
21/02/17 01:03:38 INFO DAGScheduler: ResultStage 5 (count at utils.scala:135) finished in 0.013 s
21/02/17 01:03:38 INFO DAGScheduler: Job 4 is finished. Cancelling potential speculative or zombie tasks for this job
21/02/17 01:03:38 INFO TaskSchedulerImpl: Killing all running tasks in stage 5: Stage finished
21/02/17 01:03:38 INFO DAGScheduler: Job 4 finished: count at utils.scala:135, took 0.033297 s
21/02/17 01:03:38 INFO Instrumentation: [5573e5c0] training finished
21/02/17 01:03:38 INFO Instrumentation: [84e4524c] training finished
21/02/17 01:03:39 INFO CodeGenerator: Code generated in 42.487674 ms
21/02/17 01:03:39 INFO CodeGenerator: Code generated in 15.452315 ms
21/02/17 01:03:39 INFO XGBoostSpark: Running XGBoost 1.3.1 with parameters:
alpha -> 0.0
min_child_weight -> 1.0
sample_type -> uniform
base_score -> 0.5
rabit_timeout -> -1
colsample_bylevel -> 1.0
grow_policy -> depthwise
skip_drop -> 0.0
lambda_bias -> 0.0
silent -> 0
scale_pos_weight -> 1.0
seed -> 0
cache_training_set -> false
features_col -> features
num_early_stopping_rounds -> 0
label_col -> label
num_workers -> 1
subsample -> 1.0
lambda -> 1.0
max_depth -> 6
kill_spark_context_on_worker_failure -> true
tree_limit -> 0
custom_eval -> null
dmlc_worker_connect_retry -> 5
rate_drop -> 0.0
max_bin -> 16
train_test_ratio -> 1.0
use_external_memory -> false
objective -> reg:linear
eval_metric -> rmse
num_round -> 1
maximize_evaluation_metrics -> false
timeout_request_workers -> 1800000
missing -> NaN
rabit_ring_reduce_threshold -> 32768
checkpoint_path -> 
tracker_conf -> TrackerConf(0,python)
tree_method -> auto
max_delta_step -> 0.0
eta -> 0.3
verbosity -> 1
colsample_bytree -> 1.0
objective_type -> regression
normalize_type -> tree
allow_non_zero_for_missing -> false
custom_obj -> null
gamma -> 0.0
sketch_eps -> 0.03
nthread -> 1
prediction_col -> prediction
checkpoint_interval -> -1
21/02/17 01:03:39 WARN XGBoostSpark: train_test_ratio is deprecated since XGBoost 0.82, we recommend to explicitly pass a training and multiple evaluation datasets by passing 'eval_sets' and 'eval_set_names'
21/02/17 01:03:39 INFO RabitTracker$TrackerProcessLogger: 2021-02-17 01:03:39,194 INFO start listen on 192.168.2.12:9091
21/02/17 01:03:39 INFO XGBoostSpark: starting training with timeout set as 1800000 ms for waiting for resources
21/02/17 01:03:39 INFO SparkContext: Starting job: foreachPartition at XGBoost.scala:612
21/02/17 01:03:39 INFO DAGScheduler: Got job 5 (foreachPartition at XGBoost.scala:612) with 1 output partitions
21/02/17 01:03:39 INFO DAGScheduler: Final stage: ResultStage 6 (foreachPartition at XGBoost.scala:612)
21/02/17 01:03:39 INFO DAGScheduler: Parents of final stage: List()
21/02/17 01:03:39 INFO DAGScheduler: Missing parents: List()
21/02/17 01:03:39 INFO DAGScheduler: Submitting ResultStage 6 (MapPartitionsRDD[32] at mapPartitions at XGBoost.scala:493), which has no missing parents
21/02/17 01:03:39 INFO MemoryStore: Block broadcast_6 stored as values in memory (estimated size 39.8 KiB, free 912.2 MiB)
21/02/17 01:03:39 INFO MemoryStore: Block broadcast_6_piece0 stored as bytes in memory (estimated size 16.6 KiB, free 912.2 MiB)
21/02/17 01:03:39 INFO BlockManagerInfo: Added broadcast_6_piece0 in memory on localhost:37167 (size: 16.6 KiB, free: 912.3 MiB)
21/02/17 01:03:39 INFO SparkContext: Created broadcast 6 from broadcast at DAGScheduler.scala:1200
21/02/17 01:03:39 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 6 (MapPartitionsRDD[32] at mapPartitions at XGBoost.scala:493) (first 15 tasks are for partitions Vector(0))
21/02/17 01:03:39 INFO TaskSchedulerImpl: Adding task set 6.0 with 1 tasks
21/02/17 01:03:39 INFO TaskSetManager: Starting task 0.0 in stage 6.0 (TID 6, localhost, executor driver, partition 0, PROCESS_LOCAL, 18492 bytes)
21/02/17 01:03:39 INFO Executor: Running task 0.0 in stage 6.0 (TID 6)
21/02/17 01:03:39 INFO MemoryStore: Block rdd_23_0 stored as values in memory (estimated size 5.6 KiB, free 912.2 MiB)
21/02/17 01:03:39 INFO BlockManagerInfo: Added rdd_23_0 in memory on localhost:37167 (size: 5.6 KiB, free: 912.3 MiB)
21/02/17 01:03:39 INFO CodeGenerator: Code generated in 8.278032 ms
21/02/17 01:03:39 INFO CodeGenerator: Code generated in 29.517853 ms
21/02/17 01:03:39 INFO CodeGenerator: Code generated in 11.620642 ms
21/02/17 01:03:39 INFO RabitTracker$TrackerProcessLogger: /tmp/tracker5377848134096759615.py:330: DeprecationWarning: isAlive() is deprecated, use is_alive() instead
21/02/17 01:03:39 INFO RabitTracker$TrackerProcessLogger:   while self.thread.isAlive():
21/02/17 01:03:39 INFO RabitTracker$TrackerProcessLogger: 2021-02-17 01:03:39,620 DEBUG Recieve start signal from 192.168.2.12; assign rank 0
21/02/17 01:03:39 INFO RabitTracker$TrackerProcessLogger: 2021-02-17 01:03:39,620 INFO @tracker All of 1 nodes getting started
21/02/17 01:03:39 INFO RabitTracker$TrackerProcessLogger: 2021-02-17 01:03:39,630 INFO [0]	train-rmse:2.633044
21/02/17 01:03:39 INFO RabitTracker$TrackerProcessLogger: 2021-02-17 01:03:39,630 DEBUG Recieve shutdown signal from 0
21/02/17 01:03:39 INFO RabitTracker$TrackerProcessLogger: 2021-02-17 01:03:39,630 INFO @tracker All nodes finishes job
21/02/17 01:03:39 INFO RabitTracker$TrackerProcessLogger: 2021-02-17 01:03:39,631 INFO @tracker 0.010515451431274414 secs between node start and job finish
21/02/17 01:03:39 INFO MemoryStore: Block rdd_32_0 stored as values in memory (estimated size 192.0 B, free 912.2 MiB)
21/02/17 01:03:39 INFO BlockManagerInfo: Added rdd_32_0 in memory on localhost:37167 (size: 192.0 B, free: 912.3 MiB)
21/02/17 01:03:39 INFO RabitTracker: Tracker Process ends with exit code 0
21/02/17 01:03:39 INFO RabitTracker$TrackerProcessLogger: Tracker Process ends with exit code 0
21/02/17 01:03:39 INFO XGBoostSpark: Rabit returns with exit code 0
21/02/17 01:03:39 INFO Executor: 1 block locks were not released by TID = 6:
[rdd_32_0]
21/02/17 01:03:39 INFO Executor: Finished task 0.0 in stage 6.0 (TID 6). 1385 bytes result sent to driver
21/02/17 01:03:39 INFO TaskSetManager: Finished task 0.0 in stage 6.0 (TID 6) in 326 ms on localhost (executor driver) (1/1)
21/02/17 01:03:39 INFO TaskSchedulerImpl: Removed TaskSet 6.0, whose tasks have all completed, from pool 
21/02/17 01:03:39 INFO DAGScheduler: ResultStage 6 (foreachPartition at XGBoost.scala:612) finished in 0.394 s
21/02/17 01:03:39 INFO DAGScheduler: Job 5 is finished. Cancelling potential speculative or zombie tasks for this job
21/02/17 01:03:39 INFO TaskSchedulerImpl: Killing all running tasks in stage 6: Stage finished
21/02/17 01:03:39 INFO DAGScheduler: Job 5 finished: foreachPartition at XGBoost.scala:612, took 0.403788 s
21/02/17 01:03:39 INFO SparkContext: Starting job: first at XGBoost.scala:734
21/02/17 01:03:39 INFO DAGScheduler: Got job 6 (first at XGBoost.scala:734) with 1 output partitions
21/02/17 01:03:39 INFO DAGScheduler: Final stage: ResultStage 7 (first at XGBoost.scala:734)
21/02/17 01:03:39 INFO DAGScheduler: Parents of final stage: List()
21/02/17 01:03:39 INFO DAGScheduler: Missing parents: List()
21/02/17 01:03:39 INFO DAGScheduler: Submitting ResultStage 7 (MapPartitionsRDD[32] at mapPartitions at XGBoost.scala:493), which has no missing parents
21/02/17 01:03:39 INFO MemoryStore: Block broadcast_7 stored as values in memory (estimated size 39.6 KiB, free 912.2 MiB)
21/02/17 01:03:39 INFO MemoryStore: Block broadcast_7_piece0 stored as bytes in memory (estimated size 16.6 KiB, free 912.1 MiB)
21/02/17 01:03:39 INFO BlockManagerInfo: Added broadcast_7_piece0 in memory on localhost:37167 (size: 16.6 KiB, free: 912.2 MiB)
21/02/17 01:03:39 INFO SparkContext: Created broadcast 7 from broadcast at DAGScheduler.scala:1200
21/02/17 01:03:39 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 7 (MapPartitionsRDD[32] at mapPartitions at XGBoost.scala:493) (first 15 tasks are for partitions Vector(0))
21/02/17 01:03:39 INFO TaskSchedulerImpl: Adding task set 7.0 with 1 tasks
21/02/17 01:03:39 INFO TaskSetManager: Starting task 0.0 in stage 7.0 (TID 7, localhost, executor driver, partition 0, PROCESS_LOCAL, 18492 bytes)
21/02/17 01:03:39 INFO Executor: Running task 0.0 in stage 7.0 (TID 7)
21/02/17 01:03:39 INFO BlockManager: Found block rdd_32_0 locally
21/02/17 01:03:39 INFO Executor: 1 block locks were not released by TID = 7:
[rdd_32_0]
21/02/17 01:03:39 INFO Executor: Finished task 0.0 in stage 7.0 (TID 7). 2676 bytes result sent to driver
21/02/17 01:03:39 INFO TaskSetManager: Finished task 0.0 in stage 7.0 (TID 7) in 14 ms on localhost (executor driver) (1/1)
21/02/17 01:03:39 INFO TaskSchedulerImpl: Removed TaskSet 7.0, whose tasks have all completed, from pool 
21/02/17 01:03:39 INFO DAGScheduler: ResultStage 7 (first at XGBoost.scala:734) finished in 0.023 s
21/02/17 01:03:39 INFO DAGScheduler: Job 6 is finished. Cancelling potential speculative or zombie tasks for this job
21/02/17 01:03:39 INFO TaskSchedulerImpl: Killing all running tasks in stage 7: Stage finished
21/02/17 01:03:39 INFO DAGScheduler: Job 6 finished: first at XGBoost.scala:734, took 0.027227 s
21/02/17 01:03:39 INFO MapPartitionsRDD: Removing RDD 32 from persistence list
21/02/17 01:03:39 INFO BlockManager: Removing RDD 32
21/02/17 01:03:39 INFO Instrumentation: [fe90414f] training finished
21/02/17 01:03:39 INFO BlockManagerInfo: Removed broadcast_4_piece0 on localhost:37167 in memory (size: 5.2 KiB, free: 912.3 MiB)
21/02/17 01:03:39 INFO BlockManagerInfo: Removed broadcast_3_piece0 on localhost:37167 in memory (size: 3.7 KiB, free: 912.3 MiB)
21/02/17 01:03:39 INFO BlockManagerInfo: Removed broadcast_6_piece0 on localhost:37167 in memory (size: 16.6 KiB, free: 912.3 MiB)
21/02/17 01:03:39 INFO BlockManager: Removing RDD 32
21/02/17 01:03:39 INFO BlockManagerInfo: Removed broadcast_5_piece0 on localhost:37167 in memory (size: 5.0 KiB, free: 912.3 MiB)
21/02/17 01:03:39 INFO BlockManagerInfo: Removed broadcast_7_piece0 on localhost:37167 in memory (size: 16.6 KiB, free: 912.3 MiB)
21/02/17 01:03:39 INFO Instrumentation: [356282a0] training finished
21/02/17 01:03:39 INFO MemoryStore: Block broadcast_8 stored as values in memory (estimated size 64.0 B, free 912.3 MiB)
21/02/17 01:03:39 INFO MemoryStore: Block broadcast_8_piece0 stored as bytes in memory (estimated size 514.0 B, free 912.3 MiB)
21/02/17 01:03:39 INFO BlockManagerInfo: Added broadcast_8_piece0 in memory on localhost:37167 (size: 514.0 B, free: 912.3 MiB)
21/02/17 01:03:39 INFO SparkContext: Created broadcast 8 from broadcast at XGBoostRegressor.scala:279
21/02/17 01:03:40 INFO CodeGenerator: Code generated in 26.078597 ms
21/02/17 01:03:40 INFO Instrumentation: [4b4a7f3d] training finished
21/02/17 01:03:40 INFO CodeGenerator: Code generated in 8.427067 ms
21/02/17 01:03:40 INFO SparkContext: Starting job: collect at utils.scala:137
21/02/17 01:03:40 INFO DAGScheduler: Got job 7 (collect at utils.scala:137) with 1 output partitions
21/02/17 01:03:40 INFO DAGScheduler: Final stage: ResultStage 8 (collect at utils.scala:137)
21/02/17 01:03:40 INFO DAGScheduler: Parents of final stage: List()
21/02/17 01:03:40 INFO DAGScheduler: Missing parents: List()
21/02/17 01:03:40 INFO DAGScheduler: Submitting ResultStage 8 (MapPartitionsRDD[42] at collect at utils.scala:137), which has no missing parents
21/02/17 01:03:40 INFO MemoryStore: Block broadcast_9 stored as values in memory (estimated size 7.3 KiB, free 912.3 MiB)
21/02/17 01:03:40 INFO MemoryStore: Block broadcast_9_piece0 stored as bytes in memory (estimated size 3.7 KiB, free 912.3 MiB)
21/02/17 01:03:40 INFO BlockManagerInfo: Added broadcast_9_piece0 in memory on localhost:37167 (size: 3.7 KiB, free: 912.3 MiB)
21/02/17 01:03:40 INFO SparkContext: Created broadcast 9 from broadcast at DAGScheduler.scala:1200
21/02/17 01:03:40 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 8 (MapPartitionsRDD[42] at collect at utils.scala:137) (first 15 tasks are for partitions Vector(0))
21/02/17 01:03:40 INFO TaskSchedulerImpl: Adding task set 8.0 with 1 tasks
21/02/17 01:03:40 INFO TaskSetManager: Starting task 0.0 in stage 8.0 (TID 8, localhost, executor driver, partition 0, PROCESS_LOCAL, 7561 bytes)
21/02/17 01:03:40 INFO Executor: Running task 0.0 in stage 8.0 (TID 8)
21/02/17 01:03:40 INFO Executor: Finished task 0.0 in stage 8.0 (TID 8). 1397 bytes result sent to driver
21/02/17 01:03:40 INFO TaskSetManager: Finished task 0.0 in stage 8.0 (TID 8) in 6 ms on localhost (executor driver) (1/1)
21/02/17 01:03:40 INFO TaskSchedulerImpl: Removed TaskSet 8.0, whose tasks have all completed, from pool 
21/02/17 01:03:40 INFO DAGScheduler: ResultStage 8 (collect at utils.scala:137) finished in 0.011 s
21/02/17 01:03:40 INFO DAGScheduler: Job 7 is finished. Cancelling potential speculative or zombie tasks for this job
21/02/17 01:03:40 INFO TaskSchedulerImpl: Killing all running tasks in stage 8: Stage finished
21/02/17 01:03:40 INFO DAGScheduler: Job 7 finished: collect at utils.scala:137, took 0.013319 s
21/02/17 01:03:40 INFO CodeGenerator: Code generated in 8.447234 ms
21/02/17 01:03:40 INFO SparkContext: Starting job: count at utils.scala:135
21/02/17 01:03:40 INFO DAGScheduler: Registering RDD 44 (count at utils.scala:135) as input to shuffle 2
21/02/17 01:03:40 INFO DAGScheduler: Got job 8 (count at utils.scala:135) with 1 output partitions
21/02/17 01:03:40 INFO DAGScheduler: Final stage: ResultStage 10 (count at utils.scala:135)
21/02/17 01:03:40 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 9)
21/02/17 01:03:40 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 9)
21/02/17 01:03:40 INFO DAGScheduler: Submitting ShuffleMapStage 9 (MapPartitionsRDD[44] at count at utils.scala:135), which has no missing parents
21/02/17 01:03:40 INFO MemoryStore: Block broadcast_10 stored as values in memory (estimated size 10.0 KiB, free 912.3 MiB)
21/02/17 01:03:40 INFO MemoryStore: Block broadcast_10_piece0 stored as bytes in memory (estimated size 5.2 KiB, free 912.3 MiB)
21/02/17 01:03:40 INFO BlockManagerInfo: Added broadcast_10_piece0 in memory on localhost:37167 (size: 5.2 KiB, free: 912.3 MiB)
21/02/17 01:03:40 INFO SparkContext: Created broadcast 10 from broadcast at DAGScheduler.scala:1200
21/02/17 01:03:40 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 9 (MapPartitionsRDD[44] at count at utils.scala:135) (first 15 tasks are for partitions Vector(0))
21/02/17 01:03:40 INFO TaskSchedulerImpl: Adding task set 9.0 with 1 tasks
21/02/17 01:03:40 INFO TaskSetManager: Starting task 0.0 in stage 9.0 (TID 9, localhost, executor driver, partition 0, PROCESS_LOCAL, 7550 bytes)
21/02/17 01:03:40 INFO Executor: Running task 0.0 in stage 9.0 (TID 9)
21/02/17 01:03:40 INFO Executor: Finished task 0.0 in stage 9.0 (TID 9). 1833 bytes result sent to driver
21/02/17 01:03:40 INFO TaskSetManager: Finished task 0.0 in stage 9.0 (TID 9) in 5 ms on localhost (executor driver) (1/1)
21/02/17 01:03:40 INFO TaskSchedulerImpl: Removed TaskSet 9.0, whose tasks have all completed, from pool 
21/02/17 01:03:40 INFO DAGScheduler: ShuffleMapStage 9 (count at utils.scala:135) finished in 0.010 s
21/02/17 01:03:40 INFO DAGScheduler: looking for newly runnable stages
21/02/17 01:03:40 INFO DAGScheduler: running: Set()
21/02/17 01:03:40 INFO DAGScheduler: waiting: Set(ResultStage 10)
21/02/17 01:03:40 INFO DAGScheduler: failed: Set()
21/02/17 01:03:40 INFO DAGScheduler: Submitting ResultStage 10 (MapPartitionsRDD[47] at count at utils.scala:135), which has no missing parents
21/02/17 01:03:40 INFO MemoryStore: Block broadcast_11 stored as values in memory (estimated size 10.1 KiB, free 912.3 MiB)
21/02/17 01:03:40 INFO MemoryStore: Block broadcast_11_piece0 stored as bytes in memory (estimated size 5.0 KiB, free 912.3 MiB)
21/02/17 01:03:40 INFO BlockManagerInfo: Added broadcast_11_piece0 in memory on localhost:37167 (size: 5.0 KiB, free: 912.3 MiB)
21/02/17 01:03:40 INFO SparkContext: Created broadcast 11 from broadcast at DAGScheduler.scala:1200
21/02/17 01:03:40 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 10 (MapPartitionsRDD[47] at count at utils.scala:135) (first 15 tasks are for partitions Vector(0))
21/02/17 01:03:40 INFO TaskSchedulerImpl: Adding task set 10.0 with 1 tasks
21/02/17 01:03:40 INFO TaskSetManager: Starting task 0.0 in stage 10.0 (TID 10, localhost, executor driver, partition 0, NODE_LOCAL, 7325 bytes)
21/02/17 01:03:40 INFO Executor: Running task 0.0 in stage 10.0 (TID 10)
21/02/17 01:03:40 INFO ShuffleBlockFetcherIterator: Getting 1 (60.0 B) non-empty blocks including 1 (60.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
21/02/17 01:03:40 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
21/02/17 01:03:40 INFO Executor: Finished task 0.0 in stage 10.0 (TID 10). 2648 bytes result sent to driver
21/02/17 01:03:40 INFO TaskSetManager: Finished task 0.0 in stage 10.0 (TID 10) in 6 ms on localhost (executor driver) (1/1)
21/02/17 01:03:40 INFO TaskSchedulerImpl: Removed TaskSet 10.0, whose tasks have all completed, from pool 
21/02/17 01:03:40 INFO DAGScheduler: ResultStage 10 (count at utils.scala:135) finished in 0.010 s
21/02/17 01:03:40 INFO DAGScheduler: Job 8 is finished. Cancelling potential speculative or zombie tasks for this job
21/02/17 01:03:40 INFO TaskSchedulerImpl: Killing all running tasks in stage 10: Stage finished
21/02/17 01:03:40 INFO DAGScheduler: Job 8 finished: count at utils.scala:135, took 0.025271 s
21/02/17 01:03:40 INFO CodeGenerator: Code generated in 11.228907 ms
21/02/17 01:03:40 INFO SparkContext: Starting job: collect at utils.scala:137
21/02/17 01:03:40 INFO DAGScheduler: Got job 9 (collect at utils.scala:137) with 1 output partitions
21/02/17 01:03:40 INFO DAGScheduler: Final stage: ResultStage 11 (collect at utils.scala:137)
21/02/17 01:03:40 INFO DAGScheduler: Parents of final stage: List()
21/02/17 01:03:40 INFO DAGScheduler: Missing parents: List()
21/02/17 01:03:40 INFO DAGScheduler: Submitting ResultStage 11 (MapPartitionsRDD[49] at collect at utils.scala:137), which has no missing parents
21/02/17 01:03:40 INFO MemoryStore: Block broadcast_12 stored as values in memory (estimated size 70.7 KiB, free 912.2 MiB)
21/02/17 01:03:40 INFO MemoryStore: Block broadcast_12_piece0 stored as bytes in memory (estimated size 28.0 KiB, free 912.2 MiB)
21/02/17 01:03:40 INFO BlockManagerInfo: Added broadcast_12_piece0 in memory on localhost:37167 (size: 28.0 KiB, free: 912.3 MiB)
21/02/17 01:03:40 INFO SparkContext: Created broadcast 12 from broadcast at DAGScheduler.scala:1200
21/02/17 01:03:40 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 11 (MapPartitionsRDD[49] at collect at utils.scala:137) (first 15 tasks are for partitions Vector(0))
21/02/17 01:03:40 INFO TaskSchedulerImpl: Adding task set 11.0 with 1 tasks
21/02/17 01:03:40 INFO TaskSetManager: Starting task 0.0 in stage 11.0 (TID 11, localhost, executor driver, partition 0, PROCESS_LOCAL, 18492 bytes)
21/02/17 01:03:40 INFO Executor: Running task 0.0 in stage 11.0 (TID 11)
21/02/17 01:03:40 INFO BlockManager: Found block rdd_23_0 locally
21/02/17 01:03:40 INFO CodeGenerator: Code generated in 13.083321 ms
21/02/17 01:03:40 INFO CodeGenerator: Code generated in 35.849329 ms
21/02/17 01:03:40 INFO Executor: Finished task 0.0 in stage 11.0 (TID 11). 1912 bytes result sent to driver
21/02/17 01:03:40 INFO TaskSetManager: Finished task 0.0 in stage 11.0 (TID 11) in 158 ms on localhost (executor driver) (1/1)
21/02/17 01:03:40 INFO TaskSchedulerImpl: Removed TaskSet 11.0, whose tasks have all completed, from pool 
21/02/17 01:03:41 INFO DAGScheduler: ResultStage 11 (collect at utils.scala:137) finished in 0.164 s
21/02/17 01:03:41 INFO DAGScheduler: Job 9 is finished. Cancelling potential speculative or zombie tasks for this job
21/02/17 01:03:41 INFO TaskSchedulerImpl: Killing all running tasks in stage 11: Stage finished
21/02/17 01:03:41 INFO DAGScheduler: Job 9 finished: collect at utils.scala:137, took 0.167597 s
21/02/17 01:03:41 INFO CodeGenerator: Code generated in 5.837435 ms
21/02/17 01:03:41 INFO CodeGenerator: Code generated in 10.465544 ms
21/02/17 01:03:41 INFO SparkContext: Starting job: count at utils.scala:135
21/02/17 01:03:41 INFO DAGScheduler: Registering RDD 51 (count at utils.scala:135) as input to shuffle 3
21/02/17 01:03:41 INFO DAGScheduler: Got job 10 (count at utils.scala:135) with 1 output partitions
21/02/17 01:03:41 INFO DAGScheduler: Final stage: ResultStage 13 (count at utils.scala:135)
21/02/17 01:03:41 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 12)
21/02/17 01:03:41 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 12)
21/02/17 01:03:41 INFO DAGScheduler: Submitting ShuffleMapStage 12 (MapPartitionsRDD[51] at count at utils.scala:135), which has no missing parents
21/02/17 01:03:41 INFO MemoryStore: Block broadcast_13 stored as values in memory (estimated size 72.9 KiB, free 912.1 MiB)
21/02/17 01:03:41 INFO MemoryStore: Block broadcast_13_piece0 stored as bytes in memory (estimated size 29.1 KiB, free 912.1 MiB)
21/02/17 01:03:41 INFO BlockManagerInfo: Added broadcast_13_piece0 in memory on localhost:37167 (size: 29.1 KiB, free: 912.2 MiB)
21/02/17 01:03:41 INFO SparkContext: Created broadcast 13 from broadcast at DAGScheduler.scala:1200
21/02/17 01:03:41 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 12 (MapPartitionsRDD[51] at count at utils.scala:135) (first 15 tasks are for partitions Vector(0))
21/02/17 01:03:41 INFO TaskSchedulerImpl: Adding task set 12.0 with 1 tasks
21/02/17 01:03:41 INFO TaskSetManager: Starting task 0.0 in stage 12.0 (TID 12, localhost, executor driver, partition 0, PROCESS_LOCAL, 18481 bytes)
21/02/17 01:03:41 INFO Executor: Running task 0.0 in stage 12.0 (TID 12)
21/02/17 01:03:41 INFO BlockManager: Found block rdd_23_0 locally
21/02/17 01:03:41 INFO Executor: Finished task 0.0 in stage 12.0 (TID 12). 2253 bytes result sent to driver
21/02/17 01:03:41 INFO TaskSetManager: Finished task 0.0 in stage 12.0 (TID 12) in 50 ms on localhost (executor driver) (1/1)
21/02/17 01:03:41 INFO TaskSchedulerImpl: Removed TaskSet 12.0, whose tasks have all completed, from pool 
21/02/17 01:03:41 INFO DAGScheduler: ShuffleMapStage 12 (count at utils.scala:135) finished in 0.058 s
21/02/17 01:03:41 INFO DAGScheduler: looking for newly runnable stages
21/02/17 01:03:41 INFO DAGScheduler: running: Set()
21/02/17 01:03:41 INFO DAGScheduler: waiting: Set(ResultStage 13)
21/02/17 01:03:41 INFO DAGScheduler: failed: Set()
21/02/17 01:03:41 INFO DAGScheduler: Submitting ResultStage 13 (MapPartitionsRDD[54] at count at utils.scala:135), which has no missing parents
21/02/17 01:03:41 INFO MemoryStore: Block broadcast_14 stored as values in memory (estimated size 10.1 KiB, free 912.0 MiB)
21/02/17 01:03:41 INFO MemoryStore: Block broadcast_14_piece0 stored as bytes in memory (estimated size 5.0 KiB, free 912.0 MiB)
21/02/17 01:03:41 INFO BlockManagerInfo: Added broadcast_14_piece0 in memory on localhost:37167 (size: 5.0 KiB, free: 912.2 MiB)
21/02/17 01:03:41 INFO SparkContext: Created broadcast 14 from broadcast at DAGScheduler.scala:1200
21/02/17 01:03:41 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 13 (MapPartitionsRDD[54] at count at utils.scala:135) (first 15 tasks are for partitions Vector(0))
21/02/17 01:03:41 INFO TaskSchedulerImpl: Adding task set 13.0 with 1 tasks
21/02/17 01:03:41 INFO TaskSetManager: Starting task 0.0 in stage 13.0 (TID 13, localhost, executor driver, partition 0, NODE_LOCAL, 7325 bytes)
21/02/17 01:03:41 INFO Executor: Running task 0.0 in stage 13.0 (TID 13)
21/02/17 01:03:41 INFO ShuffleBlockFetcherIterator: Getting 1 (60.0 B) non-empty blocks including 1 (60.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
21/02/17 01:03:41 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
21/02/17 01:03:41 INFO Executor: Finished task 0.0 in stage 13.0 (TID 13). 2648 bytes result sent to driver
21/02/17 01:03:41 INFO TaskSetManager: Finished task 0.0 in stage 13.0 (TID 13) in 7 ms on localhost (executor driver) (1/1)
21/02/17 01:03:41 INFO TaskSchedulerImpl: Removed TaskSet 13.0, whose tasks have all completed, from pool 
21/02/17 01:03:41 INFO DAGScheduler: ResultStage 13 (count at utils.scala:135) finished in 0.010 s
21/02/17 01:03:41 INFO DAGScheduler: Job 10 is finished. Cancelling potential speculative or zombie tasks for this job
21/02/17 01:03:41 INFO TaskSchedulerImpl: Killing all running tasks in stage 13: Stage finished
21/02/17 01:03:41 INFO DAGScheduler: Job 10 finished: count at utils.scala:135, took 0.073010 s
21/02/17 01:03:41 INFO deprecation: mapred.output.dir is deprecated. Instead, use mapreduce.output.fileoutputformat.outputdir
21/02/17 01:03:41 INFO HadoopMapRedCommitProtocol: Using output committer class org.apache.hadoop.mapred.FileOutputCommitter
21/02/17 01:03:41 INFO FileOutputCommitter: File Output Committer Algorithm version is 2
21/02/17 01:03:41 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
21/02/17 01:03:41 INFO SparkContext: Starting job: runJob at SparkHadoopWriter.scala:78
21/02/17 01:03:41 INFO DAGScheduler: Got job 11 (runJob at SparkHadoopWriter.scala:78) with 1 output partitions
21/02/17 01:03:41 INFO DAGScheduler: Final stage: ResultStage 14 (runJob at SparkHadoopWriter.scala:78)
21/02/17 01:03:41 INFO DAGScheduler: Parents of final stage: List()
21/02/17 01:03:41 INFO DAGScheduler: Missing parents: List()
21/02/17 01:03:41 INFO DAGScheduler: Submitting ResultStage 14 (MapPartitionsRDD[56] at saveAsTextFile at ReadWrite.scala:413), which has no missing parents
21/02/17 01:03:41 INFO MemoryStore: Block broadcast_15 stored as values in memory (estimated size 83.9 KiB, free 912.0 MiB)
21/02/17 01:03:41 INFO MemoryStore: Block broadcast_15_piece0 stored as bytes in memory (estimated size 29.9 KiB, free 911.9 MiB)
21/02/17 01:03:41 INFO BlockManagerInfo: Added broadcast_15_piece0 in memory on localhost:37167 (size: 29.9 KiB, free: 912.2 MiB)
21/02/17 01:03:41 INFO SparkContext: Created broadcast 15 from broadcast at DAGScheduler.scala:1200
21/02/17 01:03:41 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 14 (MapPartitionsRDD[56] at saveAsTextFile at ReadWrite.scala:413) (first 15 tasks are for partitions Vector(0))
21/02/17 01:03:41 INFO TaskSchedulerImpl: Adding task set 14.0 with 1 tasks
21/02/17 01:03:41 INFO TaskSetManager: Starting task 0.0 in stage 14.0 (TID 14, localhost, executor driver, partition 0, PROCESS_LOCAL, 7657 bytes)
21/02/17 01:03:41 INFO Executor: Running task 0.0 in stage 14.0 (TID 14)
21/02/17 01:03:41 INFO HadoopMapRedCommitProtocol: Using output committer class org.apache.hadoop.mapred.FileOutputCommitter
21/02/17 01:03:41 INFO FileOutputCommitter: File Output Committer Algorithm version is 2
21/02/17 01:03:41 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
21/02/17 01:03:41 INFO FileOutputCommitter: Saved output of task 'attempt_20210217010341_0056_m_000000_0' to file:/tmp/RtmpdJZfO0/file1fe9816a0746c/metadata
21/02/17 01:03:41 INFO SparkHadoopMapRedUtil: attempt_20210217010341_0056_m_000000_0: Committed
21/02/17 01:03:41 INFO Executor: Finished task 0.0 in stage 14.0 (TID 14). 1201 bytes result sent to driver
21/02/17 01:03:41 INFO TaskSetManager: Finished task 0.0 in stage 14.0 (TID 14) in 48 ms on localhost (executor driver) (1/1)
21/02/17 01:03:41 INFO TaskSchedulerImpl: Removed TaskSet 14.0, whose tasks have all completed, from pool 
21/02/17 01:03:41 INFO DAGScheduler: ResultStage 14 (runJob at SparkHadoopWriter.scala:78) finished in 0.060 s
21/02/17 01:03:41 INFO DAGScheduler: Job 11 is finished. Cancelling potential speculative or zombie tasks for this job
21/02/17 01:03:41 INFO TaskSchedulerImpl: Killing all running tasks in stage 14: Stage finished
21/02/17 01:03:41 INFO DAGScheduler: Job 11 finished: runJob at SparkHadoopWriter.scala:78, took 0.062103 s
21/02/17 01:03:41 INFO SparkHadoopWriter: Job job_20210217010341_0056 committed.
21/02/17 01:03:41 INFO BlockManagerInfo: Removed broadcast_14_piece0 on localhost:37167 in memory (size: 5.0 KiB, free: 912.2 MiB)
21/02/17 01:03:41 INFO HadoopMapRedCommitProtocol: Using output committer class org.apache.hadoop.mapred.FileOutputCommitter
21/02/17 01:03:41 INFO FileOutputCommitter: File Output Committer Algorithm version is 2
21/02/17 01:03:41 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
21/02/17 01:03:41 INFO BlockManagerInfo: Removed broadcast_10_piece0 on localhost:37167 in memory (size: 5.2 KiB, free: 912.2 MiB)
21/02/17 01:03:41 INFO BlockManagerInfo: Removed broadcast_15_piece0 on localhost:37167 in memory (size: 29.9 KiB, free: 912.2 MiB)
21/02/17 01:03:41 INFO BlockManagerInfo: Removed broadcast_11_piece0 on localhost:37167 in memory (size: 5.0 KiB, free: 912.2 MiB)
21/02/17 01:03:41 INFO BlockManagerInfo: Removed broadcast_9_piece0 on localhost:37167 in memory (size: 3.7 KiB, free: 912.2 MiB)
21/02/17 01:03:41 INFO BlockManagerInfo: Removed broadcast_13_piece0 on localhost:37167 in memory (size: 29.1 KiB, free: 912.3 MiB)
21/02/17 01:03:41 INFO SparkContext: Starting job: runJob at SparkHadoopWriter.scala:78
21/02/17 01:03:41 INFO DAGScheduler: Got job 12 (runJob at SparkHadoopWriter.scala:78) with 1 output partitions
21/02/17 01:03:41 INFO DAGScheduler: Final stage: ResultStage 15 (runJob at SparkHadoopWriter.scala:78)
21/02/17 01:03:41 INFO DAGScheduler: Parents of final stage: List()
21/02/17 01:03:41 INFO DAGScheduler: Missing parents: List()
21/02/17 01:03:41 INFO DAGScheduler: Submitting ResultStage 15 (MapPartitionsRDD[58] at saveAsTextFile at ReadWrite.scala:413), which has no missing parents
21/02/17 01:03:41 INFO BlockManagerInfo: Removed broadcast_12_piece0 on localhost:37167 in memory (size: 28.0 KiB, free: 912.3 MiB)
21/02/17 01:03:41 INFO MemoryStore: Block broadcast_16 stored as values in memory (estimated size 84.0 KiB, free 912.2 MiB)
21/02/17 01:03:41 INFO MemoryStore: Block broadcast_16_piece0 stored as bytes in memory (estimated size 30.0 KiB, free 912.2 MiB)
21/02/17 01:03:41 INFO BlockManagerInfo: Added broadcast_16_piece0 in memory on localhost:37167 (size: 30.0 KiB, free: 912.3 MiB)
21/02/17 01:03:41 INFO SparkContext: Created broadcast 16 from broadcast at DAGScheduler.scala:1200
21/02/17 01:03:41 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 15 (MapPartitionsRDD[58] at saveAsTextFile at ReadWrite.scala:413) (first 15 tasks are for partitions Vector(0))
21/02/17 01:03:41 INFO TaskSchedulerImpl: Adding task set 15.0 with 1 tasks
21/02/17 01:03:41 INFO TaskSetManager: Starting task 0.0 in stage 15.0 (TID 15, localhost, executor driver, partition 0, PROCESS_LOCAL, 7798 bytes)
21/02/17 01:03:41 INFO Executor: Running task 0.0 in stage 15.0 (TID 15)
21/02/17 01:03:41 INFO HadoopMapRedCommitProtocol: Using output committer class org.apache.hadoop.mapred.FileOutputCommitter
21/02/17 01:03:41 INFO FileOutputCommitter: File Output Committer Algorithm version is 2
21/02/17 01:03:41 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
21/02/17 01:03:41 INFO FileOutputCommitter: Saved output of task 'attempt_20210217010341_0058_m_000000_0' to file:/tmp/RtmpdJZfO0/file1fe9816a0746c/stages/0_r_formula__a8f3fe0a_f74c_4053_97c3_d6d773d4c9bd/metadata
21/02/17 01:03:41 INFO SparkHadoopMapRedUtil: attempt_20210217010341_0058_m_000000_0: Committed
21/02/17 01:03:41 INFO Executor: Finished task 0.0 in stage 15.0 (TID 15). 1158 bytes result sent to driver
21/02/17 01:03:41 INFO TaskSetManager: Finished task 0.0 in stage 15.0 (TID 15) in 23 ms on localhost (executor driver) (1/1)
21/02/17 01:03:41 INFO TaskSchedulerImpl: Removed TaskSet 15.0, whose tasks have all completed, from pool 
21/02/17 01:03:41 INFO DAGScheduler: ResultStage 15 (runJob at SparkHadoopWriter.scala:78) finished in 0.037 s
21/02/17 01:03:41 INFO DAGScheduler: Job 12 is finished. Cancelling potential speculative or zombie tasks for this job
21/02/17 01:03:41 INFO TaskSchedulerImpl: Killing all running tasks in stage 15: Stage finished
21/02/17 01:03:41 INFO DAGScheduler: Job 12 finished: runJob at SparkHadoopWriter.scala:78, took 0.039545 s
21/02/17 01:03:41 INFO SparkHadoopWriter: Job job_20210217010341_0058 committed.
21/02/17 01:03:41 INFO ParquetFileFormat: Using default output committer for Parquet: org.apache.parquet.hadoop.ParquetOutputCommitter
21/02/17 01:03:41 INFO FileOutputCommitter: File Output Committer Algorithm version is 2
21/02/17 01:03:41 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
21/02/17 01:03:41 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
21/02/17 01:03:41 INFO FileOutputCommitter: File Output Committer Algorithm version is 2
21/02/17 01:03:41 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
21/02/17 01:03:41 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
21/02/17 01:03:41 INFO CodeGenerator: Code generated in 10.311982 ms
21/02/17 01:03:41 INFO SparkContext: Starting job: parquet at RFormula.scala:434
21/02/17 01:03:41 INFO DAGScheduler: Registering RDD 61 (parquet at RFormula.scala:434) as input to shuffle 4
21/02/17 01:03:41 INFO DAGScheduler: Got job 13 (parquet at RFormula.scala:434) with 1 output partitions
21/02/17 01:03:41 INFO DAGScheduler: Final stage: ResultStage 17 (parquet at RFormula.scala:434)
21/02/17 01:03:41 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 16)
21/02/17 01:03:41 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 16)
21/02/17 01:03:41 INFO DAGScheduler: Submitting ShuffleMapStage 16 (MapPartitionsRDD[61] at parquet at RFormula.scala:434), which has no missing parents
21/02/17 01:03:41 INFO MemoryStore: Block broadcast_17 stored as values in memory (estimated size 7.7 KiB, free 912.2 MiB)
21/02/17 01:03:41 INFO MemoryStore: Block broadcast_17_piece0 stored as bytes in memory (estimated size 4.2 KiB, free 912.2 MiB)
21/02/17 01:03:41 INFO BlockManagerInfo: Added broadcast_17_piece0 in memory on localhost:37167 (size: 4.2 KiB, free: 912.3 MiB)
21/02/17 01:03:41 INFO SparkContext: Created broadcast 17 from broadcast at DAGScheduler.scala:1200
21/02/17 01:03:41 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 16 (MapPartitionsRDD[61] at parquet at RFormula.scala:434) (first 15 tasks are for partitions Vector(0))
21/02/17 01:03:41 INFO TaskSchedulerImpl: Adding task set 16.0 with 1 tasks
21/02/17 01:03:41 INFO TaskSetManager: Starting task 0.0 in stage 16.0 (TID 16, localhost, executor driver, partition 0, PROCESS_LOCAL, 7658 bytes)
21/02/17 01:03:41 INFO Executor: Running task 0.0 in stage 16.0 (TID 16)
21/02/17 01:03:41 INFO Executor: Finished task 0.0 in stage 16.0 (TID 16). 1614 bytes result sent to driver
21/02/17 01:03:41 INFO TaskSetManager: Finished task 0.0 in stage 16.0 (TID 16) in 6 ms on localhost (executor driver) (1/1)
21/02/17 01:03:41 INFO TaskSchedulerImpl: Removed TaskSet 16.0, whose tasks have all completed, from pool 
21/02/17 01:03:41 INFO DAGScheduler: ShuffleMapStage 16 (parquet at RFormula.scala:434) finished in 0.011 s
21/02/17 01:03:41 INFO DAGScheduler: looking for newly runnable stages
21/02/17 01:03:41 INFO DAGScheduler: running: Set()
21/02/17 01:03:41 INFO DAGScheduler: waiting: Set(ResultStage 17)
21/02/17 01:03:41 INFO DAGScheduler: failed: Set()
21/02/17 01:03:41 INFO DAGScheduler: Submitting ResultStage 17 (ShuffledRowRDD[62] at parquet at RFormula.scala:434), which has no missing parents
21/02/17 01:03:41 INFO MemoryStore: Block broadcast_18 stored as values in memory (estimated size 175.1 KiB, free 912.0 MiB)
21/02/17 01:03:41 INFO MemoryStore: Block broadcast_18_piece0 stored as bytes in memory (estimated size 61.7 KiB, free 911.9 MiB)
21/02/17 01:03:41 INFO BlockManagerInfo: Added broadcast_18_piece0 in memory on localhost:37167 (size: 61.7 KiB, free: 912.2 MiB)
21/02/17 01:03:41 INFO SparkContext: Created broadcast 18 from broadcast at DAGScheduler.scala:1200
21/02/17 01:03:41 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 17 (ShuffledRowRDD[62] at parquet at RFormula.scala:434) (first 15 tasks are for partitions Vector(0))
21/02/17 01:03:41 INFO TaskSchedulerImpl: Adding task set 17.0 with 1 tasks
21/02/17 01:03:41 INFO TaskSetManager: Starting task 0.0 in stage 17.0 (TID 17, localhost, executor driver, partition 0, NODE_LOCAL, 7325 bytes)
21/02/17 01:03:41 INFO Executor: Running task 0.0 in stage 17.0 (TID 17)
21/02/17 01:03:41 INFO ShuffleBlockFetcherIterator: Getting 1 (156.0 B) non-empty blocks including 1 (156.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
21/02/17 01:03:41 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
21/02/17 01:03:41 INFO FileOutputCommitter: File Output Committer Algorithm version is 2
21/02/17 01:03:41 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
21/02/17 01:03:41 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
21/02/17 01:03:41 INFO FileOutputCommitter: File Output Committer Algorithm version is 2
21/02/17 01:03:41 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
21/02/17 01:03:41 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
21/02/17 01:03:41 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:
{
  "type" : "struct",
  "fields" : [ {
    "name" : "label",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "terms",
    "type" : {
      "type" : "array",
      "elementType" : {
        "type" : "array",
        "elementType" : "string",
        "containsNull" : true
      },
      "containsNull" : true
    },
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "hasIntercept",
    "type" : "boolean",
    "nullable" : false,
    "metadata" : { }
  } ]
}
and corresponding Parquet message type:
message spark_schema {
  optional binary label (UTF8);
  optional group terms (LIST) {
    repeated group list {
      optional group element (LIST) {
        repeated group list {
          optional binary element (UTF8);
        }
      }
    }
  }
  required boolean hasIntercept;
}

       
21/02/17 01:03:41 INFO CodecPool: Got brand-new compressor [.snappy]
21/02/17 01:03:42 INFO BlockManagerInfo: Removed broadcast_16_piece0 on localhost:37167 in memory (size: 30.0 KiB, free: 912.2 MiB)
21/02/17 01:03:42 INFO BlockManagerInfo: Removed broadcast_17_piece0 on localhost:37167 in memory (size: 4.2 KiB, free: 912.2 MiB)
21/02/17 01:03:42 INFO FileOutputCommitter: Saved output of task 'attempt_20210217010341_0017_m_000000_17' to file:/tmp/RtmpdJZfO0/file1fe9816a0746c/stages/0_r_formula__a8f3fe0a_f74c_4053_97c3_d6d773d4c9bd/data
21/02/17 01:03:42 INFO SparkHadoopMapRedUtil: attempt_20210217010341_0017_m_000000_17: Committed
21/02/17 01:03:42 INFO Executor: Finished task 0.0 in stage 17.0 (TID 17). 3281 bytes result sent to driver
21/02/17 01:03:42 INFO TaskSetManager: Finished task 0.0 in stage 17.0 (TID 17) in 517 ms on localhost (executor driver) (1/1)
21/02/17 01:03:42 INFO TaskSchedulerImpl: Removed TaskSet 17.0, whose tasks have all completed, from pool 
21/02/17 01:03:42 INFO DAGScheduler: ResultStage 17 (parquet at RFormula.scala:434) finished in 0.542 s
21/02/17 01:03:42 INFO DAGScheduler: Job 13 is finished. Cancelling potential speculative or zombie tasks for this job
21/02/17 01:03:42 INFO TaskSchedulerImpl: Killing all running tasks in stage 17: Stage finished
21/02/17 01:03:42 INFO DAGScheduler: Job 13 finished: parquet at RFormula.scala:434, took 0.558341 s
21/02/17 01:03:42 INFO FileFormatWriter: Write Job 5efc6c31-35bf-40ca-ae68-a287b1a806eb committed.
21/02/17 01:03:42 INFO FileFormatWriter: Finished processing stats for write job 5efc6c31-35bf-40ca-ae68-a287b1a806eb.
21/02/17 01:03:42 INFO HadoopMapRedCommitProtocol: Using output committer class org.apache.hadoop.mapred.FileOutputCommitter
21/02/17 01:03:42 INFO FileOutputCommitter: File Output Committer Algorithm version is 2
21/02/17 01:03:42 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
21/02/17 01:03:42 INFO SparkContext: Starting job: runJob at SparkHadoopWriter.scala:78
21/02/17 01:03:42 INFO DAGScheduler: Got job 14 (runJob at SparkHadoopWriter.scala:78) with 1 output partitions
21/02/17 01:03:42 INFO DAGScheduler: Final stage: ResultStage 18 (runJob at SparkHadoopWriter.scala:78)
21/02/17 01:03:42 INFO DAGScheduler: Parents of final stage: List()
21/02/17 01:03:42 INFO DAGScheduler: Missing parents: List()
21/02/17 01:03:42 INFO DAGScheduler: Submitting ResultStage 18 (MapPartitionsRDD[66] at saveAsTextFile at ReadWrite.scala:413), which has no missing parents
21/02/17 01:03:42 INFO MemoryStore: Block broadcast_19 stored as values in memory (estimated size 84.1 KiB, free 912.0 MiB)
21/02/17 01:03:42 INFO MemoryStore: Block broadcast_19_piece0 stored as bytes in memory (estimated size 30.0 KiB, free 912.0 MiB)
21/02/17 01:03:42 INFO BlockManagerInfo: Added broadcast_19_piece0 in memory on localhost:37167 (size: 30.0 KiB, free: 912.2 MiB)
21/02/17 01:03:42 INFO SparkContext: Created broadcast 19 from broadcast at DAGScheduler.scala:1200
21/02/17 01:03:42 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 18 (MapPartitionsRDD[66] at saveAsTextFile at ReadWrite.scala:413) (first 15 tasks are for partitions Vector(0))
21/02/17 01:03:42 INFO TaskSchedulerImpl: Adding task set 18.0 with 1 tasks
21/02/17 01:03:42 INFO TaskSetManager: Starting task 0.0 in stage 18.0 (TID 18, localhost, executor driver, partition 0, PROCESS_LOCAL, 7662 bytes)
21/02/17 01:03:42 INFO Executor: Running task 0.0 in stage 18.0 (TID 18)
21/02/17 01:03:42 INFO HadoopMapRedCommitProtocol: Using output committer class org.apache.hadoop.mapred.FileOutputCommitter
21/02/17 01:03:42 INFO FileOutputCommitter: File Output Committer Algorithm version is 2
21/02/17 01:03:42 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
21/02/17 01:03:42 INFO FileOutputCommitter: Saved output of task 'attempt_20210217010342_0066_m_000000_0' to file:/tmp/RtmpdJZfO0/file1fe9816a0746c/stages/0_r_formula__a8f3fe0a_f74c_4053_97c3_d6d773d4c9bd/pipelineModel/metadata
21/02/17 01:03:42 INFO SparkHadoopMapRedUtil: attempt_20210217010342_0066_m_000000_0: Committed
21/02/17 01:03:42 INFO Executor: Finished task 0.0 in stage 18.0 (TID 18). 1158 bytes result sent to driver
21/02/17 01:03:42 INFO TaskSetManager: Finished task 0.0 in stage 18.0 (TID 18) in 18 ms on localhost (executor driver) (1/1)
21/02/17 01:03:42 INFO TaskSchedulerImpl: Removed TaskSet 18.0, whose tasks have all completed, from pool 
21/02/17 01:03:42 INFO DAGScheduler: ResultStage 18 (runJob at SparkHadoopWriter.scala:78) finished in 0.028 s
21/02/17 01:03:42 INFO DAGScheduler: Job 14 is finished. Cancelling potential speculative or zombie tasks for this job
21/02/17 01:03:42 INFO TaskSchedulerImpl: Killing all running tasks in stage 18: Stage finished
21/02/17 01:03:42 INFO DAGScheduler: Job 14 finished: runJob at SparkHadoopWriter.scala:78, took 0.029394 s
21/02/17 01:03:42 INFO SparkHadoopWriter: Job job_20210217010342_0066 committed.
21/02/17 01:03:42 INFO HadoopMapRedCommitProtocol: Using output committer class org.apache.hadoop.mapred.FileOutputCommitter
21/02/17 01:03:42 INFO FileOutputCommitter: File Output Committer Algorithm version is 2
21/02/17 01:03:42 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
21/02/17 01:03:42 INFO SparkContext: Starting job: runJob at SparkHadoopWriter.scala:78
21/02/17 01:03:42 INFO DAGScheduler: Got job 15 (runJob at SparkHadoopWriter.scala:78) with 1 output partitions
21/02/17 01:03:42 INFO DAGScheduler: Final stage: ResultStage 19 (runJob at SparkHadoopWriter.scala:78)
21/02/17 01:03:42 INFO DAGScheduler: Parents of final stage: List()
21/02/17 01:03:42 INFO DAGScheduler: Missing parents: List()
21/02/17 01:03:42 INFO DAGScheduler: Submitting ResultStage 19 (MapPartitionsRDD[68] at saveAsTextFile at ReadWrite.scala:413), which has no missing parents
21/02/17 01:03:42 INFO MemoryStore: Block broadcast_20 stored as values in memory (estimated size 84.2 KiB, free 911.9 MiB)
21/02/17 01:03:42 INFO MemoryStore: Block broadcast_20_piece0 stored as bytes in memory (estimated size 30.0 KiB, free 911.8 MiB)
21/02/17 01:03:42 INFO BlockManagerInfo: Added broadcast_20_piece0 in memory on localhost:37167 (size: 30.0 KiB, free: 912.2 MiB)
21/02/17 01:03:42 INFO SparkContext: Created broadcast 20 from broadcast at DAGScheduler.scala:1200
21/02/17 01:03:42 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 19 (MapPartitionsRDD[68] at saveAsTextFile at ReadWrite.scala:413) (first 15 tasks are for partitions Vector(0))
21/02/17 01:03:42 INFO TaskSchedulerImpl: Adding task set 19.0 with 1 tasks
21/02/17 01:03:42 INFO TaskSetManager: Starting task 0.0 in stage 19.0 (TID 19, localhost, executor driver, partition 0, PROCESS_LOCAL, 7729 bytes)
21/02/17 01:03:42 INFO Executor: Running task 0.0 in stage 19.0 (TID 19)
21/02/17 01:03:42 INFO HadoopMapRedCommitProtocol: Using output committer class org.apache.hadoop.mapred.FileOutputCommitter
21/02/17 01:03:42 INFO FileOutputCommitter: File Output Committer Algorithm version is 2
21/02/17 01:03:42 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
21/02/17 01:03:42 INFO FileOutputCommitter: Saved output of task 'attempt_20210217010342_0068_m_000000_0' to file:/tmp/RtmpdJZfO0/file1fe9816a0746c/stages/0_r_formula__a8f3fe0a_f74c_4053_97c3_d6d773d4c9bd/pipelineModel/stages/0_r_formula__a8f3fe0a_f74c_4053_97c3_d6d773d4c9bd/metadata
21/02/17 01:03:42 INFO SparkHadoopMapRedUtil: attempt_20210217010342_0068_m_000000_0: Committed
21/02/17 01:03:42 INFO Executor: Finished task 0.0 in stage 19.0 (TID 19). 1158 bytes result sent to driver
21/02/17 01:03:42 INFO TaskSetManager: Finished task 0.0 in stage 19.0 (TID 19) in 15 ms on localhost (executor driver) (1/1)
21/02/17 01:03:42 INFO TaskSchedulerImpl: Removed TaskSet 19.0, whose tasks have all completed, from pool 
21/02/17 01:03:42 INFO DAGScheduler: ResultStage 19 (runJob at SparkHadoopWriter.scala:78) finished in 0.026 s
21/02/17 01:03:42 INFO DAGScheduler: Job 15 is finished. Cancelling potential speculative or zombie tasks for this job
21/02/17 01:03:42 INFO TaskSchedulerImpl: Killing all running tasks in stage 19: Stage finished
21/02/17 01:03:42 INFO DAGScheduler: Job 15 finished: runJob at SparkHadoopWriter.scala:78, took 0.027357 s
21/02/17 01:03:42 INFO SparkHadoopWriter: Job job_20210217010342_0068 committed.
21/02/17 01:03:42 INFO HadoopMapRedCommitProtocol: Using output committer class org.apache.hadoop.mapred.FileOutputCommitter
21/02/17 01:03:42 INFO FileOutputCommitter: File Output Committer Algorithm version is 2
21/02/17 01:03:42 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
21/02/17 01:03:42 INFO SparkContext: Starting job: runJob at SparkHadoopWriter.scala:78
21/02/17 01:03:42 INFO DAGScheduler: Got job 16 (runJob at SparkHadoopWriter.scala:78) with 1 output partitions
21/02/17 01:03:42 INFO DAGScheduler: Final stage: ResultStage 20 (runJob at SparkHadoopWriter.scala:78)
21/02/17 01:03:42 INFO DAGScheduler: Parents of final stage: List()
21/02/17 01:03:42 INFO DAGScheduler: Missing parents: List()
21/02/17 01:03:42 INFO DAGScheduler: Submitting ResultStage 20 (MapPartitionsRDD[70] at saveAsTextFile at ReadWrite.scala:413), which has no missing parents
21/02/17 01:03:42 INFO MemoryStore: Block broadcast_21 stored as values in memory (estimated size 84.1 KiB, free 911.8 MiB)
21/02/17 01:03:42 INFO MemoryStore: Block broadcast_21_piece0 stored as bytes in memory (estimated size 30.0 KiB, free 911.7 MiB)
21/02/17 01:03:42 INFO BlockManagerInfo: Added broadcast_21_piece0 in memory on localhost:37167 (size: 30.0 KiB, free: 912.1 MiB)
21/02/17 01:03:42 INFO SparkContext: Created broadcast 21 from broadcast at DAGScheduler.scala:1200
21/02/17 01:03:42 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 20 (MapPartitionsRDD[70] at saveAsTextFile at ReadWrite.scala:413) (first 15 tasks are for partitions Vector(0))
21/02/17 01:03:42 INFO TaskSchedulerImpl: Adding task set 20.0 with 1 tasks
21/02/17 01:03:42 INFO TaskSetManager: Starting task 0.0 in stage 20.0 (TID 20, localhost, executor driver, partition 0, PROCESS_LOCAL, 7539 bytes)
21/02/17 01:03:42 INFO Executor: Running task 0.0 in stage 20.0 (TID 20)
21/02/17 01:03:42 INFO HadoopMapRedCommitProtocol: Using output committer class org.apache.hadoop.mapred.FileOutputCommitter
21/02/17 01:03:42 INFO FileOutputCommitter: File Output Committer Algorithm version is 2
21/02/17 01:03:42 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
21/02/17 01:03:42 INFO FileOutputCommitter: Saved output of task 'attempt_20210217010342_0070_m_000000_0' to file:/tmp/RtmpdJZfO0/file1fe9816a0746c/stages/0_r_formula__a8f3fe0a_f74c_4053_97c3_d6d773d4c9bd/pipelineModel/stages/1_vectorAttrRewriter_ab7c6f18b3b3/metadata
21/02/17 01:03:42 INFO SparkHadoopMapRedUtil: attempt_20210217010342_0070_m_000000_0: Committed
21/02/17 01:03:42 INFO Executor: Finished task 0.0 in stage 20.0 (TID 20). 1158 bytes result sent to driver
21/02/17 01:03:42 INFO TaskSetManager: Finished task 0.0 in stage 20.0 (TID 20) in 15 ms on localhost (executor driver) (1/1)
21/02/17 01:03:42 INFO TaskSchedulerImpl: Removed TaskSet 20.0, whose tasks have all completed, from pool 
21/02/17 01:03:42 INFO DAGScheduler: ResultStage 20 (runJob at SparkHadoopWriter.scala:78) finished in 0.024 s
21/02/17 01:03:42 INFO DAGScheduler: Job 16 is finished. Cancelling potential speculative or zombie tasks for this job
21/02/17 01:03:42 INFO TaskSchedulerImpl: Killing all running tasks in stage 20: Stage finished
21/02/17 01:03:42 INFO DAGScheduler: Job 16 finished: runJob at SparkHadoopWriter.scala:78, took 0.025982 s
21/02/17 01:03:42 INFO SparkHadoopWriter: Job job_20210217010342_0070 committed.
21/02/17 01:03:42 INFO ParquetFileFormat: Using default output committer for Parquet: org.apache.parquet.hadoop.ParquetOutputCommitter
21/02/17 01:03:42 INFO FileOutputCommitter: File Output Committer Algorithm version is 2
21/02/17 01:03:42 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
21/02/17 01:03:42 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
21/02/17 01:03:42 INFO FileOutputCommitter: File Output Committer Algorithm version is 2
21/02/17 01:03:42 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
21/02/17 01:03:42 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
21/02/17 01:03:42 INFO CodeGenerator: Code generated in 11.865706 ms
21/02/17 01:03:42 INFO SparkContext: Starting job: parquet at RFormula.scala:599
21/02/17 01:03:42 INFO DAGScheduler: Registering RDD 73 (parquet at RFormula.scala:599) as input to shuffle 5
21/02/17 01:03:42 INFO DAGScheduler: Got job 17 (parquet at RFormula.scala:599) with 1 output partitions
21/02/17 01:03:42 INFO DAGScheduler: Final stage: ResultStage 22 (parquet at RFormula.scala:599)
21/02/17 01:03:42 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 21)
21/02/17 01:03:42 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 21)
21/02/17 01:03:42 INFO DAGScheduler: Submitting ShuffleMapStage 21 (MapPartitionsRDD[73] at parquet at RFormula.scala:599), which has no missing parents
21/02/17 01:03:42 INFO MemoryStore: Block broadcast_22 stored as values in memory (estimated size 7.7 KiB, free 911.7 MiB)
21/02/17 01:03:42 INFO MemoryStore: Block broadcast_22_piece0 stored as bytes in memory (estimated size 4.2 KiB, free 911.7 MiB)
21/02/17 01:03:42 INFO BlockManagerInfo: Added broadcast_22_piece0 in memory on localhost:37167 (size: 4.2 KiB, free: 912.1 MiB)
21/02/17 01:03:42 INFO SparkContext: Created broadcast 22 from broadcast at DAGScheduler.scala:1200
21/02/17 01:03:42 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 21 (MapPartitionsRDD[73] at parquet at RFormula.scala:599) (first 15 tasks are for partitions Vector(0))
21/02/17 01:03:42 INFO TaskSchedulerImpl: Adding task set 21.0 with 1 tasks
21/02/17 01:03:42 INFO TaskSetManager: Starting task 0.0 in stage 21.0 (TID 21, localhost, executor driver, partition 0, PROCESS_LOCAL, 7554 bytes)
21/02/17 01:03:42 INFO Executor: Running task 0.0 in stage 21.0 (TID 21)
21/02/17 01:03:42 INFO Executor: Finished task 0.0 in stage 21.0 (TID 21). 1614 bytes result sent to driver
21/02/17 01:03:42 INFO TaskSetManager: Finished task 0.0 in stage 21.0 (TID 21) in 5 ms on localhost (executor driver) (1/1)
21/02/17 01:03:42 INFO TaskSchedulerImpl: Removed TaskSet 21.0, whose tasks have all completed, from pool 
21/02/17 01:03:42 INFO DAGScheduler: ShuffleMapStage 21 (parquet at RFormula.scala:599) finished in 0.009 s
21/02/17 01:03:42 INFO DAGScheduler: looking for newly runnable stages
21/02/17 01:03:42 INFO DAGScheduler: running: Set()
21/02/17 01:03:42 INFO DAGScheduler: waiting: Set(ResultStage 22)
21/02/17 01:03:42 INFO DAGScheduler: failed: Set()
21/02/17 01:03:42 INFO DAGScheduler: Submitting ResultStage 22 (ShuffledRowRDD[74] at parquet at RFormula.scala:599), which has no missing parents
21/02/17 01:03:42 INFO MemoryStore: Block broadcast_23 stored as values in memory (estimated size 175.1 KiB, free 911.5 MiB)
21/02/17 01:03:42 INFO MemoryStore: Block broadcast_23_piece0 stored as bytes in memory (estimated size 61.8 KiB, free 911.5 MiB)
21/02/17 01:03:42 INFO BlockManagerInfo: Added broadcast_23_piece0 in memory on localhost:37167 (size: 61.8 KiB, free: 912.1 MiB)
21/02/17 01:03:42 INFO SparkContext: Created broadcast 23 from broadcast at DAGScheduler.scala:1200
21/02/17 01:03:42 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 22 (ShuffledRowRDD[74] at parquet at RFormula.scala:599) (first 15 tasks are for partitions Vector(0))
21/02/17 01:03:42 INFO TaskSchedulerImpl: Adding task set 22.0 with 1 tasks
21/02/17 01:03:42 INFO TaskSetManager: Starting task 0.0 in stage 22.0 (TID 22, localhost, executor driver, partition 0, NODE_LOCAL, 7325 bytes)
21/02/17 01:03:42 INFO Executor: Running task 0.0 in stage 22.0 (TID 22)
21/02/17 01:03:42 INFO ShuffleBlockFetcherIterator: Getting 1 (88.0 B) non-empty blocks including 1 (88.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
21/02/17 01:03:42 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
21/02/17 01:03:42 INFO FileOutputCommitter: File Output Committer Algorithm version is 2
21/02/17 01:03:42 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
21/02/17 01:03:42 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
21/02/17 01:03:42 INFO FileOutputCommitter: File Output Committer Algorithm version is 2
21/02/17 01:03:42 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
21/02/17 01:03:42 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
21/02/17 01:03:42 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:
{
  "type" : "struct",
  "fields" : [ {
    "name" : "vectorCol",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "prefixesToRewrite",
    "type" : {
      "type" : "map",
      "keyType" : "string",
      "valueType" : "string",
      "valueContainsNull" : true
    },
    "nullable" : true,
    "metadata" : { }
  } ]
}
and corresponding Parquet message type:
message spark_schema {
  optional binary vectorCol (UTF8);
  optional group prefixesToRewrite (MAP) {
    repeated group key_value {
      required binary key (UTF8);
      optional binary value (UTF8);
    }
  }
}

       
21/02/17 01:03:42 INFO FileOutputCommitter: Saved output of task 'attempt_20210217010342_0022_m_000000_22' to file:/tmp/RtmpdJZfO0/file1fe9816a0746c/stages/0_r_formula__a8f3fe0a_f74c_4053_97c3_d6d773d4c9bd/pipelineModel/stages/1_vectorAttrRewriter_ab7c6f18b3b3/data
21/02/17 01:03:42 INFO SparkHadoopMapRedUtil: attempt_20210217010342_0022_m_000000_22: Committed
21/02/17 01:03:42 INFO Executor: Finished task 0.0 in stage 22.0 (TID 22). 3195 bytes result sent to driver
21/02/17 01:03:42 INFO TaskSetManager: Finished task 0.0 in stage 22.0 (TID 22) in 32 ms on localhost (executor driver) (1/1)
21/02/17 01:03:42 INFO TaskSchedulerImpl: Removed TaskSet 22.0, whose tasks have all completed, from pool 
21/02/17 01:03:42 INFO DAGScheduler: ResultStage 22 (parquet at RFormula.scala:599) finished in 0.050 s
21/02/17 01:03:42 INFO DAGScheduler: Job 17 is finished. Cancelling potential speculative or zombie tasks for this job
21/02/17 01:03:42 INFO TaskSchedulerImpl: Killing all running tasks in stage 22: Stage finished
21/02/17 01:03:42 INFO DAGScheduler: Job 17 finished: parquet at RFormula.scala:599, took 0.062732 s
21/02/17 01:03:42 INFO FileFormatWriter: Write Job 621e6b7e-67dd-4e6a-a5df-c07b267e6d92 committed.
21/02/17 01:03:42 INFO FileFormatWriter: Finished processing stats for write job 621e6b7e-67dd-4e6a-a5df-c07b267e6d92.
21/02/17 01:03:42 INFO HadoopMapRedCommitProtocol: Using output committer class org.apache.hadoop.mapred.FileOutputCommitter
21/02/17 01:03:42 INFO FileOutputCommitter: File Output Committer Algorithm version is 2
21/02/17 01:03:42 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
21/02/17 01:03:42 INFO SparkContext: Starting job: runJob at SparkHadoopWriter.scala:78
21/02/17 01:03:42 INFO DAGScheduler: Got job 18 (runJob at SparkHadoopWriter.scala:78) with 1 output partitions
21/02/17 01:03:42 INFO DAGScheduler: Final stage: ResultStage 23 (runJob at SparkHadoopWriter.scala:78)
21/02/17 01:03:42 INFO DAGScheduler: Parents of final stage: List()
21/02/17 01:03:42 INFO DAGScheduler: Missing parents: List()
21/02/17 01:03:42 INFO DAGScheduler: Submitting ResultStage 23 (MapPartitionsRDD[78] at saveAsTextFile at ReadWrite.scala:413), which has no missing parents
21/02/17 01:03:42 INFO MemoryStore: Block broadcast_24 stored as values in memory (estimated size 84.1 KiB, free 911.4 MiB)
21/02/17 01:03:42 INFO MemoryStore: Block broadcast_24_piece0 stored as bytes in memory (estimated size 30.0 KiB, free 911.4 MiB)
21/02/17 01:03:42 INFO BlockManagerInfo: Added broadcast_24_piece0 in memory on localhost:37167 (size: 30.0 KiB, free: 912.1 MiB)
21/02/17 01:03:42 INFO SparkContext: Created broadcast 24 from broadcast at DAGScheduler.scala:1200
21/02/17 01:03:42 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 23 (MapPartitionsRDD[78] at saveAsTextFile at ReadWrite.scala:413) (first 15 tasks are for partitions Vector(0))
21/02/17 01:03:42 INFO TaskSchedulerImpl: Adding task set 23.0 with 1 tasks
21/02/17 01:03:42 INFO TaskSetManager: Starting task 0.0 in stage 23.0 (TID 23, localhost, executor driver, partition 0, PROCESS_LOCAL, 7522 bytes)
21/02/17 01:03:42 INFO Executor: Running task 0.0 in stage 23.0 (TID 23)
21/02/17 01:03:42 INFO HadoopMapRedCommitProtocol: Using output committer class org.apache.hadoop.mapred.FileOutputCommitter
21/02/17 01:03:42 INFO FileOutputCommitter: File Output Committer Algorithm version is 2
21/02/17 01:03:42 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
21/02/17 01:03:42 INFO FileOutputCommitter: Saved output of task 'attempt_20210217010342_0078_m_000000_0' to file:/tmp/RtmpdJZfO0/file1fe9816a0746c/stages/0_r_formula__a8f3fe0a_f74c_4053_97c3_d6d773d4c9bd/pipelineModel/stages/2_columnPruner_b54e3fcdd491/metadata
21/02/17 01:03:42 INFO SparkHadoopMapRedUtil: attempt_20210217010342_0078_m_000000_0: Committed
21/02/17 01:03:42 INFO Executor: Finished task 0.0 in stage 23.0 (TID 23). 1158 bytes result sent to driver
21/02/17 01:03:42 INFO TaskSetManager: Finished task 0.0 in stage 23.0 (TID 23) in 16 ms on localhost (executor driver) (1/1)
21/02/17 01:03:42 INFO TaskSchedulerImpl: Removed TaskSet 23.0, whose tasks have all completed, from pool 
21/02/17 01:03:42 INFO DAGScheduler: ResultStage 23 (runJob at SparkHadoopWriter.scala:78) finished in 0.025 s
21/02/17 01:03:42 INFO DAGScheduler: Job 18 is finished. Cancelling potential speculative or zombie tasks for this job
21/02/17 01:03:42 INFO TaskSchedulerImpl: Killing all running tasks in stage 23: Stage finished
21/02/17 01:03:42 INFO DAGScheduler: Job 18 finished: runJob at SparkHadoopWriter.scala:78, took 0.027156 s
21/02/17 01:03:42 INFO SparkHadoopWriter: Job job_20210217010342_0078 committed.
21/02/17 01:03:42 INFO ParquetFileFormat: Using default output committer for Parquet: org.apache.parquet.hadoop.ParquetOutputCommitter
21/02/17 01:03:42 INFO FileOutputCommitter: File Output Committer Algorithm version is 2
21/02/17 01:03:42 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
21/02/17 01:03:42 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
21/02/17 01:03:42 INFO FileOutputCommitter: File Output Committer Algorithm version is 2
21/02/17 01:03:42 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
21/02/17 01:03:42 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
21/02/17 01:03:42 INFO CodeGenerator: Code generated in 7.29631 ms
21/02/17 01:03:42 INFO SparkContext: Starting job: parquet at RFormula.scala:508
21/02/17 01:03:42 INFO DAGScheduler: Registering RDD 81 (parquet at RFormula.scala:508) as input to shuffle 6
21/02/17 01:03:42 INFO DAGScheduler: Got job 19 (parquet at RFormula.scala:508) with 1 output partitions
21/02/17 01:03:42 INFO DAGScheduler: Final stage: ResultStage 25 (parquet at RFormula.scala:508)
21/02/17 01:03:42 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 24)
21/02/17 01:03:42 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 24)
21/02/17 01:03:42 INFO DAGScheduler: Submitting ShuffleMapStage 24 (MapPartitionsRDD[81] at parquet at RFormula.scala:508), which has no missing parents
21/02/17 01:03:42 INFO MemoryStore: Block broadcast_25 stored as values in memory (estimated size 7.6 KiB, free 911.4 MiB)
21/02/17 01:03:42 INFO MemoryStore: Block broadcast_25_piece0 stored as bytes in memory (estimated size 4.1 KiB, free 911.4 MiB)
21/02/17 01:03:42 INFO BlockManagerInfo: Added broadcast_25_piece0 in memory on localhost:37167 (size: 4.1 KiB, free: 912.0 MiB)
21/02/17 01:03:42 INFO SparkContext: Created broadcast 25 from broadcast at DAGScheduler.scala:1200
21/02/17 01:03:42 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 24 (MapPartitionsRDD[81] at parquet at RFormula.scala:508) (first 15 tasks are for partitions Vector(0))
21/02/17 01:03:42 INFO TaskSchedulerImpl: Adding task set 24.0 with 1 tasks
21/02/17 01:03:42 INFO TaskSetManager: Starting task 0.0 in stage 24.0 (TID 24, localhost, executor driver, partition 0, PROCESS_LOCAL, 7522 bytes)
21/02/17 01:03:42 INFO Executor: Running task 0.0 in stage 24.0 (TID 24)
21/02/17 01:03:42 INFO Executor: Finished task 0.0 in stage 24.0 (TID 24). 1614 bytes result sent to driver
21/02/17 01:03:42 INFO TaskSetManager: Finished task 0.0 in stage 24.0 (TID 24) in 4 ms on localhost (executor driver) (1/1)
21/02/17 01:03:42 INFO TaskSchedulerImpl: Removed TaskSet 24.0, whose tasks have all completed, from pool 
21/02/17 01:03:42 INFO DAGScheduler: ShuffleMapStage 24 (parquet at RFormula.scala:508) finished in 0.009 s
21/02/17 01:03:42 INFO DAGScheduler: looking for newly runnable stages
21/02/17 01:03:42 INFO DAGScheduler: running: Set()
21/02/17 01:03:42 INFO DAGScheduler: waiting: Set(ResultStage 25)
21/02/17 01:03:42 INFO DAGScheduler: failed: Set()
21/02/17 01:03:42 INFO DAGScheduler: Submitting ResultStage 25 (ShuffledRowRDD[82] at parquet at RFormula.scala:508), which has no missing parents
21/02/17 01:03:42 INFO MemoryStore: Block broadcast_26 stored as values in memory (estimated size 175.0 KiB, free 911.2 MiB)
21/02/17 01:03:42 INFO MemoryStore: Block broadcast_26_piece0 stored as bytes in memory (estimated size 61.7 KiB, free 911.1 MiB)
21/02/17 01:03:42 INFO BlockManagerInfo: Added broadcast_26_piece0 in memory on localhost:37167 (size: 61.7 KiB, free: 912.0 MiB)
21/02/17 01:03:42 INFO SparkContext: Created broadcast 26 from broadcast at DAGScheduler.scala:1200
21/02/17 01:03:42 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 25 (ShuffledRowRDD[82] at parquet at RFormula.scala:508) (first 15 tasks are for partitions Vector(0))
21/02/17 01:03:42 INFO TaskSchedulerImpl: Adding task set 25.0 with 1 tasks
21/02/17 01:03:42 INFO TaskSetManager: Starting task 0.0 in stage 25.0 (TID 25, localhost, executor driver, partition 0, NODE_LOCAL, 7325 bytes)
21/02/17 01:03:42 INFO Executor: Running task 0.0 in stage 25.0 (TID 25)
21/02/17 01:03:42 INFO ShuffleBlockFetcherIterator: Getting 1 (72.0 B) non-empty blocks including 1 (72.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
21/02/17 01:03:42 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
21/02/17 01:03:42 INFO FileOutputCommitter: File Output Committer Algorithm version is 2
21/02/17 01:03:42 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
21/02/17 01:03:42 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
21/02/17 01:03:42 INFO FileOutputCommitter: File Output Committer Algorithm version is 2
21/02/17 01:03:42 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
21/02/17 01:03:42 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
21/02/17 01:03:42 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:
{
  "type" : "struct",
  "fields" : [ {
    "name" : "columnsToPrune",
    "type" : {
      "type" : "array",
      "elementType" : "string",
      "containsNull" : true
    },
    "nullable" : true,
    "metadata" : { }
  } ]
}
and corresponding Parquet message type:
message spark_schema {
  optional group columnsToPrune (LIST) {
    repeated group list {
      optional binary element (UTF8);
    }
  }
}

       
21/02/17 01:03:42 INFO FileOutputCommitter: Saved output of task 'attempt_20210217010342_0025_m_000000_25' to file:/tmp/RtmpdJZfO0/file1fe9816a0746c/stages/0_r_formula__a8f3fe0a_f74c_4053_97c3_d6d773d4c9bd/pipelineModel/stages/2_columnPruner_b54e3fcdd491/data
21/02/17 01:03:42 INFO SparkHadoopMapRedUtil: attempt_20210217010342_0025_m_000000_25: Committed
21/02/17 01:03:42 INFO Executor: Finished task 0.0 in stage 25.0 (TID 25). 3195 bytes result sent to driver
21/02/17 01:03:42 INFO TaskSetManager: Finished task 0.0 in stage 25.0 (TID 25) in 25 ms on localhost (executor driver) (1/1)
21/02/17 01:03:42 INFO TaskSchedulerImpl: Removed TaskSet 25.0, whose tasks have all completed, from pool 
21/02/17 01:03:42 INFO DAGScheduler: ResultStage 25 (parquet at RFormula.scala:508) finished in 0.044 s
21/02/17 01:03:42 INFO DAGScheduler: Job 19 is finished. Cancelling potential speculative or zombie tasks for this job
21/02/17 01:03:42 INFO TaskSchedulerImpl: Killing all running tasks in stage 25: Stage finished
21/02/17 01:03:42 INFO DAGScheduler: Job 19 finished: parquet at RFormula.scala:508, took 0.057444 s
21/02/17 01:03:42 INFO FileFormatWriter: Write Job 08dec09c-2e72-46eb-89b3-4de04313941b committed.
21/02/17 01:03:42 INFO FileFormatWriter: Finished processing stats for write job 08dec09c-2e72-46eb-89b3-4de04313941b.
21/02/17 01:03:42 INFO Instrumentation: [916b312b] training finished
21/02/17 01:03:42 INFO Instrumentation: [139fa3f6] training finished
21/02/17 01:03:42 INFO HadoopMapRedCommitProtocol: Using output committer class org.apache.hadoop.mapred.FileOutputCommitter
21/02/17 01:03:42 INFO FileOutputCommitter: File Output Committer Algorithm version is 2
21/02/17 01:03:42 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
21/02/17 01:03:42 INFO SparkContext: Starting job: runJob at SparkHadoopWriter.scala:78
21/02/17 01:03:42 INFO DAGScheduler: Got job 20 (runJob at SparkHadoopWriter.scala:78) with 1 output partitions
21/02/17 01:03:42 INFO DAGScheduler: Final stage: ResultStage 26 (runJob at SparkHadoopWriter.scala:78)
21/02/17 01:03:42 INFO DAGScheduler: Parents of final stage: List()
21/02/17 01:03:42 INFO DAGScheduler: Missing parents: List()
21/02/17 01:03:42 INFO DAGScheduler: Submitting ResultStage 26 (MapPartitionsRDD[86] at saveAsTextFile at DefaultXGBoostParamsWriter.scala:52), which has no missing parents
21/02/17 01:03:42 INFO MemoryStore: Block broadcast_27 stored as values in memory (estimated size 84.0 KiB, free 911.0 MiB)
21/02/17 01:03:42 INFO MemoryStore: Block broadcast_27_piece0 stored as bytes in memory (estimated size 30.0 KiB, free 911.0 MiB)
21/02/17 01:03:42 INFO BlockManagerInfo: Added broadcast_27_piece0 in memory on localhost:37167 (size: 30.0 KiB, free: 912.0 MiB)
21/02/17 01:03:42 INFO SparkContext: Created broadcast 27 from broadcast at DAGScheduler.scala:1200
21/02/17 01:03:42 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 26 (MapPartitionsRDD[86] at saveAsTextFile at DefaultXGBoostParamsWriter.scala:52) (first 15 tasks are for partitions Vector(0))
21/02/17 01:03:42 INFO TaskSchedulerImpl: Adding task set 26.0 with 1 tasks
21/02/17 01:03:42 INFO TaskSetManager: Starting task 0.0 in stage 26.0 (TID 26, localhost, executor driver, partition 0, PROCESS_LOCAL, 8635 bytes)
21/02/17 01:03:42 INFO Executor: Running task 0.0 in stage 26.0 (TID 26)
21/02/17 01:03:42 INFO HadoopMapRedCommitProtocol: Using output committer class org.apache.hadoop.mapred.FileOutputCommitter
21/02/17 01:03:42 INFO FileOutputCommitter: File Output Committer Algorithm version is 2
21/02/17 01:03:42 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
21/02/17 01:03:42 INFO FileOutputCommitter: Saved output of task 'attempt_20210217010342_0086_m_000000_0' to file:/tmp/RtmpdJZfO0/file1fe9816a0746c/stages/1_xgboost_regressor__ca0588f9_18d0_4aef_81e6_bf950f6e60ff/metadata
21/02/17 01:03:42 INFO SparkHadoopMapRedUtil: attempt_20210217010342_0086_m_000000_0: Committed
21/02/17 01:03:42 INFO Executor: Finished task 0.0 in stage 26.0 (TID 26). 1158 bytes result sent to driver
21/02/17 01:03:42 INFO TaskSetManager: Finished task 0.0 in stage 26.0 (TID 26) in 13 ms on localhost (executor driver) (1/1)
21/02/17 01:03:42 INFO TaskSchedulerImpl: Removed TaskSet 26.0, whose tasks have all completed, from pool 
21/02/17 01:03:42 INFO DAGScheduler: ResultStage 26 (runJob at SparkHadoopWriter.scala:78) finished in 0.021 s
21/02/17 01:03:42 INFO DAGScheduler: Job 20 is finished. Cancelling potential speculative or zombie tasks for this job
21/02/17 01:03:42 INFO TaskSchedulerImpl: Killing all running tasks in stage 26: Stage finished
21/02/17 01:03:42 INFO DAGScheduler: Job 20 finished: runJob at SparkHadoopWriter.scala:78, took 0.023740 s
21/02/17 01:03:42 INFO SparkHadoopWriter: Job job_20210217010342_0086 committed.
21/02/17 01:03:42 INFO Instrumentation: [37222d96] training finished
21/02/17 01:03:42 INFO Instrumentation: [a081c7ff] training finished
21/02/17 01:03:42 INFO HiveMetaStore: 0: get_database: default
21/02/17 01:03:42 INFO audit: ugi=yitaoli	ip=unknown-ip-addr	cmd=get_database: default	
21/02/17 01:03:42 INFO HiveMetaStore: 0: get_database: default
21/02/17 01:03:42 INFO audit: ugi=yitaoli	ip=unknown-ip-addr	cmd=get_database: default	
21/02/17 01:03:42 INFO HiveMetaStore: 0: get_tables: db=default pat=*
21/02/17 01:03:42 INFO audit: ugi=yitaoli	ip=unknown-ip-addr	cmd=get_tables: db=default pat=*	
21/02/17 01:03:42 INFO CodeGenerator: Code generated in 4.244617 ms
21/02/17 01:03:42 INFO SparkContext: Starting job: collect at utils.scala:54
21/02/17 01:03:42 INFO DAGScheduler: Got job 21 (collect at utils.scala:54) with 2 output partitions
21/02/17 01:03:42 INFO DAGScheduler: Final stage: ResultStage 27 (collect at utils.scala:54)
21/02/17 01:03:42 INFO DAGScheduler: Parents of final stage: List()
21/02/17 01:03:42 INFO DAGScheduler: Missing parents: List()
21/02/17 01:03:42 INFO DAGScheduler: Submitting ResultStage 27 (MapPartitionsRDD[92] at map at utils.scala:54), which has no missing parents
21/02/17 01:03:42 INFO MemoryStore: Block broadcast_28 stored as values in memory (estimated size 10.7 KiB, free 911.0 MiB)
21/02/17 01:03:42 INFO MemoryStore: Block broadcast_28_piece0 stored as bytes in memory (estimated size 4.9 KiB, free 911.0 MiB)
21/02/17 01:03:42 INFO BlockManagerInfo: Added broadcast_28_piece0 in memory on localhost:37167 (size: 4.9 KiB, free: 912.0 MiB)
21/02/17 01:03:42 INFO SparkContext: Created broadcast 28 from broadcast at DAGScheduler.scala:1200
21/02/17 01:03:42 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 27 (MapPartitionsRDD[92] at map at utils.scala:54) (first 15 tasks are for partitions Vector(0, 1))
21/02/17 01:03:42 INFO TaskSchedulerImpl: Adding task set 27.0 with 2 tasks
21/02/17 01:03:42 INFO TaskSetManager: Starting task 0.0 in stage 27.0 (TID 27, localhost, executor driver, partition 0, PROCESS_LOCAL, 7533 bytes)
21/02/17 01:03:42 INFO TaskSetManager: Starting task 1.0 in stage 27.0 (TID 28, localhost, executor driver, partition 1, PROCESS_LOCAL, 7581 bytes)
21/02/17 01:03:42 INFO Executor: Running task 0.0 in stage 27.0 (TID 27)
21/02/17 01:03:42 INFO Executor: Running task 1.0 in stage 27.0 (TID 28)
21/02/17 01:03:42 INFO CodeGenerator: Code generated in 5.882119 ms
21/02/17 01:03:42 INFO Executor: Finished task 0.0 in stage 27.0 (TID 27). 1110 bytes result sent to driver
21/02/17 01:03:42 INFO Executor: Finished task 1.0 in stage 27.0 (TID 28). 1155 bytes result sent to driver
21/02/17 01:03:42 INFO TaskSetManager: Finished task 0.0 in stage 27.0 (TID 27) in 24 ms on localhost (executor driver) (1/2)
21/02/17 01:03:42 INFO TaskSetManager: Finished task 1.0 in stage 27.0 (TID 28) in 25 ms on localhost (executor driver) (2/2)
21/02/17 01:03:42 INFO TaskSchedulerImpl: Removed TaskSet 27.0, whose tasks have all completed, from pool 
21/02/17 01:03:42 INFO DAGScheduler: ResultStage 27 (collect at utils.scala:54) finished in 0.028 s
21/02/17 01:03:42 INFO DAGScheduler: Job 21 is finished. Cancelling potential speculative or zombie tasks for this job
21/02/17 01:03:42 INFO TaskSchedulerImpl: Killing all running tasks in stage 27: Stage finished
21/02/17 01:03:42 INFO DAGScheduler: Job 21 finished: collect at utils.scala:54, took 0.030958 s
21/02/17 01:03:43 INFO InMemoryFileIndex: It took 7 ms to list leaf files for 1 paths.
21/02/17 01:03:43 INFO InMemoryFileIndex: It took 0 ms to list leaf files for 1 paths.
21/02/17 01:03:43 INFO FileSourceStrategy: Pruning directories with: 
21/02/17 01:03:43 INFO FileSourceStrategy: Pushed Filters: 
21/02/17 01:03:43 INFO FileSourceStrategy: Post-Scan Filters: 
21/02/17 01:03:43 INFO FileSourceStrategy: Output Data Schema: struct<value: string>
21/02/17 01:03:43 INFO MemoryStore: Block broadcast_29 stored as values in memory (estimated size 313.9 KiB, free 910.7 MiB)
21/02/17 01:03:43 INFO MemoryStore: Block broadcast_29_piece0 stored as bytes in memory (estimated size 28.3 KiB, free 910.7 MiB)
21/02/17 01:03:43 INFO BlockManagerInfo: Added broadcast_29_piece0 in memory on localhost:37167 (size: 28.3 KiB, free: 911.9 MiB)
21/02/17 01:03:43 INFO SparkContext: Created broadcast 29 from json at NativeMethodAccessorImpl.java:0
21/02/17 01:03:43 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
21/02/17 01:03:43 INFO BlockManagerInfo: Removed broadcast_19_piece0 on localhost:37167 in memory (size: 30.0 KiB, free: 912.0 MiB)
21/02/17 01:03:43 INFO BlockManagerInfo: Removed broadcast_24_piece0 on localhost:37167 in memory (size: 30.0 KiB, free: 912.0 MiB)
21/02/17 01:03:43 INFO BlockManagerInfo: Removed broadcast_22_piece0 on localhost:37167 in memory (size: 4.2 KiB, free: 912.0 MiB)
21/02/17 01:03:43 INFO BlockManagerInfo: Removed broadcast_21_piece0 on localhost:37167 in memory (size: 30.0 KiB, free: 912.0 MiB)
21/02/17 01:03:43 INFO BlockManagerInfo: Removed broadcast_27_piece0 on localhost:37167 in memory (size: 30.0 KiB, free: 912.0 MiB)
21/02/17 01:03:43 INFO BlockManagerInfo: Removed broadcast_23_piece0 on localhost:37167 in memory (size: 61.8 KiB, free: 912.1 MiB)
21/02/17 01:03:43 INFO BlockManagerInfo: Removed broadcast_26_piece0 on localhost:37167 in memory (size: 61.7 KiB, free: 912.2 MiB)
21/02/17 01:03:43 INFO BlockManagerInfo: Removed broadcast_25_piece0 on localhost:37167 in memory (size: 4.1 KiB, free: 912.2 MiB)
21/02/17 01:03:43 INFO BlockManagerInfo: Removed broadcast_28_piece0 on localhost:37167 in memory (size: 4.9 KiB, free: 912.2 MiB)
21/02/17 01:03:43 INFO BlockManagerInfo: Removed broadcast_20_piece0 on localhost:37167 in memory (size: 30.0 KiB, free: 912.2 MiB)
21/02/17 01:03:43 INFO SparkContext: Starting job: json at NativeMethodAccessorImpl.java:0
21/02/17 01:03:43 INFO DAGScheduler: Got job 22 (json at NativeMethodAccessorImpl.java:0) with 1 output partitions
21/02/17 01:03:43 INFO DAGScheduler: Final stage: ResultStage 28 (json at NativeMethodAccessorImpl.java:0)
21/02/17 01:03:43 INFO DAGScheduler: Parents of final stage: List()
21/02/17 01:03:43 INFO DAGScheduler: Missing parents: List()
21/02/17 01:03:43 INFO DAGScheduler: Submitting ResultStage 28 (MapPartitionsRDD[96] at json at NativeMethodAccessorImpl.java:0), which has no missing parents
21/02/17 01:03:43 INFO MemoryStore: Block broadcast_30 stored as values in memory (estimated size 14.4 KiB, free 911.7 MiB)
21/02/17 01:03:43 INFO MemoryStore: Block broadcast_30_piece0 stored as bytes in memory (estimated size 6.8 KiB, free 911.7 MiB)
21/02/17 01:03:43 INFO BlockManagerInfo: Added broadcast_30_piece0 in memory on localhost:37167 (size: 6.8 KiB, free: 912.2 MiB)
21/02/17 01:03:43 INFO SparkContext: Created broadcast 30 from broadcast at DAGScheduler.scala:1200
21/02/17 01:03:43 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 28 (MapPartitionsRDD[96] at json at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
21/02/17 01:03:43 INFO TaskSchedulerImpl: Adding task set 28.0 with 1 tasks
21/02/17 01:03:43 INFO TaskSetManager: Starting task 0.0 in stage 28.0 (TID 29, localhost, executor driver, partition 0, PROCESS_LOCAL, 7757 bytes)
21/02/17 01:03:43 INFO Executor: Running task 0.0 in stage 28.0 (TID 29)
21/02/17 01:03:43 INFO FileScanRDD: Reading File path: file:///tmp/RtmpdJZfO0/file1fe9816a0746c/metadata/part-00000, range: 0-306, partition values: [empty row]
21/02/17 01:03:43 INFO CodeGenerator: Code generated in 4.937109 ms
21/02/17 01:03:43 INFO Executor: Finished task 0.0 in stage 28.0 (TID 29). 2251 bytes result sent to driver
21/02/17 01:03:43 INFO TaskSetManager: Finished task 0.0 in stage 28.0 (TID 29) in 79 ms on localhost (executor driver) (1/1)
21/02/17 01:03:43 INFO TaskSchedulerImpl: Removed TaskSet 28.0, whose tasks have all completed, from pool 
21/02/17 01:03:43 INFO DAGScheduler: ResultStage 28 (json at NativeMethodAccessorImpl.java:0) finished in 0.086 s
21/02/17 01:03:43 INFO DAGScheduler: Job 22 is finished. Cancelling potential speculative or zombie tasks for this job
21/02/17 01:03:43 INFO TaskSchedulerImpl: Killing all running tasks in stage 28: Stage finished
21/02/17 01:03:43 INFO DAGScheduler: Job 22 finished: json at NativeMethodAccessorImpl.java:0, took 0.090322 s
21/02/17 01:03:43 INFO HiveMetaStore: 0: get_database: default
21/02/17 01:03:43 INFO audit: ugi=yitaoli	ip=unknown-ip-addr	cmd=get_database: default	
21/02/17 01:03:43 INFO HiveMetaStore: 0: get_database: default
21/02/17 01:03:43 INFO audit: ugi=yitaoli	ip=unknown-ip-addr	cmd=get_database: default	
21/02/17 01:03:43 INFO HiveMetaStore: 0: get_tables: db=default pat=*
21/02/17 01:03:43 INFO audit: ugi=yitaoli	ip=unknown-ip-addr	cmd=get_tables: db=default pat=*	
21/02/17 01:03:43 INFO CodeGenerator: Code generated in 3.967008 ms
21/02/17 01:03:43 INFO CodeGenerator: Code generated in 4.487976 ms
21/02/17 01:03:43 INFO CodeGenerator: Code generated in 6.002818 ms
21/02/17 01:03:43 INFO CodeGenerator: Code generated in 3.423124 ms
21/02/17 01:03:43 INFO SparkContext: Starting job: count at utils.scala:135
21/02/17 01:03:43 INFO DAGScheduler: Registering RDD 99 (count at utils.scala:135) as input to shuffle 7
21/02/17 01:03:43 INFO DAGScheduler: Got job 23 (count at utils.scala:135) with 1 output partitions
21/02/17 01:03:43 INFO DAGScheduler: Final stage: ResultStage 30 (count at utils.scala:135)
21/02/17 01:03:43 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 29)
21/02/17 01:03:43 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 29)
21/02/17 01:03:43 INFO DAGScheduler: Submitting ShuffleMapStage 29 (MapPartitionsRDD[99] at count at utils.scala:135), which has no missing parents
21/02/17 01:03:43 INFO MemoryStore: Block broadcast_31 stored as values in memory (estimated size 10.1 KiB, free 911.7 MiB)
21/02/17 01:03:43 INFO MemoryStore: Block broadcast_31_piece0 stored as bytes in memory (estimated size 5.3 KiB, free 911.7 MiB)
21/02/17 01:03:43 INFO BlockManagerInfo: Added broadcast_31_piece0 in memory on localhost:37167 (size: 5.3 KiB, free: 912.2 MiB)
21/02/17 01:03:43 INFO SparkContext: Created broadcast 31 from broadcast at DAGScheduler.scala:1200
21/02/17 01:03:43 INFO DAGScheduler: Submitting 2 missing tasks from ShuffleMapStage 29 (MapPartitionsRDD[99] at count at utils.scala:135) (first 15 tasks are for partitions Vector(0, 1))
21/02/17 01:03:43 INFO TaskSchedulerImpl: Adding task set 29.0 with 2 tasks
21/02/17 01:03:43 INFO TaskSetManager: Starting task 0.0 in stage 29.0 (TID 30, localhost, executor driver, partition 0, PROCESS_LOCAL, 7498 bytes)
21/02/17 01:03:43 INFO TaskSetManager: Starting task 1.0 in stage 29.0 (TID 31, localhost, executor driver, partition 1, PROCESS_LOCAL, 7498 bytes)
21/02/17 01:03:43 INFO Executor: Running task 1.0 in stage 29.0 (TID 31)
21/02/17 01:03:43 INFO Executor: Running task 0.0 in stage 29.0 (TID 30)
21/02/17 01:03:43 INFO Executor: Finished task 0.0 in stage 29.0 (TID 30). 1833 bytes result sent to driver
21/02/17 01:03:43 INFO Executor: Finished task 1.0 in stage 29.0 (TID 31). 1833 bytes result sent to driver
21/02/17 01:03:43 INFO TaskSetManager: Finished task 0.0 in stage 29.0 (TID 30) in 9 ms on localhost (executor driver) (1/2)
21/02/17 01:03:43 INFO TaskSetManager: Finished task 1.0 in stage 29.0 (TID 31) in 9 ms on localhost (executor driver) (2/2)
21/02/17 01:03:43 INFO TaskSchedulerImpl: Removed TaskSet 29.0, whose tasks have all completed, from pool 
21/02/17 01:03:43 INFO DAGScheduler: ShuffleMapStage 29 (count at utils.scala:135) finished in 0.012 s
21/02/17 01:03:43 INFO DAGScheduler: looking for newly runnable stages
21/02/17 01:03:43 INFO DAGScheduler: running: Set()
21/02/17 01:03:43 INFO DAGScheduler: waiting: Set(ResultStage 30)
21/02/17 01:03:43 INFO DAGScheduler: failed: Set()
21/02/17 01:03:43 INFO DAGScheduler: Submitting ResultStage 30 (MapPartitionsRDD[102] at count at utils.scala:135), which has no missing parents
21/02/17 01:03:43 INFO MemoryStore: Block broadcast_32 stored as values in memory (estimated size 10.1 KiB, free 911.7 MiB)
21/02/17 01:03:43 INFO MemoryStore: Block broadcast_32_piece0 stored as bytes in memory (estimated size 5.0 KiB, free 911.7 MiB)
21/02/17 01:03:43 INFO BlockManagerInfo: Added broadcast_32_piece0 in memory on localhost:37167 (size: 5.0 KiB, free: 912.2 MiB)
21/02/17 01:03:43 INFO SparkContext: Created broadcast 32 from broadcast at DAGScheduler.scala:1200
21/02/17 01:03:43 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 30 (MapPartitionsRDD[102] at count at utils.scala:135) (first 15 tasks are for partitions Vector(0))
21/02/17 01:03:43 INFO TaskSchedulerImpl: Adding task set 30.0 with 1 tasks
21/02/17 01:03:43 INFO TaskSetManager: Starting task 0.0 in stage 30.0 (TID 32, localhost, executor driver, partition 0, NODE_LOCAL, 7325 bytes)
21/02/17 01:03:43 INFO Executor: Running task 0.0 in stage 30.0 (TID 32)
21/02/17 01:03:43 INFO ShuffleBlockFetcherIterator: Getting 2 (120.0 B) non-empty blocks including 2 (120.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
21/02/17 01:03:43 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
21/02/17 01:03:43 INFO Executor: Finished task 0.0 in stage 30.0 (TID 32). 2648 bytes result sent to driver
21/02/17 01:03:43 INFO TaskSetManager: Finished task 0.0 in stage 30.0 (TID 32) in 5 ms on localhost (executor driver) (1/1)
21/02/17 01:03:43 INFO TaskSchedulerImpl: Removed TaskSet 30.0, whose tasks have all completed, from pool 
21/02/17 01:03:43 INFO DAGScheduler: ResultStage 30 (count at utils.scala:135) finished in 0.009 s
21/02/17 01:03:43 INFO DAGScheduler: Job 23 is finished. Cancelling potential speculative or zombie tasks for this job
21/02/17 01:03:43 INFO TaskSchedulerImpl: Killing all running tasks in stage 30: Stage finished
21/02/17 01:03:43 INFO DAGScheduler: Job 23 finished: count at utils.scala:135, took 0.024366 s
21/02/17 01:03:43 INFO FileSourceStrategy: Pruning directories with: 
21/02/17 01:03:43 INFO FileSourceStrategy: Pushed Filters: 
21/02/17 01:03:43 INFO FileSourceStrategy: Post-Scan Filters: 
21/02/17 01:03:43 INFO FileSourceStrategy: Output Data Schema: struct<class: string, paramMap: struct<stageUids: array<string>>, sparkVersion: string, timestamp: bigint, uid: string ... 3 more fields>
21/02/17 01:03:43 INFO CodeGenerator: Code generated in 6.084781 ms
21/02/17 01:03:43 INFO MemoryStore: Block broadcast_33 stored as values in memory (estimated size 313.9 KiB, free 911.4 MiB)
21/02/17 01:03:43 INFO MemoryStore: Block broadcast_33_piece0 stored as bytes in memory (estimated size 28.3 KiB, free 911.3 MiB)
21/02/17 01:03:43 INFO BlockManagerInfo: Added broadcast_33_piece0 in memory on localhost:37167 (size: 28.3 KiB, free: 912.2 MiB)
21/02/17 01:03:43 INFO SparkContext: Created broadcast 33 from sql at <unknown>:0
21/02/17 01:03:43 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
21/02/17 01:03:43 INFO SparkContext: Starting job: sql at <unknown>:0
21/02/17 01:03:43 INFO DAGScheduler: Registering RDD 109 (sql at <unknown>:0) as input to shuffle 8
21/02/17 01:03:43 INFO DAGScheduler: Got job 24 (sql at <unknown>:0) with 1 output partitions
21/02/17 01:03:43 INFO DAGScheduler: Final stage: ResultStage 32 (sql at <unknown>:0)
21/02/17 01:03:43 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 31)
21/02/17 01:03:43 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 31)
21/02/17 01:03:43 INFO DAGScheduler: Submitting ShuffleMapStage 31 (MapPartitionsRDD[109] at sql at <unknown>:0), which has no missing parents
21/02/17 01:03:43 INFO MemoryStore: Block broadcast_34 stored as values in memory (estimated size 21.5 KiB, free 911.3 MiB)
21/02/17 01:03:43 INFO MemoryStore: Block broadcast_34_piece0 stored as bytes in memory (estimated size 10.1 KiB, free 911.3 MiB)
21/02/17 01:03:43 INFO BlockManagerInfo: Added broadcast_34_piece0 in memory on localhost:37167 (size: 10.1 KiB, free: 912.2 MiB)
21/02/17 01:03:43 INFO SparkContext: Created broadcast 34 from broadcast at DAGScheduler.scala:1200
21/02/17 01:03:43 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 31 (MapPartitionsRDD[109] at sql at <unknown>:0) (first 15 tasks are for partitions Vector(0))
21/02/17 01:03:43 INFO TaskSchedulerImpl: Adding task set 31.0 with 1 tasks
21/02/17 01:03:43 INFO TaskSetManager: Starting task 0.0 in stage 31.0 (TID 33, localhost, executor driver, partition 0, PROCESS_LOCAL, 7746 bytes)
21/02/17 01:03:43 INFO Executor: Running task 0.0 in stage 31.0 (TID 33)
21/02/17 01:03:43 INFO FileScanRDD: Reading File path: file:///tmp/RtmpdJZfO0/file1fe9816a0746c/metadata/part-00000, range: 0-306, partition values: [empty row]
21/02/17 01:03:43 INFO CodeGenerator: Code generated in 6.784433 ms
21/02/17 01:03:43 INFO MemoryStore: Block rdd_105_0 stored as values in memory (estimated size 1296.0 B, free 911.3 MiB)
21/02/17 01:03:43 INFO BlockManagerInfo: Added rdd_105_0 in memory on localhost:37167 (size: 1296.0 B, free: 912.2 MiB)
21/02/17 01:03:43 INFO CodeGenerator: Code generated in 7.650226 ms
21/02/17 01:03:43 INFO Executor: Finished task 0.0 in stage 31.0 (TID 33). 2067 bytes result sent to driver
21/02/17 01:03:43 INFO TaskSetManager: Finished task 0.0 in stage 31.0 (TID 33) in 48 ms on localhost (executor driver) (1/1)
21/02/17 01:03:43 INFO TaskSchedulerImpl: Removed TaskSet 31.0, whose tasks have all completed, from pool 
21/02/17 01:03:43 INFO DAGScheduler: ShuffleMapStage 31 (sql at <unknown>:0) finished in 0.056 s
21/02/17 01:03:43 INFO DAGScheduler: looking for newly runnable stages
21/02/17 01:03:43 INFO DAGScheduler: running: Set()
21/02/17 01:03:43 INFO DAGScheduler: waiting: Set(ResultStage 32)
21/02/17 01:03:43 INFO DAGScheduler: failed: Set()
21/02/17 01:03:43 INFO DAGScheduler: Submitting ResultStage 32 (MapPartitionsRDD[112] at sql at <unknown>:0), which has no missing parents
21/02/17 01:03:43 INFO MemoryStore: Block broadcast_35 stored as values in memory (estimated size 10.1 KiB, free 911.3 MiB)
21/02/17 01:03:43 INFO MemoryStore: Block broadcast_35_piece0 stored as bytes in memory (estimated size 5.0 KiB, free 911.3 MiB)
21/02/17 01:03:43 INFO BlockManagerInfo: Added broadcast_35_piece0 in memory on localhost:37167 (size: 5.0 KiB, free: 912.1 MiB)
21/02/17 01:03:43 INFO SparkContext: Created broadcast 35 from broadcast at DAGScheduler.scala:1200
21/02/17 01:03:43 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 32 (MapPartitionsRDD[112] at sql at <unknown>:0) (first 15 tasks are for partitions Vector(0))
21/02/17 01:03:43 INFO TaskSchedulerImpl: Adding task set 32.0 with 1 tasks
21/02/17 01:03:43 INFO TaskSetManager: Starting task 0.0 in stage 32.0 (TID 34, localhost, executor driver, partition 0, NODE_LOCAL, 7325 bytes)
21/02/17 01:03:43 INFO Executor: Running task 0.0 in stage 32.0 (TID 34)
21/02/17 01:03:43 INFO ShuffleBlockFetcherIterator: Getting 1 (60.0 B) non-empty blocks including 1 (60.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
21/02/17 01:03:43 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
21/02/17 01:03:43 INFO Executor: Finished task 0.0 in stage 32.0 (TID 34). 2648 bytes result sent to driver
21/02/17 01:03:43 INFO TaskSetManager: Finished task 0.0 in stage 32.0 (TID 34) in 4 ms on localhost (executor driver) (1/1)
21/02/17 01:03:43 INFO TaskSchedulerImpl: Removed TaskSet 32.0, whose tasks have all completed, from pool 
21/02/17 01:03:43 INFO DAGScheduler: ResultStage 32 (sql at <unknown>:0) finished in 0.008 s
21/02/17 01:03:43 INFO DAGScheduler: Job 24 is finished. Cancelling potential speculative or zombie tasks for this job
21/02/17 01:03:43 INFO TaskSchedulerImpl: Killing all running tasks in stage 32: Stage finished
21/02/17 01:03:43 INFO DAGScheduler: Job 24 finished: sql at <unknown>:0, took 0.068138 s
21/02/17 01:03:43 INFO SparkContext: Starting job: collect at utils.scala:137
21/02/17 01:03:43 INFO DAGScheduler: Registering RDD 116 (collect at utils.scala:137) as input to shuffle 9
21/02/17 01:03:43 INFO DAGScheduler: Got job 25 (collect at utils.scala:137) with 1 output partitions
21/02/17 01:03:43 INFO DAGScheduler: Final stage: ResultStage 34 (collect at utils.scala:137)
21/02/17 01:03:43 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 33)
21/02/17 01:03:43 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 33)
21/02/17 01:03:43 INFO DAGScheduler: Submitting ShuffleMapStage 33 (MapPartitionsRDD[116] at collect at utils.scala:137), which has no missing parents
21/02/17 01:03:43 INFO MemoryStore: Block broadcast_36 stored as values in memory (estimated size 21.5 KiB, free 911.3 MiB)
21/02/17 01:03:43 INFO MemoryStore: Block broadcast_36_piece0 stored as bytes in memory (estimated size 10.1 KiB, free 911.3 MiB)
21/02/17 01:03:43 INFO BlockManagerInfo: Added broadcast_36_piece0 in memory on localhost:37167 (size: 10.1 KiB, free: 912.1 MiB)
21/02/17 01:03:43 INFO SparkContext: Created broadcast 36 from broadcast at DAGScheduler.scala:1200
21/02/17 01:03:43 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 33 (MapPartitionsRDD[116] at collect at utils.scala:137) (first 15 tasks are for partitions Vector(0))
21/02/17 01:03:43 INFO TaskSchedulerImpl: Adding task set 33.0 with 1 tasks
21/02/17 01:03:43 INFO TaskSetManager: Starting task 0.0 in stage 33.0 (TID 35, localhost, executor driver, partition 0, PROCESS_LOCAL, 7746 bytes)
21/02/17 01:03:43 INFO Executor: Running task 0.0 in stage 33.0 (TID 35)
21/02/17 01:03:43 INFO BlockManager: Found block rdd_105_0 locally
21/02/17 01:03:43 INFO Executor: Finished task 0.0 in stage 33.0 (TID 35). 2067 bytes result sent to driver
21/02/17 01:03:43 INFO TaskSetManager: Finished task 0.0 in stage 33.0 (TID 35) in 6 ms on localhost (executor driver) (1/1)
21/02/17 01:03:43 INFO TaskSchedulerImpl: Removed TaskSet 33.0, whose tasks have all completed, from pool 
21/02/17 01:03:43 INFO DAGScheduler: ShuffleMapStage 33 (collect at utils.scala:137) finished in 0.011 s
21/02/17 01:03:43 INFO DAGScheduler: looking for newly runnable stages
21/02/17 01:03:43 INFO DAGScheduler: running: Set()
21/02/17 01:03:43 INFO DAGScheduler: waiting: Set(ResultStage 34)
21/02/17 01:03:43 INFO DAGScheduler: failed: Set()
21/02/17 01:03:43 INFO DAGScheduler: Submitting ResultStage 34 (MapPartitionsRDD[119] at collect at utils.scala:137), which has no missing parents
21/02/17 01:03:43 INFO MemoryStore: Block broadcast_37 stored as values in memory (estimated size 10.1 KiB, free 911.3 MiB)
21/02/17 01:03:43 INFO MemoryStore: Block broadcast_37_piece0 stored as bytes in memory (estimated size 5.0 KiB, free 911.3 MiB)
21/02/17 01:03:43 INFO BlockManagerInfo: Added broadcast_37_piece0 in memory on localhost:37167 (size: 5.0 KiB, free: 912.1 MiB)
21/02/17 01:03:43 INFO SparkContext: Created broadcast 37 from broadcast at DAGScheduler.scala:1200
21/02/17 01:03:43 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 34 (MapPartitionsRDD[119] at collect at utils.scala:137) (first 15 tasks are for partitions Vector(0))
21/02/17 01:03:43 INFO TaskSchedulerImpl: Adding task set 34.0 with 1 tasks
21/02/17 01:03:43 INFO TaskSetManager: Starting task 0.0 in stage 34.0 (TID 36, localhost, executor driver, partition 0, NODE_LOCAL, 7325 bytes)
21/02/17 01:03:43 INFO Executor: Running task 0.0 in stage 34.0 (TID 36)
21/02/17 01:03:43 INFO ShuffleBlockFetcherIterator: Getting 1 (60.0 B) non-empty blocks including 1 (60.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
21/02/17 01:03:43 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
21/02/17 01:03:43 INFO Executor: Finished task 0.0 in stage 34.0 (TID 36). 2648 bytes result sent to driver
21/02/17 01:03:43 INFO TaskSetManager: Finished task 0.0 in stage 34.0 (TID 36) in 5 ms on localhost (executor driver) (1/1)
21/02/17 01:03:43 INFO TaskSchedulerImpl: Removed TaskSet 34.0, whose tasks have all completed, from pool 
21/02/17 01:03:43 INFO DAGScheduler: ResultStage 34 (collect at utils.scala:137) finished in 0.008 s
21/02/17 01:03:43 INFO DAGScheduler: Job 25 is finished. Cancelling potential speculative or zombie tasks for this job
21/02/17 01:03:43 INFO TaskSchedulerImpl: Killing all running tasks in stage 34: Stage finished
21/02/17 01:03:43 INFO DAGScheduler: Job 25 finished: collect at utils.scala:137, took 0.023509 s
21/02/17 01:03:43 INFO CodeGenerator: Code generated in 4.582299 ms
21/02/17 01:03:43 INFO CodeGenerator: Code generated in 7.296599 ms
21/02/17 01:03:43 INFO CodeGenerator: Code generated in 5.333245 ms
21/02/17 01:03:43 INFO SparkContext: Starting job: count at utils.scala:135
21/02/17 01:03:43 INFO DAGScheduler: Registering RDD 123 (count at utils.scala:135) as input to shuffle 10
21/02/17 01:03:43 INFO DAGScheduler: Got job 26 (count at utils.scala:135) with 1 output partitions
21/02/17 01:03:43 INFO DAGScheduler: Final stage: ResultStage 36 (count at utils.scala:135)
21/02/17 01:03:43 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 35)
21/02/17 01:03:43 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 35)
21/02/17 01:03:43 INFO DAGScheduler: Submitting ShuffleMapStage 35 (MapPartitionsRDD[123] at count at utils.scala:135), which has no missing parents
21/02/17 01:03:43 INFO MemoryStore: Block broadcast_38 stored as values in memory (estimated size 20.9 KiB, free 911.2 MiB)
21/02/17 01:03:43 INFO MemoryStore: Block broadcast_38_piece0 stored as bytes in memory (estimated size 9.9 KiB, free 911.2 MiB)
21/02/17 01:03:43 INFO BlockManagerInfo: Added broadcast_38_piece0 in memory on localhost:37167 (size: 9.9 KiB, free: 912.1 MiB)
21/02/17 01:03:43 INFO SparkContext: Created broadcast 38 from broadcast at DAGScheduler.scala:1200
21/02/17 01:03:43 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 35 (MapPartitionsRDD[123] at count at utils.scala:135) (first 15 tasks are for partitions Vector(0))
21/02/17 01:03:43 INFO TaskSchedulerImpl: Adding task set 35.0 with 1 tasks
21/02/17 01:03:43 INFO TaskSetManager: Starting task 0.0 in stage 35.0 (TID 37, localhost, executor driver, partition 0, PROCESS_LOCAL, 7746 bytes)
21/02/17 01:03:43 INFO Executor: Running task 0.0 in stage 35.0 (TID 37)
21/02/17 01:03:43 INFO BlockManager: Found block rdd_105_0 locally
21/02/17 01:03:43 INFO Executor: Finished task 0.0 in stage 35.0 (TID 37). 2067 bytes result sent to driver
21/02/17 01:03:43 INFO TaskSetManager: Finished task 0.0 in stage 35.0 (TID 37) in 7 ms on localhost (executor driver) (1/1)
21/02/17 01:03:43 INFO TaskSchedulerImpl: Removed TaskSet 35.0, whose tasks have all completed, from pool 
21/02/17 01:03:43 INFO DAGScheduler: ShuffleMapStage 35 (count at utils.scala:135) finished in 0.013 s
21/02/17 01:03:43 INFO DAGScheduler: looking for newly runnable stages
21/02/17 01:03:43 INFO DAGScheduler: running: Set()
21/02/17 01:03:43 INFO DAGScheduler: waiting: Set(ResultStage 36)
21/02/17 01:03:43 INFO DAGScheduler: failed: Set()
21/02/17 01:03:43 INFO DAGScheduler: Submitting ResultStage 36 (MapPartitionsRDD[126] at count at utils.scala:135), which has no missing parents
21/02/17 01:03:43 INFO MemoryStore: Block broadcast_39 stored as values in memory (estimated size 12.1 KiB, free 911.2 MiB)
21/02/17 01:03:43 INFO MemoryStore: Block broadcast_39_piece0 stored as bytes in memory (estimated size 5.3 KiB, free 911.2 MiB)
21/02/17 01:03:43 INFO BlockManagerInfo: Added broadcast_39_piece0 in memory on localhost:37167 (size: 5.3 KiB, free: 912.1 MiB)
21/02/17 01:03:43 INFO SparkContext: Created broadcast 39 from broadcast at DAGScheduler.scala:1200
21/02/17 01:03:43 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 36 (MapPartitionsRDD[126] at count at utils.scala:135) (first 15 tasks are for partitions Vector(0))
21/02/17 01:03:43 INFO TaskSchedulerImpl: Adding task set 36.0 with 1 tasks
21/02/17 01:03:43 INFO TaskSetManager: Starting task 0.0 in stage 36.0 (TID 38, localhost, executor driver, partition 0, NODE_LOCAL, 7325 bytes)
21/02/17 01:03:43 INFO Executor: Running task 0.0 in stage 36.0 (TID 38)
21/02/17 01:03:43 INFO ShuffleBlockFetcherIterator: Getting 1 (49.0 B) non-empty blocks including 1 (49.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
21/02/17 01:03:43 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
21/02/17 01:03:43 INFO Executor: Finished task 0.0 in stage 36.0 (TID 38). 2896 bytes result sent to driver
21/02/17 01:03:43 INFO TaskSetManager: Finished task 0.0 in stage 36.0 (TID 38) in 6 ms on localhost (executor driver) (1/1)
21/02/17 01:03:43 INFO TaskSchedulerImpl: Removed TaskSet 36.0, whose tasks have all completed, from pool 
21/02/17 01:03:43 INFO DAGScheduler: ResultStage 36 (count at utils.scala:135) finished in 0.010 s
21/02/17 01:03:43 INFO DAGScheduler: Job 26 is finished. Cancelling potential speculative or zombie tasks for this job
21/02/17 01:03:43 INFO TaskSchedulerImpl: Killing all running tasks in stage 36: Stage finished
21/02/17 01:03:43 INFO DAGScheduler: Job 26 finished: count at utils.scala:135, took 0.026432 s
21/02/17 01:03:43 INFO SparkContext: Starting job: collect at utils.scala:137
21/02/17 01:03:43 INFO DAGScheduler: Got job 27 (collect at utils.scala:137) with 1 output partitions
21/02/17 01:03:43 INFO DAGScheduler: Final stage: ResultStage 37 (collect at utils.scala:137)
21/02/17 01:03:43 INFO DAGScheduler: Parents of final stage: List()
21/02/17 01:03:43 INFO DAGScheduler: Missing parents: List()
21/02/17 01:03:43 INFO DAGScheduler: Submitting ResultStage 37 (MapPartitionsRDD[128] at collect at utils.scala:137), which has no missing parents
21/02/17 01:03:43 INFO MemoryStore: Block broadcast_40 stored as values in memory (estimated size 7.2 KiB, free 911.2 MiB)
21/02/17 01:03:43 INFO MemoryStore: Block broadcast_40_piece0 stored as bytes in memory (estimated size 3.7 KiB, free 911.2 MiB)
21/02/17 01:03:43 INFO BlockManagerInfo: Added broadcast_40_piece0 in memory on localhost:37167 (size: 3.7 KiB, free: 912.1 MiB)
21/02/17 01:03:43 INFO SparkContext: Created broadcast 40 from broadcast at DAGScheduler.scala:1200
21/02/17 01:03:43 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 37 (MapPartitionsRDD[128] at collect at utils.scala:137) (first 15 tasks are for partitions Vector(0))
21/02/17 01:03:43 INFO TaskSchedulerImpl: Adding task set 37.0 with 1 tasks
21/02/17 01:03:43 INFO TaskSetManager: Starting task 0.0 in stage 37.0 (TID 39, localhost, executor driver, partition 0, PROCESS_LOCAL, 7561 bytes)
21/02/17 01:03:43 INFO Executor: Running task 0.0 in stage 37.0 (TID 39)
21/02/17 01:03:43 INFO Executor: Finished task 0.0 in stage 37.0 (TID 39). 1354 bytes result sent to driver
21/02/17 01:03:43 INFO TaskSetManager: Finished task 0.0 in stage 37.0 (TID 39) in 4 ms on localhost (executor driver) (1/1)
21/02/17 01:03:43 INFO TaskSchedulerImpl: Removed TaskSet 37.0, whose tasks have all completed, from pool 
21/02/17 01:03:43 INFO DAGScheduler: ResultStage 37 (collect at utils.scala:137) finished in 0.008 s
21/02/17 01:03:43 INFO DAGScheduler: Job 27 is finished. Cancelling potential speculative or zombie tasks for this job
21/02/17 01:03:43 INFO TaskSchedulerImpl: Killing all running tasks in stage 37: Stage finished
21/02/17 01:03:43 INFO DAGScheduler: Job 27 finished: collect at utils.scala:137, took 0.009718 s
21/02/17 01:03:43 INFO SparkContext: Starting job: count at utils.scala:135
21/02/17 01:03:43 INFO DAGScheduler: Registering RDD 130 (count at utils.scala:135) as input to shuffle 11
21/02/17 01:03:43 INFO DAGScheduler: Got job 28 (count at utils.scala:135) with 1 output partitions
21/02/17 01:03:43 INFO DAGScheduler: Final stage: ResultStage 39 (count at utils.scala:135)
21/02/17 01:03:43 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 38)
21/02/17 01:03:43 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 38)
21/02/17 01:03:43 INFO DAGScheduler: Submitting ShuffleMapStage 38 (MapPartitionsRDD[130] at count at utils.scala:135), which has no missing parents
21/02/17 01:03:43 INFO MemoryStore: Block broadcast_41 stored as values in memory (estimated size 10.0 KiB, free 911.2 MiB)
21/02/17 01:03:43 INFO MemoryStore: Block broadcast_41_piece0 stored as bytes in memory (estimated size 5.2 KiB, free 911.2 MiB)
21/02/17 01:03:43 INFO BlockManagerInfo: Added broadcast_41_piece0 in memory on localhost:37167 (size: 5.2 KiB, free: 912.1 MiB)
21/02/17 01:03:43 INFO SparkContext: Created broadcast 41 from broadcast at DAGScheduler.scala:1200
21/02/17 01:03:43 INFO BlockManagerInfo: Removed broadcast_35_piece0 on localhost:37167 in memory (size: 5.0 KiB, free: 912.1 MiB)
21/02/17 01:03:43 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 38 (MapPartitionsRDD[130] at count at utils.scala:135) (first 15 tasks are for partitions Vector(0))
21/02/17 01:03:43 INFO TaskSchedulerImpl: Adding task set 38.0 with 1 tasks
21/02/17 01:03:43 INFO TaskSetManager: Starting task 0.0 in stage 38.0 (TID 40, localhost, executor driver, partition 0, PROCESS_LOCAL, 7550 bytes)
21/02/17 01:03:43 INFO Executor: Running task 0.0 in stage 38.0 (TID 40)
21/02/17 01:03:43 INFO BlockManagerInfo: Removed broadcast_39_piece0 on localhost:37167 in memory (size: 5.3 KiB, free: 912.1 MiB)
21/02/17 01:03:43 INFO BlockManagerInfo: Removed broadcast_31_piece0 on localhost:37167 in memory (size: 5.3 KiB, free: 912.1 MiB)
21/02/17 01:03:43 INFO BlockManagerInfo: Removed broadcast_32_piece0 on localhost:37167 in memory (size: 5.0 KiB, free: 912.1 MiB)
21/02/17 01:03:43 INFO Executor: Finished task 0.0 in stage 38.0 (TID 40). 1833 bytes result sent to driver
21/02/17 01:03:43 INFO TaskSetManager: Finished task 0.0 in stage 38.0 (TID 40) in 5 ms on localhost (executor driver) (1/1)
21/02/17 01:03:43 INFO TaskSchedulerImpl: Removed TaskSet 38.0, whose tasks have all completed, from pool 
21/02/17 01:03:43 INFO DAGScheduler: ShuffleMapStage 38 (count at utils.scala:135) finished in 0.017 s
21/02/17 01:03:43 INFO DAGScheduler: looking for newly runnable stages
21/02/17 01:03:43 INFO DAGScheduler: running: Set()
21/02/17 01:03:43 INFO DAGScheduler: waiting: Set(ResultStage 39)
21/02/17 01:03:43 INFO DAGScheduler: failed: Set()
21/02/17 01:03:43 INFO BlockManagerInfo: Removed broadcast_38_piece0 on localhost:37167 in memory (size: 9.9 KiB, free: 912.1 MiB)
21/02/17 01:03:43 INFO DAGScheduler: Submitting ResultStage 39 (MapPartitionsRDD[133] at count at utils.scala:135), which has no missing parents
21/02/17 01:03:43 INFO BlockManagerInfo: Removed broadcast_34_piece0 on localhost:37167 in memory (size: 10.1 KiB, free: 912.1 MiB)
21/02/17 01:03:43 INFO MemoryStore: Block broadcast_42 stored as values in memory (estimated size 10.1 KiB, free 911.3 MiB)
21/02/17 01:03:43 INFO MemoryStore: Block broadcast_42_piece0 stored as bytes in memory (estimated size 5.0 KiB, free 911.3 MiB)
21/02/17 01:03:43 INFO BlockManagerInfo: Removed broadcast_40_piece0 on localhost:37167 in memory (size: 3.7 KiB, free: 912.2 MiB)
21/02/17 01:03:43 INFO BlockManagerInfo: Added broadcast_42_piece0 in memory on localhost:37167 (size: 5.0 KiB, free: 912.1 MiB)
21/02/17 01:03:43 INFO SparkContext: Created broadcast 42 from broadcast at DAGScheduler.scala:1200
21/02/17 01:03:43 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 39 (MapPartitionsRDD[133] at count at utils.scala:135) (first 15 tasks are for partitions Vector(0))
21/02/17 01:03:43 INFO TaskSchedulerImpl: Adding task set 39.0 with 1 tasks
21/02/17 01:03:43 INFO BlockManagerInfo: Removed broadcast_30_piece0 on localhost:37167 in memory (size: 6.8 KiB, free: 912.2 MiB)
21/02/17 01:03:43 INFO TaskSetManager: Starting task 0.0 in stage 39.0 (TID 41, localhost, executor driver, partition 0, NODE_LOCAL, 7325 bytes)
21/02/17 01:03:43 INFO Executor: Running task 0.0 in stage 39.0 (TID 41)
21/02/17 01:03:43 INFO BlockManagerInfo: Removed broadcast_37_piece0 on localhost:37167 in memory (size: 5.0 KiB, free: 912.2 MiB)
21/02/17 01:03:43 INFO ShuffleBlockFetcherIterator: Getting 1 (60.0 B) non-empty blocks including 1 (60.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
21/02/17 01:03:43 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
21/02/17 01:03:43 INFO BlockManagerInfo: Removed broadcast_36_piece0 on localhost:37167 in memory (size: 10.1 KiB, free: 912.2 MiB)
21/02/17 01:03:43 INFO BlockManagerInfo: Removed broadcast_29_piece0 on localhost:37167 in memory (size: 28.3 KiB, free: 912.2 MiB)
21/02/17 01:03:43 INFO Executor: Finished task 0.0 in stage 39.0 (TID 41). 2648 bytes result sent to driver
21/02/17 01:03:43 INFO TaskSetManager: Finished task 0.0 in stage 39.0 (TID 41) in 7 ms on localhost (executor driver) (1/1)
21/02/17 01:03:43 INFO TaskSchedulerImpl: Removed TaskSet 39.0, whose tasks have all completed, from pool 
21/02/17 01:03:43 INFO DAGScheduler: ResultStage 39 (count at utils.scala:135) finished in 0.013 s
21/02/17 01:03:43 INFO DAGScheduler: Job 28 is finished. Cancelling potential speculative or zombie tasks for this job
21/02/17 01:03:43 INFO TaskSchedulerImpl: Killing all running tasks in stage 39: Stage finished
21/02/17 01:03:43 INFO DAGScheduler: Job 28 finished: count at utils.scala:135, took 0.032829 s
21/02/17 01:03:44 INFO SparkContext: Starting job: collect at utils.scala:137
21/02/17 01:03:44 INFO DAGScheduler: Got job 29 (collect at utils.scala:137) with 1 output partitions
21/02/17 01:03:44 INFO DAGScheduler: Final stage: ResultStage 40 (collect at utils.scala:137)
21/02/17 01:03:44 INFO DAGScheduler: Parents of final stage: List()
21/02/17 01:03:44 INFO DAGScheduler: Missing parents: List()
21/02/17 01:03:44 INFO DAGScheduler: Submitting ResultStage 40 (MapPartitionsRDD[136] at collect at utils.scala:137), which has no missing parents
21/02/17 01:03:44 INFO MemoryStore: Block broadcast_43 stored as values in memory (estimated size 16.7 KiB, free 911.7 MiB)
21/02/17 01:03:44 INFO MemoryStore: Block broadcast_43_piece0 stored as bytes in memory (estimated size 8.0 KiB, free 911.7 MiB)
21/02/17 01:03:44 INFO BlockManagerInfo: Added broadcast_43_piece0 in memory on localhost:37167 (size: 8.0 KiB, free: 912.2 MiB)
21/02/17 01:03:44 INFO SparkContext: Created broadcast 43 from broadcast at DAGScheduler.scala:1200
21/02/17 01:03:44 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 40 (MapPartitionsRDD[136] at collect at utils.scala:137) (first 15 tasks are for partitions Vector(0))
21/02/17 01:03:44 INFO TaskSchedulerImpl: Adding task set 40.0 with 1 tasks
21/02/17 01:03:44 INFO TaskSetManager: Starting task 0.0 in stage 40.0 (TID 42, localhost, executor driver, partition 0, PROCESS_LOCAL, 7757 bytes)
21/02/17 01:03:44 INFO Executor: Running task 0.0 in stage 40.0 (TID 42)
21/02/17 01:03:44 INFO BlockManager: Found block rdd_105_0 locally
21/02/17 01:03:44 INFO CodeGenerator: Code generated in 8.193038 ms
21/02/17 01:03:44 INFO Executor: Finished task 0.0 in stage 40.0 (TID 42). 1606 bytes result sent to driver
21/02/17 01:03:44 INFO TaskSetManager: Finished task 0.0 in stage 40.0 (TID 42) in 15 ms on localhost (executor driver) (1/1)
21/02/17 01:03:44 INFO TaskSchedulerImpl: Removed TaskSet 40.0, whose tasks have all completed, from pool 
21/02/17 01:03:44 INFO DAGScheduler: ResultStage 40 (collect at utils.scala:137) finished in 0.018 s
21/02/17 01:03:44 INFO DAGScheduler: Job 29 is finished. Cancelling potential speculative or zombie tasks for this job
21/02/17 01:03:44 INFO TaskSchedulerImpl: Killing all running tasks in stage 40: Stage finished
21/02/17 01:03:44 INFO DAGScheduler: Job 29 finished: collect at utils.scala:137, took 0.020555 s
21/02/17 01:03:44 INFO CodeGenerator: Code generated in 4.670565 ms
21/02/17 01:03:44 INFO SparkContext: Starting job: count at utils.scala:135
21/02/17 01:03:44 INFO DAGScheduler: Registering RDD 140 (count at utils.scala:135) as input to shuffle 12
21/02/17 01:03:44 INFO DAGScheduler: Got job 30 (count at utils.scala:135) with 1 output partitions
21/02/17 01:03:44 INFO DAGScheduler: Final stage: ResultStage 42 (count at utils.scala:135)
21/02/17 01:03:44 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 41)
21/02/17 01:03:44 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 41)
21/02/17 01:03:44 INFO DAGScheduler: Submitting ShuffleMapStage 41 (MapPartitionsRDD[140] at count at utils.scala:135), which has no missing parents
21/02/17 01:03:44 INFO MemoryStore: Block broadcast_44 stored as values in memory (estimated size 21.5 KiB, free 911.7 MiB)
21/02/17 01:03:44 INFO MemoryStore: Block broadcast_44_piece0 stored as bytes in memory (estimated size 10.1 KiB, free 911.6 MiB)
21/02/17 01:03:44 INFO BlockManagerInfo: Added broadcast_44_piece0 in memory on localhost:37167 (size: 10.1 KiB, free: 912.2 MiB)
21/02/17 01:03:44 INFO SparkContext: Created broadcast 44 from broadcast at DAGScheduler.scala:1200
21/02/17 01:03:44 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 41 (MapPartitionsRDD[140] at count at utils.scala:135) (first 15 tasks are for partitions Vector(0))
21/02/17 01:03:44 INFO TaskSchedulerImpl: Adding task set 41.0 with 1 tasks
21/02/17 01:03:44 INFO TaskSetManager: Starting task 0.0 in stage 41.0 (TID 43, localhost, executor driver, partition 0, PROCESS_LOCAL, 7746 bytes)
21/02/17 01:03:44 INFO Executor: Running task 0.0 in stage 41.0 (TID 43)
21/02/17 01:03:44 INFO BlockManager: Found block rdd_105_0 locally
21/02/17 01:03:44 INFO Executor: Finished task 0.0 in stage 41.0 (TID 43). 2067 bytes result sent to driver
21/02/17 01:03:44 INFO TaskSetManager: Finished task 0.0 in stage 41.0 (TID 43) in 8 ms on localhost (executor driver) (1/1)
21/02/17 01:03:44 INFO TaskSchedulerImpl: Removed TaskSet 41.0, whose tasks have all completed, from pool 
21/02/17 01:03:44 INFO DAGScheduler: ShuffleMapStage 41 (count at utils.scala:135) finished in 0.013 s
21/02/17 01:03:44 INFO DAGScheduler: looking for newly runnable stages
21/02/17 01:03:44 INFO DAGScheduler: running: Set()
21/02/17 01:03:44 INFO DAGScheduler: waiting: Set(ResultStage 42)
21/02/17 01:03:44 INFO DAGScheduler: failed: Set()
21/02/17 01:03:44 INFO DAGScheduler: Submitting ResultStage 42 (MapPartitionsRDD[143] at count at utils.scala:135), which has no missing parents
21/02/17 01:03:44 INFO MemoryStore: Block broadcast_45 stored as values in memory (estimated size 10.1 KiB, free 911.6 MiB)
21/02/17 01:03:44 INFO MemoryStore: Block broadcast_45_piece0 stored as bytes in memory (estimated size 5.0 KiB, free 911.6 MiB)
21/02/17 01:03:44 INFO BlockManagerInfo: Added broadcast_45_piece0 in memory on localhost:37167 (size: 5.0 KiB, free: 912.2 MiB)
21/02/17 01:03:44 INFO SparkContext: Created broadcast 45 from broadcast at DAGScheduler.scala:1200
21/02/17 01:03:44 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 42 (MapPartitionsRDD[143] at count at utils.scala:135) (first 15 tasks are for partitions Vector(0))
21/02/17 01:03:44 INFO TaskSchedulerImpl: Adding task set 42.0 with 1 tasks
21/02/17 01:03:44 INFO TaskSetManager: Starting task 0.0 in stage 42.0 (TID 44, localhost, executor driver, partition 0, NODE_LOCAL, 7325 bytes)
21/02/17 01:03:44 INFO Executor: Running task 0.0 in stage 42.0 (TID 44)
21/02/17 01:03:44 INFO ShuffleBlockFetcherIterator: Getting 1 (60.0 B) non-empty blocks including 1 (60.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
21/02/17 01:03:44 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
21/02/17 01:03:44 INFO Executor: Finished task 0.0 in stage 42.0 (TID 44). 2648 bytes result sent to driver
21/02/17 01:03:44 INFO TaskSetManager: Finished task 0.0 in stage 42.0 (TID 44) in 5 ms on localhost (executor driver) (1/1)
21/02/17 01:03:44 INFO TaskSchedulerImpl: Removed TaskSet 42.0, whose tasks have all completed, from pool 
21/02/17 01:03:44 INFO DAGScheduler: ResultStage 42 (count at utils.scala:135) finished in 0.010 s
21/02/17 01:03:44 INFO DAGScheduler: Job 30 is finished. Cancelling potential speculative or zombie tasks for this job
21/02/17 01:03:44 INFO TaskSchedulerImpl: Killing all running tasks in stage 42: Stage finished
21/02/17 01:03:44 INFO DAGScheduler: Job 30 finished: count at utils.scala:135, took 0.026900 s
21/02/17 01:03:44 INFO MapPartitionsRDD: Removing RDD 105 from persistence list
21/02/17 01:03:44 INFO BlockManager: Removing RDD 105
21/02/17 01:03:44 INFO MemoryStore: Block broadcast_46 stored as values in memory (estimated size 294.6 KiB, free 911.3 MiB)
21/02/17 01:03:44 INFO MemoryStore: Block broadcast_46_piece0 stored as bytes in memory (estimated size 27.2 KiB, free 911.3 MiB)
21/02/17 01:03:44 INFO BlockManagerInfo: Added broadcast_46_piece0 in memory on localhost:37167 (size: 27.2 KiB, free: 912.1 MiB)
21/02/17 01:03:44 INFO SparkContext: Created broadcast 46 from textFile at ReadWrite.scala:587
21/02/17 01:03:44 INFO FileInputFormat: Total input files to process : 1
21/02/17 01:03:44 INFO SparkContext: Starting job: first at ReadWrite.scala:587
21/02/17 01:03:44 INFO DAGScheduler: Got job 31 (first at ReadWrite.scala:587) with 1 output partitions
21/02/17 01:03:44 INFO DAGScheduler: Final stage: ResultStage 43 (first at ReadWrite.scala:587)
21/02/17 01:03:44 INFO DAGScheduler: Parents of final stage: List()
21/02/17 01:03:44 INFO DAGScheduler: Missing parents: List()
21/02/17 01:03:44 INFO DAGScheduler: Submitting ResultStage 43 (/tmp/RtmpdJZfO0/file1fe9816a0746c/metadata MapPartitionsRDD[145] at textFile at ReadWrite.scala:587), which has no missing parents
21/02/17 01:03:44 INFO MemoryStore: Block broadcast_47 stored as values in memory (estimated size 4.1 KiB, free 911.3 MiB)
21/02/17 01:03:44 INFO MemoryStore: Block broadcast_47_piece0 stored as bytes in memory (estimated size 2.4 KiB, free 911.3 MiB)
21/02/17 01:03:44 INFO BlockManagerInfo: Added broadcast_47_piece0 in memory on localhost:37167 (size: 2.4 KiB, free: 912.1 MiB)
21/02/17 01:03:44 INFO SparkContext: Created broadcast 47 from broadcast at DAGScheduler.scala:1200
21/02/17 01:03:44 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 43 (/tmp/RtmpdJZfO0/file1fe9816a0746c/metadata MapPartitionsRDD[145] at textFile at ReadWrite.scala:587) (first 15 tasks are for partitions Vector(0))
21/02/17 01:03:44 INFO TaskSchedulerImpl: Adding task set 43.0 with 1 tasks
21/02/17 01:03:44 INFO TaskSetManager: Starting task 0.0 in stage 43.0 (TID 45, localhost, executor driver, partition 0, PROCESS_LOCAL, 7399 bytes)
21/02/17 01:03:44 INFO Executor: Running task 0.0 in stage 43.0 (TID 45)
21/02/17 01:03:44 INFO HadoopRDD: Input split: file:/tmp/RtmpdJZfO0/file1fe9816a0746c/metadata/part-00000:0+306
21/02/17 01:03:44 INFO Executor: Finished task 0.0 in stage 43.0 (TID 45). 1234 bytes result sent to driver
21/02/17 01:03:44 INFO TaskSetManager: Finished task 0.0 in stage 43.0 (TID 45) in 22 ms on localhost (executor driver) (1/1)
21/02/17 01:03:44 INFO TaskSchedulerImpl: Removed TaskSet 43.0, whose tasks have all completed, from pool 
21/02/17 01:03:44 INFO DAGScheduler: ResultStage 43 (first at ReadWrite.scala:587) finished in 0.027 s
21/02/17 01:03:44 INFO DAGScheduler: Job 31 is finished. Cancelling potential speculative or zombie tasks for this job
21/02/17 01:03:44 INFO TaskSchedulerImpl: Killing all running tasks in stage 43: Stage finished
21/02/17 01:03:44 INFO DAGScheduler: Job 31 finished: first at ReadWrite.scala:587, took 0.029612 s
21/02/17 01:03:44 INFO MemoryStore: Block broadcast_48 stored as values in memory (estimated size 294.6 KiB, free 911.0 MiB)
21/02/17 01:03:44 INFO MemoryStore: Block broadcast_48_piece0 stored as bytes in memory (estimated size 27.2 KiB, free 911.0 MiB)
21/02/17 01:03:44 INFO BlockManagerInfo: Added broadcast_48_piece0 in memory on localhost:37167 (size: 27.2 KiB, free: 912.1 MiB)
21/02/17 01:03:44 INFO SparkContext: Created broadcast 48 from textFile at ReadWrite.scala:587
21/02/17 01:03:44 INFO FileInputFormat: Total input files to process : 1
21/02/17 01:03:44 INFO SparkContext: Starting job: first at ReadWrite.scala:587
21/02/17 01:03:44 INFO DAGScheduler: Got job 32 (first at ReadWrite.scala:587) with 1 output partitions
21/02/17 01:03:44 INFO DAGScheduler: Final stage: ResultStage 44 (first at ReadWrite.scala:587)
21/02/17 01:03:44 INFO DAGScheduler: Parents of final stage: List()
21/02/17 01:03:44 INFO DAGScheduler: Missing parents: List()
21/02/17 01:03:44 INFO DAGScheduler: Submitting ResultStage 44 (/tmp/RtmpdJZfO0/file1fe9816a0746c/stages/0_r_formula__a8f3fe0a_f74c_4053_97c3_d6d773d4c9bd/metadata MapPartitionsRDD[147] at textFile at ReadWrite.scala:587), which has no missing parents
21/02/17 01:03:44 INFO MemoryStore: Block broadcast_49 stored as values in memory (estimated size 4.2 KiB, free 911.0 MiB)
21/02/17 01:03:44 INFO MemoryStore: Block broadcast_49_piece0 stored as bytes in memory (estimated size 2.5 KiB, free 911.0 MiB)
21/02/17 01:03:44 INFO BlockManagerInfo: Added broadcast_49_piece0 in memory on localhost:37167 (size: 2.5 KiB, free: 912.1 MiB)
21/02/17 01:03:44 INFO SparkContext: Created broadcast 49 from broadcast at DAGScheduler.scala:1200
21/02/17 01:03:44 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 44 (/tmp/RtmpdJZfO0/file1fe9816a0746c/stages/0_r_formula__a8f3fe0a_f74c_4053_97c3_d6d773d4c9bd/metadata MapPartitionsRDD[147] at textFile at ReadWrite.scala:587) (first 15 tasks are for partitions Vector(0))
21/02/17 01:03:44 INFO TaskSchedulerImpl: Adding task set 44.0 with 1 tasks
21/02/17 01:03:44 INFO TaskSetManager: Starting task 0.0 in stage 44.0 (TID 46, localhost, executor driver, partition 0, PROCESS_LOCAL, 7456 bytes)
21/02/17 01:03:44 INFO Executor: Running task 0.0 in stage 44.0 (TID 46)
21/02/17 01:03:44 INFO HadoopRDD: Input split: file:/tmp/RtmpdJZfO0/file1fe9816a0746c/stages/0_r_formula__a8f3fe0a_f74c_4053_97c3_d6d773d4c9bd/metadata/part-00000:0+447
21/02/17 01:03:44 INFO Executor: Finished task 0.0 in stage 44.0 (TID 46). 1375 bytes result sent to driver
21/02/17 01:03:44 INFO TaskSetManager: Finished task 0.0 in stage 44.0 (TID 46) in 4 ms on localhost (executor driver) (1/1)
21/02/17 01:03:44 INFO TaskSchedulerImpl: Removed TaskSet 44.0, whose tasks have all completed, from pool 
21/02/17 01:03:44 INFO DAGScheduler: ResultStage 44 (first at ReadWrite.scala:587) finished in 0.007 s
21/02/17 01:03:44 INFO DAGScheduler: Job 32 is finished. Cancelling potential speculative or zombie tasks for this job
21/02/17 01:03:44 INFO TaskSchedulerImpl: Killing all running tasks in stage 44: Stage finished
21/02/17 01:03:44 INFO DAGScheduler: Job 32 finished: first at ReadWrite.scala:587, took 0.008575 s
21/02/17 01:03:44 INFO MemoryStore: Block broadcast_50 stored as values in memory (estimated size 294.6 KiB, free 910.7 MiB)
21/02/17 01:03:44 INFO MemoryStore: Block broadcast_50_piece0 stored as bytes in memory (estimated size 27.2 KiB, free 910.7 MiB)
21/02/17 01:03:44 INFO BlockManagerInfo: Added broadcast_50_piece0 in memory on localhost:37167 (size: 27.2 KiB, free: 912.1 MiB)
21/02/17 01:03:44 INFO SparkContext: Created broadcast 50 from textFile at ReadWrite.scala:587
21/02/17 01:03:44 INFO FileInputFormat: Total input files to process : 1
21/02/17 01:03:44 INFO SparkContext: Starting job: first at ReadWrite.scala:587
21/02/17 01:03:44 INFO DAGScheduler: Got job 33 (first at ReadWrite.scala:587) with 1 output partitions
21/02/17 01:03:44 INFO DAGScheduler: Final stage: ResultStage 45 (first at ReadWrite.scala:587)
21/02/17 01:03:44 INFO DAGScheduler: Parents of final stage: List()
21/02/17 01:03:44 INFO DAGScheduler: Missing parents: List()
21/02/17 01:03:44 INFO DAGScheduler: Submitting ResultStage 45 (/tmp/RtmpdJZfO0/file1fe9816a0746c/stages/0_r_formula__a8f3fe0a_f74c_4053_97c3_d6d773d4c9bd/metadata MapPartitionsRDD[149] at textFile at ReadWrite.scala:587), which has no missing parents
21/02/17 01:03:44 INFO MemoryStore: Block broadcast_51 stored as values in memory (estimated size 4.2 KiB, free 910.7 MiB)
21/02/17 01:03:44 INFO MemoryStore: Block broadcast_51_piece0 stored as bytes in memory (estimated size 2.5 KiB, free 910.7 MiB)
21/02/17 01:03:44 INFO BlockManagerInfo: Added broadcast_51_piece0 in memory on localhost:37167 (size: 2.5 KiB, free: 912.1 MiB)
21/02/17 01:03:44 INFO SparkContext: Created broadcast 51 from broadcast at DAGScheduler.scala:1200
21/02/17 01:03:44 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 45 (/tmp/RtmpdJZfO0/file1fe9816a0746c/stages/0_r_formula__a8f3fe0a_f74c_4053_97c3_d6d773d4c9bd/metadata MapPartitionsRDD[149] at textFile at ReadWrite.scala:587) (first 15 tasks are for partitions Vector(0))
21/02/17 01:03:44 INFO TaskSchedulerImpl: Adding task set 45.0 with 1 tasks
21/02/17 01:03:44 INFO TaskSetManager: Starting task 0.0 in stage 45.0 (TID 47, localhost, executor driver, partition 0, PROCESS_LOCAL, 7456 bytes)
21/02/17 01:03:44 INFO Executor: Running task 0.0 in stage 45.0 (TID 47)
21/02/17 01:03:44 INFO HadoopRDD: Input split: file:/tmp/RtmpdJZfO0/file1fe9816a0746c/stages/0_r_formula__a8f3fe0a_f74c_4053_97c3_d6d773d4c9bd/metadata/part-00000:0+447
21/02/17 01:03:44 INFO Executor: Finished task 0.0 in stage 45.0 (TID 47). 1332 bytes result sent to driver
21/02/17 01:03:44 INFO TaskSetManager: Finished task 0.0 in stage 45.0 (TID 47) in 3 ms on localhost (executor driver) (1/1)
21/02/17 01:03:44 INFO TaskSchedulerImpl: Removed TaskSet 45.0, whose tasks have all completed, from pool 
21/02/17 01:03:44 INFO DAGScheduler: ResultStage 45 (first at ReadWrite.scala:587) finished in 0.008 s
21/02/17 01:03:44 INFO DAGScheduler: Job 33 is finished. Cancelling potential speculative or zombie tasks for this job
21/02/17 01:03:44 INFO TaskSchedulerImpl: Killing all running tasks in stage 45: Stage finished
21/02/17 01:03:44 INFO DAGScheduler: Job 33 finished: first at ReadWrite.scala:587, took 0.009745 s
21/02/17 01:03:44 INFO InMemoryFileIndex: It took 1 ms to list leaf files for 1 paths.
21/02/17 01:03:44 INFO SparkContext: Starting job: parquet at RFormula.scala:450
21/02/17 01:03:44 INFO DAGScheduler: Got job 34 (parquet at RFormula.scala:450) with 1 output partitions
21/02/17 01:03:44 INFO DAGScheduler: Final stage: ResultStage 46 (parquet at RFormula.scala:450)
21/02/17 01:03:44 INFO DAGScheduler: Parents of final stage: List()
21/02/17 01:03:44 INFO DAGScheduler: Missing parents: List()
21/02/17 01:03:44 INFO DAGScheduler: Submitting ResultStage 46 (MapPartitionsRDD[151] at parquet at RFormula.scala:450), which has no missing parents
21/02/17 01:03:44 INFO MemoryStore: Block broadcast_52 stored as values in memory (estimated size 86.6 KiB, free 910.6 MiB)
21/02/17 01:03:44 INFO MemoryStore: Block broadcast_52_piece0 stored as bytes in memory (estimated size 30.8 KiB, free 910.6 MiB)
21/02/17 01:03:44 INFO BlockManagerInfo: Added broadcast_52_piece0 in memory on localhost:37167 (size: 30.8 KiB, free: 912.1 MiB)
21/02/17 01:03:44 INFO SparkContext: Created broadcast 52 from broadcast at DAGScheduler.scala:1200
21/02/17 01:03:44 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 46 (MapPartitionsRDD[151] at parquet at RFormula.scala:450) (first 15 tasks are for partitions Vector(0))
21/02/17 01:03:44 INFO TaskSchedulerImpl: Adding task set 46.0 with 1 tasks
21/02/17 01:03:44 INFO TaskSetManager: Starting task 0.0 in stage 46.0 (TID 48, localhost, executor driver, partition 0, PROCESS_LOCAL, 7616 bytes)
21/02/17 01:03:44 INFO Executor: Running task 0.0 in stage 46.0 (TID 48)
21/02/17 01:03:44 INFO Executor: Finished task 0.0 in stage 46.0 (TID 48). 1835 bytes result sent to driver
21/02/17 01:03:44 INFO TaskSetManager: Finished task 0.0 in stage 46.0 (TID 48) in 34 ms on localhost (executor driver) (1/1)
21/02/17 01:03:44 INFO TaskSchedulerImpl: Removed TaskSet 46.0, whose tasks have all completed, from pool 
21/02/17 01:03:44 INFO DAGScheduler: ResultStage 46 (parquet at RFormula.scala:450) finished in 0.042 s
21/02/17 01:03:44 INFO DAGScheduler: Job 34 is finished. Cancelling potential speculative or zombie tasks for this job
21/02/17 01:03:44 INFO TaskSchedulerImpl: Killing all running tasks in stage 46: Stage finished
21/02/17 01:03:44 INFO DAGScheduler: Job 34 finished: parquet at RFormula.scala:450, took 0.044203 s
21/02/17 01:03:44 INFO FileSourceStrategy: Pruning directories with: 
21/02/17 01:03:44 INFO FileSourceStrategy: Pushed Filters: 
21/02/17 01:03:44 INFO FileSourceStrategy: Post-Scan Filters: 
21/02/17 01:03:44 INFO FileSourceStrategy: Output Data Schema: struct<label: string, terms: array<array<string>>, hasIntercept: boolean ... 1 more fields>
21/02/17 01:03:44 INFO MemoryStore: Block broadcast_53 stored as values in memory (estimated size 319.0 KiB, free 910.2 MiB)
21/02/17 01:03:44 INFO MemoryStore: Block broadcast_53_piece0 stored as bytes in memory (estimated size 29.0 KiB, free 910.2 MiB)
21/02/17 01:03:44 INFO BlockManagerInfo: Added broadcast_53_piece0 in memory on localhost:37167 (size: 29.0 KiB, free: 912.0 MiB)
21/02/17 01:03:44 INFO SparkContext: Created broadcast 53 from head at RFormula.scala:450
21/02/17 01:03:44 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
21/02/17 01:03:44 INFO SparkContext: Starting job: head at RFormula.scala:450
21/02/17 01:03:44 INFO DAGScheduler: Got job 35 (head at RFormula.scala:450) with 1 output partitions
21/02/17 01:03:44 INFO DAGScheduler: Final stage: ResultStage 47 (head at RFormula.scala:450)
21/02/17 01:03:44 INFO DAGScheduler: Parents of final stage: List()
21/02/17 01:03:44 INFO DAGScheduler: Missing parents: List()
21/02/17 01:03:44 INFO DAGScheduler: Submitting ResultStage 47 (MapPartitionsRDD[154] at head at RFormula.scala:450), which has no missing parents
21/02/17 01:03:44 INFO MemoryStore: Block broadcast_54 stored as values in memory (estimated size 9.1 KiB, free 910.2 MiB)
21/02/17 01:03:44 INFO MemoryStore: Block broadcast_54_piece0 stored as bytes in memory (estimated size 4.9 KiB, free 910.2 MiB)
21/02/17 01:03:44 INFO BlockManagerInfo: Added broadcast_54_piece0 in memory on localhost:37167 (size: 4.9 KiB, free: 912.0 MiB)
21/02/17 01:03:44 INFO SparkContext: Created broadcast 54 from broadcast at DAGScheduler.scala:1200
21/02/17 01:03:44 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 47 (MapPartitionsRDD[154] at head at RFormula.scala:450) (first 15 tasks are for partitions Vector(0))
21/02/17 01:03:44 INFO TaskSchedulerImpl: Adding task set 47.0 with 1 tasks
21/02/17 01:03:44 INFO TaskSetManager: Starting task 0.0 in stage 47.0 (TID 49, localhost, executor driver, partition 0, PROCESS_LOCAL, 7867 bytes)
21/02/17 01:03:44 INFO Executor: Running task 0.0 in stage 47.0 (TID 49)
21/02/17 01:03:44 INFO CodeGenerator: Code generated in 6.374754 ms
21/02/17 01:03:44 INFO FileScanRDD: Reading File path: file:///tmp/RtmpdJZfO0/file1fe9816a0746c/stages/0_r_formula__a8f3fe0a_f74c_4053_97c3_d6d773d4c9bd/data/part-00000-0a9442af-8a96-480a-937c-aab2a605715d-c000.snappy.parquet, range: 0-1140, partition values: [empty row]
21/02/17 01:03:44 INFO CodecPool: Got brand-new decompressor [.snappy]
21/02/17 01:03:44 INFO Executor: Finished task 0.0 in stage 47.0 (TID 49). 1790 bytes result sent to driver
21/02/17 01:03:44 INFO TaskSetManager: Finished task 0.0 in stage 47.0 (TID 49) in 90 ms on localhost (executor driver) (1/1)
21/02/17 01:03:44 INFO TaskSchedulerImpl: Removed TaskSet 47.0, whose tasks have all completed, from pool 
21/02/17 01:03:44 INFO DAGScheduler: ResultStage 47 (head at RFormula.scala:450) finished in 0.098 s
21/02/17 01:03:44 INFO DAGScheduler: Job 35 is finished. Cancelling potential speculative or zombie tasks for this job
21/02/17 01:03:44 INFO TaskSchedulerImpl: Killing all running tasks in stage 47: Stage finished
21/02/17 01:03:44 INFO DAGScheduler: Job 35 finished: head at RFormula.scala:450, took 0.100361 s
21/02/17 01:03:44 INFO CodeGenerator: Code generated in 14.419589 ms
21/02/17 01:03:44 INFO MemoryStore: Block broadcast_55 stored as values in memory (estimated size 294.6 KiB, free 909.9 MiB)
21/02/17 01:03:44 INFO MemoryStore: Block broadcast_55_piece0 stored as bytes in memory (estimated size 27.2 KiB, free 909.9 MiB)
21/02/17 01:03:44 INFO BlockManagerInfo: Added broadcast_55_piece0 in memory on localhost:37167 (size: 27.2 KiB, free: 912.0 MiB)
21/02/17 01:03:44 INFO SparkContext: Created broadcast 55 from textFile at ReadWrite.scala:587
21/02/17 01:03:44 INFO FileInputFormat: Total input files to process : 1
21/02/17 01:03:44 INFO SparkContext: Starting job: first at ReadWrite.scala:587
21/02/17 01:03:44 INFO DAGScheduler: Got job 36 (first at ReadWrite.scala:587) with 1 output partitions
21/02/17 01:03:44 INFO DAGScheduler: Final stage: ResultStage 48 (first at ReadWrite.scala:587)
21/02/17 01:03:44 INFO DAGScheduler: Parents of final stage: List()
21/02/17 01:03:44 INFO DAGScheduler: Missing parents: List()
21/02/17 01:03:44 INFO DAGScheduler: Submitting ResultStage 48 (/tmp/RtmpdJZfO0/file1fe9816a0746c/stages/0_r_formula__a8f3fe0a_f74c_4053_97c3_d6d773d4c9bd/pipelineModel/metadata MapPartitionsRDD[156] at textFile at ReadWrite.scala:587), which has no missing parents
21/02/17 01:03:44 INFO MemoryStore: Block broadcast_56 stored as values in memory (estimated size 4.2 KiB, free 909.9 MiB)
21/02/17 01:03:44 INFO MemoryStore: Block broadcast_56_piece0 stored as bytes in memory (estimated size 2.5 KiB, free 909.9 MiB)
21/02/17 01:03:44 INFO BlockManagerInfo: Added broadcast_56_piece0 in memory on localhost:37167 (size: 2.5 KiB, free: 912.0 MiB)
21/02/17 01:03:44 INFO SparkContext: Created broadcast 56 from broadcast at DAGScheduler.scala:1200
21/02/17 01:03:44 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 48 (/tmp/RtmpdJZfO0/file1fe9816a0746c/stages/0_r_formula__a8f3fe0a_f74c_4053_97c3_d6d773d4c9bd/pipelineModel/metadata MapPartitionsRDD[156] at textFile at ReadWrite.scala:587) (first 15 tasks are for partitions Vector(0))
21/02/17 01:03:44 INFO TaskSchedulerImpl: Adding task set 48.0 with 1 tasks
21/02/17 01:03:44 INFO TaskSetManager: Starting task 0.0 in stage 48.0 (TID 50, localhost, executor driver, partition 0, PROCESS_LOCAL, 7471 bytes)
21/02/17 01:03:44 INFO Executor: Running task 0.0 in stage 48.0 (TID 50)
21/02/17 01:03:44 INFO HadoopRDD: Input split: file:/tmp/RtmpdJZfO0/file1fe9816a0746c/stages/0_r_formula__a8f3fe0a_f74c_4053_97c3_d6d773d4c9bd/pipelineModel/metadata/part-00000:0+311
21/02/17 01:03:44 INFO Executor: Finished task 0.0 in stage 48.0 (TID 50). 1196 bytes result sent to driver
21/02/17 01:03:44 INFO TaskSetManager: Finished task 0.0 in stage 48.0 (TID 50) in 4 ms on localhost (executor driver) (1/1)
21/02/17 01:03:44 INFO TaskSchedulerImpl: Removed TaskSet 48.0, whose tasks have all completed, from pool 
21/02/17 01:03:44 INFO DAGScheduler: ResultStage 48 (first at ReadWrite.scala:587) finished in 0.007 s
21/02/17 01:03:44 INFO DAGScheduler: Job 36 is finished. Cancelling potential speculative or zombie tasks for this job
21/02/17 01:03:44 INFO TaskSchedulerImpl: Killing all running tasks in stage 48: Stage finished
21/02/17 01:03:44 INFO DAGScheduler: Job 36 finished: first at ReadWrite.scala:587, took 0.008676 s
21/02/17 01:03:44 INFO MemoryStore: Block broadcast_57 stored as values in memory (estimated size 294.6 KiB, free 909.6 MiB)
21/02/17 01:03:44 INFO MemoryStore: Block broadcast_57_piece0 stored as bytes in memory (estimated size 27.2 KiB, free 909.6 MiB)
21/02/17 01:03:44 INFO BlockManagerInfo: Added broadcast_57_piece0 in memory on localhost:37167 (size: 27.2 KiB, free: 912.0 MiB)
21/02/17 01:03:44 INFO SparkContext: Created broadcast 57 from textFile at ReadWrite.scala:587
21/02/17 01:03:44 INFO FileInputFormat: Total input files to process : 1
21/02/17 01:03:44 INFO SparkContext: Starting job: first at ReadWrite.scala:587
21/02/17 01:03:44 INFO DAGScheduler: Got job 37 (first at ReadWrite.scala:587) with 1 output partitions
21/02/17 01:03:44 INFO DAGScheduler: Final stage: ResultStage 49 (first at ReadWrite.scala:587)
21/02/17 01:03:44 INFO DAGScheduler: Parents of final stage: List()
21/02/17 01:03:44 INFO DAGScheduler: Missing parents: List()
21/02/17 01:03:44 INFO DAGScheduler: Submitting ResultStage 49 (/tmp/RtmpdJZfO0/file1fe9816a0746c/stages/0_r_formula__a8f3fe0a_f74c_4053_97c3_d6d773d4c9bd/pipelineModel/stages/0_r_formula__a8f3fe0a_f74c_4053_97c3_d6d773d4c9bd/metadata MapPartitionsRDD[158] at textFile at ReadWrite.scala:587), which has no missing parents
21/02/17 01:03:44 INFO MemoryStore: Block broadcast_58 stored as values in memory (estimated size 4.3 KiB, free 909.6 MiB)
21/02/17 01:03:44 INFO MemoryStore: Block broadcast_58_piece0 stored as bytes in memory (estimated size 2.5 KiB, free 909.6 MiB)
21/02/17 01:03:44 INFO BlockManagerInfo: Added broadcast_58_piece0 in memory on localhost:37167 (size: 2.5 KiB, free: 912.0 MiB)
21/02/17 01:03:44 INFO SparkContext: Created broadcast 58 from broadcast at DAGScheduler.scala:1200
21/02/17 01:03:44 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 49 (/tmp/RtmpdJZfO0/file1fe9816a0746c/stages/0_r_formula__a8f3fe0a_f74c_4053_97c3_d6d773d4c9bd/pipelineModel/stages/0_r_formula__a8f3fe0a_f74c_4053_97c3_d6d773d4c9bd/metadata MapPartitionsRDD[158] at textFile at ReadWrite.scala:587) (first 15 tasks are for partitions Vector(0))
21/02/17 01:03:44 INFO TaskSchedulerImpl: Adding task set 49.0 with 1 tasks
21/02/17 01:03:44 INFO TaskSetManager: Starting task 0.0 in stage 49.0 (TID 51, localhost, executor driver, partition 0, PROCESS_LOCAL, 7531 bytes)
21/02/17 01:03:44 INFO Executor: Running task 0.0 in stage 49.0 (TID 51)
21/02/17 01:03:44 INFO HadoopRDD: Input split: file:/tmp/RtmpdJZfO0/file1fe9816a0746c/stages/0_r_formula__a8f3fe0a_f74c_4053_97c3_d6d773d4c9bd/pipelineModel/stages/0_r_formula__a8f3fe0a_f74c_4053_97c3_d6d773d4c9bd/metadata/part-00000:0+378
21/02/17 01:03:44 INFO Executor: Finished task 0.0 in stage 49.0 (TID 51). 1306 bytes result sent to driver
21/02/17 01:03:44 INFO TaskSetManager: Finished task 0.0 in stage 49.0 (TID 51) in 4 ms on localhost (executor driver) (1/1)
21/02/17 01:03:44 INFO TaskSchedulerImpl: Removed TaskSet 49.0, whose tasks have all completed, from pool 
21/02/17 01:03:44 INFO DAGScheduler: ResultStage 49 (first at ReadWrite.scala:587) finished in 0.008 s
21/02/17 01:03:44 INFO DAGScheduler: Job 37 is finished. Cancelling potential speculative or zombie tasks for this job
21/02/17 01:03:44 INFO TaskSchedulerImpl: Killing all running tasks in stage 49: Stage finished
21/02/17 01:03:44 INFO DAGScheduler: Job 37 finished: first at ReadWrite.scala:587, took 0.009378 s
21/02/17 01:03:44 INFO MemoryStore: Block broadcast_59 stored as values in memory (estimated size 294.6 KiB, free 909.3 MiB)
21/02/17 01:03:44 INFO MemoryStore: Block broadcast_59_piece0 stored as bytes in memory (estimated size 27.2 KiB, free 909.2 MiB)
21/02/17 01:03:44 INFO BlockManagerInfo: Added broadcast_59_piece0 in memory on localhost:37167 (size: 27.2 KiB, free: 911.9 MiB)
21/02/17 01:03:44 INFO SparkContext: Created broadcast 59 from textFile at ReadWrite.scala:587
21/02/17 01:03:44 INFO FileInputFormat: Total input files to process : 1
21/02/17 01:03:44 INFO SparkContext: Starting job: first at ReadWrite.scala:587
21/02/17 01:03:44 INFO DAGScheduler: Got job 38 (first at ReadWrite.scala:587) with 1 output partitions
21/02/17 01:03:44 INFO DAGScheduler: Final stage: ResultStage 50 (first at ReadWrite.scala:587)
21/02/17 01:03:44 INFO DAGScheduler: Parents of final stage: List()
21/02/17 01:03:44 INFO DAGScheduler: Missing parents: List()
21/02/17 01:03:44 INFO DAGScheduler: Submitting ResultStage 50 (/tmp/RtmpdJZfO0/file1fe9816a0746c/stages/0_r_formula__a8f3fe0a_f74c_4053_97c3_d6d773d4c9bd/pipelineModel/stages/0_r_formula__a8f3fe0a_f74c_4053_97c3_d6d773d4c9bd/metadata MapPartitionsRDD[160] at textFile at ReadWrite.scala:587), which has no missing parents
21/02/17 01:03:44 INFO MemoryStore: Block broadcast_60 stored as values in memory (estimated size 4.3 KiB, free 909.2 MiB)
21/02/17 01:03:44 INFO MemoryStore: Block broadcast_60_piece0 stored as bytes in memory (estimated size 2.5 KiB, free 909.2 MiB)
21/02/17 01:03:44 INFO BlockManagerInfo: Added broadcast_60_piece0 in memory on localhost:37167 (size: 2.5 KiB, free: 911.9 MiB)
21/02/17 01:03:44 INFO SparkContext: Created broadcast 60 from broadcast at DAGScheduler.scala:1200
21/02/17 01:03:44 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 50 (/tmp/RtmpdJZfO0/file1fe9816a0746c/stages/0_r_formula__a8f3fe0a_f74c_4053_97c3_d6d773d4c9bd/pipelineModel/stages/0_r_formula__a8f3fe0a_f74c_4053_97c3_d6d773d4c9bd/metadata MapPartitionsRDD[160] at textFile at ReadWrite.scala:587) (first 15 tasks are for partitions Vector(0))
21/02/17 01:03:44 INFO TaskSchedulerImpl: Adding task set 50.0 with 1 tasks
21/02/17 01:03:44 INFO TaskSetManager: Starting task 0.0 in stage 50.0 (TID 52, localhost, executor driver, partition 0, PROCESS_LOCAL, 7531 bytes)
21/02/17 01:03:44 INFO Executor: Running task 0.0 in stage 50.0 (TID 52)
21/02/17 01:03:44 INFO HadoopRDD: Input split: file:/tmp/RtmpdJZfO0/file1fe9816a0746c/stages/0_r_formula__a8f3fe0a_f74c_4053_97c3_d6d773d4c9bd/pipelineModel/stages/0_r_formula__a8f3fe0a_f74c_4053_97c3_d6d773d4c9bd/metadata/part-00000:0+378
21/02/17 01:03:44 INFO Executor: Finished task 0.0 in stage 50.0 (TID 52). 1306 bytes result sent to driver
21/02/17 01:03:44 INFO TaskSetManager: Finished task 0.0 in stage 50.0 (TID 52) in 4 ms on localhost (executor driver) (1/1)
21/02/17 01:03:44 INFO TaskSchedulerImpl: Removed TaskSet 50.0, whose tasks have all completed, from pool 
21/02/17 01:03:44 INFO DAGScheduler: ResultStage 50 (first at ReadWrite.scala:587) finished in 0.007 s
21/02/17 01:03:44 INFO DAGScheduler: Job 38 is finished. Cancelling potential speculative or zombie tasks for this job
21/02/17 01:03:44 INFO TaskSchedulerImpl: Killing all running tasks in stage 50: Stage finished
21/02/17 01:03:44 INFO DAGScheduler: Job 38 finished: first at ReadWrite.scala:587, took 0.008574 s
21/02/17 01:03:44 INFO MemoryStore: Block broadcast_61 stored as values in memory (estimated size 294.6 KiB, free 908.9 MiB)
21/02/17 01:03:44 INFO MemoryStore: Block broadcast_61_piece0 stored as bytes in memory (estimated size 27.2 KiB, free 908.9 MiB)
21/02/17 01:03:44 INFO BlockManagerInfo: Added broadcast_61_piece0 in memory on localhost:37167 (size: 27.2 KiB, free: 911.9 MiB)
21/02/17 01:03:44 INFO SparkContext: Created broadcast 61 from textFile at ReadWrite.scala:587
21/02/17 01:03:44 INFO FileInputFormat: Total input files to process : 1
21/02/17 01:03:44 INFO SparkContext: Starting job: first at ReadWrite.scala:587
21/02/17 01:03:44 INFO DAGScheduler: Got job 39 (first at ReadWrite.scala:587) with 1 output partitions
21/02/17 01:03:44 INFO DAGScheduler: Final stage: ResultStage 51 (first at ReadWrite.scala:587)
21/02/17 01:03:44 INFO DAGScheduler: Parents of final stage: List()
21/02/17 01:03:44 INFO DAGScheduler: Missing parents: List()
21/02/17 01:03:44 INFO DAGScheduler: Submitting ResultStage 51 (/tmp/RtmpdJZfO0/file1fe9816a0746c/stages/0_r_formula__a8f3fe0a_f74c_4053_97c3_d6d773d4c9bd/pipelineModel/stages/1_vectorAttrRewriter_ab7c6f18b3b3/metadata MapPartitionsRDD[162] at textFile at ReadWrite.scala:587), which has no missing parents
21/02/17 01:03:44 INFO MemoryStore: Block broadcast_62 stored as values in memory (estimated size 4.2 KiB, free 908.9 MiB)
21/02/17 01:03:44 INFO MemoryStore: Block broadcast_62_piece0 stored as bytes in memory (estimated size 2.5 KiB, free 908.9 MiB)
21/02/17 01:03:44 INFO BlockManagerInfo: Added broadcast_62_piece0 in memory on localhost:37167 (size: 2.5 KiB, free: 911.9 MiB)
21/02/17 01:03:44 INFO SparkContext: Created broadcast 62 from broadcast at DAGScheduler.scala:1200
21/02/17 01:03:44 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 51 (/tmp/RtmpdJZfO0/file1fe9816a0746c/stages/0_r_formula__a8f3fe0a_f74c_4053_97c3_d6d773d4c9bd/pipelineModel/stages/1_vectorAttrRewriter_ab7c6f18b3b3/metadata MapPartitionsRDD[162] at textFile at ReadWrite.scala:587) (first 15 tasks are for partitions Vector(0))
21/02/17 01:03:44 INFO TaskSchedulerImpl: Adding task set 51.0 with 1 tasks
21/02/17 01:03:44 INFO TaskSetManager: Starting task 0.0 in stage 51.0 (TID 53, localhost, executor driver, partition 0, PROCESS_LOCAL, 7515 bytes)
21/02/17 01:03:44 INFO Executor: Running task 0.0 in stage 51.0 (TID 53)
21/02/17 01:03:44 INFO HadoopRDD: Input split: file:/tmp/RtmpdJZfO0/file1fe9816a0746c/stages/0_r_formula__a8f3fe0a_f74c_4053_97c3_d6d773d4c9bd/pipelineModel/stages/1_vectorAttrRewriter_ab7c6f18b3b3/metadata/part-00000:0+188
21/02/17 01:03:44 INFO Executor: Finished task 0.0 in stage 51.0 (TID 53). 1070 bytes result sent to driver
21/02/17 01:03:44 INFO TaskSetManager: Finished task 0.0 in stage 51.0 (TID 53) in 4 ms on localhost (executor driver) (1/1)
21/02/17 01:03:44 INFO TaskSchedulerImpl: Removed TaskSet 51.0, whose tasks have all completed, from pool 
21/02/17 01:03:44 INFO DAGScheduler: ResultStage 51 (first at ReadWrite.scala:587) finished in 0.006 s
21/02/17 01:03:44 INFO DAGScheduler: Job 39 is finished. Cancelling potential speculative or zombie tasks for this job
21/02/17 01:03:44 INFO TaskSchedulerImpl: Killing all running tasks in stage 51: Stage finished
21/02/17 01:03:44 INFO DAGScheduler: Job 39 finished: first at ReadWrite.scala:587, took 0.007818 s
21/02/17 01:03:44 INFO MemoryStore: Block broadcast_63 stored as values in memory (estimated size 294.6 KiB, free 908.6 MiB)
21/02/17 01:03:44 INFO MemoryStore: Block broadcast_63_piece0 stored as bytes in memory (estimated size 27.2 KiB, free 908.6 MiB)
21/02/17 01:03:44 INFO BlockManagerInfo: Removed broadcast_55_piece0 on localhost:37167 in memory (size: 27.2 KiB, free: 911.9 MiB)
21/02/17 01:03:44 INFO BlockManagerInfo: Added broadcast_63_piece0 in memory on localhost:37167 (size: 27.2 KiB, free: 911.9 MiB)
21/02/17 01:03:44 INFO SparkContext: Created broadcast 63 from textFile at ReadWrite.scala:587
21/02/17 01:03:44 INFO BlockManagerInfo: Removed broadcast_41_piece0 on localhost:37167 in memory (size: 5.2 KiB, free: 911.9 MiB)
21/02/17 01:03:44 INFO BlockManagerInfo: Removed broadcast_50_piece0 on localhost:37167 in memory (size: 27.2 KiB, free: 911.9 MiB)
21/02/17 01:03:44 INFO BlockManagerInfo: Removed broadcast_52_piece0 on localhost:37167 in memory (size: 30.8 KiB, free: 912.0 MiB)
21/02/17 01:03:44 INFO BlockManagerInfo: Removed broadcast_53_piece0 on localhost:37167 in memory (size: 29.0 KiB, free: 912.0 MiB)
21/02/17 01:03:44 INFO BlockManagerInfo: Removed broadcast_56_piece0 on localhost:37167 in memory (size: 2.5 KiB, free: 912.0 MiB)
21/02/17 01:03:44 INFO BlockManagerInfo: Removed broadcast_46_piece0 on localhost:37167 in memory (size: 27.2 KiB, free: 912.0 MiB)
21/02/17 01:03:44 INFO BlockManagerInfo: Removed broadcast_44_piece0 on localhost:37167 in memory (size: 10.1 KiB, free: 912.0 MiB)
21/02/17 01:03:44 INFO BlockManagerInfo: Removed broadcast_61_piece0 on localhost:37167 in memory (size: 27.2 KiB, free: 912.1 MiB)
21/02/17 01:03:44 INFO BlockManagerInfo: Removed broadcast_57_piece0 on localhost:37167 in memory (size: 27.2 KiB, free: 912.1 MiB)
21/02/17 01:03:44 INFO BlockManagerInfo: Removed broadcast_33_piece0 on localhost:37167 in memory (size: 28.3 KiB, free: 912.1 MiB)
21/02/17 01:03:44 INFO BlockManagerInfo: Removed broadcast_42_piece0 on localhost:37167 in memory (size: 5.0 KiB, free: 912.1 MiB)
21/02/17 01:03:44 INFO BlockManagerInfo: Removed broadcast_54_piece0 on localhost:37167 in memory (size: 4.9 KiB, free: 912.1 MiB)
21/02/17 01:03:44 INFO FileInputFormat: Total input files to process : 1
21/02/17 01:03:44 INFO BlockManagerInfo: Removed broadcast_47_piece0 on localhost:37167 in memory (size: 2.4 KiB, free: 912.1 MiB)
21/02/17 01:03:44 INFO BlockManagerInfo: Removed broadcast_48_piece0 on localhost:37167 in memory (size: 27.2 KiB, free: 912.2 MiB)
21/02/17 01:03:44 INFO BlockManagerInfo: Removed broadcast_51_piece0 on localhost:37167 in memory (size: 2.5 KiB, free: 912.2 MiB)
21/02/17 01:03:44 INFO BlockManagerInfo: Removed broadcast_45_piece0 on localhost:37167 in memory (size: 5.0 KiB, free: 912.2 MiB)
21/02/17 01:03:44 INFO BlockManagerInfo: Removed broadcast_43_piece0 on localhost:37167 in memory (size: 8.0 KiB, free: 912.2 MiB)
21/02/17 01:03:44 INFO BlockManagerInfo: Removed broadcast_60_piece0 on localhost:37167 in memory (size: 2.5 KiB, free: 912.2 MiB)
21/02/17 01:03:44 INFO BlockManagerInfo: Removed broadcast_58_piece0 on localhost:37167 in memory (size: 2.5 KiB, free: 912.2 MiB)
21/02/17 01:03:44 INFO BlockManagerInfo: Removed broadcast_59_piece0 on localhost:37167 in memory (size: 27.2 KiB, free: 912.2 MiB)
21/02/17 01:03:44 INFO BlockManagerInfo: Removed broadcast_49_piece0 on localhost:37167 in memory (size: 2.5 KiB, free: 912.2 MiB)
21/02/17 01:03:44 INFO SparkContext: Starting job: first at ReadWrite.scala:587
21/02/17 01:03:44 INFO BlockManager: Removing RDD 105
21/02/17 01:03:44 INFO DAGScheduler: Got job 40 (first at ReadWrite.scala:587) with 1 output partitions
21/02/17 01:03:44 INFO DAGScheduler: Final stage: ResultStage 52 (first at ReadWrite.scala:587)
21/02/17 01:03:44 INFO DAGScheduler: Parents of final stage: List()
21/02/17 01:03:44 INFO DAGScheduler: Missing parents: List()
21/02/17 01:03:44 INFO DAGScheduler: Submitting ResultStage 52 (/tmp/RtmpdJZfO0/file1fe9816a0746c/stages/0_r_formula__a8f3fe0a_f74c_4053_97c3_d6d773d4c9bd/pipelineModel/stages/1_vectorAttrRewriter_ab7c6f18b3b3/metadata MapPartitionsRDD[164] at textFile at ReadWrite.scala:587), which has no missing parents
21/02/17 01:03:44 INFO BlockManagerInfo: Removed broadcast_62_piece0 on localhost:37167 in memory (size: 2.5 KiB, free: 912.2 MiB)
21/02/17 01:03:44 INFO MemoryStore: Block broadcast_64 stored as values in memory (estimated size 4.2 KiB, free 911.7 MiB)
21/02/17 01:03:44 INFO MemoryStore: Block broadcast_64_piece0 stored as bytes in memory (estimated size 2.5 KiB, free 911.7 MiB)
21/02/17 01:03:44 INFO BlockManagerInfo: Added broadcast_64_piece0 in memory on localhost:37167 (size: 2.5 KiB, free: 912.2 MiB)
21/02/17 01:03:44 INFO SparkContext: Created broadcast 64 from broadcast at DAGScheduler.scala:1200
21/02/17 01:03:44 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 52 (/tmp/RtmpdJZfO0/file1fe9816a0746c/stages/0_r_formula__a8f3fe0a_f74c_4053_97c3_d6d773d4c9bd/pipelineModel/stages/1_vectorAttrRewriter_ab7c6f18b3b3/metadata MapPartitionsRDD[164] at textFile at ReadWrite.scala:587) (first 15 tasks are for partitions Vector(0))
21/02/17 01:03:44 INFO TaskSchedulerImpl: Adding task set 52.0 with 1 tasks
21/02/17 01:03:44 INFO TaskSetManager: Starting task 0.0 in stage 52.0 (TID 54, localhost, executor driver, partition 0, PROCESS_LOCAL, 7515 bytes)
21/02/17 01:03:44 INFO Executor: Running task 0.0 in stage 52.0 (TID 54)
21/02/17 01:03:44 INFO HadoopRDD: Input split: file:/tmp/RtmpdJZfO0/file1fe9816a0746c/stages/0_r_formula__a8f3fe0a_f74c_4053_97c3_d6d773d4c9bd/pipelineModel/stages/1_vectorAttrRewriter_ab7c6f18b3b3/metadata/part-00000:0+188
21/02/17 01:03:44 INFO Executor: Finished task 0.0 in stage 52.0 (TID 54). 1113 bytes result sent to driver
21/02/17 01:03:44 INFO TaskSetManager: Finished task 0.0 in stage 52.0 (TID 54) in 4 ms on localhost (executor driver) (1/1)
21/02/17 01:03:44 INFO TaskSchedulerImpl: Removed TaskSet 52.0, whose tasks have all completed, from pool 
21/02/17 01:03:44 INFO DAGScheduler: ResultStage 52 (first at ReadWrite.scala:587) finished in 0.008 s
21/02/17 01:03:44 INFO DAGScheduler: Job 40 is finished. Cancelling potential speculative or zombie tasks for this job
21/02/17 01:03:44 INFO TaskSchedulerImpl: Killing all running tasks in stage 52: Stage finished
21/02/17 01:03:44 INFO DAGScheduler: Job 40 finished: first at ReadWrite.scala:587, took 0.009518 s
21/02/17 01:03:44 INFO InMemoryFileIndex: It took 0 ms to list leaf files for 1 paths.
21/02/17 01:03:44 INFO SparkContext: Starting job: parquet at RFormula.scala:612
21/02/17 01:03:44 INFO DAGScheduler: Got job 41 (parquet at RFormula.scala:612) with 1 output partitions
21/02/17 01:03:44 INFO DAGScheduler: Final stage: ResultStage 53 (parquet at RFormula.scala:612)
21/02/17 01:03:44 INFO DAGScheduler: Parents of final stage: List()
21/02/17 01:03:44 INFO DAGScheduler: Missing parents: List()
21/02/17 01:03:44 INFO DAGScheduler: Submitting ResultStage 53 (MapPartitionsRDD[166] at parquet at RFormula.scala:612), which has no missing parents
21/02/17 01:03:44 INFO MemoryStore: Block broadcast_65 stored as values in memory (estimated size 86.6 KiB, free 911.7 MiB)
21/02/17 01:03:44 INFO MemoryStore: Block broadcast_65_piece0 stored as bytes in memory (estimated size 30.8 KiB, free 911.6 MiB)
21/02/17 01:03:44 INFO BlockManagerInfo: Added broadcast_65_piece0 in memory on localhost:37167 (size: 30.8 KiB, free: 912.2 MiB)
21/02/17 01:03:44 INFO SparkContext: Created broadcast 65 from broadcast at DAGScheduler.scala:1200
21/02/17 01:03:44 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 53 (MapPartitionsRDD[166] at parquet at RFormula.scala:612) (first 15 tasks are for partitions Vector(0))
21/02/17 01:03:44 INFO TaskSchedulerImpl: Adding task set 53.0 with 1 tasks
21/02/17 01:03:44 INFO TaskSetManager: Starting task 0.0 in stage 53.0 (TID 55, localhost, executor driver, partition 0, PROCESS_LOCAL, 7671 bytes)
21/02/17 01:03:44 INFO Executor: Running task 0.0 in stage 53.0 (TID 55)
21/02/17 01:03:44 INFO Executor: Finished task 0.0 in stage 53.0 (TID 55). 1769 bytes result sent to driver
21/02/17 01:03:44 INFO TaskSetManager: Finished task 0.0 in stage 53.0 (TID 55) in 9 ms on localhost (executor driver) (1/1)
21/02/17 01:03:44 INFO TaskSchedulerImpl: Removed TaskSet 53.0, whose tasks have all completed, from pool 
21/02/17 01:03:44 INFO DAGScheduler: ResultStage 53 (parquet at RFormula.scala:612) finished in 0.016 s
21/02/17 01:03:44 INFO DAGScheduler: Job 41 is finished. Cancelling potential speculative or zombie tasks for this job
21/02/17 01:03:44 INFO TaskSchedulerImpl: Killing all running tasks in stage 53: Stage finished
21/02/17 01:03:44 INFO DAGScheduler: Job 41 finished: parquet at RFormula.scala:612, took 0.017850 s
21/02/17 01:03:44 INFO FileSourceStrategy: Pruning directories with: 
21/02/17 01:03:44 INFO FileSourceStrategy: Pushed Filters: 
21/02/17 01:03:44 INFO FileSourceStrategy: Post-Scan Filters: 
21/02/17 01:03:44 INFO FileSourceStrategy: Output Data Schema: struct<vectorCol: string, prefixesToRewrite: map<string,string>>
21/02/17 01:03:44 INFO MemoryStore: Block broadcast_66 stored as values in memory (estimated size 318.7 KiB, free 911.3 MiB)
21/02/17 01:03:44 INFO MemoryStore: Block broadcast_66_piece0 stored as bytes in memory (estimated size 29.0 KiB, free 911.3 MiB)
21/02/17 01:03:44 INFO BlockManagerInfo: Added broadcast_66_piece0 in memory on localhost:37167 (size: 29.0 KiB, free: 912.1 MiB)
21/02/17 01:03:44 INFO SparkContext: Created broadcast 66 from head at RFormula.scala:612
21/02/17 01:03:44 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
21/02/17 01:03:44 INFO SparkContext: Starting job: head at RFormula.scala:612
21/02/17 01:03:44 INFO DAGScheduler: Got job 42 (head at RFormula.scala:612) with 1 output partitions
21/02/17 01:03:44 INFO DAGScheduler: Final stage: ResultStage 54 (head at RFormula.scala:612)
21/02/17 01:03:44 INFO DAGScheduler: Parents of final stage: List()
21/02/17 01:03:44 INFO DAGScheduler: Missing parents: List()
21/02/17 01:03:44 INFO DAGScheduler: Submitting ResultStage 54 (MapPartitionsRDD[169] at head at RFormula.scala:612), which has no missing parents
21/02/17 01:03:44 INFO MemoryStore: Block broadcast_67 stored as values in memory (estimated size 9.1 KiB, free 911.3 MiB)
21/02/17 01:03:44 INFO MemoryStore: Block broadcast_67_piece0 stored as bytes in memory (estimated size 4.8 KiB, free 911.3 MiB)
21/02/17 01:03:44 INFO BlockManagerInfo: Added broadcast_67_piece0 in memory on localhost:37167 (size: 4.8 KiB, free: 912.1 MiB)
21/02/17 01:03:44 INFO SparkContext: Created broadcast 67 from broadcast at DAGScheduler.scala:1200
21/02/17 01:03:44 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 54 (MapPartitionsRDD[169] at head at RFormula.scala:612) (first 15 tasks are for partitions Vector(0))
21/02/17 01:03:44 INFO TaskSchedulerImpl: Adding task set 54.0 with 1 tasks
21/02/17 01:03:44 INFO TaskSetManager: Starting task 0.0 in stage 54.0 (TID 56, localhost, executor driver, partition 0, PROCESS_LOCAL, 7922 bytes)
21/02/17 01:03:44 INFO Executor: Running task 0.0 in stage 54.0 (TID 56)
21/02/17 01:03:44 INFO FileScanRDD: Reading File path: file:///tmp/RtmpdJZfO0/file1fe9816a0746c/stages/0_r_formula__a8f3fe0a_f74c_4053_97c3_d6d773d4c9bd/pipelineModel/stages/1_vectorAttrRewriter_ab7c6f18b3b3/data/part-00000-edaa45d9-c54b-49f3-9d70-355899bc2893-c000.snappy.parquet, range: 0-927, partition values: [empty row]
21/02/17 01:03:45 INFO Executor: Finished task 0.0 in stage 54.0 (TID 56). 1728 bytes result sent to driver
21/02/17 01:03:45 INFO TaskSetManager: Finished task 0.0 in stage 54.0 (TID 56) in 13 ms on localhost (executor driver) (1/1)
21/02/17 01:03:45 INFO TaskSchedulerImpl: Removed TaskSet 54.0, whose tasks have all completed, from pool 
21/02/17 01:03:45 INFO DAGScheduler: ResultStage 54 (head at RFormula.scala:612) finished in 0.016 s
21/02/17 01:03:45 INFO DAGScheduler: Job 42 is finished. Cancelling potential speculative or zombie tasks for this job
21/02/17 01:03:45 INFO TaskSchedulerImpl: Killing all running tasks in stage 54: Stage finished
21/02/17 01:03:45 INFO DAGScheduler: Job 42 finished: head at RFormula.scala:612, took 0.017843 s
21/02/17 01:03:45 INFO CodeGenerator: Code generated in 14.620599 ms
21/02/17 01:03:45 INFO MemoryStore: Block broadcast_68 stored as values in memory (estimated size 294.6 KiB, free 911.0 MiB)
21/02/17 01:03:45 INFO MemoryStore: Block broadcast_68_piece0 stored as bytes in memory (estimated size 27.2 KiB, free 911.0 MiB)
21/02/17 01:03:45 INFO BlockManagerInfo: Added broadcast_68_piece0 in memory on localhost:37167 (size: 27.2 KiB, free: 912.1 MiB)
21/02/17 01:03:45 INFO SparkContext: Created broadcast 68 from textFile at ReadWrite.scala:587
21/02/17 01:03:45 INFO FileInputFormat: Total input files to process : 1
21/02/17 01:03:45 INFO SparkContext: Starting job: first at ReadWrite.scala:587
21/02/17 01:03:45 INFO DAGScheduler: Got job 43 (first at ReadWrite.scala:587) with 1 output partitions
21/02/17 01:03:45 INFO DAGScheduler: Final stage: ResultStage 55 (first at ReadWrite.scala:587)
21/02/17 01:03:45 INFO DAGScheduler: Parents of final stage: List()
21/02/17 01:03:45 INFO DAGScheduler: Missing parents: List()
21/02/17 01:03:45 INFO DAGScheduler: Submitting ResultStage 55 (/tmp/RtmpdJZfO0/file1fe9816a0746c/stages/0_r_formula__a8f3fe0a_f74c_4053_97c3_d6d773d4c9bd/pipelineModel/stages/2_columnPruner_b54e3fcdd491/metadata MapPartitionsRDD[171] at textFile at ReadWrite.scala:587), which has no missing parents
21/02/17 01:03:45 INFO MemoryStore: Block broadcast_69 stored as values in memory (estimated size 4.2 KiB, free 911.0 MiB)
21/02/17 01:03:45 INFO MemoryStore: Block broadcast_69_piece0 stored as bytes in memory (estimated size 2.5 KiB, free 911.0 MiB)
21/02/17 01:03:45 INFO BlockManagerInfo: Added broadcast_69_piece0 in memory on localhost:37167 (size: 2.5 KiB, free: 912.1 MiB)
21/02/17 01:03:45 INFO SparkContext: Created broadcast 69 from broadcast at DAGScheduler.scala:1200
21/02/17 01:03:45 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 55 (/tmp/RtmpdJZfO0/file1fe9816a0746c/stages/0_r_formula__a8f3fe0a_f74c_4053_97c3_d6d773d4c9bd/pipelineModel/stages/2_columnPruner_b54e3fcdd491/metadata MapPartitionsRDD[171] at textFile at ReadWrite.scala:587) (first 15 tasks are for partitions Vector(0))
21/02/17 01:03:45 INFO TaskSchedulerImpl: Adding task set 55.0 with 1 tasks
21/02/17 01:03:45 INFO TaskSetManager: Starting task 0.0 in stage 55.0 (TID 57, localhost, executor driver, partition 0, PROCESS_LOCAL, 7506 bytes)
21/02/17 01:03:45 INFO Executor: Running task 0.0 in stage 55.0 (TID 57)
21/02/17 01:03:45 INFO HadoopRDD: Input split: file:/tmp/RtmpdJZfO0/file1fe9816a0746c/stages/0_r_formula__a8f3fe0a_f74c_4053_97c3_d6d773d4c9bd/pipelineModel/stages/2_columnPruner_b54e3fcdd491/metadata/part-00000:0+171
21/02/17 01:03:45 INFO Executor: Finished task 0.0 in stage 55.0 (TID 57). 1053 bytes result sent to driver
21/02/17 01:03:45 INFO TaskSetManager: Finished task 0.0 in stage 55.0 (TID 57) in 4 ms on localhost (executor driver) (1/1)
21/02/17 01:03:45 INFO TaskSchedulerImpl: Removed TaskSet 55.0, whose tasks have all completed, from pool 
21/02/17 01:03:45 INFO DAGScheduler: ResultStage 55 (first at ReadWrite.scala:587) finished in 0.006 s
21/02/17 01:03:45 INFO DAGScheduler: Job 43 is finished. Cancelling potential speculative or zombie tasks for this job
21/02/17 01:03:45 INFO TaskSchedulerImpl: Killing all running tasks in stage 55: Stage finished
21/02/17 01:03:45 INFO DAGScheduler: Job 43 finished: first at ReadWrite.scala:587, took 0.007552 s
21/02/17 01:03:45 INFO MemoryStore: Block broadcast_70 stored as values in memory (estimated size 294.6 KiB, free 910.7 MiB)
21/02/17 01:03:45 INFO MemoryStore: Block broadcast_70_piece0 stored as bytes in memory (estimated size 27.2 KiB, free 910.6 MiB)
21/02/17 01:03:45 INFO BlockManagerInfo: Added broadcast_70_piece0 in memory on localhost:37167 (size: 27.2 KiB, free: 912.1 MiB)
21/02/17 01:03:45 INFO SparkContext: Created broadcast 70 from textFile at ReadWrite.scala:587
21/02/17 01:03:45 INFO FileInputFormat: Total input files to process : 1
21/02/17 01:03:45 INFO SparkContext: Starting job: first at ReadWrite.scala:587
21/02/17 01:03:45 INFO DAGScheduler: Got job 44 (first at ReadWrite.scala:587) with 1 output partitions
21/02/17 01:03:45 INFO DAGScheduler: Final stage: ResultStage 56 (first at ReadWrite.scala:587)
21/02/17 01:03:45 INFO DAGScheduler: Parents of final stage: List()
21/02/17 01:03:45 INFO DAGScheduler: Missing parents: List()
21/02/17 01:03:45 INFO DAGScheduler: Submitting ResultStage 56 (/tmp/RtmpdJZfO0/file1fe9816a0746c/stages/0_r_formula__a8f3fe0a_f74c_4053_97c3_d6d773d4c9bd/pipelineModel/stages/2_columnPruner_b54e3fcdd491/metadata MapPartitionsRDD[173] at textFile at ReadWrite.scala:587), which has no missing parents
21/02/17 01:03:45 INFO MemoryStore: Block broadcast_71 stored as values in memory (estimated size 4.2 KiB, free 910.6 MiB)
21/02/17 01:03:45 INFO MemoryStore: Block broadcast_71_piece0 stored as bytes in memory (estimated size 2.5 KiB, free 910.6 MiB)
21/02/17 01:03:45 INFO BlockManagerInfo: Added broadcast_71_piece0 in memory on localhost:37167 (size: 2.5 KiB, free: 912.1 MiB)
21/02/17 01:03:45 INFO SparkContext: Created broadcast 71 from broadcast at DAGScheduler.scala:1200
21/02/17 01:03:45 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 56 (/tmp/RtmpdJZfO0/file1fe9816a0746c/stages/0_r_formula__a8f3fe0a_f74c_4053_97c3_d6d773d4c9bd/pipelineModel/stages/2_columnPruner_b54e3fcdd491/metadata MapPartitionsRDD[173] at textFile at ReadWrite.scala:587) (first 15 tasks are for partitions Vector(0))
21/02/17 01:03:45 INFO TaskSchedulerImpl: Adding task set 56.0 with 1 tasks
21/02/17 01:03:45 INFO TaskSetManager: Starting task 0.0 in stage 56.0 (TID 58, localhost, executor driver, partition 0, PROCESS_LOCAL, 7506 bytes)
21/02/17 01:03:45 INFO Executor: Running task 0.0 in stage 56.0 (TID 58)
21/02/17 01:03:45 INFO HadoopRDD: Input split: file:/tmp/RtmpdJZfO0/file1fe9816a0746c/stages/0_r_formula__a8f3fe0a_f74c_4053_97c3_d6d773d4c9bd/pipelineModel/stages/2_columnPruner_b54e3fcdd491/metadata/part-00000:0+171
21/02/17 01:03:45 INFO Executor: Finished task 0.0 in stage 56.0 (TID 58). 1053 bytes result sent to driver
21/02/17 01:03:45 INFO TaskSetManager: Finished task 0.0 in stage 56.0 (TID 58) in 4 ms on localhost (executor driver) (1/1)
21/02/17 01:03:45 INFO TaskSchedulerImpl: Removed TaskSet 56.0, whose tasks have all completed, from pool 
21/02/17 01:03:45 INFO DAGScheduler: ResultStage 56 (first at ReadWrite.scala:587) finished in 0.007 s
21/02/17 01:03:45 INFO DAGScheduler: Job 44 is finished. Cancelling potential speculative or zombie tasks for this job
21/02/17 01:03:45 INFO TaskSchedulerImpl: Killing all running tasks in stage 56: Stage finished
21/02/17 01:03:45 INFO DAGScheduler: Job 44 finished: first at ReadWrite.scala:587, took 0.008739 s
21/02/17 01:03:45 INFO InMemoryFileIndex: It took 1 ms to list leaf files for 1 paths.
21/02/17 01:03:45 INFO SparkContext: Starting job: parquet at RFormula.scala:521
21/02/17 01:03:45 INFO DAGScheduler: Got job 45 (parquet at RFormula.scala:521) with 1 output partitions
21/02/17 01:03:45 INFO DAGScheduler: Final stage: ResultStage 57 (parquet at RFormula.scala:521)
21/02/17 01:03:45 INFO DAGScheduler: Parents of final stage: List()
21/02/17 01:03:45 INFO DAGScheduler: Missing parents: List()
21/02/17 01:03:45 INFO DAGScheduler: Submitting ResultStage 57 (MapPartitionsRDD[175] at parquet at RFormula.scala:521), which has no missing parents
21/02/17 01:03:45 INFO MemoryStore: Block broadcast_72 stored as values in memory (estimated size 86.6 KiB, free 910.5 MiB)
21/02/17 01:03:45 INFO MemoryStore: Block broadcast_72_piece0 stored as bytes in memory (estimated size 30.8 KiB, free 910.5 MiB)
21/02/17 01:03:45 INFO BlockManagerInfo: Added broadcast_72_piece0 in memory on localhost:37167 (size: 30.8 KiB, free: 912.1 MiB)
21/02/17 01:03:45 INFO SparkContext: Created broadcast 72 from broadcast at DAGScheduler.scala:1200
21/02/17 01:03:45 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 57 (MapPartitionsRDD[175] at parquet at RFormula.scala:521) (first 15 tasks are for partitions Vector(0))
21/02/17 01:03:45 INFO TaskSchedulerImpl: Adding task set 57.0 with 1 tasks
21/02/17 01:03:45 INFO TaskSetManager: Starting task 0.0 in stage 57.0 (TID 59, localhost, executor driver, partition 0, PROCESS_LOCAL, 7665 bytes)
21/02/17 01:03:45 INFO Executor: Running task 0.0 in stage 57.0 (TID 59)
21/02/17 01:03:45 INFO Executor: Finished task 0.0 in stage 57.0 (TID 59). 1705 bytes result sent to driver
21/02/17 01:03:45 INFO TaskSetManager: Finished task 0.0 in stage 57.0 (TID 59) in 7 ms on localhost (executor driver) (1/1)
21/02/17 01:03:45 INFO TaskSchedulerImpl: Removed TaskSet 57.0, whose tasks have all completed, from pool 
21/02/17 01:03:45 INFO DAGScheduler: ResultStage 57 (parquet at RFormula.scala:521) finished in 0.015 s
21/02/17 01:03:45 INFO DAGScheduler: Job 45 is finished. Cancelling potential speculative or zombie tasks for this job
21/02/17 01:03:45 INFO TaskSchedulerImpl: Killing all running tasks in stage 57: Stage finished
21/02/17 01:03:45 INFO DAGScheduler: Job 45 finished: parquet at RFormula.scala:521, took 0.016497 s
21/02/17 01:03:45 INFO FileSourceStrategy: Pruning directories with: 
21/02/17 01:03:45 INFO FileSourceStrategy: Pushed Filters: 
21/02/17 01:03:45 INFO FileSourceStrategy: Post-Scan Filters: 
21/02/17 01:03:45 INFO FileSourceStrategy: Output Data Schema: struct<columnsToPrune: array<string>>
21/02/17 01:03:45 INFO MemoryStore: Block broadcast_73 stored as values in memory (estimated size 318.3 KiB, free 910.2 MiB)
21/02/17 01:03:45 INFO MemoryStore: Block broadcast_73_piece0 stored as bytes in memory (estimated size 28.9 KiB, free 910.2 MiB)
21/02/17 01:03:45 INFO BlockManagerInfo: Added broadcast_73_piece0 in memory on localhost:37167 (size: 28.9 KiB, free: 912.0 MiB)
21/02/17 01:03:45 INFO SparkContext: Created broadcast 73 from head at RFormula.scala:521
21/02/17 01:03:45 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
21/02/17 01:03:45 INFO SparkContext: Starting job: head at RFormula.scala:521
21/02/17 01:03:45 INFO DAGScheduler: Got job 46 (head at RFormula.scala:521) with 1 output partitions
21/02/17 01:03:45 INFO DAGScheduler: Final stage: ResultStage 58 (head at RFormula.scala:521)
21/02/17 01:03:45 INFO DAGScheduler: Parents of final stage: List()
21/02/17 01:03:45 INFO DAGScheduler: Missing parents: List()
21/02/17 01:03:45 INFO DAGScheduler: Submitting ResultStage 58 (MapPartitionsRDD[178] at head at RFormula.scala:521), which has no missing parents
21/02/17 01:03:45 INFO MemoryStore: Block broadcast_74 stored as values in memory (estimated size 8.9 KiB, free 910.2 MiB)
21/02/17 01:03:45 INFO MemoryStore: Block broadcast_74_piece0 stored as bytes in memory (estimated size 4.8 KiB, free 910.2 MiB)
21/02/17 01:03:45 INFO BlockManagerInfo: Added broadcast_74_piece0 in memory on localhost:37167 (size: 4.8 KiB, free: 912.0 MiB)
21/02/17 01:03:45 INFO SparkContext: Created broadcast 74 from broadcast at DAGScheduler.scala:1200
21/02/17 01:03:45 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 58 (MapPartitionsRDD[178] at head at RFormula.scala:521) (first 15 tasks are for partitions Vector(0))
21/02/17 01:03:45 INFO TaskSchedulerImpl: Adding task set 58.0 with 1 tasks
21/02/17 01:03:45 INFO TaskSetManager: Starting task 0.0 in stage 58.0 (TID 60, localhost, executor driver, partition 0, PROCESS_LOCAL, 7916 bytes)
21/02/17 01:03:45 INFO Executor: Running task 0.0 in stage 58.0 (TID 60)
21/02/17 01:03:45 INFO FileScanRDD: Reading File path: file:///tmp/RtmpdJZfO0/file1fe9816a0746c/stages/0_r_formula__a8f3fe0a_f74c_4053_97c3_d6d773d4c9bd/pipelineModel/stages/2_columnPruner_b54e3fcdd491/data/part-00000-bd65526d-8f51-4ac7-a487-d460e1f4880d-c000.snappy.parquet, range: 0-510, partition values: [empty row]
21/02/17 01:03:45 INFO Executor: Finished task 0.0 in stage 58.0 (TID 60). 1709 bytes result sent to driver
21/02/17 01:03:45 INFO TaskSetManager: Finished task 0.0 in stage 58.0 (TID 60) in 8 ms on localhost (executor driver) (1/1)
21/02/17 01:03:45 INFO TaskSchedulerImpl: Removed TaskSet 58.0, whose tasks have all completed, from pool 
21/02/17 01:03:45 INFO DAGScheduler: ResultStage 58 (head at RFormula.scala:521) finished in 0.012 s
21/02/17 01:03:45 INFO DAGScheduler: Job 46 is finished. Cancelling potential speculative or zombie tasks for this job
21/02/17 01:03:45 INFO TaskSchedulerImpl: Killing all running tasks in stage 58: Stage finished
21/02/17 01:03:45 INFO DAGScheduler: Job 46 finished: head at RFormula.scala:521, took 0.013651 s
21/02/17 01:03:45 INFO CodeGenerator: Code generated in 9.740437 ms
21/02/17 01:03:45 INFO Instrumentation: [2372e648] training finished
21/02/17 01:03:45 INFO Instrumentation: [f832db0e] training finished
21/02/17 01:03:45 INFO MemoryStore: Block broadcast_75 stored as values in memory (estimated size 294.6 KiB, free 909.9 MiB)
21/02/17 01:03:45 INFO MemoryStore: Block broadcast_75_piece0 stored as bytes in memory (estimated size 27.2 KiB, free 909.9 MiB)
21/02/17 01:03:45 INFO BlockManagerInfo: Added broadcast_75_piece0 in memory on localhost:37167 (size: 27.2 KiB, free: 912.0 MiB)
21/02/17 01:03:45 INFO SparkContext: Created broadcast 75 from textFile at ReadWrite.scala:587
21/02/17 01:03:45 INFO FileInputFormat: Total input files to process : 1
21/02/17 01:03:45 INFO SparkContext: Starting job: first at ReadWrite.scala:587
21/02/17 01:03:45 INFO DAGScheduler: Got job 47 (first at ReadWrite.scala:587) with 1 output partitions
21/02/17 01:03:45 INFO DAGScheduler: Final stage: ResultStage 59 (first at ReadWrite.scala:587)
21/02/17 01:03:45 INFO DAGScheduler: Parents of final stage: List()
21/02/17 01:03:45 INFO DAGScheduler: Missing parents: List()
21/02/17 01:03:45 INFO DAGScheduler: Submitting ResultStage 59 (/tmp/RtmpdJZfO0/file1fe9816a0746c/stages/1_xgboost_regressor__ca0588f9_18d0_4aef_81e6_bf950f6e60ff/metadata MapPartitionsRDD[180] at textFile at ReadWrite.scala:587), which has no missing parents
21/02/17 01:03:45 INFO MemoryStore: Block broadcast_76 stored as values in memory (estimated size 4.2 KiB, free 909.8 MiB)
21/02/17 01:03:45 INFO MemoryStore: Block broadcast_76_piece0 stored as bytes in memory (estimated size 2.5 KiB, free 909.8 MiB)
21/02/17 01:03:45 INFO BlockManagerInfo: Added broadcast_76_piece0 in memory on localhost:37167 (size: 2.5 KiB, free: 912.0 MiB)
21/02/17 01:03:45 INFO SparkContext: Created broadcast 76 from broadcast at DAGScheduler.scala:1200
21/02/17 01:03:45 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 59 (/tmp/RtmpdJZfO0/file1fe9816a0746c/stages/1_xgboost_regressor__ca0588f9_18d0_4aef_81e6_bf950f6e60ff/metadata MapPartitionsRDD[180] at textFile at ReadWrite.scala:587) (first 15 tasks are for partitions Vector(0))
21/02/17 01:03:45 INFO TaskSchedulerImpl: Adding task set 59.0 with 1 tasks
21/02/17 01:03:45 INFO TaskSetManager: Starting task 0.0 in stage 59.0 (TID 61, localhost, executor driver, partition 0, PROCESS_LOCAL, 7464 bytes)
21/02/17 01:03:45 INFO Executor: Running task 0.0 in stage 59.0 (TID 61)
21/02/17 01:03:45 INFO HadoopRDD: Input split: file:/tmp/RtmpdJZfO0/file1fe9816a0746c/stages/1_xgboost_regressor__ca0588f9_18d0_4aef_81e6_bf950f6e60ff/metadata/part-00000:0+1284
21/02/17 01:03:45 INFO Executor: Finished task 0.0 in stage 59.0 (TID 61). 2217 bytes result sent to driver
21/02/17 01:03:45 INFO TaskSetManager: Finished task 0.0 in stage 59.0 (TID 61) in 4 ms on localhost (executor driver) (1/1)
21/02/17 01:03:45 INFO TaskSchedulerImpl: Removed TaskSet 59.0, whose tasks have all completed, from pool 
21/02/17 01:03:45 INFO DAGScheduler: ResultStage 59 (first at ReadWrite.scala:587) finished in 0.006 s
21/02/17 01:03:45 INFO DAGScheduler: Job 47 is finished. Cancelling potential speculative or zombie tasks for this job
21/02/17 01:03:45 INFO TaskSchedulerImpl: Killing all running tasks in stage 59: Stage finished
21/02/17 01:03:45 INFO DAGScheduler: Job 47 finished: first at ReadWrite.scala:587, took 0.008470 s
21/02/17 01:03:45 INFO MemoryStore: Block broadcast_77 stored as values in memory (estimated size 294.6 KiB, free 909.6 MiB)
21/02/17 01:03:45 INFO MemoryStore: Block broadcast_77_piece0 stored as bytes in memory (estimated size 27.2 KiB, free 909.5 MiB)
21/02/17 01:03:45 INFO BlockManagerInfo: Added broadcast_77_piece0 in memory on localhost:37167 (size: 27.2 KiB, free: 912.0 MiB)
21/02/17 01:03:45 INFO SparkContext: Created broadcast 77 from textFile at DefaultXGBoostParamsReader.scala:82
21/02/17 01:03:45 INFO FileInputFormat: Total input files to process : 1
21/02/17 01:03:45 INFO SparkContext: Starting job: first at DefaultXGBoostParamsReader.scala:82
21/02/17 01:03:45 INFO DAGScheduler: Got job 48 (first at DefaultXGBoostParamsReader.scala:82) with 1 output partitions
21/02/17 01:03:45 INFO DAGScheduler: Final stage: ResultStage 60 (first at DefaultXGBoostParamsReader.scala:82)
21/02/17 01:03:45 INFO DAGScheduler: Parents of final stage: List()
21/02/17 01:03:45 INFO DAGScheduler: Missing parents: List()
21/02/17 01:03:45 INFO DAGScheduler: Submitting ResultStage 60 (/tmp/RtmpdJZfO0/file1fe9816a0746c/stages/1_xgboost_regressor__ca0588f9_18d0_4aef_81e6_bf950f6e60ff/metadata MapPartitionsRDD[182] at textFile at DefaultXGBoostParamsReader.scala:82), which has no missing parents
21/02/17 01:03:45 INFO MemoryStore: Block broadcast_78 stored as values in memory (estimated size 4.2 KiB, free 909.5 MiB)
21/02/17 01:03:45 INFO MemoryStore: Block broadcast_78_piece0 stored as bytes in memory (estimated size 2.5 KiB, free 909.5 MiB)
21/02/17 01:03:45 INFO BlockManagerInfo: Added broadcast_78_piece0 in memory on localhost:37167 (size: 2.5 KiB, free: 912.0 MiB)
21/02/17 01:03:45 INFO SparkContext: Created broadcast 78 from broadcast at DAGScheduler.scala:1200
21/02/17 01:03:45 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 60 (/tmp/RtmpdJZfO0/file1fe9816a0746c/stages/1_xgboost_regressor__ca0588f9_18d0_4aef_81e6_bf950f6e60ff/metadata MapPartitionsRDD[182] at textFile at DefaultXGBoostParamsReader.scala:82) (first 15 tasks are for partitions Vector(0))
21/02/17 01:03:45 INFO TaskSchedulerImpl: Adding task set 60.0 with 1 tasks
21/02/17 01:03:45 INFO TaskSetManager: Starting task 0.0 in stage 60.0 (TID 62, localhost, executor driver, partition 0, PROCESS_LOCAL, 7464 bytes)
21/02/17 01:03:45 INFO Executor: Running task 0.0 in stage 60.0 (TID 62)
21/02/17 01:03:45 INFO HadoopRDD: Input split: file:/tmp/RtmpdJZfO0/file1fe9816a0746c/stages/1_xgboost_regressor__ca0588f9_18d0_4aef_81e6_bf950f6e60ff/metadata/part-00000:0+1284
21/02/17 01:03:45 INFO Executor: Finished task 0.0 in stage 60.0 (TID 62). 2217 bytes result sent to driver
21/02/17 01:03:45 INFO TaskSetManager: Finished task 0.0 in stage 60.0 (TID 62) in 3 ms on localhost (executor driver) (1/1)
21/02/17 01:03:45 INFO TaskSchedulerImpl: Removed TaskSet 60.0, whose tasks have all completed, from pool 
21/02/17 01:03:45 INFO DAGScheduler: ResultStage 60 (first at DefaultXGBoostParamsReader.scala:82) finished in 0.006 s
21/02/17 01:03:45 INFO DAGScheduler: Job 48 is finished. Cancelling potential speculative or zombie tasks for this job
21/02/17 01:03:45 INFO TaskSchedulerImpl: Killing all running tasks in stage 60: Stage finished
21/02/17 01:03:45 INFO DAGScheduler: Job 48 finished: first at DefaultXGBoostParamsReader.scala:82, took 0.007902 s
21/02/17 01:03:45 INFO Instrumentation: [6a89eb24] training finished
21/02/17 01:03:45 INFO Instrumentation: [af961110] training finished
21/02/17 01:03:45 INFO Instrumentation: [253291d0] training finished
21/02/17 01:03:45 INFO MemoryStore: Block broadcast_79 stored as values in memory (estimated size 64.0 B, free 909.5 MiB)
21/02/17 01:03:45 INFO MemoryStore: Block broadcast_79_piece0 stored as bytes in memory (estimated size 515.0 B, free 909.5 MiB)
21/02/17 01:03:45 INFO BlockManagerInfo: Added broadcast_79_piece0 in memory on localhost:37167 (size: 515.0 B, free: 912.0 MiB)
21/02/17 01:03:45 INFO SparkContext: Created broadcast 79 from broadcast at XGBoostRegressor.scala:279
21/02/17 01:03:45 INFO Instrumentation: [89067d87] training finished
21/02/17 01:03:45 INFO SparkContext: Starting job: collect at utils.scala:137
21/02/17 01:03:45 INFO DAGScheduler: Got job 49 (collect at utils.scala:137) with 1 output partitions
21/02/17 01:03:45 INFO DAGScheduler: Final stage: ResultStage 61 (collect at utils.scala:137)
21/02/17 01:03:45 INFO DAGScheduler: Parents of final stage: List()
21/02/17 01:03:45 INFO DAGScheduler: Missing parents: List()
21/02/17 01:03:45 INFO DAGScheduler: Submitting ResultStage 61 (MapPartitionsRDD[192] at collect at utils.scala:137), which has no missing parents
21/02/17 01:03:45 INFO MemoryStore: Block broadcast_80 stored as values in memory (estimated size 7.3 KiB, free 909.5 MiB)
21/02/17 01:03:45 INFO MemoryStore: Block broadcast_80_piece0 stored as bytes in memory (estimated size 3.7 KiB, free 909.5 MiB)
21/02/17 01:03:45 INFO BlockManagerInfo: Added broadcast_80_piece0 in memory on localhost:37167 (size: 3.7 KiB, free: 912.0 MiB)
21/02/17 01:03:45 INFO SparkContext: Created broadcast 80 from broadcast at DAGScheduler.scala:1200
21/02/17 01:03:45 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 61 (MapPartitionsRDD[192] at collect at utils.scala:137) (first 15 tasks are for partitions Vector(0))
21/02/17 01:03:45 INFO TaskSchedulerImpl: Adding task set 61.0 with 1 tasks
21/02/17 01:03:45 INFO TaskSetManager: Starting task 0.0 in stage 61.0 (TID 63, localhost, executor driver, partition 0, PROCESS_LOCAL, 7561 bytes)
21/02/17 01:03:45 INFO Executor: Running task 0.0 in stage 61.0 (TID 63)
21/02/17 01:03:45 INFO Executor: Finished task 0.0 in stage 61.0 (TID 63). 1354 bytes result sent to driver
21/02/17 01:03:45 INFO TaskSetManager: Finished task 0.0 in stage 61.0 (TID 63) in 3 ms on localhost (executor driver) (1/1)
21/02/17 01:03:45 INFO TaskSchedulerImpl: Removed TaskSet 61.0, whose tasks have all completed, from pool 
21/02/17 01:03:45 INFO DAGScheduler: ResultStage 61 (collect at utils.scala:137) finished in 0.007 s
21/02/17 01:03:45 INFO DAGScheduler: Job 49 is finished. Cancelling potential speculative or zombie tasks for this job
21/02/17 01:03:45 INFO TaskSchedulerImpl: Killing all running tasks in stage 61: Stage finished
21/02/17 01:03:45 INFO DAGScheduler: Job 49 finished: collect at utils.scala:137, took 0.008400 s
21/02/17 01:03:45 INFO BlockManagerInfo: Removed broadcast_76_piece0 on localhost:37167 in memory (size: 2.5 KiB, free: 912.0 MiB)
21/02/17 01:03:45 INFO BlockManagerInfo: Removed broadcast_78_piece0 on localhost:37167 in memory (size: 2.5 KiB, free: 912.0 MiB)
21/02/17 01:03:45 INFO BlockManagerInfo: Removed broadcast_74_piece0 on localhost:37167 in memory (size: 4.8 KiB, free: 912.0 MiB)
21/02/17 01:03:45 INFO BlockManagerInfo: Removed broadcast_67_piece0 on localhost:37167 in memory (size: 4.8 KiB, free: 912.0 MiB)
21/02/17 01:03:45 INFO BlockManagerInfo: Removed broadcast_65_piece0 on localhost:37167 in memory (size: 30.8 KiB, free: 912.0 MiB)
21/02/17 01:03:45 INFO BlockManagerInfo: Removed broadcast_75_piece0 on localhost:37167 in memory (size: 27.2 KiB, free: 912.0 MiB)
21/02/17 01:03:45 INFO BlockManagerInfo: Removed broadcast_64_piece0 on localhost:37167 in memory (size: 2.5 KiB, free: 912.0 MiB)
21/02/17 01:03:45 INFO BlockManagerInfo: Removed broadcast_63_piece0 on localhost:37167 in memory (size: 27.2 KiB, free: 912.1 MiB)
21/02/17 01:03:45 INFO BlockManagerInfo: Removed broadcast_80_piece0 on localhost:37167 in memory (size: 3.7 KiB, free: 912.1 MiB)
21/02/17 01:03:45 INFO BlockManagerInfo: Removed broadcast_71_piece0 on localhost:37167 in memory (size: 2.5 KiB, free: 912.1 MiB)
21/02/17 01:03:45 INFO BlockManagerInfo: Removed broadcast_68_piece0 on localhost:37167 in memory (size: 27.2 KiB, free: 912.1 MiB)
21/02/17 01:03:45 INFO BlockManagerInfo: Removed broadcast_66_piece0 on localhost:37167 in memory (size: 29.0 KiB, free: 912.1 MiB)
21/02/17 01:03:45 INFO BlockManagerInfo: Removed broadcast_73_piece0 on localhost:37167 in memory (size: 28.9 KiB, free: 912.1 MiB)
21/02/17 01:03:45 INFO BlockManagerInfo: Removed broadcast_72_piece0 on localhost:37167 in memory (size: 30.8 KiB, free: 912.2 MiB)
21/02/17 01:03:45 INFO SparkContext: Starting job: count at utils.scala:135
21/02/17 01:03:45 INFO BlockManagerInfo: Removed broadcast_77_piece0 on localhost:37167 in memory (size: 27.2 KiB, free: 912.2 MiB)
21/02/17 01:03:45 INFO DAGScheduler: Registering RDD 194 (count at utils.scala:135) as input to shuffle 13
21/02/17 01:03:45 INFO DAGScheduler: Got job 50 (count at utils.scala:135) with 1 output partitions
21/02/17 01:03:45 INFO DAGScheduler: Final stage: ResultStage 63 (count at utils.scala:135)
21/02/17 01:03:45 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 62)
21/02/17 01:03:45 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 62)
21/02/17 01:03:45 INFO BlockManagerInfo: Removed broadcast_69_piece0 on localhost:37167 in memory (size: 2.5 KiB, free: 912.2 MiB)
21/02/17 01:03:45 INFO DAGScheduler: Submitting ShuffleMapStage 62 (MapPartitionsRDD[194] at count at utils.scala:135), which has no missing parents
21/02/17 01:03:45 INFO BlockManagerInfo: Removed broadcast_70_piece0 on localhost:37167 in memory (size: 27.2 KiB, free: 912.2 MiB)
21/02/17 01:03:45 INFO MemoryStore: Block broadcast_81 stored as values in memory (estimated size 10.0 KiB, free 912.1 MiB)
21/02/17 01:03:45 INFO MemoryStore: Block broadcast_81_piece0 stored as bytes in memory (estimated size 5.2 KiB, free 912.0 MiB)
21/02/17 01:03:45 INFO BlockManagerInfo: Added broadcast_81_piece0 in memory on localhost:37167 (size: 5.2 KiB, free: 912.2 MiB)
21/02/17 01:03:45 INFO SparkContext: Created broadcast 81 from broadcast at DAGScheduler.scala:1200
21/02/17 01:03:45 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 62 (MapPartitionsRDD[194] at count at utils.scala:135) (first 15 tasks are for partitions Vector(0))
21/02/17 01:03:45 INFO TaskSchedulerImpl: Adding task set 62.0 with 1 tasks
21/02/17 01:03:45 INFO TaskSetManager: Starting task 0.0 in stage 62.0 (TID 64, localhost, executor driver, partition 0, PROCESS_LOCAL, 7550 bytes)
21/02/17 01:03:45 INFO Executor: Running task 0.0 in stage 62.0 (TID 64)
21/02/17 01:03:45 INFO Executor: Finished task 0.0 in stage 62.0 (TID 64). 1833 bytes result sent to driver
21/02/17 01:03:45 INFO TaskSetManager: Finished task 0.0 in stage 62.0 (TID 64) in 3 ms on localhost (executor driver) (1/1)
21/02/17 01:03:45 INFO TaskSchedulerImpl: Removed TaskSet 62.0, whose tasks have all completed, from pool 
21/02/17 01:03:45 INFO DAGScheduler: ShuffleMapStage 62 (count at utils.scala:135) finished in 0.007 s
21/02/17 01:03:45 INFO DAGScheduler: looking for newly runnable stages
21/02/17 01:03:45 INFO DAGScheduler: running: Set()
21/02/17 01:03:45 INFO DAGScheduler: waiting: Set(ResultStage 63)
21/02/17 01:03:45 INFO DAGScheduler: failed: Set()
21/02/17 01:03:45 INFO DAGScheduler: Submitting ResultStage 63 (MapPartitionsRDD[197] at count at utils.scala:135), which has no missing parents
21/02/17 01:03:45 INFO MemoryStore: Block broadcast_82 stored as values in memory (estimated size 10.1 KiB, free 912.0 MiB)
21/02/17 01:03:45 INFO MemoryStore: Block broadcast_82_piece0 stored as bytes in memory (estimated size 5.0 KiB, free 912.0 MiB)
21/02/17 01:03:45 INFO BlockManagerInfo: Added broadcast_82_piece0 in memory on localhost:37167 (size: 5.0 KiB, free: 912.2 MiB)
21/02/17 01:03:45 INFO SparkContext: Created broadcast 82 from broadcast at DAGScheduler.scala:1200
21/02/17 01:03:45 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 63 (MapPartitionsRDD[197] at count at utils.scala:135) (first 15 tasks are for partitions Vector(0))
21/02/17 01:03:45 INFO TaskSchedulerImpl: Adding task set 63.0 with 1 tasks
21/02/17 01:03:45 INFO TaskSetManager: Starting task 0.0 in stage 63.0 (TID 65, localhost, executor driver, partition 0, NODE_LOCAL, 7325 bytes)
21/02/17 01:03:45 INFO Executor: Running task 0.0 in stage 63.0 (TID 65)
21/02/17 01:03:45 INFO ShuffleBlockFetcherIterator: Getting 1 (60.0 B) non-empty blocks including 1 (60.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
21/02/17 01:03:45 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
21/02/17 01:03:45 INFO Executor: Finished task 0.0 in stage 63.0 (TID 65). 2605 bytes result sent to driver
21/02/17 01:03:45 INFO TaskSetManager: Finished task 0.0 in stage 63.0 (TID 65) in 4 ms on localhost (executor driver) (1/1)
21/02/17 01:03:45 INFO TaskSchedulerImpl: Removed TaskSet 63.0, whose tasks have all completed, from pool 
21/02/17 01:03:45 INFO DAGScheduler: ResultStage 63 (count at utils.scala:135) finished in 0.006 s
21/02/17 01:03:45 INFO DAGScheduler: Job 50 is finished. Cancelling potential speculative or zombie tasks for this job
21/02/17 01:03:45 INFO TaskSchedulerImpl: Killing all running tasks in stage 63: Stage finished
21/02/17 01:03:45 INFO DAGScheduler: Job 50 finished: count at utils.scala:135, took 0.015343 s
21/02/17 01:03:45 INFO SparkContext: Starting job: collect at utils.scala:137
21/02/17 01:03:45 INFO DAGScheduler: Got job 51 (collect at utils.scala:137) with 1 output partitions
21/02/17 01:03:45 INFO DAGScheduler: Final stage: ResultStage 64 (collect at utils.scala:137)
21/02/17 01:03:45 INFO DAGScheduler: Parents of final stage: List()
21/02/17 01:03:45 INFO DAGScheduler: Missing parents: List()
21/02/17 01:03:45 INFO DAGScheduler: Submitting ResultStage 64 (MapPartitionsRDD[199] at collect at utils.scala:137), which has no missing parents
21/02/17 01:03:45 INFO MemoryStore: Block broadcast_83 stored as values in memory (estimated size 71.2 KiB, free 912.0 MiB)
21/02/17 01:03:45 INFO MemoryStore: Block broadcast_83_piece0 stored as bytes in memory (estimated size 28.3 KiB, free 911.9 MiB)
21/02/17 01:03:45 INFO BlockManagerInfo: Added broadcast_83_piece0 in memory on localhost:37167 (size: 28.3 KiB, free: 912.2 MiB)
21/02/17 01:03:45 INFO SparkContext: Created broadcast 83 from broadcast at DAGScheduler.scala:1200
21/02/17 01:03:45 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 64 (MapPartitionsRDD[199] at collect at utils.scala:137) (first 15 tasks are for partitions Vector(0))
21/02/17 01:03:45 INFO TaskSchedulerImpl: Adding task set 64.0 with 1 tasks
21/02/17 01:03:45 INFO TaskSetManager: Starting task 0.0 in stage 64.0 (TID 66, localhost, executor driver, partition 0, PROCESS_LOCAL, 18492 bytes)
21/02/17 01:03:45 INFO Executor: Running task 0.0 in stage 64.0 (TID 66)
21/02/17 01:03:45 INFO BlockManager: Found block rdd_23_0 locally
21/02/17 01:03:45 INFO Executor: Finished task 0.0 in stage 64.0 (TID 66). 1912 bytes result sent to driver
21/02/17 01:03:45 INFO TaskSetManager: Finished task 0.0 in stage 64.0 (TID 66) in 28 ms on localhost (executor driver) (1/1)
21/02/17 01:03:45 INFO TaskSchedulerImpl: Removed TaskSet 64.0, whose tasks have all completed, from pool 
21/02/17 01:03:45 INFO DAGScheduler: ResultStage 64 (collect at utils.scala:137) finished in 0.033 s
21/02/17 01:03:45 INFO DAGScheduler: Job 51 is finished. Cancelling potential speculative or zombie tasks for this job
21/02/17 01:03:45 INFO TaskSchedulerImpl: Killing all running tasks in stage 64: Stage finished
21/02/17 01:03:45 INFO DAGScheduler: Job 51 finished: collect at utils.scala:137, took 0.035625 s
21/02/17 01:03:45 INFO SparkContext: Starting job: count at utils.scala:135
21/02/17 01:03:45 INFO DAGScheduler: Registering RDD 201 (count at utils.scala:135) as input to shuffle 14
21/02/17 01:03:45 INFO DAGScheduler: Got job 52 (count at utils.scala:135) with 1 output partitions
21/02/17 01:03:45 INFO DAGScheduler: Final stage: ResultStage 66 (count at utils.scala:135)
21/02/17 01:03:45 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 65)
21/02/17 01:03:45 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 65)
21/02/17 01:03:45 INFO DAGScheduler: Submitting ShuffleMapStage 65 (MapPartitionsRDD[201] at count at utils.scala:135), which has no missing parents
21/02/17 01:03:45 INFO MemoryStore: Block broadcast_84 stored as values in memory (estimated size 72.7 KiB, free 911.9 MiB)
21/02/17 01:03:45 INFO MemoryStore: Block broadcast_84_piece0 stored as bytes in memory (estimated size 29.0 KiB, free 911.8 MiB)
21/02/17 01:03:45 INFO BlockManagerInfo: Added broadcast_84_piece0 in memory on localhost:37167 (size: 29.0 KiB, free: 912.2 MiB)
21/02/17 01:03:45 INFO SparkContext: Created broadcast 84 from broadcast at DAGScheduler.scala:1200
21/02/17 01:03:45 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 65 (MapPartitionsRDD[201] at count at utils.scala:135) (first 15 tasks are for partitions Vector(0))
21/02/17 01:03:45 INFO TaskSchedulerImpl: Adding task set 65.0 with 1 tasks
21/02/17 01:03:46 INFO TaskSetManager: Starting task 0.0 in stage 65.0 (TID 67, localhost, executor driver, partition 0, PROCESS_LOCAL, 18481 bytes)
21/02/17 01:03:46 INFO Executor: Running task 0.0 in stage 65.0 (TID 67)
21/02/17 01:03:46 INFO BlockManager: Found block rdd_23_0 locally
21/02/17 01:03:46 INFO Executor: Finished task 0.0 in stage 65.0 (TID 67). 2253 bytes result sent to driver
21/02/17 01:03:46 INFO TaskSetManager: Finished task 0.0 in stage 65.0 (TID 67) in 24 ms on localhost (executor driver) (1/1)
21/02/17 01:03:46 INFO TaskSchedulerImpl: Removed TaskSet 65.0, whose tasks have all completed, from pool 
21/02/17 01:03:46 INFO DAGScheduler: ShuffleMapStage 65 (count at utils.scala:135) finished in 0.027 s
21/02/17 01:03:46 INFO DAGScheduler: looking for newly runnable stages
21/02/17 01:03:46 INFO DAGScheduler: running: Set()
21/02/17 01:03:46 INFO DAGScheduler: waiting: Set(ResultStage 66)
21/02/17 01:03:46 INFO DAGScheduler: failed: Set()
21/02/17 01:03:46 INFO DAGScheduler: Submitting ResultStage 66 (MapPartitionsRDD[204] at count at utils.scala:135), which has no missing parents
21/02/17 01:03:46 INFO MemoryStore: Block broadcast_85 stored as values in memory (estimated size 10.1 KiB, free 911.8 MiB)
21/02/17 01:03:46 INFO MemoryStore: Block broadcast_85_piece0 stored as bytes in memory (estimated size 5.0 KiB, free 911.8 MiB)
21/02/17 01:03:46 INFO BlockManagerInfo: Added broadcast_85_piece0 in memory on localhost:37167 (size: 5.0 KiB, free: 912.2 MiB)
21/02/17 01:03:46 INFO SparkContext: Created broadcast 85 from broadcast at DAGScheduler.scala:1200
21/02/17 01:03:46 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 66 (MapPartitionsRDD[204] at count at utils.scala:135) (first 15 tasks are for partitions Vector(0))
21/02/17 01:03:46 INFO TaskSchedulerImpl: Adding task set 66.0 with 1 tasks
21/02/17 01:03:46 INFO TaskSetManager: Starting task 0.0 in stage 66.0 (TID 68, localhost, executor driver, partition 0, NODE_LOCAL, 7325 bytes)
21/02/17 01:03:46 INFO Executor: Running task 0.0 in stage 66.0 (TID 68)
21/02/17 01:03:46 INFO ShuffleBlockFetcherIterator: Getting 1 (60.0 B) non-empty blocks including 1 (60.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
21/02/17 01:03:46 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
21/02/17 01:03:46 INFO Executor: Finished task 0.0 in stage 66.0 (TID 68). 2648 bytes result sent to driver
21/02/17 01:03:46 INFO TaskSetManager: Finished task 0.0 in stage 66.0 (TID 68) in 4 ms on localhost (executor driver) (1/1)
21/02/17 01:03:46 INFO TaskSchedulerImpl: Removed TaskSet 66.0, whose tasks have all completed, from pool 
21/02/17 01:03:46 INFO DAGScheduler: ResultStage 66 (count at utils.scala:135) finished in 0.007 s
21/02/17 01:03:46 INFO DAGScheduler: Job 52 is finished. Cancelling potential speculative or zombie tasks for this job
21/02/17 01:03:46 INFO TaskSchedulerImpl: Killing all running tasks in stage 66: Stage finished
21/02/17 01:03:46 INFO DAGScheduler: Job 52 finished: count at utils.scala:135, took 0.038196 s
21/02/17 01:03:47 INFO SparkContext: Invoking stop() from shutdown hook
21/02/17 01:03:47 INFO SparkUI: Stopped Spark web UI at http://localhost:4040
21/02/17 01:03:47 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!
21/02/17 01:03:47 INFO MemoryStore: MemoryStore cleared
21/02/17 01:03:47 INFO BlockManager: BlockManager stopped
21/02/17 01:03:47 INFO BlockManagerMaster: BlockManagerMaster stopped
21/02/17 01:03:47 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!
21/02/17 01:03:47 INFO SparkContext: Successfully stopped SparkContext
21/02/17 01:03:47 INFO ShutdownHookManager: Shutdown hook called
21/02/17 01:03:47 INFO ShutdownHookManager: Deleting directory /tmp/spark-a42d86af-ead5-41e1-9502-8350571fb19f
21/02/17 01:03:47 INFO ShutdownHookManager: Deleting directory /tmp/spark-7830d85d-e99e-4157-9d39-45ea74c0872e
21/02/17 01:04:14 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
21/02/17 01:04:14 INFO SecurityManager: Changing view acls to: yitaoli
21/02/17 01:04:14 INFO SecurityManager: Changing modify acls to: yitaoli
21/02/17 01:04:14 INFO SecurityManager: Changing view acls groups to: 
21/02/17 01:04:14 INFO SecurityManager: Changing modify acls groups to: 
21/02/17 01:04:14 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(yitaoli); groups with view permissions: Set(); users  with modify permissions: Set(yitaoli); groups with modify permissions: Set()
21/02/17 01:04:15 INFO HiveConf: Found configuration file file:/home/yitaoli/spark/spark-3.0.0-bin-hadoop3.2/conf/hive-site.xml
21/02/17 01:04:15 INFO SparkContext: Running Spark version 3.0.0
21/02/17 01:04:15 INFO ResourceUtils: ==============================================================
21/02/17 01:04:15 INFO ResourceUtils: Resources for spark.driver:

21/02/17 01:04:15 INFO ResourceUtils: ==============================================================
21/02/17 01:04:15 INFO SparkContext: Submitted application: sparklyr
21/02/17 01:04:15 INFO SecurityManager: Changing view acls to: yitaoli
21/02/17 01:04:15 INFO SecurityManager: Changing modify acls to: yitaoli
21/02/17 01:04:15 INFO SecurityManager: Changing view acls groups to: 
21/02/17 01:04:15 INFO SecurityManager: Changing modify acls groups to: 
21/02/17 01:04:15 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(yitaoli); groups with view permissions: Set(); users  with modify permissions: Set(yitaoli); groups with modify permissions: Set()
21/02/17 01:04:15 INFO Utils: Successfully started service 'sparkDriver' on port 43599.
21/02/17 01:04:15 INFO SparkEnv: Registering MapOutputTracker
21/02/17 01:04:15 INFO SparkEnv: Registering BlockManagerMaster
21/02/17 01:04:15 INFO BlockManagerMasterEndpoint: Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
21/02/17 01:04:15 INFO BlockManagerMasterEndpoint: BlockManagerMasterEndpoint up
21/02/17 01:04:15 INFO SparkEnv: Registering BlockManagerMasterHeartbeat
21/02/17 01:04:15 INFO DiskBlockManager: Created local directory at /tmp/blockmgr-3cf63c80-b028-415b-9886-01d24b087bc2
21/02/17 01:04:15 INFO MemoryStore: MemoryStore started with capacity 912.3 MiB
21/02/17 01:04:15 INFO SparkEnv: Registering OutputCommitCoordinator
21/02/17 01:04:15 INFO Utils: Successfully started service 'SparkUI' on port 4040.
21/02/17 01:04:15 INFO SparkUI: Bound SparkUI to 127.0.0.1, and started at http://localhost:4040
21/02/17 01:04:15 INFO SparkContext: Added JAR file:///home/yitaoli/.ivy2/jars/ml.dmlc_xgboost4j-spark_2.12-1.3.1.jar at spark://localhost:43599/jars/ml.dmlc_xgboost4j-spark_2.12-1.3.1.jar with timestamp 1613523855863
21/02/17 01:04:15 INFO SparkContext: Added JAR file:///home/yitaoli/.ivy2/jars/ml.dmlc_xgboost4j_2.12-1.3.1.jar at spark://localhost:43599/jars/ml.dmlc_xgboost4j_2.12-1.3.1.jar with timestamp 1613523855864
21/02/17 01:04:15 INFO SparkContext: Added JAR file:///home/yitaoli/.ivy2/jars/com.esotericsoftware_kryo-4.0.2.jar at spark://localhost:43599/jars/com.esotericsoftware_kryo-4.0.2.jar with timestamp 1613523855864
21/02/17 01:04:15 INFO SparkContext: Added JAR file:///home/yitaoli/.ivy2/jars/org.scala-lang_scala-compiler-2.12.8.jar at spark://localhost:43599/jars/org.scala-lang_scala-compiler-2.12.8.jar with timestamp 1613523855864
21/02/17 01:04:15 INFO SparkContext: Added JAR file:///home/yitaoli/.ivy2/jars/org.scala-lang_scala-reflect-2.12.8.jar at spark://localhost:43599/jars/org.scala-lang_scala-reflect-2.12.8.jar with timestamp 1613523855864
21/02/17 01:04:15 INFO SparkContext: Added JAR file:///home/yitaoli/.ivy2/jars/commons-logging_commons-logging-1.2.jar at spark://localhost:43599/jars/commons-logging_commons-logging-1.2.jar with timestamp 1613523855864
21/02/17 01:04:15 INFO SparkContext: Added JAR file:///home/yitaoli/.ivy2/jars/com.typesafe.akka_akka-actor_2.12-2.5.23.jar at spark://localhost:43599/jars/com.typesafe.akka_akka-actor_2.12-2.5.23.jar with timestamp 1613523855864
21/02/17 01:04:15 INFO SparkContext: Added JAR file:///home/yitaoli/.ivy2/jars/org.scalatest_scalatest_2.12-3.0.5.jar at spark://localhost:43599/jars/org.scalatest_scalatest_2.12-3.0.5.jar with timestamp 1613523855865
21/02/17 01:04:15 INFO SparkContext: Added JAR file:///home/yitaoli/.ivy2/jars/com.typesafe_config-1.3.3.jar at spark://localhost:43599/jars/com.typesafe_config-1.3.3.jar with timestamp 1613523855865
21/02/17 01:04:15 INFO SparkContext: Added JAR file:///home/yitaoli/.ivy2/jars/org.scala-lang.modules_scala-java8-compat_2.12-0.8.0.jar at spark://localhost:43599/jars/org.scala-lang.modules_scala-java8-compat_2.12-0.8.0.jar with timestamp 1613523855865
21/02/17 01:04:15 INFO SparkContext: Added JAR file:///home/yitaoli/.ivy2/jars/org.scalactic_scalactic_2.12-3.0.5.jar at spark://localhost:43599/jars/org.scalactic_scalactic_2.12-3.0.5.jar with timestamp 1613523855865
21/02/17 01:04:15 INFO SparkContext: Added JAR file:///home/yitaoli/.ivy2/jars/org.scala-lang.modules_scala-xml_2.12-1.0.6.jar at spark://localhost:43599/jars/org.scala-lang.modules_scala-xml_2.12-1.0.6.jar with timestamp 1613523855865
21/02/17 01:04:15 INFO SparkContext: Added JAR file:///home/yitaoli/.ivy2/jars/com.esotericsoftware_reflectasm-1.11.3.jar at spark://localhost:43599/jars/com.esotericsoftware_reflectasm-1.11.3.jar with timestamp 1613523855865
21/02/17 01:04:15 INFO SparkContext: Added JAR file:///home/yitaoli/.ivy2/jars/com.esotericsoftware_minlog-1.3.0.jar at spark://localhost:43599/jars/com.esotericsoftware_minlog-1.3.0.jar with timestamp 1613523855865
21/02/17 01:04:15 INFO SparkContext: Added JAR file:///home/yitaoli/.ivy2/jars/org.objenesis_objenesis-2.5.1.jar at spark://localhost:43599/jars/org.objenesis_objenesis-2.5.1.jar with timestamp 1613523855865
21/02/17 01:04:15 INFO SparkContext: Added JAR file:///home/yitaoli/.ivy2/jars/org.ow2.asm_asm-5.0.4.jar at spark://localhost:43599/jars/org.ow2.asm_asm-5.0.4.jar with timestamp 1613523855865
21/02/17 01:04:15 INFO SparkContext: Added JAR file:/home/yitaoli/R/x86_64-pc-linux-gnu-library/4.0/sparklyr/java/sparklyr-3.0-2.12.jar at spark://localhost:43599/jars/sparklyr-3.0-2.12.jar with timestamp 1613523855866
21/02/17 01:04:15 INFO Executor: Starting executor ID driver on host localhost
21/02/17 01:04:15 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 39871.
21/02/17 01:04:15 INFO NettyBlockTransferService: Server created on localhost:39871
21/02/17 01:04:15 INFO BlockManager: Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
21/02/17 01:04:16 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, localhost, 39871, None)
21/02/17 01:04:16 INFO BlockManagerMasterEndpoint: Registering block manager localhost:39871 with 912.3 MiB RAM, BlockManagerId(driver, localhost, 39871, None)
21/02/17 01:04:16 INFO BlockManagerMaster: Registered BlockManager BlockManagerId(driver, localhost, 39871, None)
21/02/17 01:04:16 INFO BlockManager: Initialized BlockManager: BlockManagerId(driver, localhost, 39871, None)
21/02/17 01:04:16 INFO SharedState: loading hive config file: file:/home/yitaoli/spark/spark-3.0.0-bin-hadoop3.2/conf/hive-site.xml
21/02/17 01:04:16 INFO SharedState: Setting hive.metastore.warehouse.dir ('null') to the value of spark.sql.warehouse.dir ('file:/home/yitaoli/sparkxgb/tests/testthat/spark-warehouse').
21/02/17 01:04:16 INFO SharedState: Warehouse path is 'file:/home/yitaoli/sparkxgb/tests/testthat/spark-warehouse'.
21/02/17 01:04:17 INFO HiveUtils: Initializing HiveMetastoreConnection version 2.3.7 using Spark classes.
21/02/17 01:04:18 INFO HiveConf: Found configuration file file:/home/yitaoli/spark/spark-3.0.0-bin-hadoop3.2/conf/hive-site.xml
21/02/17 01:04:18 INFO SessionState: Created HDFS directory: /tmp/hive/yitaoli/56f7b10f-f32b-4aba-8a50-32ad2402d18f
21/02/17 01:04:18 INFO SessionState: Created local directory: /tmp/yitaoli/56f7b10f-f32b-4aba-8a50-32ad2402d18f
21/02/17 01:04:18 INFO SessionState: Created HDFS directory: /tmp/hive/yitaoli/56f7b10f-f32b-4aba-8a50-32ad2402d18f/_tmp_space.db
21/02/17 01:04:18 INFO HiveClientImpl: Warehouse location for Hive client (version 2.3.7) is file:/home/yitaoli/sparkxgb/tests/testthat/spark-warehouse
21/02/17 01:04:18 WARN HiveConf: HiveConf of name hive.stats.jdbc.timeout does not exist
21/02/17 01:04:18 WARN HiveConf: HiveConf of name hive.stats.retries.wait does not exist
21/02/17 01:04:18 INFO HiveMetaStore: 0: Opening raw store with implementation class:org.apache.hadoop.hive.metastore.ObjectStore
21/02/17 01:04:18 INFO ObjectStore: ObjectStore, initialize called
21/02/17 01:04:18 INFO Persistence: Property hive.metastore.integral.jdo.pushdown unknown - will be ignored
21/02/17 01:04:18 INFO Persistence: Property datanucleus.cache.level2 unknown - will be ignored
21/02/17 01:04:19 INFO ObjectStore: Setting MetaStore object pin classes with hive.metastore.cache.pinobjtypes="Table,StorageDescriptor,SerDeInfo,Partition,Database,Type,FieldSchema,Order"
21/02/17 01:04:20 INFO MetaStoreDirectSql: Using direct SQL, underlying DB is DERBY
21/02/17 01:04:20 INFO ObjectStore: Initialized ObjectStore
21/02/17 01:04:21 WARN ObjectStore: Version information not found in metastore. hive.metastore.schema.verification is not enabled so recording the schema version 2.3.0
21/02/17 01:04:21 WARN ObjectStore: setMetaStoreSchemaVersion called but recording version is disabled: version = 2.3.0, comment = Set by MetaStore yitaoli@127.0.1.1
21/02/17 01:04:21 WARN ObjectStore: Failed to get database default, returning NoSuchObjectException
21/02/17 01:04:21 INFO HiveMetaStore: Added admin role in metastore
21/02/17 01:04:21 INFO HiveMetaStore: Added public role in metastore
21/02/17 01:04:21 INFO HiveMetaStore: No user is added in admin role, since config is empty
21/02/17 01:04:21 INFO HiveMetaStore: 0: get_all_functions
21/02/17 01:04:21 INFO audit: ugi=yitaoli	ip=unknown-ip-addr	cmd=get_all_functions	
21/02/17 01:04:21 INFO HiveMetaStore: 0: get_database: default
21/02/17 01:04:21 INFO audit: ugi=yitaoli	ip=unknown-ip-addr	cmd=get_database: default	
21/02/17 01:04:21 INFO HiveMetaStore: 0: get_database: default
21/02/17 01:04:21 INFO audit: ugi=yitaoli	ip=unknown-ip-addr	cmd=get_database: default	
21/02/17 01:04:21 INFO HiveMetaStore: 0: get_table : db=default tbl=iris
21/02/17 01:04:21 INFO audit: ugi=yitaoli	ip=unknown-ip-addr	cmd=get_table : db=default tbl=iris	
21/02/17 01:04:21 INFO HiveMetaStore: 0: get_database: global_temp
21/02/17 01:04:21 INFO audit: ugi=yitaoli	ip=unknown-ip-addr	cmd=get_database: global_temp	
21/02/17 01:04:21 WARN ObjectStore: Failed to get database global_temp, returning NoSuchObjectException
21/02/17 01:04:21 INFO HiveMetaStore: 0: get_database: default
21/02/17 01:04:21 INFO audit: ugi=yitaoli	ip=unknown-ip-addr	cmd=get_database: default	
21/02/17 01:04:21 INFO HiveMetaStore: 0: get_database: default
21/02/17 01:04:21 INFO audit: ugi=yitaoli	ip=unknown-ip-addr	cmd=get_database: default	
21/02/17 01:04:21 INFO HiveMetaStore: 0: get_tables: db=default pat=*
21/02/17 01:04:21 INFO audit: ugi=yitaoli	ip=unknown-ip-addr	cmd=get_tables: db=default pat=*	
21/02/17 01:04:22 INFO SparkContext: Starting job: collect at utils.scala:54
21/02/17 01:04:22 INFO DAGScheduler: Job 0 finished: collect at utils.scala:54, took 0.005372 s
21/02/17 01:04:22 INFO CodeGenerator: Code generated in 170.92928 ms
21/02/17 01:04:22 INFO SparkContext: Starting job: collect at utils.scala:137
21/02/17 01:04:22 INFO DAGScheduler: Got job 1 (collect at utils.scala:137) with 1 output partitions
21/02/17 01:04:22 INFO DAGScheduler: Final stage: ResultStage 0 (collect at utils.scala:137)
21/02/17 01:04:22 INFO DAGScheduler: Parents of final stage: List()
21/02/17 01:04:22 INFO DAGScheduler: Missing parents: List()
21/02/17 01:04:22 INFO DAGScheduler: Submitting ResultStage 0 (MapPartitionsRDD[9] at collect at utils.scala:137), which has no missing parents
21/02/17 01:04:23 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 6.5 KiB, free 912.3 MiB)
21/02/17 01:04:23 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 3.2 KiB, free 912.3 MiB)
21/02/17 01:04:23 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on localhost:39871 (size: 3.2 KiB, free: 912.3 MiB)
21/02/17 01:04:23 INFO SparkContext: Created broadcast 0 from broadcast at DAGScheduler.scala:1200
21/02/17 01:04:23 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 0 (MapPartitionsRDD[9] at collect at utils.scala:137) (first 15 tasks are for partitions Vector(0))
21/02/17 01:04:23 INFO TaskSchedulerImpl: Adding task set 0.0 with 1 tasks
21/02/17 01:04:23 INFO TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0, localhost, executor driver, partition 0, PROCESS_LOCAL, 7561 bytes)
21/02/17 01:04:23 INFO Executor: Running task 0.0 in stage 0.0 (TID 0)
21/02/17 01:04:23 INFO Executor: Fetching spark://localhost:43599/jars/org.ow2.asm_asm-5.0.4.jar with timestamp 1613523855865
21/02/17 01:04:23 INFO TransportClientFactory: Successfully created connection to localhost/127.0.0.1:43599 after 12 ms (0 ms spent in bootstraps)
21/02/17 01:04:23 INFO Utils: Fetching spark://localhost:43599/jars/org.ow2.asm_asm-5.0.4.jar to /tmp/spark-ed2414e0-45f9-4b71-a3e9-c5ee891e1efe/userFiles-56177e06-e1ad-4392-97c3-5c0bf51ef44b/fetchFileTemp52132090653493127.tmp
21/02/17 01:04:23 INFO Executor: Adding file:/tmp/spark-ed2414e0-45f9-4b71-a3e9-c5ee891e1efe/userFiles-56177e06-e1ad-4392-97c3-5c0bf51ef44b/org.ow2.asm_asm-5.0.4.jar to class loader
21/02/17 01:04:23 INFO Executor: Fetching spark://localhost:43599/jars/com.esotericsoftware_minlog-1.3.0.jar with timestamp 1613523855865
21/02/17 01:04:23 INFO Utils: Fetching spark://localhost:43599/jars/com.esotericsoftware_minlog-1.3.0.jar to /tmp/spark-ed2414e0-45f9-4b71-a3e9-c5ee891e1efe/userFiles-56177e06-e1ad-4392-97c3-5c0bf51ef44b/fetchFileTemp2876765368350215595.tmp
21/02/17 01:04:23 INFO Executor: Adding file:/tmp/spark-ed2414e0-45f9-4b71-a3e9-c5ee891e1efe/userFiles-56177e06-e1ad-4392-97c3-5c0bf51ef44b/com.esotericsoftware_minlog-1.3.0.jar to class loader
21/02/17 01:04:23 INFO Executor: Fetching spark://localhost:43599/jars/org.scalatest_scalatest_2.12-3.0.5.jar with timestamp 1613523855865
21/02/17 01:04:23 INFO Utils: Fetching spark://localhost:43599/jars/org.scalatest_scalatest_2.12-3.0.5.jar to /tmp/spark-ed2414e0-45f9-4b71-a3e9-c5ee891e1efe/userFiles-56177e06-e1ad-4392-97c3-5c0bf51ef44b/fetchFileTemp8681607812854866068.tmp
21/02/17 01:04:23 INFO Executor: Adding file:/tmp/spark-ed2414e0-45f9-4b71-a3e9-c5ee891e1efe/userFiles-56177e06-e1ad-4392-97c3-5c0bf51ef44b/org.scalatest_scalatest_2.12-3.0.5.jar to class loader
21/02/17 01:04:23 INFO Executor: Fetching spark://localhost:43599/jars/sparklyr-3.0-2.12.jar with timestamp 1613523855866
21/02/17 01:04:23 INFO Utils: Fetching spark://localhost:43599/jars/sparklyr-3.0-2.12.jar to /tmp/spark-ed2414e0-45f9-4b71-a3e9-c5ee891e1efe/userFiles-56177e06-e1ad-4392-97c3-5c0bf51ef44b/fetchFileTemp1390826608644147478.tmp
21/02/17 01:04:23 INFO Executor: Adding file:/tmp/spark-ed2414e0-45f9-4b71-a3e9-c5ee891e1efe/userFiles-56177e06-e1ad-4392-97c3-5c0bf51ef44b/sparklyr-3.0-2.12.jar to class loader
21/02/17 01:04:23 INFO Executor: Fetching spark://localhost:43599/jars/org.scala-lang_scala-reflect-2.12.8.jar with timestamp 1613523855864
21/02/17 01:04:23 INFO Utils: Fetching spark://localhost:43599/jars/org.scala-lang_scala-reflect-2.12.8.jar to /tmp/spark-ed2414e0-45f9-4b71-a3e9-c5ee891e1efe/userFiles-56177e06-e1ad-4392-97c3-5c0bf51ef44b/fetchFileTemp3352200892755451901.tmp
21/02/17 01:04:23 INFO Executor: Adding file:/tmp/spark-ed2414e0-45f9-4b71-a3e9-c5ee891e1efe/userFiles-56177e06-e1ad-4392-97c3-5c0bf51ef44b/org.scala-lang_scala-reflect-2.12.8.jar to class loader
21/02/17 01:04:23 INFO Executor: Fetching spark://localhost:43599/jars/org.objenesis_objenesis-2.5.1.jar with timestamp 1613523855865
21/02/17 01:04:23 INFO Utils: Fetching spark://localhost:43599/jars/org.objenesis_objenesis-2.5.1.jar to /tmp/spark-ed2414e0-45f9-4b71-a3e9-c5ee891e1efe/userFiles-56177e06-e1ad-4392-97c3-5c0bf51ef44b/fetchFileTemp8300734539316360494.tmp
21/02/17 01:04:23 INFO Executor: Adding file:/tmp/spark-ed2414e0-45f9-4b71-a3e9-c5ee891e1efe/userFiles-56177e06-e1ad-4392-97c3-5c0bf51ef44b/org.objenesis_objenesis-2.5.1.jar to class loader
21/02/17 01:04:23 INFO Executor: Fetching spark://localhost:43599/jars/ml.dmlc_xgboost4j_2.12-1.3.1.jar with timestamp 1613523855864
21/02/17 01:04:23 INFO Utils: Fetching spark://localhost:43599/jars/ml.dmlc_xgboost4j_2.12-1.3.1.jar to /tmp/spark-ed2414e0-45f9-4b71-a3e9-c5ee891e1efe/userFiles-56177e06-e1ad-4392-97c3-5c0bf51ef44b/fetchFileTemp4946501994753373235.tmp
21/02/17 01:04:23 INFO Executor: Adding file:/tmp/spark-ed2414e0-45f9-4b71-a3e9-c5ee891e1efe/userFiles-56177e06-e1ad-4392-97c3-5c0bf51ef44b/ml.dmlc_xgboost4j_2.12-1.3.1.jar to class loader
21/02/17 01:04:23 INFO Executor: Fetching spark://localhost:43599/jars/com.esotericsoftware_kryo-4.0.2.jar with timestamp 1613523855864
21/02/17 01:04:23 INFO Utils: Fetching spark://localhost:43599/jars/com.esotericsoftware_kryo-4.0.2.jar to /tmp/spark-ed2414e0-45f9-4b71-a3e9-c5ee891e1efe/userFiles-56177e06-e1ad-4392-97c3-5c0bf51ef44b/fetchFileTemp7373173025306790375.tmp
21/02/17 01:04:23 INFO Executor: Adding file:/tmp/spark-ed2414e0-45f9-4b71-a3e9-c5ee891e1efe/userFiles-56177e06-e1ad-4392-97c3-5c0bf51ef44b/com.esotericsoftware_kryo-4.0.2.jar to class loader
21/02/17 01:04:23 INFO Executor: Fetching spark://localhost:43599/jars/org.scala-lang_scala-compiler-2.12.8.jar with timestamp 1613523855864
21/02/17 01:04:23 INFO Utils: Fetching spark://localhost:43599/jars/org.scala-lang_scala-compiler-2.12.8.jar to /tmp/spark-ed2414e0-45f9-4b71-a3e9-c5ee891e1efe/userFiles-56177e06-e1ad-4392-97c3-5c0bf51ef44b/fetchFileTemp6146360786026562133.tmp
21/02/17 01:04:23 INFO Executor: Adding file:/tmp/spark-ed2414e0-45f9-4b71-a3e9-c5ee891e1efe/userFiles-56177e06-e1ad-4392-97c3-5c0bf51ef44b/org.scala-lang_scala-compiler-2.12.8.jar to class loader
21/02/17 01:04:23 INFO Executor: Fetching spark://localhost:43599/jars/org.scala-lang.modules_scala-java8-compat_2.12-0.8.0.jar with timestamp 1613523855865
21/02/17 01:04:23 INFO Utils: Fetching spark://localhost:43599/jars/org.scala-lang.modules_scala-java8-compat_2.12-0.8.0.jar to /tmp/spark-ed2414e0-45f9-4b71-a3e9-c5ee891e1efe/userFiles-56177e06-e1ad-4392-97c3-5c0bf51ef44b/fetchFileTemp6544903635824388287.tmp
21/02/17 01:04:23 INFO Executor: Adding file:/tmp/spark-ed2414e0-45f9-4b71-a3e9-c5ee891e1efe/userFiles-56177e06-e1ad-4392-97c3-5c0bf51ef44b/org.scala-lang.modules_scala-java8-compat_2.12-0.8.0.jar to class loader
21/02/17 01:04:23 INFO Executor: Fetching spark://localhost:43599/jars/com.typesafe.akka_akka-actor_2.12-2.5.23.jar with timestamp 1613523855864
21/02/17 01:04:23 INFO Utils: Fetching spark://localhost:43599/jars/com.typesafe.akka_akka-actor_2.12-2.5.23.jar to /tmp/spark-ed2414e0-45f9-4b71-a3e9-c5ee891e1efe/userFiles-56177e06-e1ad-4392-97c3-5c0bf51ef44b/fetchFileTemp5942821006411502173.tmp
21/02/17 01:04:23 INFO Executor: Adding file:/tmp/spark-ed2414e0-45f9-4b71-a3e9-c5ee891e1efe/userFiles-56177e06-e1ad-4392-97c3-5c0bf51ef44b/com.typesafe.akka_akka-actor_2.12-2.5.23.jar to class loader
21/02/17 01:04:23 INFO Executor: Fetching spark://localhost:43599/jars/ml.dmlc_xgboost4j-spark_2.12-1.3.1.jar with timestamp 1613523855863
21/02/17 01:04:23 INFO Utils: Fetching spark://localhost:43599/jars/ml.dmlc_xgboost4j-spark_2.12-1.3.1.jar to /tmp/spark-ed2414e0-45f9-4b71-a3e9-c5ee891e1efe/userFiles-56177e06-e1ad-4392-97c3-5c0bf51ef44b/fetchFileTemp6361157779350792688.tmp
21/02/17 01:04:23 INFO Executor: Adding file:/tmp/spark-ed2414e0-45f9-4b71-a3e9-c5ee891e1efe/userFiles-56177e06-e1ad-4392-97c3-5c0bf51ef44b/ml.dmlc_xgboost4j-spark_2.12-1.3.1.jar to class loader
21/02/17 01:04:23 INFO Executor: Fetching spark://localhost:43599/jars/com.esotericsoftware_reflectasm-1.11.3.jar with timestamp 1613523855865
21/02/17 01:04:23 INFO Utils: Fetching spark://localhost:43599/jars/com.esotericsoftware_reflectasm-1.11.3.jar to /tmp/spark-ed2414e0-45f9-4b71-a3e9-c5ee891e1efe/userFiles-56177e06-e1ad-4392-97c3-5c0bf51ef44b/fetchFileTemp2987327304003095390.tmp
21/02/17 01:04:23 INFO Executor: Adding file:/tmp/spark-ed2414e0-45f9-4b71-a3e9-c5ee891e1efe/userFiles-56177e06-e1ad-4392-97c3-5c0bf51ef44b/com.esotericsoftware_reflectasm-1.11.3.jar to class loader
21/02/17 01:04:23 INFO Executor: Fetching spark://localhost:43599/jars/org.scala-lang.modules_scala-xml_2.12-1.0.6.jar with timestamp 1613523855865
21/02/17 01:04:23 INFO Utils: Fetching spark://localhost:43599/jars/org.scala-lang.modules_scala-xml_2.12-1.0.6.jar to /tmp/spark-ed2414e0-45f9-4b71-a3e9-c5ee891e1efe/userFiles-56177e06-e1ad-4392-97c3-5c0bf51ef44b/fetchFileTemp5437729552150409282.tmp
21/02/17 01:04:23 INFO Executor: Adding file:/tmp/spark-ed2414e0-45f9-4b71-a3e9-c5ee891e1efe/userFiles-56177e06-e1ad-4392-97c3-5c0bf51ef44b/org.scala-lang.modules_scala-xml_2.12-1.0.6.jar to class loader
21/02/17 01:04:23 INFO Executor: Fetching spark://localhost:43599/jars/org.scalactic_scalactic_2.12-3.0.5.jar with timestamp 1613523855865
21/02/17 01:04:23 INFO Utils: Fetching spark://localhost:43599/jars/org.scalactic_scalactic_2.12-3.0.5.jar to /tmp/spark-ed2414e0-45f9-4b71-a3e9-c5ee891e1efe/userFiles-56177e06-e1ad-4392-97c3-5c0bf51ef44b/fetchFileTemp8840258395639278027.tmp
21/02/17 01:04:23 INFO Executor: Adding file:/tmp/spark-ed2414e0-45f9-4b71-a3e9-c5ee891e1efe/userFiles-56177e06-e1ad-4392-97c3-5c0bf51ef44b/org.scalactic_scalactic_2.12-3.0.5.jar to class loader
21/02/17 01:04:23 INFO Executor: Fetching spark://localhost:43599/jars/commons-logging_commons-logging-1.2.jar with timestamp 1613523855864
21/02/17 01:04:23 INFO Utils: Fetching spark://localhost:43599/jars/commons-logging_commons-logging-1.2.jar to /tmp/spark-ed2414e0-45f9-4b71-a3e9-c5ee891e1efe/userFiles-56177e06-e1ad-4392-97c3-5c0bf51ef44b/fetchFileTemp266601613316739005.tmp
21/02/17 01:04:23 INFO Executor: Adding file:/tmp/spark-ed2414e0-45f9-4b71-a3e9-c5ee891e1efe/userFiles-56177e06-e1ad-4392-97c3-5c0bf51ef44b/commons-logging_commons-logging-1.2.jar to class loader
21/02/17 01:04:23 INFO Executor: Fetching spark://localhost:43599/jars/com.typesafe_config-1.3.3.jar with timestamp 1613523855865
21/02/17 01:04:23 INFO Utils: Fetching spark://localhost:43599/jars/com.typesafe_config-1.3.3.jar to /tmp/spark-ed2414e0-45f9-4b71-a3e9-c5ee891e1efe/userFiles-56177e06-e1ad-4392-97c3-5c0bf51ef44b/fetchFileTemp6210765630998462316.tmp
21/02/17 01:04:23 INFO Executor: Adding file:/tmp/spark-ed2414e0-45f9-4b71-a3e9-c5ee891e1efe/userFiles-56177e06-e1ad-4392-97c3-5c0bf51ef44b/com.typesafe_config-1.3.3.jar to class loader
21/02/17 01:04:23 INFO Executor: Finished task 0.0 in stage 0.0 (TID 0). 1397 bytes result sent to driver
21/02/17 01:04:23 INFO TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in 391 ms on localhost (executor driver) (1/1)
21/02/17 01:04:23 INFO TaskSchedulerImpl: Removed TaskSet 0.0, whose tasks have all completed, from pool 
21/02/17 01:04:23 INFO DAGScheduler: ResultStage 0 (collect at utils.scala:137) finished in 0.516 s
21/02/17 01:04:23 INFO DAGScheduler: Job 1 is finished. Cancelling potential speculative or zombie tasks for this job
21/02/17 01:04:23 INFO TaskSchedulerImpl: Killing all running tasks in stage 0: Stage finished
21/02/17 01:04:23 INFO DAGScheduler: Job 1 finished: collect at utils.scala:137, took 0.547527 s
21/02/17 01:04:23 INFO CodeGenerator: Code generated in 15.890128 ms
21/02/17 01:04:23 INFO CodeGenerator: Code generated in 14.845659 ms
21/02/17 01:04:23 INFO CodeGenerator: Code generated in 12.171379 ms
21/02/17 01:04:23 INFO SparkContext: Starting job: count at utils.scala:135
21/02/17 01:04:23 INFO DAGScheduler: Registering RDD 11 (count at utils.scala:135) as input to shuffle 0
21/02/17 01:04:23 INFO DAGScheduler: Got job 2 (count at utils.scala:135) with 1 output partitions
21/02/17 01:04:23 INFO DAGScheduler: Final stage: ResultStage 2 (count at utils.scala:135)
21/02/17 01:04:23 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 1)
21/02/17 01:04:23 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 1)
21/02/17 01:04:23 INFO DAGScheduler: Submitting ShuffleMapStage 1 (MapPartitionsRDD[11] at count at utils.scala:135), which has no missing parents
21/02/17 01:04:23 INFO MemoryStore: Block broadcast_1 stored as values in memory (estimated size 10.0 KiB, free 912.3 MiB)
21/02/17 01:04:23 INFO MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 5.2 KiB, free 912.3 MiB)
21/02/17 01:04:23 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on localhost:39871 (size: 5.2 KiB, free: 912.3 MiB)
21/02/17 01:04:23 INFO SparkContext: Created broadcast 1 from broadcast at DAGScheduler.scala:1200
21/02/17 01:04:23 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 1 (MapPartitionsRDD[11] at count at utils.scala:135) (first 15 tasks are for partitions Vector(0))
21/02/17 01:04:23 INFO TaskSchedulerImpl: Adding task set 1.0 with 1 tasks
21/02/17 01:04:23 INFO TaskSetManager: Starting task 0.0 in stage 1.0 (TID 1, localhost, executor driver, partition 0, PROCESS_LOCAL, 7550 bytes)
21/02/17 01:04:23 INFO Executor: Running task 0.0 in stage 1.0 (TID 1)
21/02/17 01:04:23 INFO Executor: Finished task 0.0 in stage 1.0 (TID 1). 1833 bytes result sent to driver
21/02/17 01:04:23 INFO TaskSetManager: Finished task 0.0 in stage 1.0 (TID 1) in 44 ms on localhost (executor driver) (1/1)
21/02/17 01:04:23 INFO TaskSchedulerImpl: Removed TaskSet 1.0, whose tasks have all completed, from pool 
21/02/17 01:04:23 INFO DAGScheduler: ShuffleMapStage 1 (count at utils.scala:135) finished in 0.060 s
21/02/17 01:04:23 INFO DAGScheduler: looking for newly runnable stages
21/02/17 01:04:23 INFO DAGScheduler: running: Set()
21/02/17 01:04:23 INFO DAGScheduler: waiting: Set(ResultStage 2)
21/02/17 01:04:23 INFO DAGScheduler: failed: Set()
21/02/17 01:04:23 INFO DAGScheduler: Submitting ResultStage 2 (MapPartitionsRDD[14] at count at utils.scala:135), which has no missing parents
21/02/17 01:04:23 INFO MemoryStore: Block broadcast_2 stored as values in memory (estimated size 10.1 KiB, free 912.3 MiB)
21/02/17 01:04:23 INFO MemoryStore: Block broadcast_2_piece0 stored as bytes in memory (estimated size 5.0 KiB, free 912.3 MiB)
21/02/17 01:04:23 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on localhost:39871 (size: 5.0 KiB, free: 912.3 MiB)
21/02/17 01:04:23 INFO SparkContext: Created broadcast 2 from broadcast at DAGScheduler.scala:1200
21/02/17 01:04:23 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 2 (MapPartitionsRDD[14] at count at utils.scala:135) (first 15 tasks are for partitions Vector(0))
21/02/17 01:04:23 INFO TaskSchedulerImpl: Adding task set 2.0 with 1 tasks
21/02/17 01:04:23 INFO TaskSetManager: Starting task 0.0 in stage 2.0 (TID 2, localhost, executor driver, partition 0, NODE_LOCAL, 7325 bytes)
21/02/17 01:04:23 INFO Executor: Running task 0.0 in stage 2.0 (TID 2)
21/02/17 01:04:23 INFO ShuffleBlockFetcherIterator: Getting 1 (60.0 B) non-empty blocks including 1 (60.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
21/02/17 01:04:23 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 5 ms
21/02/17 01:04:23 INFO Executor: Finished task 0.0 in stage 2.0 (TID 2). 2648 bytes result sent to driver
21/02/17 01:04:23 INFO TaskSetManager: Finished task 0.0 in stage 2.0 (TID 2) in 33 ms on localhost (executor driver) (1/1)
21/02/17 01:04:23 INFO TaskSchedulerImpl: Removed TaskSet 2.0, whose tasks have all completed, from pool 
21/02/17 01:04:23 INFO DAGScheduler: ResultStage 2 (count at utils.scala:135) finished in 0.041 s
21/02/17 01:04:23 INFO DAGScheduler: Job 2 is finished. Cancelling potential speculative or zombie tasks for this job
21/02/17 01:04:23 INFO TaskSchedulerImpl: Killing all running tasks in stage 2: Stage finished
21/02/17 01:04:23 INFO DAGScheduler: Job 2 finished: count at utils.scala:135, took 0.120573 s
21/02/17 01:04:24 INFO SparkContext: Starting job: collect at utils.scala:137
21/02/17 01:04:24 INFO DAGScheduler: Got job 3 (collect at utils.scala:137) with 1 output partitions
21/02/17 01:04:24 INFO DAGScheduler: Final stage: ResultStage 3 (collect at utils.scala:137)
21/02/17 01:04:24 INFO DAGScheduler: Parents of final stage: List()
21/02/17 01:04:24 INFO DAGScheduler: Missing parents: List()
21/02/17 01:04:24 INFO DAGScheduler: Submitting ResultStage 3 (MapPartitionsRDD[16] at collect at utils.scala:137), which has no missing parents
21/02/17 01:04:24 INFO MemoryStore: Block broadcast_3 stored as values in memory (estimated size 7.2 KiB, free 912.3 MiB)
21/02/17 01:04:24 INFO MemoryStore: Block broadcast_3_piece0 stored as bytes in memory (estimated size 3.7 KiB, free 912.3 MiB)
21/02/17 01:04:24 INFO BlockManagerInfo: Added broadcast_3_piece0 in memory on localhost:39871 (size: 3.7 KiB, free: 912.3 MiB)
21/02/17 01:04:24 INFO SparkContext: Created broadcast 3 from broadcast at DAGScheduler.scala:1200
21/02/17 01:04:24 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 3 (MapPartitionsRDD[16] at collect at utils.scala:137) (first 15 tasks are for partitions Vector(0))
21/02/17 01:04:24 INFO TaskSchedulerImpl: Adding task set 3.0 with 1 tasks
21/02/17 01:04:24 INFO TaskSetManager: Starting task 0.0 in stage 3.0 (TID 3, localhost, executor driver, partition 0, PROCESS_LOCAL, 7561 bytes)
21/02/17 01:04:24 INFO Executor: Running task 0.0 in stage 3.0 (TID 3)
21/02/17 01:04:24 INFO Executor: Finished task 0.0 in stage 3.0 (TID 3). 1397 bytes result sent to driver
21/02/17 01:04:24 INFO TaskSetManager: Finished task 0.0 in stage 3.0 (TID 3) in 5 ms on localhost (executor driver) (1/1)
21/02/17 01:04:24 INFO TaskSchedulerImpl: Removed TaskSet 3.0, whose tasks have all completed, from pool 
21/02/17 01:04:24 INFO DAGScheduler: ResultStage 3 (collect at utils.scala:137) finished in 0.011 s
21/02/17 01:04:24 INFO DAGScheduler: Job 3 is finished. Cancelling potential speculative or zombie tasks for this job
21/02/17 01:04:24 INFO TaskSchedulerImpl: Killing all running tasks in stage 3: Stage finished
21/02/17 01:04:24 INFO DAGScheduler: Job 3 finished: collect at utils.scala:137, took 0.013961 s
21/02/17 01:04:24 INFO BlockManagerInfo: Removed broadcast_0_piece0 on localhost:39871 in memory (size: 3.2 KiB, free: 912.3 MiB)
21/02/17 01:04:24 INFO BlockManagerInfo: Removed broadcast_2_piece0 on localhost:39871 in memory (size: 5.0 KiB, free: 912.3 MiB)
21/02/17 01:04:24 INFO BlockManagerInfo: Removed broadcast_3_piece0 on localhost:39871 in memory (size: 3.7 KiB, free: 912.3 MiB)
21/02/17 01:04:24 INFO BlockManagerInfo: Removed broadcast_1_piece0 on localhost:39871 in memory (size: 5.2 KiB, free: 912.3 MiB)
21/02/17 01:04:24 INFO SparkContext: Starting job: count at utils.scala:135
21/02/17 01:04:24 INFO DAGScheduler: Registering RDD 18 (count at utils.scala:135) as input to shuffle 1
21/02/17 01:04:24 INFO DAGScheduler: Got job 4 (count at utils.scala:135) with 1 output partitions
21/02/17 01:04:24 INFO DAGScheduler: Final stage: ResultStage 5 (count at utils.scala:135)
21/02/17 01:04:24 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 4)
21/02/17 01:04:24 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 4)
21/02/17 01:04:24 INFO DAGScheduler: Submitting ShuffleMapStage 4 (MapPartitionsRDD[18] at count at utils.scala:135), which has no missing parents
21/02/17 01:04:24 INFO MemoryStore: Block broadcast_4 stored as values in memory (estimated size 10.0 KiB, free 912.3 MiB)
21/02/17 01:04:24 INFO MemoryStore: Block broadcast_4_piece0 stored as bytes in memory (estimated size 5.2 KiB, free 912.3 MiB)
21/02/17 01:04:24 INFO BlockManagerInfo: Added broadcast_4_piece0 in memory on localhost:39871 (size: 5.2 KiB, free: 912.3 MiB)
21/02/17 01:04:24 INFO SparkContext: Created broadcast 4 from broadcast at DAGScheduler.scala:1200
21/02/17 01:04:24 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 4 (MapPartitionsRDD[18] at count at utils.scala:135) (first 15 tasks are for partitions Vector(0))
21/02/17 01:04:24 INFO TaskSchedulerImpl: Adding task set 4.0 with 1 tasks
21/02/17 01:04:24 INFO TaskSetManager: Starting task 0.0 in stage 4.0 (TID 4, localhost, executor driver, partition 0, PROCESS_LOCAL, 7550 bytes)
21/02/17 01:04:24 INFO Executor: Running task 0.0 in stage 4.0 (TID 4)
21/02/17 01:04:24 INFO Executor: Finished task 0.0 in stage 4.0 (TID 4). 1833 bytes result sent to driver
21/02/17 01:04:24 INFO TaskSetManager: Finished task 0.0 in stage 4.0 (TID 4) in 6 ms on localhost (executor driver) (1/1)
21/02/17 01:04:24 INFO TaskSchedulerImpl: Removed TaskSet 4.0, whose tasks have all completed, from pool 
21/02/17 01:04:24 INFO DAGScheduler: ShuffleMapStage 4 (count at utils.scala:135) finished in 0.014 s
21/02/17 01:04:24 INFO DAGScheduler: looking for newly runnable stages
21/02/17 01:04:24 INFO DAGScheduler: running: Set()
21/02/17 01:04:24 INFO DAGScheduler: waiting: Set(ResultStage 5)
21/02/17 01:04:24 INFO DAGScheduler: failed: Set()
21/02/17 01:04:24 INFO DAGScheduler: Submitting ResultStage 5 (MapPartitionsRDD[21] at count at utils.scala:135), which has no missing parents
21/02/17 01:04:24 INFO MemoryStore: Block broadcast_5 stored as values in memory (estimated size 10.1 KiB, free 912.3 MiB)
21/02/17 01:04:24 INFO MemoryStore: Block broadcast_5_piece0 stored as bytes in memory (estimated size 5.0 KiB, free 912.3 MiB)
21/02/17 01:04:24 INFO BlockManagerInfo: Added broadcast_5_piece0 in memory on localhost:39871 (size: 5.0 KiB, free: 912.3 MiB)
21/02/17 01:04:24 INFO SparkContext: Created broadcast 5 from broadcast at DAGScheduler.scala:1200
21/02/17 01:04:24 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 5 (MapPartitionsRDD[21] at count at utils.scala:135) (first 15 tasks are for partitions Vector(0))
21/02/17 01:04:24 INFO TaskSchedulerImpl: Adding task set 5.0 with 1 tasks
21/02/17 01:04:24 INFO TaskSetManager: Starting task 0.0 in stage 5.0 (TID 5, localhost, executor driver, partition 0, NODE_LOCAL, 7325 bytes)
21/02/17 01:04:24 INFO Executor: Running task 0.0 in stage 5.0 (TID 5)
21/02/17 01:04:24 INFO ShuffleBlockFetcherIterator: Getting 1 (60.0 B) non-empty blocks including 1 (60.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
21/02/17 01:04:24 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
21/02/17 01:04:24 INFO Executor: Finished task 0.0 in stage 5.0 (TID 5). 2648 bytes result sent to driver
21/02/17 01:04:24 INFO TaskSetManager: Finished task 0.0 in stage 5.0 (TID 5) in 7 ms on localhost (executor driver) (1/1)
21/02/17 01:04:24 INFO TaskSchedulerImpl: Removed TaskSet 5.0, whose tasks have all completed, from pool 
21/02/17 01:04:24 INFO DAGScheduler: ResultStage 5 (count at utils.scala:135) finished in 0.013 s
21/02/17 01:04:24 INFO DAGScheduler: Job 4 is finished. Cancelling potential speculative or zombie tasks for this job
21/02/17 01:04:24 INFO TaskSchedulerImpl: Killing all running tasks in stage 5: Stage finished
21/02/17 01:04:24 INFO DAGScheduler: Job 4 finished: count at utils.scala:135, took 0.034822 s
21/02/17 01:04:24 INFO Instrumentation: [e278fe10] training finished
21/02/17 01:04:24 INFO Instrumentation: [60d83d95] training finished
21/02/17 01:04:24 INFO CodeGenerator: Code generated in 30.554791 ms
21/02/17 01:04:24 INFO CodeGenerator: Code generated in 10.401848 ms
21/02/17 01:04:25 INFO XGBoostSpark: Running XGBoost 1.3.1 with parameters:
alpha -> 0.0
min_child_weight -> 1.0
sample_type -> uniform
base_score -> 0.5
rabit_timeout -> -1
colsample_bylevel -> 1.0
grow_policy -> depthwise
skip_drop -> 0.0
lambda_bias -> 0.0
silent -> 0
scale_pos_weight -> 1.0
seed -> 0
cache_training_set -> false
features_col -> features
num_early_stopping_rounds -> 0
label_col -> label
num_workers -> 1
subsample -> 1.0
lambda -> 1.0
max_depth -> 6
kill_spark_context_on_worker_failure -> true
tree_limit -> 0
custom_eval -> null
dmlc_worker_connect_retry -> 5
rate_drop -> 0.0
max_bin -> 16
train_test_ratio -> 1.0
use_external_memory -> false
objective -> reg:linear
eval_metric -> rmse
num_round -> 1
maximize_evaluation_metrics -> false
timeout_request_workers -> 1800000
missing -> NaN
rabit_ring_reduce_threshold -> 32768
checkpoint_path -> 
tracker_conf -> TrackerConf(0,python)
tree_method -> auto
max_delta_step -> 0.0
eta -> 0.3
verbosity -> 1
colsample_bytree -> 1.0
objective_type -> regression
normalize_type -> tree
allow_non_zero_for_missing -> false
custom_obj -> null
gamma -> 0.0
sketch_eps -> 0.03
nthread -> 1
prediction_col -> prediction
checkpoint_interval -> -1
21/02/17 01:04:25 WARN XGBoostSpark: train_test_ratio is deprecated since XGBoost 0.82, we recommend to explicitly pass a training and multiple evaluation datasets by passing 'eval_sets' and 'eval_set_names'
21/02/17 01:04:25 INFO RabitTracker$TrackerProcessLogger: 2021-02-17 01:04:25,073 INFO start listen on 192.168.2.12:9091
21/02/17 01:04:25 INFO XGBoostSpark: starting training with timeout set as 1800000 ms for waiting for resources
21/02/17 01:04:25 INFO SparkContext: Starting job: foreachPartition at XGBoost.scala:612
21/02/17 01:04:25 INFO DAGScheduler: Got job 5 (foreachPartition at XGBoost.scala:612) with 1 output partitions
21/02/17 01:04:25 INFO DAGScheduler: Final stage: ResultStage 6 (foreachPartition at XGBoost.scala:612)
21/02/17 01:04:25 INFO DAGScheduler: Parents of final stage: List()
21/02/17 01:04:25 INFO DAGScheduler: Missing parents: List()
21/02/17 01:04:25 INFO DAGScheduler: Submitting ResultStage 6 (MapPartitionsRDD[32] at mapPartitions at XGBoost.scala:493), which has no missing parents
21/02/17 01:04:25 INFO MemoryStore: Block broadcast_6 stored as values in memory (estimated size 39.8 KiB, free 912.2 MiB)
21/02/17 01:04:25 INFO MemoryStore: Block broadcast_6_piece0 stored as bytes in memory (estimated size 16.6 KiB, free 912.2 MiB)
21/02/17 01:04:25 INFO BlockManagerInfo: Added broadcast_6_piece0 in memory on localhost:39871 (size: 16.6 KiB, free: 912.3 MiB)
21/02/17 01:04:25 INFO SparkContext: Created broadcast 6 from broadcast at DAGScheduler.scala:1200
21/02/17 01:04:25 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 6 (MapPartitionsRDD[32] at mapPartitions at XGBoost.scala:493) (first 15 tasks are for partitions Vector(0))
21/02/17 01:04:25 INFO TaskSchedulerImpl: Adding task set 6.0 with 1 tasks
21/02/17 01:04:25 INFO TaskSetManager: Starting task 0.0 in stage 6.0 (TID 6, localhost, executor driver, partition 0, PROCESS_LOCAL, 18492 bytes)
21/02/17 01:04:25 INFO Executor: Running task 0.0 in stage 6.0 (TID 6)
21/02/17 01:04:25 INFO MemoryStore: Block rdd_23_0 stored as values in memory (estimated size 5.6 KiB, free 912.2 MiB)
21/02/17 01:04:25 INFO BlockManagerInfo: Added rdd_23_0 in memory on localhost:39871 (size: 5.6 KiB, free: 912.3 MiB)
21/02/17 01:04:25 INFO CodeGenerator: Code generated in 8.594691 ms
21/02/17 01:04:25 INFO CodeGenerator: Code generated in 26.343426 ms
21/02/17 01:04:25 INFO CodeGenerator: Code generated in 10.471198 ms
21/02/17 01:04:25 INFO RabitTracker$TrackerProcessLogger: /tmp/tracker1191948025564490524.py:330: DeprecationWarning: isAlive() is deprecated, use is_alive() instead
21/02/17 01:04:25 INFO RabitTracker$TrackerProcessLogger:   while self.thread.isAlive():
21/02/17 01:04:25 INFO RabitTracker$TrackerProcessLogger: 2021-02-17 01:04:25,472 DEBUG Recieve start signal from 192.168.2.12; assign rank 0
21/02/17 01:04:25 INFO RabitTracker$TrackerProcessLogger: 2021-02-17 01:04:25,472 INFO @tracker All of 1 nodes getting started
21/02/17 01:04:25 INFO RabitTracker$TrackerProcessLogger: 2021-02-17 01:04:25,480 INFO [0]	train-rmse:2.633044
21/02/17 01:04:25 INFO RabitTracker$TrackerProcessLogger: 2021-02-17 01:04:25,480 DEBUG Recieve shutdown signal from 0
21/02/17 01:04:25 INFO RabitTracker$TrackerProcessLogger: 2021-02-17 01:04:25,481 INFO @tracker All nodes finishes job
21/02/17 01:04:25 INFO RabitTracker$TrackerProcessLogger: 2021-02-17 01:04:25,481 INFO @tracker 0.008249759674072266 secs between node start and job finish
21/02/17 01:04:25 INFO MemoryStore: Block rdd_32_0 stored as values in memory (estimated size 192.0 B, free 912.2 MiB)
21/02/17 01:04:25 INFO BlockManagerInfo: Added rdd_32_0 in memory on localhost:39871 (size: 192.0 B, free: 912.3 MiB)
21/02/17 01:04:25 INFO RabitTracker: Tracker Process ends with exit code 0
21/02/17 01:04:25 INFO RabitTracker$TrackerProcessLogger: Tracker Process ends with exit code 0
21/02/17 01:04:25 INFO XGBoostSpark: Rabit returns with exit code 0
21/02/17 01:04:25 INFO Executor: 1 block locks were not released by TID = 6:
[rdd_32_0]
21/02/17 01:04:25 INFO Executor: Finished task 0.0 in stage 6.0 (TID 6). 1385 bytes result sent to driver
21/02/17 01:04:25 INFO TaskSetManager: Finished task 0.0 in stage 6.0 (TID 6) in 313 ms on localhost (executor driver) (1/1)
21/02/17 01:04:25 INFO TaskSchedulerImpl: Removed TaskSet 6.0, whose tasks have all completed, from pool 
21/02/17 01:04:25 INFO DAGScheduler: ResultStage 6 (foreachPartition at XGBoost.scala:612) finished in 0.381 s
21/02/17 01:04:25 INFO DAGScheduler: Job 5 is finished. Cancelling potential speculative or zombie tasks for this job
21/02/17 01:04:25 INFO TaskSchedulerImpl: Killing all running tasks in stage 6: Stage finished
21/02/17 01:04:25 INFO DAGScheduler: Job 5 finished: foreachPartition at XGBoost.scala:612, took 0.388361 s
21/02/17 01:04:25 INFO SparkContext: Starting job: first at XGBoost.scala:734
21/02/17 01:04:25 INFO DAGScheduler: Got job 6 (first at XGBoost.scala:734) with 1 output partitions
21/02/17 01:04:25 INFO DAGScheduler: Final stage: ResultStage 7 (first at XGBoost.scala:734)
21/02/17 01:04:25 INFO DAGScheduler: Parents of final stage: List()
21/02/17 01:04:25 INFO DAGScheduler: Missing parents: List()
21/02/17 01:04:25 INFO DAGScheduler: Submitting ResultStage 7 (MapPartitionsRDD[32] at mapPartitions at XGBoost.scala:493), which has no missing parents
21/02/17 01:04:25 INFO MemoryStore: Block broadcast_7 stored as values in memory (estimated size 39.6 KiB, free 912.2 MiB)
21/02/17 01:04:25 INFO MemoryStore: Block broadcast_7_piece0 stored as bytes in memory (estimated size 16.6 KiB, free 912.2 MiB)
21/02/17 01:04:25 INFO BlockManagerInfo: Added broadcast_7_piece0 in memory on localhost:39871 (size: 16.6 KiB, free: 912.3 MiB)
21/02/17 01:04:25 INFO SparkContext: Created broadcast 7 from broadcast at DAGScheduler.scala:1200
21/02/17 01:04:25 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 7 (MapPartitionsRDD[32] at mapPartitions at XGBoost.scala:493) (first 15 tasks are for partitions Vector(0))
21/02/17 01:04:25 INFO TaskSchedulerImpl: Adding task set 7.0 with 1 tasks
21/02/17 01:04:25 INFO TaskSetManager: Starting task 0.0 in stage 7.0 (TID 7, localhost, executor driver, partition 0, PROCESS_LOCAL, 18492 bytes)
21/02/17 01:04:25 INFO Executor: Running task 0.0 in stage 7.0 (TID 7)
21/02/17 01:04:25 INFO BlockManager: Found block rdd_32_0 locally
21/02/17 01:04:25 INFO Executor: 1 block locks were not released by TID = 7:
[rdd_32_0]
21/02/17 01:04:25 INFO Executor: Finished task 0.0 in stage 7.0 (TID 7). 2676 bytes result sent to driver
21/02/17 01:04:25 INFO TaskSetManager: Finished task 0.0 in stage 7.0 (TID 7) in 10 ms on localhost (executor driver) (1/1)
21/02/17 01:04:25 INFO TaskSchedulerImpl: Removed TaskSet 7.0, whose tasks have all completed, from pool 
21/02/17 01:04:25 INFO DAGScheduler: ResultStage 7 (first at XGBoost.scala:734) finished in 0.019 s
21/02/17 01:04:25 INFO DAGScheduler: Job 6 is finished. Cancelling potential speculative or zombie tasks for this job
21/02/17 01:04:25 INFO TaskSchedulerImpl: Killing all running tasks in stage 7: Stage finished
21/02/17 01:04:25 INFO DAGScheduler: Job 6 finished: first at XGBoost.scala:734, took 0.022078 s
21/02/17 01:04:25 INFO MapPartitionsRDD: Removing RDD 32 from persistence list
21/02/17 01:04:25 INFO BlockManager: Removing RDD 32
21/02/17 01:04:25 INFO Instrumentation: [38c82f68] training finished
21/02/17 01:04:25 INFO Instrumentation: [1f5e8fbc] training finished
21/02/17 01:04:25 INFO MemoryStore: Block broadcast_8 stored as values in memory (estimated size 64.0 B, free 912.2 MiB)
21/02/17 01:04:25 INFO MemoryStore: Block broadcast_8_piece0 stored as bytes in memory (estimated size 514.0 B, free 912.2 MiB)
21/02/17 01:04:25 INFO BlockManagerInfo: Added broadcast_8_piece0 in memory on localhost:39871 (size: 514.0 B, free: 912.3 MiB)
21/02/17 01:04:25 INFO SparkContext: Created broadcast 8 from broadcast at XGBoostRegressor.scala:279
21/02/17 01:04:25 INFO BlockManagerInfo: Removed broadcast_7_piece0 on localhost:39871 in memory (size: 16.6 KiB, free: 912.3 MiB)
21/02/17 01:04:25 INFO BlockManagerInfo: Removed broadcast_6_piece0 on localhost:39871 in memory (size: 16.6 KiB, free: 912.3 MiB)
21/02/17 01:04:25 INFO BlockManagerInfo: Removed broadcast_4_piece0 on localhost:39871 in memory (size: 5.2 KiB, free: 912.3 MiB)
21/02/17 01:04:25 INFO BlockManagerInfo: Removed broadcast_5_piece0 on localhost:39871 in memory (size: 5.0 KiB, free: 912.3 MiB)
21/02/17 01:04:25 INFO BlockManager: Removing RDD 32
21/02/17 01:04:25 INFO CodeGenerator: Code generated in 25.849591 ms
21/02/17 01:04:26 INFO Instrumentation: [b3d3c495] training finished
21/02/17 01:04:26 INFO CodeGenerator: Code generated in 9.537253 ms
21/02/17 01:04:26 INFO SparkContext: Starting job: collect at utils.scala:137
21/02/17 01:04:26 INFO DAGScheduler: Got job 7 (collect at utils.scala:137) with 1 output partitions
21/02/17 01:04:26 INFO DAGScheduler: Final stage: ResultStage 8 (collect at utils.scala:137)
21/02/17 01:04:26 INFO DAGScheduler: Parents of final stage: List()
21/02/17 01:04:26 INFO DAGScheduler: Missing parents: List()
21/02/17 01:04:26 INFO DAGScheduler: Submitting ResultStage 8 (MapPartitionsRDD[42] at collect at utils.scala:137), which has no missing parents
21/02/17 01:04:26 INFO MemoryStore: Block broadcast_9 stored as values in memory (estimated size 7.3 KiB, free 912.3 MiB)
21/02/17 01:04:26 INFO MemoryStore: Block broadcast_9_piece0 stored as bytes in memory (estimated size 3.7 KiB, free 912.3 MiB)
21/02/17 01:04:26 INFO BlockManagerInfo: Added broadcast_9_piece0 in memory on localhost:39871 (size: 3.7 KiB, free: 912.3 MiB)
21/02/17 01:04:26 INFO SparkContext: Created broadcast 9 from broadcast at DAGScheduler.scala:1200
21/02/17 01:04:26 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 8 (MapPartitionsRDD[42] at collect at utils.scala:137) (first 15 tasks are for partitions Vector(0))
21/02/17 01:04:26 INFO TaskSchedulerImpl: Adding task set 8.0 with 1 tasks
21/02/17 01:04:26 INFO TaskSetManager: Starting task 0.0 in stage 8.0 (TID 8, localhost, executor driver, partition 0, PROCESS_LOCAL, 7561 bytes)
21/02/17 01:04:26 INFO Executor: Running task 0.0 in stage 8.0 (TID 8)
21/02/17 01:04:26 INFO Executor: Finished task 0.0 in stage 8.0 (TID 8). 1397 bytes result sent to driver
21/02/17 01:04:26 INFO TaskSetManager: Finished task 0.0 in stage 8.0 (TID 8) in 7 ms on localhost (executor driver) (1/1)
21/02/17 01:04:26 INFO TaskSchedulerImpl: Removed TaskSet 8.0, whose tasks have all completed, from pool 
21/02/17 01:04:26 INFO DAGScheduler: ResultStage 8 (collect at utils.scala:137) finished in 0.012 s
21/02/17 01:04:26 INFO DAGScheduler: Job 7 is finished. Cancelling potential speculative or zombie tasks for this job
21/02/17 01:04:26 INFO TaskSchedulerImpl: Killing all running tasks in stage 8: Stage finished
21/02/17 01:04:26 INFO DAGScheduler: Job 7 finished: collect at utils.scala:137, took 0.014752 s
21/02/17 01:04:26 INFO CodeGenerator: Code generated in 9.966631 ms
21/02/17 01:04:26 INFO SparkContext: Starting job: count at utils.scala:135
21/02/17 01:04:26 INFO DAGScheduler: Registering RDD 44 (count at utils.scala:135) as input to shuffle 2
21/02/17 01:04:26 INFO DAGScheduler: Got job 8 (count at utils.scala:135) with 1 output partitions
21/02/17 01:04:26 INFO DAGScheduler: Final stage: ResultStage 10 (count at utils.scala:135)
21/02/17 01:04:26 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 9)
21/02/17 01:04:26 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 9)
21/02/17 01:04:26 INFO DAGScheduler: Submitting ShuffleMapStage 9 (MapPartitionsRDD[44] at count at utils.scala:135), which has no missing parents
21/02/17 01:04:26 INFO MemoryStore: Block broadcast_10 stored as values in memory (estimated size 10.0 KiB, free 912.3 MiB)
21/02/17 01:04:26 INFO MemoryStore: Block broadcast_10_piece0 stored as bytes in memory (estimated size 5.2 KiB, free 912.3 MiB)
21/02/17 01:04:26 INFO BlockManagerInfo: Added broadcast_10_piece0 in memory on localhost:39871 (size: 5.2 KiB, free: 912.3 MiB)
21/02/17 01:04:26 INFO SparkContext: Created broadcast 10 from broadcast at DAGScheduler.scala:1200
21/02/17 01:04:26 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 9 (MapPartitionsRDD[44] at count at utils.scala:135) (first 15 tasks are for partitions Vector(0))
21/02/17 01:04:26 INFO TaskSchedulerImpl: Adding task set 9.0 with 1 tasks
21/02/17 01:04:26 INFO TaskSetManager: Starting task 0.0 in stage 9.0 (TID 9, localhost, executor driver, partition 0, PROCESS_LOCAL, 7550 bytes)
21/02/17 01:04:26 INFO Executor: Running task 0.0 in stage 9.0 (TID 9)
21/02/17 01:04:26 INFO Executor: Finished task 0.0 in stage 9.0 (TID 9). 1833 bytes result sent to driver
21/02/17 01:04:26 INFO TaskSetManager: Finished task 0.0 in stage 9.0 (TID 9) in 5 ms on localhost (executor driver) (1/1)
21/02/17 01:04:26 INFO TaskSchedulerImpl: Removed TaskSet 9.0, whose tasks have all completed, from pool 
21/02/17 01:04:26 INFO DAGScheduler: ShuffleMapStage 9 (count at utils.scala:135) finished in 0.011 s
21/02/17 01:04:26 INFO DAGScheduler: looking for newly runnable stages
21/02/17 01:04:26 INFO DAGScheduler: running: Set()
21/02/17 01:04:26 INFO DAGScheduler: waiting: Set(ResultStage 10)
21/02/17 01:04:26 INFO DAGScheduler: failed: Set()
21/02/17 01:04:26 INFO DAGScheduler: Submitting ResultStage 10 (MapPartitionsRDD[47] at count at utils.scala:135), which has no missing parents
21/02/17 01:04:26 INFO MemoryStore: Block broadcast_11 stored as values in memory (estimated size 10.1 KiB, free 912.3 MiB)
21/02/17 01:04:26 INFO MemoryStore: Block broadcast_11_piece0 stored as bytes in memory (estimated size 5.0 KiB, free 912.3 MiB)
21/02/17 01:04:26 INFO BlockManagerInfo: Added broadcast_11_piece0 in memory on localhost:39871 (size: 5.0 KiB, free: 912.3 MiB)
21/02/17 01:04:26 INFO SparkContext: Created broadcast 11 from broadcast at DAGScheduler.scala:1200
21/02/17 01:04:26 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 10 (MapPartitionsRDD[47] at count at utils.scala:135) (first 15 tasks are for partitions Vector(0))
21/02/17 01:04:26 INFO TaskSchedulerImpl: Adding task set 10.0 with 1 tasks
21/02/17 01:04:26 INFO TaskSetManager: Starting task 0.0 in stage 10.0 (TID 10, localhost, executor driver, partition 0, NODE_LOCAL, 7325 bytes)
21/02/17 01:04:26 INFO Executor: Running task 0.0 in stage 10.0 (TID 10)
21/02/17 01:04:26 INFO ShuffleBlockFetcherIterator: Getting 1 (60.0 B) non-empty blocks including 1 (60.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
21/02/17 01:04:26 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
21/02/17 01:04:26 INFO Executor: Finished task 0.0 in stage 10.0 (TID 10). 2648 bytes result sent to driver
21/02/17 01:04:26 INFO TaskSetManager: Finished task 0.0 in stage 10.0 (TID 10) in 5 ms on localhost (executor driver) (1/1)
21/02/17 01:04:26 INFO TaskSchedulerImpl: Removed TaskSet 10.0, whose tasks have all completed, from pool 
21/02/17 01:04:26 INFO DAGScheduler: ResultStage 10 (count at utils.scala:135) finished in 0.011 s
21/02/17 01:04:26 INFO DAGScheduler: Job 8 is finished. Cancelling potential speculative or zombie tasks for this job
21/02/17 01:04:26 INFO TaskSchedulerImpl: Killing all running tasks in stage 10: Stage finished
21/02/17 01:04:26 INFO DAGScheduler: Job 8 finished: count at utils.scala:135, took 0.026424 s
21/02/17 01:04:26 INFO CodeGenerator: Code generated in 6.789485 ms
21/02/17 01:04:26 INFO SparkContext: Starting job: collect at utils.scala:137
21/02/17 01:04:26 INFO DAGScheduler: Got job 9 (collect at utils.scala:137) with 1 output partitions
21/02/17 01:04:26 INFO DAGScheduler: Final stage: ResultStage 11 (collect at utils.scala:137)
21/02/17 01:04:26 INFO DAGScheduler: Parents of final stage: List()
21/02/17 01:04:26 INFO DAGScheduler: Missing parents: List()
21/02/17 01:04:26 INFO DAGScheduler: Submitting ResultStage 11 (MapPartitionsRDD[49] at collect at utils.scala:137), which has no missing parents
21/02/17 01:04:26 INFO MemoryStore: Block broadcast_12 stored as values in memory (estimated size 70.7 KiB, free 912.2 MiB)
21/02/17 01:04:26 INFO MemoryStore: Block broadcast_12_piece0 stored as bytes in memory (estimated size 28.0 KiB, free 912.2 MiB)
21/02/17 01:04:26 INFO BlockManagerInfo: Added broadcast_12_piece0 in memory on localhost:39871 (size: 28.0 KiB, free: 912.3 MiB)
21/02/17 01:04:26 INFO SparkContext: Created broadcast 12 from broadcast at DAGScheduler.scala:1200
21/02/17 01:04:26 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 11 (MapPartitionsRDD[49] at collect at utils.scala:137) (first 15 tasks are for partitions Vector(0))
21/02/17 01:04:26 INFO TaskSchedulerImpl: Adding task set 11.0 with 1 tasks
21/02/17 01:04:26 INFO TaskSetManager: Starting task 0.0 in stage 11.0 (TID 11, localhost, executor driver, partition 0, PROCESS_LOCAL, 18492 bytes)
21/02/17 01:04:26 INFO Executor: Running task 0.0 in stage 11.0 (TID 11)
21/02/17 01:04:26 INFO BlockManager: Found block rdd_23_0 locally
21/02/17 01:04:26 INFO CodeGenerator: Code generated in 8.248598 ms
21/02/17 01:04:26 INFO CodeGenerator: Code generated in 34.052919 ms
21/02/17 01:04:26 INFO Executor: Finished task 0.0 in stage 11.0 (TID 11). 1912 bytes result sent to driver
21/02/17 01:04:26 INFO TaskSetManager: Finished task 0.0 in stage 11.0 (TID 11) in 122 ms on localhost (executor driver) (1/1)
21/02/17 01:04:26 INFO TaskSchedulerImpl: Removed TaskSet 11.0, whose tasks have all completed, from pool 
21/02/17 01:04:26 INFO DAGScheduler: ResultStage 11 (collect at utils.scala:137) finished in 0.129 s
21/02/17 01:04:26 INFO DAGScheduler: Job 9 is finished. Cancelling potential speculative or zombie tasks for this job
21/02/17 01:04:26 INFO TaskSchedulerImpl: Killing all running tasks in stage 11: Stage finished
21/02/17 01:04:26 INFO DAGScheduler: Job 9 finished: collect at utils.scala:137, took 0.132174 s
21/02/17 01:04:26 INFO CodeGenerator: Code generated in 5.270847 ms
21/02/17 01:04:26 INFO CodeGenerator: Code generated in 7.277323 ms
21/02/17 01:04:26 INFO SparkContext: Starting job: count at utils.scala:135
21/02/17 01:04:26 INFO DAGScheduler: Registering RDD 51 (count at utils.scala:135) as input to shuffle 3
21/02/17 01:04:26 INFO DAGScheduler: Got job 10 (count at utils.scala:135) with 1 output partitions
21/02/17 01:04:26 INFO DAGScheduler: Final stage: ResultStage 13 (count at utils.scala:135)
21/02/17 01:04:26 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 12)
21/02/17 01:04:26 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 12)
21/02/17 01:04:26 INFO DAGScheduler: Submitting ShuffleMapStage 12 (MapPartitionsRDD[51] at count at utils.scala:135), which has no missing parents
21/02/17 01:04:26 INFO MemoryStore: Block broadcast_13 stored as values in memory (estimated size 72.9 KiB, free 912.1 MiB)
21/02/17 01:04:26 INFO MemoryStore: Block broadcast_13_piece0 stored as bytes in memory (estimated size 29.2 KiB, free 912.1 MiB)
21/02/17 01:04:26 INFO BlockManagerInfo: Added broadcast_13_piece0 in memory on localhost:39871 (size: 29.2 KiB, free: 912.2 MiB)
21/02/17 01:04:26 INFO SparkContext: Created broadcast 13 from broadcast at DAGScheduler.scala:1200
21/02/17 01:04:26 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 12 (MapPartitionsRDD[51] at count at utils.scala:135) (first 15 tasks are for partitions Vector(0))
21/02/17 01:04:26 INFO TaskSchedulerImpl: Adding task set 12.0 with 1 tasks
21/02/17 01:04:26 INFO TaskSetManager: Starting task 0.0 in stage 12.0 (TID 12, localhost, executor driver, partition 0, PROCESS_LOCAL, 18481 bytes)
21/02/17 01:04:26 INFO Executor: Running task 0.0 in stage 12.0 (TID 12)
21/02/17 01:04:26 INFO BlockManager: Found block rdd_23_0 locally
21/02/17 01:04:26 INFO Executor: Finished task 0.0 in stage 12.0 (TID 12). 2253 bytes result sent to driver
21/02/17 01:04:26 INFO TaskSetManager: Finished task 0.0 in stage 12.0 (TID 12) in 38 ms on localhost (executor driver) (1/1)
21/02/17 01:04:26 INFO TaskSchedulerImpl: Removed TaskSet 12.0, whose tasks have all completed, from pool 
21/02/17 01:04:26 INFO DAGScheduler: ShuffleMapStage 12 (count at utils.scala:135) finished in 0.044 s
21/02/17 01:04:26 INFO DAGScheduler: looking for newly runnable stages
21/02/17 01:04:26 INFO DAGScheduler: running: Set()
21/02/17 01:04:26 INFO DAGScheduler: waiting: Set(ResultStage 13)
21/02/17 01:04:26 INFO DAGScheduler: failed: Set()
21/02/17 01:04:26 INFO DAGScheduler: Submitting ResultStage 13 (MapPartitionsRDD[54] at count at utils.scala:135), which has no missing parents
21/02/17 01:04:26 INFO MemoryStore: Block broadcast_14 stored as values in memory (estimated size 10.1 KiB, free 912.0 MiB)
21/02/17 01:04:26 INFO MemoryStore: Block broadcast_14_piece0 stored as bytes in memory (estimated size 5.0 KiB, free 912.0 MiB)
21/02/17 01:04:26 INFO BlockManagerInfo: Added broadcast_14_piece0 in memory on localhost:39871 (size: 5.0 KiB, free: 912.2 MiB)
21/02/17 01:04:26 INFO SparkContext: Created broadcast 14 from broadcast at DAGScheduler.scala:1200
21/02/17 01:04:26 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 13 (MapPartitionsRDD[54] at count at utils.scala:135) (first 15 tasks are for partitions Vector(0))
21/02/17 01:04:26 INFO TaskSchedulerImpl: Adding task set 13.0 with 1 tasks
21/02/17 01:04:26 INFO TaskSetManager: Starting task 0.0 in stage 13.0 (TID 13, localhost, executor driver, partition 0, NODE_LOCAL, 7325 bytes)
21/02/17 01:04:26 INFO Executor: Running task 0.0 in stage 13.0 (TID 13)
21/02/17 01:04:26 INFO ShuffleBlockFetcherIterator: Getting 1 (60.0 B) non-empty blocks including 1 (60.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
21/02/17 01:04:26 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
21/02/17 01:04:26 INFO Executor: Finished task 0.0 in stage 13.0 (TID 13). 2648 bytes result sent to driver
21/02/17 01:04:26 INFO TaskSetManager: Finished task 0.0 in stage 13.0 (TID 13) in 5 ms on localhost (executor driver) (1/1)
21/02/17 01:04:26 INFO TaskSchedulerImpl: Removed TaskSet 13.0, whose tasks have all completed, from pool 
21/02/17 01:04:26 INFO DAGScheduler: ResultStage 13 (count at utils.scala:135) finished in 0.010 s
21/02/17 01:04:26 INFO DAGScheduler: Job 10 is finished. Cancelling potential speculative or zombie tasks for this job
21/02/17 01:04:26 INFO TaskSchedulerImpl: Killing all running tasks in stage 13: Stage finished
21/02/17 01:04:26 INFO DAGScheduler: Job 10 finished: count at utils.scala:135, took 0.058925 s
21/02/17 01:04:26 INFO deprecation: mapred.output.dir is deprecated. Instead, use mapreduce.output.fileoutputformat.outputdir
21/02/17 01:04:26 INFO HadoopMapRedCommitProtocol: Using output committer class org.apache.hadoop.mapred.FileOutputCommitter
21/02/17 01:04:26 INFO FileOutputCommitter: File Output Committer Algorithm version is 2
21/02/17 01:04:26 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
21/02/17 01:04:26 INFO SparkContext: Starting job: runJob at SparkHadoopWriter.scala:78
21/02/17 01:04:26 INFO DAGScheduler: Got job 11 (runJob at SparkHadoopWriter.scala:78) with 1 output partitions
21/02/17 01:04:26 INFO DAGScheduler: Final stage: ResultStage 14 (runJob at SparkHadoopWriter.scala:78)
21/02/17 01:04:26 INFO DAGScheduler: Parents of final stage: List()
21/02/17 01:04:26 INFO DAGScheduler: Missing parents: List()
21/02/17 01:04:26 INFO DAGScheduler: Submitting ResultStage 14 (MapPartitionsRDD[56] at saveAsTextFile at ReadWrite.scala:413), which has no missing parents
21/02/17 01:04:26 INFO MemoryStore: Block broadcast_15 stored as values in memory (estimated size 83.9 KiB, free 912.0 MiB)
21/02/17 01:04:26 INFO MemoryStore: Block broadcast_15_piece0 stored as bytes in memory (estimated size 29.9 KiB, free 911.9 MiB)
21/02/17 01:04:26 INFO BlockManagerInfo: Added broadcast_15_piece0 in memory on localhost:39871 (size: 29.9 KiB, free: 912.2 MiB)
21/02/17 01:04:26 INFO SparkContext: Created broadcast 15 from broadcast at DAGScheduler.scala:1200
21/02/17 01:04:26 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 14 (MapPartitionsRDD[56] at saveAsTextFile at ReadWrite.scala:413) (first 15 tasks are for partitions Vector(0))
21/02/17 01:04:26 INFO TaskSchedulerImpl: Adding task set 14.0 with 1 tasks
21/02/17 01:04:26 INFO TaskSetManager: Starting task 0.0 in stage 14.0 (TID 14, localhost, executor driver, partition 0, PROCESS_LOCAL, 7657 bytes)
21/02/17 01:04:26 INFO Executor: Running task 0.0 in stage 14.0 (TID 14)
21/02/17 01:04:27 INFO HadoopMapRedCommitProtocol: Using output committer class org.apache.hadoop.mapred.FileOutputCommitter
21/02/17 01:04:27 INFO FileOutputCommitter: File Output Committer Algorithm version is 2
21/02/17 01:04:27 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
21/02/17 01:04:27 INFO FileOutputCommitter: Saved output of task 'attempt_20210217010426_0056_m_000000_0' to file:/tmp/RtmpbZfqhf/file201a73deadac6/metadata
21/02/17 01:04:27 INFO SparkHadoopMapRedUtil: attempt_20210217010426_0056_m_000000_0: Committed
21/02/17 01:04:27 INFO Executor: Finished task 0.0 in stage 14.0 (TID 14). 1158 bytes result sent to driver
21/02/17 01:04:27 INFO TaskSetManager: Finished task 0.0 in stage 14.0 (TID 14) in 46 ms on localhost (executor driver) (1/1)
21/02/17 01:04:27 INFO TaskSchedulerImpl: Removed TaskSet 14.0, whose tasks have all completed, from pool 
21/02/17 01:04:27 INFO DAGScheduler: ResultStage 14 (runJob at SparkHadoopWriter.scala:78) finished in 0.058 s
21/02/17 01:04:27 INFO DAGScheduler: Job 11 is finished. Cancelling potential speculative or zombie tasks for this job
21/02/17 01:04:27 INFO TaskSchedulerImpl: Killing all running tasks in stage 14: Stage finished
21/02/17 01:04:27 INFO DAGScheduler: Job 11 finished: runJob at SparkHadoopWriter.scala:78, took 0.060634 s
21/02/17 01:04:27 INFO SparkHadoopWriter: Job job_20210217010426_0056 committed.
21/02/17 01:04:27 INFO HadoopMapRedCommitProtocol: Using output committer class org.apache.hadoop.mapred.FileOutputCommitter
21/02/17 01:04:27 INFO FileOutputCommitter: File Output Committer Algorithm version is 2
21/02/17 01:04:27 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
21/02/17 01:04:27 INFO SparkContext: Starting job: runJob at SparkHadoopWriter.scala:78
21/02/17 01:04:27 INFO DAGScheduler: Got job 12 (runJob at SparkHadoopWriter.scala:78) with 1 output partitions
21/02/17 01:04:27 INFO DAGScheduler: Final stage: ResultStage 15 (runJob at SparkHadoopWriter.scala:78)
21/02/17 01:04:27 INFO DAGScheduler: Parents of final stage: List()
21/02/17 01:04:27 INFO DAGScheduler: Missing parents: List()
21/02/17 01:04:27 INFO DAGScheduler: Submitting ResultStage 15 (MapPartitionsRDD[58] at saveAsTextFile at ReadWrite.scala:413), which has no missing parents
21/02/17 01:04:27 INFO MemoryStore: Block broadcast_16 stored as values in memory (estimated size 84.0 KiB, free 911.8 MiB)
21/02/17 01:04:27 INFO MemoryStore: Block broadcast_16_piece0 stored as bytes in memory (estimated size 29.9 KiB, free 911.8 MiB)
21/02/17 01:04:27 INFO BlockManagerInfo: Added broadcast_16_piece0 in memory on localhost:39871 (size: 29.9 KiB, free: 912.2 MiB)
21/02/17 01:04:27 INFO SparkContext: Created broadcast 16 from broadcast at DAGScheduler.scala:1200
21/02/17 01:04:27 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 15 (MapPartitionsRDD[58] at saveAsTextFile at ReadWrite.scala:413) (first 15 tasks are for partitions Vector(0))
21/02/17 01:04:27 INFO TaskSchedulerImpl: Adding task set 15.0 with 1 tasks
21/02/17 01:04:27 INFO TaskSetManager: Starting task 0.0 in stage 15.0 (TID 15, localhost, executor driver, partition 0, PROCESS_LOCAL, 7798 bytes)
21/02/17 01:04:27 INFO Executor: Running task 0.0 in stage 15.0 (TID 15)
21/02/17 01:04:27 INFO HadoopMapRedCommitProtocol: Using output committer class org.apache.hadoop.mapred.FileOutputCommitter
21/02/17 01:04:27 INFO FileOutputCommitter: File Output Committer Algorithm version is 2
21/02/17 01:04:27 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
21/02/17 01:04:27 INFO FileOutputCommitter: Saved output of task 'attempt_20210217010427_0058_m_000000_0' to file:/tmp/RtmpbZfqhf/file201a73deadac6/stages/0_r_formula__56fd7584_4f86_4137_b58a_3260f77a610d/metadata
21/02/17 01:04:27 INFO SparkHadoopMapRedUtil: attempt_20210217010427_0058_m_000000_0: Committed
21/02/17 01:04:27 INFO Executor: Finished task 0.0 in stage 15.0 (TID 15). 1158 bytes result sent to driver
21/02/17 01:04:27 INFO TaskSetManager: Finished task 0.0 in stage 15.0 (TID 15) in 20 ms on localhost (executor driver) (1/1)
21/02/17 01:04:27 INFO TaskSchedulerImpl: Removed TaskSet 15.0, whose tasks have all completed, from pool 
21/02/17 01:04:27 INFO DAGScheduler: ResultStage 15 (runJob at SparkHadoopWriter.scala:78) finished in 0.032 s
21/02/17 01:04:27 INFO DAGScheduler: Job 12 is finished. Cancelling potential speculative or zombie tasks for this job
21/02/17 01:04:27 INFO TaskSchedulerImpl: Killing all running tasks in stage 15: Stage finished
21/02/17 01:04:27 INFO DAGScheduler: Job 12 finished: runJob at SparkHadoopWriter.scala:78, took 0.034356 s
21/02/17 01:04:27 INFO SparkHadoopWriter: Job job_20210217010427_0058 committed.
21/02/17 01:04:27 INFO ParquetFileFormat: Using default output committer for Parquet: org.apache.parquet.hadoop.ParquetOutputCommitter
21/02/17 01:04:27 INFO BlockManagerInfo: Removed broadcast_15_piece0 on localhost:39871 in memory (size: 29.9 KiB, free: 912.2 MiB)
21/02/17 01:04:27 INFO BlockManagerInfo: Removed broadcast_11_piece0 on localhost:39871 in memory (size: 5.0 KiB, free: 912.2 MiB)
21/02/17 01:04:27 INFO BlockManagerInfo: Removed broadcast_10_piece0 on localhost:39871 in memory (size: 5.2 KiB, free: 912.2 MiB)
21/02/17 01:04:27 INFO BlockManagerInfo: Removed broadcast_13_piece0 on localhost:39871 in memory (size: 29.2 KiB, free: 912.2 MiB)
21/02/17 01:04:27 INFO BlockManagerInfo: Removed broadcast_16_piece0 on localhost:39871 in memory (size: 29.9 KiB, free: 912.3 MiB)
21/02/17 01:04:27 INFO BlockManagerInfo: Removed broadcast_9_piece0 on localhost:39871 in memory (size: 3.7 KiB, free: 912.3 MiB)
21/02/17 01:04:27 INFO FileOutputCommitter: File Output Committer Algorithm version is 2
21/02/17 01:04:27 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
21/02/17 01:04:27 INFO BlockManagerInfo: Removed broadcast_12_piece0 on localhost:39871 in memory (size: 28.0 KiB, free: 912.3 MiB)
21/02/17 01:04:27 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
21/02/17 01:04:27 INFO FileOutputCommitter: File Output Committer Algorithm version is 2
21/02/17 01:04:27 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
21/02/17 01:04:27 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
21/02/17 01:04:27 INFO BlockManagerInfo: Removed broadcast_14_piece0 on localhost:39871 in memory (size: 5.0 KiB, free: 912.3 MiB)
21/02/17 01:04:27 INFO CodeGenerator: Code generated in 8.827339 ms
21/02/17 01:04:27 INFO SparkContext: Starting job: parquet at RFormula.scala:434
21/02/17 01:04:27 INFO DAGScheduler: Registering RDD 61 (parquet at RFormula.scala:434) as input to shuffle 4
21/02/17 01:04:27 INFO DAGScheduler: Got job 13 (parquet at RFormula.scala:434) with 1 output partitions
21/02/17 01:04:27 INFO DAGScheduler: Final stage: ResultStage 17 (parquet at RFormula.scala:434)
21/02/17 01:04:27 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 16)
21/02/17 01:04:27 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 16)
21/02/17 01:04:27 INFO DAGScheduler: Submitting ShuffleMapStage 16 (MapPartitionsRDD[61] at parquet at RFormula.scala:434), which has no missing parents
21/02/17 01:04:27 INFO MemoryStore: Block broadcast_17 stored as values in memory (estimated size 7.7 KiB, free 912.3 MiB)
21/02/17 01:04:27 INFO MemoryStore: Block broadcast_17_piece0 stored as bytes in memory (estimated size 4.2 KiB, free 912.3 MiB)
21/02/17 01:04:27 INFO BlockManagerInfo: Added broadcast_17_piece0 in memory on localhost:39871 (size: 4.2 KiB, free: 912.3 MiB)
21/02/17 01:04:27 INFO SparkContext: Created broadcast 17 from broadcast at DAGScheduler.scala:1200
21/02/17 01:04:27 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 16 (MapPartitionsRDD[61] at parquet at RFormula.scala:434) (first 15 tasks are for partitions Vector(0))
21/02/17 01:04:27 INFO TaskSchedulerImpl: Adding task set 16.0 with 1 tasks
21/02/17 01:04:27 INFO TaskSetManager: Starting task 0.0 in stage 16.0 (TID 16, localhost, executor driver, partition 0, PROCESS_LOCAL, 7658 bytes)
21/02/17 01:04:27 INFO Executor: Running task 0.0 in stage 16.0 (TID 16)
21/02/17 01:04:27 INFO Executor: Finished task 0.0 in stage 16.0 (TID 16). 1614 bytes result sent to driver
21/02/17 01:04:27 INFO TaskSetManager: Finished task 0.0 in stage 16.0 (TID 16) in 5 ms on localhost (executor driver) (1/1)
21/02/17 01:04:27 INFO TaskSchedulerImpl: Removed TaskSet 16.0, whose tasks have all completed, from pool 
21/02/17 01:04:27 INFO DAGScheduler: ShuffleMapStage 16 (parquet at RFormula.scala:434) finished in 0.012 s
21/02/17 01:04:27 INFO DAGScheduler: looking for newly runnable stages
21/02/17 01:04:27 INFO DAGScheduler: running: Set()
21/02/17 01:04:27 INFO DAGScheduler: waiting: Set(ResultStage 17)
21/02/17 01:04:27 INFO DAGScheduler: failed: Set()
21/02/17 01:04:27 INFO DAGScheduler: Submitting ResultStage 17 (ShuffledRowRDD[62] at parquet at RFormula.scala:434), which has no missing parents
21/02/17 01:04:27 INFO MemoryStore: Block broadcast_18 stored as values in memory (estimated size 175.1 KiB, free 912.1 MiB)
21/02/17 01:04:27 INFO MemoryStore: Block broadcast_18_piece0 stored as bytes in memory (estimated size 61.8 KiB, free 912.1 MiB)
21/02/17 01:04:27 INFO BlockManagerInfo: Added broadcast_18_piece0 in memory on localhost:39871 (size: 61.8 KiB, free: 912.2 MiB)
21/02/17 01:04:27 INFO SparkContext: Created broadcast 18 from broadcast at DAGScheduler.scala:1200
21/02/17 01:04:27 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 17 (ShuffledRowRDD[62] at parquet at RFormula.scala:434) (first 15 tasks are for partitions Vector(0))
21/02/17 01:04:27 INFO TaskSchedulerImpl: Adding task set 17.0 with 1 tasks
21/02/17 01:04:27 INFO TaskSetManager: Starting task 0.0 in stage 17.0 (TID 17, localhost, executor driver, partition 0, NODE_LOCAL, 7325 bytes)
21/02/17 01:04:27 INFO Executor: Running task 0.0 in stage 17.0 (TID 17)
21/02/17 01:04:27 INFO ShuffleBlockFetcherIterator: Getting 1 (156.0 B) non-empty blocks including 1 (156.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
21/02/17 01:04:27 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
21/02/17 01:04:27 INFO FileOutputCommitter: File Output Committer Algorithm version is 2
21/02/17 01:04:27 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
21/02/17 01:04:27 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
21/02/17 01:04:27 INFO FileOutputCommitter: File Output Committer Algorithm version is 2
21/02/17 01:04:27 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
21/02/17 01:04:27 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
21/02/17 01:04:27 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:
{
  "type" : "struct",
  "fields" : [ {
    "name" : "label",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "terms",
    "type" : {
      "type" : "array",
      "elementType" : {
        "type" : "array",
        "elementType" : "string",
        "containsNull" : true
      },
      "containsNull" : true
    },
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "hasIntercept",
    "type" : "boolean",
    "nullable" : false,
    "metadata" : { }
  } ]
}
and corresponding Parquet message type:
message spark_schema {
  optional binary label (UTF8);
  optional group terms (LIST) {
    repeated group list {
      optional group element (LIST) {
        repeated group list {
          optional binary element (UTF8);
        }
      }
    }
  }
  required boolean hasIntercept;
}

       
21/02/17 01:04:27 INFO CodecPool: Got brand-new compressor [.snappy]
21/02/17 01:04:27 INFO BlockManagerInfo: Removed broadcast_17_piece0 on localhost:39871 in memory (size: 4.2 KiB, free: 912.2 MiB)
21/02/17 01:04:27 INFO FileOutputCommitter: Saved output of task 'attempt_20210217010427_0017_m_000000_17' to file:/tmp/RtmpbZfqhf/file201a73deadac6/stages/0_r_formula__56fd7584_4f86_4137_b58a_3260f77a610d/data
21/02/17 01:04:27 INFO SparkHadoopMapRedUtil: attempt_20210217010427_0017_m_000000_17: Committed
21/02/17 01:04:27 INFO Executor: Finished task 0.0 in stage 17.0 (TID 17). 3281 bytes result sent to driver
21/02/17 01:04:27 INFO TaskSetManager: Finished task 0.0 in stage 17.0 (TID 17) in 455 ms on localhost (executor driver) (1/1)
21/02/17 01:04:27 INFO TaskSchedulerImpl: Removed TaskSet 17.0, whose tasks have all completed, from pool 
21/02/17 01:04:27 INFO DAGScheduler: ResultStage 17 (parquet at RFormula.scala:434) finished in 0.472 s
21/02/17 01:04:27 INFO DAGScheduler: Job 13 is finished. Cancelling potential speculative or zombie tasks for this job
21/02/17 01:04:27 INFO TaskSchedulerImpl: Killing all running tasks in stage 17: Stage finished
21/02/17 01:04:27 INFO DAGScheduler: Job 13 finished: parquet at RFormula.scala:434, took 0.488601 s
21/02/17 01:04:27 INFO FileFormatWriter: Write Job 4f841139-f87c-4227-939c-bdce406d52c6 committed.
21/02/17 01:04:27 INFO FileFormatWriter: Finished processing stats for write job 4f841139-f87c-4227-939c-bdce406d52c6.
21/02/17 01:04:27 INFO HadoopMapRedCommitProtocol: Using output committer class org.apache.hadoop.mapred.FileOutputCommitter
21/02/17 01:04:27 INFO FileOutputCommitter: File Output Committer Algorithm version is 2
21/02/17 01:04:27 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
21/02/17 01:04:27 INFO SparkContext: Starting job: runJob at SparkHadoopWriter.scala:78
21/02/17 01:04:27 INFO DAGScheduler: Got job 14 (runJob at SparkHadoopWriter.scala:78) with 1 output partitions
21/02/17 01:04:27 INFO DAGScheduler: Final stage: ResultStage 18 (runJob at SparkHadoopWriter.scala:78)
21/02/17 01:04:27 INFO DAGScheduler: Parents of final stage: List()
21/02/17 01:04:27 INFO DAGScheduler: Missing parents: List()
21/02/17 01:04:27 INFO DAGScheduler: Submitting ResultStage 18 (MapPartitionsRDD[66] at saveAsTextFile at ReadWrite.scala:413), which has no missing parents
21/02/17 01:04:27 INFO MemoryStore: Block broadcast_19 stored as values in memory (estimated size 84.1 KiB, free 912.0 MiB)
21/02/17 01:04:27 INFO MemoryStore: Block broadcast_19_piece0 stored as bytes in memory (estimated size 30.0 KiB, free 912.0 MiB)
21/02/17 01:04:27 INFO BlockManagerInfo: Added broadcast_19_piece0 in memory on localhost:39871 (size: 30.0 KiB, free: 912.2 MiB)
21/02/17 01:04:27 INFO SparkContext: Created broadcast 19 from broadcast at DAGScheduler.scala:1200
21/02/17 01:04:27 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 18 (MapPartitionsRDD[66] at saveAsTextFile at ReadWrite.scala:413) (first 15 tasks are for partitions Vector(0))
21/02/17 01:04:27 INFO TaskSchedulerImpl: Adding task set 18.0 with 1 tasks
21/02/17 01:04:27 INFO TaskSetManager: Starting task 0.0 in stage 18.0 (TID 18, localhost, executor driver, partition 0, PROCESS_LOCAL, 7662 bytes)
21/02/17 01:04:27 INFO Executor: Running task 0.0 in stage 18.0 (TID 18)
21/02/17 01:04:27 INFO HadoopMapRedCommitProtocol: Using output committer class org.apache.hadoop.mapred.FileOutputCommitter
21/02/17 01:04:27 INFO FileOutputCommitter: File Output Committer Algorithm version is 2
21/02/17 01:04:27 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
21/02/17 01:04:27 INFO FileOutputCommitter: Saved output of task 'attempt_20210217010427_0066_m_000000_0' to file:/tmp/RtmpbZfqhf/file201a73deadac6/stages/0_r_formula__56fd7584_4f86_4137_b58a_3260f77a610d/pipelineModel/metadata
21/02/17 01:04:27 INFO SparkHadoopMapRedUtil: attempt_20210217010427_0066_m_000000_0: Committed
21/02/17 01:04:27 INFO Executor: Finished task 0.0 in stage 18.0 (TID 18). 1158 bytes result sent to driver
21/02/17 01:04:27 INFO TaskSetManager: Finished task 0.0 in stage 18.0 (TID 18) in 18 ms on localhost (executor driver) (1/1)
21/02/17 01:04:27 INFO TaskSchedulerImpl: Removed TaskSet 18.0, whose tasks have all completed, from pool 
21/02/17 01:04:27 INFO DAGScheduler: ResultStage 18 (runJob at SparkHadoopWriter.scala:78) finished in 0.030 s
21/02/17 01:04:27 INFO DAGScheduler: Job 14 is finished. Cancelling potential speculative or zombie tasks for this job
21/02/17 01:04:27 INFO TaskSchedulerImpl: Killing all running tasks in stage 18: Stage finished
21/02/17 01:04:27 INFO DAGScheduler: Job 14 finished: runJob at SparkHadoopWriter.scala:78, took 0.033508 s
21/02/17 01:04:27 INFO SparkHadoopWriter: Job job_20210217010427_0066 committed.
21/02/17 01:04:27 INFO HadoopMapRedCommitProtocol: Using output committer class org.apache.hadoop.mapred.FileOutputCommitter
21/02/17 01:04:27 INFO FileOutputCommitter: File Output Committer Algorithm version is 2
21/02/17 01:04:27 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
21/02/17 01:04:27 INFO SparkContext: Starting job: runJob at SparkHadoopWriter.scala:78
21/02/17 01:04:27 INFO DAGScheduler: Got job 15 (runJob at SparkHadoopWriter.scala:78) with 1 output partitions
21/02/17 01:04:27 INFO DAGScheduler: Final stage: ResultStage 19 (runJob at SparkHadoopWriter.scala:78)
21/02/17 01:04:27 INFO DAGScheduler: Parents of final stage: List()
21/02/17 01:04:27 INFO DAGScheduler: Missing parents: List()
21/02/17 01:04:27 INFO DAGScheduler: Submitting ResultStage 19 (MapPartitionsRDD[68] at saveAsTextFile at ReadWrite.scala:413), which has no missing parents
21/02/17 01:04:27 INFO MemoryStore: Block broadcast_20 stored as values in memory (estimated size 84.2 KiB, free 911.9 MiB)
21/02/17 01:04:27 INFO MemoryStore: Block broadcast_20_piece0 stored as bytes in memory (estimated size 30.0 KiB, free 911.8 MiB)
21/02/17 01:04:27 INFO BlockManagerInfo: Added broadcast_20_piece0 in memory on localhost:39871 (size: 30.0 KiB, free: 912.2 MiB)
21/02/17 01:04:27 INFO SparkContext: Created broadcast 20 from broadcast at DAGScheduler.scala:1200
21/02/17 01:04:27 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 19 (MapPartitionsRDD[68] at saveAsTextFile at ReadWrite.scala:413) (first 15 tasks are for partitions Vector(0))
21/02/17 01:04:27 INFO TaskSchedulerImpl: Adding task set 19.0 with 1 tasks
21/02/17 01:04:27 INFO TaskSetManager: Starting task 0.0 in stage 19.0 (TID 19, localhost, executor driver, partition 0, PROCESS_LOCAL, 7729 bytes)
21/02/17 01:04:27 INFO Executor: Running task 0.0 in stage 19.0 (TID 19)
21/02/17 01:04:27 INFO HadoopMapRedCommitProtocol: Using output committer class org.apache.hadoop.mapred.FileOutputCommitter
21/02/17 01:04:27 INFO FileOutputCommitter: File Output Committer Algorithm version is 2
21/02/17 01:04:27 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
21/02/17 01:04:27 INFO FileOutputCommitter: Saved output of task 'attempt_20210217010427_0068_m_000000_0' to file:/tmp/RtmpbZfqhf/file201a73deadac6/stages/0_r_formula__56fd7584_4f86_4137_b58a_3260f77a610d/pipelineModel/stages/0_r_formula__56fd7584_4f86_4137_b58a_3260f77a610d/metadata
21/02/17 01:04:27 INFO SparkHadoopMapRedUtil: attempt_20210217010427_0068_m_000000_0: Committed
21/02/17 01:04:27 INFO Executor: Finished task 0.0 in stage 19.0 (TID 19). 1158 bytes result sent to driver
21/02/17 01:04:27 INFO TaskSetManager: Finished task 0.0 in stage 19.0 (TID 19) in 17 ms on localhost (executor driver) (1/1)
21/02/17 01:04:27 INFO TaskSchedulerImpl: Removed TaskSet 19.0, whose tasks have all completed, from pool 
21/02/17 01:04:27 INFO DAGScheduler: ResultStage 19 (runJob at SparkHadoopWriter.scala:78) finished in 0.027 s
21/02/17 01:04:27 INFO DAGScheduler: Job 15 is finished. Cancelling potential speculative or zombie tasks for this job
21/02/17 01:04:27 INFO TaskSchedulerImpl: Killing all running tasks in stage 19: Stage finished
21/02/17 01:04:27 INFO DAGScheduler: Job 15 finished: runJob at SparkHadoopWriter.scala:78, took 0.029310 s
21/02/17 01:04:27 INFO SparkHadoopWriter: Job job_20210217010427_0068 committed.
21/02/17 01:04:27 INFO HadoopMapRedCommitProtocol: Using output committer class org.apache.hadoop.mapred.FileOutputCommitter
21/02/17 01:04:27 INFO FileOutputCommitter: File Output Committer Algorithm version is 2
21/02/17 01:04:27 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
21/02/17 01:04:27 INFO SparkContext: Starting job: runJob at SparkHadoopWriter.scala:78
21/02/17 01:04:27 INFO DAGScheduler: Got job 16 (runJob at SparkHadoopWriter.scala:78) with 1 output partitions
21/02/17 01:04:27 INFO DAGScheduler: Final stage: ResultStage 20 (runJob at SparkHadoopWriter.scala:78)
21/02/17 01:04:27 INFO DAGScheduler: Parents of final stage: List()
21/02/17 01:04:27 INFO DAGScheduler: Missing parents: List()
21/02/17 01:04:27 INFO DAGScheduler: Submitting ResultStage 20 (MapPartitionsRDD[70] at saveAsTextFile at ReadWrite.scala:413), which has no missing parents
21/02/17 01:04:27 INFO MemoryStore: Block broadcast_21 stored as values in memory (estimated size 84.1 KiB, free 911.8 MiB)
21/02/17 01:04:27 INFO MemoryStore: Block broadcast_21_piece0 stored as bytes in memory (estimated size 30.0 KiB, free 911.7 MiB)
21/02/17 01:04:27 INFO BlockManagerInfo: Added broadcast_21_piece0 in memory on localhost:39871 (size: 30.0 KiB, free: 912.1 MiB)
21/02/17 01:04:27 INFO SparkContext: Created broadcast 21 from broadcast at DAGScheduler.scala:1200
21/02/17 01:04:27 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 20 (MapPartitionsRDD[70] at saveAsTextFile at ReadWrite.scala:413) (first 15 tasks are for partitions Vector(0))
21/02/17 01:04:27 INFO TaskSchedulerImpl: Adding task set 20.0 with 1 tasks
21/02/17 01:04:27 INFO TaskSetManager: Starting task 0.0 in stage 20.0 (TID 20, localhost, executor driver, partition 0, PROCESS_LOCAL, 7539 bytes)
21/02/17 01:04:27 INFO Executor: Running task 0.0 in stage 20.0 (TID 20)
21/02/17 01:04:27 INFO HadoopMapRedCommitProtocol: Using output committer class org.apache.hadoop.mapred.FileOutputCommitter
21/02/17 01:04:27 INFO FileOutputCommitter: File Output Committer Algorithm version is 2
21/02/17 01:04:27 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
21/02/17 01:04:27 INFO FileOutputCommitter: Saved output of task 'attempt_20210217010427_0070_m_000000_0' to file:/tmp/RtmpbZfqhf/file201a73deadac6/stages/0_r_formula__56fd7584_4f86_4137_b58a_3260f77a610d/pipelineModel/stages/1_vectorAttrRewriter_3ec7e7fc06d5/metadata
21/02/17 01:04:27 INFO SparkHadoopMapRedUtil: attempt_20210217010427_0070_m_000000_0: Committed
21/02/17 01:04:27 INFO Executor: Finished task 0.0 in stage 20.0 (TID 20). 1158 bytes result sent to driver
21/02/17 01:04:27 INFO TaskSetManager: Finished task 0.0 in stage 20.0 (TID 20) in 16 ms on localhost (executor driver) (1/1)
21/02/17 01:04:27 INFO TaskSchedulerImpl: Removed TaskSet 20.0, whose tasks have all completed, from pool 
21/02/17 01:04:27 INFO DAGScheduler: ResultStage 20 (runJob at SparkHadoopWriter.scala:78) finished in 0.025 s
21/02/17 01:04:27 INFO DAGScheduler: Job 16 is finished. Cancelling potential speculative or zombie tasks for this job
21/02/17 01:04:27 INFO TaskSchedulerImpl: Killing all running tasks in stage 20: Stage finished
21/02/17 01:04:27 INFO DAGScheduler: Job 16 finished: runJob at SparkHadoopWriter.scala:78, took 0.027469 s
21/02/17 01:04:27 INFO SparkHadoopWriter: Job job_20210217010427_0070 committed.
21/02/17 01:04:28 INFO ParquetFileFormat: Using default output committer for Parquet: org.apache.parquet.hadoop.ParquetOutputCommitter
21/02/17 01:04:28 INFO FileOutputCommitter: File Output Committer Algorithm version is 2
21/02/17 01:04:28 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
21/02/17 01:04:28 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
21/02/17 01:04:28 INFO FileOutputCommitter: File Output Committer Algorithm version is 2
21/02/17 01:04:28 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
21/02/17 01:04:28 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
21/02/17 01:04:28 INFO CodeGenerator: Code generated in 8.459942 ms
21/02/17 01:04:28 INFO SparkContext: Starting job: parquet at RFormula.scala:599
21/02/17 01:04:28 INFO DAGScheduler: Registering RDD 73 (parquet at RFormula.scala:599) as input to shuffle 5
21/02/17 01:04:28 INFO DAGScheduler: Got job 17 (parquet at RFormula.scala:599) with 1 output partitions
21/02/17 01:04:28 INFO DAGScheduler: Final stage: ResultStage 22 (parquet at RFormula.scala:599)
21/02/17 01:04:28 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 21)
21/02/17 01:04:28 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 21)
21/02/17 01:04:28 INFO DAGScheduler: Submitting ShuffleMapStage 21 (MapPartitionsRDD[73] at parquet at RFormula.scala:599), which has no missing parents
21/02/17 01:04:28 INFO MemoryStore: Block broadcast_22 stored as values in memory (estimated size 7.7 KiB, free 911.7 MiB)
21/02/17 01:04:28 INFO MemoryStore: Block broadcast_22_piece0 stored as bytes in memory (estimated size 4.2 KiB, free 911.7 MiB)
21/02/17 01:04:28 INFO BlockManagerInfo: Added broadcast_22_piece0 in memory on localhost:39871 (size: 4.2 KiB, free: 912.1 MiB)
21/02/17 01:04:28 INFO SparkContext: Created broadcast 22 from broadcast at DAGScheduler.scala:1200
21/02/17 01:04:28 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 21 (MapPartitionsRDD[73] at parquet at RFormula.scala:599) (first 15 tasks are for partitions Vector(0))
21/02/17 01:04:28 INFO TaskSchedulerImpl: Adding task set 21.0 with 1 tasks
21/02/17 01:04:28 INFO TaskSetManager: Starting task 0.0 in stage 21.0 (TID 21, localhost, executor driver, partition 0, PROCESS_LOCAL, 7554 bytes)
21/02/17 01:04:28 INFO Executor: Running task 0.0 in stage 21.0 (TID 21)
21/02/17 01:04:28 INFO Executor: Finished task 0.0 in stage 21.0 (TID 21). 1614 bytes result sent to driver
21/02/17 01:04:28 INFO TaskSetManager: Finished task 0.0 in stage 21.0 (TID 21) in 5 ms on localhost (executor driver) (1/1)
21/02/17 01:04:28 INFO TaskSchedulerImpl: Removed TaskSet 21.0, whose tasks have all completed, from pool 
21/02/17 01:04:28 INFO DAGScheduler: ShuffleMapStage 21 (parquet at RFormula.scala:599) finished in 0.010 s
21/02/17 01:04:28 INFO DAGScheduler: looking for newly runnable stages
21/02/17 01:04:28 INFO DAGScheduler: running: Set()
21/02/17 01:04:28 INFO DAGScheduler: waiting: Set(ResultStage 22)
21/02/17 01:04:28 INFO DAGScheduler: failed: Set()
21/02/17 01:04:28 INFO DAGScheduler: Submitting ResultStage 22 (ShuffledRowRDD[74] at parquet at RFormula.scala:599), which has no missing parents
21/02/17 01:04:28 INFO MemoryStore: Block broadcast_23 stored as values in memory (estimated size 175.1 KiB, free 911.5 MiB)
21/02/17 01:04:28 INFO MemoryStore: Block broadcast_23_piece0 stored as bytes in memory (estimated size 61.8 KiB, free 911.5 MiB)
21/02/17 01:04:28 INFO BlockManagerInfo: Added broadcast_23_piece0 in memory on localhost:39871 (size: 61.8 KiB, free: 912.1 MiB)
21/02/17 01:04:28 INFO SparkContext: Created broadcast 23 from broadcast at DAGScheduler.scala:1200
21/02/17 01:04:28 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 22 (ShuffledRowRDD[74] at parquet at RFormula.scala:599) (first 15 tasks are for partitions Vector(0))
21/02/17 01:04:28 INFO TaskSchedulerImpl: Adding task set 22.0 with 1 tasks
21/02/17 01:04:28 INFO TaskSetManager: Starting task 0.0 in stage 22.0 (TID 22, localhost, executor driver, partition 0, NODE_LOCAL, 7325 bytes)
21/02/17 01:04:28 INFO Executor: Running task 0.0 in stage 22.0 (TID 22)
21/02/17 01:04:28 INFO ShuffleBlockFetcherIterator: Getting 1 (88.0 B) non-empty blocks including 1 (88.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
21/02/17 01:04:28 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
21/02/17 01:04:28 INFO FileOutputCommitter: File Output Committer Algorithm version is 2
21/02/17 01:04:28 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
21/02/17 01:04:28 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
21/02/17 01:04:28 INFO FileOutputCommitter: File Output Committer Algorithm version is 2
21/02/17 01:04:28 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
21/02/17 01:04:28 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
21/02/17 01:04:28 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:
{
  "type" : "struct",
  "fields" : [ {
    "name" : "vectorCol",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "prefixesToRewrite",
    "type" : {
      "type" : "map",
      "keyType" : "string",
      "valueType" : "string",
      "valueContainsNull" : true
    },
    "nullable" : true,
    "metadata" : { }
  } ]
}
and corresponding Parquet message type:
message spark_schema {
  optional binary vectorCol (UTF8);
  optional group prefixesToRewrite (MAP) {
    repeated group key_value {
      required binary key (UTF8);
      optional binary value (UTF8);
    }
  }
}

       
21/02/17 01:04:28 INFO FileOutputCommitter: Saved output of task 'attempt_20210217010428_0022_m_000000_22' to file:/tmp/RtmpbZfqhf/file201a73deadac6/stages/0_r_formula__56fd7584_4f86_4137_b58a_3260f77a610d/pipelineModel/stages/1_vectorAttrRewriter_3ec7e7fc06d5/data
21/02/17 01:04:28 INFO SparkHadoopMapRedUtil: attempt_20210217010428_0022_m_000000_22: Committed
21/02/17 01:04:28 INFO Executor: Finished task 0.0 in stage 22.0 (TID 22). 3195 bytes result sent to driver
21/02/17 01:04:28 INFO TaskSetManager: Finished task 0.0 in stage 22.0 (TID 22) in 37 ms on localhost (executor driver) (1/1)
21/02/17 01:04:28 INFO TaskSchedulerImpl: Removed TaskSet 22.0, whose tasks have all completed, from pool 
21/02/17 01:04:28 INFO DAGScheduler: ResultStage 22 (parquet at RFormula.scala:599) finished in 0.055 s
21/02/17 01:04:28 INFO DAGScheduler: Job 17 is finished. Cancelling potential speculative or zombie tasks for this job
21/02/17 01:04:28 INFO TaskSchedulerImpl: Killing all running tasks in stage 22: Stage finished
21/02/17 01:04:28 INFO DAGScheduler: Job 17 finished: parquet at RFormula.scala:599, took 0.069995 s
21/02/17 01:04:28 INFO FileFormatWriter: Write Job 3697970d-fab2-445e-ad91-4780e97cfab9 committed.
21/02/17 01:04:28 INFO FileFormatWriter: Finished processing stats for write job 3697970d-fab2-445e-ad91-4780e97cfab9.
21/02/17 01:04:28 INFO HadoopMapRedCommitProtocol: Using output committer class org.apache.hadoop.mapred.FileOutputCommitter
21/02/17 01:04:28 INFO FileOutputCommitter: File Output Committer Algorithm version is 2
21/02/17 01:04:28 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
21/02/17 01:04:28 INFO SparkContext: Starting job: runJob at SparkHadoopWriter.scala:78
21/02/17 01:04:28 INFO DAGScheduler: Got job 18 (runJob at SparkHadoopWriter.scala:78) with 1 output partitions
21/02/17 01:04:28 INFO DAGScheduler: Final stage: ResultStage 23 (runJob at SparkHadoopWriter.scala:78)
21/02/17 01:04:28 INFO DAGScheduler: Parents of final stage: List()
21/02/17 01:04:28 INFO DAGScheduler: Missing parents: List()
21/02/17 01:04:28 INFO DAGScheduler: Submitting ResultStage 23 (MapPartitionsRDD[78] at saveAsTextFile at ReadWrite.scala:413), which has no missing parents
21/02/17 01:04:28 INFO MemoryStore: Block broadcast_24 stored as values in memory (estimated size 84.1 KiB, free 911.4 MiB)
21/02/17 01:04:28 INFO MemoryStore: Block broadcast_24_piece0 stored as bytes in memory (estimated size 30.0 KiB, free 911.4 MiB)
21/02/17 01:04:28 INFO BlockManagerInfo: Added broadcast_24_piece0 in memory on localhost:39871 (size: 30.0 KiB, free: 912.1 MiB)
21/02/17 01:04:28 INFO SparkContext: Created broadcast 24 from broadcast at DAGScheduler.scala:1200
21/02/17 01:04:28 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 23 (MapPartitionsRDD[78] at saveAsTextFile at ReadWrite.scala:413) (first 15 tasks are for partitions Vector(0))
21/02/17 01:04:28 INFO TaskSchedulerImpl: Adding task set 23.0 with 1 tasks
21/02/17 01:04:28 INFO TaskSetManager: Starting task 0.0 in stage 23.0 (TID 23, localhost, executor driver, partition 0, PROCESS_LOCAL, 7522 bytes)
21/02/17 01:04:28 INFO Executor: Running task 0.0 in stage 23.0 (TID 23)
21/02/17 01:04:28 INFO HadoopMapRedCommitProtocol: Using output committer class org.apache.hadoop.mapred.FileOutputCommitter
21/02/17 01:04:28 INFO FileOutputCommitter: File Output Committer Algorithm version is 2
21/02/17 01:04:28 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
21/02/17 01:04:28 INFO FileOutputCommitter: Saved output of task 'attempt_20210217010428_0078_m_000000_0' to file:/tmp/RtmpbZfqhf/file201a73deadac6/stages/0_r_formula__56fd7584_4f86_4137_b58a_3260f77a610d/pipelineModel/stages/2_columnPruner_45df637c9a01/metadata
21/02/17 01:04:28 INFO SparkHadoopMapRedUtil: attempt_20210217010428_0078_m_000000_0: Committed
21/02/17 01:04:28 INFO Executor: Finished task 0.0 in stage 23.0 (TID 23). 1158 bytes result sent to driver
21/02/17 01:04:28 INFO TaskSetManager: Finished task 0.0 in stage 23.0 (TID 23) in 14 ms on localhost (executor driver) (1/1)
21/02/17 01:04:28 INFO TaskSchedulerImpl: Removed TaskSet 23.0, whose tasks have all completed, from pool 
21/02/17 01:04:28 INFO DAGScheduler: ResultStage 23 (runJob at SparkHadoopWriter.scala:78) finished in 0.024 s
21/02/17 01:04:28 INFO DAGScheduler: Job 18 is finished. Cancelling potential speculative or zombie tasks for this job
21/02/17 01:04:28 INFO TaskSchedulerImpl: Killing all running tasks in stage 23: Stage finished
21/02/17 01:04:28 INFO DAGScheduler: Job 18 finished: runJob at SparkHadoopWriter.scala:78, took 0.025779 s
21/02/17 01:04:28 INFO SparkHadoopWriter: Job job_20210217010428_0078 committed.
21/02/17 01:04:28 INFO ParquetFileFormat: Using default output committer for Parquet: org.apache.parquet.hadoop.ParquetOutputCommitter
21/02/17 01:04:28 INFO FileOutputCommitter: File Output Committer Algorithm version is 2
21/02/17 01:04:28 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
21/02/17 01:04:28 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
21/02/17 01:04:28 INFO FileOutputCommitter: File Output Committer Algorithm version is 2
21/02/17 01:04:28 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
21/02/17 01:04:28 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
21/02/17 01:04:28 INFO CodeGenerator: Code generated in 7.08398 ms
21/02/17 01:04:28 INFO SparkContext: Starting job: parquet at RFormula.scala:508
21/02/17 01:04:28 INFO DAGScheduler: Registering RDD 81 (parquet at RFormula.scala:508) as input to shuffle 6
21/02/17 01:04:28 INFO DAGScheduler: Got job 19 (parquet at RFormula.scala:508) with 1 output partitions
21/02/17 01:04:28 INFO DAGScheduler: Final stage: ResultStage 25 (parquet at RFormula.scala:508)
21/02/17 01:04:28 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 24)
21/02/17 01:04:28 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 24)
21/02/17 01:04:28 INFO DAGScheduler: Submitting ShuffleMapStage 24 (MapPartitionsRDD[81] at parquet at RFormula.scala:508), which has no missing parents
21/02/17 01:04:28 INFO MemoryStore: Block broadcast_25 stored as values in memory (estimated size 7.6 KiB, free 911.4 MiB)
21/02/17 01:04:28 INFO MemoryStore: Block broadcast_25_piece0 stored as bytes in memory (estimated size 4.1 KiB, free 911.4 MiB)
21/02/17 01:04:28 INFO BlockManagerInfo: Added broadcast_25_piece0 in memory on localhost:39871 (size: 4.1 KiB, free: 912.0 MiB)
21/02/17 01:04:28 INFO SparkContext: Created broadcast 25 from broadcast at DAGScheduler.scala:1200
21/02/17 01:04:28 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 24 (MapPartitionsRDD[81] at parquet at RFormula.scala:508) (first 15 tasks are for partitions Vector(0))
21/02/17 01:04:28 INFO TaskSchedulerImpl: Adding task set 24.0 with 1 tasks
21/02/17 01:04:28 INFO TaskSetManager: Starting task 0.0 in stage 24.0 (TID 24, localhost, executor driver, partition 0, PROCESS_LOCAL, 7522 bytes)
21/02/17 01:04:28 INFO Executor: Running task 0.0 in stage 24.0 (TID 24)
21/02/17 01:04:28 INFO Executor: Finished task 0.0 in stage 24.0 (TID 24). 1614 bytes result sent to driver
21/02/17 01:04:28 INFO TaskSetManager: Finished task 0.0 in stage 24.0 (TID 24) in 5 ms on localhost (executor driver) (1/1)
21/02/17 01:04:28 INFO TaskSchedulerImpl: Removed TaskSet 24.0, whose tasks have all completed, from pool 
21/02/17 01:04:28 INFO DAGScheduler: ShuffleMapStage 24 (parquet at RFormula.scala:508) finished in 0.010 s
21/02/17 01:04:28 INFO DAGScheduler: looking for newly runnable stages
21/02/17 01:04:28 INFO DAGScheduler: running: Set()
21/02/17 01:04:28 INFO DAGScheduler: waiting: Set(ResultStage 25)
21/02/17 01:04:28 INFO DAGScheduler: failed: Set()
21/02/17 01:04:28 INFO DAGScheduler: Submitting ResultStage 25 (ShuffledRowRDD[82] at parquet at RFormula.scala:508), which has no missing parents
21/02/17 01:04:28 INFO MemoryStore: Block broadcast_26 stored as values in memory (estimated size 175.0 KiB, free 911.2 MiB)
21/02/17 01:04:28 INFO MemoryStore: Block broadcast_26_piece0 stored as bytes in memory (estimated size 61.7 KiB, free 911.1 MiB)
21/02/17 01:04:28 INFO BlockManagerInfo: Added broadcast_26_piece0 in memory on localhost:39871 (size: 61.7 KiB, free: 912.0 MiB)
21/02/17 01:04:28 INFO SparkContext: Created broadcast 26 from broadcast at DAGScheduler.scala:1200
21/02/17 01:04:28 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 25 (ShuffledRowRDD[82] at parquet at RFormula.scala:508) (first 15 tasks are for partitions Vector(0))
21/02/17 01:04:28 INFO TaskSchedulerImpl: Adding task set 25.0 with 1 tasks
21/02/17 01:04:28 INFO TaskSetManager: Starting task 0.0 in stage 25.0 (TID 25, localhost, executor driver, partition 0, NODE_LOCAL, 7325 bytes)
21/02/17 01:04:28 INFO Executor: Running task 0.0 in stage 25.0 (TID 25)
21/02/17 01:04:28 INFO ShuffleBlockFetcherIterator: Getting 1 (72.0 B) non-empty blocks including 1 (72.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
21/02/17 01:04:28 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
21/02/17 01:04:28 INFO FileOutputCommitter: File Output Committer Algorithm version is 2
21/02/17 01:04:28 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
21/02/17 01:04:28 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
21/02/17 01:04:28 INFO FileOutputCommitter: File Output Committer Algorithm version is 2
21/02/17 01:04:28 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
21/02/17 01:04:28 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
21/02/17 01:04:28 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:
{
  "type" : "struct",
  "fields" : [ {
    "name" : "columnsToPrune",
    "type" : {
      "type" : "array",
      "elementType" : "string",
      "containsNull" : true
    },
    "nullable" : true,
    "metadata" : { }
  } ]
}
and corresponding Parquet message type:
message spark_schema {
  optional group columnsToPrune (LIST) {
    repeated group list {
      optional binary element (UTF8);
    }
  }
}

       
21/02/17 01:04:28 INFO FileOutputCommitter: Saved output of task 'attempt_20210217010428_0025_m_000000_25' to file:/tmp/RtmpbZfqhf/file201a73deadac6/stages/0_r_formula__56fd7584_4f86_4137_b58a_3260f77a610d/pipelineModel/stages/2_columnPruner_45df637c9a01/data
21/02/17 01:04:28 INFO SparkHadoopMapRedUtil: attempt_20210217010428_0025_m_000000_25: Committed
21/02/17 01:04:28 INFO Executor: Finished task 0.0 in stage 25.0 (TID 25). 3195 bytes result sent to driver
21/02/17 01:04:28 INFO TaskSetManager: Finished task 0.0 in stage 25.0 (TID 25) in 20 ms on localhost (executor driver) (1/1)
21/02/17 01:04:28 INFO TaskSchedulerImpl: Removed TaskSet 25.0, whose tasks have all completed, from pool 
21/02/17 01:04:28 INFO DAGScheduler: ResultStage 25 (parquet at RFormula.scala:508) finished in 0.041 s
21/02/17 01:04:28 INFO DAGScheduler: Job 19 is finished. Cancelling potential speculative or zombie tasks for this job
21/02/17 01:04:28 INFO TaskSchedulerImpl: Killing all running tasks in stage 25: Stage finished
21/02/17 01:04:28 INFO DAGScheduler: Job 19 finished: parquet at RFormula.scala:508, took 0.056973 s
21/02/17 01:04:28 INFO FileFormatWriter: Write Job 4df6e799-1854-4624-b4f5-6eb7e3f2ea9c committed.
21/02/17 01:04:28 INFO FileFormatWriter: Finished processing stats for write job 4df6e799-1854-4624-b4f5-6eb7e3f2ea9c.
21/02/17 01:04:28 INFO Instrumentation: [54b9010f] training finished
21/02/17 01:04:28 INFO Instrumentation: [c39afd45] training finished
21/02/17 01:04:28 INFO HadoopMapRedCommitProtocol: Using output committer class org.apache.hadoop.mapred.FileOutputCommitter
21/02/17 01:04:28 INFO FileOutputCommitter: File Output Committer Algorithm version is 2
21/02/17 01:04:28 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
21/02/17 01:04:28 INFO SparkContext: Starting job: runJob at SparkHadoopWriter.scala:78
21/02/17 01:04:28 INFO DAGScheduler: Got job 20 (runJob at SparkHadoopWriter.scala:78) with 1 output partitions
21/02/17 01:04:28 INFO DAGScheduler: Final stage: ResultStage 26 (runJob at SparkHadoopWriter.scala:78)
21/02/17 01:04:28 INFO DAGScheduler: Parents of final stage: List()
21/02/17 01:04:28 INFO DAGScheduler: Missing parents: List()
21/02/17 01:04:28 INFO DAGScheduler: Submitting ResultStage 26 (MapPartitionsRDD[86] at saveAsTextFile at DefaultXGBoostParamsWriter.scala:52), which has no missing parents
21/02/17 01:04:28 INFO MemoryStore: Block broadcast_27 stored as values in memory (estimated size 84.0 KiB, free 911.0 MiB)
21/02/17 01:04:28 INFO MemoryStore: Block broadcast_27_piece0 stored as bytes in memory (estimated size 30.0 KiB, free 911.0 MiB)
21/02/17 01:04:28 INFO BlockManagerInfo: Added broadcast_27_piece0 in memory on localhost:39871 (size: 30.0 KiB, free: 912.0 MiB)
21/02/17 01:04:28 INFO SparkContext: Created broadcast 27 from broadcast at DAGScheduler.scala:1200
21/02/17 01:04:28 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 26 (MapPartitionsRDD[86] at saveAsTextFile at DefaultXGBoostParamsWriter.scala:52) (first 15 tasks are for partitions Vector(0))
21/02/17 01:04:28 INFO TaskSchedulerImpl: Adding task set 26.0 with 1 tasks
21/02/17 01:04:28 INFO TaskSetManager: Starting task 0.0 in stage 26.0 (TID 26, localhost, executor driver, partition 0, PROCESS_LOCAL, 8635 bytes)
21/02/17 01:04:28 INFO Executor: Running task 0.0 in stage 26.0 (TID 26)
21/02/17 01:04:28 INFO HadoopMapRedCommitProtocol: Using output committer class org.apache.hadoop.mapred.FileOutputCommitter
21/02/17 01:04:28 INFO FileOutputCommitter: File Output Committer Algorithm version is 2
21/02/17 01:04:28 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
21/02/17 01:04:28 INFO FileOutputCommitter: Saved output of task 'attempt_20210217010428_0086_m_000000_0' to file:/tmp/RtmpbZfqhf/file201a73deadac6/stages/1_xgboost_regressor__80e12a7b_8c17_4325_80c6_fa3a9511ae8c/metadata
21/02/17 01:04:28 INFO SparkHadoopMapRedUtil: attempt_20210217010428_0086_m_000000_0: Committed
21/02/17 01:04:28 INFO Executor: Finished task 0.0 in stage 26.0 (TID 26). 1158 bytes result sent to driver
21/02/17 01:04:28 INFO TaskSetManager: Finished task 0.0 in stage 26.0 (TID 26) in 13 ms on localhost (executor driver) (1/1)
21/02/17 01:04:28 INFO TaskSchedulerImpl: Removed TaskSet 26.0, whose tasks have all completed, from pool 
21/02/17 01:04:28 INFO DAGScheduler: ResultStage 26 (runJob at SparkHadoopWriter.scala:78) finished in 0.024 s
21/02/17 01:04:28 INFO DAGScheduler: Job 20 is finished. Cancelling potential speculative or zombie tasks for this job
21/02/17 01:04:28 INFO TaskSchedulerImpl: Killing all running tasks in stage 26: Stage finished
21/02/17 01:04:28 INFO DAGScheduler: Job 20 finished: runJob at SparkHadoopWriter.scala:78, took 0.026118 s
21/02/17 01:04:28 INFO SparkHadoopWriter: Job job_20210217010428_0086 committed.
21/02/17 01:04:28 INFO Instrumentation: [67828386] training finished
21/02/17 01:04:28 INFO Instrumentation: [956e365a] training finished
21/02/17 01:04:28 INFO HiveMetaStore: 0: get_database: default
21/02/17 01:04:28 INFO audit: ugi=yitaoli	ip=unknown-ip-addr	cmd=get_database: default	
21/02/17 01:04:28 INFO HiveMetaStore: 0: get_database: default
21/02/17 01:04:28 INFO audit: ugi=yitaoli	ip=unknown-ip-addr	cmd=get_database: default	
21/02/17 01:04:28 INFO HiveMetaStore: 0: get_tables: db=default pat=*
21/02/17 01:04:28 INFO audit: ugi=yitaoli	ip=unknown-ip-addr	cmd=get_tables: db=default pat=*	
21/02/17 01:04:28 INFO CodeGenerator: Code generated in 3.977886 ms
21/02/17 01:04:28 INFO SparkContext: Starting job: collect at utils.scala:54
21/02/17 01:04:28 INFO DAGScheduler: Got job 21 (collect at utils.scala:54) with 2 output partitions
21/02/17 01:04:28 INFO DAGScheduler: Final stage: ResultStage 27 (collect at utils.scala:54)
21/02/17 01:04:28 INFO DAGScheduler: Parents of final stage: List()
21/02/17 01:04:28 INFO DAGScheduler: Missing parents: List()
21/02/17 01:04:28 INFO DAGScheduler: Submitting ResultStage 27 (MapPartitionsRDD[92] at map at utils.scala:54), which has no missing parents
21/02/17 01:04:28 INFO MemoryStore: Block broadcast_28 stored as values in memory (estimated size 10.7 KiB, free 911.0 MiB)
21/02/17 01:04:28 INFO MemoryStore: Block broadcast_28_piece0 stored as bytes in memory (estimated size 4.9 KiB, free 911.0 MiB)
21/02/17 01:04:28 INFO BlockManagerInfo: Added broadcast_28_piece0 in memory on localhost:39871 (size: 4.9 KiB, free: 912.0 MiB)
21/02/17 01:04:28 INFO SparkContext: Created broadcast 28 from broadcast at DAGScheduler.scala:1200
21/02/17 01:04:28 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 27 (MapPartitionsRDD[92] at map at utils.scala:54) (first 15 tasks are for partitions Vector(0, 1))
21/02/17 01:04:28 INFO TaskSchedulerImpl: Adding task set 27.0 with 2 tasks
21/02/17 01:04:28 INFO TaskSetManager: Starting task 0.0 in stage 27.0 (TID 27, localhost, executor driver, partition 0, PROCESS_LOCAL, 7533 bytes)
21/02/17 01:04:28 INFO TaskSetManager: Starting task 1.0 in stage 27.0 (TID 28, localhost, executor driver, partition 1, PROCESS_LOCAL, 7581 bytes)
21/02/17 01:04:28 INFO Executor: Running task 0.0 in stage 27.0 (TID 27)
21/02/17 01:04:28 INFO Executor: Running task 1.0 in stage 27.0 (TID 28)
21/02/17 01:04:28 INFO CodeGenerator: Code generated in 5.57103 ms
21/02/17 01:04:28 INFO Executor: Finished task 0.0 in stage 27.0 (TID 27). 1110 bytes result sent to driver
21/02/17 01:04:28 INFO Executor: Finished task 1.0 in stage 27.0 (TID 28). 1155 bytes result sent to driver
21/02/17 01:04:28 INFO TaskSetManager: Finished task 0.0 in stage 27.0 (TID 27) in 26 ms on localhost (executor driver) (1/2)
21/02/17 01:04:28 INFO TaskSetManager: Finished task 1.0 in stage 27.0 (TID 28) in 26 ms on localhost (executor driver) (2/2)
21/02/17 01:04:28 INFO TaskSchedulerImpl: Removed TaskSet 27.0, whose tasks have all completed, from pool 
21/02/17 01:04:28 INFO DAGScheduler: ResultStage 27 (collect at utils.scala:54) finished in 0.030 s
21/02/17 01:04:28 INFO DAGScheduler: Job 21 is finished. Cancelling potential speculative or zombie tasks for this job
21/02/17 01:04:28 INFO TaskSchedulerImpl: Killing all running tasks in stage 27: Stage finished
21/02/17 01:04:28 INFO DAGScheduler: Job 21 finished: collect at utils.scala:54, took 0.033322 s
21/02/17 01:04:28 INFO InMemoryFileIndex: It took 7 ms to list leaf files for 1 paths.
21/02/17 01:04:28 INFO InMemoryFileIndex: It took 0 ms to list leaf files for 1 paths.
21/02/17 01:04:28 INFO FileSourceStrategy: Pruning directories with: 
21/02/17 01:04:28 INFO FileSourceStrategy: Pushed Filters: 
21/02/17 01:04:28 INFO FileSourceStrategy: Post-Scan Filters: 
21/02/17 01:04:28 INFO FileSourceStrategy: Output Data Schema: struct<value: string>
21/02/17 01:04:28 INFO MemoryStore: Block broadcast_29 stored as values in memory (estimated size 313.9 KiB, free 910.7 MiB)
21/02/17 01:04:28 INFO MemoryStore: Block broadcast_29_piece0 stored as bytes in memory (estimated size 28.3 KiB, free 910.7 MiB)
21/02/17 01:04:28 INFO BlockManagerInfo: Added broadcast_29_piece0 in memory on localhost:39871 (size: 28.3 KiB, free: 911.9 MiB)
21/02/17 01:04:28 INFO SparkContext: Created broadcast 29 from json at NativeMethodAccessorImpl.java:0
21/02/17 01:04:28 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
21/02/17 01:04:28 INFO SparkContext: Starting job: json at NativeMethodAccessorImpl.java:0
21/02/17 01:04:28 INFO DAGScheduler: Got job 22 (json at NativeMethodAccessorImpl.java:0) with 1 output partitions
21/02/17 01:04:28 INFO DAGScheduler: Final stage: ResultStage 28 (json at NativeMethodAccessorImpl.java:0)
21/02/17 01:04:28 INFO DAGScheduler: Parents of final stage: List()
21/02/17 01:04:28 INFO DAGScheduler: Missing parents: List()
21/02/17 01:04:28 INFO DAGScheduler: Submitting ResultStage 28 (MapPartitionsRDD[96] at json at NativeMethodAccessorImpl.java:0), which has no missing parents
21/02/17 01:04:28 INFO MemoryStore: Block broadcast_30 stored as values in memory (estimated size 14.4 KiB, free 910.7 MiB)
21/02/17 01:04:28 INFO MemoryStore: Block broadcast_30_piece0 stored as bytes in memory (estimated size 6.8 KiB, free 910.6 MiB)
21/02/17 01:04:28 INFO BlockManagerInfo: Added broadcast_30_piece0 in memory on localhost:39871 (size: 6.8 KiB, free: 911.9 MiB)
21/02/17 01:04:28 INFO SparkContext: Created broadcast 30 from broadcast at DAGScheduler.scala:1200
21/02/17 01:04:28 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 28 (MapPartitionsRDD[96] at json at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
21/02/17 01:04:28 INFO TaskSchedulerImpl: Adding task set 28.0 with 1 tasks
21/02/17 01:04:28 INFO TaskSetManager: Starting task 0.0 in stage 28.0 (TID 29, localhost, executor driver, partition 0, PROCESS_LOCAL, 7757 bytes)
21/02/17 01:04:28 INFO Executor: Running task 0.0 in stage 28.0 (TID 29)
21/02/17 01:04:28 INFO BlockManagerInfo: Removed broadcast_24_piece0 on localhost:39871 in memory (size: 30.0 KiB, free: 911.9 MiB)
21/02/17 01:04:28 INFO FileScanRDD: Reading File path: file:///tmp/RtmpbZfqhf/file201a73deadac6/metadata/part-00000, range: 0-306, partition values: [empty row]
21/02/17 01:04:28 INFO BlockManagerInfo: Removed broadcast_28_piece0 on localhost:39871 in memory (size: 4.9 KiB, free: 912.0 MiB)
21/02/17 01:04:28 INFO BlockManagerInfo: Removed broadcast_22_piece0 on localhost:39871 in memory (size: 4.2 KiB, free: 912.0 MiB)
21/02/17 01:04:28 INFO BlockManagerInfo: Removed broadcast_25_piece0 on localhost:39871 in memory (size: 4.1 KiB, free: 912.0 MiB)
21/02/17 01:04:28 INFO BlockManagerInfo: Removed broadcast_26_piece0 on localhost:39871 in memory (size: 61.7 KiB, free: 912.0 MiB)
21/02/17 01:04:28 INFO CodeGenerator: Code generated in 7.870442 ms
21/02/17 01:04:28 INFO BlockManagerInfo: Removed broadcast_20_piece0 on localhost:39871 in memory (size: 30.0 KiB, free: 912.1 MiB)
21/02/17 01:04:28 INFO BlockManagerInfo: Removed broadcast_19_piece0 on localhost:39871 in memory (size: 30.0 KiB, free: 912.1 MiB)
21/02/17 01:04:28 INFO BlockManagerInfo: Removed broadcast_21_piece0 on localhost:39871 in memory (size: 30.0 KiB, free: 912.1 MiB)
21/02/17 01:04:28 INFO BlockManagerInfo: Removed broadcast_23_piece0 on localhost:39871 in memory (size: 61.8 KiB, free: 912.2 MiB)
21/02/17 01:04:28 INFO BlockManagerInfo: Removed broadcast_27_piece0 on localhost:39871 in memory (size: 30.0 KiB, free: 912.2 MiB)
21/02/17 01:04:28 INFO Executor: Finished task 0.0 in stage 28.0 (TID 29). 2294 bytes result sent to driver
21/02/17 01:04:28 INFO TaskSetManager: Finished task 0.0 in stage 28.0 (TID 29) in 96 ms on localhost (executor driver) (1/1)
21/02/17 01:04:28 INFO TaskSchedulerImpl: Removed TaskSet 28.0, whose tasks have all completed, from pool 
21/02/17 01:04:28 INFO DAGScheduler: ResultStage 28 (json at NativeMethodAccessorImpl.java:0) finished in 0.103 s
21/02/17 01:04:28 INFO DAGScheduler: Job 22 is finished. Cancelling potential speculative or zombie tasks for this job
21/02/17 01:04:28 INFO TaskSchedulerImpl: Killing all running tasks in stage 28: Stage finished
21/02/17 01:04:28 INFO DAGScheduler: Job 22 finished: json at NativeMethodAccessorImpl.java:0, took 0.106661 s
21/02/17 01:04:28 INFO HiveMetaStore: 0: get_database: default
21/02/17 01:04:28 INFO audit: ugi=yitaoli	ip=unknown-ip-addr	cmd=get_database: default	
21/02/17 01:04:28 INFO HiveMetaStore: 0: get_database: default
21/02/17 01:04:28 INFO audit: ugi=yitaoli	ip=unknown-ip-addr	cmd=get_database: default	
21/02/17 01:04:28 INFO HiveMetaStore: 0: get_tables: db=default pat=*
21/02/17 01:04:28 INFO audit: ugi=yitaoli	ip=unknown-ip-addr	cmd=get_tables: db=default pat=*	
21/02/17 01:04:28 INFO CodeGenerator: Code generated in 4.826674 ms
21/02/17 01:04:28 INFO CodeGenerator: Code generated in 4.398387 ms
21/02/17 01:04:28 INFO CodeGenerator: Code generated in 5.0723 ms
21/02/17 01:04:28 INFO CodeGenerator: Code generated in 3.486079 ms
21/02/17 01:04:28 INFO SparkContext: Starting job: count at utils.scala:135
21/02/17 01:04:28 INFO DAGScheduler: Registering RDD 99 (count at utils.scala:135) as input to shuffle 7
21/02/17 01:04:28 INFO DAGScheduler: Got job 23 (count at utils.scala:135) with 1 output partitions
21/02/17 01:04:28 INFO DAGScheduler: Final stage: ResultStage 30 (count at utils.scala:135)
21/02/17 01:04:28 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 29)
21/02/17 01:04:28 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 29)
21/02/17 01:04:28 INFO DAGScheduler: Submitting ShuffleMapStage 29 (MapPartitionsRDD[99] at count at utils.scala:135), which has no missing parents
21/02/17 01:04:28 INFO MemoryStore: Block broadcast_31 stored as values in memory (estimated size 10.1 KiB, free 911.7 MiB)
21/02/17 01:04:28 INFO MemoryStore: Block broadcast_31_piece0 stored as bytes in memory (estimated size 5.3 KiB, free 911.7 MiB)
21/02/17 01:04:28 INFO BlockManagerInfo: Added broadcast_31_piece0 in memory on localhost:39871 (size: 5.3 KiB, free: 912.2 MiB)
21/02/17 01:04:28 INFO SparkContext: Created broadcast 31 from broadcast at DAGScheduler.scala:1200
21/02/17 01:04:28 INFO DAGScheduler: Submitting 2 missing tasks from ShuffleMapStage 29 (MapPartitionsRDD[99] at count at utils.scala:135) (first 15 tasks are for partitions Vector(0, 1))
21/02/17 01:04:28 INFO TaskSchedulerImpl: Adding task set 29.0 with 2 tasks
21/02/17 01:04:28 INFO TaskSetManager: Starting task 0.0 in stage 29.0 (TID 30, localhost, executor driver, partition 0, PROCESS_LOCAL, 7498 bytes)
21/02/17 01:04:28 INFO TaskSetManager: Starting task 1.0 in stage 29.0 (TID 31, localhost, executor driver, partition 1, PROCESS_LOCAL, 7498 bytes)
21/02/17 01:04:28 INFO Executor: Running task 0.0 in stage 29.0 (TID 30)
21/02/17 01:04:28 INFO Executor: Running task 1.0 in stage 29.0 (TID 31)
21/02/17 01:04:28 INFO Executor: Finished task 0.0 in stage 29.0 (TID 30). 1833 bytes result sent to driver
21/02/17 01:04:28 INFO Executor: Finished task 1.0 in stage 29.0 (TID 31). 1833 bytes result sent to driver
21/02/17 01:04:28 INFO TaskSetManager: Finished task 0.0 in stage 29.0 (TID 30) in 10 ms on localhost (executor driver) (1/2)
21/02/17 01:04:28 INFO TaskSetManager: Finished task 1.0 in stage 29.0 (TID 31) in 10 ms on localhost (executor driver) (2/2)
21/02/17 01:04:28 INFO TaskSchedulerImpl: Removed TaskSet 29.0, whose tasks have all completed, from pool 
21/02/17 01:04:28 INFO DAGScheduler: ShuffleMapStage 29 (count at utils.scala:135) finished in 0.015 s
21/02/17 01:04:28 INFO DAGScheduler: looking for newly runnable stages
21/02/17 01:04:28 INFO DAGScheduler: running: Set()
21/02/17 01:04:28 INFO DAGScheduler: waiting: Set(ResultStage 30)
21/02/17 01:04:28 INFO DAGScheduler: failed: Set()
21/02/17 01:04:28 INFO DAGScheduler: Submitting ResultStage 30 (MapPartitionsRDD[102] at count at utils.scala:135), which has no missing parents
21/02/17 01:04:28 INFO MemoryStore: Block broadcast_32 stored as values in memory (estimated size 10.1 KiB, free 911.7 MiB)
21/02/17 01:04:28 INFO MemoryStore: Block broadcast_32_piece0 stored as bytes in memory (estimated size 5.0 KiB, free 911.7 MiB)
21/02/17 01:04:28 INFO BlockManagerInfo: Added broadcast_32_piece0 in memory on localhost:39871 (size: 5.0 KiB, free: 912.2 MiB)
21/02/17 01:04:28 INFO SparkContext: Created broadcast 32 from broadcast at DAGScheduler.scala:1200
21/02/17 01:04:28 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 30 (MapPartitionsRDD[102] at count at utils.scala:135) (first 15 tasks are for partitions Vector(0))
21/02/17 01:04:28 INFO TaskSchedulerImpl: Adding task set 30.0 with 1 tasks
21/02/17 01:04:28 INFO TaskSetManager: Starting task 0.0 in stage 30.0 (TID 32, localhost, executor driver, partition 0, NODE_LOCAL, 7325 bytes)
21/02/17 01:04:28 INFO Executor: Running task 0.0 in stage 30.0 (TID 32)
21/02/17 01:04:28 INFO ShuffleBlockFetcherIterator: Getting 2 (120.0 B) non-empty blocks including 2 (120.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
21/02/17 01:04:28 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
21/02/17 01:04:28 INFO Executor: Finished task 0.0 in stage 30.0 (TID 32). 2648 bytes result sent to driver
21/02/17 01:04:28 INFO TaskSetManager: Finished task 0.0 in stage 30.0 (TID 32) in 4 ms on localhost (executor driver) (1/1)
21/02/17 01:04:28 INFO TaskSchedulerImpl: Removed TaskSet 30.0, whose tasks have all completed, from pool 
21/02/17 01:04:28 INFO DAGScheduler: ResultStage 30 (count at utils.scala:135) finished in 0.008 s
21/02/17 01:04:28 INFO DAGScheduler: Job 23 is finished. Cancelling potential speculative or zombie tasks for this job
21/02/17 01:04:28 INFO TaskSchedulerImpl: Killing all running tasks in stage 30: Stage finished
21/02/17 01:04:28 INFO DAGScheduler: Job 23 finished: count at utils.scala:135, took 0.026944 s
21/02/17 01:04:29 INFO FileSourceStrategy: Pruning directories with: 
21/02/17 01:04:29 INFO FileSourceStrategy: Pushed Filters: 
21/02/17 01:04:29 INFO FileSourceStrategy: Post-Scan Filters: 
21/02/17 01:04:29 INFO FileSourceStrategy: Output Data Schema: struct<class: string, paramMap: struct<stageUids: array<string>>, sparkVersion: string, timestamp: bigint, uid: string ... 3 more fields>
21/02/17 01:04:29 INFO CodeGenerator: Code generated in 6.041445 ms
21/02/17 01:04:29 INFO MemoryStore: Block broadcast_33 stored as values in memory (estimated size 313.9 KiB, free 911.4 MiB)
21/02/17 01:04:29 INFO MemoryStore: Block broadcast_33_piece0 stored as bytes in memory (estimated size 28.3 KiB, free 911.3 MiB)
21/02/17 01:04:29 INFO BlockManagerInfo: Added broadcast_33_piece0 in memory on localhost:39871 (size: 28.3 KiB, free: 912.2 MiB)
21/02/17 01:04:29 INFO SparkContext: Created broadcast 33 from sql at <unknown>:0
21/02/17 01:04:29 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
21/02/17 01:04:29 INFO SparkContext: Starting job: sql at <unknown>:0
21/02/17 01:04:29 INFO DAGScheduler: Registering RDD 109 (sql at <unknown>:0) as input to shuffle 8
21/02/17 01:04:29 INFO DAGScheduler: Got job 24 (sql at <unknown>:0) with 1 output partitions
21/02/17 01:04:29 INFO DAGScheduler: Final stage: ResultStage 32 (sql at <unknown>:0)
21/02/17 01:04:29 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 31)
21/02/17 01:04:29 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 31)
21/02/17 01:04:29 INFO DAGScheduler: Submitting ShuffleMapStage 31 (MapPartitionsRDD[109] at sql at <unknown>:0), which has no missing parents
21/02/17 01:04:29 INFO MemoryStore: Block broadcast_34 stored as values in memory (estimated size 21.5 KiB, free 911.3 MiB)
21/02/17 01:04:29 INFO MemoryStore: Block broadcast_34_piece0 stored as bytes in memory (estimated size 10.1 KiB, free 911.3 MiB)
21/02/17 01:04:29 INFO BlockManagerInfo: Added broadcast_34_piece0 in memory on localhost:39871 (size: 10.1 KiB, free: 912.2 MiB)
21/02/17 01:04:29 INFO SparkContext: Created broadcast 34 from broadcast at DAGScheduler.scala:1200
21/02/17 01:04:29 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 31 (MapPartitionsRDD[109] at sql at <unknown>:0) (first 15 tasks are for partitions Vector(0))
21/02/17 01:04:29 INFO TaskSchedulerImpl: Adding task set 31.0 with 1 tasks
21/02/17 01:04:29 INFO TaskSetManager: Starting task 0.0 in stage 31.0 (TID 33, localhost, executor driver, partition 0, PROCESS_LOCAL, 7746 bytes)
21/02/17 01:04:29 INFO Executor: Running task 0.0 in stage 31.0 (TID 33)
21/02/17 01:04:29 INFO FileScanRDD: Reading File path: file:///tmp/RtmpbZfqhf/file201a73deadac6/metadata/part-00000, range: 0-306, partition values: [empty row]
21/02/17 01:04:29 INFO CodeGenerator: Code generated in 6.85689 ms
21/02/17 01:04:29 INFO MemoryStore: Block rdd_105_0 stored as values in memory (estimated size 1296.0 B, free 911.3 MiB)
21/02/17 01:04:29 INFO BlockManagerInfo: Added rdd_105_0 in memory on localhost:39871 (size: 1296.0 B, free: 912.2 MiB)
21/02/17 01:04:29 INFO CodeGenerator: Code generated in 7.757453 ms
21/02/17 01:04:29 INFO Executor: Finished task 0.0 in stage 31.0 (TID 33). 2067 bytes result sent to driver
21/02/17 01:04:29 INFO TaskSetManager: Finished task 0.0 in stage 31.0 (TID 33) in 46 ms on localhost (executor driver) (1/1)
21/02/17 01:04:29 INFO TaskSchedulerImpl: Removed TaskSet 31.0, whose tasks have all completed, from pool 
21/02/17 01:04:29 INFO DAGScheduler: ShuffleMapStage 31 (sql at <unknown>:0) finished in 0.054 s
21/02/17 01:04:29 INFO DAGScheduler: looking for newly runnable stages
21/02/17 01:04:29 INFO DAGScheduler: running: Set()
21/02/17 01:04:29 INFO DAGScheduler: waiting: Set(ResultStage 32)
21/02/17 01:04:29 INFO DAGScheduler: failed: Set()
21/02/17 01:04:29 INFO DAGScheduler: Submitting ResultStage 32 (MapPartitionsRDD[112] at sql at <unknown>:0), which has no missing parents
21/02/17 01:04:29 INFO MemoryStore: Block broadcast_35 stored as values in memory (estimated size 10.1 KiB, free 911.3 MiB)
21/02/17 01:04:29 INFO MemoryStore: Block broadcast_35_piece0 stored as bytes in memory (estimated size 5.0 KiB, free 911.3 MiB)
21/02/17 01:04:29 INFO BlockManagerInfo: Added broadcast_35_piece0 in memory on localhost:39871 (size: 5.0 KiB, free: 912.1 MiB)
21/02/17 01:04:29 INFO SparkContext: Created broadcast 35 from broadcast at DAGScheduler.scala:1200
21/02/17 01:04:29 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 32 (MapPartitionsRDD[112] at sql at <unknown>:0) (first 15 tasks are for partitions Vector(0))
21/02/17 01:04:29 INFO TaskSchedulerImpl: Adding task set 32.0 with 1 tasks
21/02/17 01:04:29 INFO TaskSetManager: Starting task 0.0 in stage 32.0 (TID 34, localhost, executor driver, partition 0, NODE_LOCAL, 7325 bytes)
21/02/17 01:04:29 INFO Executor: Running task 0.0 in stage 32.0 (TID 34)
21/02/17 01:04:29 INFO ShuffleBlockFetcherIterator: Getting 1 (60.0 B) non-empty blocks including 1 (60.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
21/02/17 01:04:29 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
21/02/17 01:04:29 INFO Executor: Finished task 0.0 in stage 32.0 (TID 34). 2648 bytes result sent to driver
21/02/17 01:04:29 INFO TaskSetManager: Finished task 0.0 in stage 32.0 (TID 34) in 5 ms on localhost (executor driver) (1/1)
21/02/17 01:04:29 INFO TaskSchedulerImpl: Removed TaskSet 32.0, whose tasks have all completed, from pool 
21/02/17 01:04:29 INFO DAGScheduler: ResultStage 32 (sql at <unknown>:0) finished in 0.009 s
21/02/17 01:04:29 INFO DAGScheduler: Job 24 is finished. Cancelling potential speculative or zombie tasks for this job
21/02/17 01:04:29 INFO TaskSchedulerImpl: Killing all running tasks in stage 32: Stage finished
21/02/17 01:04:29 INFO DAGScheduler: Job 24 finished: sql at <unknown>:0, took 0.068026 s
21/02/17 01:04:29 INFO SparkContext: Starting job: collect at utils.scala:137
21/02/17 01:04:29 INFO DAGScheduler: Registering RDD 116 (collect at utils.scala:137) as input to shuffle 9
21/02/17 01:04:29 INFO DAGScheduler: Got job 25 (collect at utils.scala:137) with 1 output partitions
21/02/17 01:04:29 INFO DAGScheduler: Final stage: ResultStage 34 (collect at utils.scala:137)
21/02/17 01:04:29 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 33)
21/02/17 01:04:29 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 33)
21/02/17 01:04:29 INFO DAGScheduler: Submitting ShuffleMapStage 33 (MapPartitionsRDD[116] at collect at utils.scala:137), which has no missing parents
21/02/17 01:04:29 INFO MemoryStore: Block broadcast_36 stored as values in memory (estimated size 21.5 KiB, free 911.3 MiB)
21/02/17 01:04:29 INFO MemoryStore: Block broadcast_36_piece0 stored as bytes in memory (estimated size 10.1 KiB, free 911.3 MiB)
21/02/17 01:04:29 INFO BlockManagerInfo: Added broadcast_36_piece0 in memory on localhost:39871 (size: 10.1 KiB, free: 912.1 MiB)
21/02/17 01:04:29 INFO SparkContext: Created broadcast 36 from broadcast at DAGScheduler.scala:1200
21/02/17 01:04:29 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 33 (MapPartitionsRDD[116] at collect at utils.scala:137) (first 15 tasks are for partitions Vector(0))
21/02/17 01:04:29 INFO TaskSchedulerImpl: Adding task set 33.0 with 1 tasks
21/02/17 01:04:29 INFO TaskSetManager: Starting task 0.0 in stage 33.0 (TID 35, localhost, executor driver, partition 0, PROCESS_LOCAL, 7746 bytes)
21/02/17 01:04:29 INFO Executor: Running task 0.0 in stage 33.0 (TID 35)
21/02/17 01:04:29 INFO BlockManager: Found block rdd_105_0 locally
21/02/17 01:04:29 INFO Executor: Finished task 0.0 in stage 33.0 (TID 35). 2067 bytes result sent to driver
21/02/17 01:04:29 INFO TaskSetManager: Finished task 0.0 in stage 33.0 (TID 35) in 6 ms on localhost (executor driver) (1/1)
21/02/17 01:04:29 INFO TaskSchedulerImpl: Removed TaskSet 33.0, whose tasks have all completed, from pool 
21/02/17 01:04:29 INFO DAGScheduler: ShuffleMapStage 33 (collect at utils.scala:137) finished in 0.010 s
21/02/17 01:04:29 INFO DAGScheduler: looking for newly runnable stages
21/02/17 01:04:29 INFO DAGScheduler: running: Set()
21/02/17 01:04:29 INFO DAGScheduler: waiting: Set(ResultStage 34)
21/02/17 01:04:29 INFO DAGScheduler: failed: Set()
21/02/17 01:04:29 INFO DAGScheduler: Submitting ResultStage 34 (MapPartitionsRDD[119] at collect at utils.scala:137), which has no missing parents
21/02/17 01:04:29 INFO MemoryStore: Block broadcast_37 stored as values in memory (estimated size 10.1 KiB, free 911.3 MiB)
21/02/17 01:04:29 INFO MemoryStore: Block broadcast_37_piece0 stored as bytes in memory (estimated size 5.0 KiB, free 911.3 MiB)
21/02/17 01:04:29 INFO BlockManagerInfo: Added broadcast_37_piece0 in memory on localhost:39871 (size: 5.0 KiB, free: 912.1 MiB)
21/02/17 01:04:29 INFO SparkContext: Created broadcast 37 from broadcast at DAGScheduler.scala:1200
21/02/17 01:04:29 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 34 (MapPartitionsRDD[119] at collect at utils.scala:137) (first 15 tasks are for partitions Vector(0))
21/02/17 01:04:29 INFO TaskSchedulerImpl: Adding task set 34.0 with 1 tasks
21/02/17 01:04:29 INFO TaskSetManager: Starting task 0.0 in stage 34.0 (TID 36, localhost, executor driver, partition 0, NODE_LOCAL, 7325 bytes)
21/02/17 01:04:29 INFO Executor: Running task 0.0 in stage 34.0 (TID 36)
21/02/17 01:04:29 INFO ShuffleBlockFetcherIterator: Getting 1 (60.0 B) non-empty blocks including 1 (60.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
21/02/17 01:04:29 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
21/02/17 01:04:29 INFO Executor: Finished task 0.0 in stage 34.0 (TID 36). 2648 bytes result sent to driver
21/02/17 01:04:29 INFO TaskSetManager: Finished task 0.0 in stage 34.0 (TID 36) in 4 ms on localhost (executor driver) (1/1)
21/02/17 01:04:29 INFO TaskSchedulerImpl: Removed TaskSet 34.0, whose tasks have all completed, from pool 
21/02/17 01:04:29 INFO DAGScheduler: ResultStage 34 (collect at utils.scala:137) finished in 0.008 s
21/02/17 01:04:29 INFO DAGScheduler: Job 25 is finished. Cancelling potential speculative or zombie tasks for this job
21/02/17 01:04:29 INFO TaskSchedulerImpl: Killing all running tasks in stage 34: Stage finished
21/02/17 01:04:29 INFO DAGScheduler: Job 25 finished: collect at utils.scala:137, took 0.021069 s
21/02/17 01:04:29 INFO CodeGenerator: Code generated in 5.767602 ms
21/02/17 01:04:29 INFO CodeGenerator: Code generated in 8.467616 ms
21/02/17 01:04:29 INFO CodeGenerator: Code generated in 6.624151 ms
21/02/17 01:04:29 INFO SparkContext: Starting job: count at utils.scala:135
21/02/17 01:04:29 INFO DAGScheduler: Registering RDD 123 (count at utils.scala:135) as input to shuffle 10
21/02/17 01:04:29 INFO DAGScheduler: Got job 26 (count at utils.scala:135) with 1 output partitions
21/02/17 01:04:29 INFO DAGScheduler: Final stage: ResultStage 36 (count at utils.scala:135)
21/02/17 01:04:29 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 35)
21/02/17 01:04:29 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 35)
21/02/17 01:04:29 INFO DAGScheduler: Submitting ShuffleMapStage 35 (MapPartitionsRDD[123] at count at utils.scala:135), which has no missing parents
21/02/17 01:04:29 INFO MemoryStore: Block broadcast_38 stored as values in memory (estimated size 20.9 KiB, free 911.2 MiB)
21/02/17 01:04:29 INFO MemoryStore: Block broadcast_38_piece0 stored as bytes in memory (estimated size 9.9 KiB, free 911.2 MiB)
21/02/17 01:04:29 INFO BlockManagerInfo: Added broadcast_38_piece0 in memory on localhost:39871 (size: 9.9 KiB, free: 912.1 MiB)
21/02/17 01:04:29 INFO SparkContext: Created broadcast 38 from broadcast at DAGScheduler.scala:1200
21/02/17 01:04:29 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 35 (MapPartitionsRDD[123] at count at utils.scala:135) (first 15 tasks are for partitions Vector(0))
21/02/17 01:04:29 INFO TaskSchedulerImpl: Adding task set 35.0 with 1 tasks
21/02/17 01:04:29 INFO TaskSetManager: Starting task 0.0 in stage 35.0 (TID 37, localhost, executor driver, partition 0, PROCESS_LOCAL, 7746 bytes)
21/02/17 01:04:29 INFO Executor: Running task 0.0 in stage 35.0 (TID 37)
21/02/17 01:04:29 INFO BlockManager: Found block rdd_105_0 locally
21/02/17 01:04:29 INFO Executor: Finished task 0.0 in stage 35.0 (TID 37). 2067 bytes result sent to driver
21/02/17 01:04:29 INFO TaskSetManager: Finished task 0.0 in stage 35.0 (TID 37) in 7 ms on localhost (executor driver) (1/1)
21/02/17 01:04:29 INFO TaskSchedulerImpl: Removed TaskSet 35.0, whose tasks have all completed, from pool 
21/02/17 01:04:29 INFO DAGScheduler: ShuffleMapStage 35 (count at utils.scala:135) finished in 0.013 s
21/02/17 01:04:29 INFO DAGScheduler: looking for newly runnable stages
21/02/17 01:04:29 INFO DAGScheduler: running: Set()
21/02/17 01:04:29 INFO DAGScheduler: waiting: Set(ResultStage 36)
21/02/17 01:04:29 INFO DAGScheduler: failed: Set()
21/02/17 01:04:29 INFO DAGScheduler: Submitting ResultStage 36 (MapPartitionsRDD[126] at count at utils.scala:135), which has no missing parents
21/02/17 01:04:29 INFO MemoryStore: Block broadcast_39 stored as values in memory (estimated size 12.1 KiB, free 911.2 MiB)
21/02/17 01:04:29 INFO MemoryStore: Block broadcast_39_piece0 stored as bytes in memory (estimated size 5.3 KiB, free 911.2 MiB)
21/02/17 01:04:29 INFO BlockManagerInfo: Added broadcast_39_piece0 in memory on localhost:39871 (size: 5.3 KiB, free: 912.1 MiB)
21/02/17 01:04:29 INFO SparkContext: Created broadcast 39 from broadcast at DAGScheduler.scala:1200
21/02/17 01:04:29 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 36 (MapPartitionsRDD[126] at count at utils.scala:135) (first 15 tasks are for partitions Vector(0))
21/02/17 01:04:29 INFO TaskSchedulerImpl: Adding task set 36.0 with 1 tasks
21/02/17 01:04:29 INFO TaskSetManager: Starting task 0.0 in stage 36.0 (TID 38, localhost, executor driver, partition 0, NODE_LOCAL, 7325 bytes)
21/02/17 01:04:29 INFO Executor: Running task 0.0 in stage 36.0 (TID 38)
21/02/17 01:04:29 INFO ShuffleBlockFetcherIterator: Getting 1 (49.0 B) non-empty blocks including 1 (49.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
21/02/17 01:04:29 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
21/02/17 01:04:29 INFO Executor: Finished task 0.0 in stage 36.0 (TID 38). 2896 bytes result sent to driver
21/02/17 01:04:29 INFO TaskSetManager: Finished task 0.0 in stage 36.0 (TID 38) in 7 ms on localhost (executor driver) (1/1)
21/02/17 01:04:29 INFO TaskSchedulerImpl: Removed TaskSet 36.0, whose tasks have all completed, from pool 
21/02/17 01:04:29 INFO DAGScheduler: ResultStage 36 (count at utils.scala:135) finished in 0.011 s
21/02/17 01:04:29 INFO DAGScheduler: Job 26 is finished. Cancelling potential speculative or zombie tasks for this job
21/02/17 01:04:29 INFO TaskSchedulerImpl: Killing all running tasks in stage 36: Stage finished
21/02/17 01:04:29 INFO DAGScheduler: Job 26 finished: count at utils.scala:135, took 0.027933 s
21/02/17 01:04:29 INFO SparkContext: Starting job: collect at utils.scala:137
21/02/17 01:04:29 INFO DAGScheduler: Got job 27 (collect at utils.scala:137) with 1 output partitions
21/02/17 01:04:29 INFO DAGScheduler: Final stage: ResultStage 37 (collect at utils.scala:137)
21/02/17 01:04:29 INFO DAGScheduler: Parents of final stage: List()
21/02/17 01:04:29 INFO DAGScheduler: Missing parents: List()
21/02/17 01:04:29 INFO DAGScheduler: Submitting ResultStage 37 (MapPartitionsRDD[128] at collect at utils.scala:137), which has no missing parents
21/02/17 01:04:29 INFO MemoryStore: Block broadcast_40 stored as values in memory (estimated size 7.2 KiB, free 911.2 MiB)
21/02/17 01:04:29 INFO MemoryStore: Block broadcast_40_piece0 stored as bytes in memory (estimated size 3.7 KiB, free 911.2 MiB)
21/02/17 01:04:29 INFO BlockManagerInfo: Added broadcast_40_piece0 in memory on localhost:39871 (size: 3.7 KiB, free: 912.1 MiB)
21/02/17 01:04:29 INFO SparkContext: Created broadcast 40 from broadcast at DAGScheduler.scala:1200
21/02/17 01:04:29 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 37 (MapPartitionsRDD[128] at collect at utils.scala:137) (first 15 tasks are for partitions Vector(0))
21/02/17 01:04:29 INFO TaskSchedulerImpl: Adding task set 37.0 with 1 tasks
21/02/17 01:04:29 INFO TaskSetManager: Starting task 0.0 in stage 37.0 (TID 39, localhost, executor driver, partition 0, PROCESS_LOCAL, 7561 bytes)
21/02/17 01:04:29 INFO Executor: Running task 0.0 in stage 37.0 (TID 39)
21/02/17 01:04:29 INFO Executor: Finished task 0.0 in stage 37.0 (TID 39). 1354 bytes result sent to driver
21/02/17 01:04:29 INFO TaskSetManager: Finished task 0.0 in stage 37.0 (TID 39) in 4 ms on localhost (executor driver) (1/1)
21/02/17 01:04:29 INFO TaskSchedulerImpl: Removed TaskSet 37.0, whose tasks have all completed, from pool 
21/02/17 01:04:29 INFO DAGScheduler: ResultStage 37 (collect at utils.scala:137) finished in 0.007 s
21/02/17 01:04:29 INFO DAGScheduler: Job 27 is finished. Cancelling potential speculative or zombie tasks for this job
21/02/17 01:04:29 INFO TaskSchedulerImpl: Killing all running tasks in stage 37: Stage finished
21/02/17 01:04:29 INFO DAGScheduler: Job 27 finished: collect at utils.scala:137, took 0.008638 s
21/02/17 01:04:29 INFO SparkContext: Starting job: count at utils.scala:135
21/02/17 01:04:29 INFO DAGScheduler: Registering RDD 130 (count at utils.scala:135) as input to shuffle 11
21/02/17 01:04:29 INFO DAGScheduler: Got job 28 (count at utils.scala:135) with 1 output partitions
21/02/17 01:04:29 INFO DAGScheduler: Final stage: ResultStage 39 (count at utils.scala:135)
21/02/17 01:04:29 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 38)
21/02/17 01:04:29 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 38)
21/02/17 01:04:29 INFO DAGScheduler: Submitting ShuffleMapStage 38 (MapPartitionsRDD[130] at count at utils.scala:135), which has no missing parents
21/02/17 01:04:29 INFO MemoryStore: Block broadcast_41 stored as values in memory (estimated size 10.0 KiB, free 911.2 MiB)
21/02/17 01:04:29 INFO MemoryStore: Block broadcast_41_piece0 stored as bytes in memory (estimated size 5.2 KiB, free 911.2 MiB)
21/02/17 01:04:29 INFO BlockManagerInfo: Added broadcast_41_piece0 in memory on localhost:39871 (size: 5.2 KiB, free: 912.1 MiB)
21/02/17 01:04:29 INFO SparkContext: Created broadcast 41 from broadcast at DAGScheduler.scala:1200
21/02/17 01:04:29 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 38 (MapPartitionsRDD[130] at count at utils.scala:135) (first 15 tasks are for partitions Vector(0))
21/02/17 01:04:29 INFO TaskSchedulerImpl: Adding task set 38.0 with 1 tasks
21/02/17 01:04:29 INFO TaskSetManager: Starting task 0.0 in stage 38.0 (TID 40, localhost, executor driver, partition 0, PROCESS_LOCAL, 7550 bytes)
21/02/17 01:04:29 INFO Executor: Running task 0.0 in stage 38.0 (TID 40)
21/02/17 01:04:29 INFO Executor: Finished task 0.0 in stage 38.0 (TID 40). 1833 bytes result sent to driver
21/02/17 01:04:29 INFO TaskSetManager: Finished task 0.0 in stage 38.0 (TID 40) in 5 ms on localhost (executor driver) (1/1)
21/02/17 01:04:29 INFO TaskSchedulerImpl: Removed TaskSet 38.0, whose tasks have all completed, from pool 
21/02/17 01:04:29 INFO DAGScheduler: ShuffleMapStage 38 (count at utils.scala:135) finished in 0.008 s
21/02/17 01:04:29 INFO DAGScheduler: looking for newly runnable stages
21/02/17 01:04:29 INFO DAGScheduler: running: Set()
21/02/17 01:04:29 INFO DAGScheduler: waiting: Set(ResultStage 39)
21/02/17 01:04:29 INFO DAGScheduler: failed: Set()
21/02/17 01:04:29 INFO DAGScheduler: Submitting ResultStage 39 (MapPartitionsRDD[133] at count at utils.scala:135), which has no missing parents
21/02/17 01:04:29 INFO MemoryStore: Block broadcast_42 stored as values in memory (estimated size 10.1 KiB, free 911.2 MiB)
21/02/17 01:04:29 INFO MemoryStore: Block broadcast_42_piece0 stored as bytes in memory (estimated size 5.0 KiB, free 911.2 MiB)
21/02/17 01:04:29 INFO BlockManagerInfo: Added broadcast_42_piece0 in memory on localhost:39871 (size: 5.0 KiB, free: 912.1 MiB)
21/02/17 01:04:29 INFO SparkContext: Created broadcast 42 from broadcast at DAGScheduler.scala:1200
21/02/17 01:04:29 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 39 (MapPartitionsRDD[133] at count at utils.scala:135) (first 15 tasks are for partitions Vector(0))
21/02/17 01:04:29 INFO TaskSchedulerImpl: Adding task set 39.0 with 1 tasks
21/02/17 01:04:29 INFO TaskSetManager: Starting task 0.0 in stage 39.0 (TID 41, localhost, executor driver, partition 0, NODE_LOCAL, 7325 bytes)
21/02/17 01:04:29 INFO Executor: Running task 0.0 in stage 39.0 (TID 41)
21/02/17 01:04:29 INFO ShuffleBlockFetcherIterator: Getting 1 (60.0 B) non-empty blocks including 1 (60.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
21/02/17 01:04:29 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
21/02/17 01:04:29 INFO Executor: Finished task 0.0 in stage 39.0 (TID 41). 2648 bytes result sent to driver
21/02/17 01:04:29 INFO TaskSetManager: Finished task 0.0 in stage 39.0 (TID 41) in 5 ms on localhost (executor driver) (1/1)
21/02/17 01:04:29 INFO TaskSchedulerImpl: Removed TaskSet 39.0, whose tasks have all completed, from pool 
21/02/17 01:04:29 INFO DAGScheduler: ResultStage 39 (count at utils.scala:135) finished in 0.011 s
21/02/17 01:04:29 INFO DAGScheduler: Job 28 is finished. Cancelling potential speculative or zombie tasks for this job
21/02/17 01:04:29 INFO TaskSchedulerImpl: Killing all running tasks in stage 39: Stage finished
21/02/17 01:04:29 INFO DAGScheduler: Job 28 finished: count at utils.scala:135, took 0.021931 s
21/02/17 01:04:29 INFO BlockManagerInfo: Removed broadcast_39_piece0 on localhost:39871 in memory (size: 5.3 KiB, free: 912.1 MiB)
21/02/17 01:04:29 INFO BlockManagerInfo: Removed broadcast_32_piece0 on localhost:39871 in memory (size: 5.0 KiB, free: 912.1 MiB)
21/02/17 01:04:29 INFO BlockManagerInfo: Removed broadcast_38_piece0 on localhost:39871 in memory (size: 9.9 KiB, free: 912.1 MiB)
21/02/17 01:04:29 INFO BlockManagerInfo: Removed broadcast_37_piece0 on localhost:39871 in memory (size: 5.0 KiB, free: 912.1 MiB)
21/02/17 01:04:29 INFO SparkContext: Starting job: collect at utils.scala:137
21/02/17 01:04:29 INFO DAGScheduler: Got job 29 (collect at utils.scala:137) with 1 output partitions
21/02/17 01:04:29 INFO DAGScheduler: Final stage: ResultStage 40 (collect at utils.scala:137)
21/02/17 01:04:29 INFO DAGScheduler: Parents of final stage: List()
21/02/17 01:04:29 INFO DAGScheduler: Missing parents: List()
21/02/17 01:04:29 INFO DAGScheduler: Submitting ResultStage 40 (MapPartitionsRDD[136] at collect at utils.scala:137), which has no missing parents
21/02/17 01:04:29 INFO BlockManagerInfo: Removed broadcast_42_piece0 on localhost:39871 in memory (size: 5.0 KiB, free: 912.1 MiB)
21/02/17 01:04:29 INFO BlockManagerInfo: Removed broadcast_34_piece0 on localhost:39871 in memory (size: 10.1 KiB, free: 912.1 MiB)
21/02/17 01:04:29 INFO MemoryStore: Block broadcast_43 stored as values in memory (estimated size 16.7 KiB, free 911.3 MiB)
21/02/17 01:04:29 INFO MemoryStore: Block broadcast_43_piece0 stored as bytes in memory (estimated size 8.0 KiB, free 911.3 MiB)
21/02/17 01:04:29 INFO BlockManagerInfo: Added broadcast_43_piece0 in memory on localhost:39871 (size: 8.0 KiB, free: 912.1 MiB)
21/02/17 01:04:29 INFO BlockManagerInfo: Removed broadcast_35_piece0 on localhost:39871 in memory (size: 5.0 KiB, free: 912.1 MiB)
21/02/17 01:04:29 INFO SparkContext: Created broadcast 43 from broadcast at DAGScheduler.scala:1200
21/02/17 01:04:29 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 40 (MapPartitionsRDD[136] at collect at utils.scala:137) (first 15 tasks are for partitions Vector(0))
21/02/17 01:04:29 INFO TaskSchedulerImpl: Adding task set 40.0 with 1 tasks
21/02/17 01:04:29 INFO TaskSetManager: Starting task 0.0 in stage 40.0 (TID 42, localhost, executor driver, partition 0, PROCESS_LOCAL, 7757 bytes)
21/02/17 01:04:29 INFO Executor: Running task 0.0 in stage 40.0 (TID 42)
21/02/17 01:04:29 INFO BlockManagerInfo: Removed broadcast_30_piece0 on localhost:39871 in memory (size: 6.8 KiB, free: 912.1 MiB)
21/02/17 01:04:29 INFO BlockManagerInfo: Removed broadcast_29_piece0 on localhost:39871 in memory (size: 28.3 KiB, free: 912.2 MiB)
21/02/17 01:04:29 INFO BlockManager: Found block rdd_105_0 locally
21/02/17 01:04:29 INFO BlockManagerInfo: Removed broadcast_41_piece0 on localhost:39871 in memory (size: 5.2 KiB, free: 912.2 MiB)
21/02/17 01:04:29 INFO BlockManagerInfo: Removed broadcast_31_piece0 on localhost:39871 in memory (size: 5.3 KiB, free: 912.2 MiB)
21/02/17 01:04:29 INFO BlockManagerInfo: Removed broadcast_40_piece0 on localhost:39871 in memory (size: 3.7 KiB, free: 912.2 MiB)
21/02/17 01:04:29 INFO BlockManagerInfo: Removed broadcast_36_piece0 on localhost:39871 in memory (size: 10.1 KiB, free: 912.2 MiB)
21/02/17 01:04:29 INFO CodeGenerator: Code generated in 11.877337 ms
21/02/17 01:04:29 INFO Executor: Finished task 0.0 in stage 40.0 (TID 42). 1606 bytes result sent to driver
21/02/17 01:04:29 INFO TaskSetManager: Finished task 0.0 in stage 40.0 (TID 42) in 18 ms on localhost (executor driver) (1/1)
21/02/17 01:04:29 INFO TaskSchedulerImpl: Removed TaskSet 40.0, whose tasks have all completed, from pool 
21/02/17 01:04:29 INFO DAGScheduler: ResultStage 40 (collect at utils.scala:137) finished in 0.022 s
21/02/17 01:04:29 INFO DAGScheduler: Job 29 is finished. Cancelling potential speculative or zombie tasks for this job
21/02/17 01:04:29 INFO TaskSchedulerImpl: Killing all running tasks in stage 40: Stage finished
21/02/17 01:04:29 INFO DAGScheduler: Job 29 finished: collect at utils.scala:137, took 0.025137 s
21/02/17 01:04:29 INFO CodeGenerator: Code generated in 4.297792 ms
21/02/17 01:04:29 INFO SparkContext: Starting job: count at utils.scala:135
21/02/17 01:04:29 INFO DAGScheduler: Registering RDD 140 (count at utils.scala:135) as input to shuffle 12
21/02/17 01:04:29 INFO DAGScheduler: Got job 30 (count at utils.scala:135) with 1 output partitions
21/02/17 01:04:29 INFO DAGScheduler: Final stage: ResultStage 42 (count at utils.scala:135)
21/02/17 01:04:29 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 41)
21/02/17 01:04:29 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 41)
21/02/17 01:04:29 INFO DAGScheduler: Submitting ShuffleMapStage 41 (MapPartitionsRDD[140] at count at utils.scala:135), which has no missing parents
21/02/17 01:04:29 INFO MemoryStore: Block broadcast_44 stored as values in memory (estimated size 21.5 KiB, free 911.7 MiB)
21/02/17 01:04:29 INFO MemoryStore: Block broadcast_44_piece0 stored as bytes in memory (estimated size 10.1 KiB, free 911.7 MiB)
21/02/17 01:04:29 INFO BlockManagerInfo: Added broadcast_44_piece0 in memory on localhost:39871 (size: 10.1 KiB, free: 912.2 MiB)
21/02/17 01:04:29 INFO SparkContext: Created broadcast 44 from broadcast at DAGScheduler.scala:1200
21/02/17 01:04:29 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 41 (MapPartitionsRDD[140] at count at utils.scala:135) (first 15 tasks are for partitions Vector(0))
21/02/17 01:04:29 INFO TaskSchedulerImpl: Adding task set 41.0 with 1 tasks
21/02/17 01:04:29 INFO TaskSetManager: Starting task 0.0 in stage 41.0 (TID 43, localhost, executor driver, partition 0, PROCESS_LOCAL, 7746 bytes)
21/02/17 01:04:29 INFO Executor: Running task 0.0 in stage 41.0 (TID 43)
21/02/17 01:04:29 INFO BlockManager: Found block rdd_105_0 locally
21/02/17 01:04:29 INFO Executor: Finished task 0.0 in stage 41.0 (TID 43). 2067 bytes result sent to driver
21/02/17 01:04:29 INFO TaskSetManager: Finished task 0.0 in stage 41.0 (TID 43) in 6 ms on localhost (executor driver) (1/1)
21/02/17 01:04:29 INFO TaskSchedulerImpl: Removed TaskSet 41.0, whose tasks have all completed, from pool 
21/02/17 01:04:29 INFO DAGScheduler: ShuffleMapStage 41 (count at utils.scala:135) finished in 0.010 s
21/02/17 01:04:29 INFO DAGScheduler: looking for newly runnable stages
21/02/17 01:04:29 INFO DAGScheduler: running: Set()
21/02/17 01:04:29 INFO DAGScheduler: waiting: Set(ResultStage 42)
21/02/17 01:04:29 INFO DAGScheduler: failed: Set()
21/02/17 01:04:29 INFO DAGScheduler: Submitting ResultStage 42 (MapPartitionsRDD[143] at count at utils.scala:135), which has no missing parents
21/02/17 01:04:29 INFO MemoryStore: Block broadcast_45 stored as values in memory (estimated size 10.1 KiB, free 911.7 MiB)
21/02/17 01:04:29 INFO MemoryStore: Block broadcast_45_piece0 stored as bytes in memory (estimated size 5.0 KiB, free 911.7 MiB)
21/02/17 01:04:29 INFO BlockManagerInfo: Added broadcast_45_piece0 in memory on localhost:39871 (size: 5.0 KiB, free: 912.2 MiB)
21/02/17 01:04:29 INFO SparkContext: Created broadcast 45 from broadcast at DAGScheduler.scala:1200
21/02/17 01:04:29 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 42 (MapPartitionsRDD[143] at count at utils.scala:135) (first 15 tasks are for partitions Vector(0))
21/02/17 01:04:29 INFO TaskSchedulerImpl: Adding task set 42.0 with 1 tasks
21/02/17 01:04:29 INFO TaskSetManager: Starting task 0.0 in stage 42.0 (TID 44, localhost, executor driver, partition 0, NODE_LOCAL, 7325 bytes)
21/02/17 01:04:29 INFO Executor: Running task 0.0 in stage 42.0 (TID 44)
21/02/17 01:04:29 INFO ShuffleBlockFetcherIterator: Getting 1 (60.0 B) non-empty blocks including 1 (60.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
21/02/17 01:04:29 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
21/02/17 01:04:29 INFO Executor: Finished task 0.0 in stage 42.0 (TID 44). 2648 bytes result sent to driver
21/02/17 01:04:29 INFO TaskSetManager: Finished task 0.0 in stage 42.0 (TID 44) in 4 ms on localhost (executor driver) (1/1)
21/02/17 01:04:29 INFO TaskSchedulerImpl: Removed TaskSet 42.0, whose tasks have all completed, from pool 
21/02/17 01:04:29 INFO DAGScheduler: ResultStage 42 (count at utils.scala:135) finished in 0.008 s
21/02/17 01:04:29 INFO DAGScheduler: Job 30 is finished. Cancelling potential speculative or zombie tasks for this job
21/02/17 01:04:29 INFO TaskSchedulerImpl: Killing all running tasks in stage 42: Stage finished
21/02/17 01:04:29 INFO DAGScheduler: Job 30 finished: count at utils.scala:135, took 0.021202 s
21/02/17 01:04:29 INFO MapPartitionsRDD: Removing RDD 105 from persistence list
21/02/17 01:04:29 INFO BlockManager: Removing RDD 105
21/02/17 01:04:29 INFO MemoryStore: Block broadcast_46 stored as values in memory (estimated size 294.6 KiB, free 911.4 MiB)
21/02/17 01:04:29 INFO MemoryStore: Block broadcast_46_piece0 stored as bytes in memory (estimated size 27.2 KiB, free 911.3 MiB)
21/02/17 01:04:29 INFO BlockManagerInfo: Added broadcast_46_piece0 in memory on localhost:39871 (size: 27.2 KiB, free: 912.2 MiB)
21/02/17 01:04:29 INFO SparkContext: Created broadcast 46 from textFile at ReadWrite.scala:587
21/02/17 01:04:29 INFO FileInputFormat: Total input files to process : 1
21/02/17 01:04:29 INFO SparkContext: Starting job: first at ReadWrite.scala:587
21/02/17 01:04:29 INFO DAGScheduler: Got job 31 (first at ReadWrite.scala:587) with 1 output partitions
21/02/17 01:04:29 INFO DAGScheduler: Final stage: ResultStage 43 (first at ReadWrite.scala:587)
21/02/17 01:04:29 INFO DAGScheduler: Parents of final stage: List()
21/02/17 01:04:29 INFO DAGScheduler: Missing parents: List()
21/02/17 01:04:29 INFO DAGScheduler: Submitting ResultStage 43 (/tmp/RtmpbZfqhf/file201a73deadac6/metadata MapPartitionsRDD[145] at textFile at ReadWrite.scala:587), which has no missing parents
21/02/17 01:04:29 INFO MemoryStore: Block broadcast_47 stored as values in memory (estimated size 4.1 KiB, free 911.3 MiB)
21/02/17 01:04:29 INFO MemoryStore: Block broadcast_47_piece0 stored as bytes in memory (estimated size 2.4 KiB, free 911.3 MiB)
21/02/17 01:04:29 INFO BlockManagerInfo: Added broadcast_47_piece0 in memory on localhost:39871 (size: 2.4 KiB, free: 912.2 MiB)
21/02/17 01:04:29 INFO SparkContext: Created broadcast 47 from broadcast at DAGScheduler.scala:1200
21/02/17 01:04:29 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 43 (/tmp/RtmpbZfqhf/file201a73deadac6/metadata MapPartitionsRDD[145] at textFile at ReadWrite.scala:587) (first 15 tasks are for partitions Vector(0))
21/02/17 01:04:29 INFO TaskSchedulerImpl: Adding task set 43.0 with 1 tasks
21/02/17 01:04:29 INFO TaskSetManager: Starting task 0.0 in stage 43.0 (TID 45, localhost, executor driver, partition 0, PROCESS_LOCAL, 7399 bytes)
21/02/17 01:04:29 INFO Executor: Running task 0.0 in stage 43.0 (TID 45)
21/02/17 01:04:29 INFO HadoopRDD: Input split: file:/tmp/RtmpbZfqhf/file201a73deadac6/metadata/part-00000:0+306
21/02/17 01:04:29 INFO Executor: Finished task 0.0 in stage 43.0 (TID 45). 1234 bytes result sent to driver
21/02/17 01:04:29 INFO TaskSetManager: Finished task 0.0 in stage 43.0 (TID 45) in 18 ms on localhost (executor driver) (1/1)
21/02/17 01:04:29 INFO TaskSchedulerImpl: Removed TaskSet 43.0, whose tasks have all completed, from pool 
21/02/17 01:04:29 INFO DAGScheduler: ResultStage 43 (first at ReadWrite.scala:587) finished in 0.022 s
21/02/17 01:04:29 INFO DAGScheduler: Job 31 is finished. Cancelling potential speculative or zombie tasks for this job
21/02/17 01:04:29 INFO TaskSchedulerImpl: Killing all running tasks in stage 43: Stage finished
21/02/17 01:04:29 INFO DAGScheduler: Job 31 finished: first at ReadWrite.scala:587, took 0.024830 s
21/02/17 01:04:29 INFO MemoryStore: Block broadcast_48 stored as values in memory (estimated size 294.6 KiB, free 911.1 MiB)
21/02/17 01:04:29 INFO MemoryStore: Block broadcast_48_piece0 stored as bytes in memory (estimated size 27.2 KiB, free 911.0 MiB)
21/02/17 01:04:29 INFO BlockManagerInfo: Added broadcast_48_piece0 in memory on localhost:39871 (size: 27.2 KiB, free: 912.1 MiB)
21/02/17 01:04:29 INFO SparkContext: Created broadcast 48 from textFile at ReadWrite.scala:587
21/02/17 01:04:29 INFO FileInputFormat: Total input files to process : 1
21/02/17 01:04:29 INFO SparkContext: Starting job: first at ReadWrite.scala:587
21/02/17 01:04:29 INFO DAGScheduler: Got job 32 (first at ReadWrite.scala:587) with 1 output partitions
21/02/17 01:04:29 INFO DAGScheduler: Final stage: ResultStage 44 (first at ReadWrite.scala:587)
21/02/17 01:04:29 INFO DAGScheduler: Parents of final stage: List()
21/02/17 01:04:29 INFO DAGScheduler: Missing parents: List()
21/02/17 01:04:29 INFO DAGScheduler: Submitting ResultStage 44 (/tmp/RtmpbZfqhf/file201a73deadac6/stages/0_r_formula__56fd7584_4f86_4137_b58a_3260f77a610d/metadata MapPartitionsRDD[147] at textFile at ReadWrite.scala:587), which has no missing parents
21/02/17 01:04:29 INFO MemoryStore: Block broadcast_49 stored as values in memory (estimated size 4.2 KiB, free 911.0 MiB)
21/02/17 01:04:29 INFO MemoryStore: Block broadcast_49_piece0 stored as bytes in memory (estimated size 2.5 KiB, free 911.0 MiB)
21/02/17 01:04:29 INFO BlockManagerInfo: Added broadcast_49_piece0 in memory on localhost:39871 (size: 2.5 KiB, free: 912.1 MiB)
21/02/17 01:04:29 INFO SparkContext: Created broadcast 49 from broadcast at DAGScheduler.scala:1200
21/02/17 01:04:29 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 44 (/tmp/RtmpbZfqhf/file201a73deadac6/stages/0_r_formula__56fd7584_4f86_4137_b58a_3260f77a610d/metadata MapPartitionsRDD[147] at textFile at ReadWrite.scala:587) (first 15 tasks are for partitions Vector(0))
21/02/17 01:04:29 INFO TaskSchedulerImpl: Adding task set 44.0 with 1 tasks
21/02/17 01:04:29 INFO TaskSetManager: Starting task 0.0 in stage 44.0 (TID 46, localhost, executor driver, partition 0, PROCESS_LOCAL, 7456 bytes)
21/02/17 01:04:29 INFO Executor: Running task 0.0 in stage 44.0 (TID 46)
21/02/17 01:04:29 INFO HadoopRDD: Input split: file:/tmp/RtmpbZfqhf/file201a73deadac6/stages/0_r_formula__56fd7584_4f86_4137_b58a_3260f77a610d/metadata/part-00000:0+447
21/02/17 01:04:29 INFO Executor: Finished task 0.0 in stage 44.0 (TID 46). 1375 bytes result sent to driver
21/02/17 01:04:29 INFO TaskSetManager: Finished task 0.0 in stage 44.0 (TID 46) in 3 ms on localhost (executor driver) (1/1)
21/02/17 01:04:29 INFO TaskSchedulerImpl: Removed TaskSet 44.0, whose tasks have all completed, from pool 
21/02/17 01:04:29 INFO DAGScheduler: ResultStage 44 (first at ReadWrite.scala:587) finished in 0.008 s
21/02/17 01:04:29 INFO DAGScheduler: Job 32 is finished. Cancelling potential speculative or zombie tasks for this job
21/02/17 01:04:29 INFO TaskSchedulerImpl: Killing all running tasks in stage 44: Stage finished
21/02/17 01:04:29 INFO DAGScheduler: Job 32 finished: first at ReadWrite.scala:587, took 0.008697 s
21/02/17 01:04:29 INFO MemoryStore: Block broadcast_50 stored as values in memory (estimated size 294.6 KiB, free 910.7 MiB)
21/02/17 01:04:29 INFO MemoryStore: Block broadcast_50_piece0 stored as bytes in memory (estimated size 27.2 KiB, free 910.7 MiB)
21/02/17 01:04:29 INFO BlockManagerInfo: Added broadcast_50_piece0 in memory on localhost:39871 (size: 27.2 KiB, free: 912.1 MiB)
21/02/17 01:04:29 INFO SparkContext: Created broadcast 50 from textFile at ReadWrite.scala:587
21/02/17 01:04:29 INFO FileInputFormat: Total input files to process : 1
21/02/17 01:04:29 INFO SparkContext: Starting job: first at ReadWrite.scala:587
21/02/17 01:04:29 INFO DAGScheduler: Got job 33 (first at ReadWrite.scala:587) with 1 output partitions
21/02/17 01:04:29 INFO DAGScheduler: Final stage: ResultStage 45 (first at ReadWrite.scala:587)
21/02/17 01:04:29 INFO DAGScheduler: Parents of final stage: List()
21/02/17 01:04:29 INFO DAGScheduler: Missing parents: List()
21/02/17 01:04:29 INFO DAGScheduler: Submitting ResultStage 45 (/tmp/RtmpbZfqhf/file201a73deadac6/stages/0_r_formula__56fd7584_4f86_4137_b58a_3260f77a610d/metadata MapPartitionsRDD[149] at textFile at ReadWrite.scala:587), which has no missing parents
21/02/17 01:04:29 INFO MemoryStore: Block broadcast_51 stored as values in memory (estimated size 4.2 KiB, free 910.7 MiB)
21/02/17 01:04:29 INFO MemoryStore: Block broadcast_51_piece0 stored as bytes in memory (estimated size 2.5 KiB, free 910.7 MiB)
21/02/17 01:04:29 INFO BlockManagerInfo: Added broadcast_51_piece0 in memory on localhost:39871 (size: 2.5 KiB, free: 912.1 MiB)
21/02/17 01:04:29 INFO SparkContext: Created broadcast 51 from broadcast at DAGScheduler.scala:1200
21/02/17 01:04:29 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 45 (/tmp/RtmpbZfqhf/file201a73deadac6/stages/0_r_formula__56fd7584_4f86_4137_b58a_3260f77a610d/metadata MapPartitionsRDD[149] at textFile at ReadWrite.scala:587) (first 15 tasks are for partitions Vector(0))
21/02/17 01:04:29 INFO TaskSchedulerImpl: Adding task set 45.0 with 1 tasks
21/02/17 01:04:29 INFO TaskSetManager: Starting task 0.0 in stage 45.0 (TID 47, localhost, executor driver, partition 0, PROCESS_LOCAL, 7456 bytes)
21/02/17 01:04:29 INFO Executor: Running task 0.0 in stage 45.0 (TID 47)
21/02/17 01:04:29 INFO HadoopRDD: Input split: file:/tmp/RtmpbZfqhf/file201a73deadac6/stages/0_r_formula__56fd7584_4f86_4137_b58a_3260f77a610d/metadata/part-00000:0+447
21/02/17 01:04:29 INFO Executor: Finished task 0.0 in stage 45.0 (TID 47). 1375 bytes result sent to driver
21/02/17 01:04:29 INFO TaskSetManager: Finished task 0.0 in stage 45.0 (TID 47) in 4 ms on localhost (executor driver) (1/1)
21/02/17 01:04:29 INFO TaskSchedulerImpl: Removed TaskSet 45.0, whose tasks have all completed, from pool 
21/02/17 01:04:29 INFO DAGScheduler: ResultStage 45 (first at ReadWrite.scala:587) finished in 0.007 s
21/02/17 01:04:29 INFO DAGScheduler: Job 33 is finished. Cancelling potential speculative or zombie tasks for this job
21/02/17 01:04:29 INFO TaskSchedulerImpl: Killing all running tasks in stage 45: Stage finished
21/02/17 01:04:29 INFO DAGScheduler: Job 33 finished: first at ReadWrite.scala:587, took 0.017955 s
21/02/17 01:04:29 INFO InMemoryFileIndex: It took 0 ms to list leaf files for 1 paths.
21/02/17 01:04:29 INFO SparkContext: Starting job: parquet at RFormula.scala:450
21/02/17 01:04:29 INFO DAGScheduler: Got job 34 (parquet at RFormula.scala:450) with 1 output partitions
21/02/17 01:04:29 INFO DAGScheduler: Final stage: ResultStage 46 (parquet at RFormula.scala:450)
21/02/17 01:04:29 INFO DAGScheduler: Parents of final stage: List()
21/02/17 01:04:29 INFO DAGScheduler: Missing parents: List()
21/02/17 01:04:29 INFO DAGScheduler: Submitting ResultStage 46 (MapPartitionsRDD[151] at parquet at RFormula.scala:450), which has no missing parents
21/02/17 01:04:29 INFO MemoryStore: Block broadcast_52 stored as values in memory (estimated size 86.6 KiB, free 910.6 MiB)
21/02/17 01:04:29 INFO MemoryStore: Block broadcast_52_piece0 stored as bytes in memory (estimated size 30.8 KiB, free 910.6 MiB)
21/02/17 01:04:29 INFO BlockManagerInfo: Added broadcast_52_piece0 in memory on localhost:39871 (size: 30.8 KiB, free: 912.1 MiB)
21/02/17 01:04:29 INFO SparkContext: Created broadcast 52 from broadcast at DAGScheduler.scala:1200
21/02/17 01:04:29 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 46 (MapPartitionsRDD[151] at parquet at RFormula.scala:450) (first 15 tasks are for partitions Vector(0))
21/02/17 01:04:29 INFO TaskSchedulerImpl: Adding task set 46.0 with 1 tasks
21/02/17 01:04:29 INFO TaskSetManager: Starting task 0.0 in stage 46.0 (TID 48, localhost, executor driver, partition 0, PROCESS_LOCAL, 7616 bytes)
21/02/17 01:04:30 INFO Executor: Running task 0.0 in stage 46.0 (TID 48)
21/02/17 01:04:30 INFO Executor: Finished task 0.0 in stage 46.0 (TID 48). 1835 bytes result sent to driver
21/02/17 01:04:30 INFO TaskSetManager: Finished task 0.0 in stage 46.0 (TID 48) in 34 ms on localhost (executor driver) (1/1)
21/02/17 01:04:30 INFO TaskSchedulerImpl: Removed TaskSet 46.0, whose tasks have all completed, from pool 
21/02/17 01:04:30 INFO DAGScheduler: ResultStage 46 (parquet at RFormula.scala:450) finished in 0.044 s
21/02/17 01:04:30 INFO DAGScheduler: Job 34 is finished. Cancelling potential speculative or zombie tasks for this job
21/02/17 01:04:30 INFO TaskSchedulerImpl: Killing all running tasks in stage 46: Stage finished
21/02/17 01:04:30 INFO DAGScheduler: Job 34 finished: parquet at RFormula.scala:450, took 0.045485 s
21/02/17 01:04:30 INFO FileSourceStrategy: Pruning directories with: 
21/02/17 01:04:30 INFO FileSourceStrategy: Pushed Filters: 
21/02/17 01:04:30 INFO FileSourceStrategy: Post-Scan Filters: 
21/02/17 01:04:30 INFO FileSourceStrategy: Output Data Schema: struct<label: string, terms: array<array<string>>, hasIntercept: boolean ... 1 more fields>
21/02/17 01:04:30 INFO MemoryStore: Block broadcast_53 stored as values in memory (estimated size 319.0 KiB, free 910.3 MiB)
21/02/17 01:04:30 INFO MemoryStore: Block broadcast_53_piece0 stored as bytes in memory (estimated size 29.0 KiB, free 910.2 MiB)
21/02/17 01:04:30 INFO BlockManagerInfo: Added broadcast_53_piece0 in memory on localhost:39871 (size: 29.0 KiB, free: 912.0 MiB)
21/02/17 01:04:30 INFO SparkContext: Created broadcast 53 from head at RFormula.scala:450
21/02/17 01:04:30 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
21/02/17 01:04:30 INFO SparkContext: Starting job: head at RFormula.scala:450
21/02/17 01:04:30 INFO DAGScheduler: Got job 35 (head at RFormula.scala:450) with 1 output partitions
21/02/17 01:04:30 INFO DAGScheduler: Final stage: ResultStage 47 (head at RFormula.scala:450)
21/02/17 01:04:30 INFO DAGScheduler: Parents of final stage: List()
21/02/17 01:04:30 INFO DAGScheduler: Missing parents: List()
21/02/17 01:04:30 INFO DAGScheduler: Submitting ResultStage 47 (MapPartitionsRDD[154] at head at RFormula.scala:450), which has no missing parents
21/02/17 01:04:30 INFO MemoryStore: Block broadcast_54 stored as values in memory (estimated size 9.1 KiB, free 910.2 MiB)
21/02/17 01:04:30 INFO MemoryStore: Block broadcast_54_piece0 stored as bytes in memory (estimated size 4.9 KiB, free 910.2 MiB)
21/02/17 01:04:30 INFO BlockManagerInfo: Added broadcast_54_piece0 in memory on localhost:39871 (size: 4.9 KiB, free: 912.0 MiB)
21/02/17 01:04:30 INFO SparkContext: Created broadcast 54 from broadcast at DAGScheduler.scala:1200
21/02/17 01:04:30 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 47 (MapPartitionsRDD[154] at head at RFormula.scala:450) (first 15 tasks are for partitions Vector(0))
21/02/17 01:04:30 INFO TaskSchedulerImpl: Adding task set 47.0 with 1 tasks
21/02/17 01:04:30 INFO TaskSetManager: Starting task 0.0 in stage 47.0 (TID 49, localhost, executor driver, partition 0, PROCESS_LOCAL, 7867 bytes)
21/02/17 01:04:30 INFO Executor: Running task 0.0 in stage 47.0 (TID 49)
21/02/17 01:04:30 INFO CodeGenerator: Code generated in 7.961671 ms
21/02/17 01:04:30 INFO FileScanRDD: Reading File path: file:///tmp/RtmpbZfqhf/file201a73deadac6/stages/0_r_formula__56fd7584_4f86_4137_b58a_3260f77a610d/data/part-00000-5bd7c746-acab-49f2-8f9b-60a7739ea2c6-c000.snappy.parquet, range: 0-1140, partition values: [empty row]
21/02/17 01:04:30 INFO CodecPool: Got brand-new decompressor [.snappy]
21/02/17 01:04:30 INFO Executor: Finished task 0.0 in stage 47.0 (TID 49). 1790 bytes result sent to driver
21/02/17 01:04:30 INFO TaskSetManager: Finished task 0.0 in stage 47.0 (TID 49) in 79 ms on localhost (executor driver) (1/1)
21/02/17 01:04:30 INFO TaskSchedulerImpl: Removed TaskSet 47.0, whose tasks have all completed, from pool 
21/02/17 01:04:30 INFO DAGScheduler: ResultStage 47 (head at RFormula.scala:450) finished in 0.089 s
21/02/17 01:04:30 INFO DAGScheduler: Job 35 is finished. Cancelling potential speculative or zombie tasks for this job
21/02/17 01:04:30 INFO TaskSchedulerImpl: Killing all running tasks in stage 47: Stage finished
21/02/17 01:04:30 INFO DAGScheduler: Job 35 finished: head at RFormula.scala:450, took 0.091453 s
21/02/17 01:04:30 INFO CodeGenerator: Code generated in 13.794655 ms
21/02/17 01:04:30 INFO MemoryStore: Block broadcast_55 stored as values in memory (estimated size 294.6 KiB, free 909.9 MiB)
21/02/17 01:04:30 INFO MemoryStore: Block broadcast_55_piece0 stored as bytes in memory (estimated size 27.2 KiB, free 909.9 MiB)
21/02/17 01:04:30 INFO BlockManagerInfo: Added broadcast_55_piece0 in memory on localhost:39871 (size: 27.2 KiB, free: 912.0 MiB)
21/02/17 01:04:30 INFO SparkContext: Created broadcast 55 from textFile at ReadWrite.scala:587
21/02/17 01:04:30 INFO FileInputFormat: Total input files to process : 1
21/02/17 01:04:30 INFO SparkContext: Starting job: first at ReadWrite.scala:587
21/02/17 01:04:30 INFO DAGScheduler: Got job 36 (first at ReadWrite.scala:587) with 1 output partitions
21/02/17 01:04:30 INFO DAGScheduler: Final stage: ResultStage 48 (first at ReadWrite.scala:587)
21/02/17 01:04:30 INFO DAGScheduler: Parents of final stage: List()
21/02/17 01:04:30 INFO DAGScheduler: Missing parents: List()
21/02/17 01:04:30 INFO DAGScheduler: Submitting ResultStage 48 (/tmp/RtmpbZfqhf/file201a73deadac6/stages/0_r_formula__56fd7584_4f86_4137_b58a_3260f77a610d/pipelineModel/metadata MapPartitionsRDD[156] at textFile at ReadWrite.scala:587), which has no missing parents
21/02/17 01:04:30 INFO MemoryStore: Block broadcast_56 stored as values in memory (estimated size 4.2 KiB, free 909.9 MiB)
21/02/17 01:04:30 INFO MemoryStore: Block broadcast_56_piece0 stored as bytes in memory (estimated size 2.5 KiB, free 909.9 MiB)
21/02/17 01:04:30 INFO BlockManagerInfo: Added broadcast_56_piece0 in memory on localhost:39871 (size: 2.5 KiB, free: 912.0 MiB)
21/02/17 01:04:30 INFO SparkContext: Created broadcast 56 from broadcast at DAGScheduler.scala:1200
21/02/17 01:04:30 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 48 (/tmp/RtmpbZfqhf/file201a73deadac6/stages/0_r_formula__56fd7584_4f86_4137_b58a_3260f77a610d/pipelineModel/metadata MapPartitionsRDD[156] at textFile at ReadWrite.scala:587) (first 15 tasks are for partitions Vector(0))
21/02/17 01:04:30 INFO TaskSchedulerImpl: Adding task set 48.0 with 1 tasks
21/02/17 01:04:30 INFO TaskSetManager: Starting task 0.0 in stage 48.0 (TID 50, localhost, executor driver, partition 0, PROCESS_LOCAL, 7471 bytes)
21/02/17 01:04:30 INFO Executor: Running task 0.0 in stage 48.0 (TID 50)
21/02/17 01:04:30 INFO HadoopRDD: Input split: file:/tmp/RtmpbZfqhf/file201a73deadac6/stages/0_r_formula__56fd7584_4f86_4137_b58a_3260f77a610d/pipelineModel/metadata/part-00000:0+311
21/02/17 01:04:30 INFO Executor: Finished task 0.0 in stage 48.0 (TID 50). 1196 bytes result sent to driver
21/02/17 01:04:30 INFO TaskSetManager: Finished task 0.0 in stage 48.0 (TID 50) in 4 ms on localhost (executor driver) (1/1)
21/02/17 01:04:30 INFO TaskSchedulerImpl: Removed TaskSet 48.0, whose tasks have all completed, from pool 
21/02/17 01:04:30 INFO DAGScheduler: ResultStage 48 (first at ReadWrite.scala:587) finished in 0.007 s
21/02/17 01:04:30 INFO DAGScheduler: Job 36 is finished. Cancelling potential speculative or zombie tasks for this job
21/02/17 01:04:30 INFO TaskSchedulerImpl: Killing all running tasks in stage 48: Stage finished
21/02/17 01:04:30 INFO DAGScheduler: Job 36 finished: first at ReadWrite.scala:587, took 0.008620 s
21/02/17 01:04:30 INFO MemoryStore: Block broadcast_57 stored as values in memory (estimated size 294.6 KiB, free 909.6 MiB)
21/02/17 01:04:30 INFO MemoryStore: Block broadcast_57_piece0 stored as bytes in memory (estimated size 27.2 KiB, free 909.6 MiB)
21/02/17 01:04:30 INFO BlockManagerInfo: Added broadcast_57_piece0 in memory on localhost:39871 (size: 27.2 KiB, free: 912.0 MiB)
21/02/17 01:04:30 INFO SparkContext: Created broadcast 57 from textFile at ReadWrite.scala:587
21/02/17 01:04:30 INFO FileInputFormat: Total input files to process : 1
21/02/17 01:04:30 INFO SparkContext: Starting job: first at ReadWrite.scala:587
21/02/17 01:04:30 INFO DAGScheduler: Got job 37 (first at ReadWrite.scala:587) with 1 output partitions
21/02/17 01:04:30 INFO DAGScheduler: Final stage: ResultStage 49 (first at ReadWrite.scala:587)
21/02/17 01:04:30 INFO DAGScheduler: Parents of final stage: List()
21/02/17 01:04:30 INFO DAGScheduler: Missing parents: List()
21/02/17 01:04:30 INFO DAGScheduler: Submitting ResultStage 49 (/tmp/RtmpbZfqhf/file201a73deadac6/stages/0_r_formula__56fd7584_4f86_4137_b58a_3260f77a610d/pipelineModel/stages/0_r_formula__56fd7584_4f86_4137_b58a_3260f77a610d/metadata MapPartitionsRDD[158] at textFile at ReadWrite.scala:587), which has no missing parents
21/02/17 01:04:30 INFO MemoryStore: Block broadcast_58 stored as values in memory (estimated size 4.3 KiB, free 909.6 MiB)
21/02/17 01:04:30 INFO MemoryStore: Block broadcast_58_piece0 stored as bytes in memory (estimated size 2.5 KiB, free 909.6 MiB)
21/02/17 01:04:30 INFO BlockManagerInfo: Added broadcast_58_piece0 in memory on localhost:39871 (size: 2.5 KiB, free: 912.0 MiB)
21/02/17 01:04:30 INFO SparkContext: Created broadcast 58 from broadcast at DAGScheduler.scala:1200
21/02/17 01:04:30 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 49 (/tmp/RtmpbZfqhf/file201a73deadac6/stages/0_r_formula__56fd7584_4f86_4137_b58a_3260f77a610d/pipelineModel/stages/0_r_formula__56fd7584_4f86_4137_b58a_3260f77a610d/metadata MapPartitionsRDD[158] at textFile at ReadWrite.scala:587) (first 15 tasks are for partitions Vector(0))
21/02/17 01:04:30 INFO TaskSchedulerImpl: Adding task set 49.0 with 1 tasks
21/02/17 01:04:30 INFO TaskSetManager: Starting task 0.0 in stage 49.0 (TID 51, localhost, executor driver, partition 0, PROCESS_LOCAL, 7531 bytes)
21/02/17 01:04:30 INFO Executor: Running task 0.0 in stage 49.0 (TID 51)
21/02/17 01:04:30 INFO HadoopRDD: Input split: file:/tmp/RtmpbZfqhf/file201a73deadac6/stages/0_r_formula__56fd7584_4f86_4137_b58a_3260f77a610d/pipelineModel/stages/0_r_formula__56fd7584_4f86_4137_b58a_3260f77a610d/metadata/part-00000:0+378
21/02/17 01:04:30 INFO Executor: Finished task 0.0 in stage 49.0 (TID 51). 1306 bytes result sent to driver
21/02/17 01:04:30 INFO TaskSetManager: Finished task 0.0 in stage 49.0 (TID 51) in 4 ms on localhost (executor driver) (1/1)
21/02/17 01:04:30 INFO TaskSchedulerImpl: Removed TaskSet 49.0, whose tasks have all completed, from pool 
21/02/17 01:04:30 INFO DAGScheduler: ResultStage 49 (first at ReadWrite.scala:587) finished in 0.008 s
21/02/17 01:04:30 INFO DAGScheduler: Job 37 is finished. Cancelling potential speculative or zombie tasks for this job
21/02/17 01:04:30 INFO TaskSchedulerImpl: Killing all running tasks in stage 49: Stage finished
21/02/17 01:04:30 INFO DAGScheduler: Job 37 finished: first at ReadWrite.scala:587, took 0.010102 s
21/02/17 01:04:30 INFO MemoryStore: Block broadcast_59 stored as values in memory (estimated size 294.6 KiB, free 909.3 MiB)
21/02/17 01:04:30 INFO MemoryStore: Block broadcast_59_piece0 stored as bytes in memory (estimated size 27.2 KiB, free 909.3 MiB)
21/02/17 01:04:30 INFO BlockManagerInfo: Added broadcast_59_piece0 in memory on localhost:39871 (size: 27.2 KiB, free: 911.9 MiB)
21/02/17 01:04:30 INFO SparkContext: Created broadcast 59 from textFile at ReadWrite.scala:587
21/02/17 01:04:30 INFO FileInputFormat: Total input files to process : 1
21/02/17 01:04:30 INFO SparkContext: Starting job: first at ReadWrite.scala:587
21/02/17 01:04:30 INFO DAGScheduler: Got job 38 (first at ReadWrite.scala:587) with 1 output partitions
21/02/17 01:04:30 INFO DAGScheduler: Final stage: ResultStage 50 (first at ReadWrite.scala:587)
21/02/17 01:04:30 INFO DAGScheduler: Parents of final stage: List()
21/02/17 01:04:30 INFO DAGScheduler: Missing parents: List()
21/02/17 01:04:30 INFO DAGScheduler: Submitting ResultStage 50 (/tmp/RtmpbZfqhf/file201a73deadac6/stages/0_r_formula__56fd7584_4f86_4137_b58a_3260f77a610d/pipelineModel/stages/0_r_formula__56fd7584_4f86_4137_b58a_3260f77a610d/metadata MapPartitionsRDD[160] at textFile at ReadWrite.scala:587), which has no missing parents
21/02/17 01:04:30 INFO MemoryStore: Block broadcast_60 stored as values in memory (estimated size 4.3 KiB, free 909.3 MiB)
21/02/17 01:04:30 INFO MemoryStore: Block broadcast_60_piece0 stored as bytes in memory (estimated size 2.5 KiB, free 909.3 MiB)
21/02/17 01:04:30 INFO BlockManagerInfo: Added broadcast_60_piece0 in memory on localhost:39871 (size: 2.5 KiB, free: 911.9 MiB)
21/02/17 01:04:30 INFO SparkContext: Created broadcast 60 from broadcast at DAGScheduler.scala:1200
21/02/17 01:04:30 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 50 (/tmp/RtmpbZfqhf/file201a73deadac6/stages/0_r_formula__56fd7584_4f86_4137_b58a_3260f77a610d/pipelineModel/stages/0_r_formula__56fd7584_4f86_4137_b58a_3260f77a610d/metadata MapPartitionsRDD[160] at textFile at ReadWrite.scala:587) (first 15 tasks are for partitions Vector(0))
21/02/17 01:04:30 INFO TaskSchedulerImpl: Adding task set 50.0 with 1 tasks
21/02/17 01:04:30 INFO TaskSetManager: Starting task 0.0 in stage 50.0 (TID 52, localhost, executor driver, partition 0, PROCESS_LOCAL, 7531 bytes)
21/02/17 01:04:30 INFO Executor: Running task 0.0 in stage 50.0 (TID 52)
21/02/17 01:04:30 INFO HadoopRDD: Input split: file:/tmp/RtmpbZfqhf/file201a73deadac6/stages/0_r_formula__56fd7584_4f86_4137_b58a_3260f77a610d/pipelineModel/stages/0_r_formula__56fd7584_4f86_4137_b58a_3260f77a610d/metadata/part-00000:0+378
21/02/17 01:04:30 INFO Executor: Finished task 0.0 in stage 50.0 (TID 52). 1306 bytes result sent to driver
21/02/17 01:04:30 INFO TaskSetManager: Finished task 0.0 in stage 50.0 (TID 52) in 3 ms on localhost (executor driver) (1/1)
21/02/17 01:04:30 INFO TaskSchedulerImpl: Removed TaskSet 50.0, whose tasks have all completed, from pool 
21/02/17 01:04:30 INFO DAGScheduler: ResultStage 50 (first at ReadWrite.scala:587) finished in 0.007 s
21/02/17 01:04:30 INFO DAGScheduler: Job 38 is finished. Cancelling potential speculative or zombie tasks for this job
21/02/17 01:04:30 INFO TaskSchedulerImpl: Killing all running tasks in stage 50: Stage finished
21/02/17 01:04:30 INFO DAGScheduler: Job 38 finished: first at ReadWrite.scala:587, took 0.008786 s
21/02/17 01:04:30 INFO MemoryStore: Block broadcast_61 stored as values in memory (estimated size 294.6 KiB, free 909.0 MiB)
21/02/17 01:04:30 INFO MemoryStore: Block broadcast_61_piece0 stored as bytes in memory (estimated size 27.2 KiB, free 909.0 MiB)
21/02/17 01:04:30 INFO BlockManagerInfo: Added broadcast_61_piece0 in memory on localhost:39871 (size: 27.2 KiB, free: 911.9 MiB)
21/02/17 01:04:30 INFO SparkContext: Created broadcast 61 from textFile at ReadWrite.scala:587
21/02/17 01:04:30 INFO FileInputFormat: Total input files to process : 1
21/02/17 01:04:30 INFO SparkContext: Starting job: first at ReadWrite.scala:587
21/02/17 01:04:30 INFO DAGScheduler: Got job 39 (first at ReadWrite.scala:587) with 1 output partitions
21/02/17 01:04:30 INFO DAGScheduler: Final stage: ResultStage 51 (first at ReadWrite.scala:587)
21/02/17 01:04:30 INFO DAGScheduler: Parents of final stage: List()
21/02/17 01:04:30 INFO DAGScheduler: Missing parents: List()
21/02/17 01:04:30 INFO DAGScheduler: Submitting ResultStage 51 (/tmp/RtmpbZfqhf/file201a73deadac6/stages/0_r_formula__56fd7584_4f86_4137_b58a_3260f77a610d/pipelineModel/stages/1_vectorAttrRewriter_3ec7e7fc06d5/metadata MapPartitionsRDD[162] at textFile at ReadWrite.scala:587), which has no missing parents
21/02/17 01:04:30 INFO MemoryStore: Block broadcast_62 stored as values in memory (estimated size 4.2 KiB, free 908.9 MiB)
21/02/17 01:04:30 INFO MemoryStore: Block broadcast_62_piece0 stored as bytes in memory (estimated size 2.5 KiB, free 908.9 MiB)
21/02/17 01:04:30 INFO BlockManagerInfo: Added broadcast_62_piece0 in memory on localhost:39871 (size: 2.5 KiB, free: 911.9 MiB)
21/02/17 01:04:30 INFO SparkContext: Created broadcast 62 from broadcast at DAGScheduler.scala:1200
21/02/17 01:04:30 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 51 (/tmp/RtmpbZfqhf/file201a73deadac6/stages/0_r_formula__56fd7584_4f86_4137_b58a_3260f77a610d/pipelineModel/stages/1_vectorAttrRewriter_3ec7e7fc06d5/metadata MapPartitionsRDD[162] at textFile at ReadWrite.scala:587) (first 15 tasks are for partitions Vector(0))
21/02/17 01:04:30 INFO TaskSchedulerImpl: Adding task set 51.0 with 1 tasks
21/02/17 01:04:30 INFO TaskSetManager: Starting task 0.0 in stage 51.0 (TID 53, localhost, executor driver, partition 0, PROCESS_LOCAL, 7515 bytes)
21/02/17 01:04:30 INFO Executor: Running task 0.0 in stage 51.0 (TID 53)
21/02/17 01:04:30 INFO HadoopRDD: Input split: file:/tmp/RtmpbZfqhf/file201a73deadac6/stages/0_r_formula__56fd7584_4f86_4137_b58a_3260f77a610d/pipelineModel/stages/1_vectorAttrRewriter_3ec7e7fc06d5/metadata/part-00000:0+188
21/02/17 01:04:30 INFO Executor: Finished task 0.0 in stage 51.0 (TID 53). 1070 bytes result sent to driver
21/02/17 01:04:30 INFO TaskSetManager: Finished task 0.0 in stage 51.0 (TID 53) in 4 ms on localhost (executor driver) (1/1)
21/02/17 01:04:30 INFO TaskSchedulerImpl: Removed TaskSet 51.0, whose tasks have all completed, from pool 
21/02/17 01:04:30 INFO DAGScheduler: ResultStage 51 (first at ReadWrite.scala:587) finished in 0.006 s
21/02/17 01:04:30 INFO DAGScheduler: Job 39 is finished. Cancelling potential speculative or zombie tasks for this job
21/02/17 01:04:30 INFO TaskSchedulerImpl: Killing all running tasks in stage 51: Stage finished
21/02/17 01:04:30 INFO DAGScheduler: Job 39 finished: first at ReadWrite.scala:587, took 0.007826 s
21/02/17 01:04:30 INFO MemoryStore: Block broadcast_63 stored as values in memory (estimated size 294.6 KiB, free 908.7 MiB)
21/02/17 01:04:30 INFO MemoryStore: Block broadcast_63_piece0 stored as bytes in memory (estimated size 27.2 KiB, free 908.6 MiB)
21/02/17 01:04:30 INFO BlockManagerInfo: Added broadcast_63_piece0 in memory on localhost:39871 (size: 27.2 KiB, free: 911.9 MiB)
21/02/17 01:04:30 INFO SparkContext: Created broadcast 63 from textFile at ReadWrite.scala:587
21/02/17 01:04:30 INFO FileInputFormat: Total input files to process : 1
21/02/17 01:04:30 INFO SparkContext: Starting job: first at ReadWrite.scala:587
21/02/17 01:04:30 INFO DAGScheduler: Got job 40 (first at ReadWrite.scala:587) with 1 output partitions
21/02/17 01:04:30 INFO DAGScheduler: Final stage: ResultStage 52 (first at ReadWrite.scala:587)
21/02/17 01:04:30 INFO DAGScheduler: Parents of final stage: List()
21/02/17 01:04:30 INFO DAGScheduler: Missing parents: List()
21/02/17 01:04:30 INFO DAGScheduler: Submitting ResultStage 52 (/tmp/RtmpbZfqhf/file201a73deadac6/stages/0_r_formula__56fd7584_4f86_4137_b58a_3260f77a610d/pipelineModel/stages/1_vectorAttrRewriter_3ec7e7fc06d5/metadata MapPartitionsRDD[164] at textFile at ReadWrite.scala:587), which has no missing parents
21/02/17 01:04:30 INFO MemoryStore: Block broadcast_64 stored as values in memory (estimated size 4.2 KiB, free 908.6 MiB)
21/02/17 01:04:30 INFO MemoryStore: Block broadcast_64_piece0 stored as bytes in memory (estimated size 2.5 KiB, free 908.6 MiB)
21/02/17 01:04:30 INFO BlockManagerInfo: Added broadcast_64_piece0 in memory on localhost:39871 (size: 2.5 KiB, free: 911.9 MiB)
21/02/17 01:04:30 INFO SparkContext: Created broadcast 64 from broadcast at DAGScheduler.scala:1200
21/02/17 01:04:30 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 52 (/tmp/RtmpbZfqhf/file201a73deadac6/stages/0_r_formula__56fd7584_4f86_4137_b58a_3260f77a610d/pipelineModel/stages/1_vectorAttrRewriter_3ec7e7fc06d5/metadata MapPartitionsRDD[164] at textFile at ReadWrite.scala:587) (first 15 tasks are for partitions Vector(0))
21/02/17 01:04:30 INFO TaskSchedulerImpl: Adding task set 52.0 with 1 tasks
21/02/17 01:04:30 INFO TaskSetManager: Starting task 0.0 in stage 52.0 (TID 54, localhost, executor driver, partition 0, PROCESS_LOCAL, 7515 bytes)
21/02/17 01:04:30 INFO Executor: Running task 0.0 in stage 52.0 (TID 54)
21/02/17 01:04:30 INFO HadoopRDD: Input split: file:/tmp/RtmpbZfqhf/file201a73deadac6/stages/0_r_formula__56fd7584_4f86_4137_b58a_3260f77a610d/pipelineModel/stages/1_vectorAttrRewriter_3ec7e7fc06d5/metadata/part-00000:0+188
21/02/17 01:04:30 INFO Executor: Finished task 0.0 in stage 52.0 (TID 54). 1113 bytes result sent to driver
21/02/17 01:04:30 INFO TaskSetManager: Finished task 0.0 in stage 52.0 (TID 54) in 4 ms on localhost (executor driver) (1/1)
21/02/17 01:04:30 INFO TaskSchedulerImpl: Removed TaskSet 52.0, whose tasks have all completed, from pool 
21/02/17 01:04:30 INFO DAGScheduler: ResultStage 52 (first at ReadWrite.scala:587) finished in 0.008 s
21/02/17 01:04:30 INFO DAGScheduler: Job 40 is finished. Cancelling potential speculative or zombie tasks for this job
21/02/17 01:04:30 INFO TaskSchedulerImpl: Killing all running tasks in stage 52: Stage finished
21/02/17 01:04:30 INFO DAGScheduler: Job 40 finished: first at ReadWrite.scala:587, took 0.008541 s
21/02/17 01:04:30 INFO InMemoryFileIndex: It took 1 ms to list leaf files for 1 paths.
21/02/17 01:04:30 INFO SparkContext: Starting job: parquet at RFormula.scala:612
21/02/17 01:04:30 INFO DAGScheduler: Got job 41 (parquet at RFormula.scala:612) with 1 output partitions
21/02/17 01:04:30 INFO DAGScheduler: Final stage: ResultStage 53 (parquet at RFormula.scala:612)
21/02/17 01:04:30 INFO DAGScheduler: Parents of final stage: List()
21/02/17 01:04:30 INFO DAGScheduler: Missing parents: List()
21/02/17 01:04:30 INFO DAGScheduler: Submitting ResultStage 53 (MapPartitionsRDD[166] at parquet at RFormula.scala:612), which has no missing parents
21/02/17 01:04:30 INFO MemoryStore: Block broadcast_65 stored as values in memory (estimated size 86.6 KiB, free 908.5 MiB)
21/02/17 01:04:30 INFO MemoryStore: Block broadcast_65_piece0 stored as bytes in memory (estimated size 30.8 KiB, free 908.5 MiB)
21/02/17 01:04:30 INFO BlockManagerInfo: Added broadcast_65_piece0 in memory on localhost:39871 (size: 30.8 KiB, free: 911.9 MiB)
21/02/17 01:04:30 INFO SparkContext: Created broadcast 65 from broadcast at DAGScheduler.scala:1200
21/02/17 01:04:30 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 53 (MapPartitionsRDD[166] at parquet at RFormula.scala:612) (first 15 tasks are for partitions Vector(0))
21/02/17 01:04:30 INFO TaskSchedulerImpl: Adding task set 53.0 with 1 tasks
21/02/17 01:04:30 INFO TaskSetManager: Starting task 0.0 in stage 53.0 (TID 55, localhost, executor driver, partition 0, PROCESS_LOCAL, 7671 bytes)
21/02/17 01:04:30 INFO Executor: Running task 0.0 in stage 53.0 (TID 55)
21/02/17 01:04:30 INFO BlockManagerInfo: Removed broadcast_50_piece0 on localhost:39871 in memory (size: 27.2 KiB, free: 911.9 MiB)
21/02/17 01:04:30 INFO BlockManagerInfo: Removed broadcast_47_piece0 on localhost:39871 in memory (size: 2.4 KiB, free: 911.9 MiB)
21/02/17 01:04:30 INFO BlockManagerInfo: Removed broadcast_51_piece0 on localhost:39871 in memory (size: 2.5 KiB, free: 911.9 MiB)
21/02/17 01:04:30 INFO BlockManagerInfo: Removed broadcast_60_piece0 on localhost:39871 in memory (size: 2.5 KiB, free: 911.9 MiB)
21/02/17 01:04:30 INFO BlockManagerInfo: Removed broadcast_56_piece0 on localhost:39871 in memory (size: 2.5 KiB, free: 911.9 MiB)
21/02/17 01:04:30 INFO Executor: Finished task 0.0 in stage 53.0 (TID 55). 1769 bytes result sent to driver
21/02/17 01:04:30 INFO TaskSetManager: Finished task 0.0 in stage 53.0 (TID 55) in 15 ms on localhost (executor driver) (1/1)
21/02/17 01:04:30 INFO TaskSchedulerImpl: Removed TaskSet 53.0, whose tasks have all completed, from pool 
21/02/17 01:04:30 INFO BlockManagerInfo: Removed broadcast_61_piece0 on localhost:39871 in memory (size: 27.2 KiB, free: 911.9 MiB)
21/02/17 01:04:30 INFO DAGScheduler: ResultStage 53 (parquet at RFormula.scala:612) finished in 0.032 s
21/02/17 01:04:30 INFO DAGScheduler: Job 41 is finished. Cancelling potential speculative or zombie tasks for this job
21/02/17 01:04:30 INFO TaskSchedulerImpl: Killing all running tasks in stage 53: Stage finished
21/02/17 01:04:30 INFO DAGScheduler: Job 41 finished: parquet at RFormula.scala:612, took 0.033035 s
21/02/17 01:04:30 INFO BlockManagerInfo: Removed broadcast_59_piece0 on localhost:39871 in memory (size: 27.2 KiB, free: 911.9 MiB)
21/02/17 01:04:30 INFO BlockManagerInfo: Removed broadcast_49_piece0 on localhost:39871 in memory (size: 2.5 KiB, free: 912.0 MiB)
21/02/17 01:04:30 INFO BlockManagerInfo: Removed broadcast_52_piece0 on localhost:39871 in memory (size: 30.8 KiB, free: 912.0 MiB)
21/02/17 01:04:30 INFO BlockManagerInfo: Removed broadcast_58_piece0 on localhost:39871 in memory (size: 2.5 KiB, free: 912.0 MiB)
21/02/17 01:04:30 INFO BlockManagerInfo: Removed broadcast_64_piece0 on localhost:39871 in memory (size: 2.5 KiB, free: 912.0 MiB)
21/02/17 01:04:30 INFO BlockManager: Removing RDD 105
21/02/17 01:04:30 INFO BlockManagerInfo: Removed broadcast_43_piece0 on localhost:39871 in memory (size: 8.0 KiB, free: 912.0 MiB)
21/02/17 01:04:30 INFO BlockManagerInfo: Removed broadcast_55_piece0 on localhost:39871 in memory (size: 27.2 KiB, free: 912.0 MiB)
21/02/17 01:04:30 INFO BlockManagerInfo: Removed broadcast_44_piece0 on localhost:39871 in memory (size: 10.1 KiB, free: 912.0 MiB)
21/02/17 01:04:30 INFO BlockManagerInfo: Removed broadcast_48_piece0 on localhost:39871 in memory (size: 27.2 KiB, free: 912.1 MiB)
21/02/17 01:04:30 INFO BlockManagerInfo: Removed broadcast_54_piece0 on localhost:39871 in memory (size: 4.9 KiB, free: 912.1 MiB)
21/02/17 01:04:30 INFO BlockManagerInfo: Removed broadcast_57_piece0 on localhost:39871 in memory (size: 27.2 KiB, free: 912.1 MiB)
21/02/17 01:04:30 INFO BlockManagerInfo: Removed broadcast_33_piece0 on localhost:39871 in memory (size: 28.3 KiB, free: 912.1 MiB)
21/02/17 01:04:30 INFO BlockManagerInfo: Removed broadcast_46_piece0 on localhost:39871 in memory (size: 27.2 KiB, free: 912.1 MiB)
21/02/17 01:04:30 INFO BlockManagerInfo: Removed broadcast_63_piece0 on localhost:39871 in memory (size: 27.2 KiB, free: 912.2 MiB)
21/02/17 01:04:30 INFO BlockManagerInfo: Removed broadcast_45_piece0 on localhost:39871 in memory (size: 5.0 KiB, free: 912.2 MiB)
21/02/17 01:04:30 INFO BlockManagerInfo: Removed broadcast_62_piece0 on localhost:39871 in memory (size: 2.5 KiB, free: 912.2 MiB)
21/02/17 01:04:30 INFO BlockManagerInfo: Removed broadcast_53_piece0 on localhost:39871 in memory (size: 29.0 KiB, free: 912.2 MiB)
21/02/17 01:04:30 INFO FileSourceStrategy: Pruning directories with: 
21/02/17 01:04:30 INFO FileSourceStrategy: Pushed Filters: 
21/02/17 01:04:30 INFO FileSourceStrategy: Post-Scan Filters: 
21/02/17 01:04:30 INFO FileSourceStrategy: Output Data Schema: struct<vectorCol: string, prefixesToRewrite: map<string,string>>
21/02/17 01:04:30 INFO MemoryStore: Block broadcast_66 stored as values in memory (estimated size 318.7 KiB, free 911.6 MiB)
21/02/17 01:04:30 INFO MemoryStore: Block broadcast_66_piece0 stored as bytes in memory (estimated size 29.0 KiB, free 911.6 MiB)
21/02/17 01:04:30 INFO BlockManagerInfo: Added broadcast_66_piece0 in memory on localhost:39871 (size: 29.0 KiB, free: 912.2 MiB)
21/02/17 01:04:30 INFO SparkContext: Created broadcast 66 from head at RFormula.scala:612
21/02/17 01:04:30 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
21/02/17 01:04:30 INFO SparkContext: Starting job: head at RFormula.scala:612
21/02/17 01:04:30 INFO DAGScheduler: Got job 42 (head at RFormula.scala:612) with 1 output partitions
21/02/17 01:04:30 INFO DAGScheduler: Final stage: ResultStage 54 (head at RFormula.scala:612)
21/02/17 01:04:30 INFO DAGScheduler: Parents of final stage: List()
21/02/17 01:04:30 INFO DAGScheduler: Missing parents: List()
21/02/17 01:04:30 INFO DAGScheduler: Submitting ResultStage 54 (MapPartitionsRDD[169] at head at RFormula.scala:612), which has no missing parents
21/02/17 01:04:30 INFO MemoryStore: Block broadcast_67 stored as values in memory (estimated size 9.1 KiB, free 911.6 MiB)
21/02/17 01:04:30 INFO MemoryStore: Block broadcast_67_piece0 stored as bytes in memory (estimated size 4.8 KiB, free 911.6 MiB)
21/02/17 01:04:30 INFO BlockManagerInfo: Added broadcast_67_piece0 in memory on localhost:39871 (size: 4.8 KiB, free: 912.2 MiB)
21/02/17 01:04:30 INFO SparkContext: Created broadcast 67 from broadcast at DAGScheduler.scala:1200
21/02/17 01:04:30 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 54 (MapPartitionsRDD[169] at head at RFormula.scala:612) (first 15 tasks are for partitions Vector(0))
21/02/17 01:04:30 INFO TaskSchedulerImpl: Adding task set 54.0 with 1 tasks
21/02/17 01:04:30 INFO TaskSetManager: Starting task 0.0 in stage 54.0 (TID 56, localhost, executor driver, partition 0, PROCESS_LOCAL, 7922 bytes)
21/02/17 01:04:30 INFO Executor: Running task 0.0 in stage 54.0 (TID 56)
21/02/17 01:04:30 INFO FileScanRDD: Reading File path: file:///tmp/RtmpbZfqhf/file201a73deadac6/stages/0_r_formula__56fd7584_4f86_4137_b58a_3260f77a610d/pipelineModel/stages/1_vectorAttrRewriter_3ec7e7fc06d5/data/part-00000-d6b05f97-04e0-48b6-9bac-a18ea42e26ab-c000.snappy.parquet, range: 0-927, partition values: [empty row]
21/02/17 01:04:30 INFO Executor: Finished task 0.0 in stage 54.0 (TID 56). 1728 bytes result sent to driver
21/02/17 01:04:30 INFO TaskSetManager: Finished task 0.0 in stage 54.0 (TID 56) in 13 ms on localhost (executor driver) (1/1)
21/02/17 01:04:30 INFO TaskSchedulerImpl: Removed TaskSet 54.0, whose tasks have all completed, from pool 
21/02/17 01:04:30 INFO DAGScheduler: ResultStage 54 (head at RFormula.scala:612) finished in 0.016 s
21/02/17 01:04:30 INFO DAGScheduler: Job 42 is finished. Cancelling potential speculative or zombie tasks for this job
21/02/17 01:04:30 INFO TaskSchedulerImpl: Killing all running tasks in stage 54: Stage finished
21/02/17 01:04:30 INFO DAGScheduler: Job 42 finished: head at RFormula.scala:612, took 0.017617 s
21/02/17 01:04:30 INFO CodeGenerator: Code generated in 13.783953 ms
21/02/17 01:04:30 INFO MemoryStore: Block broadcast_68 stored as values in memory (estimated size 294.6 KiB, free 911.3 MiB)
21/02/17 01:04:30 INFO MemoryStore: Block broadcast_68_piece0 stored as bytes in memory (estimated size 27.2 KiB, free 911.3 MiB)
21/02/17 01:04:30 INFO BlockManagerInfo: Added broadcast_68_piece0 in memory on localhost:39871 (size: 27.2 KiB, free: 912.1 MiB)
21/02/17 01:04:30 INFO SparkContext: Created broadcast 68 from textFile at ReadWrite.scala:587
21/02/17 01:04:30 INFO FileInputFormat: Total input files to process : 1
21/02/17 01:04:30 INFO SparkContext: Starting job: first at ReadWrite.scala:587
21/02/17 01:04:30 INFO DAGScheduler: Got job 43 (first at ReadWrite.scala:587) with 1 output partitions
21/02/17 01:04:30 INFO DAGScheduler: Final stage: ResultStage 55 (first at ReadWrite.scala:587)
21/02/17 01:04:30 INFO DAGScheduler: Parents of final stage: List()
21/02/17 01:04:30 INFO DAGScheduler: Missing parents: List()
21/02/17 01:04:30 INFO DAGScheduler: Submitting ResultStage 55 (/tmp/RtmpbZfqhf/file201a73deadac6/stages/0_r_formula__56fd7584_4f86_4137_b58a_3260f77a610d/pipelineModel/stages/2_columnPruner_45df637c9a01/metadata MapPartitionsRDD[171] at textFile at ReadWrite.scala:587), which has no missing parents
21/02/17 01:04:30 INFO MemoryStore: Block broadcast_69 stored as values in memory (estimated size 4.2 KiB, free 911.3 MiB)
21/02/17 01:04:30 INFO MemoryStore: Block broadcast_69_piece0 stored as bytes in memory (estimated size 2.5 KiB, free 911.3 MiB)
21/02/17 01:04:30 INFO BlockManagerInfo: Added broadcast_69_piece0 in memory on localhost:39871 (size: 2.5 KiB, free: 912.1 MiB)
21/02/17 01:04:30 INFO SparkContext: Created broadcast 69 from broadcast at DAGScheduler.scala:1200
21/02/17 01:04:30 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 55 (/tmp/RtmpbZfqhf/file201a73deadac6/stages/0_r_formula__56fd7584_4f86_4137_b58a_3260f77a610d/pipelineModel/stages/2_columnPruner_45df637c9a01/metadata MapPartitionsRDD[171] at textFile at ReadWrite.scala:587) (first 15 tasks are for partitions Vector(0))
21/02/17 01:04:30 INFO TaskSchedulerImpl: Adding task set 55.0 with 1 tasks
21/02/17 01:04:30 INFO TaskSetManager: Starting task 0.0 in stage 55.0 (TID 57, localhost, executor driver, partition 0, PROCESS_LOCAL, 7506 bytes)
21/02/17 01:04:30 INFO Executor: Running task 0.0 in stage 55.0 (TID 57)
21/02/17 01:04:30 INFO HadoopRDD: Input split: file:/tmp/RtmpbZfqhf/file201a73deadac6/stages/0_r_formula__56fd7584_4f86_4137_b58a_3260f77a610d/pipelineModel/stages/2_columnPruner_45df637c9a01/metadata/part-00000:0+171
21/02/17 01:04:30 INFO Executor: Finished task 0.0 in stage 55.0 (TID 57). 1096 bytes result sent to driver
21/02/17 01:04:30 INFO TaskSetManager: Finished task 0.0 in stage 55.0 (TID 57) in 3 ms on localhost (executor driver) (1/1)
21/02/17 01:04:30 INFO TaskSchedulerImpl: Removed TaskSet 55.0, whose tasks have all completed, from pool 
21/02/17 01:04:30 INFO DAGScheduler: ResultStage 55 (first at ReadWrite.scala:587) finished in 0.006 s
21/02/17 01:04:30 INFO DAGScheduler: Job 43 is finished. Cancelling potential speculative or zombie tasks for this job
21/02/17 01:04:30 INFO TaskSchedulerImpl: Killing all running tasks in stage 55: Stage finished
21/02/17 01:04:30 INFO DAGScheduler: Job 43 finished: first at ReadWrite.scala:587, took 0.008557 s
21/02/17 01:04:30 INFO MemoryStore: Block broadcast_70 stored as values in memory (estimated size 294.6 KiB, free 911.0 MiB)
21/02/17 01:04:30 INFO MemoryStore: Block broadcast_70_piece0 stored as bytes in memory (estimated size 27.2 KiB, free 911.0 MiB)
21/02/17 01:04:30 INFO BlockManagerInfo: Added broadcast_70_piece0 in memory on localhost:39871 (size: 27.2 KiB, free: 912.1 MiB)
21/02/17 01:04:30 INFO SparkContext: Created broadcast 70 from textFile at ReadWrite.scala:587
21/02/17 01:04:30 INFO FileInputFormat: Total input files to process : 1
21/02/17 01:04:30 INFO SparkContext: Starting job: first at ReadWrite.scala:587
21/02/17 01:04:30 INFO DAGScheduler: Got job 44 (first at ReadWrite.scala:587) with 1 output partitions
21/02/17 01:04:30 INFO DAGScheduler: Final stage: ResultStage 56 (first at ReadWrite.scala:587)
21/02/17 01:04:30 INFO DAGScheduler: Parents of final stage: List()
21/02/17 01:04:30 INFO DAGScheduler: Missing parents: List()
21/02/17 01:04:30 INFO DAGScheduler: Submitting ResultStage 56 (/tmp/RtmpbZfqhf/file201a73deadac6/stages/0_r_formula__56fd7584_4f86_4137_b58a_3260f77a610d/pipelineModel/stages/2_columnPruner_45df637c9a01/metadata MapPartitionsRDD[173] at textFile at ReadWrite.scala:587), which has no missing parents
21/02/17 01:04:30 INFO MemoryStore: Block broadcast_71 stored as values in memory (estimated size 4.2 KiB, free 911.0 MiB)
21/02/17 01:04:30 INFO MemoryStore: Block broadcast_71_piece0 stored as bytes in memory (estimated size 2.5 KiB, free 911.0 MiB)
21/02/17 01:04:30 INFO BlockManagerInfo: Added broadcast_71_piece0 in memory on localhost:39871 (size: 2.5 KiB, free: 912.1 MiB)
21/02/17 01:04:30 INFO SparkContext: Created broadcast 71 from broadcast at DAGScheduler.scala:1200
21/02/17 01:04:30 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 56 (/tmp/RtmpbZfqhf/file201a73deadac6/stages/0_r_formula__56fd7584_4f86_4137_b58a_3260f77a610d/pipelineModel/stages/2_columnPruner_45df637c9a01/metadata MapPartitionsRDD[173] at textFile at ReadWrite.scala:587) (first 15 tasks are for partitions Vector(0))
21/02/17 01:04:30 INFO TaskSchedulerImpl: Adding task set 56.0 with 1 tasks
21/02/17 01:04:30 INFO TaskSetManager: Starting task 0.0 in stage 56.0 (TID 58, localhost, executor driver, partition 0, PROCESS_LOCAL, 7506 bytes)
21/02/17 01:04:30 INFO Executor: Running task 0.0 in stage 56.0 (TID 58)
21/02/17 01:04:30 INFO HadoopRDD: Input split: file:/tmp/RtmpbZfqhf/file201a73deadac6/stages/0_r_formula__56fd7584_4f86_4137_b58a_3260f77a610d/pipelineModel/stages/2_columnPruner_45df637c9a01/metadata/part-00000:0+171
21/02/17 01:04:30 INFO Executor: Finished task 0.0 in stage 56.0 (TID 58). 1053 bytes result sent to driver
21/02/17 01:04:30 INFO TaskSetManager: Finished task 0.0 in stage 56.0 (TID 58) in 4 ms on localhost (executor driver) (1/1)
21/02/17 01:04:30 INFO TaskSchedulerImpl: Removed TaskSet 56.0, whose tasks have all completed, from pool 
21/02/17 01:04:30 INFO DAGScheduler: ResultStage 56 (first at ReadWrite.scala:587) finished in 0.007 s
21/02/17 01:04:30 INFO DAGScheduler: Job 44 is finished. Cancelling potential speculative or zombie tasks for this job
21/02/17 01:04:30 INFO TaskSchedulerImpl: Killing all running tasks in stage 56: Stage finished
21/02/17 01:04:30 INFO DAGScheduler: Job 44 finished: first at ReadWrite.scala:587, took 0.008889 s
21/02/17 01:04:30 INFO InMemoryFileIndex: It took 0 ms to list leaf files for 1 paths.
21/02/17 01:04:30 INFO SparkContext: Starting job: parquet at RFormula.scala:521
21/02/17 01:04:30 INFO DAGScheduler: Got job 45 (parquet at RFormula.scala:521) with 1 output partitions
21/02/17 01:04:30 INFO DAGScheduler: Final stage: ResultStage 57 (parquet at RFormula.scala:521)
21/02/17 01:04:30 INFO DAGScheduler: Parents of final stage: List()
21/02/17 01:04:30 INFO DAGScheduler: Missing parents: List()
21/02/17 01:04:30 INFO DAGScheduler: Submitting ResultStage 57 (MapPartitionsRDD[175] at parquet at RFormula.scala:521), which has no missing parents
21/02/17 01:04:30 INFO MemoryStore: Block broadcast_72 stored as values in memory (estimated size 86.6 KiB, free 910.9 MiB)
21/02/17 01:04:30 INFO MemoryStore: Block broadcast_72_piece0 stored as bytes in memory (estimated size 30.8 KiB, free 910.8 MiB)
21/02/17 01:04:30 INFO BlockManagerInfo: Added broadcast_72_piece0 in memory on localhost:39871 (size: 30.8 KiB, free: 912.1 MiB)
21/02/17 01:04:30 INFO SparkContext: Created broadcast 72 from broadcast at DAGScheduler.scala:1200
21/02/17 01:04:30 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 57 (MapPartitionsRDD[175] at parquet at RFormula.scala:521) (first 15 tasks are for partitions Vector(0))
21/02/17 01:04:30 INFO TaskSchedulerImpl: Adding task set 57.0 with 1 tasks
21/02/17 01:04:30 INFO TaskSetManager: Starting task 0.0 in stage 57.0 (TID 59, localhost, executor driver, partition 0, PROCESS_LOCAL, 7665 bytes)
21/02/17 01:04:30 INFO Executor: Running task 0.0 in stage 57.0 (TID 59)
21/02/17 01:04:30 INFO Executor: Finished task 0.0 in stage 57.0 (TID 59). 1705 bytes result sent to driver
21/02/17 01:04:30 INFO TaskSetManager: Finished task 0.0 in stage 57.0 (TID 59) in 7 ms on localhost (executor driver) (1/1)
21/02/17 01:04:30 INFO TaskSchedulerImpl: Removed TaskSet 57.0, whose tasks have all completed, from pool 
21/02/17 01:04:30 INFO DAGScheduler: ResultStage 57 (parquet at RFormula.scala:521) finished in 0.015 s
21/02/17 01:04:30 INFO DAGScheduler: Job 45 is finished. Cancelling potential speculative or zombie tasks for this job
21/02/17 01:04:30 INFO TaskSchedulerImpl: Killing all running tasks in stage 57: Stage finished
21/02/17 01:04:30 INFO DAGScheduler: Job 45 finished: parquet at RFormula.scala:521, took 0.016605 s
21/02/17 01:04:30 INFO FileSourceStrategy: Pruning directories with: 
21/02/17 01:04:30 INFO FileSourceStrategy: Pushed Filters: 
21/02/17 01:04:30 INFO FileSourceStrategy: Post-Scan Filters: 
21/02/17 01:04:30 INFO FileSourceStrategy: Output Data Schema: struct<columnsToPrune: array<string>>
21/02/17 01:04:30 INFO MemoryStore: Block broadcast_73 stored as values in memory (estimated size 318.3 KiB, free 910.5 MiB)
21/02/17 01:04:30 INFO MemoryStore: Block broadcast_73_piece0 stored as bytes in memory (estimated size 29.0 KiB, free 910.5 MiB)
21/02/17 01:04:30 INFO BlockManagerInfo: Added broadcast_73_piece0 in memory on localhost:39871 (size: 29.0 KiB, free: 912.1 MiB)
21/02/17 01:04:30 INFO SparkContext: Created broadcast 73 from head at RFormula.scala:521
21/02/17 01:04:30 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
21/02/17 01:04:30 INFO SparkContext: Starting job: head at RFormula.scala:521
21/02/17 01:04:30 INFO DAGScheduler: Got job 46 (head at RFormula.scala:521) with 1 output partitions
21/02/17 01:04:30 INFO DAGScheduler: Final stage: ResultStage 58 (head at RFormula.scala:521)
21/02/17 01:04:30 INFO DAGScheduler: Parents of final stage: List()
21/02/17 01:04:30 INFO DAGScheduler: Missing parents: List()
21/02/17 01:04:30 INFO DAGScheduler: Submitting ResultStage 58 (MapPartitionsRDD[178] at head at RFormula.scala:521), which has no missing parents
21/02/17 01:04:30 INFO MemoryStore: Block broadcast_74 stored as values in memory (estimated size 8.9 KiB, free 910.5 MiB)
21/02/17 01:04:30 INFO MemoryStore: Block broadcast_74_piece0 stored as bytes in memory (estimated size 4.8 KiB, free 910.5 MiB)
21/02/17 01:04:30 INFO BlockManagerInfo: Added broadcast_74_piece0 in memory on localhost:39871 (size: 4.8 KiB, free: 912.0 MiB)
21/02/17 01:04:30 INFO SparkContext: Created broadcast 74 from broadcast at DAGScheduler.scala:1200
21/02/17 01:04:30 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 58 (MapPartitionsRDD[178] at head at RFormula.scala:521) (first 15 tasks are for partitions Vector(0))
21/02/17 01:04:30 INFO TaskSchedulerImpl: Adding task set 58.0 with 1 tasks
21/02/17 01:04:30 INFO TaskSetManager: Starting task 0.0 in stage 58.0 (TID 60, localhost, executor driver, partition 0, PROCESS_LOCAL, 7916 bytes)
21/02/17 01:04:30 INFO Executor: Running task 0.0 in stage 58.0 (TID 60)
21/02/17 01:04:30 INFO FileScanRDD: Reading File path: file:///tmp/RtmpbZfqhf/file201a73deadac6/stages/0_r_formula__56fd7584_4f86_4137_b58a_3260f77a610d/pipelineModel/stages/2_columnPruner_45df637c9a01/data/part-00000-6682e436-1a82-4e87-bbdf-63566353f210-c000.snappy.parquet, range: 0-510, partition values: [empty row]
21/02/17 01:04:30 INFO Executor: Finished task 0.0 in stage 58.0 (TID 60). 1709 bytes result sent to driver
21/02/17 01:04:30 INFO TaskSetManager: Finished task 0.0 in stage 58.0 (TID 60) in 11 ms on localhost (executor driver) (1/1)
21/02/17 01:04:30 INFO TaskSchedulerImpl: Removed TaskSet 58.0, whose tasks have all completed, from pool 
21/02/17 01:04:30 INFO DAGScheduler: ResultStage 58 (head at RFormula.scala:521) finished in 0.015 s
21/02/17 01:04:30 INFO DAGScheduler: Job 46 is finished. Cancelling potential speculative or zombie tasks for this job
21/02/17 01:04:30 INFO TaskSchedulerImpl: Killing all running tasks in stage 58: Stage finished
21/02/17 01:04:30 INFO DAGScheduler: Job 46 finished: head at RFormula.scala:521, took 0.016019 s
21/02/17 01:04:30 INFO CodeGenerator: Code generated in 9.000453 ms
21/02/17 01:04:30 INFO Instrumentation: [cbee8526] training finished
21/02/17 01:04:30 INFO Instrumentation: [68c8764a] training finished
21/02/17 01:04:30 INFO MemoryStore: Block broadcast_75 stored as values in memory (estimated size 294.6 KiB, free 910.2 MiB)
21/02/17 01:04:30 INFO MemoryStore: Block broadcast_75_piece0 stored as bytes in memory (estimated size 27.2 KiB, free 910.2 MiB)
21/02/17 01:04:30 INFO BlockManagerInfo: Added broadcast_75_piece0 in memory on localhost:39871 (size: 27.2 KiB, free: 912.0 MiB)
21/02/17 01:04:30 INFO SparkContext: Created broadcast 75 from textFile at ReadWrite.scala:587
21/02/17 01:04:30 INFO FileInputFormat: Total input files to process : 1
21/02/17 01:04:30 INFO SparkContext: Starting job: first at ReadWrite.scala:587
21/02/17 01:04:30 INFO DAGScheduler: Got job 47 (first at ReadWrite.scala:587) with 1 output partitions
21/02/17 01:04:30 INFO DAGScheduler: Final stage: ResultStage 59 (first at ReadWrite.scala:587)
21/02/17 01:04:30 INFO DAGScheduler: Parents of final stage: List()
21/02/17 01:04:30 INFO DAGScheduler: Missing parents: List()
21/02/17 01:04:30 INFO DAGScheduler: Submitting ResultStage 59 (/tmp/RtmpbZfqhf/file201a73deadac6/stages/1_xgboost_regressor__80e12a7b_8c17_4325_80c6_fa3a9511ae8c/metadata MapPartitionsRDD[180] at textFile at ReadWrite.scala:587), which has no missing parents
21/02/17 01:04:30 INFO MemoryStore: Block broadcast_76 stored as values in memory (estimated size 4.2 KiB, free 910.2 MiB)
21/02/17 01:04:30 INFO MemoryStore: Block broadcast_76_piece0 stored as bytes in memory (estimated size 2.5 KiB, free 910.2 MiB)
21/02/17 01:04:30 INFO BlockManagerInfo: Added broadcast_76_piece0 in memory on localhost:39871 (size: 2.5 KiB, free: 912.0 MiB)
21/02/17 01:04:30 INFO SparkContext: Created broadcast 76 from broadcast at DAGScheduler.scala:1200
21/02/17 01:04:30 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 59 (/tmp/RtmpbZfqhf/file201a73deadac6/stages/1_xgboost_regressor__80e12a7b_8c17_4325_80c6_fa3a9511ae8c/metadata MapPartitionsRDD[180] at textFile at ReadWrite.scala:587) (first 15 tasks are for partitions Vector(0))
21/02/17 01:04:30 INFO TaskSchedulerImpl: Adding task set 59.0 with 1 tasks
21/02/17 01:04:30 INFO TaskSetManager: Starting task 0.0 in stage 59.0 (TID 61, localhost, executor driver, partition 0, PROCESS_LOCAL, 7464 bytes)
21/02/17 01:04:30 INFO Executor: Running task 0.0 in stage 59.0 (TID 61)
21/02/17 01:04:30 INFO HadoopRDD: Input split: file:/tmp/RtmpbZfqhf/file201a73deadac6/stages/1_xgboost_regressor__80e12a7b_8c17_4325_80c6_fa3a9511ae8c/metadata/part-00000:0+1284
21/02/17 01:04:30 INFO Executor: Finished task 0.0 in stage 59.0 (TID 61). 2217 bytes result sent to driver
21/02/17 01:04:30 INFO TaskSetManager: Finished task 0.0 in stage 59.0 (TID 61) in 4 ms on localhost (executor driver) (1/1)
21/02/17 01:04:30 INFO TaskSchedulerImpl: Removed TaskSet 59.0, whose tasks have all completed, from pool 
21/02/17 01:04:30 INFO DAGScheduler: ResultStage 59 (first at ReadWrite.scala:587) finished in 0.007 s
21/02/17 01:04:30 INFO DAGScheduler: Job 47 is finished. Cancelling potential speculative or zombie tasks for this job
21/02/17 01:04:30 INFO TaskSchedulerImpl: Killing all running tasks in stage 59: Stage finished
21/02/17 01:04:30 INFO DAGScheduler: Job 47 finished: first at ReadWrite.scala:587, took 0.008669 s
21/02/17 01:04:30 INFO MemoryStore: Block broadcast_77 stored as values in memory (estimated size 294.6 KiB, free 909.9 MiB)
21/02/17 01:04:30 INFO MemoryStore: Block broadcast_77_piece0 stored as bytes in memory (estimated size 27.2 KiB, free 909.9 MiB)
21/02/17 01:04:30 INFO BlockManagerInfo: Added broadcast_77_piece0 in memory on localhost:39871 (size: 27.2 KiB, free: 912.0 MiB)
21/02/17 01:04:30 INFO SparkContext: Created broadcast 77 from textFile at DefaultXGBoostParamsReader.scala:82
21/02/17 01:04:30 INFO FileInputFormat: Total input files to process : 1
21/02/17 01:04:30 INFO SparkContext: Starting job: first at DefaultXGBoostParamsReader.scala:82
21/02/17 01:04:30 INFO DAGScheduler: Got job 48 (first at DefaultXGBoostParamsReader.scala:82) with 1 output partitions
21/02/17 01:04:30 INFO DAGScheduler: Final stage: ResultStage 60 (first at DefaultXGBoostParamsReader.scala:82)
21/02/17 01:04:30 INFO DAGScheduler: Parents of final stage: List()
21/02/17 01:04:30 INFO DAGScheduler: Missing parents: List()
21/02/17 01:04:30 INFO DAGScheduler: Submitting ResultStage 60 (/tmp/RtmpbZfqhf/file201a73deadac6/stages/1_xgboost_regressor__80e12a7b_8c17_4325_80c6_fa3a9511ae8c/metadata MapPartitionsRDD[182] at textFile at DefaultXGBoostParamsReader.scala:82), which has no missing parents
21/02/17 01:04:30 INFO MemoryStore: Block broadcast_78 stored as values in memory (estimated size 4.2 KiB, free 909.8 MiB)
21/02/17 01:04:30 INFO MemoryStore: Block broadcast_78_piece0 stored as bytes in memory (estimated size 2.5 KiB, free 909.8 MiB)
21/02/17 01:04:30 INFO BlockManagerInfo: Added broadcast_78_piece0 in memory on localhost:39871 (size: 2.5 KiB, free: 912.0 MiB)
21/02/17 01:04:30 INFO SparkContext: Created broadcast 78 from broadcast at DAGScheduler.scala:1200
21/02/17 01:04:30 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 60 (/tmp/RtmpbZfqhf/file201a73deadac6/stages/1_xgboost_regressor__80e12a7b_8c17_4325_80c6_fa3a9511ae8c/metadata MapPartitionsRDD[182] at textFile at DefaultXGBoostParamsReader.scala:82) (first 15 tasks are for partitions Vector(0))
21/02/17 01:04:30 INFO TaskSchedulerImpl: Adding task set 60.0 with 1 tasks
21/02/17 01:04:30 INFO TaskSetManager: Starting task 0.0 in stage 60.0 (TID 62, localhost, executor driver, partition 0, PROCESS_LOCAL, 7464 bytes)
21/02/17 01:04:30 INFO Executor: Running task 0.0 in stage 60.0 (TID 62)
21/02/17 01:04:30 INFO HadoopRDD: Input split: file:/tmp/RtmpbZfqhf/file201a73deadac6/stages/1_xgboost_regressor__80e12a7b_8c17_4325_80c6_fa3a9511ae8c/metadata/part-00000:0+1284
21/02/17 01:04:30 INFO Executor: Finished task 0.0 in stage 60.0 (TID 62). 2174 bytes result sent to driver
21/02/17 01:04:30 INFO TaskSetManager: Finished task 0.0 in stage 60.0 (TID 62) in 3 ms on localhost (executor driver) (1/1)
21/02/17 01:04:30 INFO TaskSchedulerImpl: Removed TaskSet 60.0, whose tasks have all completed, from pool 
21/02/17 01:04:30 INFO DAGScheduler: ResultStage 60 (first at DefaultXGBoostParamsReader.scala:82) finished in 0.007 s
21/02/17 01:04:30 INFO DAGScheduler: Job 48 is finished. Cancelling potential speculative or zombie tasks for this job
21/02/17 01:04:30 INFO TaskSchedulerImpl: Killing all running tasks in stage 60: Stage finished
21/02/17 01:04:30 INFO DAGScheduler: Job 48 finished: first at DefaultXGBoostParamsReader.scala:82, took 0.008314 s
21/02/17 01:04:30 INFO Instrumentation: [5a40b1d7] training finished
21/02/17 01:04:30 INFO Instrumentation: [286bfe81] training finished
21/02/17 01:04:30 INFO Instrumentation: [f58da26d] training finished
21/02/17 01:04:30 INFO MemoryStore: Block broadcast_79 stored as values in memory (estimated size 64.0 B, free 909.8 MiB)
21/02/17 01:04:30 INFO MemoryStore: Block broadcast_79_piece0 stored as bytes in memory (estimated size 515.0 B, free 909.8 MiB)
21/02/17 01:04:30 INFO BlockManagerInfo: Added broadcast_79_piece0 in memory on localhost:39871 (size: 515.0 B, free: 912.0 MiB)
21/02/17 01:04:30 INFO SparkContext: Created broadcast 79 from broadcast at XGBoostRegressor.scala:279
21/02/17 01:04:30 INFO Instrumentation: [c04bc658] training finished
21/02/17 01:04:31 INFO SparkContext: Starting job: collect at utils.scala:137
21/02/17 01:04:31 INFO DAGScheduler: Got job 49 (collect at utils.scala:137) with 1 output partitions
21/02/17 01:04:31 INFO DAGScheduler: Final stage: ResultStage 61 (collect at utils.scala:137)
21/02/17 01:04:31 INFO DAGScheduler: Parents of final stage: List()
21/02/17 01:04:31 INFO DAGScheduler: Missing parents: List()
21/02/17 01:04:31 INFO DAGScheduler: Submitting ResultStage 61 (MapPartitionsRDD[192] at collect at utils.scala:137), which has no missing parents
21/02/17 01:04:31 INFO MemoryStore: Block broadcast_80 stored as values in memory (estimated size 7.3 KiB, free 909.8 MiB)
21/02/17 01:04:31 INFO MemoryStore: Block broadcast_80_piece0 stored as bytes in memory (estimated size 3.7 KiB, free 909.8 MiB)
21/02/17 01:04:31 INFO BlockManagerInfo: Added broadcast_80_piece0 in memory on localhost:39871 (size: 3.7 KiB, free: 912.0 MiB)
21/02/17 01:04:31 INFO SparkContext: Created broadcast 80 from broadcast at DAGScheduler.scala:1200
21/02/17 01:04:31 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 61 (MapPartitionsRDD[192] at collect at utils.scala:137) (first 15 tasks are for partitions Vector(0))
21/02/17 01:04:31 INFO TaskSchedulerImpl: Adding task set 61.0 with 1 tasks
21/02/17 01:04:31 INFO TaskSetManager: Starting task 0.0 in stage 61.0 (TID 63, localhost, executor driver, partition 0, PROCESS_LOCAL, 7561 bytes)
21/02/17 01:04:31 INFO Executor: Running task 0.0 in stage 61.0 (TID 63)
21/02/17 01:04:31 INFO Executor: Finished task 0.0 in stage 61.0 (TID 63). 1354 bytes result sent to driver
21/02/17 01:04:31 INFO TaskSetManager: Finished task 0.0 in stage 61.0 (TID 63) in 3 ms on localhost (executor driver) (1/1)
21/02/17 01:04:31 INFO TaskSchedulerImpl: Removed TaskSet 61.0, whose tasks have all completed, from pool 
21/02/17 01:04:31 INFO DAGScheduler: ResultStage 61 (collect at utils.scala:137) finished in 0.006 s
21/02/17 01:04:31 INFO DAGScheduler: Job 49 is finished. Cancelling potential speculative or zombie tasks for this job
21/02/17 01:04:31 INFO TaskSchedulerImpl: Killing all running tasks in stage 61: Stage finished
21/02/17 01:04:31 INFO DAGScheduler: Job 49 finished: collect at utils.scala:137, took 0.006991 s
21/02/17 01:04:31 INFO SparkContext: Starting job: count at utils.scala:135
21/02/17 01:04:31 INFO DAGScheduler: Registering RDD 194 (count at utils.scala:135) as input to shuffle 13
21/02/17 01:04:31 INFO DAGScheduler: Got job 50 (count at utils.scala:135) with 1 output partitions
21/02/17 01:04:31 INFO DAGScheduler: Final stage: ResultStage 63 (count at utils.scala:135)
21/02/17 01:04:31 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 62)
21/02/17 01:04:31 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 62)
21/02/17 01:04:31 INFO DAGScheduler: Submitting ShuffleMapStage 62 (MapPartitionsRDD[194] at count at utils.scala:135), which has no missing parents
21/02/17 01:04:31 INFO MemoryStore: Block broadcast_81 stored as values in memory (estimated size 10.0 KiB, free 909.8 MiB)
21/02/17 01:04:31 INFO MemoryStore: Block broadcast_81_piece0 stored as bytes in memory (estimated size 5.2 KiB, free 909.8 MiB)
21/02/17 01:04:31 INFO BlockManagerInfo: Added broadcast_81_piece0 in memory on localhost:39871 (size: 5.2 KiB, free: 912.0 MiB)
21/02/17 01:04:31 INFO SparkContext: Created broadcast 81 from broadcast at DAGScheduler.scala:1200
21/02/17 01:04:31 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 62 (MapPartitionsRDD[194] at count at utils.scala:135) (first 15 tasks are for partitions Vector(0))
21/02/17 01:04:31 INFO TaskSchedulerImpl: Adding task set 62.0 with 1 tasks
21/02/17 01:04:31 INFO TaskSetManager: Starting task 0.0 in stage 62.0 (TID 64, localhost, executor driver, partition 0, PROCESS_LOCAL, 7550 bytes)
21/02/17 01:04:31 INFO Executor: Running task 0.0 in stage 62.0 (TID 64)
21/02/17 01:04:31 INFO Executor: Finished task 0.0 in stage 62.0 (TID 64). 1833 bytes result sent to driver
21/02/17 01:04:31 INFO TaskSetManager: Finished task 0.0 in stage 62.0 (TID 64) in 5 ms on localhost (executor driver) (1/1)
21/02/17 01:04:31 INFO TaskSchedulerImpl: Removed TaskSet 62.0, whose tasks have all completed, from pool 
21/02/17 01:04:31 INFO DAGScheduler: ShuffleMapStage 62 (count at utils.scala:135) finished in 0.009 s
21/02/17 01:04:31 INFO DAGScheduler: looking for newly runnable stages
21/02/17 01:04:31 INFO DAGScheduler: running: Set()
21/02/17 01:04:31 INFO DAGScheduler: waiting: Set(ResultStage 63)
21/02/17 01:04:31 INFO DAGScheduler: failed: Set()
21/02/17 01:04:31 INFO DAGScheduler: Submitting ResultStage 63 (MapPartitionsRDD[197] at count at utils.scala:135), which has no missing parents
21/02/17 01:04:31 INFO MemoryStore: Block broadcast_82 stored as values in memory (estimated size 10.1 KiB, free 909.8 MiB)
21/02/17 01:04:31 INFO MemoryStore: Block broadcast_82_piece0 stored as bytes in memory (estimated size 5.0 KiB, free 909.8 MiB)
21/02/17 01:04:31 INFO BlockManagerInfo: Added broadcast_82_piece0 in memory on localhost:39871 (size: 5.0 KiB, free: 912.0 MiB)
21/02/17 01:04:31 INFO SparkContext: Created broadcast 82 from broadcast at DAGScheduler.scala:1200
21/02/17 01:04:31 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 63 (MapPartitionsRDD[197] at count at utils.scala:135) (first 15 tasks are for partitions Vector(0))
21/02/17 01:04:31 INFO TaskSchedulerImpl: Adding task set 63.0 with 1 tasks
21/02/17 01:04:31 INFO TaskSetManager: Starting task 0.0 in stage 63.0 (TID 65, localhost, executor driver, partition 0, NODE_LOCAL, 7325 bytes)
21/02/17 01:04:31 INFO Executor: Running task 0.0 in stage 63.0 (TID 65)
21/02/17 01:04:31 INFO ShuffleBlockFetcherIterator: Getting 1 (60.0 B) non-empty blocks including 1 (60.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
21/02/17 01:04:31 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
21/02/17 01:04:31 INFO Executor: Finished task 0.0 in stage 63.0 (TID 65). 2648 bytes result sent to driver
21/02/17 01:04:31 INFO TaskSetManager: Finished task 0.0 in stage 63.0 (TID 65) in 3 ms on localhost (executor driver) (1/1)
21/02/17 01:04:31 INFO TaskSchedulerImpl: Removed TaskSet 63.0, whose tasks have all completed, from pool 
21/02/17 01:04:31 INFO DAGScheduler: ResultStage 63 (count at utils.scala:135) finished in 0.007 s
21/02/17 01:04:31 INFO DAGScheduler: Job 50 is finished. Cancelling potential speculative or zombie tasks for this job
21/02/17 01:04:31 INFO TaskSchedulerImpl: Killing all running tasks in stage 63: Stage finished
21/02/17 01:04:31 INFO DAGScheduler: Job 50 finished: count at utils.scala:135, took 0.017254 s
21/02/17 01:04:31 INFO BlockManagerInfo: Removed broadcast_78_piece0 on localhost:39871 in memory (size: 2.5 KiB, free: 912.0 MiB)
21/02/17 01:04:31 INFO BlockManagerInfo: Removed broadcast_74_piece0 on localhost:39871 in memory (size: 4.8 KiB, free: 912.0 MiB)
21/02/17 01:04:31 INFO BlockManagerInfo: Removed broadcast_80_piece0 on localhost:39871 in memory (size: 3.7 KiB, free: 912.0 MiB)
21/02/17 01:04:31 INFO BlockManagerInfo: Removed broadcast_70_piece0 on localhost:39871 in memory (size: 27.2 KiB, free: 912.0 MiB)
21/02/17 01:04:31 INFO BlockManagerInfo: Removed broadcast_81_piece0 on localhost:39871 in memory (size: 5.2 KiB, free: 912.0 MiB)
21/02/17 01:04:31 INFO BlockManagerInfo: Removed broadcast_82_piece0 on localhost:39871 in memory (size: 5.0 KiB, free: 912.0 MiB)
21/02/17 01:04:31 INFO BlockManagerInfo: Removed broadcast_69_piece0 on localhost:39871 in memory (size: 2.5 KiB, free: 912.0 MiB)
21/02/17 01:04:31 INFO BlockManagerInfo: Removed broadcast_77_piece0 on localhost:39871 in memory (size: 27.2 KiB, free: 912.1 MiB)
21/02/17 01:04:31 INFO SparkContext: Starting job: collect at utils.scala:137
21/02/17 01:04:31 INFO BlockManagerInfo: Removed broadcast_65_piece0 on localhost:39871 in memory (size: 30.8 KiB, free: 912.1 MiB)
21/02/17 01:04:31 INFO DAGScheduler: Got job 51 (collect at utils.scala:137) with 1 output partitions
21/02/17 01:04:31 INFO DAGScheduler: Final stage: ResultStage 64 (collect at utils.scala:137)
21/02/17 01:04:31 INFO DAGScheduler: Parents of final stage: List()
21/02/17 01:04:31 INFO BlockManagerInfo: Removed broadcast_71_piece0 on localhost:39871 in memory (size: 2.5 KiB, free: 912.1 MiB)
21/02/17 01:04:31 INFO DAGScheduler: Missing parents: List()
21/02/17 01:04:31 INFO DAGScheduler: Submitting ResultStage 64 (MapPartitionsRDD[199] at collect at utils.scala:137), which has no missing parents
21/02/17 01:04:31 INFO BlockManagerInfo: Removed broadcast_73_piece0 on localhost:39871 in memory (size: 29.0 KiB, free: 912.1 MiB)
21/02/17 01:04:31 INFO BlockManagerInfo: Removed broadcast_76_piece0 on localhost:39871 in memory (size: 2.5 KiB, free: 912.1 MiB)
21/02/17 01:04:31 INFO MemoryStore: Block broadcast_83 stored as values in memory (estimated size 71.2 KiB, free 910.9 MiB)
21/02/17 01:04:31 INFO BlockManagerInfo: Removed broadcast_75_piece0 on localhost:39871 in memory (size: 27.2 KiB, free: 912.1 MiB)
21/02/17 01:04:31 INFO MemoryStore: Block broadcast_83_piece0 stored as bytes in memory (estimated size 28.4 KiB, free 911.2 MiB)
21/02/17 01:04:31 INFO BlockManagerInfo: Added broadcast_83_piece0 in memory on localhost:39871 (size: 28.4 KiB, free: 912.1 MiB)
21/02/17 01:04:31 INFO BlockManagerInfo: Removed broadcast_72_piece0 on localhost:39871 in memory (size: 30.8 KiB, free: 912.1 MiB)
21/02/17 01:04:31 INFO SparkContext: Created broadcast 83 from broadcast at DAGScheduler.scala:1200
21/02/17 01:04:31 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 64 (MapPartitionsRDD[199] at collect at utils.scala:137) (first 15 tasks are for partitions Vector(0))
21/02/17 01:04:31 INFO TaskSchedulerImpl: Adding task set 64.0 with 1 tasks
21/02/17 01:04:31 INFO BlockManagerInfo: Removed broadcast_68_piece0 on localhost:39871 in memory (size: 27.2 KiB, free: 912.2 MiB)
21/02/17 01:04:31 INFO TaskSetManager: Starting task 0.0 in stage 64.0 (TID 66, localhost, executor driver, partition 0, PROCESS_LOCAL, 18492 bytes)
21/02/17 01:04:31 INFO Executor: Running task 0.0 in stage 64.0 (TID 66)
21/02/17 01:04:31 INFO BlockManagerInfo: Removed broadcast_66_piece0 on localhost:39871 in memory (size: 29.0 KiB, free: 912.2 MiB)
21/02/17 01:04:31 INFO BlockManagerInfo: Removed broadcast_67_piece0 on localhost:39871 in memory (size: 4.8 KiB, free: 912.2 MiB)
21/02/17 01:04:31 INFO BlockManager: Found block rdd_23_0 locally
21/02/17 01:04:31 INFO Executor: Finished task 0.0 in stage 64.0 (TID 66). 1912 bytes result sent to driver
21/02/17 01:04:31 INFO TaskSetManager: Finished task 0.0 in stage 64.0 (TID 66) in 30 ms on localhost (executor driver) (1/1)
21/02/17 01:04:31 INFO TaskSchedulerImpl: Removed TaskSet 64.0, whose tasks have all completed, from pool 
21/02/17 01:04:31 INFO DAGScheduler: ResultStage 64 (collect at utils.scala:137) finished in 0.035 s
21/02/17 01:04:31 INFO DAGScheduler: Job 51 is finished. Cancelling potential speculative or zombie tasks for this job
21/02/17 01:04:31 INFO TaskSchedulerImpl: Killing all running tasks in stage 64: Stage finished
21/02/17 01:04:31 INFO DAGScheduler: Job 51 finished: collect at utils.scala:137, took 0.037558 s
21/02/17 01:04:31 INFO SparkContext: Starting job: count at utils.scala:135
21/02/17 01:04:31 INFO DAGScheduler: Registering RDD 201 (count at utils.scala:135) as input to shuffle 14
21/02/17 01:04:31 INFO DAGScheduler: Got job 52 (count at utils.scala:135) with 1 output partitions
21/02/17 01:04:31 INFO DAGScheduler: Final stage: ResultStage 66 (count at utils.scala:135)
21/02/17 01:04:31 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 65)
21/02/17 01:04:31 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 65)
21/02/17 01:04:31 INFO DAGScheduler: Submitting ShuffleMapStage 65 (MapPartitionsRDD[201] at count at utils.scala:135), which has no missing parents
21/02/17 01:04:31 INFO MemoryStore: Block broadcast_84 stored as values in memory (estimated size 72.7 KiB, free 911.9 MiB)
21/02/17 01:04:31 INFO MemoryStore: Block broadcast_84_piece0 stored as bytes in memory (estimated size 29.1 KiB, free 911.9 MiB)
21/02/17 01:04:31 INFO BlockManagerInfo: Added broadcast_84_piece0 in memory on localhost:39871 (size: 29.1 KiB, free: 912.2 MiB)
21/02/17 01:04:31 INFO SparkContext: Created broadcast 84 from broadcast at DAGScheduler.scala:1200
21/02/17 01:04:31 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 65 (MapPartitionsRDD[201] at count at utils.scala:135) (first 15 tasks are for partitions Vector(0))
21/02/17 01:04:31 INFO TaskSchedulerImpl: Adding task set 65.0 with 1 tasks
21/02/17 01:04:31 INFO TaskSetManager: Starting task 0.0 in stage 65.0 (TID 67, localhost, executor driver, partition 0, PROCESS_LOCAL, 18481 bytes)
21/02/17 01:04:31 INFO Executor: Running task 0.0 in stage 65.0 (TID 67)
21/02/17 01:04:31 INFO BlockManager: Found block rdd_23_0 locally
21/02/17 01:04:31 INFO Executor: Finished task 0.0 in stage 65.0 (TID 67). 2253 bytes result sent to driver
21/02/17 01:04:31 INFO TaskSetManager: Finished task 0.0 in stage 65.0 (TID 67) in 22 ms on localhost (executor driver) (1/1)
21/02/17 01:04:31 INFO TaskSchedulerImpl: Removed TaskSet 65.0, whose tasks have all completed, from pool 
21/02/17 01:04:31 INFO DAGScheduler: ShuffleMapStage 65 (count at utils.scala:135) finished in 0.026 s
21/02/17 01:04:31 INFO DAGScheduler: looking for newly runnable stages
21/02/17 01:04:31 INFO DAGScheduler: running: Set()
21/02/17 01:04:31 INFO DAGScheduler: waiting: Set(ResultStage 66)
21/02/17 01:04:31 INFO DAGScheduler: failed: Set()
21/02/17 01:04:31 INFO DAGScheduler: Submitting ResultStage 66 (MapPartitionsRDD[204] at count at utils.scala:135), which has no missing parents
21/02/17 01:04:31 INFO MemoryStore: Block broadcast_85 stored as values in memory (estimated size 10.1 KiB, free 911.9 MiB)
21/02/17 01:04:31 INFO MemoryStore: Block broadcast_85_piece0 stored as bytes in memory (estimated size 5.0 KiB, free 911.9 MiB)
21/02/17 01:04:31 INFO BlockManagerInfo: Added broadcast_85_piece0 in memory on localhost:39871 (size: 5.0 KiB, free: 912.2 MiB)
21/02/17 01:04:31 INFO SparkContext: Created broadcast 85 from broadcast at DAGScheduler.scala:1200
21/02/17 01:04:31 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 66 (MapPartitionsRDD[204] at count at utils.scala:135) (first 15 tasks are for partitions Vector(0))
21/02/17 01:04:31 INFO TaskSchedulerImpl: Adding task set 66.0 with 1 tasks
21/02/17 01:04:31 INFO TaskSetManager: Starting task 0.0 in stage 66.0 (TID 68, localhost, executor driver, partition 0, NODE_LOCAL, 7325 bytes)
21/02/17 01:04:31 INFO Executor: Running task 0.0 in stage 66.0 (TID 68)
21/02/17 01:04:31 INFO ShuffleBlockFetcherIterator: Getting 1 (60.0 B) non-empty blocks including 1 (60.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
21/02/17 01:04:31 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
21/02/17 01:04:31 INFO Executor: Finished task 0.0 in stage 66.0 (TID 68). 2648 bytes result sent to driver
21/02/17 01:04:31 INFO TaskSetManager: Finished task 0.0 in stage 66.0 (TID 68) in 4 ms on localhost (executor driver) (1/1)
21/02/17 01:04:31 INFO TaskSchedulerImpl: Removed TaskSet 66.0, whose tasks have all completed, from pool 
21/02/17 01:04:31 INFO DAGScheduler: ResultStage 66 (count at utils.scala:135) finished in 0.007 s
21/02/17 01:04:31 INFO DAGScheduler: Job 52 is finished. Cancelling potential speculative or zombie tasks for this job
21/02/17 01:04:31 INFO TaskSchedulerImpl: Killing all running tasks in stage 66: Stage finished
21/02/17 01:04:31 INFO DAGScheduler: Job 52 finished: count at utils.scala:135, took 0.035651 s
21/02/17 01:04:33 INFO SparkContext: Invoking stop() from shutdown hook
21/02/17 01:04:33 INFO SparkUI: Stopped Spark web UI at http://localhost:4040
21/02/17 01:04:33 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!
21/02/17 01:04:33 INFO MemoryStore: MemoryStore cleared
21/02/17 01:04:33 INFO BlockManager: BlockManager stopped
21/02/17 01:04:33 INFO BlockManagerMaster: BlockManagerMaster stopped
21/02/17 01:04:33 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!
21/02/17 01:04:33 INFO SparkContext: Successfully stopped SparkContext
21/02/17 01:04:33 INFO ShutdownHookManager: Shutdown hook called
21/02/17 01:04:33 INFO ShutdownHookManager: Deleting directory /tmp/spark-1424d278-f166-4c98-8eb2-cf2f76cb210d
21/02/17 01:04:33 INFO ShutdownHookManager: Deleting directory /tmp/spark-ed2414e0-45f9-4b71-a3e9-c5ee891e1efe
21/02/17 01:11:48 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
21/02/17 01:11:48 INFO SecurityManager: Changing view acls to: yitaoli
21/02/17 01:11:48 INFO SecurityManager: Changing modify acls to: yitaoli
21/02/17 01:11:48 INFO SecurityManager: Changing view acls groups to: 
21/02/17 01:11:48 INFO SecurityManager: Changing modify acls groups to: 
21/02/17 01:11:48 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(yitaoli); groups with view permissions: Set(); users  with modify permissions: Set(yitaoli); groups with modify permissions: Set()
21/02/17 01:11:49 INFO HiveConf: Found configuration file file:/home/yitaoli/spark/spark-3.0.0-bin-hadoop3.2/conf/hive-site.xml
21/02/17 01:11:49 INFO SparkContext: Running Spark version 3.0.0
21/02/17 01:11:49 INFO ResourceUtils: ==============================================================
21/02/17 01:11:49 INFO ResourceUtils: Resources for spark.driver:

21/02/17 01:11:49 INFO ResourceUtils: ==============================================================
21/02/17 01:11:49 INFO SparkContext: Submitted application: sparklyr
21/02/17 01:11:49 INFO SecurityManager: Changing view acls to: yitaoli
21/02/17 01:11:49 INFO SecurityManager: Changing modify acls to: yitaoli
21/02/17 01:11:49 INFO SecurityManager: Changing view acls groups to: 
21/02/17 01:11:49 INFO SecurityManager: Changing modify acls groups to: 
21/02/17 01:11:49 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(yitaoli); groups with view permissions: Set(); users  with modify permissions: Set(yitaoli); groups with modify permissions: Set()
21/02/17 01:11:49 INFO Utils: Successfully started service 'sparkDriver' on port 43099.
21/02/17 01:11:49 INFO SparkEnv: Registering MapOutputTracker
21/02/17 01:11:49 INFO SparkEnv: Registering BlockManagerMaster
21/02/17 01:11:49 INFO BlockManagerMasterEndpoint: Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
21/02/17 01:11:49 INFO BlockManagerMasterEndpoint: BlockManagerMasterEndpoint up
21/02/17 01:11:49 INFO SparkEnv: Registering BlockManagerMasterHeartbeat
21/02/17 01:11:49 INFO DiskBlockManager: Created local directory at /tmp/blockmgr-0a2cda6f-adb8-4cb7-9b21-51d982dafea3
21/02/17 01:11:49 INFO MemoryStore: MemoryStore started with capacity 912.3 MiB
21/02/17 01:11:49 INFO SparkEnv: Registering OutputCommitCoordinator
21/02/17 01:11:49 INFO Utils: Successfully started service 'SparkUI' on port 4040.
21/02/17 01:11:49 INFO SparkUI: Bound SparkUI to 127.0.0.1, and started at http://localhost:4040
21/02/17 01:11:49 INFO SparkContext: Added JAR file:/home/yitaoli/R/x86_64-pc-linux-gnu-library/4.0/sparklyr/java/sparklyr-3.0-2.12.jar at spark://localhost:43099/jars/sparklyr-3.0-2.12.jar with timestamp 1613524309719
21/02/17 01:11:49 INFO Executor: Starting executor ID driver on host localhost
21/02/17 01:11:49 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 39255.
21/02/17 01:11:49 INFO NettyBlockTransferService: Server created on localhost:39255
21/02/17 01:11:49 INFO BlockManager: Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
21/02/17 01:11:49 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, localhost, 39255, None)
21/02/17 01:11:49 INFO BlockManagerMasterEndpoint: Registering block manager localhost:39255 with 912.3 MiB RAM, BlockManagerId(driver, localhost, 39255, None)
21/02/17 01:11:49 INFO BlockManagerMaster: Registered BlockManager BlockManagerId(driver, localhost, 39255, None)
21/02/17 01:11:49 INFO BlockManager: Initialized BlockManager: BlockManagerId(driver, localhost, 39255, None)
21/02/17 01:11:50 INFO SharedState: loading hive config file: file:/home/yitaoli/spark/spark-3.0.0-bin-hadoop3.2/conf/hive-site.xml
21/02/17 01:11:50 INFO SharedState: Setting hive.metastore.warehouse.dir ('null') to the value of spark.sql.warehouse.dir ('file:/home/yitaoli/sparkxgb/tests/testthat/spark-warehouse').
21/02/17 01:11:50 INFO SharedState: Warehouse path is 'file:/home/yitaoli/sparkxgb/tests/testthat/spark-warehouse'.
21/02/17 01:11:52 INFO HiveUtils: Initializing HiveMetastoreConnection version 2.3.7 using Spark classes.
21/02/17 01:11:52 INFO HiveConf: Found configuration file file:/home/yitaoli/spark/spark-3.0.0-bin-hadoop3.2/conf/hive-site.xml
21/02/17 01:11:52 INFO SessionState: Created HDFS directory: /tmp/hive/yitaoli/5c491f9c-0a05-4820-998d-e60a07c43169
21/02/17 01:11:52 INFO SessionState: Created local directory: /tmp/yitaoli/5c491f9c-0a05-4820-998d-e60a07c43169
21/02/17 01:11:52 INFO SessionState: Created HDFS directory: /tmp/hive/yitaoli/5c491f9c-0a05-4820-998d-e60a07c43169/_tmp_space.db
21/02/17 01:11:52 INFO HiveClientImpl: Warehouse location for Hive client (version 2.3.7) is file:/home/yitaoli/sparkxgb/tests/testthat/spark-warehouse
21/02/17 01:11:52 WARN HiveConf: HiveConf of name hive.stats.jdbc.timeout does not exist
21/02/17 01:11:52 WARN HiveConf: HiveConf of name hive.stats.retries.wait does not exist
21/02/17 01:11:52 INFO HiveMetaStore: 0: Opening raw store with implementation class:org.apache.hadoop.hive.metastore.ObjectStore
21/02/17 01:11:52 INFO ObjectStore: ObjectStore, initialize called
21/02/17 01:11:53 INFO Persistence: Property hive.metastore.integral.jdo.pushdown unknown - will be ignored
21/02/17 01:11:53 INFO Persistence: Property datanucleus.cache.level2 unknown - will be ignored
21/02/17 01:11:54 INFO ObjectStore: Setting MetaStore object pin classes with hive.metastore.cache.pinobjtypes="Table,StorageDescriptor,SerDeInfo,Partition,Database,Type,FieldSchema,Order"
21/02/17 01:11:55 INFO MetaStoreDirectSql: Using direct SQL, underlying DB is DERBY
21/02/17 01:11:55 INFO ObjectStore: Initialized ObjectStore
21/02/17 01:11:55 WARN ObjectStore: Version information not found in metastore. hive.metastore.schema.verification is not enabled so recording the schema version 2.3.0
21/02/17 01:11:55 WARN ObjectStore: setMetaStoreSchemaVersion called but recording version is disabled: version = 2.3.0, comment = Set by MetaStore yitaoli@127.0.1.1
21/02/17 01:11:55 WARN ObjectStore: Failed to get database default, returning NoSuchObjectException
21/02/17 01:11:55 INFO HiveMetaStore: Added admin role in metastore
21/02/17 01:11:55 INFO HiveMetaStore: Added public role in metastore
21/02/17 01:11:55 INFO HiveMetaStore: No user is added in admin role, since config is empty
21/02/17 01:11:55 INFO HiveMetaStore: 0: get_all_functions
21/02/17 01:11:55 INFO audit: ugi=yitaoli	ip=unknown-ip-addr	cmd=get_all_functions	
21/02/17 01:11:56 INFO HiveMetaStore: 0: get_database: default
21/02/17 01:11:56 INFO audit: ugi=yitaoli	ip=unknown-ip-addr	cmd=get_database: default	
21/02/17 01:11:56 INFO HiveMetaStore: 0: get_database: default
21/02/17 01:11:56 INFO audit: ugi=yitaoli	ip=unknown-ip-addr	cmd=get_database: default	
21/02/17 01:11:56 INFO HiveMetaStore: 0: get_table : db=default tbl=iris
21/02/17 01:11:56 INFO audit: ugi=yitaoli	ip=unknown-ip-addr	cmd=get_table : db=default tbl=iris	
21/02/17 01:11:56 INFO HiveMetaStore: 0: get_database: global_temp
21/02/17 01:11:56 INFO audit: ugi=yitaoli	ip=unknown-ip-addr	cmd=get_database: global_temp	
21/02/17 01:11:56 WARN ObjectStore: Failed to get database global_temp, returning NoSuchObjectException
21/02/17 01:11:56 INFO HiveMetaStore: 0: get_database: default
21/02/17 01:11:56 INFO audit: ugi=yitaoli	ip=unknown-ip-addr	cmd=get_database: default	
21/02/17 01:11:56 INFO HiveMetaStore: 0: get_database: default
21/02/17 01:11:56 INFO audit: ugi=yitaoli	ip=unknown-ip-addr	cmd=get_database: default	
21/02/17 01:11:56 INFO HiveMetaStore: 0: get_tables: db=default pat=*
21/02/17 01:11:56 INFO audit: ugi=yitaoli	ip=unknown-ip-addr	cmd=get_tables: db=default pat=*	
21/02/17 01:11:57 INFO SparkContext: Starting job: collect at utils.scala:54
21/02/17 01:11:57 INFO DAGScheduler: Job 0 finished: collect at utils.scala:54, took 0.005076 s
21/02/17 01:11:57 INFO CodeGenerator: Code generated in 184.662469 ms
21/02/17 01:11:57 INFO SparkContext: Starting job: collect at utils.scala:137
21/02/17 01:11:57 INFO DAGScheduler: Got job 1 (collect at utils.scala:137) with 1 output partitions
21/02/17 01:11:57 INFO DAGScheduler: Final stage: ResultStage 0 (collect at utils.scala:137)
21/02/17 01:11:57 INFO DAGScheduler: Parents of final stage: List()
21/02/17 01:11:57 INFO DAGScheduler: Missing parents: List()
21/02/17 01:11:57 INFO DAGScheduler: Submitting ResultStage 0 (MapPartitionsRDD[9] at collect at utils.scala:137), which has no missing parents
21/02/17 01:11:57 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 6.5 KiB, free 912.3 MiB)
21/02/17 01:11:57 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 3.2 KiB, free 912.3 MiB)
21/02/17 01:11:57 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on localhost:39255 (size: 3.2 KiB, free: 912.3 MiB)
21/02/17 01:11:57 INFO SparkContext: Created broadcast 0 from broadcast at DAGScheduler.scala:1200
21/02/17 01:11:57 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 0 (MapPartitionsRDD[9] at collect at utils.scala:137) (first 15 tasks are for partitions Vector(0))
21/02/17 01:11:57 INFO TaskSchedulerImpl: Adding task set 0.0 with 1 tasks
21/02/17 01:11:57 INFO TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0, localhost, executor driver, partition 0, PROCESS_LOCAL, 7561 bytes)
21/02/17 01:11:57 INFO Executor: Running task 0.0 in stage 0.0 (TID 0)
21/02/17 01:11:57 INFO Executor: Fetching spark://localhost:43099/jars/sparklyr-3.0-2.12.jar with timestamp 1613524309719
21/02/17 01:11:57 INFO TransportClientFactory: Successfully created connection to localhost/127.0.0.1:43099 after 11 ms (0 ms spent in bootstraps)
21/02/17 01:11:57 INFO Utils: Fetching spark://localhost:43099/jars/sparklyr-3.0-2.12.jar to /tmp/spark-5bf5c6f6-303d-4115-b2e0-5c2cf5364b2a/userFiles-4744d8b4-0f78-4e88-befb-2c18b608df23/fetchFileTemp8982090696480611656.tmp
21/02/17 01:11:58 INFO Executor: Adding file:/tmp/spark-5bf5c6f6-303d-4115-b2e0-5c2cf5364b2a/userFiles-4744d8b4-0f78-4e88-befb-2c18b608df23/sparklyr-3.0-2.12.jar to class loader
21/02/17 01:11:58 INFO Executor: Finished task 0.0 in stage 0.0 (TID 0). 1440 bytes result sent to driver
21/02/17 01:11:58 INFO TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in 304 ms on localhost (executor driver) (1/1)
21/02/17 01:11:58 INFO TaskSchedulerImpl: Removed TaskSet 0.0, whose tasks have all completed, from pool 
21/02/17 01:11:58 INFO DAGScheduler: ResultStage 0 (collect at utils.scala:137) finished in 0.422 s
21/02/17 01:11:58 INFO DAGScheduler: Job 1 is finished. Cancelling potential speculative or zombie tasks for this job
21/02/17 01:11:58 INFO TaskSchedulerImpl: Killing all running tasks in stage 0: Stage finished
21/02/17 01:11:58 INFO DAGScheduler: Job 1 finished: collect at utils.scala:137, took 0.448165 s
21/02/17 01:11:58 INFO CodeGenerator: Code generated in 14.517605 ms
21/02/17 01:11:58 INFO CodeGenerator: Code generated in 12.494845 ms
21/02/17 01:11:58 INFO CodeGenerator: Code generated in 14.253942 ms
21/02/17 01:11:58 INFO SparkContext: Starting job: count at utils.scala:135
21/02/17 01:11:58 INFO DAGScheduler: Registering RDD 11 (count at utils.scala:135) as input to shuffle 0
21/02/17 01:11:58 INFO DAGScheduler: Got job 2 (count at utils.scala:135) with 1 output partitions
21/02/17 01:11:58 INFO DAGScheduler: Final stage: ResultStage 2 (count at utils.scala:135)
21/02/17 01:11:58 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 1)
21/02/17 01:11:58 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 1)
21/02/17 01:11:58 INFO DAGScheduler: Submitting ShuffleMapStage 1 (MapPartitionsRDD[11] at count at utils.scala:135), which has no missing parents
21/02/17 01:11:58 INFO MemoryStore: Block broadcast_1 stored as values in memory (estimated size 10.0 KiB, free 912.3 MiB)
21/02/17 01:11:58 INFO MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 5.2 KiB, free 912.3 MiB)
21/02/17 01:11:58 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on localhost:39255 (size: 5.2 KiB, free: 912.3 MiB)
21/02/17 01:11:58 INFO SparkContext: Created broadcast 1 from broadcast at DAGScheduler.scala:1200
21/02/17 01:11:58 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 1 (MapPartitionsRDD[11] at count at utils.scala:135) (first 15 tasks are for partitions Vector(0))
21/02/17 01:11:58 INFO TaskSchedulerImpl: Adding task set 1.0 with 1 tasks
21/02/17 01:11:58 INFO TaskSetManager: Starting task 0.0 in stage 1.0 (TID 1, localhost, executor driver, partition 0, PROCESS_LOCAL, 7550 bytes)
21/02/17 01:11:58 INFO Executor: Running task 0.0 in stage 1.0 (TID 1)
21/02/17 01:11:58 INFO Executor: Finished task 0.0 in stage 1.0 (TID 1). 1833 bytes result sent to driver
21/02/17 01:11:58 INFO TaskSetManager: Finished task 0.0 in stage 1.0 (TID 1) in 39 ms on localhost (executor driver) (1/1)
21/02/17 01:11:58 INFO TaskSchedulerImpl: Removed TaskSet 1.0, whose tasks have all completed, from pool 
21/02/17 01:11:58 INFO DAGScheduler: ShuffleMapStage 1 (count at utils.scala:135) finished in 0.054 s
21/02/17 01:11:58 INFO DAGScheduler: looking for newly runnable stages
21/02/17 01:11:58 INFO DAGScheduler: running: Set()
21/02/17 01:11:58 INFO DAGScheduler: waiting: Set(ResultStage 2)
21/02/17 01:11:58 INFO DAGScheduler: failed: Set()
21/02/17 01:11:58 INFO DAGScheduler: Submitting ResultStage 2 (MapPartitionsRDD[14] at count at utils.scala:135), which has no missing parents
21/02/17 01:11:58 INFO MemoryStore: Block broadcast_2 stored as values in memory (estimated size 10.1 KiB, free 912.3 MiB)
21/02/17 01:11:58 INFO MemoryStore: Block broadcast_2_piece0 stored as bytes in memory (estimated size 5.0 KiB, free 912.3 MiB)
21/02/17 01:11:58 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on localhost:39255 (size: 5.0 KiB, free: 912.3 MiB)
21/02/17 01:11:58 INFO SparkContext: Created broadcast 2 from broadcast at DAGScheduler.scala:1200
21/02/17 01:11:58 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 2 (MapPartitionsRDD[14] at count at utils.scala:135) (first 15 tasks are for partitions Vector(0))
21/02/17 01:11:58 INFO TaskSchedulerImpl: Adding task set 2.0 with 1 tasks
21/02/17 01:11:58 INFO TaskSetManager: Starting task 0.0 in stage 2.0 (TID 2, localhost, executor driver, partition 0, NODE_LOCAL, 7325 bytes)
21/02/17 01:11:58 INFO Executor: Running task 0.0 in stage 2.0 (TID 2)
21/02/17 01:11:58 INFO ShuffleBlockFetcherIterator: Getting 1 (60.0 B) non-empty blocks including 1 (60.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
21/02/17 01:11:58 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 5 ms
21/02/17 01:11:58 INFO Executor: Finished task 0.0 in stage 2.0 (TID 2). 2648 bytes result sent to driver
21/02/17 01:11:58 INFO TaskSetManager: Finished task 0.0 in stage 2.0 (TID 2) in 35 ms on localhost (executor driver) (1/1)
21/02/17 01:11:58 INFO TaskSchedulerImpl: Removed TaskSet 2.0, whose tasks have all completed, from pool 
21/02/17 01:11:58 INFO DAGScheduler: ResultStage 2 (count at utils.scala:135) finished in 0.042 s
21/02/17 01:11:58 INFO DAGScheduler: Job 2 is finished. Cancelling potential speculative or zombie tasks for this job
21/02/17 01:11:58 INFO TaskSchedulerImpl: Killing all running tasks in stage 2: Stage finished
21/02/17 01:11:58 INFO DAGScheduler: Job 2 finished: count at utils.scala:135, took 0.116467 s
21/02/17 01:11:58 INFO SparkContext: Starting job: collect at utils.scala:137
21/02/17 01:11:58 INFO DAGScheduler: Got job 3 (collect at utils.scala:137) with 1 output partitions
21/02/17 01:11:58 INFO DAGScheduler: Final stage: ResultStage 3 (collect at utils.scala:137)
21/02/17 01:11:58 INFO DAGScheduler: Parents of final stage: List()
21/02/17 01:11:58 INFO DAGScheduler: Missing parents: List()
21/02/17 01:11:58 INFO DAGScheduler: Submitting ResultStage 3 (MapPartitionsRDD[16] at collect at utils.scala:137), which has no missing parents
21/02/17 01:11:58 INFO MemoryStore: Block broadcast_3 stored as values in memory (estimated size 7.2 KiB, free 912.3 MiB)
21/02/17 01:11:58 INFO MemoryStore: Block broadcast_3_piece0 stored as bytes in memory (estimated size 3.7 KiB, free 912.3 MiB)
21/02/17 01:11:58 INFO BlockManagerInfo: Added broadcast_3_piece0 in memory on localhost:39255 (size: 3.7 KiB, free: 912.3 MiB)
21/02/17 01:11:58 INFO SparkContext: Created broadcast 3 from broadcast at DAGScheduler.scala:1200
21/02/17 01:11:58 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 3 (MapPartitionsRDD[16] at collect at utils.scala:137) (first 15 tasks are for partitions Vector(0))
21/02/17 01:11:58 INFO TaskSchedulerImpl: Adding task set 3.0 with 1 tasks
21/02/17 01:11:58 INFO TaskSetManager: Starting task 0.0 in stage 3.0 (TID 3, localhost, executor driver, partition 0, PROCESS_LOCAL, 7561 bytes)
21/02/17 01:11:58 INFO Executor: Running task 0.0 in stage 3.0 (TID 3)
21/02/17 01:11:58 INFO Executor: Finished task 0.0 in stage 3.0 (TID 3). 1397 bytes result sent to driver
21/02/17 01:11:58 INFO TaskSetManager: Finished task 0.0 in stage 3.0 (TID 3) in 6 ms on localhost (executor driver) (1/1)
21/02/17 01:11:58 INFO TaskSchedulerImpl: Removed TaskSet 3.0, whose tasks have all completed, from pool 
21/02/17 01:11:58 INFO DAGScheduler: ResultStage 3 (collect at utils.scala:137) finished in 0.013 s
21/02/17 01:11:58 INFO DAGScheduler: Job 3 is finished. Cancelling potential speculative or zombie tasks for this job
21/02/17 01:11:58 INFO TaskSchedulerImpl: Killing all running tasks in stage 3: Stage finished
21/02/17 01:11:58 INFO DAGScheduler: Job 3 finished: collect at utils.scala:137, took 0.016539 s
21/02/17 01:11:58 INFO SparkContext: Starting job: count at utils.scala:135
21/02/17 01:11:58 INFO DAGScheduler: Registering RDD 18 (count at utils.scala:135) as input to shuffle 1
21/02/17 01:11:58 INFO DAGScheduler: Got job 4 (count at utils.scala:135) with 1 output partitions
21/02/17 01:11:58 INFO DAGScheduler: Final stage: ResultStage 5 (count at utils.scala:135)
21/02/17 01:11:58 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 4)
21/02/17 01:11:58 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 4)
21/02/17 01:11:58 INFO DAGScheduler: Submitting ShuffleMapStage 4 (MapPartitionsRDD[18] at count at utils.scala:135), which has no missing parents
21/02/17 01:11:58 INFO MemoryStore: Block broadcast_4 stored as values in memory (estimated size 10.0 KiB, free 912.2 MiB)
21/02/17 01:11:58 INFO MemoryStore: Block broadcast_4_piece0 stored as bytes in memory (estimated size 5.2 KiB, free 912.2 MiB)
21/02/17 01:11:58 INFO BlockManagerInfo: Added broadcast_4_piece0 in memory on localhost:39255 (size: 5.2 KiB, free: 912.3 MiB)
21/02/17 01:11:58 INFO SparkContext: Created broadcast 4 from broadcast at DAGScheduler.scala:1200
21/02/17 01:11:58 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 4 (MapPartitionsRDD[18] at count at utils.scala:135) (first 15 tasks are for partitions Vector(0))
21/02/17 01:11:58 INFO TaskSchedulerImpl: Adding task set 4.0 with 1 tasks
21/02/17 01:11:58 INFO TaskSetManager: Starting task 0.0 in stage 4.0 (TID 4, localhost, executor driver, partition 0, PROCESS_LOCAL, 7550 bytes)
21/02/17 01:11:58 INFO Executor: Running task 0.0 in stage 4.0 (TID 4)
21/02/17 01:11:58 INFO Executor: Finished task 0.0 in stage 4.0 (TID 4). 1833 bytes result sent to driver
21/02/17 01:11:58 INFO TaskSetManager: Finished task 0.0 in stage 4.0 (TID 4) in 7 ms on localhost (executor driver) (1/1)
21/02/17 01:11:58 INFO TaskSchedulerImpl: Removed TaskSet 4.0, whose tasks have all completed, from pool 
21/02/17 01:11:58 INFO DAGScheduler: ShuffleMapStage 4 (count at utils.scala:135) finished in 0.015 s
21/02/17 01:11:58 INFO DAGScheduler: looking for newly runnable stages
21/02/17 01:11:58 INFO DAGScheduler: running: Set()
21/02/17 01:11:58 INFO DAGScheduler: waiting: Set(ResultStage 5)
21/02/17 01:11:58 INFO DAGScheduler: failed: Set()
21/02/17 01:11:58 INFO DAGScheduler: Submitting ResultStage 5 (MapPartitionsRDD[21] at count at utils.scala:135), which has no missing parents
21/02/17 01:11:58 INFO MemoryStore: Block broadcast_5 stored as values in memory (estimated size 10.1 KiB, free 912.2 MiB)
21/02/17 01:11:58 INFO MemoryStore: Block broadcast_5_piece0 stored as bytes in memory (estimated size 5.0 KiB, free 912.2 MiB)
21/02/17 01:11:58 INFO BlockManagerInfo: Added broadcast_5_piece0 in memory on localhost:39255 (size: 5.0 KiB, free: 912.3 MiB)
21/02/17 01:11:58 INFO SparkContext: Created broadcast 5 from broadcast at DAGScheduler.scala:1200
21/02/17 01:11:58 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 5 (MapPartitionsRDD[21] at count at utils.scala:135) (first 15 tasks are for partitions Vector(0))
21/02/17 01:11:58 INFO TaskSchedulerImpl: Adding task set 5.0 with 1 tasks
21/02/17 01:11:58 INFO TaskSetManager: Starting task 0.0 in stage 5.0 (TID 5, localhost, executor driver, partition 0, NODE_LOCAL, 7325 bytes)
21/02/17 01:11:58 INFO Executor: Running task 0.0 in stage 5.0 (TID 5)
21/02/17 01:11:58 INFO ShuffleBlockFetcherIterator: Getting 1 (60.0 B) non-empty blocks including 1 (60.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
21/02/17 01:11:58 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
21/02/17 01:11:58 INFO Executor: Finished task 0.0 in stage 5.0 (TID 5). 2648 bytes result sent to driver
21/02/17 01:11:58 INFO TaskSetManager: Finished task 0.0 in stage 5.0 (TID 5) in 6 ms on localhost (executor driver) (1/1)
21/02/17 01:11:58 INFO TaskSchedulerImpl: Removed TaskSet 5.0, whose tasks have all completed, from pool 
21/02/17 01:11:58 INFO DAGScheduler: ResultStage 5 (count at utils.scala:135) finished in 0.013 s
21/02/17 01:11:58 INFO DAGScheduler: Job 4 is finished. Cancelling potential speculative or zombie tasks for this job
21/02/17 01:11:58 INFO TaskSchedulerImpl: Killing all running tasks in stage 5: Stage finished
21/02/17 01:11:58 INFO DAGScheduler: Job 4 finished: count at utils.scala:135, took 0.035448 s
21/02/17 01:12:00 INFO SparkContext: Invoking stop() from shutdown hook
21/02/17 01:12:00 INFO SparkUI: Stopped Spark web UI at http://localhost:4040
21/02/17 01:12:00 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!
21/02/17 01:12:00 INFO MemoryStore: MemoryStore cleared
21/02/17 01:12:00 INFO BlockManager: BlockManager stopped
21/02/17 01:12:00 INFO BlockManagerMaster: BlockManagerMaster stopped
21/02/17 01:12:00 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!
21/02/17 01:12:00 INFO SparkContext: Successfully stopped SparkContext
21/02/17 01:12:00 INFO ShutdownHookManager: Shutdown hook called
21/02/17 01:12:00 INFO ShutdownHookManager: Deleting directory /tmp/spark-5bf5c6f6-303d-4115-b2e0-5c2cf5364b2a
21/02/17 01:12:00 INFO ShutdownHookManager: Deleting directory /tmp/spark-128c6aa0-307a-458e-99b4-849d8b6f13fc
21/02/17 01:15:32 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
21/02/17 01:15:32 INFO SparkContext: Running Spark version 2.3.0
21/02/17 01:15:32 INFO SparkContext: Submitted application: sparklyr
21/02/17 01:15:32 INFO SecurityManager: Changing view acls to: yitaoli
21/02/17 01:15:32 INFO SecurityManager: Changing modify acls to: yitaoli
21/02/17 01:15:32 INFO SecurityManager: Changing view acls groups to: 
21/02/17 01:15:32 INFO SecurityManager: Changing modify acls groups to: 
21/02/17 01:15:32 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(yitaoli); groups with view permissions: Set(); users  with modify permissions: Set(yitaoli); groups with modify permissions: Set()
21/02/17 01:15:32 INFO Utils: Successfully started service 'sparkDriver' on port 38593.
21/02/17 01:15:32 INFO SparkEnv: Registering MapOutputTracker
21/02/17 01:15:32 INFO SparkEnv: Registering BlockManagerMaster
21/02/17 01:15:32 INFO BlockManagerMasterEndpoint: Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
21/02/17 01:15:32 INFO BlockManagerMasterEndpoint: BlockManagerMasterEndpoint up
21/02/17 01:15:32 INFO DiskBlockManager: Created local directory at /tmp/blockmgr-eccd4528-31ca-4441-a3e3-7bbb1aeed36b
21/02/17 01:15:32 INFO MemoryStore: MemoryStore started with capacity 912.3 MB
21/02/17 01:15:32 INFO SparkEnv: Registering OutputCommitCoordinator
21/02/17 01:15:33 INFO Utils: Successfully started service 'SparkUI' on port 4040.
21/02/17 01:15:33 INFO SparkUI: Bound SparkUI to 127.0.0.1, and started at http://localhost:4040
21/02/17 01:15:33 INFO SparkContext: Added JAR file:///home/yitaoli/R/x86_64-pc-linux-gnu-library/4.0/sparkxgb/java/sparkxgb-2.3-2.11.jar at spark://localhost:38593/jars/sparkxgb-2.3-2.11.jar with timestamp 1613524533114
21/02/17 01:15:33 INFO SparkContext: Added JAR file:/home/yitaoli/R/x86_64-pc-linux-gnu-library/4.0/sparklyr/java/sparklyr-2.3-2.11.jar at spark://localhost:38593/jars/sparklyr-2.3-2.11.jar with timestamp 1613524533115
21/02/17 01:15:33 INFO Executor: Starting executor ID driver on host localhost
21/02/17 01:15:33 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 42851.
21/02/17 01:15:33 INFO NettyBlockTransferService: Server created on localhost:42851
21/02/17 01:15:33 INFO BlockManager: Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
21/02/17 01:15:33 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, localhost, 42851, None)
21/02/17 01:15:33 INFO BlockManagerMasterEndpoint: Registering block manager localhost:42851 with 912.3 MB RAM, BlockManagerId(driver, localhost, 42851, None)
21/02/17 01:15:33 INFO BlockManagerMaster: Registered BlockManager BlockManagerId(driver, localhost, 42851, None)
21/02/17 01:15:33 INFO BlockManager: Initialized BlockManager: BlockManagerId(driver, localhost, 42851, None)
21/02/17 01:15:33 INFO SharedState: loading hive config file: file:/home/yitaoli/spark/spark-2.3.0-bin-hadoop2.7/conf/hive-site.xml
21/02/17 01:15:33 INFO SharedState: Setting hive.metastore.warehouse.dir ('null') to the value of spark.sql.warehouse.dir ('file:/home/yitaoli/sparkxgb/tests/testthat/spark-warehouse').
21/02/17 01:15:33 INFO SharedState: Warehouse path is 'file:/home/yitaoli/sparkxgb/tests/testthat/spark-warehouse'.
21/02/17 01:15:33 INFO StateStoreCoordinatorRef: Registered StateStoreCoordinator endpoint
21/02/17 01:15:34 INFO HiveUtils: Initializing HiveMetastoreConnection version 1.2.1 using Spark classes.
21/02/17 01:15:35 INFO HiveMetaStore: 0: Opening raw store with implemenation class:org.apache.hadoop.hive.metastore.ObjectStore
21/02/17 01:15:35 INFO ObjectStore: ObjectStore, initialize called
21/02/17 01:15:35 INFO Persistence: Property hive.metastore.integral.jdo.pushdown unknown - will be ignored
21/02/17 01:15:35 INFO Persistence: Property datanucleus.cache.level2 unknown - will be ignored
21/02/17 01:15:36 INFO ObjectStore: Setting MetaStore object pin classes with hive.metastore.cache.pinobjtypes="Table,StorageDescriptor,SerDeInfo,Partition,Database,Type,FieldSchema,Order"
21/02/17 01:15:36 INFO Datastore: The class "org.apache.hadoop.hive.metastore.model.MFieldSchema" is tagged as "embedded-only" so does not have its own datastore table.
21/02/17 01:15:36 INFO Datastore: The class "org.apache.hadoop.hive.metastore.model.MOrder" is tagged as "embedded-only" so does not have its own datastore table.
21/02/17 01:15:37 INFO Datastore: The class "org.apache.hadoop.hive.metastore.model.MFieldSchema" is tagged as "embedded-only" so does not have its own datastore table.
21/02/17 01:15:37 INFO Datastore: The class "org.apache.hadoop.hive.metastore.model.MOrder" is tagged as "embedded-only" so does not have its own datastore table.
21/02/17 01:15:37 INFO MetaStoreDirectSql: Using direct SQL, underlying DB is DERBY
21/02/17 01:15:37 INFO ObjectStore: Initialized ObjectStore
21/02/17 01:15:37 WARN ObjectStore: Version information not found in metastore. hive.metastore.schema.verification is not enabled so recording the schema version 1.2.0
21/02/17 01:15:37 WARN ObjectStore: Failed to get database default, returning NoSuchObjectException
21/02/17 01:15:37 INFO HiveMetaStore: Added admin role in metastore
21/02/17 01:15:37 INFO HiveMetaStore: Added public role in metastore
21/02/17 01:15:37 INFO HiveMetaStore: No user is added in admin role, since config is empty
21/02/17 01:15:37 INFO HiveMetaStore: 0: get_all_databases
21/02/17 01:15:37 INFO audit: ugi=yitaoli	ip=unknown-ip-addr	cmd=get_all_databases	
21/02/17 01:15:37 INFO HiveMetaStore: 0: get_functions: db=default pat=*
21/02/17 01:15:37 INFO audit: ugi=yitaoli	ip=unknown-ip-addr	cmd=get_functions: db=default pat=*	
21/02/17 01:15:37 INFO Datastore: The class "org.apache.hadoop.hive.metastore.model.MResourceUri" is tagged as "embedded-only" so does not have its own datastore table.
21/02/17 01:15:37 INFO SessionState: Created local directory: /tmp/406bb6bf-f621-49dd-8443-327cdb0a9817_resources
21/02/17 01:15:37 INFO SessionState: Created HDFS directory: /tmp/hive/yitaoli/406bb6bf-f621-49dd-8443-327cdb0a9817
21/02/17 01:15:37 INFO SessionState: Created local directory: /tmp/yitaoli/406bb6bf-f621-49dd-8443-327cdb0a9817
21/02/17 01:15:37 INFO SessionState: Created HDFS directory: /tmp/hive/yitaoli/406bb6bf-f621-49dd-8443-327cdb0a9817/_tmp_space.db
21/02/17 01:15:37 INFO HiveClientImpl: Warehouse location for Hive client (version 1.2.2) is file:/home/yitaoli/sparkxgb/tests/testthat/spark-warehouse
21/02/17 01:15:37 INFO HiveMetaStore: 0: get_database: default
21/02/17 01:15:37 INFO audit: ugi=yitaoli	ip=unknown-ip-addr	cmd=get_database: default	
21/02/17 01:15:37 INFO HiveMetaStore: 0: get_database: global_temp
21/02/17 01:15:37 INFO audit: ugi=yitaoli	ip=unknown-ip-addr	cmd=get_database: global_temp	
21/02/17 01:15:37 WARN ObjectStore: Failed to get database global_temp, returning NoSuchObjectException
21/02/17 01:15:37 INFO HiveMetaStore: 0: get_table : db=default tbl=iris
21/02/17 01:15:37 INFO audit: ugi=yitaoli	ip=unknown-ip-addr	cmd=get_table : db=default tbl=iris	
21/02/17 01:15:38 INFO HiveMetaStore: 0: get_database: default
21/02/17 01:15:38 INFO audit: ugi=yitaoli	ip=unknown-ip-addr	cmd=get_database: default	
21/02/17 01:15:38 INFO HiveMetaStore: 0: get_database: default
21/02/17 01:15:38 INFO audit: ugi=yitaoli	ip=unknown-ip-addr	cmd=get_database: default	
21/02/17 01:15:38 INFO HiveMetaStore: 0: get_tables: db=default pat=*
21/02/17 01:15:38 INFO audit: ugi=yitaoli	ip=unknown-ip-addr	cmd=get_tables: db=default pat=*	
21/02/17 01:15:38 INFO SparkContext: Starting job: collect at utils.scala:61
21/02/17 01:15:38 INFO DAGScheduler: Got job 0 (collect at utils.scala:61) with 1 output partitions
21/02/17 01:15:38 INFO DAGScheduler: Final stage: ResultStage 0 (collect at utils.scala:61)
21/02/17 01:15:38 INFO DAGScheduler: Parents of final stage: List()
21/02/17 01:15:38 INFO DAGScheduler: Missing parents: List()
21/02/17 01:15:38 INFO DAGScheduler: Submitting ResultStage 0 (MapPartitionsRDD[4] at map at utils.scala:54), which has no missing parents
21/02/17 01:15:38 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 5.9 KB, free 912.3 MB)
21/02/17 01:15:38 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 3.3 KB, free 912.3 MB)
21/02/17 01:15:38 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on localhost:42851 (size: 3.3 KB, free: 912.3 MB)
21/02/17 01:15:38 INFO SparkContext: Created broadcast 0 from broadcast at DAGScheduler.scala:1039
21/02/17 01:15:38 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 0 (MapPartitionsRDD[4] at map at utils.scala:54) (first 15 tasks are for partitions Vector(0))
21/02/17 01:15:38 INFO TaskSchedulerImpl: Adding task set 0.0 with 1 tasks
21/02/17 01:15:38 INFO TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0, localhost, executor driver, partition 0, PROCESS_LOCAL, 7880 bytes)
21/02/17 01:15:38 INFO Executor: Running task 0.0 in stage 0.0 (TID 0)
21/02/17 01:15:38 INFO Executor: Fetching spark://localhost:38593/jars/sparklyr-2.3-2.11.jar with timestamp 1613524533115
21/02/17 01:15:38 INFO TransportClientFactory: Successfully created connection to localhost/127.0.0.1:38593 after 12 ms (0 ms spent in bootstraps)
21/02/17 01:15:38 INFO Utils: Fetching spark://localhost:38593/jars/sparklyr-2.3-2.11.jar to /tmp/spark-cd065985-8543-4f0e-8504-d73b7cbcaf1b/userFiles-1a79a2f6-0e41-4660-86cc-e25cc44f4f6a/fetchFileTemp2774605361631532265.tmp
21/02/17 01:15:38 INFO Executor: Adding file:/tmp/spark-cd065985-8543-4f0e-8504-d73b7cbcaf1b/userFiles-1a79a2f6-0e41-4660-86cc-e25cc44f4f6a/sparklyr-2.3-2.11.jar to class loader
21/02/17 01:15:38 INFO Executor: Fetching spark://localhost:38593/jars/sparkxgb-2.3-2.11.jar with timestamp 1613524533114
21/02/17 01:15:38 INFO Utils: Fetching spark://localhost:38593/jars/sparkxgb-2.3-2.11.jar to /tmp/spark-cd065985-8543-4f0e-8504-d73b7cbcaf1b/userFiles-1a79a2f6-0e41-4660-86cc-e25cc44f4f6a/fetchFileTemp8068996986507521633.tmp
21/02/17 01:15:38 INFO Executor: Adding file:/tmp/spark-cd065985-8543-4f0e-8504-d73b7cbcaf1b/userFiles-1a79a2f6-0e41-4660-86cc-e25cc44f4f6a/sparkxgb-2.3-2.11.jar to class loader
21/02/17 01:15:38 INFO CodeGenerator: Code generated in 153.952584 ms
21/02/17 01:15:38 INFO Executor: Finished task 0.0 in stage 0.0 (TID 0). 970 bytes result sent to driver
21/02/17 01:15:38 INFO TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in 354 ms on localhost (executor driver) (1/1)
21/02/17 01:15:38 INFO TaskSchedulerImpl: Removed TaskSet 0.0, whose tasks have all completed, from pool 
21/02/17 01:15:38 INFO DAGScheduler: ResultStage 0 (collect at utils.scala:61) finished in 0.449 s
21/02/17 01:15:38 INFO DAGScheduler: Job 0 finished: collect at utils.scala:61, took 0.483151 s
21/02/17 01:15:39 INFO ContextCleaner: Cleaned accumulator 17
21/02/17 01:15:39 INFO ContextCleaner: Cleaned accumulator 5
21/02/17 01:15:39 INFO ContextCleaner: Cleaned accumulator 22
21/02/17 01:15:39 INFO ContextCleaner: Cleaned accumulator 19
21/02/17 01:15:39 INFO ContextCleaner: Cleaned accumulator 1
21/02/17 01:15:39 INFO ContextCleaner: Cleaned accumulator 10
21/02/17 01:15:39 INFO ContextCleaner: Cleaned accumulator 13
21/02/17 01:15:39 INFO ContextCleaner: Cleaned accumulator 4
21/02/17 01:15:39 INFO ContextCleaner: Cleaned accumulator 6
21/02/17 01:15:39 INFO ContextCleaner: Cleaned accumulator 2
21/02/17 01:15:39 INFO ContextCleaner: Cleaned accumulator 0
21/02/17 01:15:39 INFO ContextCleaner: Cleaned accumulator 18
21/02/17 01:15:39 INFO ContextCleaner: Cleaned accumulator 20
21/02/17 01:15:39 INFO ContextCleaner: Cleaned accumulator 23
21/02/17 01:15:39 INFO ContextCleaner: Cleaned accumulator 7
21/02/17 01:15:39 INFO ContextCleaner: Cleaned accumulator 25
21/02/17 01:15:39 INFO ContextCleaner: Cleaned accumulator 24
21/02/17 01:15:39 INFO ContextCleaner: Cleaned accumulator 15
21/02/17 01:15:39 INFO ContextCleaner: Cleaned accumulator 11
21/02/17 01:15:39 INFO ContextCleaner: Cleaned accumulator 14
21/02/17 01:15:39 INFO ContextCleaner: Cleaned accumulator 16
21/02/17 01:15:39 INFO ContextCleaner: Cleaned accumulator 3
21/02/17 01:15:39 INFO ContextCleaner: Cleaned accumulator 9
21/02/17 01:15:39 INFO ContextCleaner: Cleaned accumulator 8
21/02/17 01:15:39 INFO BlockManagerInfo: Removed broadcast_0_piece0 on localhost:42851 in memory (size: 3.3 KB, free: 912.3 MB)
21/02/17 01:15:39 INFO ContextCleaner: Cleaned accumulator 12
21/02/17 01:15:39 INFO ContextCleaner: Cleaned accumulator 21
21/02/17 01:15:39 INFO CodeGenerator: Code generated in 11.77133 ms
21/02/17 01:15:39 INFO CodeGenerator: Code generated in 13.288206 ms
21/02/17 01:15:39 INFO SparkContext: Starting job: collect at utils.scala:135
21/02/17 01:15:39 INFO DAGScheduler: Got job 1 (collect at utils.scala:135) with 1 output partitions
21/02/17 01:15:39 INFO DAGScheduler: Final stage: ResultStage 1 (collect at utils.scala:135)
21/02/17 01:15:39 INFO DAGScheduler: Parents of final stage: List()
21/02/17 01:15:39 INFO DAGScheduler: Missing parents: List()
21/02/17 01:15:39 INFO DAGScheduler: Submitting ResultStage 1 (MapPartitionsRDD[9] at collect at utils.scala:135), which has no missing parents
21/02/17 01:15:39 INFO MemoryStore: Block broadcast_1 stored as values in memory (estimated size 6.4 KB, free 912.3 MB)
21/02/17 01:15:39 INFO MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 3.2 KB, free 912.3 MB)
21/02/17 01:15:39 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on localhost:42851 (size: 3.2 KB, free: 912.3 MB)
21/02/17 01:15:39 INFO SparkContext: Created broadcast 1 from broadcast at DAGScheduler.scala:1039
21/02/17 01:15:39 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 1 (MapPartitionsRDD[9] at collect at utils.scala:135) (first 15 tasks are for partitions Vector(0))
21/02/17 01:15:39 INFO TaskSchedulerImpl: Adding task set 1.0 with 1 tasks
21/02/17 01:15:39 INFO TaskSetManager: Starting task 0.0 in stage 1.0 (TID 1, localhost, executor driver, partition 0, PROCESS_LOCAL, 8067 bytes)
21/02/17 01:15:39 INFO Executor: Running task 0.0 in stage 1.0 (TID 1)
21/02/17 01:15:39 INFO CodeGenerator: Code generated in 5.89469 ms
21/02/17 01:15:39 INFO Executor: Finished task 0.0 in stage 1.0 (TID 1). 1329 bytes result sent to driver
21/02/17 01:15:39 INFO TaskSetManager: Finished task 0.0 in stage 1.0 (TID 1) in 19 ms on localhost (executor driver) (1/1)
21/02/17 01:15:39 INFO TaskSchedulerImpl: Removed TaskSet 1.0, whose tasks have all completed, from pool 
21/02/17 01:15:39 INFO DAGScheduler: ResultStage 1 (collect at utils.scala:135) finished in 0.026 s
21/02/17 01:15:39 INFO DAGScheduler: Job 1 finished: collect at utils.scala:135, took 0.029043 s
21/02/17 01:15:39 INFO CodeGenerator: Code generated in 11.798367 ms
21/02/17 01:15:39 INFO CodeGenerator: Code generated in 10.670036 ms
21/02/17 01:15:39 INFO SparkContext: Starting job: count at utils.scala:135
21/02/17 01:15:39 INFO DAGScheduler: Registering RDD 12 (count at utils.scala:135)
21/02/17 01:15:39 INFO DAGScheduler: Got job 2 (count at utils.scala:135) with 1 output partitions
21/02/17 01:15:39 INFO DAGScheduler: Final stage: ResultStage 3 (count at utils.scala:135)
21/02/17 01:15:39 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 2)
21/02/17 01:15:39 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 2)
21/02/17 01:15:39 INFO DAGScheduler: Submitting ShuffleMapStage 2 (MapPartitionsRDD[12] at count at utils.scala:135), which has no missing parents
21/02/17 01:15:39 INFO MemoryStore: Block broadcast_2 stored as values in memory (estimated size 8.9 KB, free 912.3 MB)
21/02/17 01:15:39 INFO MemoryStore: Block broadcast_2_piece0 stored as bytes in memory (estimated size 4.5 KB, free 912.3 MB)
21/02/17 01:15:39 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on localhost:42851 (size: 4.5 KB, free: 912.3 MB)
21/02/17 01:15:39 INFO SparkContext: Created broadcast 2 from broadcast at DAGScheduler.scala:1039
21/02/17 01:15:39 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 2 (MapPartitionsRDD[12] at count at utils.scala:135) (first 15 tasks are for partitions Vector(0))
21/02/17 01:15:39 INFO TaskSchedulerImpl: Adding task set 2.0 with 1 tasks
21/02/17 01:15:39 INFO TaskSetManager: Starting task 0.0 in stage 2.0 (TID 2, localhost, executor driver, partition 0, PROCESS_LOCAL, 8056 bytes)
21/02/17 01:15:39 INFO Executor: Running task 0.0 in stage 2.0 (TID 2)
21/02/17 01:15:39 INFO Executor: Finished task 0.0 in stage 2.0 (TID 2). 1499 bytes result sent to driver
21/02/17 01:15:39 INFO TaskSetManager: Finished task 0.0 in stage 2.0 (TID 2) in 28 ms on localhost (executor driver) (1/1)
21/02/17 01:15:39 INFO TaskSchedulerImpl: Removed TaskSet 2.0, whose tasks have all completed, from pool 
21/02/17 01:15:39 INFO DAGScheduler: ShuffleMapStage 2 (count at utils.scala:135) finished in 0.038 s
21/02/17 01:15:39 INFO DAGScheduler: looking for newly runnable stages
21/02/17 01:15:39 INFO DAGScheduler: running: Set()
21/02/17 01:15:39 INFO DAGScheduler: waiting: Set(ResultStage 3)
21/02/17 01:15:39 INFO DAGScheduler: failed: Set()
21/02/17 01:15:39 INFO DAGScheduler: Submitting ResultStage 3 (MapPartitionsRDD[15] at count at utils.scala:135), which has no missing parents
21/02/17 01:15:39 INFO MemoryStore: Block broadcast_3 stored as values in memory (estimated size 7.3 KB, free 912.3 MB)
21/02/17 01:15:39 INFO MemoryStore: Block broadcast_3_piece0 stored as bytes in memory (estimated size 3.8 KB, free 912.3 MB)
21/02/17 01:15:39 INFO BlockManagerInfo: Added broadcast_3_piece0 in memory on localhost:42851 (size: 3.8 KB, free: 912.3 MB)
21/02/17 01:15:39 INFO SparkContext: Created broadcast 3 from broadcast at DAGScheduler.scala:1039
21/02/17 01:15:39 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 3 (MapPartitionsRDD[15] at count at utils.scala:135) (first 15 tasks are for partitions Vector(0))
21/02/17 01:15:39 INFO TaskSchedulerImpl: Adding task set 3.0 with 1 tasks
21/02/17 01:15:39 INFO TaskSetManager: Starting task 0.0 in stage 3.0 (TID 3, localhost, executor driver, partition 0, NODE_LOCAL, 7754 bytes)
21/02/17 01:15:39 INFO Executor: Running task 0.0 in stage 3.0 (TID 3)
21/02/17 01:15:39 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
21/02/17 01:15:39 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 2 ms
21/02/17 01:15:39 INFO Executor: Finished task 0.0 in stage 3.0 (TID 3). 1782 bytes result sent to driver
21/02/17 01:15:39 INFO TaskSetManager: Finished task 0.0 in stage 3.0 (TID 3) in 22 ms on localhost (executor driver) (1/1)
21/02/17 01:15:39 INFO TaskSchedulerImpl: Removed TaskSet 3.0, whose tasks have all completed, from pool 
21/02/17 01:15:39 INFO DAGScheduler: ResultStage 3 (count at utils.scala:135) finished in 0.030 s
21/02/17 01:15:39 INFO DAGScheduler: Job 2 finished: count at utils.scala:135, took 0.083263 s
21/02/17 01:15:39 INFO SparkContext: Starting job: collect at utils.scala:135
21/02/17 01:15:39 INFO DAGScheduler: Got job 3 (collect at utils.scala:135) with 1 output partitions
21/02/17 01:15:39 INFO DAGScheduler: Final stage: ResultStage 4 (collect at utils.scala:135)
21/02/17 01:15:39 INFO DAGScheduler: Parents of final stage: List()
21/02/17 01:15:39 INFO DAGScheduler: Missing parents: List()
21/02/17 01:15:39 INFO DAGScheduler: Submitting ResultStage 4 (MapPartitionsRDD[20] at collect at utils.scala:135), which has no missing parents
21/02/17 01:15:39 INFO MemoryStore: Block broadcast_4 stored as values in memory (estimated size 6.4 KB, free 912.3 MB)
21/02/17 01:15:39 INFO MemoryStore: Block broadcast_4_piece0 stored as bytes in memory (estimated size 3.2 KB, free 912.3 MB)
21/02/17 01:15:39 INFO BlockManagerInfo: Added broadcast_4_piece0 in memory on localhost:42851 (size: 3.2 KB, free: 912.3 MB)
21/02/17 01:15:39 INFO SparkContext: Created broadcast 4 from broadcast at DAGScheduler.scala:1039
21/02/17 01:15:39 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 4 (MapPartitionsRDD[20] at collect at utils.scala:135) (first 15 tasks are for partitions Vector(0))
21/02/17 01:15:39 INFO TaskSchedulerImpl: Adding task set 4.0 with 1 tasks
21/02/17 01:15:39 INFO TaskSetManager: Starting task 0.0 in stage 4.0 (TID 4, localhost, executor driver, partition 0, PROCESS_LOCAL, 8067 bytes)
21/02/17 01:15:39 INFO Executor: Running task 0.0 in stage 4.0 (TID 4)
21/02/17 01:15:39 INFO Executor: Finished task 0.0 in stage 4.0 (TID 4). 1286 bytes result sent to driver
21/02/17 01:15:39 INFO TaskSetManager: Finished task 0.0 in stage 4.0 (TID 4) in 5 ms on localhost (executor driver) (1/1)
21/02/17 01:15:39 INFO TaskSchedulerImpl: Removed TaskSet 4.0, whose tasks have all completed, from pool 
21/02/17 01:15:39 INFO DAGScheduler: ResultStage 4 (collect at utils.scala:135) finished in 0.012 s
21/02/17 01:15:39 INFO DAGScheduler: Job 3 finished: collect at utils.scala:135, took 0.014765 s
21/02/17 01:15:39 INFO SparkContext: Starting job: count at utils.scala:135
21/02/17 01:15:39 INFO DAGScheduler: Registering RDD 23 (count at utils.scala:135)
21/02/17 01:15:39 INFO DAGScheduler: Got job 4 (count at utils.scala:135) with 1 output partitions
21/02/17 01:15:39 INFO DAGScheduler: Final stage: ResultStage 6 (count at utils.scala:135)
21/02/17 01:15:39 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 5)
21/02/17 01:15:39 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 5)
21/02/17 01:15:39 INFO DAGScheduler: Submitting ShuffleMapStage 5 (MapPartitionsRDD[23] at count at utils.scala:135), which has no missing parents
21/02/17 01:15:39 INFO MemoryStore: Block broadcast_5 stored as values in memory (estimated size 8.9 KB, free 912.2 MB)
21/02/17 01:15:39 INFO MemoryStore: Block broadcast_5_piece0 stored as bytes in memory (estimated size 4.5 KB, free 912.2 MB)
21/02/17 01:15:39 INFO BlockManagerInfo: Added broadcast_5_piece0 in memory on localhost:42851 (size: 4.5 KB, free: 912.3 MB)
21/02/17 01:15:39 INFO SparkContext: Created broadcast 5 from broadcast at DAGScheduler.scala:1039
21/02/17 01:15:39 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 5 (MapPartitionsRDD[23] at count at utils.scala:135) (first 15 tasks are for partitions Vector(0))
21/02/17 01:15:39 INFO TaskSchedulerImpl: Adding task set 5.0 with 1 tasks
21/02/17 01:15:39 INFO TaskSetManager: Starting task 0.0 in stage 5.0 (TID 5, localhost, executor driver, partition 0, PROCESS_LOCAL, 8056 bytes)
21/02/17 01:15:39 INFO Executor: Running task 0.0 in stage 5.0 (TID 5)
21/02/17 01:15:39 INFO Executor: Finished task 0.0 in stage 5.0 (TID 5). 1499 bytes result sent to driver
21/02/17 01:15:39 INFO TaskSetManager: Finished task 0.0 in stage 5.0 (TID 5) in 7 ms on localhost (executor driver) (1/1)
21/02/17 01:15:39 INFO TaskSchedulerImpl: Removed TaskSet 5.0, whose tasks have all completed, from pool 
21/02/17 01:15:39 INFO DAGScheduler: ShuffleMapStage 5 (count at utils.scala:135) finished in 0.015 s
21/02/17 01:15:39 INFO DAGScheduler: looking for newly runnable stages
21/02/17 01:15:39 INFO DAGScheduler: running: Set()
21/02/17 01:15:39 INFO DAGScheduler: waiting: Set(ResultStage 6)
21/02/17 01:15:39 INFO DAGScheduler: failed: Set()
21/02/17 01:15:39 INFO DAGScheduler: Submitting ResultStage 6 (MapPartitionsRDD[26] at count at utils.scala:135), which has no missing parents
21/02/17 01:15:39 INFO MemoryStore: Block broadcast_6 stored as values in memory (estimated size 7.3 KB, free 912.2 MB)
21/02/17 01:15:39 INFO MemoryStore: Block broadcast_6_piece0 stored as bytes in memory (estimated size 3.8 KB, free 912.2 MB)
21/02/17 01:15:39 INFO BlockManagerInfo: Added broadcast_6_piece0 in memory on localhost:42851 (size: 3.8 KB, free: 912.3 MB)
21/02/17 01:15:39 INFO SparkContext: Created broadcast 6 from broadcast at DAGScheduler.scala:1039
21/02/17 01:15:39 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 6 (MapPartitionsRDD[26] at count at utils.scala:135) (first 15 tasks are for partitions Vector(0))
21/02/17 01:15:39 INFO TaskSchedulerImpl: Adding task set 6.0 with 1 tasks
21/02/17 01:15:39 INFO TaskSetManager: Starting task 0.0 in stage 6.0 (TID 6, localhost, executor driver, partition 0, NODE_LOCAL, 7754 bytes)
21/02/17 01:15:39 INFO Executor: Running task 0.0 in stage 6.0 (TID 6)
21/02/17 01:15:39 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
21/02/17 01:15:39 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
21/02/17 01:15:39 INFO Executor: Finished task 0.0 in stage 6.0 (TID 6). 1782 bytes result sent to driver
21/02/17 01:15:39 INFO TaskSetManager: Finished task 0.0 in stage 6.0 (TID 6) in 5 ms on localhost (executor driver) (1/1)
21/02/17 01:15:39 INFO TaskSchedulerImpl: Removed TaskSet 6.0, whose tasks have all completed, from pool 
21/02/17 01:15:39 INFO DAGScheduler: ResultStage 6 (count at utils.scala:135) finished in 0.012 s
21/02/17 01:15:39 INFO DAGScheduler: Job 4 finished: count at utils.scala:135, took 0.030351 s
21/02/17 01:15:41 INFO SparkContext: Invoking stop() from shutdown hook
21/02/17 01:15:41 INFO SparkUI: Stopped Spark web UI at http://localhost:4040
21/02/17 01:15:41 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!
21/02/17 01:15:41 INFO MemoryStore: MemoryStore cleared
21/02/17 01:15:41 INFO BlockManager: BlockManager stopped
21/02/17 01:15:41 INFO BlockManagerMaster: BlockManagerMaster stopped
21/02/17 01:15:41 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!
21/02/17 01:15:41 INFO SparkContext: Successfully stopped SparkContext
21/02/17 01:15:41 INFO ShutdownHookManager: Shutdown hook called
21/02/17 01:15:41 INFO ShutdownHookManager: Deleting directory /tmp/spark-cd065985-8543-4f0e-8504-d73b7cbcaf1b
21/02/17 01:15:41 INFO ShutdownHookManager: Deleting directory /tmp/spark-dd4b4c85-bd3e-4322-b5f3-bbb7bcd2afd9
21/02/17 01:16:26 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
21/02/17 01:16:26 INFO SparkContext: Running Spark version 2.3.0
21/02/17 01:16:26 INFO SparkContext: Submitted application: sparklyr
21/02/17 01:16:26 INFO SecurityManager: Changing view acls to: yitaoli
21/02/17 01:16:26 INFO SecurityManager: Changing modify acls to: yitaoli
21/02/17 01:16:26 INFO SecurityManager: Changing view acls groups to: 
21/02/17 01:16:26 INFO SecurityManager: Changing modify acls groups to: 
21/02/17 01:16:26 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(yitaoli); groups with view permissions: Set(); users  with modify permissions: Set(yitaoli); groups with modify permissions: Set()
21/02/17 01:16:26 INFO Utils: Successfully started service 'sparkDriver' on port 36161.
21/02/17 01:16:26 INFO SparkEnv: Registering MapOutputTracker
21/02/17 01:16:26 INFO SparkEnv: Registering BlockManagerMaster
21/02/17 01:16:27 INFO BlockManagerMasterEndpoint: Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
21/02/17 01:16:27 INFO BlockManagerMasterEndpoint: BlockManagerMasterEndpoint up
21/02/17 01:16:27 INFO DiskBlockManager: Created local directory at /tmp/blockmgr-a1884550-d3b0-4930-9e76-e6cf34e488ed
21/02/17 01:16:27 INFO MemoryStore: MemoryStore started with capacity 912.3 MB
21/02/17 01:16:27 INFO SparkEnv: Registering OutputCommitCoordinator
21/02/17 01:16:27 INFO Utils: Successfully started service 'SparkUI' on port 4040.
21/02/17 01:16:27 INFO SparkUI: Bound SparkUI to 127.0.0.1, and started at http://localhost:4040
21/02/17 01:16:27 INFO SparkContext: Added JAR file:///home/yitaoli/R/x86_64-pc-linux-gnu-library/4.0/sparkxgb/java/sparkxgb-2.3-2.11.jar at spark://localhost:36161/jars/sparkxgb-2.3-2.11.jar with timestamp 1613524587268
21/02/17 01:16:27 INFO SparkContext: Added JAR file:/home/yitaoli/R/x86_64-pc-linux-gnu-library/4.0/sparklyr/java/sparklyr-2.3-2.11.jar at spark://localhost:36161/jars/sparklyr-2.3-2.11.jar with timestamp 1613524587269
21/02/17 01:16:27 INFO Executor: Starting executor ID driver on host localhost
21/02/17 01:16:27 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 32921.
21/02/17 01:16:27 INFO NettyBlockTransferService: Server created on localhost:32921
21/02/17 01:16:27 INFO BlockManager: Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
21/02/17 01:16:27 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, localhost, 32921, None)
21/02/17 01:16:27 INFO BlockManagerMasterEndpoint: Registering block manager localhost:32921 with 912.3 MB RAM, BlockManagerId(driver, localhost, 32921, None)
21/02/17 01:16:27 INFO BlockManagerMaster: Registered BlockManager BlockManagerId(driver, localhost, 32921, None)
21/02/17 01:16:27 INFO BlockManager: Initialized BlockManager: BlockManagerId(driver, localhost, 32921, None)
21/02/17 01:16:27 INFO SharedState: loading hive config file: file:/home/yitaoli/spark/spark-2.3.0-bin-hadoop2.7/conf/hive-site.xml
21/02/17 01:16:27 INFO SharedState: Setting hive.metastore.warehouse.dir ('null') to the value of spark.sql.warehouse.dir ('file:/home/yitaoli/sparkxgb/tests/testthat/spark-warehouse').
21/02/17 01:16:27 INFO SharedState: Warehouse path is 'file:/home/yitaoli/sparkxgb/tests/testthat/spark-warehouse'.
21/02/17 01:16:27 INFO StateStoreCoordinatorRef: Registered StateStoreCoordinator endpoint
21/02/17 01:16:28 INFO HiveUtils: Initializing HiveMetastoreConnection version 1.2.1 using Spark classes.
21/02/17 01:16:29 INFO HiveMetaStore: 0: Opening raw store with implemenation class:org.apache.hadoop.hive.metastore.ObjectStore
21/02/17 01:16:29 INFO ObjectStore: ObjectStore, initialize called
21/02/17 01:16:29 INFO Persistence: Property hive.metastore.integral.jdo.pushdown unknown - will be ignored
21/02/17 01:16:29 INFO Persistence: Property datanucleus.cache.level2 unknown - will be ignored
21/02/17 01:16:30 INFO ObjectStore: Setting MetaStore object pin classes with hive.metastore.cache.pinobjtypes="Table,StorageDescriptor,SerDeInfo,Partition,Database,Type,FieldSchema,Order"
21/02/17 01:16:31 INFO Datastore: The class "org.apache.hadoop.hive.metastore.model.MFieldSchema" is tagged as "embedded-only" so does not have its own datastore table.
21/02/17 01:16:31 INFO Datastore: The class "org.apache.hadoop.hive.metastore.model.MOrder" is tagged as "embedded-only" so does not have its own datastore table.
21/02/17 01:16:31 INFO Datastore: The class "org.apache.hadoop.hive.metastore.model.MFieldSchema" is tagged as "embedded-only" so does not have its own datastore table.
21/02/17 01:16:31 INFO Datastore: The class "org.apache.hadoop.hive.metastore.model.MOrder" is tagged as "embedded-only" so does not have its own datastore table.
21/02/17 01:16:31 INFO MetaStoreDirectSql: Using direct SQL, underlying DB is DERBY
21/02/17 01:16:31 INFO ObjectStore: Initialized ObjectStore
21/02/17 01:16:31 WARN ObjectStore: Version information not found in metastore. hive.metastore.schema.verification is not enabled so recording the schema version 1.2.0
21/02/17 01:16:31 WARN ObjectStore: Failed to get database default, returning NoSuchObjectException
21/02/17 01:16:31 INFO HiveMetaStore: Added admin role in metastore
21/02/17 01:16:31 INFO HiveMetaStore: Added public role in metastore
21/02/17 01:16:31 INFO HiveMetaStore: No user is added in admin role, since config is empty
21/02/17 01:16:31 INFO HiveMetaStore: 0: get_all_databases
21/02/17 01:16:31 INFO audit: ugi=yitaoli	ip=unknown-ip-addr	cmd=get_all_databases	
21/02/17 01:16:31 INFO HiveMetaStore: 0: get_functions: db=default pat=*
21/02/17 01:16:31 INFO audit: ugi=yitaoli	ip=unknown-ip-addr	cmd=get_functions: db=default pat=*	
21/02/17 01:16:31 INFO Datastore: The class "org.apache.hadoop.hive.metastore.model.MResourceUri" is tagged as "embedded-only" so does not have its own datastore table.
21/02/17 01:16:31 INFO SessionState: Created local directory: /tmp/2e457ce5-de0a-4372-a286-e2a6c1b0041f_resources
21/02/17 01:16:31 INFO SessionState: Created HDFS directory: /tmp/hive/yitaoli/2e457ce5-de0a-4372-a286-e2a6c1b0041f
21/02/17 01:16:31 INFO SessionState: Created local directory: /tmp/yitaoli/2e457ce5-de0a-4372-a286-e2a6c1b0041f
21/02/17 01:16:31 INFO SessionState: Created HDFS directory: /tmp/hive/yitaoli/2e457ce5-de0a-4372-a286-e2a6c1b0041f/_tmp_space.db
21/02/17 01:16:31 INFO HiveClientImpl: Warehouse location for Hive client (version 1.2.2) is file:/home/yitaoli/sparkxgb/tests/testthat/spark-warehouse
21/02/17 01:16:31 INFO HiveMetaStore: 0: get_database: default
21/02/17 01:16:31 INFO audit: ugi=yitaoli	ip=unknown-ip-addr	cmd=get_database: default	
21/02/17 01:16:31 INFO HiveMetaStore: 0: get_database: global_temp
21/02/17 01:16:31 INFO audit: ugi=yitaoli	ip=unknown-ip-addr	cmd=get_database: global_temp	
21/02/17 01:16:31 WARN ObjectStore: Failed to get database global_temp, returning NoSuchObjectException
21/02/17 01:16:32 INFO HiveMetaStore: 0: get_table : db=default tbl=iris
21/02/17 01:16:32 INFO audit: ugi=yitaoli	ip=unknown-ip-addr	cmd=get_table : db=default tbl=iris	
21/02/17 01:16:32 INFO HiveMetaStore: 0: get_database: default
21/02/17 01:16:32 INFO audit: ugi=yitaoli	ip=unknown-ip-addr	cmd=get_database: default	
21/02/17 01:16:32 INFO HiveMetaStore: 0: get_database: default
21/02/17 01:16:32 INFO audit: ugi=yitaoli	ip=unknown-ip-addr	cmd=get_database: default	
21/02/17 01:16:32 INFO HiveMetaStore: 0: get_tables: db=default pat=*
21/02/17 01:16:32 INFO audit: ugi=yitaoli	ip=unknown-ip-addr	cmd=get_tables: db=default pat=*	
21/02/17 01:16:32 INFO SparkContext: Starting job: collect at utils.scala:61
21/02/17 01:16:32 INFO DAGScheduler: Got job 0 (collect at utils.scala:61) with 1 output partitions
21/02/17 01:16:32 INFO DAGScheduler: Final stage: ResultStage 0 (collect at utils.scala:61)
21/02/17 01:16:32 INFO DAGScheduler: Parents of final stage: List()
21/02/17 01:16:32 INFO DAGScheduler: Missing parents: List()
21/02/17 01:16:32 INFO DAGScheduler: Submitting ResultStage 0 (MapPartitionsRDD[4] at map at utils.scala:54), which has no missing parents
21/02/17 01:16:32 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 5.9 KB, free 912.3 MB)
21/02/17 01:16:32 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 3.3 KB, free 912.3 MB)
21/02/17 01:16:32 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on localhost:32921 (size: 3.3 KB, free: 912.3 MB)
21/02/17 01:16:32 INFO SparkContext: Created broadcast 0 from broadcast at DAGScheduler.scala:1039
21/02/17 01:16:32 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 0 (MapPartitionsRDD[4] at map at utils.scala:54) (first 15 tasks are for partitions Vector(0))
21/02/17 01:16:32 INFO TaskSchedulerImpl: Adding task set 0.0 with 1 tasks
21/02/17 01:16:32 INFO TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0, localhost, executor driver, partition 0, PROCESS_LOCAL, 7880 bytes)
21/02/17 01:16:32 INFO Executor: Running task 0.0 in stage 0.0 (TID 0)
21/02/17 01:16:32 INFO Executor: Fetching spark://localhost:36161/jars/sparkxgb-2.3-2.11.jar with timestamp 1613524587268
21/02/17 01:16:32 INFO TransportClientFactory: Successfully created connection to localhost/127.0.0.1:36161 after 10 ms (0 ms spent in bootstraps)
21/02/17 01:16:32 INFO Utils: Fetching spark://localhost:36161/jars/sparkxgb-2.3-2.11.jar to /tmp/spark-f0718f16-2150-4a40-8bc7-976d2e241f53/userFiles-5a0bfff0-5c49-4c19-8a03-9a910bd54e9e/fetchFileTemp3368749715501862816.tmp
21/02/17 01:16:32 INFO Executor: Adding file:/tmp/spark-f0718f16-2150-4a40-8bc7-976d2e241f53/userFiles-5a0bfff0-5c49-4c19-8a03-9a910bd54e9e/sparkxgb-2.3-2.11.jar to class loader
21/02/17 01:16:32 INFO Executor: Fetching spark://localhost:36161/jars/sparklyr-2.3-2.11.jar with timestamp 1613524587269
21/02/17 01:16:32 INFO Utils: Fetching spark://localhost:36161/jars/sparklyr-2.3-2.11.jar to /tmp/spark-f0718f16-2150-4a40-8bc7-976d2e241f53/userFiles-5a0bfff0-5c49-4c19-8a03-9a910bd54e9e/fetchFileTemp9151605645577288566.tmp
21/02/17 01:16:32 INFO Executor: Adding file:/tmp/spark-f0718f16-2150-4a40-8bc7-976d2e241f53/userFiles-5a0bfff0-5c49-4c19-8a03-9a910bd54e9e/sparklyr-2.3-2.11.jar to class loader
21/02/17 01:16:33 INFO CodeGenerator: Code generated in 140.097622 ms
21/02/17 01:16:33 INFO Executor: Finished task 0.0 in stage 0.0 (TID 0). 970 bytes result sent to driver
21/02/17 01:16:33 INFO TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in 322 ms on localhost (executor driver) (1/1)
21/02/17 01:16:33 INFO TaskSchedulerImpl: Removed TaskSet 0.0, whose tasks have all completed, from pool 
21/02/17 01:16:33 INFO DAGScheduler: ResultStage 0 (collect at utils.scala:61) finished in 0.443 s
21/02/17 01:16:33 INFO DAGScheduler: Job 0 finished: collect at utils.scala:61, took 0.489176 s
21/02/17 01:16:33 INFO BlockManagerInfo: Removed broadcast_0_piece0 on localhost:32921 in memory (size: 3.3 KB, free: 912.3 MB)
21/02/17 01:16:33 INFO ContextCleaner: Cleaned accumulator 13
21/02/17 01:16:33 INFO ContextCleaner: Cleaned accumulator 6
21/02/17 01:16:33 INFO ContextCleaner: Cleaned accumulator 19
21/02/17 01:16:33 INFO ContextCleaner: Cleaned accumulator 7
21/02/17 01:16:33 INFO ContextCleaner: Cleaned accumulator 12
21/02/17 01:16:33 INFO ContextCleaner: Cleaned accumulator 2
21/02/17 01:16:33 INFO ContextCleaner: Cleaned accumulator 20
21/02/17 01:16:33 INFO ContextCleaner: Cleaned accumulator 9
21/02/17 01:16:33 INFO ContextCleaner: Cleaned accumulator 3
21/02/17 01:16:33 INFO ContextCleaner: Cleaned accumulator 24
21/02/17 01:16:33 INFO ContextCleaner: Cleaned accumulator 5
21/02/17 01:16:33 INFO ContextCleaner: Cleaned accumulator 4
21/02/17 01:16:33 INFO ContextCleaner: Cleaned accumulator 11
21/02/17 01:16:33 INFO ContextCleaner: Cleaned accumulator 18
21/02/17 01:16:33 INFO ContextCleaner: Cleaned accumulator 0
21/02/17 01:16:33 INFO ContextCleaner: Cleaned accumulator 22
21/02/17 01:16:33 INFO ContextCleaner: Cleaned accumulator 15
21/02/17 01:16:33 INFO ContextCleaner: Cleaned accumulator 14
21/02/17 01:16:33 INFO ContextCleaner: Cleaned accumulator 25
21/02/17 01:16:33 INFO ContextCleaner: Cleaned accumulator 1
21/02/17 01:16:33 INFO ContextCleaner: Cleaned accumulator 21
21/02/17 01:16:33 INFO ContextCleaner: Cleaned accumulator 23
21/02/17 01:16:33 INFO ContextCleaner: Cleaned accumulator 17
21/02/17 01:16:33 INFO ContextCleaner: Cleaned accumulator 10
21/02/17 01:16:33 INFO ContextCleaner: Cleaned accumulator 8
21/02/17 01:16:33 INFO ContextCleaner: Cleaned accumulator 16
21/02/17 01:16:33 INFO CodeGenerator: Code generated in 9.088835 ms
21/02/17 01:16:33 INFO CodeGenerator: Code generated in 11.489001 ms
21/02/17 01:16:33 INFO SparkContext: Starting job: collect at utils.scala:135
21/02/17 01:16:33 INFO DAGScheduler: Got job 1 (collect at utils.scala:135) with 1 output partitions
21/02/17 01:16:33 INFO DAGScheduler: Final stage: ResultStage 1 (collect at utils.scala:135)
21/02/17 01:16:33 INFO DAGScheduler: Parents of final stage: List()
21/02/17 01:16:33 INFO DAGScheduler: Missing parents: List()
21/02/17 01:16:33 INFO DAGScheduler: Submitting ResultStage 1 (MapPartitionsRDD[9] at collect at utils.scala:135), which has no missing parents
21/02/17 01:16:33 INFO MemoryStore: Block broadcast_1 stored as values in memory (estimated size 6.4 KB, free 912.3 MB)
21/02/17 01:16:33 INFO MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 3.2 KB, free 912.3 MB)
21/02/17 01:16:33 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on localhost:32921 (size: 3.2 KB, free: 912.3 MB)
21/02/17 01:16:33 INFO SparkContext: Created broadcast 1 from broadcast at DAGScheduler.scala:1039
21/02/17 01:16:33 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 1 (MapPartitionsRDD[9] at collect at utils.scala:135) (first 15 tasks are for partitions Vector(0))
21/02/17 01:16:33 INFO TaskSchedulerImpl: Adding task set 1.0 with 1 tasks
21/02/17 01:16:33 INFO TaskSetManager: Starting task 0.0 in stage 1.0 (TID 1, localhost, executor driver, partition 0, PROCESS_LOCAL, 8067 bytes)
21/02/17 01:16:33 INFO Executor: Running task 0.0 in stage 1.0 (TID 1)
21/02/17 01:16:33 INFO CodeGenerator: Code generated in 6.25478 ms
21/02/17 01:16:33 INFO Executor: Finished task 0.0 in stage 1.0 (TID 1). 1329 bytes result sent to driver
21/02/17 01:16:33 INFO TaskSetManager: Finished task 0.0 in stage 1.0 (TID 1) in 21 ms on localhost (executor driver) (1/1)
21/02/17 01:16:33 INFO TaskSchedulerImpl: Removed TaskSet 1.0, whose tasks have all completed, from pool 
21/02/17 01:16:33 INFO DAGScheduler: ResultStage 1 (collect at utils.scala:135) finished in 0.029 s
21/02/17 01:16:33 INFO DAGScheduler: Job 1 finished: collect at utils.scala:135, took 0.032173 s
21/02/17 01:16:33 INFO CodeGenerator: Code generated in 15.992722 ms
21/02/17 01:16:33 INFO CodeGenerator: Code generated in 12.941756 ms
21/02/17 01:16:33 INFO SparkContext: Starting job: count at utils.scala:135
21/02/17 01:16:33 INFO DAGScheduler: Registering RDD 12 (count at utils.scala:135)
21/02/17 01:16:33 INFO DAGScheduler: Got job 2 (count at utils.scala:135) with 1 output partitions
21/02/17 01:16:33 INFO DAGScheduler: Final stage: ResultStage 3 (count at utils.scala:135)
21/02/17 01:16:33 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 2)
21/02/17 01:16:33 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 2)
21/02/17 01:16:33 INFO DAGScheduler: Submitting ShuffleMapStage 2 (MapPartitionsRDD[12] at count at utils.scala:135), which has no missing parents
21/02/17 01:16:33 INFO MemoryStore: Block broadcast_2 stored as values in memory (estimated size 8.9 KB, free 912.3 MB)
21/02/17 01:16:33 INFO MemoryStore: Block broadcast_2_piece0 stored as bytes in memory (estimated size 4.5 KB, free 912.3 MB)
21/02/17 01:16:33 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on localhost:32921 (size: 4.5 KB, free: 912.3 MB)
21/02/17 01:16:33 INFO SparkContext: Created broadcast 2 from broadcast at DAGScheduler.scala:1039
21/02/17 01:16:33 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 2 (MapPartitionsRDD[12] at count at utils.scala:135) (first 15 tasks are for partitions Vector(0))
21/02/17 01:16:33 INFO TaskSchedulerImpl: Adding task set 2.0 with 1 tasks
21/02/17 01:16:33 INFO TaskSetManager: Starting task 0.0 in stage 2.0 (TID 2, localhost, executor driver, partition 0, PROCESS_LOCAL, 8056 bytes)
21/02/17 01:16:33 INFO Executor: Running task 0.0 in stage 2.0 (TID 2)
21/02/17 01:16:33 INFO Executor: Finished task 0.0 in stage 2.0 (TID 2). 1542 bytes result sent to driver
21/02/17 01:16:33 INFO TaskSetManager: Finished task 0.0 in stage 2.0 (TID 2) in 25 ms on localhost (executor driver) (1/1)
21/02/17 01:16:33 INFO TaskSchedulerImpl: Removed TaskSet 2.0, whose tasks have all completed, from pool 
21/02/17 01:16:33 INFO DAGScheduler: ShuffleMapStage 2 (count at utils.scala:135) finished in 0.035 s
21/02/17 01:16:33 INFO DAGScheduler: looking for newly runnable stages
21/02/17 01:16:33 INFO DAGScheduler: running: Set()
21/02/17 01:16:33 INFO DAGScheduler: waiting: Set(ResultStage 3)
21/02/17 01:16:33 INFO DAGScheduler: failed: Set()
21/02/17 01:16:33 INFO DAGScheduler: Submitting ResultStage 3 (MapPartitionsRDD[15] at count at utils.scala:135), which has no missing parents
21/02/17 01:16:33 INFO MemoryStore: Block broadcast_3 stored as values in memory (estimated size 7.3 KB, free 912.3 MB)
21/02/17 01:16:33 INFO MemoryStore: Block broadcast_3_piece0 stored as bytes in memory (estimated size 3.8 KB, free 912.3 MB)
21/02/17 01:16:33 INFO BlockManagerInfo: Added broadcast_3_piece0 in memory on localhost:32921 (size: 3.8 KB, free: 912.3 MB)
21/02/17 01:16:33 INFO SparkContext: Created broadcast 3 from broadcast at DAGScheduler.scala:1039
21/02/17 01:16:33 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 3 (MapPartitionsRDD[15] at count at utils.scala:135) (first 15 tasks are for partitions Vector(0))
21/02/17 01:16:33 INFO TaskSchedulerImpl: Adding task set 3.0 with 1 tasks
21/02/17 01:16:33 INFO TaskSetManager: Starting task 0.0 in stage 3.0 (TID 3, localhost, executor driver, partition 0, NODE_LOCAL, 7754 bytes)
21/02/17 01:16:33 INFO Executor: Running task 0.0 in stage 3.0 (TID 3)
21/02/17 01:16:33 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
21/02/17 01:16:33 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 3 ms
21/02/17 01:16:33 INFO Executor: Finished task 0.0 in stage 3.0 (TID 3). 1782 bytes result sent to driver
21/02/17 01:16:33 INFO TaskSetManager: Finished task 0.0 in stage 3.0 (TID 3) in 22 ms on localhost (executor driver) (1/1)
21/02/17 01:16:33 INFO TaskSchedulerImpl: Removed TaskSet 3.0, whose tasks have all completed, from pool 
21/02/17 01:16:33 INFO DAGScheduler: ResultStage 3 (count at utils.scala:135) finished in 0.029 s
21/02/17 01:16:33 INFO DAGScheduler: Job 2 finished: count at utils.scala:135, took 0.076926 s
21/02/17 01:16:34 INFO SparkContext: Starting job: collect at utils.scala:135
21/02/17 01:16:34 INFO DAGScheduler: Got job 3 (collect at utils.scala:135) with 1 output partitions
21/02/17 01:16:34 INFO DAGScheduler: Final stage: ResultStage 4 (collect at utils.scala:135)
21/02/17 01:16:34 INFO DAGScheduler: Parents of final stage: List()
21/02/17 01:16:34 INFO DAGScheduler: Missing parents: List()
21/02/17 01:16:34 INFO DAGScheduler: Submitting ResultStage 4 (MapPartitionsRDD[20] at collect at utils.scala:135), which has no missing parents
21/02/17 01:16:34 INFO MemoryStore: Block broadcast_4 stored as values in memory (estimated size 6.4 KB, free 912.3 MB)
21/02/17 01:16:34 INFO MemoryStore: Block broadcast_4_piece0 stored as bytes in memory (estimated size 3.2 KB, free 912.3 MB)
21/02/17 01:16:34 INFO BlockManagerInfo: Added broadcast_4_piece0 in memory on localhost:32921 (size: 3.2 KB, free: 912.3 MB)
21/02/17 01:16:34 INFO SparkContext: Created broadcast 4 from broadcast at DAGScheduler.scala:1039
21/02/17 01:16:34 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 4 (MapPartitionsRDD[20] at collect at utils.scala:135) (first 15 tasks are for partitions Vector(0))
21/02/17 01:16:34 INFO TaskSchedulerImpl: Adding task set 4.0 with 1 tasks
21/02/17 01:16:34 INFO TaskSetManager: Starting task 0.0 in stage 4.0 (TID 4, localhost, executor driver, partition 0, PROCESS_LOCAL, 8067 bytes)
21/02/17 01:16:34 INFO Executor: Running task 0.0 in stage 4.0 (TID 4)
21/02/17 01:16:34 INFO Executor: Finished task 0.0 in stage 4.0 (TID 4). 1286 bytes result sent to driver
21/02/17 01:16:34 INFO TaskSetManager: Finished task 0.0 in stage 4.0 (TID 4) in 6 ms on localhost (executor driver) (1/1)
21/02/17 01:16:34 INFO TaskSchedulerImpl: Removed TaskSet 4.0, whose tasks have all completed, from pool 
21/02/17 01:16:34 INFO DAGScheduler: ResultStage 4 (collect at utils.scala:135) finished in 0.011 s
21/02/17 01:16:34 INFO DAGScheduler: Job 3 finished: collect at utils.scala:135, took 0.013119 s
21/02/17 01:16:34 INFO SparkContext: Starting job: count at utils.scala:135
21/02/17 01:16:34 INFO DAGScheduler: Registering RDD 23 (count at utils.scala:135)
21/02/17 01:16:34 INFO DAGScheduler: Got job 4 (count at utils.scala:135) with 1 output partitions
21/02/17 01:16:34 INFO DAGScheduler: Final stage: ResultStage 6 (count at utils.scala:135)
21/02/17 01:16:34 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 5)
21/02/17 01:16:34 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 5)
21/02/17 01:16:34 INFO DAGScheduler: Submitting ShuffleMapStage 5 (MapPartitionsRDD[23] at count at utils.scala:135), which has no missing parents
21/02/17 01:16:34 INFO MemoryStore: Block broadcast_5 stored as values in memory (estimated size 8.9 KB, free 912.2 MB)
21/02/17 01:16:34 INFO MemoryStore: Block broadcast_5_piece0 stored as bytes in memory (estimated size 4.5 KB, free 912.2 MB)
21/02/17 01:16:34 INFO BlockManagerInfo: Added broadcast_5_piece0 in memory on localhost:32921 (size: 4.5 KB, free: 912.3 MB)
21/02/17 01:16:34 INFO SparkContext: Created broadcast 5 from broadcast at DAGScheduler.scala:1039
21/02/17 01:16:34 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 5 (MapPartitionsRDD[23] at count at utils.scala:135) (first 15 tasks are for partitions Vector(0))
21/02/17 01:16:34 INFO TaskSchedulerImpl: Adding task set 5.0 with 1 tasks
21/02/17 01:16:34 INFO TaskSetManager: Starting task 0.0 in stage 5.0 (TID 5, localhost, executor driver, partition 0, PROCESS_LOCAL, 8056 bytes)
21/02/17 01:16:34 INFO Executor: Running task 0.0 in stage 5.0 (TID 5)
21/02/17 01:16:34 INFO Executor: Finished task 0.0 in stage 5.0 (TID 5). 1499 bytes result sent to driver
21/02/17 01:16:34 INFO TaskSetManager: Finished task 0.0 in stage 5.0 (TID 5) in 7 ms on localhost (executor driver) (1/1)
21/02/17 01:16:34 INFO TaskSchedulerImpl: Removed TaskSet 5.0, whose tasks have all completed, from pool 
21/02/17 01:16:34 INFO DAGScheduler: ShuffleMapStage 5 (count at utils.scala:135) finished in 0.013 s
21/02/17 01:16:34 INFO DAGScheduler: looking for newly runnable stages
21/02/17 01:16:34 INFO DAGScheduler: running: Set()
21/02/17 01:16:34 INFO DAGScheduler: waiting: Set(ResultStage 6)
21/02/17 01:16:34 INFO DAGScheduler: failed: Set()
21/02/17 01:16:34 INFO DAGScheduler: Submitting ResultStage 6 (MapPartitionsRDD[26] at count at utils.scala:135), which has no missing parents
21/02/17 01:16:34 INFO MemoryStore: Block broadcast_6 stored as values in memory (estimated size 7.3 KB, free 912.2 MB)
21/02/17 01:16:34 INFO MemoryStore: Block broadcast_6_piece0 stored as bytes in memory (estimated size 3.8 KB, free 912.2 MB)
21/02/17 01:16:34 INFO BlockManagerInfo: Added broadcast_6_piece0 in memory on localhost:32921 (size: 3.8 KB, free: 912.3 MB)
21/02/17 01:16:34 INFO SparkContext: Created broadcast 6 from broadcast at DAGScheduler.scala:1039
21/02/17 01:16:34 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 6 (MapPartitionsRDD[26] at count at utils.scala:135) (first 15 tasks are for partitions Vector(0))
21/02/17 01:16:34 INFO TaskSchedulerImpl: Adding task set 6.0 with 1 tasks
21/02/17 01:16:34 INFO TaskSetManager: Starting task 0.0 in stage 6.0 (TID 6, localhost, executor driver, partition 0, NODE_LOCAL, 7754 bytes)
21/02/17 01:16:34 INFO Executor: Running task 0.0 in stage 6.0 (TID 6)
21/02/17 01:16:34 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
21/02/17 01:16:34 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
21/02/17 01:16:34 INFO Executor: Finished task 0.0 in stage 6.0 (TID 6). 1782 bytes result sent to driver
21/02/17 01:16:34 INFO TaskSetManager: Finished task 0.0 in stage 6.0 (TID 6) in 5 ms on localhost (executor driver) (1/1)
21/02/17 01:16:34 INFO TaskSchedulerImpl: Removed TaskSet 6.0, whose tasks have all completed, from pool 
21/02/17 01:16:34 INFO DAGScheduler: ResultStage 6 (count at utils.scala:135) finished in 0.011 s
21/02/17 01:16:34 INFO DAGScheduler: Job 4 finished: count at utils.scala:135, took 0.028551 s
21/02/17 01:16:35 INFO SparkContext: Invoking stop() from shutdown hook
21/02/17 01:16:35 INFO SparkUI: Stopped Spark web UI at http://localhost:4040
21/02/17 01:16:35 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!
21/02/17 01:16:35 INFO MemoryStore: MemoryStore cleared
21/02/17 01:16:35 INFO BlockManager: BlockManager stopped
21/02/17 01:16:35 INFO BlockManagerMaster: BlockManagerMaster stopped
21/02/17 01:16:35 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!
21/02/17 01:16:35 INFO SparkContext: Successfully stopped SparkContext
21/02/17 01:16:35 INFO ShutdownHookManager: Shutdown hook called
21/02/17 01:16:35 INFO ShutdownHookManager: Deleting directory /tmp/spark-82fad1a5-8bd0-4af3-8e8d-dd525ad961b7
21/02/17 01:16:35 INFO ShutdownHookManager: Deleting directory /tmp/spark-f0718f16-2150-4a40-8bc7-976d2e241f53
21/02/17 01:17:01 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
21/02/17 01:17:01 INFO SecurityManager: Changing view acls to: yitaoli
21/02/17 01:17:01 INFO SecurityManager: Changing modify acls to: yitaoli
21/02/17 01:17:01 INFO SecurityManager: Changing view acls groups to: 
21/02/17 01:17:01 INFO SecurityManager: Changing modify acls groups to: 
21/02/17 01:17:01 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(yitaoli); groups with view permissions: Set(); users  with modify permissions: Set(yitaoli); groups with modify permissions: Set()
21/02/17 01:17:02 INFO HiveConf: Found configuration file file:/home/yitaoli/spark/spark-3.0.0-bin-hadoop3.2/conf/hive-site.xml
21/02/17 01:17:02 INFO SparkContext: Running Spark version 3.0.0
21/02/17 01:17:02 INFO ResourceUtils: ==============================================================
21/02/17 01:17:02 INFO ResourceUtils: Resources for spark.driver:

21/02/17 01:17:02 INFO ResourceUtils: ==============================================================
21/02/17 01:17:02 INFO SparkContext: Submitted application: sparklyr
21/02/17 01:17:02 INFO SecurityManager: Changing view acls to: yitaoli
21/02/17 01:17:02 INFO SecurityManager: Changing modify acls to: yitaoli
21/02/17 01:17:02 INFO SecurityManager: Changing view acls groups to: 
21/02/17 01:17:02 INFO SecurityManager: Changing modify acls groups to: 
21/02/17 01:17:02 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(yitaoli); groups with view permissions: Set(); users  with modify permissions: Set(yitaoli); groups with modify permissions: Set()
21/02/17 01:17:02 INFO Utils: Successfully started service 'sparkDriver' on port 44505.
21/02/17 01:17:02 INFO SparkEnv: Registering MapOutputTracker
21/02/17 01:17:02 INFO SparkEnv: Registering BlockManagerMaster
21/02/17 01:17:02 INFO BlockManagerMasterEndpoint: Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
21/02/17 01:17:02 INFO BlockManagerMasterEndpoint: BlockManagerMasterEndpoint up
21/02/17 01:17:02 INFO SparkEnv: Registering BlockManagerMasterHeartbeat
21/02/17 01:17:02 INFO DiskBlockManager: Created local directory at /tmp/blockmgr-c0f91bc4-fcc8-4ab6-890b-7fb637ab8e05
21/02/17 01:17:02 INFO MemoryStore: MemoryStore started with capacity 912.3 MiB
21/02/17 01:17:02 INFO SparkEnv: Registering OutputCommitCoordinator
21/02/17 01:17:02 INFO Utils: Successfully started service 'SparkUI' on port 4040.
21/02/17 01:17:02 INFO SparkUI: Bound SparkUI to 127.0.0.1, and started at http://localhost:4040
21/02/17 01:17:02 INFO SparkContext: Added JAR file:/home/yitaoli/R/x86_64-pc-linux-gnu-library/4.0/sparklyr/java/sparklyr-3.0-2.12.jar at spark://localhost:44505/jars/sparklyr-3.0-2.12.jar with timestamp 1613524622793
21/02/17 01:17:02 INFO Executor: Starting executor ID driver on host localhost
21/02/17 01:17:02 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 39479.
21/02/17 01:17:02 INFO NettyBlockTransferService: Server created on localhost:39479
21/02/17 01:17:02 INFO BlockManager: Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
21/02/17 01:17:02 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, localhost, 39479, None)
21/02/17 01:17:02 INFO BlockManagerMasterEndpoint: Registering block manager localhost:39479 with 912.3 MiB RAM, BlockManagerId(driver, localhost, 39479, None)
21/02/17 01:17:02 INFO BlockManagerMaster: Registered BlockManager BlockManagerId(driver, localhost, 39479, None)
21/02/17 01:17:02 INFO BlockManager: Initialized BlockManager: BlockManagerId(driver, localhost, 39479, None)
21/02/17 01:17:03 INFO SharedState: loading hive config file: file:/home/yitaoli/spark/spark-3.0.0-bin-hadoop3.2/conf/hive-site.xml
21/02/17 01:17:03 INFO SharedState: Setting hive.metastore.warehouse.dir ('null') to the value of spark.sql.warehouse.dir ('file:/home/yitaoli/sparkxgb/tests/testthat/spark-warehouse').
21/02/17 01:17:03 INFO SharedState: Warehouse path is 'file:/home/yitaoli/sparkxgb/tests/testthat/spark-warehouse'.
21/02/17 01:17:04 INFO HiveUtils: Initializing HiveMetastoreConnection version 2.3.7 using Spark classes.
21/02/17 01:17:05 INFO HiveConf: Found configuration file file:/home/yitaoli/spark/spark-3.0.0-bin-hadoop3.2/conf/hive-site.xml
21/02/17 01:17:05 INFO SessionState: Created HDFS directory: /tmp/hive/yitaoli/a7e7e16f-174c-42b6-b6d0-f0b1aae6eae4
21/02/17 01:17:05 INFO SessionState: Created local directory: /tmp/yitaoli/a7e7e16f-174c-42b6-b6d0-f0b1aae6eae4
21/02/17 01:17:05 INFO SessionState: Created HDFS directory: /tmp/hive/yitaoli/a7e7e16f-174c-42b6-b6d0-f0b1aae6eae4/_tmp_space.db
21/02/17 01:17:05 INFO HiveClientImpl: Warehouse location for Hive client (version 2.3.7) is file:/home/yitaoli/sparkxgb/tests/testthat/spark-warehouse
21/02/17 01:17:05 WARN HiveConf: HiveConf of name hive.stats.jdbc.timeout does not exist
21/02/17 01:17:05 WARN HiveConf: HiveConf of name hive.stats.retries.wait does not exist
21/02/17 01:17:05 INFO HiveMetaStore: 0: Opening raw store with implementation class:org.apache.hadoop.hive.metastore.ObjectStore
21/02/17 01:17:05 INFO ObjectStore: ObjectStore, initialize called
21/02/17 01:17:05 INFO Persistence: Property hive.metastore.integral.jdo.pushdown unknown - will be ignored
21/02/17 01:17:05 INFO Persistence: Property datanucleus.cache.level2 unknown - will be ignored
21/02/17 01:17:06 INFO ObjectStore: Setting MetaStore object pin classes with hive.metastore.cache.pinobjtypes="Table,StorageDescriptor,SerDeInfo,Partition,Database,Type,FieldSchema,Order"
21/02/17 01:17:08 INFO MetaStoreDirectSql: Using direct SQL, underlying DB is DERBY
21/02/17 01:17:08 INFO ObjectStore: Initialized ObjectStore
21/02/17 01:17:08 WARN ObjectStore: Version information not found in metastore. hive.metastore.schema.verification is not enabled so recording the schema version 2.3.0
21/02/17 01:17:08 WARN ObjectStore: setMetaStoreSchemaVersion called but recording version is disabled: version = 2.3.0, comment = Set by MetaStore yitaoli@127.0.1.1
21/02/17 01:17:08 WARN ObjectStore: Failed to get database default, returning NoSuchObjectException
21/02/17 01:17:08 INFO HiveMetaStore: Added admin role in metastore
21/02/17 01:17:08 INFO HiveMetaStore: Added public role in metastore
21/02/17 01:17:08 INFO HiveMetaStore: No user is added in admin role, since config is empty
21/02/17 01:17:08 INFO HiveMetaStore: 0: get_all_functions
21/02/17 01:17:08 INFO audit: ugi=yitaoli	ip=unknown-ip-addr	cmd=get_all_functions	
21/02/17 01:17:08 INFO HiveMetaStore: 0: get_database: default
21/02/17 01:17:08 INFO audit: ugi=yitaoli	ip=unknown-ip-addr	cmd=get_database: default	
21/02/17 01:17:08 INFO HiveMetaStore: 0: get_database: default
21/02/17 01:17:08 INFO audit: ugi=yitaoli	ip=unknown-ip-addr	cmd=get_database: default	
21/02/17 01:17:08 INFO HiveMetaStore: 0: get_table : db=default tbl=iris
21/02/17 01:17:08 INFO audit: ugi=yitaoli	ip=unknown-ip-addr	cmd=get_table : db=default tbl=iris	
21/02/17 01:17:09 INFO HiveMetaStore: 0: get_database: global_temp
21/02/17 01:17:09 INFO audit: ugi=yitaoli	ip=unknown-ip-addr	cmd=get_database: global_temp	
21/02/17 01:17:09 WARN ObjectStore: Failed to get database global_temp, returning NoSuchObjectException
21/02/17 01:17:09 INFO HiveMetaStore: 0: get_database: default
21/02/17 01:17:09 INFO audit: ugi=yitaoli	ip=unknown-ip-addr	cmd=get_database: default	
21/02/17 01:17:09 INFO HiveMetaStore: 0: get_database: default
21/02/17 01:17:09 INFO audit: ugi=yitaoli	ip=unknown-ip-addr	cmd=get_database: default	
21/02/17 01:17:09 INFO HiveMetaStore: 0: get_tables: db=default pat=*
21/02/17 01:17:09 INFO audit: ugi=yitaoli	ip=unknown-ip-addr	cmd=get_tables: db=default pat=*	
21/02/17 01:17:09 INFO SparkContext: Starting job: collect at utils.scala:54
21/02/17 01:17:09 INFO DAGScheduler: Job 0 finished: collect at utils.scala:54, took 0.005038 s
21/02/17 01:17:10 INFO CodeGenerator: Code generated in 172.072888 ms
21/02/17 01:17:10 INFO SparkContext: Starting job: collect at utils.scala:137
21/02/17 01:17:10 INFO DAGScheduler: Got job 1 (collect at utils.scala:137) with 1 output partitions
21/02/17 01:17:10 INFO DAGScheduler: Final stage: ResultStage 0 (collect at utils.scala:137)
21/02/17 01:17:10 INFO DAGScheduler: Parents of final stage: List()
21/02/17 01:17:10 INFO DAGScheduler: Missing parents: List()
21/02/17 01:17:10 INFO DAGScheduler: Submitting ResultStage 0 (MapPartitionsRDD[9] at collect at utils.scala:137), which has no missing parents
21/02/17 01:17:10 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 6.5 KiB, free 912.3 MiB)
21/02/17 01:17:10 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 3.2 KiB, free 912.3 MiB)
21/02/17 01:17:10 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on localhost:39479 (size: 3.2 KiB, free: 912.3 MiB)
21/02/17 01:17:10 INFO SparkContext: Created broadcast 0 from broadcast at DAGScheduler.scala:1200
21/02/17 01:17:10 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 0 (MapPartitionsRDD[9] at collect at utils.scala:137) (first 15 tasks are for partitions Vector(0))
21/02/17 01:17:10 INFO TaskSchedulerImpl: Adding task set 0.0 with 1 tasks
21/02/17 01:17:10 INFO TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0, localhost, executor driver, partition 0, PROCESS_LOCAL, 7561 bytes)
21/02/17 01:17:10 INFO Executor: Running task 0.0 in stage 0.0 (TID 0)
21/02/17 01:17:10 INFO Executor: Fetching spark://localhost:44505/jars/sparklyr-3.0-2.12.jar with timestamp 1613524622793
21/02/17 01:17:10 INFO TransportClientFactory: Successfully created connection to localhost/127.0.0.1:44505 after 11 ms (0 ms spent in bootstraps)
21/02/17 01:17:10 INFO Utils: Fetching spark://localhost:44505/jars/sparklyr-3.0-2.12.jar to /tmp/spark-bfd3a4d7-82ca-468a-8797-4b25839910af/userFiles-1341645c-7a12-4fff-baf6-09d330d3eecd/fetchFileTemp1499023030071623275.tmp
21/02/17 01:17:10 INFO Executor: Adding file:/tmp/spark-bfd3a4d7-82ca-468a-8797-4b25839910af/userFiles-1341645c-7a12-4fff-baf6-09d330d3eecd/sparklyr-3.0-2.12.jar to class loader
21/02/17 01:17:10 INFO Executor: Finished task 0.0 in stage 0.0 (TID 0). 1397 bytes result sent to driver
21/02/17 01:17:10 INFO TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in 271 ms on localhost (executor driver) (1/1)
21/02/17 01:17:10 INFO TaskSchedulerImpl: Removed TaskSet 0.0, whose tasks have all completed, from pool 
21/02/17 01:17:10 INFO DAGScheduler: ResultStage 0 (collect at utils.scala:137) finished in 0.410 s
21/02/17 01:17:10 INFO DAGScheduler: Job 1 is finished. Cancelling potential speculative or zombie tasks for this job
21/02/17 01:17:10 INFO TaskSchedulerImpl: Killing all running tasks in stage 0: Stage finished
21/02/17 01:17:10 INFO DAGScheduler: Job 1 finished: collect at utils.scala:137, took 0.442738 s
21/02/17 01:17:10 INFO CodeGenerator: Code generated in 12.497218 ms
21/02/17 01:17:10 INFO CodeGenerator: Code generated in 14.183002 ms
21/02/17 01:17:10 INFO CodeGenerator: Code generated in 12.943159 ms
21/02/17 01:17:10 INFO SparkContext: Starting job: count at utils.scala:135
21/02/17 01:17:10 INFO DAGScheduler: Registering RDD 11 (count at utils.scala:135) as input to shuffle 0
21/02/17 01:17:10 INFO DAGScheduler: Got job 2 (count at utils.scala:135) with 1 output partitions
21/02/17 01:17:10 INFO DAGScheduler: Final stage: ResultStage 2 (count at utils.scala:135)
21/02/17 01:17:10 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 1)
21/02/17 01:17:10 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 1)
21/02/17 01:17:10 INFO DAGScheduler: Submitting ShuffleMapStage 1 (MapPartitionsRDD[11] at count at utils.scala:135), which has no missing parents
21/02/17 01:17:10 INFO MemoryStore: Block broadcast_1 stored as values in memory (estimated size 10.0 KiB, free 912.3 MiB)
21/02/17 01:17:10 INFO MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 5.2 KiB, free 912.3 MiB)
21/02/17 01:17:10 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on localhost:39479 (size: 5.2 KiB, free: 912.3 MiB)
21/02/17 01:17:10 INFO SparkContext: Created broadcast 1 from broadcast at DAGScheduler.scala:1200
21/02/17 01:17:10 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 1 (MapPartitionsRDD[11] at count at utils.scala:135) (first 15 tasks are for partitions Vector(0))
21/02/17 01:17:10 INFO TaskSchedulerImpl: Adding task set 1.0 with 1 tasks
21/02/17 01:17:10 INFO TaskSetManager: Starting task 0.0 in stage 1.0 (TID 1, localhost, executor driver, partition 0, PROCESS_LOCAL, 7550 bytes)
21/02/17 01:17:10 INFO Executor: Running task 0.0 in stage 1.0 (TID 1)
21/02/17 01:17:10 INFO Executor: Finished task 0.0 in stage 1.0 (TID 1). 1876 bytes result sent to driver
21/02/17 01:17:10 INFO TaskSetManager: Finished task 0.0 in stage 1.0 (TID 1) in 46 ms on localhost (executor driver) (1/1)
21/02/17 01:17:10 INFO TaskSchedulerImpl: Removed TaskSet 1.0, whose tasks have all completed, from pool 
21/02/17 01:17:10 INFO DAGScheduler: ShuffleMapStage 1 (count at utils.scala:135) finished in 0.059 s
21/02/17 01:17:10 INFO DAGScheduler: looking for newly runnable stages
21/02/17 01:17:10 INFO DAGScheduler: running: Set()
21/02/17 01:17:10 INFO DAGScheduler: waiting: Set(ResultStage 2)
21/02/17 01:17:10 INFO DAGScheduler: failed: Set()
21/02/17 01:17:10 INFO DAGScheduler: Submitting ResultStage 2 (MapPartitionsRDD[14] at count at utils.scala:135), which has no missing parents
21/02/17 01:17:10 INFO MemoryStore: Block broadcast_2 stored as values in memory (estimated size 10.1 KiB, free 912.3 MiB)
21/02/17 01:17:10 INFO MemoryStore: Block broadcast_2_piece0 stored as bytes in memory (estimated size 5.0 KiB, free 912.3 MiB)
21/02/17 01:17:10 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on localhost:39479 (size: 5.0 KiB, free: 912.3 MiB)
21/02/17 01:17:10 INFO SparkContext: Created broadcast 2 from broadcast at DAGScheduler.scala:1200
21/02/17 01:17:10 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 2 (MapPartitionsRDD[14] at count at utils.scala:135) (first 15 tasks are for partitions Vector(0))
21/02/17 01:17:10 INFO TaskSchedulerImpl: Adding task set 2.0 with 1 tasks
21/02/17 01:17:10 INFO TaskSetManager: Starting task 0.0 in stage 2.0 (TID 2, localhost, executor driver, partition 0, NODE_LOCAL, 7325 bytes)
21/02/17 01:17:10 INFO Executor: Running task 0.0 in stage 2.0 (TID 2)
21/02/17 01:17:10 INFO ShuffleBlockFetcherIterator: Getting 1 (60.0 B) non-empty blocks including 1 (60.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
21/02/17 01:17:10 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 6 ms
21/02/17 01:17:11 INFO Executor: Finished task 0.0 in stage 2.0 (TID 2). 2648 bytes result sent to driver
21/02/17 01:17:11 INFO TaskSetManager: Finished task 0.0 in stage 2.0 (TID 2) in 37 ms on localhost (executor driver) (1/1)
21/02/17 01:17:11 INFO TaskSchedulerImpl: Removed TaskSet 2.0, whose tasks have all completed, from pool 
21/02/17 01:17:11 INFO DAGScheduler: ResultStage 2 (count at utils.scala:135) finished in 0.045 s
21/02/17 01:17:11 INFO DAGScheduler: Job 2 is finished. Cancelling potential speculative or zombie tasks for this job
21/02/17 01:17:11 INFO TaskSchedulerImpl: Killing all running tasks in stage 2: Stage finished
21/02/17 01:17:11 INFO DAGScheduler: Job 2 finished: count at utils.scala:135, took 0.123775 s
21/02/17 01:17:11 INFO SparkContext: Starting job: collect at utils.scala:137
21/02/17 01:17:11 INFO DAGScheduler: Got job 3 (collect at utils.scala:137) with 1 output partitions
21/02/17 01:17:11 INFO DAGScheduler: Final stage: ResultStage 3 (collect at utils.scala:137)
21/02/17 01:17:11 INFO DAGScheduler: Parents of final stage: List()
21/02/17 01:17:11 INFO DAGScheduler: Missing parents: List()
21/02/17 01:17:11 INFO DAGScheduler: Submitting ResultStage 3 (MapPartitionsRDD[16] at collect at utils.scala:137), which has no missing parents
21/02/17 01:17:11 INFO MemoryStore: Block broadcast_3 stored as values in memory (estimated size 7.2 KiB, free 912.3 MiB)
21/02/17 01:17:11 INFO MemoryStore: Block broadcast_3_piece0 stored as bytes in memory (estimated size 3.7 KiB, free 912.3 MiB)
21/02/17 01:17:11 INFO BlockManagerInfo: Added broadcast_3_piece0 in memory on localhost:39479 (size: 3.7 KiB, free: 912.3 MiB)
21/02/17 01:17:11 INFO SparkContext: Created broadcast 3 from broadcast at DAGScheduler.scala:1200
21/02/17 01:17:11 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 3 (MapPartitionsRDD[16] at collect at utils.scala:137) (first 15 tasks are for partitions Vector(0))
21/02/17 01:17:11 INFO TaskSchedulerImpl: Adding task set 3.0 with 1 tasks
21/02/17 01:17:11 INFO TaskSetManager: Starting task 0.0 in stage 3.0 (TID 3, localhost, executor driver, partition 0, PROCESS_LOCAL, 7561 bytes)
21/02/17 01:17:11 INFO Executor: Running task 0.0 in stage 3.0 (TID 3)
21/02/17 01:17:11 INFO Executor: Finished task 0.0 in stage 3.0 (TID 3). 1397 bytes result sent to driver
21/02/17 01:17:11 INFO TaskSetManager: Finished task 0.0 in stage 3.0 (TID 3) in 5 ms on localhost (executor driver) (1/1)
21/02/17 01:17:11 INFO TaskSchedulerImpl: Removed TaskSet 3.0, whose tasks have all completed, from pool 
21/02/17 01:17:11 INFO DAGScheduler: ResultStage 3 (collect at utils.scala:137) finished in 0.012 s
21/02/17 01:17:11 INFO DAGScheduler: Job 3 is finished. Cancelling potential speculative or zombie tasks for this job
21/02/17 01:17:11 INFO TaskSchedulerImpl: Killing all running tasks in stage 3: Stage finished
21/02/17 01:17:11 INFO DAGScheduler: Job 3 finished: collect at utils.scala:137, took 0.015243 s
21/02/17 01:17:11 INFO SparkContext: Starting job: count at utils.scala:135
21/02/17 01:17:11 INFO DAGScheduler: Registering RDD 18 (count at utils.scala:135) as input to shuffle 1
21/02/17 01:17:11 INFO DAGScheduler: Got job 4 (count at utils.scala:135) with 1 output partitions
21/02/17 01:17:11 INFO DAGScheduler: Final stage: ResultStage 5 (count at utils.scala:135)
21/02/17 01:17:11 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 4)
21/02/17 01:17:11 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 4)
21/02/17 01:17:11 INFO DAGScheduler: Submitting ShuffleMapStage 4 (MapPartitionsRDD[18] at count at utils.scala:135), which has no missing parents
21/02/17 01:17:11 INFO MemoryStore: Block broadcast_4 stored as values in memory (estimated size 10.0 KiB, free 912.2 MiB)
21/02/17 01:17:11 INFO MemoryStore: Block broadcast_4_piece0 stored as bytes in memory (estimated size 5.2 KiB, free 912.2 MiB)
21/02/17 01:17:11 INFO BlockManagerInfo: Added broadcast_4_piece0 in memory on localhost:39479 (size: 5.2 KiB, free: 912.3 MiB)
21/02/17 01:17:11 INFO SparkContext: Created broadcast 4 from broadcast at DAGScheduler.scala:1200
21/02/17 01:17:11 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 4 (MapPartitionsRDD[18] at count at utils.scala:135) (first 15 tasks are for partitions Vector(0))
21/02/17 01:17:11 INFO TaskSchedulerImpl: Adding task set 4.0 with 1 tasks
21/02/17 01:17:11 INFO TaskSetManager: Starting task 0.0 in stage 4.0 (TID 4, localhost, executor driver, partition 0, PROCESS_LOCAL, 7550 bytes)
21/02/17 01:17:11 INFO Executor: Running task 0.0 in stage 4.0 (TID 4)
21/02/17 01:17:11 INFO Executor: Finished task 0.0 in stage 4.0 (TID 4). 1833 bytes result sent to driver
21/02/17 01:17:11 INFO TaskSetManager: Finished task 0.0 in stage 4.0 (TID 4) in 8 ms on localhost (executor driver) (1/1)
21/02/17 01:17:11 INFO TaskSchedulerImpl: Removed TaskSet 4.0, whose tasks have all completed, from pool 
21/02/17 01:17:11 INFO DAGScheduler: ShuffleMapStage 4 (count at utils.scala:135) finished in 0.017 s
21/02/17 01:17:11 INFO DAGScheduler: looking for newly runnable stages
21/02/17 01:17:11 INFO DAGScheduler: running: Set()
21/02/17 01:17:11 INFO DAGScheduler: waiting: Set(ResultStage 5)
21/02/17 01:17:11 INFO DAGScheduler: failed: Set()
21/02/17 01:17:11 INFO DAGScheduler: Submitting ResultStage 5 (MapPartitionsRDD[21] at count at utils.scala:135), which has no missing parents
21/02/17 01:17:11 INFO MemoryStore: Block broadcast_5 stored as values in memory (estimated size 10.1 KiB, free 912.2 MiB)
21/02/17 01:17:11 INFO MemoryStore: Block broadcast_5_piece0 stored as bytes in memory (estimated size 5.0 KiB, free 912.2 MiB)
21/02/17 01:17:11 INFO BlockManagerInfo: Added broadcast_5_piece0 in memory on localhost:39479 (size: 5.0 KiB, free: 912.3 MiB)
21/02/17 01:17:11 INFO SparkContext: Created broadcast 5 from broadcast at DAGScheduler.scala:1200
21/02/17 01:17:11 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 5 (MapPartitionsRDD[21] at count at utils.scala:135) (first 15 tasks are for partitions Vector(0))
21/02/17 01:17:11 INFO TaskSchedulerImpl: Adding task set 5.0 with 1 tasks
21/02/17 01:17:11 INFO TaskSetManager: Starting task 0.0 in stage 5.0 (TID 5, localhost, executor driver, partition 0, NODE_LOCAL, 7325 bytes)
21/02/17 01:17:11 INFO Executor: Running task 0.0 in stage 5.0 (TID 5)
21/02/17 01:17:11 INFO ShuffleBlockFetcherIterator: Getting 1 (60.0 B) non-empty blocks including 1 (60.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
21/02/17 01:17:11 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
21/02/17 01:17:11 INFO Executor: Finished task 0.0 in stage 5.0 (TID 5). 2648 bytes result sent to driver
21/02/17 01:17:11 INFO TaskSetManager: Finished task 0.0 in stage 5.0 (TID 5) in 8 ms on localhost (executor driver) (1/1)
21/02/17 01:17:11 INFO TaskSchedulerImpl: Removed TaskSet 5.0, whose tasks have all completed, from pool 
21/02/17 01:17:11 INFO DAGScheduler: ResultStage 5 (count at utils.scala:135) finished in 0.014 s
21/02/17 01:17:11 INFO DAGScheduler: Job 4 is finished. Cancelling potential speculative or zombie tasks for this job
21/02/17 01:17:11 INFO TaskSchedulerImpl: Killing all running tasks in stage 5: Stage finished
21/02/17 01:17:11 INFO DAGScheduler: Job 4 finished: count at utils.scala:135, took 0.036949 s
21/02/17 01:17:12 INFO SparkContext: Invoking stop() from shutdown hook
21/02/17 01:17:12 INFO SparkUI: Stopped Spark web UI at http://localhost:4040
21/02/17 01:17:12 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!
21/02/17 01:17:12 INFO MemoryStore: MemoryStore cleared
21/02/17 01:17:12 INFO BlockManager: BlockManager stopped
21/02/17 01:17:12 INFO BlockManagerMaster: BlockManagerMaster stopped
21/02/17 01:17:12 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!
21/02/17 01:17:12 INFO SparkContext: Successfully stopped SparkContext
21/02/17 01:17:12 INFO ShutdownHookManager: Shutdown hook called
21/02/17 01:17:12 INFO ShutdownHookManager: Deleting directory /tmp/spark-bfd3a4d7-82ca-468a-8797-4b25839910af
21/02/17 01:17:12 INFO ShutdownHookManager: Deleting directory /tmp/spark-b90bf497-8e61-4aa5-a237-ba5a232a4d3a
21/02/17 01:18:24 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
21/02/17 01:18:24 INFO SecurityManager: Changing view acls to: yitaoli
21/02/17 01:18:24 INFO SecurityManager: Changing modify acls to: yitaoli
21/02/17 01:18:24 INFO SecurityManager: Changing view acls groups to: 
21/02/17 01:18:24 INFO SecurityManager: Changing modify acls groups to: 
21/02/17 01:18:24 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(yitaoli); groups with view permissions: Set(); users  with modify permissions: Set(yitaoli); groups with modify permissions: Set()
21/02/17 01:18:24 INFO HiveConf: Found configuration file file:/home/yitaoli/spark/spark-3.0.0-bin-hadoop3.2/conf/hive-site.xml
21/02/17 01:18:25 INFO SparkContext: Running Spark version 3.0.0
21/02/17 01:18:25 INFO ResourceUtils: ==============================================================
21/02/17 01:18:25 INFO ResourceUtils: Resources for spark.driver:

21/02/17 01:18:25 INFO ResourceUtils: ==============================================================
21/02/17 01:18:25 INFO SparkContext: Submitted application: sparklyr
21/02/17 01:18:25 INFO SecurityManager: Changing view acls to: yitaoli
21/02/17 01:18:25 INFO SecurityManager: Changing modify acls to: yitaoli
21/02/17 01:18:25 INFO SecurityManager: Changing view acls groups to: 
21/02/17 01:18:25 INFO SecurityManager: Changing modify acls groups to: 
21/02/17 01:18:25 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(yitaoli); groups with view permissions: Set(); users  with modify permissions: Set(yitaoli); groups with modify permissions: Set()
21/02/17 01:18:25 INFO Utils: Successfully started service 'sparkDriver' on port 33411.
21/02/17 01:18:25 INFO SparkEnv: Registering MapOutputTracker
21/02/17 01:18:25 INFO SparkEnv: Registering BlockManagerMaster
21/02/17 01:18:25 INFO BlockManagerMasterEndpoint: Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
21/02/17 01:18:25 INFO BlockManagerMasterEndpoint: BlockManagerMasterEndpoint up
21/02/17 01:18:25 INFO SparkEnv: Registering BlockManagerMasterHeartbeat
21/02/17 01:18:25 INFO DiskBlockManager: Created local directory at /tmp/blockmgr-588531ac-c50c-4024-b077-445c345b5f8b
21/02/17 01:18:25 INFO MemoryStore: MemoryStore started with capacity 912.3 MiB
21/02/17 01:18:25 INFO SparkEnv: Registering OutputCommitCoordinator
21/02/17 01:18:25 INFO Utils: Successfully started service 'SparkUI' on port 4040.
21/02/17 01:18:25 INFO SparkUI: Bound SparkUI to 127.0.0.1, and started at http://localhost:4040
21/02/17 01:18:25 INFO SparkContext: Added JAR file:/home/yitaoli/R/x86_64-pc-linux-gnu-library/4.0/sparklyr/java/sparklyr-3.0-2.12.jar at spark://localhost:33411/jars/sparklyr-3.0-2.12.jar with timestamp 1613524705570
21/02/17 01:18:25 INFO Executor: Starting executor ID driver on host localhost
21/02/17 01:18:25 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 44291.
21/02/17 01:18:25 INFO NettyBlockTransferService: Server created on localhost:44291
21/02/17 01:18:25 INFO BlockManager: Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
21/02/17 01:18:25 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, localhost, 44291, None)
21/02/17 01:18:25 INFO BlockManagerMasterEndpoint: Registering block manager localhost:44291 with 912.3 MiB RAM, BlockManagerId(driver, localhost, 44291, None)
21/02/17 01:18:25 INFO BlockManagerMaster: Registered BlockManager BlockManagerId(driver, localhost, 44291, None)
21/02/17 01:18:25 INFO BlockManager: Initialized BlockManager: BlockManagerId(driver, localhost, 44291, None)
21/02/17 01:18:25 INFO SharedState: loading hive config file: file:/home/yitaoli/spark/spark-3.0.0-bin-hadoop3.2/conf/hive-site.xml
21/02/17 01:18:25 INFO SharedState: Setting hive.metastore.warehouse.dir ('null') to the value of spark.sql.warehouse.dir ('file:/home/yitaoli/sparkxgb/tests/testthat/spark-warehouse').
21/02/17 01:18:25 INFO SharedState: Warehouse path is 'file:/home/yitaoli/sparkxgb/tests/testthat/spark-warehouse'.
21/02/17 01:18:27 INFO HiveUtils: Initializing HiveMetastoreConnection version 2.3.7 using Spark classes.
21/02/17 01:18:27 INFO HiveConf: Found configuration file file:/home/yitaoli/spark/spark-3.0.0-bin-hadoop3.2/conf/hive-site.xml
21/02/17 01:18:28 INFO SessionState: Created HDFS directory: /tmp/hive/yitaoli/f815f0b2-7e33-410b-a068-e8bba4816a41
21/02/17 01:18:28 INFO SessionState: Created local directory: /tmp/yitaoli/f815f0b2-7e33-410b-a068-e8bba4816a41
21/02/17 01:18:28 INFO SessionState: Created HDFS directory: /tmp/hive/yitaoli/f815f0b2-7e33-410b-a068-e8bba4816a41/_tmp_space.db
21/02/17 01:18:28 INFO HiveClientImpl: Warehouse location for Hive client (version 2.3.7) is file:/home/yitaoli/sparkxgb/tests/testthat/spark-warehouse
21/02/17 01:18:28 WARN HiveConf: HiveConf of name hive.stats.jdbc.timeout does not exist
21/02/17 01:18:28 WARN HiveConf: HiveConf of name hive.stats.retries.wait does not exist
21/02/17 01:18:28 INFO HiveMetaStore: 0: Opening raw store with implementation class:org.apache.hadoop.hive.metastore.ObjectStore
21/02/17 01:18:28 INFO ObjectStore: ObjectStore, initialize called
21/02/17 01:18:28 INFO Persistence: Property hive.metastore.integral.jdo.pushdown unknown - will be ignored
21/02/17 01:18:28 INFO Persistence: Property datanucleus.cache.level2 unknown - will be ignored
21/02/17 01:18:29 INFO ObjectStore: Setting MetaStore object pin classes with hive.metastore.cache.pinobjtypes="Table,StorageDescriptor,SerDeInfo,Partition,Database,Type,FieldSchema,Order"
21/02/17 01:18:30 INFO MetaStoreDirectSql: Using direct SQL, underlying DB is DERBY
21/02/17 01:18:30 INFO ObjectStore: Initialized ObjectStore
21/02/17 01:18:31 WARN ObjectStore: Version information not found in metastore. hive.metastore.schema.verification is not enabled so recording the schema version 2.3.0
21/02/17 01:18:31 WARN ObjectStore: setMetaStoreSchemaVersion called but recording version is disabled: version = 2.3.0, comment = Set by MetaStore yitaoli@127.0.1.1
21/02/17 01:18:31 WARN ObjectStore: Failed to get database default, returning NoSuchObjectException
21/02/17 01:18:31 INFO HiveMetaStore: Added admin role in metastore
21/02/17 01:18:31 INFO HiveMetaStore: Added public role in metastore
21/02/17 01:18:31 INFO HiveMetaStore: No user is added in admin role, since config is empty
21/02/17 01:18:31 INFO HiveMetaStore: 0: get_all_functions
21/02/17 01:18:31 INFO audit: ugi=yitaoli	ip=unknown-ip-addr	cmd=get_all_functions	
21/02/17 01:18:31 INFO HiveMetaStore: 0: get_database: default
21/02/17 01:18:31 INFO audit: ugi=yitaoli	ip=unknown-ip-addr	cmd=get_database: default	
21/02/17 01:18:31 INFO HiveMetaStore: 0: get_database: default
21/02/17 01:18:31 INFO audit: ugi=yitaoli	ip=unknown-ip-addr	cmd=get_database: default	
21/02/17 01:18:31 INFO HiveMetaStore: 0: get_table : db=default tbl=iris
21/02/17 01:18:31 INFO audit: ugi=yitaoli	ip=unknown-ip-addr	cmd=get_table : db=default tbl=iris	
21/02/17 01:18:31 INFO SparkContext: Invoking stop() from shutdown hook
21/02/17 01:18:31 INFO SparkUI: Stopped Spark web UI at http://localhost:4040
21/02/17 01:18:31 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!
21/02/17 01:18:31 INFO MemoryStore: MemoryStore cleared
21/02/17 01:18:31 INFO BlockManager: BlockManager stopped
21/02/17 01:18:31 INFO BlockManagerMaster: BlockManagerMaster stopped
21/02/17 01:18:31 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!
21/02/17 01:18:31 INFO SparkContext: Successfully stopped SparkContext
21/02/17 01:18:31 INFO ShutdownHookManager: Shutdown hook called
21/02/17 01:18:31 INFO ShutdownHookManager: Deleting directory /tmp/spark-e9f53186-0039-4a02-baaa-4f0710b4eb37
21/02/17 01:18:31 INFO ShutdownHookManager: Deleting directory /tmp/spark-3669c988-4857-484b-8b9c-09bbd0b38c30
21/02/17 01:19:13 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
21/02/17 01:19:13 INFO SecurityManager: Changing view acls to: yitaoli
21/02/17 01:19:13 INFO SecurityManager: Changing modify acls to: yitaoli
21/02/17 01:19:13 INFO SecurityManager: Changing view acls groups to: 
21/02/17 01:19:13 INFO SecurityManager: Changing modify acls groups to: 
21/02/17 01:19:13 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(yitaoli); groups with view permissions: Set(); users  with modify permissions: Set(yitaoli); groups with modify permissions: Set()
21/02/17 01:19:14 INFO HiveConf: Found configuration file file:/home/yitaoli/spark/spark-3.0.0-bin-hadoop3.2/conf/hive-site.xml
21/02/17 01:19:14 INFO SparkContext: Running Spark version 3.0.0
21/02/17 01:19:14 INFO ResourceUtils: ==============================================================
21/02/17 01:19:14 INFO ResourceUtils: Resources for spark.driver:

21/02/17 01:19:14 INFO ResourceUtils: ==============================================================
21/02/17 01:19:14 INFO SparkContext: Submitted application: sparklyr
21/02/17 01:19:14 INFO SecurityManager: Changing view acls to: yitaoli
21/02/17 01:19:14 INFO SecurityManager: Changing modify acls to: yitaoli
21/02/17 01:19:14 INFO SecurityManager: Changing view acls groups to: 
21/02/17 01:19:14 INFO SecurityManager: Changing modify acls groups to: 
21/02/17 01:19:14 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(yitaoli); groups with view permissions: Set(); users  with modify permissions: Set(yitaoli); groups with modify permissions: Set()
21/02/17 01:19:14 INFO Utils: Successfully started service 'sparkDriver' on port 42847.
21/02/17 01:19:14 INFO SparkEnv: Registering MapOutputTracker
21/02/17 01:19:14 INFO SparkEnv: Registering BlockManagerMaster
21/02/17 01:19:14 INFO BlockManagerMasterEndpoint: Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
21/02/17 01:19:14 INFO BlockManagerMasterEndpoint: BlockManagerMasterEndpoint up
21/02/17 01:19:14 INFO SparkEnv: Registering BlockManagerMasterHeartbeat
21/02/17 01:19:14 INFO DiskBlockManager: Created local directory at /tmp/blockmgr-67e11e16-b849-400d-98f7-d627be83e6a7
21/02/17 01:19:14 INFO MemoryStore: MemoryStore started with capacity 912.3 MiB
21/02/17 01:19:14 INFO SparkEnv: Registering OutputCommitCoordinator
21/02/17 01:19:15 INFO Utils: Successfully started service 'SparkUI' on port 4040.
21/02/17 01:19:15 INFO SparkUI: Bound SparkUI to 127.0.0.1, and started at http://localhost:4040
21/02/17 01:19:15 INFO SparkContext: Added JAR file:/home/yitaoli/R/x86_64-pc-linux-gnu-library/4.0/sparklyr/java/sparklyr-3.0-2.12.jar at spark://localhost:42847/jars/sparklyr-3.0-2.12.jar with timestamp 1613524755139
21/02/17 01:19:15 INFO Executor: Starting executor ID driver on host localhost
21/02/17 01:19:15 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 34557.
21/02/17 01:19:15 INFO NettyBlockTransferService: Server created on localhost:34557
21/02/17 01:19:15 INFO BlockManager: Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
21/02/17 01:19:15 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, localhost, 34557, None)
21/02/17 01:19:15 INFO BlockManagerMasterEndpoint: Registering block manager localhost:34557 with 912.3 MiB RAM, BlockManagerId(driver, localhost, 34557, None)
21/02/17 01:19:15 INFO BlockManagerMaster: Registered BlockManager BlockManagerId(driver, localhost, 34557, None)
21/02/17 01:19:15 INFO BlockManager: Initialized BlockManager: BlockManagerId(driver, localhost, 34557, None)
21/02/17 01:19:15 INFO SharedState: loading hive config file: file:/home/yitaoli/spark/spark-3.0.0-bin-hadoop3.2/conf/hive-site.xml
21/02/17 01:19:15 INFO SharedState: Setting hive.metastore.warehouse.dir ('null') to the value of spark.sql.warehouse.dir ('file:/home/yitaoli/sparkxgb/tests/testthat/spark-warehouse').
21/02/17 01:19:15 INFO SharedState: Warehouse path is 'file:/home/yitaoli/sparkxgb/tests/testthat/spark-warehouse'.
21/02/17 01:19:17 INFO HiveUtils: Initializing HiveMetastoreConnection version 2.3.7 using Spark classes.
21/02/17 01:19:17 INFO HiveConf: Found configuration file file:/home/yitaoli/spark/spark-3.0.0-bin-hadoop3.2/conf/hive-site.xml
21/02/17 01:19:17 INFO SessionState: Created HDFS directory: /tmp/hive/yitaoli/7a4957be-c19b-47e8-97d3-d0be6ed94126
21/02/17 01:19:17 INFO SessionState: Created local directory: /tmp/yitaoli/7a4957be-c19b-47e8-97d3-d0be6ed94126
21/02/17 01:19:17 INFO SessionState: Created HDFS directory: /tmp/hive/yitaoli/7a4957be-c19b-47e8-97d3-d0be6ed94126/_tmp_space.db
21/02/17 01:19:17 INFO HiveClientImpl: Warehouse location for Hive client (version 2.3.7) is file:/home/yitaoli/sparkxgb/tests/testthat/spark-warehouse
21/02/17 01:19:18 WARN HiveConf: HiveConf of name hive.stats.jdbc.timeout does not exist
21/02/17 01:19:18 WARN HiveConf: HiveConf of name hive.stats.retries.wait does not exist
21/02/17 01:19:18 INFO HiveMetaStore: 0: Opening raw store with implementation class:org.apache.hadoop.hive.metastore.ObjectStore
21/02/17 01:19:18 INFO ObjectStore: ObjectStore, initialize called
21/02/17 01:19:18 INFO Persistence: Property hive.metastore.integral.jdo.pushdown unknown - will be ignored
21/02/17 01:19:18 INFO Persistence: Property datanucleus.cache.level2 unknown - will be ignored
21/02/17 01:19:19 INFO ObjectStore: Setting MetaStore object pin classes with hive.metastore.cache.pinobjtypes="Table,StorageDescriptor,SerDeInfo,Partition,Database,Type,FieldSchema,Order"
21/02/17 01:19:20 INFO MetaStoreDirectSql: Using direct SQL, underlying DB is DERBY
21/02/17 01:19:20 INFO ObjectStore: Initialized ObjectStore
21/02/17 01:19:20 WARN ObjectStore: Version information not found in metastore. hive.metastore.schema.verification is not enabled so recording the schema version 2.3.0
21/02/17 01:19:20 WARN ObjectStore: setMetaStoreSchemaVersion called but recording version is disabled: version = 2.3.0, comment = Set by MetaStore yitaoli@127.0.1.1
21/02/17 01:19:20 WARN ObjectStore: Failed to get database default, returning NoSuchObjectException
21/02/17 01:19:20 INFO HiveMetaStore: Added admin role in metastore
21/02/17 01:19:20 INFO HiveMetaStore: Added public role in metastore
21/02/17 01:19:20 INFO HiveMetaStore: No user is added in admin role, since config is empty
21/02/17 01:19:20 INFO HiveMetaStore: 0: get_all_functions
21/02/17 01:19:20 INFO audit: ugi=yitaoli	ip=unknown-ip-addr	cmd=get_all_functions	
21/02/17 01:19:20 INFO HiveMetaStore: 0: get_database: default
21/02/17 01:19:20 INFO audit: ugi=yitaoli	ip=unknown-ip-addr	cmd=get_database: default	
21/02/17 01:19:20 INFO HiveMetaStore: 0: get_database: default
21/02/17 01:19:20 INFO audit: ugi=yitaoli	ip=unknown-ip-addr	cmd=get_database: default	
21/02/17 01:19:20 INFO HiveMetaStore: 0: get_table : db=default tbl=iris
21/02/17 01:19:20 INFO audit: ugi=yitaoli	ip=unknown-ip-addr	cmd=get_table : db=default tbl=iris	
21/02/17 01:19:21 INFO HiveMetaStore: 0: get_database: global_temp
21/02/17 01:19:21 INFO audit: ugi=yitaoli	ip=unknown-ip-addr	cmd=get_database: global_temp	
21/02/17 01:19:21 WARN ObjectStore: Failed to get database global_temp, returning NoSuchObjectException
21/02/17 01:19:21 INFO HiveMetaStore: 0: get_database: default
21/02/17 01:19:21 INFO audit: ugi=yitaoli	ip=unknown-ip-addr	cmd=get_database: default	
21/02/17 01:19:21 INFO HiveMetaStore: 0: get_database: default
21/02/17 01:19:21 INFO audit: ugi=yitaoli	ip=unknown-ip-addr	cmd=get_database: default	
21/02/17 01:19:21 INFO HiveMetaStore: 0: get_tables: db=default pat=*
21/02/17 01:19:21 INFO audit: ugi=yitaoli	ip=unknown-ip-addr	cmd=get_tables: db=default pat=*	
21/02/17 01:19:21 INFO SparkContext: Starting job: collect at utils.scala:54
21/02/17 01:19:21 INFO DAGScheduler: Job 0 finished: collect at utils.scala:54, took 0.004721 s
21/02/17 01:19:22 INFO CodeGenerator: Code generated in 174.870806 ms
21/02/17 01:19:22 INFO SparkContext: Starting job: collect at utils.scala:137
21/02/17 01:19:22 INFO DAGScheduler: Got job 1 (collect at utils.scala:137) with 1 output partitions
21/02/17 01:19:22 INFO DAGScheduler: Final stage: ResultStage 0 (collect at utils.scala:137)
21/02/17 01:19:22 INFO DAGScheduler: Parents of final stage: List()
21/02/17 01:19:22 INFO DAGScheduler: Missing parents: List()
21/02/17 01:19:22 INFO DAGScheduler: Submitting ResultStage 0 (MapPartitionsRDD[9] at collect at utils.scala:137), which has no missing parents
21/02/17 01:19:22 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 6.5 KiB, free 912.3 MiB)
21/02/17 01:19:22 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 3.2 KiB, free 912.3 MiB)
21/02/17 01:19:22 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on localhost:34557 (size: 3.2 KiB, free: 912.3 MiB)
21/02/17 01:19:22 INFO SparkContext: Created broadcast 0 from broadcast at DAGScheduler.scala:1200
21/02/17 01:19:22 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 0 (MapPartitionsRDD[9] at collect at utils.scala:137) (first 15 tasks are for partitions Vector(0))
21/02/17 01:19:22 INFO TaskSchedulerImpl: Adding task set 0.0 with 1 tasks
21/02/17 01:19:22 INFO TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0, localhost, executor driver, partition 0, PROCESS_LOCAL, 7561 bytes)
21/02/17 01:19:22 INFO Executor: Running task 0.0 in stage 0.0 (TID 0)
21/02/17 01:19:22 INFO Executor: Fetching spark://localhost:42847/jars/sparklyr-3.0-2.12.jar with timestamp 1613524755139
21/02/17 01:19:22 INFO TransportClientFactory: Successfully created connection to localhost/127.0.0.1:42847 after 13 ms (0 ms spent in bootstraps)
21/02/17 01:19:22 INFO Utils: Fetching spark://localhost:42847/jars/sparklyr-3.0-2.12.jar to /tmp/spark-1fe84a08-9325-429f-ab04-c90ef4ca8074/userFiles-2fd3b65d-cd22-4398-b846-7e539651b3e4/fetchFileTemp5417411880132164474.tmp
21/02/17 01:19:22 INFO Executor: Adding file:/tmp/spark-1fe84a08-9325-429f-ab04-c90ef4ca8074/userFiles-2fd3b65d-cd22-4398-b846-7e539651b3e4/sparklyr-3.0-2.12.jar to class loader
21/02/17 01:19:22 INFO Executor: Finished task 0.0 in stage 0.0 (TID 0). 1397 bytes result sent to driver
21/02/17 01:19:22 INFO TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in 287 ms on localhost (executor driver) (1/1)
21/02/17 01:19:22 INFO TaskSchedulerImpl: Removed TaskSet 0.0, whose tasks have all completed, from pool 
21/02/17 01:19:22 INFO DAGScheduler: ResultStage 0 (collect at utils.scala:137) finished in 0.415 s
21/02/17 01:19:22 INFO DAGScheduler: Job 1 is finished. Cancelling potential speculative or zombie tasks for this job
21/02/17 01:19:22 INFO TaskSchedulerImpl: Killing all running tasks in stage 0: Stage finished
21/02/17 01:19:22 INFO DAGScheduler: Job 1 finished: collect at utils.scala:137, took 0.445625 s
21/02/17 01:19:22 INFO CodeGenerator: Code generated in 13.448508 ms
21/02/17 01:19:23 INFO CodeGenerator: Code generated in 15.521393 ms
21/02/17 01:19:23 INFO CodeGenerator: Code generated in 13.790439 ms
21/02/17 01:19:23 INFO SparkContext: Starting job: count at utils.scala:135
21/02/17 01:19:23 INFO DAGScheduler: Registering RDD 11 (count at utils.scala:135) as input to shuffle 0
21/02/17 01:19:23 INFO DAGScheduler: Got job 2 (count at utils.scala:135) with 1 output partitions
21/02/17 01:19:23 INFO DAGScheduler: Final stage: ResultStage 2 (count at utils.scala:135)
21/02/17 01:19:23 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 1)
21/02/17 01:19:23 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 1)
21/02/17 01:19:23 INFO DAGScheduler: Submitting ShuffleMapStage 1 (MapPartitionsRDD[11] at count at utils.scala:135), which has no missing parents
21/02/17 01:19:23 INFO MemoryStore: Block broadcast_1 stored as values in memory (estimated size 10.0 KiB, free 912.3 MiB)
21/02/17 01:19:23 INFO MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 5.2 KiB, free 912.3 MiB)
21/02/17 01:19:23 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on localhost:34557 (size: 5.2 KiB, free: 912.3 MiB)
21/02/17 01:19:23 INFO SparkContext: Created broadcast 1 from broadcast at DAGScheduler.scala:1200
21/02/17 01:19:23 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 1 (MapPartitionsRDD[11] at count at utils.scala:135) (first 15 tasks are for partitions Vector(0))
21/02/17 01:19:23 INFO TaskSchedulerImpl: Adding task set 1.0 with 1 tasks
21/02/17 01:19:23 INFO TaskSetManager: Starting task 0.0 in stage 1.0 (TID 1, localhost, executor driver, partition 0, PROCESS_LOCAL, 7550 bytes)
21/02/17 01:19:23 INFO Executor: Running task 0.0 in stage 1.0 (TID 1)
21/02/17 01:19:23 INFO Executor: Finished task 0.0 in stage 1.0 (TID 1). 1833 bytes result sent to driver
21/02/17 01:19:23 INFO TaskSetManager: Finished task 0.0 in stage 1.0 (TID 1) in 42 ms on localhost (executor driver) (1/1)
21/02/17 01:19:23 INFO TaskSchedulerImpl: Removed TaskSet 1.0, whose tasks have all completed, from pool 
21/02/17 01:19:23 INFO DAGScheduler: ShuffleMapStage 1 (count at utils.scala:135) finished in 0.058 s
21/02/17 01:19:23 INFO DAGScheduler: looking for newly runnable stages
21/02/17 01:19:23 INFO DAGScheduler: running: Set()
21/02/17 01:19:23 INFO DAGScheduler: waiting: Set(ResultStage 2)
21/02/17 01:19:23 INFO DAGScheduler: failed: Set()
21/02/17 01:19:23 INFO DAGScheduler: Submitting ResultStage 2 (MapPartitionsRDD[14] at count at utils.scala:135), which has no missing parents
21/02/17 01:19:23 INFO MemoryStore: Block broadcast_2 stored as values in memory (estimated size 10.1 KiB, free 912.3 MiB)
21/02/17 01:19:23 INFO MemoryStore: Block broadcast_2_piece0 stored as bytes in memory (estimated size 5.0 KiB, free 912.3 MiB)
21/02/17 01:19:23 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on localhost:34557 (size: 5.0 KiB, free: 912.3 MiB)
21/02/17 01:19:23 INFO SparkContext: Created broadcast 2 from broadcast at DAGScheduler.scala:1200
21/02/17 01:19:23 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 2 (MapPartitionsRDD[14] at count at utils.scala:135) (first 15 tasks are for partitions Vector(0))
21/02/17 01:19:23 INFO TaskSchedulerImpl: Adding task set 2.0 with 1 tasks
21/02/17 01:19:23 INFO TaskSetManager: Starting task 0.0 in stage 2.0 (TID 2, localhost, executor driver, partition 0, NODE_LOCAL, 7325 bytes)
21/02/17 01:19:23 INFO Executor: Running task 0.0 in stage 2.0 (TID 2)
21/02/17 01:19:23 INFO ShuffleBlockFetcherIterator: Getting 1 (60.0 B) non-empty blocks including 1 (60.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
21/02/17 01:19:23 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 5 ms
21/02/17 01:19:23 INFO Executor: Finished task 0.0 in stage 2.0 (TID 2). 2648 bytes result sent to driver
21/02/17 01:19:23 INFO TaskSetManager: Finished task 0.0 in stage 2.0 (TID 2) in 35 ms on localhost (executor driver) (1/1)
21/02/17 01:19:23 INFO TaskSchedulerImpl: Removed TaskSet 2.0, whose tasks have all completed, from pool 
21/02/17 01:19:23 INFO DAGScheduler: ResultStage 2 (count at utils.scala:135) finished in 0.044 s
21/02/17 01:19:23 INFO DAGScheduler: Job 2 is finished. Cancelling potential speculative or zombie tasks for this job
21/02/17 01:19:23 INFO TaskSchedulerImpl: Killing all running tasks in stage 2: Stage finished
21/02/17 01:19:23 INFO DAGScheduler: Job 2 finished: count at utils.scala:135, took 0.124518 s
21/02/17 01:19:23 INFO SparkContext: Starting job: collect at utils.scala:137
21/02/17 01:19:23 INFO DAGScheduler: Got job 3 (collect at utils.scala:137) with 1 output partitions
21/02/17 01:19:23 INFO DAGScheduler: Final stage: ResultStage 3 (collect at utils.scala:137)
21/02/17 01:19:23 INFO DAGScheduler: Parents of final stage: List()
21/02/17 01:19:23 INFO DAGScheduler: Missing parents: List()
21/02/17 01:19:23 INFO DAGScheduler: Submitting ResultStage 3 (MapPartitionsRDD[16] at collect at utils.scala:137), which has no missing parents
21/02/17 01:19:23 INFO MemoryStore: Block broadcast_3 stored as values in memory (estimated size 7.2 KiB, free 912.3 MiB)
21/02/17 01:19:23 INFO MemoryStore: Block broadcast_3_piece0 stored as bytes in memory (estimated size 3.7 KiB, free 912.3 MiB)
21/02/17 01:19:23 INFO BlockManagerInfo: Added broadcast_3_piece0 in memory on localhost:34557 (size: 3.7 KiB, free: 912.3 MiB)
21/02/17 01:19:23 INFO SparkContext: Created broadcast 3 from broadcast at DAGScheduler.scala:1200
21/02/17 01:19:23 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 3 (MapPartitionsRDD[16] at collect at utils.scala:137) (first 15 tasks are for partitions Vector(0))
21/02/17 01:19:23 INFO TaskSchedulerImpl: Adding task set 3.0 with 1 tasks
21/02/17 01:19:23 INFO TaskSetManager: Starting task 0.0 in stage 3.0 (TID 3, localhost, executor driver, partition 0, PROCESS_LOCAL, 7561 bytes)
21/02/17 01:19:23 INFO Executor: Running task 0.0 in stage 3.0 (TID 3)
21/02/17 01:19:23 INFO Executor: Finished task 0.0 in stage 3.0 (TID 3). 1397 bytes result sent to driver
21/02/17 01:19:23 INFO TaskSetManager: Finished task 0.0 in stage 3.0 (TID 3) in 6 ms on localhost (executor driver) (1/1)
21/02/17 01:19:23 INFO TaskSchedulerImpl: Removed TaskSet 3.0, whose tasks have all completed, from pool 
21/02/17 01:19:23 INFO DAGScheduler: ResultStage 3 (collect at utils.scala:137) finished in 0.013 s
21/02/17 01:19:23 INFO DAGScheduler: Job 3 is finished. Cancelling potential speculative or zombie tasks for this job
21/02/17 01:19:23 INFO TaskSchedulerImpl: Killing all running tasks in stage 3: Stage finished
21/02/17 01:19:23 INFO DAGScheduler: Job 3 finished: collect at utils.scala:137, took 0.015923 s
21/02/17 01:19:23 INFO SparkContext: Starting job: count at utils.scala:135
21/02/17 01:19:23 INFO DAGScheduler: Registering RDD 18 (count at utils.scala:135) as input to shuffle 1
21/02/17 01:19:23 INFO DAGScheduler: Got job 4 (count at utils.scala:135) with 1 output partitions
21/02/17 01:19:23 INFO DAGScheduler: Final stage: ResultStage 5 (count at utils.scala:135)
21/02/17 01:19:23 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 4)
21/02/17 01:19:23 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 4)
21/02/17 01:19:23 INFO DAGScheduler: Submitting ShuffleMapStage 4 (MapPartitionsRDD[18] at count at utils.scala:135), which has no missing parents
21/02/17 01:19:23 INFO MemoryStore: Block broadcast_4 stored as values in memory (estimated size 10.0 KiB, free 912.2 MiB)
21/02/17 01:19:23 INFO MemoryStore: Block broadcast_4_piece0 stored as bytes in memory (estimated size 5.2 KiB, free 912.2 MiB)
21/02/17 01:19:23 INFO BlockManagerInfo: Added broadcast_4_piece0 in memory on localhost:34557 (size: 5.2 KiB, free: 912.3 MiB)
21/02/17 01:19:23 INFO SparkContext: Created broadcast 4 from broadcast at DAGScheduler.scala:1200
21/02/17 01:19:23 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 4 (MapPartitionsRDD[18] at count at utils.scala:135) (first 15 tasks are for partitions Vector(0))
21/02/17 01:19:23 INFO TaskSchedulerImpl: Adding task set 4.0 with 1 tasks
21/02/17 01:19:23 INFO TaskSetManager: Starting task 0.0 in stage 4.0 (TID 4, localhost, executor driver, partition 0, PROCESS_LOCAL, 7550 bytes)
21/02/17 01:19:23 INFO Executor: Running task 0.0 in stage 4.0 (TID 4)
21/02/17 01:19:23 INFO Executor: Finished task 0.0 in stage 4.0 (TID 4). 1833 bytes result sent to driver
21/02/17 01:19:23 INFO TaskSetManager: Finished task 0.0 in stage 4.0 (TID 4) in 8 ms on localhost (executor driver) (1/1)
21/02/17 01:19:23 INFO TaskSchedulerImpl: Removed TaskSet 4.0, whose tasks have all completed, from pool 
21/02/17 01:19:23 INFO DAGScheduler: ShuffleMapStage 4 (count at utils.scala:135) finished in 0.015 s
21/02/17 01:19:23 INFO DAGScheduler: looking for newly runnable stages
21/02/17 01:19:23 INFO DAGScheduler: running: Set()
21/02/17 01:19:23 INFO DAGScheduler: waiting: Set(ResultStage 5)
21/02/17 01:19:23 INFO DAGScheduler: failed: Set()
21/02/17 01:19:23 INFO DAGScheduler: Submitting ResultStage 5 (MapPartitionsRDD[21] at count at utils.scala:135), which has no missing parents
21/02/17 01:19:23 INFO MemoryStore: Block broadcast_5 stored as values in memory (estimated size 10.1 KiB, free 912.2 MiB)
21/02/17 01:19:23 INFO MemoryStore: Block broadcast_5_piece0 stored as bytes in memory (estimated size 5.0 KiB, free 912.2 MiB)
21/02/17 01:19:23 INFO BlockManagerInfo: Added broadcast_5_piece0 in memory on localhost:34557 (size: 5.0 KiB, free: 912.3 MiB)
21/02/17 01:19:23 INFO SparkContext: Created broadcast 5 from broadcast at DAGScheduler.scala:1200
21/02/17 01:19:23 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 5 (MapPartitionsRDD[21] at count at utils.scala:135) (first 15 tasks are for partitions Vector(0))
21/02/17 01:19:23 INFO TaskSchedulerImpl: Adding task set 5.0 with 1 tasks
21/02/17 01:19:23 INFO TaskSetManager: Starting task 0.0 in stage 5.0 (TID 5, localhost, executor driver, partition 0, NODE_LOCAL, 7325 bytes)
21/02/17 01:19:23 INFO Executor: Running task 0.0 in stage 5.0 (TID 5)
21/02/17 01:19:23 INFO ShuffleBlockFetcherIterator: Getting 1 (60.0 B) non-empty blocks including 1 (60.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
21/02/17 01:19:23 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
21/02/17 01:19:23 INFO Executor: Finished task 0.0 in stage 5.0 (TID 5). 2648 bytes result sent to driver
21/02/17 01:19:23 INFO TaskSetManager: Finished task 0.0 in stage 5.0 (TID 5) in 8 ms on localhost (executor driver) (1/1)
21/02/17 01:19:23 INFO TaskSchedulerImpl: Removed TaskSet 5.0, whose tasks have all completed, from pool 
21/02/17 01:19:23 INFO DAGScheduler: ResultStage 5 (count at utils.scala:135) finished in 0.016 s
21/02/17 01:19:23 INFO DAGScheduler: Job 4 is finished. Cancelling potential speculative or zombie tasks for this job
21/02/17 01:19:23 INFO TaskSchedulerImpl: Killing all running tasks in stage 5: Stage finished
21/02/17 01:19:23 INFO DAGScheduler: Job 4 finished: count at utils.scala:135, took 0.037190 s
21/02/17 01:19:23 INFO BlockManagerInfo: Removed broadcast_2_piece0 on localhost:34557 in memory (size: 5.0 KiB, free: 912.3 MiB)
21/02/17 01:19:23 INFO BlockManagerInfo: Removed broadcast_0_piece0 on localhost:34557 in memory (size: 3.2 KiB, free: 912.3 MiB)
21/02/17 01:19:23 INFO BlockManagerInfo: Removed broadcast_1_piece0 on localhost:34557 in memory (size: 5.2 KiB, free: 912.3 MiB)
21/02/17 01:19:23 INFO BlockManagerInfo: Removed broadcast_5_piece0 on localhost:34557 in memory (size: 5.0 KiB, free: 912.3 MiB)
21/02/17 01:19:23 INFO BlockManagerInfo: Removed broadcast_3_piece0 on localhost:34557 in memory (size: 3.7 KiB, free: 912.3 MiB)
21/02/17 01:19:23 INFO BlockManagerInfo: Removed broadcast_4_piece0 on localhost:34557 in memory (size: 5.2 KiB, free: 912.3 MiB)
21/02/17 01:19:25 INFO SparkContext: Invoking stop() from shutdown hook
21/02/17 01:19:25 INFO SparkUI: Stopped Spark web UI at http://localhost:4040
21/02/17 01:19:25 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!
21/02/17 01:19:25 INFO MemoryStore: MemoryStore cleared
21/02/17 01:19:25 INFO BlockManager: BlockManager stopped
21/02/17 01:19:25 INFO BlockManagerMaster: BlockManagerMaster stopped
21/02/17 01:19:25 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!
21/02/17 01:19:25 INFO SparkContext: Successfully stopped SparkContext
21/02/17 01:19:25 INFO ShutdownHookManager: Shutdown hook called
21/02/17 01:19:25 INFO ShutdownHookManager: Deleting directory /tmp/spark-825bfa25-42b1-4b5c-b0d6-e725b8033e51
21/02/17 01:19:25 INFO ShutdownHookManager: Deleting directory /tmp/spark-1fe84a08-9325-429f-ab04-c90ef4ca8074
21/02/17 01:20:49 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
21/02/17 01:20:49 INFO SecurityManager: Changing view acls to: yitaoli
21/02/17 01:20:49 INFO SecurityManager: Changing modify acls to: yitaoli
21/02/17 01:20:49 INFO SecurityManager: Changing view acls groups to: 
21/02/17 01:20:49 INFO SecurityManager: Changing modify acls groups to: 
21/02/17 01:20:49 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(yitaoli); groups with view permissions: Set(); users  with modify permissions: Set(yitaoli); groups with modify permissions: Set()
21/02/17 01:21:49 INFO ShutdownHookManager: Shutdown hook called
21/02/17 01:21:49 INFO ShutdownHookManager: Deleting directory /tmp/spark-23e403e6-55bc-41f7-8ecb-b3e24bcc5fae
21/02/17 01:21:55 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
21/02/17 01:21:55 INFO SecurityManager: Changing view acls to: yitaoli
21/02/17 01:21:55 INFO SecurityManager: Changing modify acls to: yitaoli
21/02/17 01:21:55 INFO SecurityManager: Changing view acls groups to: 
21/02/17 01:21:55 INFO SecurityManager: Changing modify acls groups to: 
21/02/17 01:21:55 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(yitaoli); groups with view permissions: Set(); users  with modify permissions: Set(yitaoli); groups with modify permissions: Set()
21/02/17 01:21:55 INFO HiveConf: Found configuration file file:/home/yitaoli/spark/spark-3.0.0-bin-hadoop3.2/conf/hive-site.xml
21/02/17 01:21:55 INFO SparkContext: Running Spark version 3.0.0
21/02/17 01:21:55 INFO ResourceUtils: ==============================================================
21/02/17 01:21:55 INFO ResourceUtils: Resources for spark.driver:

21/02/17 01:21:55 INFO ResourceUtils: ==============================================================
21/02/17 01:21:55 INFO SparkContext: Submitted application: sparklyr
21/02/17 01:21:55 INFO SecurityManager: Changing view acls to: yitaoli
21/02/17 01:21:55 INFO SecurityManager: Changing modify acls to: yitaoli
21/02/17 01:21:55 INFO SecurityManager: Changing view acls groups to: 
21/02/17 01:21:55 INFO SecurityManager: Changing modify acls groups to: 
21/02/17 01:21:55 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(yitaoli); groups with view permissions: Set(); users  with modify permissions: Set(yitaoli); groups with modify permissions: Set()
21/02/17 01:21:55 INFO Utils: Successfully started service 'sparkDriver' on port 35733.
21/02/17 01:21:56 INFO SparkEnv: Registering MapOutputTracker
21/02/17 01:21:56 INFO SparkEnv: Registering BlockManagerMaster
21/02/17 01:21:56 INFO BlockManagerMasterEndpoint: Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
21/02/17 01:21:56 INFO BlockManagerMasterEndpoint: BlockManagerMasterEndpoint up
21/02/17 01:21:56 INFO SparkEnv: Registering BlockManagerMasterHeartbeat
21/02/17 01:21:56 INFO DiskBlockManager: Created local directory at /tmp/blockmgr-e2ee4cb4-63e8-4e54-b424-301a1064a54f
21/02/17 01:21:56 INFO MemoryStore: MemoryStore started with capacity 912.3 MiB
21/02/17 01:21:56 INFO SparkEnv: Registering OutputCommitCoordinator
21/02/17 01:21:56 INFO Utils: Successfully started service 'SparkUI' on port 4040.
21/02/17 01:21:56 INFO SparkUI: Bound SparkUI to 127.0.0.1, and started at http://localhost:4040
21/02/17 01:21:56 INFO SparkContext: Added JAR file:/home/yitaoli/R/x86_64-pc-linux-gnu-library/4.0/sparklyr/java/sparklyr-3.0-2.12.jar at spark://localhost:35733/jars/sparklyr-3.0-2.12.jar with timestamp 1613524916349
21/02/17 01:21:56 INFO Executor: Starting executor ID driver on host localhost
21/02/17 01:21:56 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 42805.
21/02/17 01:21:56 INFO NettyBlockTransferService: Server created on localhost:42805
21/02/17 01:21:56 INFO BlockManager: Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
21/02/17 01:21:56 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, localhost, 42805, None)
21/02/17 01:21:56 INFO BlockManagerMasterEndpoint: Registering block manager localhost:42805 with 912.3 MiB RAM, BlockManagerId(driver, localhost, 42805, None)
21/02/17 01:21:56 INFO BlockManagerMaster: Registered BlockManager BlockManagerId(driver, localhost, 42805, None)
21/02/17 01:21:56 INFO BlockManager: Initialized BlockManager: BlockManagerId(driver, localhost, 42805, None)
21/02/17 01:21:56 INFO SharedState: loading hive config file: file:/home/yitaoli/spark/spark-3.0.0-bin-hadoop3.2/conf/hive-site.xml
21/02/17 01:21:56 INFO SharedState: Setting hive.metastore.warehouse.dir ('null') to the value of spark.sql.warehouse.dir ('file:/home/yitaoli/sparkxgb/tests/testthat/spark-warehouse').
21/02/17 01:21:56 INFO SharedState: Warehouse path is 'file:/home/yitaoli/sparkxgb/tests/testthat/spark-warehouse'.
21/02/17 01:21:56 INFO SparkContext: Invoking stop() from shutdown hook
21/02/17 01:21:56 INFO SparkUI: Stopped Spark web UI at http://localhost:4040
21/02/17 01:21:56 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!
21/02/17 01:21:56 INFO MemoryStore: MemoryStore cleared
21/02/17 01:21:56 INFO BlockManager: BlockManager stopped
21/02/17 01:21:56 INFO BlockManagerMaster: BlockManagerMaster stopped
21/02/17 01:21:56 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!
21/02/17 01:21:56 INFO SparkContext: Successfully stopped SparkContext
21/02/17 01:21:56 INFO ShutdownHookManager: Shutdown hook called
21/02/17 01:21:56 INFO ShutdownHookManager: Deleting directory /tmp/spark-203047c3-cdc9-4b73-aee2-10a2aec75023
21/02/17 01:21:56 INFO ShutdownHookManager: Deleting directory /tmp/spark-5a6a9a96-590a-446f-b31f-d380eb16d9f0
21/02/17 01:22:42 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
21/02/17 01:22:42 INFO SecurityManager: Changing view acls to: yitaoli
21/02/17 01:22:42 INFO SecurityManager: Changing modify acls to: yitaoli
21/02/17 01:22:42 INFO SecurityManager: Changing view acls groups to: 
21/02/17 01:22:42 INFO SecurityManager: Changing modify acls groups to: 
21/02/17 01:22:42 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(yitaoli); groups with view permissions: Set(); users  with modify permissions: Set(yitaoli); groups with modify permissions: Set()
21/02/17 01:22:43 INFO ShutdownHookManager: Shutdown hook called
21/02/17 01:22:43 INFO ShutdownHookManager: Deleting directory /tmp/spark-d9cae924-3588-430a-8f39-aebf61a3c6bd
21/02/17 01:25:35 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
21/02/17 01:25:36 INFO SecurityManager: Changing view acls to: yitaoli
21/02/17 01:25:36 INFO SecurityManager: Changing modify acls to: yitaoli
21/02/17 01:25:36 INFO SecurityManager: Changing view acls groups to: 
21/02/17 01:25:36 INFO SecurityManager: Changing modify acls groups to: 
21/02/17 01:25:36 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(yitaoli); groups with view permissions: Set(); users  with modify permissions: Set(yitaoli); groups with modify permissions: Set()
21/02/17 01:25:36 INFO HiveConf: Found configuration file file:/home/yitaoli/spark/spark-3.0.0-bin-hadoop3.2/conf/hive-site.xml
21/02/17 01:25:36 INFO SparkContext: Running Spark version 3.0.0
21/02/17 01:25:36 INFO ResourceUtils: ==============================================================
21/02/17 01:25:36 INFO ResourceUtils: Resources for spark.driver:

21/02/17 01:25:36 INFO ResourceUtils: ==============================================================
21/02/17 01:25:36 INFO SparkContext: Submitted application: sparklyr
21/02/17 01:25:36 INFO SecurityManager: Changing view acls to: yitaoli
21/02/17 01:25:36 INFO SecurityManager: Changing modify acls to: yitaoli
21/02/17 01:25:36 INFO SecurityManager: Changing view acls groups to: 
21/02/17 01:25:36 INFO SecurityManager: Changing modify acls groups to: 
21/02/17 01:25:36 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(yitaoli); groups with view permissions: Set(); users  with modify permissions: Set(yitaoli); groups with modify permissions: Set()
21/02/17 01:25:36 INFO Utils: Successfully started service 'sparkDriver' on port 40347.
21/02/17 01:25:36 INFO SparkEnv: Registering MapOutputTracker
21/02/17 01:25:36 INFO SparkEnv: Registering BlockManagerMaster
21/02/17 01:25:36 INFO BlockManagerMasterEndpoint: Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
21/02/17 01:25:36 INFO BlockManagerMasterEndpoint: BlockManagerMasterEndpoint up
21/02/17 01:25:36 INFO SparkEnv: Registering BlockManagerMasterHeartbeat
21/02/17 01:25:36 INFO DiskBlockManager: Created local directory at /tmp/blockmgr-2dbb706d-d32d-4886-9720-331b5db84394
21/02/17 01:25:36 INFO MemoryStore: MemoryStore started with capacity 912.3 MiB
21/02/17 01:25:36 INFO SparkEnv: Registering OutputCommitCoordinator
21/02/17 01:25:37 INFO Utils: Successfully started service 'SparkUI' on port 4040.
21/02/17 01:25:37 INFO SparkUI: Bound SparkUI to 127.0.0.1, and started at http://localhost:4040
21/02/17 01:25:37 INFO SparkContext: Added JAR file:///home/yitaoli/.ivy2/jars/ml.dmlc_xgboost4j-spark_2.12-1.3.1.jar at spark://localhost:40347/jars/ml.dmlc_xgboost4j-spark_2.12-1.3.1.jar with timestamp 1613525137236
21/02/17 01:25:37 INFO SparkContext: Added JAR file:///home/yitaoli/.ivy2/jars/ml.dmlc_xgboost4j_2.12-1.3.1.jar at spark://localhost:40347/jars/ml.dmlc_xgboost4j_2.12-1.3.1.jar with timestamp 1613525137237
21/02/17 01:25:37 INFO SparkContext: Added JAR file:///home/yitaoli/.ivy2/jars/com.esotericsoftware_kryo-4.0.2.jar at spark://localhost:40347/jars/com.esotericsoftware_kryo-4.0.2.jar with timestamp 1613525137237
21/02/17 01:25:37 INFO SparkContext: Added JAR file:///home/yitaoli/.ivy2/jars/org.scala-lang_scala-compiler-2.12.8.jar at spark://localhost:40347/jars/org.scala-lang_scala-compiler-2.12.8.jar with timestamp 1613525137237
21/02/17 01:25:37 INFO SparkContext: Added JAR file:///home/yitaoli/.ivy2/jars/org.scala-lang_scala-reflect-2.12.8.jar at spark://localhost:40347/jars/org.scala-lang_scala-reflect-2.12.8.jar with timestamp 1613525137237
21/02/17 01:25:37 INFO SparkContext: Added JAR file:///home/yitaoli/.ivy2/jars/commons-logging_commons-logging-1.2.jar at spark://localhost:40347/jars/commons-logging_commons-logging-1.2.jar with timestamp 1613525137237
21/02/17 01:25:37 INFO SparkContext: Added JAR file:///home/yitaoli/.ivy2/jars/com.typesafe.akka_akka-actor_2.12-2.5.23.jar at spark://localhost:40347/jars/com.typesafe.akka_akka-actor_2.12-2.5.23.jar with timestamp 1613525137237
21/02/17 01:25:37 INFO SparkContext: Added JAR file:///home/yitaoli/.ivy2/jars/org.scalatest_scalatest_2.12-3.0.5.jar at spark://localhost:40347/jars/org.scalatest_scalatest_2.12-3.0.5.jar with timestamp 1613525137237
21/02/17 01:25:37 INFO SparkContext: Added JAR file:///home/yitaoli/.ivy2/jars/com.typesafe_config-1.3.3.jar at spark://localhost:40347/jars/com.typesafe_config-1.3.3.jar with timestamp 1613525137237
21/02/17 01:25:37 INFO SparkContext: Added JAR file:///home/yitaoli/.ivy2/jars/org.scala-lang.modules_scala-java8-compat_2.12-0.8.0.jar at spark://localhost:40347/jars/org.scala-lang.modules_scala-java8-compat_2.12-0.8.0.jar with timestamp 1613525137238
21/02/17 01:25:37 INFO SparkContext: Added JAR file:///home/yitaoli/.ivy2/jars/org.scalactic_scalactic_2.12-3.0.5.jar at spark://localhost:40347/jars/org.scalactic_scalactic_2.12-3.0.5.jar with timestamp 1613525137238
21/02/17 01:25:37 INFO SparkContext: Added JAR file:///home/yitaoli/.ivy2/jars/org.scala-lang.modules_scala-xml_2.12-1.0.6.jar at spark://localhost:40347/jars/org.scala-lang.modules_scala-xml_2.12-1.0.6.jar with timestamp 1613525137238
21/02/17 01:25:37 INFO SparkContext: Added JAR file:///home/yitaoli/.ivy2/jars/com.esotericsoftware_reflectasm-1.11.3.jar at spark://localhost:40347/jars/com.esotericsoftware_reflectasm-1.11.3.jar with timestamp 1613525137238
21/02/17 01:25:37 INFO SparkContext: Added JAR file:///home/yitaoli/.ivy2/jars/com.esotericsoftware_minlog-1.3.0.jar at spark://localhost:40347/jars/com.esotericsoftware_minlog-1.3.0.jar with timestamp 1613525137238
21/02/17 01:25:37 INFO SparkContext: Added JAR file:///home/yitaoli/.ivy2/jars/org.objenesis_objenesis-2.5.1.jar at spark://localhost:40347/jars/org.objenesis_objenesis-2.5.1.jar with timestamp 1613525137238
21/02/17 01:25:37 INFO SparkContext: Added JAR file:///home/yitaoli/.ivy2/jars/org.ow2.asm_asm-5.0.4.jar at spark://localhost:40347/jars/org.ow2.asm_asm-5.0.4.jar with timestamp 1613525137239
21/02/17 01:25:37 INFO SparkContext: Added JAR file:/home/yitaoli/R/x86_64-pc-linux-gnu-library/4.0/sparklyr/java/sparklyr-3.0-2.12.jar at spark://localhost:40347/jars/sparklyr-3.0-2.12.jar with timestamp 1613525137239
21/02/17 01:25:37 INFO Executor: Starting executor ID driver on host localhost
21/02/17 01:25:37 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 41017.
21/02/17 01:25:37 INFO NettyBlockTransferService: Server created on localhost:41017
21/02/17 01:25:37 INFO BlockManager: Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
21/02/17 01:25:37 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, localhost, 41017, None)
21/02/17 01:25:37 INFO BlockManagerMasterEndpoint: Registering block manager localhost:41017 with 912.3 MiB RAM, BlockManagerId(driver, localhost, 41017, None)
21/02/17 01:25:37 INFO BlockManagerMaster: Registered BlockManager BlockManagerId(driver, localhost, 41017, None)
21/02/17 01:25:37 INFO BlockManager: Initialized BlockManager: BlockManagerId(driver, localhost, 41017, None)
21/02/17 01:25:37 INFO SharedState: loading hive config file: file:/home/yitaoli/spark/spark-3.0.0-bin-hadoop3.2/conf/hive-site.xml
21/02/17 01:25:37 INFO SharedState: Setting hive.metastore.warehouse.dir ('null') to the value of spark.sql.warehouse.dir ('file:/home/yitaoli/sparkxgb/tests/testthat/spark-warehouse').
21/02/17 01:25:37 INFO SharedState: Warehouse path is 'file:/home/yitaoli/sparkxgb/tests/testthat/spark-warehouse'.
21/02/17 01:25:39 INFO HiveUtils: Initializing HiveMetastoreConnection version 2.3.7 using Spark classes.
21/02/17 01:25:39 INFO HiveConf: Found configuration file file:/home/yitaoli/spark/spark-3.0.0-bin-hadoop3.2/conf/hive-site.xml
21/02/17 01:25:39 INFO SessionState: Created HDFS directory: /tmp/hive/yitaoli/a051ab30-fa21-4ee2-b3f7-cdaece48ce70
21/02/17 01:25:39 INFO SessionState: Created local directory: /tmp/yitaoli/a051ab30-fa21-4ee2-b3f7-cdaece48ce70
21/02/17 01:25:39 INFO SessionState: Created HDFS directory: /tmp/hive/yitaoli/a051ab30-fa21-4ee2-b3f7-cdaece48ce70/_tmp_space.db
21/02/17 01:25:39 INFO HiveClientImpl: Warehouse location for Hive client (version 2.3.7) is file:/home/yitaoli/sparkxgb/tests/testthat/spark-warehouse
21/02/17 01:25:40 WARN HiveConf: HiveConf of name hive.stats.jdbc.timeout does not exist
21/02/17 01:25:40 WARN HiveConf: HiveConf of name hive.stats.retries.wait does not exist
21/02/17 01:25:40 INFO HiveMetaStore: 0: Opening raw store with implementation class:org.apache.hadoop.hive.metastore.ObjectStore
21/02/17 01:25:40 INFO ObjectStore: ObjectStore, initialize called
21/02/17 01:25:40 INFO Persistence: Property hive.metastore.integral.jdo.pushdown unknown - will be ignored
21/02/17 01:25:40 INFO Persistence: Property datanucleus.cache.level2 unknown - will be ignored
21/02/17 01:25:41 INFO ObjectStore: Setting MetaStore object pin classes with hive.metastore.cache.pinobjtypes="Table,StorageDescriptor,SerDeInfo,Partition,Database,Type,FieldSchema,Order"
21/02/17 01:25:42 INFO MetaStoreDirectSql: Using direct SQL, underlying DB is DERBY
21/02/17 01:25:42 INFO ObjectStore: Initialized ObjectStore
21/02/17 01:25:42 WARN ObjectStore: Version information not found in metastore. hive.metastore.schema.verification is not enabled so recording the schema version 2.3.0
21/02/17 01:25:42 WARN ObjectStore: setMetaStoreSchemaVersion called but recording version is disabled: version = 2.3.0, comment = Set by MetaStore yitaoli@127.0.1.1
21/02/17 01:25:42 WARN ObjectStore: Failed to get database default, returning NoSuchObjectException
21/02/17 01:25:42 INFO HiveMetaStore: Added admin role in metastore
21/02/17 01:25:42 INFO HiveMetaStore: Added public role in metastore
21/02/17 01:25:42 INFO HiveMetaStore: No user is added in admin role, since config is empty
21/02/17 01:25:42 INFO HiveMetaStore: 0: get_all_functions
21/02/17 01:25:42 INFO audit: ugi=yitaoli	ip=unknown-ip-addr	cmd=get_all_functions	
21/02/17 01:25:42 INFO HiveMetaStore: 0: get_database: default
21/02/17 01:25:42 INFO audit: ugi=yitaoli	ip=unknown-ip-addr	cmd=get_database: default	
21/02/17 01:25:42 INFO HiveMetaStore: 0: get_database: default
21/02/17 01:25:42 INFO audit: ugi=yitaoli	ip=unknown-ip-addr	cmd=get_database: default	
21/02/17 01:25:42 INFO HiveMetaStore: 0: get_table : db=default tbl=iris
21/02/17 01:25:42 INFO audit: ugi=yitaoli	ip=unknown-ip-addr	cmd=get_table : db=default tbl=iris	
21/02/17 01:25:43 INFO HiveMetaStore: 0: get_database: global_temp
21/02/17 01:25:43 INFO audit: ugi=yitaoli	ip=unknown-ip-addr	cmd=get_database: global_temp	
21/02/17 01:25:43 WARN ObjectStore: Failed to get database global_temp, returning NoSuchObjectException
21/02/17 01:25:43 INFO HiveMetaStore: 0: get_database: default
21/02/17 01:25:43 INFO audit: ugi=yitaoli	ip=unknown-ip-addr	cmd=get_database: default	
21/02/17 01:25:43 INFO HiveMetaStore: 0: get_database: default
21/02/17 01:25:43 INFO audit: ugi=yitaoli	ip=unknown-ip-addr	cmd=get_database: default	
21/02/17 01:25:43 INFO HiveMetaStore: 0: get_tables: db=default pat=*
21/02/17 01:25:43 INFO audit: ugi=yitaoli	ip=unknown-ip-addr	cmd=get_tables: db=default pat=*	
21/02/17 01:25:43 INFO SparkContext: Starting job: collect at utils.scala:54
21/02/17 01:25:43 INFO DAGScheduler: Job 0 finished: collect at utils.scala:54, took 0.004226 s
21/02/17 01:25:44 INFO CodeGenerator: Code generated in 179.611287 ms
21/02/17 01:25:44 INFO SparkContext: Starting job: collect at utils.scala:137
21/02/17 01:25:44 INFO DAGScheduler: Got job 1 (collect at utils.scala:137) with 1 output partitions
21/02/17 01:25:44 INFO DAGScheduler: Final stage: ResultStage 0 (collect at utils.scala:137)
21/02/17 01:25:44 INFO DAGScheduler: Parents of final stage: List()
21/02/17 01:25:44 INFO DAGScheduler: Missing parents: List()
21/02/17 01:25:44 INFO DAGScheduler: Submitting ResultStage 0 (MapPartitionsRDD[9] at collect at utils.scala:137), which has no missing parents
21/02/17 01:25:44 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 6.5 KiB, free 912.3 MiB)
21/02/17 01:25:44 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 3.2 KiB, free 912.3 MiB)
21/02/17 01:25:44 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on localhost:41017 (size: 3.2 KiB, free: 912.3 MiB)
21/02/17 01:25:44 INFO SparkContext: Created broadcast 0 from broadcast at DAGScheduler.scala:1200
21/02/17 01:25:44 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 0 (MapPartitionsRDD[9] at collect at utils.scala:137) (first 15 tasks are for partitions Vector(0))
21/02/17 01:25:44 INFO TaskSchedulerImpl: Adding task set 0.0 with 1 tasks
21/02/17 01:25:44 INFO TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0, localhost, executor driver, partition 0, PROCESS_LOCAL, 7561 bytes)
21/02/17 01:25:44 INFO Executor: Running task 0.0 in stage 0.0 (TID 0)
21/02/17 01:25:44 INFO Executor: Fetching spark://localhost:40347/jars/com.esotericsoftware_reflectasm-1.11.3.jar with timestamp 1613525137238
21/02/17 01:25:44 INFO TransportClientFactory: Successfully created connection to localhost/127.0.0.1:40347 after 12 ms (0 ms spent in bootstraps)
21/02/17 01:25:44 INFO Utils: Fetching spark://localhost:40347/jars/com.esotericsoftware_reflectasm-1.11.3.jar to /tmp/spark-a38c6647-1a67-4a7f-9f82-3ad2a125e026/userFiles-a504077d-7706-4da9-be9d-fd886d992c6a/fetchFileTemp4567652267976740655.tmp
21/02/17 01:25:44 INFO Executor: Adding file:/tmp/spark-a38c6647-1a67-4a7f-9f82-3ad2a125e026/userFiles-a504077d-7706-4da9-be9d-fd886d992c6a/com.esotericsoftware_reflectasm-1.11.3.jar to class loader
21/02/17 01:25:44 INFO Executor: Fetching spark://localhost:40347/jars/org.scalactic_scalactic_2.12-3.0.5.jar with timestamp 1613525137238
21/02/17 01:25:44 INFO Utils: Fetching spark://localhost:40347/jars/org.scalactic_scalactic_2.12-3.0.5.jar to /tmp/spark-a38c6647-1a67-4a7f-9f82-3ad2a125e026/userFiles-a504077d-7706-4da9-be9d-fd886d992c6a/fetchFileTemp3311625583727256429.tmp
21/02/17 01:25:44 INFO Executor: Adding file:/tmp/spark-a38c6647-1a67-4a7f-9f82-3ad2a125e026/userFiles-a504077d-7706-4da9-be9d-fd886d992c6a/org.scalactic_scalactic_2.12-3.0.5.jar to class loader
21/02/17 01:25:44 INFO Executor: Fetching spark://localhost:40347/jars/com.typesafe_config-1.3.3.jar with timestamp 1613525137237
21/02/17 01:25:44 INFO Utils: Fetching spark://localhost:40347/jars/com.typesafe_config-1.3.3.jar to /tmp/spark-a38c6647-1a67-4a7f-9f82-3ad2a125e026/userFiles-a504077d-7706-4da9-be9d-fd886d992c6a/fetchFileTemp6349919246172092719.tmp
21/02/17 01:25:44 INFO Executor: Adding file:/tmp/spark-a38c6647-1a67-4a7f-9f82-3ad2a125e026/userFiles-a504077d-7706-4da9-be9d-fd886d992c6a/com.typesafe_config-1.3.3.jar to class loader
21/02/17 01:25:44 INFO Executor: Fetching spark://localhost:40347/jars/org.scala-lang.modules_scala-xml_2.12-1.0.6.jar with timestamp 1613525137238
21/02/17 01:25:44 INFO Utils: Fetching spark://localhost:40347/jars/org.scala-lang.modules_scala-xml_2.12-1.0.6.jar to /tmp/spark-a38c6647-1a67-4a7f-9f82-3ad2a125e026/userFiles-a504077d-7706-4da9-be9d-fd886d992c6a/fetchFileTemp6727391593052470996.tmp
21/02/17 01:25:44 INFO Executor: Adding file:/tmp/spark-a38c6647-1a67-4a7f-9f82-3ad2a125e026/userFiles-a504077d-7706-4da9-be9d-fd886d992c6a/org.scala-lang.modules_scala-xml_2.12-1.0.6.jar to class loader
21/02/17 01:25:44 INFO Executor: Fetching spark://localhost:40347/jars/ml.dmlc_xgboost4j_2.12-1.3.1.jar with timestamp 1613525137237
21/02/17 01:25:44 INFO Utils: Fetching spark://localhost:40347/jars/ml.dmlc_xgboost4j_2.12-1.3.1.jar to /tmp/spark-a38c6647-1a67-4a7f-9f82-3ad2a125e026/userFiles-a504077d-7706-4da9-be9d-fd886d992c6a/fetchFileTemp7268057795658107787.tmp
21/02/17 01:25:44 INFO Executor: Adding file:/tmp/spark-a38c6647-1a67-4a7f-9f82-3ad2a125e026/userFiles-a504077d-7706-4da9-be9d-fd886d992c6a/ml.dmlc_xgboost4j_2.12-1.3.1.jar to class loader
21/02/17 01:25:44 INFO Executor: Fetching spark://localhost:40347/jars/com.typesafe.akka_akka-actor_2.12-2.5.23.jar with timestamp 1613525137237
21/02/17 01:25:44 INFO Utils: Fetching spark://localhost:40347/jars/com.typesafe.akka_akka-actor_2.12-2.5.23.jar to /tmp/spark-a38c6647-1a67-4a7f-9f82-3ad2a125e026/userFiles-a504077d-7706-4da9-be9d-fd886d992c6a/fetchFileTemp7293778465664712871.tmp
21/02/17 01:25:44 INFO Executor: Adding file:/tmp/spark-a38c6647-1a67-4a7f-9f82-3ad2a125e026/userFiles-a504077d-7706-4da9-be9d-fd886d992c6a/com.typesafe.akka_akka-actor_2.12-2.5.23.jar to class loader
21/02/17 01:25:44 INFO Executor: Fetching spark://localhost:40347/jars/org.scala-lang_scala-reflect-2.12.8.jar with timestamp 1613525137237
21/02/17 01:25:44 INFO Utils: Fetching spark://localhost:40347/jars/org.scala-lang_scala-reflect-2.12.8.jar to /tmp/spark-a38c6647-1a67-4a7f-9f82-3ad2a125e026/userFiles-a504077d-7706-4da9-be9d-fd886d992c6a/fetchFileTemp4071437870171136546.tmp
21/02/17 01:25:44 INFO Executor: Adding file:/tmp/spark-a38c6647-1a67-4a7f-9f82-3ad2a125e026/userFiles-a504077d-7706-4da9-be9d-fd886d992c6a/org.scala-lang_scala-reflect-2.12.8.jar to class loader
21/02/17 01:25:44 INFO Executor: Fetching spark://localhost:40347/jars/org.scalatest_scalatest_2.12-3.0.5.jar with timestamp 1613525137237
21/02/17 01:25:44 INFO Utils: Fetching spark://localhost:40347/jars/org.scalatest_scalatest_2.12-3.0.5.jar to /tmp/spark-a38c6647-1a67-4a7f-9f82-3ad2a125e026/userFiles-a504077d-7706-4da9-be9d-fd886d992c6a/fetchFileTemp6017925954490152171.tmp
21/02/17 01:25:44 INFO Executor: Adding file:/tmp/spark-a38c6647-1a67-4a7f-9f82-3ad2a125e026/userFiles-a504077d-7706-4da9-be9d-fd886d992c6a/org.scalatest_scalatest_2.12-3.0.5.jar to class loader
21/02/17 01:25:44 INFO Executor: Fetching spark://localhost:40347/jars/org.objenesis_objenesis-2.5.1.jar with timestamp 1613525137238
21/02/17 01:25:44 INFO Utils: Fetching spark://localhost:40347/jars/org.objenesis_objenesis-2.5.1.jar to /tmp/spark-a38c6647-1a67-4a7f-9f82-3ad2a125e026/userFiles-a504077d-7706-4da9-be9d-fd886d992c6a/fetchFileTemp2218031835762925267.tmp
21/02/17 01:25:44 INFO Executor: Adding file:/tmp/spark-a38c6647-1a67-4a7f-9f82-3ad2a125e026/userFiles-a504077d-7706-4da9-be9d-fd886d992c6a/org.objenesis_objenesis-2.5.1.jar to class loader
21/02/17 01:25:44 INFO Executor: Fetching spark://localhost:40347/jars/com.esotericsoftware_kryo-4.0.2.jar with timestamp 1613525137237
21/02/17 01:25:44 INFO Utils: Fetching spark://localhost:40347/jars/com.esotericsoftware_kryo-4.0.2.jar to /tmp/spark-a38c6647-1a67-4a7f-9f82-3ad2a125e026/userFiles-a504077d-7706-4da9-be9d-fd886d992c6a/fetchFileTemp3762329896015958377.tmp
21/02/17 01:25:44 INFO Executor: Adding file:/tmp/spark-a38c6647-1a67-4a7f-9f82-3ad2a125e026/userFiles-a504077d-7706-4da9-be9d-fd886d992c6a/com.esotericsoftware_kryo-4.0.2.jar to class loader
21/02/17 01:25:44 INFO Executor: Fetching spark://localhost:40347/jars/sparklyr-3.0-2.12.jar with timestamp 1613525137239
21/02/17 01:25:44 INFO Utils: Fetching spark://localhost:40347/jars/sparklyr-3.0-2.12.jar to /tmp/spark-a38c6647-1a67-4a7f-9f82-3ad2a125e026/userFiles-a504077d-7706-4da9-be9d-fd886d992c6a/fetchFileTemp5915524930142044628.tmp
21/02/17 01:25:44 INFO Executor: Adding file:/tmp/spark-a38c6647-1a67-4a7f-9f82-3ad2a125e026/userFiles-a504077d-7706-4da9-be9d-fd886d992c6a/sparklyr-3.0-2.12.jar to class loader
21/02/17 01:25:44 INFO Executor: Fetching spark://localhost:40347/jars/ml.dmlc_xgboost4j-spark_2.12-1.3.1.jar with timestamp 1613525137236
21/02/17 01:25:44 INFO Utils: Fetching spark://localhost:40347/jars/ml.dmlc_xgboost4j-spark_2.12-1.3.1.jar to /tmp/spark-a38c6647-1a67-4a7f-9f82-3ad2a125e026/userFiles-a504077d-7706-4da9-be9d-fd886d992c6a/fetchFileTemp3530983474827498369.tmp
21/02/17 01:25:44 INFO Executor: Adding file:/tmp/spark-a38c6647-1a67-4a7f-9f82-3ad2a125e026/userFiles-a504077d-7706-4da9-be9d-fd886d992c6a/ml.dmlc_xgboost4j-spark_2.12-1.3.1.jar to class loader
21/02/17 01:25:44 INFO Executor: Fetching spark://localhost:40347/jars/org.scala-lang.modules_scala-java8-compat_2.12-0.8.0.jar with timestamp 1613525137238
21/02/17 01:25:44 INFO Utils: Fetching spark://localhost:40347/jars/org.scala-lang.modules_scala-java8-compat_2.12-0.8.0.jar to /tmp/spark-a38c6647-1a67-4a7f-9f82-3ad2a125e026/userFiles-a504077d-7706-4da9-be9d-fd886d992c6a/fetchFileTemp3843491211067224950.tmp
21/02/17 01:25:44 INFO Executor: Adding file:/tmp/spark-a38c6647-1a67-4a7f-9f82-3ad2a125e026/userFiles-a504077d-7706-4da9-be9d-fd886d992c6a/org.scala-lang.modules_scala-java8-compat_2.12-0.8.0.jar to class loader
21/02/17 01:25:44 INFO Executor: Fetching spark://localhost:40347/jars/org.ow2.asm_asm-5.0.4.jar with timestamp 1613525137239
21/02/17 01:25:44 INFO Utils: Fetching spark://localhost:40347/jars/org.ow2.asm_asm-5.0.4.jar to /tmp/spark-a38c6647-1a67-4a7f-9f82-3ad2a125e026/userFiles-a504077d-7706-4da9-be9d-fd886d992c6a/fetchFileTemp2548648265660585046.tmp
21/02/17 01:25:44 INFO Executor: Adding file:/tmp/spark-a38c6647-1a67-4a7f-9f82-3ad2a125e026/userFiles-a504077d-7706-4da9-be9d-fd886d992c6a/org.ow2.asm_asm-5.0.4.jar to class loader
21/02/17 01:25:44 INFO Executor: Fetching spark://localhost:40347/jars/commons-logging_commons-logging-1.2.jar with timestamp 1613525137237
21/02/17 01:25:44 INFO Utils: Fetching spark://localhost:40347/jars/commons-logging_commons-logging-1.2.jar to /tmp/spark-a38c6647-1a67-4a7f-9f82-3ad2a125e026/userFiles-a504077d-7706-4da9-be9d-fd886d992c6a/fetchFileTemp8485638920924361985.tmp
21/02/17 01:25:44 INFO Executor: Adding file:/tmp/spark-a38c6647-1a67-4a7f-9f82-3ad2a125e026/userFiles-a504077d-7706-4da9-be9d-fd886d992c6a/commons-logging_commons-logging-1.2.jar to class loader
21/02/17 01:25:44 INFO Executor: Fetching spark://localhost:40347/jars/com.esotericsoftware_minlog-1.3.0.jar with timestamp 1613525137238
21/02/17 01:25:44 INFO Utils: Fetching spark://localhost:40347/jars/com.esotericsoftware_minlog-1.3.0.jar to /tmp/spark-a38c6647-1a67-4a7f-9f82-3ad2a125e026/userFiles-a504077d-7706-4da9-be9d-fd886d992c6a/fetchFileTemp639748895659022897.tmp
21/02/17 01:25:44 INFO Executor: Adding file:/tmp/spark-a38c6647-1a67-4a7f-9f82-3ad2a125e026/userFiles-a504077d-7706-4da9-be9d-fd886d992c6a/com.esotericsoftware_minlog-1.3.0.jar to class loader
21/02/17 01:25:44 INFO Executor: Fetching spark://localhost:40347/jars/org.scala-lang_scala-compiler-2.12.8.jar with timestamp 1613525137237
21/02/17 01:25:44 INFO Utils: Fetching spark://localhost:40347/jars/org.scala-lang_scala-compiler-2.12.8.jar to /tmp/spark-a38c6647-1a67-4a7f-9f82-3ad2a125e026/userFiles-a504077d-7706-4da9-be9d-fd886d992c6a/fetchFileTemp3140892558363063964.tmp
21/02/17 01:25:44 INFO Executor: Adding file:/tmp/spark-a38c6647-1a67-4a7f-9f82-3ad2a125e026/userFiles-a504077d-7706-4da9-be9d-fd886d992c6a/org.scala-lang_scala-compiler-2.12.8.jar to class loader
21/02/17 01:25:45 INFO Executor: Finished task 0.0 in stage 0.0 (TID 0). 1397 bytes result sent to driver
21/02/17 01:25:45 INFO TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in 371 ms on localhost (executor driver) (1/1)
21/02/17 01:25:45 INFO TaskSchedulerImpl: Removed TaskSet 0.0, whose tasks have all completed, from pool 
21/02/17 01:25:45 INFO DAGScheduler: ResultStage 0 (collect at utils.scala:137) finished in 0.485 s
21/02/17 01:25:45 INFO DAGScheduler: Job 1 is finished. Cancelling potential speculative or zombie tasks for this job
21/02/17 01:25:45 INFO TaskSchedulerImpl: Killing all running tasks in stage 0: Stage finished
21/02/17 01:25:45 INFO DAGScheduler: Job 1 finished: collect at utils.scala:137, took 0.514637 s
21/02/17 01:25:45 INFO CodeGenerator: Code generated in 11.815444 ms
21/02/17 01:25:45 INFO CodeGenerator: Code generated in 13.591736 ms
21/02/17 01:25:45 INFO CodeGenerator: Code generated in 11.072013 ms
21/02/17 01:25:45 INFO SparkContext: Starting job: count at utils.scala:135
21/02/17 01:25:45 INFO DAGScheduler: Registering RDD 11 (count at utils.scala:135) as input to shuffle 0
21/02/17 01:25:45 INFO DAGScheduler: Got job 2 (count at utils.scala:135) with 1 output partitions
21/02/17 01:25:45 INFO DAGScheduler: Final stage: ResultStage 2 (count at utils.scala:135)
21/02/17 01:25:45 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 1)
21/02/17 01:25:45 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 1)
21/02/17 01:25:45 INFO DAGScheduler: Submitting ShuffleMapStage 1 (MapPartitionsRDD[11] at count at utils.scala:135), which has no missing parents
21/02/17 01:25:45 INFO MemoryStore: Block broadcast_1 stored as values in memory (estimated size 10.0 KiB, free 912.3 MiB)
21/02/17 01:25:45 INFO MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 5.2 KiB, free 912.3 MiB)
21/02/17 01:25:45 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on localhost:41017 (size: 5.2 KiB, free: 912.3 MiB)
21/02/17 01:25:45 INFO SparkContext: Created broadcast 1 from broadcast at DAGScheduler.scala:1200
21/02/17 01:25:45 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 1 (MapPartitionsRDD[11] at count at utils.scala:135) (first 15 tasks are for partitions Vector(0))
21/02/17 01:25:45 INFO TaskSchedulerImpl: Adding task set 1.0 with 1 tasks
21/02/17 01:25:45 INFO TaskSetManager: Starting task 0.0 in stage 1.0 (TID 1, localhost, executor driver, partition 0, PROCESS_LOCAL, 7550 bytes)
21/02/17 01:25:45 INFO Executor: Running task 0.0 in stage 1.0 (TID 1)
21/02/17 01:25:45 INFO Executor: Finished task 0.0 in stage 1.0 (TID 1). 1833 bytes result sent to driver
21/02/17 01:25:45 INFO TaskSetManager: Finished task 0.0 in stage 1.0 (TID 1) in 43 ms on localhost (executor driver) (1/1)
21/02/17 01:25:45 INFO TaskSchedulerImpl: Removed TaskSet 1.0, whose tasks have all completed, from pool 
21/02/17 01:25:45 INFO DAGScheduler: ShuffleMapStage 1 (count at utils.scala:135) finished in 0.057 s
21/02/17 01:25:45 INFO DAGScheduler: looking for newly runnable stages
21/02/17 01:25:45 INFO DAGScheduler: running: Set()
21/02/17 01:25:45 INFO DAGScheduler: waiting: Set(ResultStage 2)
21/02/17 01:25:45 INFO DAGScheduler: failed: Set()
21/02/17 01:25:45 INFO DAGScheduler: Submitting ResultStage 2 (MapPartitionsRDD[14] at count at utils.scala:135), which has no missing parents
21/02/17 01:25:45 INFO MemoryStore: Block broadcast_2 stored as values in memory (estimated size 10.1 KiB, free 912.3 MiB)
21/02/17 01:25:45 INFO MemoryStore: Block broadcast_2_piece0 stored as bytes in memory (estimated size 5.0 KiB, free 912.3 MiB)
21/02/17 01:25:45 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on localhost:41017 (size: 5.0 KiB, free: 912.3 MiB)
21/02/17 01:25:45 INFO SparkContext: Created broadcast 2 from broadcast at DAGScheduler.scala:1200
21/02/17 01:25:45 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 2 (MapPartitionsRDD[14] at count at utils.scala:135) (first 15 tasks are for partitions Vector(0))
21/02/17 01:25:45 INFO TaskSchedulerImpl: Adding task set 2.0 with 1 tasks
21/02/17 01:25:45 INFO TaskSetManager: Starting task 0.0 in stage 2.0 (TID 2, localhost, executor driver, partition 0, NODE_LOCAL, 7325 bytes)
21/02/17 01:25:45 INFO Executor: Running task 0.0 in stage 2.0 (TID 2)
21/02/17 01:25:45 INFO ShuffleBlockFetcherIterator: Getting 1 (60.0 B) non-empty blocks including 1 (60.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
21/02/17 01:25:45 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 7 ms
21/02/17 01:25:45 INFO Executor: Finished task 0.0 in stage 2.0 (TID 2). 2648 bytes result sent to driver
21/02/17 01:25:45 INFO TaskSetManager: Finished task 0.0 in stage 2.0 (TID 2) in 38 ms on localhost (executor driver) (1/1)
21/02/17 01:25:45 INFO TaskSchedulerImpl: Removed TaskSet 2.0, whose tasks have all completed, from pool 
21/02/17 01:25:45 INFO DAGScheduler: ResultStage 2 (count at utils.scala:135) finished in 0.047 s
21/02/17 01:25:45 INFO DAGScheduler: Job 2 is finished. Cancelling potential speculative or zombie tasks for this job
21/02/17 01:25:45 INFO TaskSchedulerImpl: Killing all running tasks in stage 2: Stage finished
21/02/17 01:25:45 INFO DAGScheduler: Job 2 finished: count at utils.scala:135, took 0.123448 s
21/02/17 01:25:45 INFO BlockManagerInfo: Removed broadcast_1_piece0 on localhost:41017 in memory (size: 5.2 KiB, free: 912.3 MiB)
21/02/17 01:25:45 INFO BlockManagerInfo: Removed broadcast_2_piece0 on localhost:41017 in memory (size: 5.0 KiB, free: 912.3 MiB)
21/02/17 01:25:45 INFO SparkContext: Starting job: collect at utils.scala:137
21/02/17 01:25:45 INFO DAGScheduler: Got job 3 (collect at utils.scala:137) with 1 output partitions
21/02/17 01:25:45 INFO DAGScheduler: Final stage: ResultStage 3 (collect at utils.scala:137)
21/02/17 01:25:45 INFO DAGScheduler: Parents of final stage: List()
21/02/17 01:25:45 INFO DAGScheduler: Missing parents: List()
21/02/17 01:25:45 INFO BlockManagerInfo: Removed broadcast_0_piece0 on localhost:41017 in memory (size: 3.2 KiB, free: 912.3 MiB)
21/02/17 01:25:45 INFO DAGScheduler: Submitting ResultStage 3 (MapPartitionsRDD[16] at collect at utils.scala:137), which has no missing parents
21/02/17 01:25:45 INFO MemoryStore: Block broadcast_3 stored as values in memory (estimated size 7.2 KiB, free 912.3 MiB)
21/02/17 01:25:45 INFO MemoryStore: Block broadcast_3_piece0 stored as bytes in memory (estimated size 3.7 KiB, free 912.3 MiB)
21/02/17 01:25:45 INFO BlockManagerInfo: Added broadcast_3_piece0 in memory on localhost:41017 (size: 3.7 KiB, free: 912.3 MiB)
21/02/17 01:25:45 INFO SparkContext: Created broadcast 3 from broadcast at DAGScheduler.scala:1200
21/02/17 01:25:45 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 3 (MapPartitionsRDD[16] at collect at utils.scala:137) (first 15 tasks are for partitions Vector(0))
21/02/17 01:25:45 INFO TaskSchedulerImpl: Adding task set 3.0 with 1 tasks
21/02/17 01:25:45 INFO TaskSetManager: Starting task 0.0 in stage 3.0 (TID 3, localhost, executor driver, partition 0, PROCESS_LOCAL, 7561 bytes)
21/02/17 01:25:45 INFO Executor: Running task 0.0 in stage 3.0 (TID 3)
21/02/17 01:25:45 INFO Executor: Finished task 0.0 in stage 3.0 (TID 3). 1354 bytes result sent to driver
21/02/17 01:25:45 INFO TaskSetManager: Finished task 0.0 in stage 3.0 (TID 3) in 5 ms on localhost (executor driver) (1/1)
21/02/17 01:25:45 INFO TaskSchedulerImpl: Removed TaskSet 3.0, whose tasks have all completed, from pool 
21/02/17 01:25:45 INFO DAGScheduler: ResultStage 3 (collect at utils.scala:137) finished in 0.010 s
21/02/17 01:25:45 INFO DAGScheduler: Job 3 is finished. Cancelling potential speculative or zombie tasks for this job
21/02/17 01:25:45 INFO TaskSchedulerImpl: Killing all running tasks in stage 3: Stage finished
21/02/17 01:25:45 INFO DAGScheduler: Job 3 finished: collect at utils.scala:137, took 0.013270 s
21/02/17 01:25:45 INFO SparkContext: Starting job: count at utils.scala:135
21/02/17 01:25:45 INFO DAGScheduler: Registering RDD 18 (count at utils.scala:135) as input to shuffle 1
21/02/17 01:25:45 INFO DAGScheduler: Got job 4 (count at utils.scala:135) with 1 output partitions
21/02/17 01:25:45 INFO DAGScheduler: Final stage: ResultStage 5 (count at utils.scala:135)
21/02/17 01:25:45 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 4)
21/02/17 01:25:45 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 4)
21/02/17 01:25:45 INFO DAGScheduler: Submitting ShuffleMapStage 4 (MapPartitionsRDD[18] at count at utils.scala:135), which has no missing parents
21/02/17 01:25:45 INFO MemoryStore: Block broadcast_4 stored as values in memory (estimated size 10.0 KiB, free 912.3 MiB)
21/02/17 01:25:45 INFO MemoryStore: Block broadcast_4_piece0 stored as bytes in memory (estimated size 5.2 KiB, free 912.3 MiB)
21/02/17 01:25:45 INFO BlockManagerInfo: Added broadcast_4_piece0 in memory on localhost:41017 (size: 5.2 KiB, free: 912.3 MiB)
21/02/17 01:25:45 INFO SparkContext: Created broadcast 4 from broadcast at DAGScheduler.scala:1200
21/02/17 01:25:45 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 4 (MapPartitionsRDD[18] at count at utils.scala:135) (first 15 tasks are for partitions Vector(0))
21/02/17 01:25:45 INFO TaskSchedulerImpl: Adding task set 4.0 with 1 tasks
21/02/17 01:25:45 INFO TaskSetManager: Starting task 0.0 in stage 4.0 (TID 4, localhost, executor driver, partition 0, PROCESS_LOCAL, 7550 bytes)
21/02/17 01:25:45 INFO Executor: Running task 0.0 in stage 4.0 (TID 4)
21/02/17 01:25:45 INFO Executor: Finished task 0.0 in stage 4.0 (TID 4). 1833 bytes result sent to driver
21/02/17 01:25:45 INFO TaskSetManager: Finished task 0.0 in stage 4.0 (TID 4) in 7 ms on localhost (executor driver) (1/1)
21/02/17 01:25:45 INFO TaskSchedulerImpl: Removed TaskSet 4.0, whose tasks have all completed, from pool 
21/02/17 01:25:45 INFO DAGScheduler: ShuffleMapStage 4 (count at utils.scala:135) finished in 0.014 s
21/02/17 01:25:45 INFO DAGScheduler: looking for newly runnable stages
21/02/17 01:25:45 INFO DAGScheduler: running: Set()
21/02/17 01:25:45 INFO DAGScheduler: waiting: Set(ResultStage 5)
21/02/17 01:25:45 INFO DAGScheduler: failed: Set()
21/02/17 01:25:45 INFO DAGScheduler: Submitting ResultStage 5 (MapPartitionsRDD[21] at count at utils.scala:135), which has no missing parents
21/02/17 01:25:45 INFO MemoryStore: Block broadcast_5 stored as values in memory (estimated size 10.1 KiB, free 912.3 MiB)
21/02/17 01:25:45 INFO MemoryStore: Block broadcast_5_piece0 stored as bytes in memory (estimated size 5.0 KiB, free 912.3 MiB)
21/02/17 01:25:45 INFO BlockManagerInfo: Added broadcast_5_piece0 in memory on localhost:41017 (size: 5.0 KiB, free: 912.3 MiB)
21/02/17 01:25:45 INFO SparkContext: Created broadcast 5 from broadcast at DAGScheduler.scala:1200
21/02/17 01:25:45 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 5 (MapPartitionsRDD[21] at count at utils.scala:135) (first 15 tasks are for partitions Vector(0))
21/02/17 01:25:45 INFO TaskSchedulerImpl: Adding task set 5.0 with 1 tasks
21/02/17 01:25:45 INFO TaskSetManager: Starting task 0.0 in stage 5.0 (TID 5, localhost, executor driver, partition 0, NODE_LOCAL, 7325 bytes)
21/02/17 01:25:45 INFO Executor: Running task 0.0 in stage 5.0 (TID 5)
21/02/17 01:25:45 INFO ShuffleBlockFetcherIterator: Getting 1 (60.0 B) non-empty blocks including 1 (60.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
21/02/17 01:25:45 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
21/02/17 01:25:45 INFO Executor: Finished task 0.0 in stage 5.0 (TID 5). 2648 bytes result sent to driver
21/02/17 01:25:45 INFO TaskSetManager: Finished task 0.0 in stage 5.0 (TID 5) in 6 ms on localhost (executor driver) (1/1)
21/02/17 01:25:45 INFO TaskSchedulerImpl: Removed TaskSet 5.0, whose tasks have all completed, from pool 
21/02/17 01:25:45 INFO DAGScheduler: ResultStage 5 (count at utils.scala:135) finished in 0.013 s
21/02/17 01:25:45 INFO DAGScheduler: Job 4 is finished. Cancelling potential speculative or zombie tasks for this job
21/02/17 01:25:45 INFO TaskSchedulerImpl: Killing all running tasks in stage 5: Stage finished
21/02/17 01:25:45 INFO DAGScheduler: Job 4 finished: count at utils.scala:135, took 0.032347 s
21/02/17 01:25:46 INFO Instrumentation: [f4011f4c] training finished
21/02/17 01:25:46 INFO Instrumentation: [9db95d9d] training finished
21/02/17 01:25:46 INFO CodeGenerator: Code generated in 30.153527 ms
21/02/17 01:25:46 INFO CodeGenerator: Code generated in 9.231753 ms
21/02/17 01:25:46 INFO XGBoostSpark: Running XGBoost 1.3.1 with parameters:
alpha -> 0.0
min_child_weight -> 1.0
sample_type -> uniform
base_score -> 0.5
rabit_timeout -> -1
colsample_bylevel -> 1.0
grow_policy -> depthwise
skip_drop -> 0.0
lambda_bias -> 0.0
silent -> 0
scale_pos_weight -> 1.0
seed -> 0
cache_training_set -> false
features_col -> features
num_early_stopping_rounds -> 0
label_col -> label
num_workers -> 1
subsample -> 1.0
lambda -> 1.0
max_depth -> 6
kill_spark_context_on_worker_failure -> true
tree_limit -> 0
custom_eval -> null
dmlc_worker_connect_retry -> 5
rate_drop -> 0.0
max_bin -> 16
train_test_ratio -> 1.0
use_external_memory -> false
objective -> reg:linear
eval_metric -> rmse
num_round -> 1
maximize_evaluation_metrics -> false
timeout_request_workers -> 1800000
missing -> NaN
rabit_ring_reduce_threshold -> 32768
checkpoint_path -> 
tracker_conf -> TrackerConf(0,python)
tree_method -> auto
max_delta_step -> 0.0
eta -> 0.3
verbosity -> 1
colsample_bytree -> 1.0
objective_type -> regression
normalize_type -> tree
allow_non_zero_for_missing -> false
custom_obj -> null
gamma -> 0.0
sketch_eps -> 0.03
nthread -> 1
prediction_col -> prediction
checkpoint_interval -> -1
21/02/17 01:25:46 WARN XGBoostSpark: train_test_ratio is deprecated since XGBoost 0.82, we recommend to explicitly pass a training and multiple evaluation datasets by passing 'eval_sets' and 'eval_set_names'
21/02/17 01:25:46 INFO RabitTracker$TrackerProcessLogger: 2021-02-17 01:25:46,659 INFO start listen on 192.168.2.12:9091
21/02/17 01:25:46 INFO XGBoostSpark: starting training with timeout set as 1800000 ms for waiting for resources
21/02/17 01:25:46 INFO SparkContext: Starting job: foreachPartition at XGBoost.scala:612
21/02/17 01:25:46 INFO DAGScheduler: Got job 5 (foreachPartition at XGBoost.scala:612) with 1 output partitions
21/02/17 01:25:46 INFO DAGScheduler: Final stage: ResultStage 6 (foreachPartition at XGBoost.scala:612)
21/02/17 01:25:46 INFO DAGScheduler: Parents of final stage: List()
21/02/17 01:25:46 INFO DAGScheduler: Missing parents: List()
21/02/17 01:25:46 INFO DAGScheduler: Submitting ResultStage 6 (MapPartitionsRDD[32] at mapPartitions at XGBoost.scala:493), which has no missing parents
21/02/17 01:25:46 INFO MemoryStore: Block broadcast_6 stored as values in memory (estimated size 39.8 KiB, free 912.2 MiB)
21/02/17 01:25:46 INFO MemoryStore: Block broadcast_6_piece0 stored as bytes in memory (estimated size 16.6 KiB, free 912.2 MiB)
21/02/17 01:25:46 INFO BlockManagerInfo: Added broadcast_6_piece0 in memory on localhost:41017 (size: 16.6 KiB, free: 912.3 MiB)
21/02/17 01:25:46 INFO SparkContext: Created broadcast 6 from broadcast at DAGScheduler.scala:1200
21/02/17 01:25:46 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 6 (MapPartitionsRDD[32] at mapPartitions at XGBoost.scala:493) (first 15 tasks are for partitions Vector(0))
21/02/17 01:25:46 INFO TaskSchedulerImpl: Adding task set 6.0 with 1 tasks
21/02/17 01:25:46 INFO TaskSetManager: Starting task 0.0 in stage 6.0 (TID 6, localhost, executor driver, partition 0, PROCESS_LOCAL, 18492 bytes)
21/02/17 01:25:46 INFO Executor: Running task 0.0 in stage 6.0 (TID 6)
21/02/17 01:25:46 INFO MemoryStore: Block rdd_23_0 stored as values in memory (estimated size 5.6 KiB, free 912.2 MiB)
21/02/17 01:25:46 INFO BlockManagerInfo: Added rdd_23_0 in memory on localhost:41017 (size: 5.6 KiB, free: 912.3 MiB)
21/02/17 01:25:46 INFO CodeGenerator: Code generated in 8.925087 ms
21/02/17 01:25:46 INFO CodeGenerator: Code generated in 21.172021 ms
21/02/17 01:25:46 INFO CodeGenerator: Code generated in 8.435324 ms
21/02/17 01:25:47 INFO RabitTracker$TrackerProcessLogger: /tmp/tracker5207943784895673363.py:330: DeprecationWarning: isAlive() is deprecated, use is_alive() instead
21/02/17 01:25:47 INFO RabitTracker$TrackerProcessLogger:   while self.thread.isAlive():
21/02/17 01:25:47 INFO RabitTracker$TrackerProcessLogger: 2021-02-17 01:25:47,008 DEBUG Recieve start signal from 192.168.2.12; assign rank 0
21/02/17 01:25:47 INFO RabitTracker$TrackerProcessLogger: 2021-02-17 01:25:47,008 INFO @tracker All of 1 nodes getting started
21/02/17 01:25:47 INFO RabitTracker$TrackerProcessLogger: 2021-02-17 01:25:47,015 INFO [0]	train-rmse:2.633044
21/02/17 01:25:47 INFO RabitTracker$TrackerProcessLogger: 2021-02-17 01:25:47,016 DEBUG Recieve shutdown signal from 0
21/02/17 01:25:47 INFO RabitTracker$TrackerProcessLogger: 2021-02-17 01:25:47,016 INFO @tracker All nodes finishes job
21/02/17 01:25:47 INFO RabitTracker$TrackerProcessLogger: 2021-02-17 01:25:47,016 INFO @tracker 0.007418394088745117 secs between node start and job finish
21/02/17 01:25:47 INFO MemoryStore: Block rdd_32_0 stored as values in memory (estimated size 192.0 B, free 912.2 MiB)
21/02/17 01:25:47 INFO BlockManagerInfo: Added rdd_32_0 in memory on localhost:41017 (size: 192.0 B, free: 912.3 MiB)
21/02/17 01:25:47 INFO RabitTracker$TrackerProcessLogger: Tracker Process ends with exit code 0
21/02/17 01:25:47 INFO RabitTracker: Tracker Process ends with exit code 0
21/02/17 01:25:47 INFO XGBoostSpark: Rabit returns with exit code 0
21/02/17 01:25:47 INFO Executor: 1 block locks were not released by TID = 6:
[rdd_32_0]
21/02/17 01:25:47 INFO Executor: Finished task 0.0 in stage 6.0 (TID 6). 1385 bytes result sent to driver
21/02/17 01:25:47 INFO TaskSetManager: Finished task 0.0 in stage 6.0 (TID 6) in 274 ms on localhost (executor driver) (1/1)
21/02/17 01:25:47 INFO TaskSchedulerImpl: Removed TaskSet 6.0, whose tasks have all completed, from pool 
21/02/17 01:25:47 INFO DAGScheduler: ResultStage 6 (foreachPartition at XGBoost.scala:612) finished in 0.332 s
21/02/17 01:25:47 INFO DAGScheduler: Job 5 is finished. Cancelling potential speculative or zombie tasks for this job
21/02/17 01:25:47 INFO TaskSchedulerImpl: Killing all running tasks in stage 6: Stage finished
21/02/17 01:25:47 INFO DAGScheduler: Job 5 finished: foreachPartition at XGBoost.scala:612, took 0.337369 s
21/02/17 01:25:47 INFO SparkContext: Starting job: first at XGBoost.scala:734
21/02/17 01:25:47 INFO DAGScheduler: Got job 6 (first at XGBoost.scala:734) with 1 output partitions
21/02/17 01:25:47 INFO DAGScheduler: Final stage: ResultStage 7 (first at XGBoost.scala:734)
21/02/17 01:25:47 INFO DAGScheduler: Parents of final stage: List()
21/02/17 01:25:47 INFO DAGScheduler: Missing parents: List()
21/02/17 01:25:47 INFO DAGScheduler: Submitting ResultStage 7 (MapPartitionsRDD[32] at mapPartitions at XGBoost.scala:493), which has no missing parents
21/02/17 01:25:47 INFO MemoryStore: Block broadcast_7 stored as values in memory (estimated size 39.6 KiB, free 912.2 MiB)
21/02/17 01:25:47 INFO MemoryStore: Block broadcast_7_piece0 stored as bytes in memory (estimated size 16.6 KiB, free 912.1 MiB)
21/02/17 01:25:47 INFO BlockManagerInfo: Added broadcast_7_piece0 in memory on localhost:41017 (size: 16.6 KiB, free: 912.2 MiB)
21/02/17 01:25:47 INFO SparkContext: Created broadcast 7 from broadcast at DAGScheduler.scala:1200
21/02/17 01:25:47 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 7 (MapPartitionsRDD[32] at mapPartitions at XGBoost.scala:493) (first 15 tasks are for partitions Vector(0))
21/02/17 01:25:47 INFO TaskSchedulerImpl: Adding task set 7.0 with 1 tasks
21/02/17 01:25:47 INFO TaskSetManager: Starting task 0.0 in stage 7.0 (TID 7, localhost, executor driver, partition 0, PROCESS_LOCAL, 18492 bytes)
21/02/17 01:25:47 INFO Executor: Running task 0.0 in stage 7.0 (TID 7)
21/02/17 01:25:47 INFO BlockManager: Found block rdd_32_0 locally
21/02/17 01:25:47 INFO Executor: 1 block locks were not released by TID = 7:
[rdd_32_0]
21/02/17 01:25:47 INFO Executor: Finished task 0.0 in stage 7.0 (TID 7). 2676 bytes result sent to driver
21/02/17 01:25:47 INFO TaskSetManager: Finished task 0.0 in stage 7.0 (TID 7) in 12 ms on localhost (executor driver) (1/1)
21/02/17 01:25:47 INFO TaskSchedulerImpl: Removed TaskSet 7.0, whose tasks have all completed, from pool 
21/02/17 01:25:47 INFO DAGScheduler: ResultStage 7 (first at XGBoost.scala:734) finished in 0.020 s
21/02/17 01:25:47 INFO DAGScheduler: Job 6 is finished. Cancelling potential speculative or zombie tasks for this job
21/02/17 01:25:47 INFO TaskSchedulerImpl: Killing all running tasks in stage 7: Stage finished
21/02/17 01:25:47 INFO DAGScheduler: Job 6 finished: first at XGBoost.scala:734, took 0.023763 s
21/02/17 01:25:47 INFO MapPartitionsRDD: Removing RDD 32 from persistence list
21/02/17 01:25:47 INFO BlockManager: Removing RDD 32
21/02/17 01:25:47 INFO Instrumentation: [b979d103] training finished
21/02/17 01:25:47 INFO Instrumentation: [296cae2f] training finished
21/02/17 01:25:47 INFO MemoryStore: Block broadcast_8 stored as values in memory (estimated size 64.0 B, free 912.1 MiB)
21/02/17 01:25:47 INFO MemoryStore: Block broadcast_8_piece0 stored as bytes in memory (estimated size 514.0 B, free 912.1 MiB)
21/02/17 01:25:47 INFO BlockManagerInfo: Added broadcast_8_piece0 in memory on localhost:41017 (size: 514.0 B, free: 912.2 MiB)
21/02/17 01:25:47 INFO SparkContext: Created broadcast 8 from broadcast at XGBoostRegressor.scala:279
21/02/17 01:25:47 INFO BlockManagerInfo: Removed broadcast_7_piece0 on localhost:41017 in memory (size: 16.6 KiB, free: 912.3 MiB)
21/02/17 01:25:47 INFO BlockManagerInfo: Removed broadcast_4_piece0 on localhost:41017 in memory (size: 5.2 KiB, free: 912.3 MiB)
21/02/17 01:25:47 INFO BlockManagerInfo: Removed broadcast_5_piece0 on localhost:41017 in memory (size: 5.0 KiB, free: 912.3 MiB)
21/02/17 01:25:47 INFO BlockManagerInfo: Removed broadcast_6_piece0 on localhost:41017 in memory (size: 16.6 KiB, free: 912.3 MiB)
21/02/17 01:25:47 INFO BlockManager: Removing RDD 32
21/02/17 01:25:47 INFO BlockManagerInfo: Removed broadcast_3_piece0 on localhost:41017 in memory (size: 3.7 KiB, free: 912.3 MiB)
21/02/17 01:25:47 INFO CodeGenerator: Code generated in 16.682274 ms
21/02/17 01:25:47 INFO Instrumentation: [a192536a] training finished
21/02/17 01:25:47 INFO CodeGenerator: Code generated in 6.854684 ms
21/02/17 01:25:47 INFO SparkContext: Starting job: collect at utils.scala:137
21/02/17 01:25:47 INFO DAGScheduler: Got job 7 (collect at utils.scala:137) with 1 output partitions
21/02/17 01:25:47 INFO DAGScheduler: Final stage: ResultStage 8 (collect at utils.scala:137)
21/02/17 01:25:47 INFO DAGScheduler: Parents of final stage: List()
21/02/17 01:25:47 INFO DAGScheduler: Missing parents: List()
21/02/17 01:25:47 INFO DAGScheduler: Submitting ResultStage 8 (MapPartitionsRDD[42] at collect at utils.scala:137), which has no missing parents
21/02/17 01:25:47 INFO MemoryStore: Block broadcast_9 stored as values in memory (estimated size 7.3 KiB, free 912.3 MiB)
21/02/17 01:25:47 INFO MemoryStore: Block broadcast_9_piece0 stored as bytes in memory (estimated size 3.7 KiB, free 912.3 MiB)
21/02/17 01:25:47 INFO BlockManagerInfo: Added broadcast_9_piece0 in memory on localhost:41017 (size: 3.7 KiB, free: 912.3 MiB)
21/02/17 01:25:47 INFO SparkContext: Created broadcast 9 from broadcast at DAGScheduler.scala:1200
21/02/17 01:25:47 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 8 (MapPartitionsRDD[42] at collect at utils.scala:137) (first 15 tasks are for partitions Vector(0))
21/02/17 01:25:47 INFO TaskSchedulerImpl: Adding task set 8.0 with 1 tasks
21/02/17 01:25:47 INFO TaskSetManager: Starting task 0.0 in stage 8.0 (TID 8, localhost, executor driver, partition 0, PROCESS_LOCAL, 7561 bytes)
21/02/17 01:25:47 INFO Executor: Running task 0.0 in stage 8.0 (TID 8)
21/02/17 01:25:47 INFO Executor: Finished task 0.0 in stage 8.0 (TID 8). 1397 bytes result sent to driver
21/02/17 01:25:47 INFO TaskSetManager: Finished task 0.0 in stage 8.0 (TID 8) in 6 ms on localhost (executor driver) (1/1)
21/02/17 01:25:47 INFO TaskSchedulerImpl: Removed TaskSet 8.0, whose tasks have all completed, from pool 
21/02/17 01:25:47 INFO DAGScheduler: ResultStage 8 (collect at utils.scala:137) finished in 0.010 s
21/02/17 01:25:47 INFO DAGScheduler: Job 7 is finished. Cancelling potential speculative or zombie tasks for this job
21/02/17 01:25:47 INFO TaskSchedulerImpl: Killing all running tasks in stage 8: Stage finished
21/02/17 01:25:47 INFO DAGScheduler: Job 7 finished: collect at utils.scala:137, took 0.012653 s
21/02/17 01:25:47 INFO CodeGenerator: Code generated in 9.510329 ms
21/02/17 01:25:47 INFO SparkContext: Starting job: count at utils.scala:135
21/02/17 01:25:47 INFO DAGScheduler: Registering RDD 44 (count at utils.scala:135) as input to shuffle 2
21/02/17 01:25:47 INFO DAGScheduler: Got job 8 (count at utils.scala:135) with 1 output partitions
21/02/17 01:25:47 INFO DAGScheduler: Final stage: ResultStage 10 (count at utils.scala:135)
21/02/17 01:25:47 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 9)
21/02/17 01:25:47 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 9)
21/02/17 01:25:47 INFO DAGScheduler: Submitting ShuffleMapStage 9 (MapPartitionsRDD[44] at count at utils.scala:135), which has no missing parents
21/02/17 01:25:47 INFO MemoryStore: Block broadcast_10 stored as values in memory (estimated size 10.0 KiB, free 912.3 MiB)
21/02/17 01:25:47 INFO MemoryStore: Block broadcast_10_piece0 stored as bytes in memory (estimated size 5.2 KiB, free 912.3 MiB)
21/02/17 01:25:47 INFO BlockManagerInfo: Added broadcast_10_piece0 in memory on localhost:41017 (size: 5.2 KiB, free: 912.3 MiB)
21/02/17 01:25:47 INFO SparkContext: Created broadcast 10 from broadcast at DAGScheduler.scala:1200
21/02/17 01:25:47 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 9 (MapPartitionsRDD[44] at count at utils.scala:135) (first 15 tasks are for partitions Vector(0))
21/02/17 01:25:47 INFO TaskSchedulerImpl: Adding task set 9.0 with 1 tasks
21/02/17 01:25:47 INFO TaskSetManager: Starting task 0.0 in stage 9.0 (TID 9, localhost, executor driver, partition 0, PROCESS_LOCAL, 7550 bytes)
21/02/17 01:25:47 INFO Executor: Running task 0.0 in stage 9.0 (TID 9)
21/02/17 01:25:47 INFO Executor: Finished task 0.0 in stage 9.0 (TID 9). 1833 bytes result sent to driver
21/02/17 01:25:47 INFO TaskSetManager: Finished task 0.0 in stage 9.0 (TID 9) in 5 ms on localhost (executor driver) (1/1)
21/02/17 01:25:47 INFO TaskSchedulerImpl: Removed TaskSet 9.0, whose tasks have all completed, from pool 
21/02/17 01:25:47 INFO DAGScheduler: ShuffleMapStage 9 (count at utils.scala:135) finished in 0.012 s
21/02/17 01:25:47 INFO DAGScheduler: looking for newly runnable stages
21/02/17 01:25:47 INFO DAGScheduler: running: Set()
21/02/17 01:25:47 INFO DAGScheduler: waiting: Set(ResultStage 10)
21/02/17 01:25:47 INFO DAGScheduler: failed: Set()
21/02/17 01:25:47 INFO DAGScheduler: Submitting ResultStage 10 (MapPartitionsRDD[47] at count at utils.scala:135), which has no missing parents
21/02/17 01:25:47 INFO MemoryStore: Block broadcast_11 stored as values in memory (estimated size 10.1 KiB, free 912.3 MiB)
21/02/17 01:25:47 INFO MemoryStore: Block broadcast_11_piece0 stored as bytes in memory (estimated size 5.0 KiB, free 912.3 MiB)
21/02/17 01:25:47 INFO BlockManagerInfo: Added broadcast_11_piece0 in memory on localhost:41017 (size: 5.0 KiB, free: 912.3 MiB)
21/02/17 01:25:47 INFO SparkContext: Created broadcast 11 from broadcast at DAGScheduler.scala:1200
21/02/17 01:25:47 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 10 (MapPartitionsRDD[47] at count at utils.scala:135) (first 15 tasks are for partitions Vector(0))
21/02/17 01:25:47 INFO TaskSchedulerImpl: Adding task set 10.0 with 1 tasks
21/02/17 01:25:47 INFO TaskSetManager: Starting task 0.0 in stage 10.0 (TID 10, localhost, executor driver, partition 0, NODE_LOCAL, 7325 bytes)
21/02/17 01:25:47 INFO Executor: Running task 0.0 in stage 10.0 (TID 10)
21/02/17 01:25:47 INFO ShuffleBlockFetcherIterator: Getting 1 (60.0 B) non-empty blocks including 1 (60.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
21/02/17 01:25:47 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
21/02/17 01:25:47 INFO Executor: Finished task 0.0 in stage 10.0 (TID 10). 2648 bytes result sent to driver
21/02/17 01:25:47 INFO TaskSetManager: Finished task 0.0 in stage 10.0 (TID 10) in 8 ms on localhost (executor driver) (1/1)
21/02/17 01:25:47 INFO TaskSchedulerImpl: Removed TaskSet 10.0, whose tasks have all completed, from pool 
21/02/17 01:25:47 INFO DAGScheduler: ResultStage 10 (count at utils.scala:135) finished in 0.013 s
21/02/17 01:25:47 INFO DAGScheduler: Job 8 is finished. Cancelling potential speculative or zombie tasks for this job
21/02/17 01:25:47 INFO TaskSchedulerImpl: Killing all running tasks in stage 10: Stage finished
21/02/17 01:25:47 INFO DAGScheduler: Job 8 finished: count at utils.scala:135, took 0.031026 s
21/02/17 01:25:48 INFO CodeGenerator: Code generated in 8.545775 ms
21/02/17 01:25:48 INFO SparkContext: Starting job: collect at utils.scala:137
21/02/17 01:25:48 INFO DAGScheduler: Got job 9 (collect at utils.scala:137) with 1 output partitions
21/02/17 01:25:48 INFO DAGScheduler: Final stage: ResultStage 11 (collect at utils.scala:137)
21/02/17 01:25:48 INFO DAGScheduler: Parents of final stage: List()
21/02/17 01:25:48 INFO DAGScheduler: Missing parents: List()
21/02/17 01:25:48 INFO DAGScheduler: Submitting ResultStage 11 (MapPartitionsRDD[49] at collect at utils.scala:137), which has no missing parents
21/02/17 01:25:48 INFO MemoryStore: Block broadcast_12 stored as values in memory (estimated size 70.7 KiB, free 912.2 MiB)
21/02/17 01:25:48 INFO MemoryStore: Block broadcast_12_piece0 stored as bytes in memory (estimated size 28.0 KiB, free 912.2 MiB)
21/02/17 01:25:48 INFO BlockManagerInfo: Added broadcast_12_piece0 in memory on localhost:41017 (size: 28.0 KiB, free: 912.3 MiB)
21/02/17 01:25:48 INFO SparkContext: Created broadcast 12 from broadcast at DAGScheduler.scala:1200
21/02/17 01:25:48 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 11 (MapPartitionsRDD[49] at collect at utils.scala:137) (first 15 tasks are for partitions Vector(0))
21/02/17 01:25:48 INFO TaskSchedulerImpl: Adding task set 11.0 with 1 tasks
21/02/17 01:25:48 INFO TaskSetManager: Starting task 0.0 in stage 11.0 (TID 11, localhost, executor driver, partition 0, PROCESS_LOCAL, 18492 bytes)
21/02/17 01:25:48 INFO Executor: Running task 0.0 in stage 11.0 (TID 11)
21/02/17 01:25:48 INFO BlockManager: Found block rdd_23_0 locally
21/02/17 01:25:48 INFO CodeGenerator: Code generated in 12.845659 ms
21/02/17 01:25:48 INFO CodeGenerator: Code generated in 49.542784 ms
21/02/17 01:25:48 INFO Executor: Finished task 0.0 in stage 11.0 (TID 11). 1912 bytes result sent to driver
21/02/17 01:25:48 INFO TaskSetManager: Finished task 0.0 in stage 11.0 (TID 11) in 176 ms on localhost (executor driver) (1/1)
21/02/17 01:25:48 INFO TaskSchedulerImpl: Removed TaskSet 11.0, whose tasks have all completed, from pool 
21/02/17 01:25:48 INFO DAGScheduler: ResultStage 11 (collect at utils.scala:137) finished in 0.184 s
21/02/17 01:25:48 INFO DAGScheduler: Job 9 is finished. Cancelling potential speculative or zombie tasks for this job
21/02/17 01:25:48 INFO TaskSchedulerImpl: Killing all running tasks in stage 11: Stage finished
21/02/17 01:25:48 INFO DAGScheduler: Job 9 finished: collect at utils.scala:137, took 0.187920 s
21/02/17 01:25:48 INFO CodeGenerator: Code generated in 5.117697 ms
21/02/17 01:25:48 INFO CodeGenerator: Code generated in 7.625738 ms
21/02/17 01:25:48 INFO SparkContext: Starting job: count at utils.scala:135
21/02/17 01:25:48 INFO DAGScheduler: Registering RDD 51 (count at utils.scala:135) as input to shuffle 3
21/02/17 01:25:48 INFO DAGScheduler: Got job 10 (count at utils.scala:135) with 1 output partitions
21/02/17 01:25:48 INFO DAGScheduler: Final stage: ResultStage 13 (count at utils.scala:135)
21/02/17 01:25:48 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 12)
21/02/17 01:25:48 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 12)
21/02/17 01:25:48 INFO DAGScheduler: Submitting ShuffleMapStage 12 (MapPartitionsRDD[51] at count at utils.scala:135), which has no missing parents
21/02/17 01:25:48 INFO MemoryStore: Block broadcast_13 stored as values in memory (estimated size 72.9 KiB, free 912.1 MiB)
21/02/17 01:25:48 INFO MemoryStore: Block broadcast_13_piece0 stored as bytes in memory (estimated size 29.1 KiB, free 912.1 MiB)
21/02/17 01:25:48 INFO BlockManagerInfo: Added broadcast_13_piece0 in memory on localhost:41017 (size: 29.1 KiB, free: 912.2 MiB)
21/02/17 01:25:48 INFO SparkContext: Created broadcast 13 from broadcast at DAGScheduler.scala:1200
21/02/17 01:25:48 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 12 (MapPartitionsRDD[51] at count at utils.scala:135) (first 15 tasks are for partitions Vector(0))
21/02/17 01:25:48 INFO TaskSchedulerImpl: Adding task set 12.0 with 1 tasks
21/02/17 01:25:48 INFO TaskSetManager: Starting task 0.0 in stage 12.0 (TID 12, localhost, executor driver, partition 0, PROCESS_LOCAL, 18481 bytes)
21/02/17 01:25:48 INFO Executor: Running task 0.0 in stage 12.0 (TID 12)
21/02/17 01:25:48 INFO BlockManager: Found block rdd_23_0 locally
21/02/17 01:25:48 INFO Executor: Finished task 0.0 in stage 12.0 (TID 12). 2253 bytes result sent to driver
21/02/17 01:25:48 INFO TaskSetManager: Finished task 0.0 in stage 12.0 (TID 12) in 50 ms on localhost (executor driver) (1/1)
21/02/17 01:25:48 INFO TaskSchedulerImpl: Removed TaskSet 12.0, whose tasks have all completed, from pool 
21/02/17 01:25:48 INFO DAGScheduler: ShuffleMapStage 12 (count at utils.scala:135) finished in 0.057 s
21/02/17 01:25:48 INFO DAGScheduler: looking for newly runnable stages
21/02/17 01:25:48 INFO DAGScheduler: running: Set()
21/02/17 01:25:48 INFO DAGScheduler: waiting: Set(ResultStage 13)
21/02/17 01:25:48 INFO DAGScheduler: failed: Set()
21/02/17 01:25:48 INFO DAGScheduler: Submitting ResultStage 13 (MapPartitionsRDD[54] at count at utils.scala:135), which has no missing parents
21/02/17 01:25:48 INFO MemoryStore: Block broadcast_14 stored as values in memory (estimated size 10.1 KiB, free 912.0 MiB)
21/02/17 01:25:48 INFO MemoryStore: Block broadcast_14_piece0 stored as bytes in memory (estimated size 5.0 KiB, free 912.0 MiB)
21/02/17 01:25:48 INFO BlockManagerInfo: Added broadcast_14_piece0 in memory on localhost:41017 (size: 5.0 KiB, free: 912.2 MiB)
21/02/17 01:25:48 INFO SparkContext: Created broadcast 14 from broadcast at DAGScheduler.scala:1200
21/02/17 01:25:48 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 13 (MapPartitionsRDD[54] at count at utils.scala:135) (first 15 tasks are for partitions Vector(0))
21/02/17 01:25:48 INFO TaskSchedulerImpl: Adding task set 13.0 with 1 tasks
21/02/17 01:25:48 INFO TaskSetManager: Starting task 0.0 in stage 13.0 (TID 13, localhost, executor driver, partition 0, NODE_LOCAL, 7325 bytes)
21/02/17 01:25:48 INFO Executor: Running task 0.0 in stage 13.0 (TID 13)
21/02/17 01:25:48 INFO ShuffleBlockFetcherIterator: Getting 1 (60.0 B) non-empty blocks including 1 (60.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
21/02/17 01:25:48 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
21/02/17 01:25:48 INFO Executor: Finished task 0.0 in stage 13.0 (TID 13). 2648 bytes result sent to driver
21/02/17 01:25:48 INFO TaskSetManager: Finished task 0.0 in stage 13.0 (TID 13) in 7 ms on localhost (executor driver) (1/1)
21/02/17 01:25:48 INFO TaskSchedulerImpl: Removed TaskSet 13.0, whose tasks have all completed, from pool 
21/02/17 01:25:48 INFO DAGScheduler: ResultStage 13 (count at utils.scala:135) finished in 0.013 s
21/02/17 01:25:48 INFO DAGScheduler: Job 10 is finished. Cancelling potential speculative or zombie tasks for this job
21/02/17 01:25:48 INFO TaskSchedulerImpl: Killing all running tasks in stage 13: Stage finished
21/02/17 01:25:48 INFO DAGScheduler: Job 10 finished: count at utils.scala:135, took 0.077314 s
21/02/17 01:25:48 INFO deprecation: mapred.output.dir is deprecated. Instead, use mapreduce.output.fileoutputformat.outputdir
21/02/17 01:25:48 INFO HadoopMapRedCommitProtocol: Using output committer class org.apache.hadoop.mapred.FileOutputCommitter
21/02/17 01:25:48 INFO FileOutputCommitter: File Output Committer Algorithm version is 2
21/02/17 01:25:48 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
21/02/17 01:25:48 INFO SparkContext: Starting job: runJob at SparkHadoopWriter.scala:78
21/02/17 01:25:48 INFO DAGScheduler: Got job 11 (runJob at SparkHadoopWriter.scala:78) with 1 output partitions
21/02/17 01:25:48 INFO DAGScheduler: Final stage: ResultStage 14 (runJob at SparkHadoopWriter.scala:78)
21/02/17 01:25:48 INFO DAGScheduler: Parents of final stage: List()
21/02/17 01:25:48 INFO DAGScheduler: Missing parents: List()
21/02/17 01:25:48 INFO DAGScheduler: Submitting ResultStage 14 (MapPartitionsRDD[56] at saveAsTextFile at ReadWrite.scala:413), which has no missing parents
21/02/17 01:25:48 INFO MemoryStore: Block broadcast_15 stored as values in memory (estimated size 83.9 KiB, free 912.0 MiB)
21/02/17 01:25:48 INFO MemoryStore: Block broadcast_15_piece0 stored as bytes in memory (estimated size 29.8 KiB, free 911.9 MiB)
21/02/17 01:25:48 INFO BlockManagerInfo: Added broadcast_15_piece0 in memory on localhost:41017 (size: 29.8 KiB, free: 912.2 MiB)
21/02/17 01:25:48 INFO SparkContext: Created broadcast 15 from broadcast at DAGScheduler.scala:1200
21/02/17 01:25:48 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 14 (MapPartitionsRDD[56] at saveAsTextFile at ReadWrite.scala:413) (first 15 tasks are for partitions Vector(0))
21/02/17 01:25:48 INFO TaskSchedulerImpl: Adding task set 14.0 with 1 tasks
21/02/17 01:25:48 INFO TaskSetManager: Starting task 0.0 in stage 14.0 (TID 14, localhost, executor driver, partition 0, PROCESS_LOCAL, 7657 bytes)
21/02/17 01:25:48 INFO Executor: Running task 0.0 in stage 14.0 (TID 14)
21/02/17 01:25:48 INFO HadoopMapRedCommitProtocol: Using output committer class org.apache.hadoop.mapred.FileOutputCommitter
21/02/17 01:25:48 INFO FileOutputCommitter: File Output Committer Algorithm version is 2
21/02/17 01:25:48 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
21/02/17 01:25:48 INFO FileOutputCommitter: Saved output of task 'attempt_20210217012548_0056_m_000000_0' to file:/tmp/RtmpLTlh4o/file2171a4eb3a620/metadata
21/02/17 01:25:48 INFO SparkHadoopMapRedUtil: attempt_20210217012548_0056_m_000000_0: Committed
21/02/17 01:25:48 INFO Executor: Finished task 0.0 in stage 14.0 (TID 14). 1201 bytes result sent to driver
21/02/17 01:25:48 INFO TaskSetManager: Finished task 0.0 in stage 14.0 (TID 14) in 49 ms on localhost (executor driver) (1/1)
21/02/17 01:25:48 INFO TaskSchedulerImpl: Removed TaskSet 14.0, whose tasks have all completed, from pool 
21/02/17 01:25:48 INFO DAGScheduler: ResultStage 14 (runJob at SparkHadoopWriter.scala:78) finished in 0.063 s
21/02/17 01:25:48 INFO DAGScheduler: Job 11 is finished. Cancelling potential speculative or zombie tasks for this job
21/02/17 01:25:48 INFO TaskSchedulerImpl: Killing all running tasks in stage 14: Stage finished
21/02/17 01:25:48 INFO DAGScheduler: Job 11 finished: runJob at SparkHadoopWriter.scala:78, took 0.066241 s
21/02/17 01:25:48 INFO SparkHadoopWriter: Job job_20210217012548_0056 committed.
21/02/17 01:25:48 INFO HadoopMapRedCommitProtocol: Using output committer class org.apache.hadoop.mapred.FileOutputCommitter
21/02/17 01:25:48 INFO FileOutputCommitter: File Output Committer Algorithm version is 2
21/02/17 01:25:48 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
21/02/17 01:25:48 INFO SparkContext: Starting job: runJob at SparkHadoopWriter.scala:78
21/02/17 01:25:48 INFO DAGScheduler: Got job 12 (runJob at SparkHadoopWriter.scala:78) with 1 output partitions
21/02/17 01:25:48 INFO DAGScheduler: Final stage: ResultStage 15 (runJob at SparkHadoopWriter.scala:78)
21/02/17 01:25:48 INFO DAGScheduler: Parents of final stage: List()
21/02/17 01:25:48 INFO DAGScheduler: Missing parents: List()
21/02/17 01:25:48 INFO DAGScheduler: Submitting ResultStage 15 (MapPartitionsRDD[58] at saveAsTextFile at ReadWrite.scala:413), which has no missing parents
21/02/17 01:25:48 INFO MemoryStore: Block broadcast_16 stored as values in memory (estimated size 84.0 KiB, free 911.8 MiB)
21/02/17 01:25:48 INFO MemoryStore: Block broadcast_16_piece0 stored as bytes in memory (estimated size 29.9 KiB, free 911.8 MiB)
21/02/17 01:25:48 INFO BlockManagerInfo: Added broadcast_16_piece0 in memory on localhost:41017 (size: 29.9 KiB, free: 912.2 MiB)
21/02/17 01:25:48 INFO SparkContext: Created broadcast 16 from broadcast at DAGScheduler.scala:1200
21/02/17 01:25:48 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 15 (MapPartitionsRDD[58] at saveAsTextFile at ReadWrite.scala:413) (first 15 tasks are for partitions Vector(0))
21/02/17 01:25:48 INFO TaskSchedulerImpl: Adding task set 15.0 with 1 tasks
21/02/17 01:25:48 INFO TaskSetManager: Starting task 0.0 in stage 15.0 (TID 15, localhost, executor driver, partition 0, PROCESS_LOCAL, 7798 bytes)
21/02/17 01:25:48 INFO Executor: Running task 0.0 in stage 15.0 (TID 15)
21/02/17 01:25:48 INFO HadoopMapRedCommitProtocol: Using output committer class org.apache.hadoop.mapred.FileOutputCommitter
21/02/17 01:25:48 INFO FileOutputCommitter: File Output Committer Algorithm version is 2
21/02/17 01:25:48 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
21/02/17 01:25:48 INFO FileOutputCommitter: Saved output of task 'attempt_20210217012548_0058_m_000000_0' to file:/tmp/RtmpLTlh4o/file2171a4eb3a620/stages/0_r_formula__8e049f4c_a0ea_471a_862c_cafd520f5953/metadata
21/02/17 01:25:48 INFO SparkHadoopMapRedUtil: attempt_20210217012548_0058_m_000000_0: Committed
21/02/17 01:25:48 INFO Executor: Finished task 0.0 in stage 15.0 (TID 15). 1158 bytes result sent to driver
21/02/17 01:25:48 INFO TaskSetManager: Finished task 0.0 in stage 15.0 (TID 15) in 21 ms on localhost (executor driver) (1/1)
21/02/17 01:25:48 INFO TaskSchedulerImpl: Removed TaskSet 15.0, whose tasks have all completed, from pool 
21/02/17 01:25:48 INFO DAGScheduler: ResultStage 15 (runJob at SparkHadoopWriter.scala:78) finished in 0.036 s
21/02/17 01:25:48 INFO DAGScheduler: Job 12 is finished. Cancelling potential speculative or zombie tasks for this job
21/02/17 01:25:48 INFO TaskSchedulerImpl: Killing all running tasks in stage 15: Stage finished
21/02/17 01:25:48 INFO DAGScheduler: Job 12 finished: runJob at SparkHadoopWriter.scala:78, took 0.037581 s
21/02/17 01:25:48 INFO SparkHadoopWriter: Job job_20210217012548_0058 committed.
21/02/17 01:25:48 INFO BlockManagerInfo: Removed broadcast_16_piece0 on localhost:41017 in memory (size: 29.9 KiB, free: 912.2 MiB)
21/02/17 01:25:48 INFO BlockManagerInfo: Removed broadcast_15_piece0 on localhost:41017 in memory (size: 29.8 KiB, free: 912.2 MiB)
21/02/17 01:25:48 INFO BlockManagerInfo: Removed broadcast_9_piece0 on localhost:41017 in memory (size: 3.7 KiB, free: 912.2 MiB)
21/02/17 01:25:48 INFO BlockManagerInfo: Removed broadcast_14_piece0 on localhost:41017 in memory (size: 5.0 KiB, free: 912.2 MiB)
21/02/17 01:25:48 INFO BlockManagerInfo: Removed broadcast_10_piece0 on localhost:41017 in memory (size: 5.2 KiB, free: 912.2 MiB)
21/02/17 01:25:48 INFO BlockManagerInfo: Removed broadcast_12_piece0 on localhost:41017 in memory (size: 28.0 KiB, free: 912.3 MiB)
21/02/17 01:25:48 INFO BlockManagerInfo: Removed broadcast_11_piece0 on localhost:41017 in memory (size: 5.0 KiB, free: 912.3 MiB)
21/02/17 01:25:48 INFO BlockManagerInfo: Removed broadcast_13_piece0 on localhost:41017 in memory (size: 29.1 KiB, free: 912.3 MiB)
21/02/17 01:25:48 INFO ParquetFileFormat: Using default output committer for Parquet: org.apache.parquet.hadoop.ParquetOutputCommitter
21/02/17 01:25:48 INFO FileOutputCommitter: File Output Committer Algorithm version is 2
21/02/17 01:25:48 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
21/02/17 01:25:48 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
21/02/17 01:25:48 INFO FileOutputCommitter: File Output Committer Algorithm version is 2
21/02/17 01:25:48 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
21/02/17 01:25:48 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
21/02/17 01:25:48 INFO CodeGenerator: Code generated in 7.235747 ms
21/02/17 01:25:49 INFO SparkContext: Starting job: parquet at RFormula.scala:434
21/02/17 01:25:49 INFO DAGScheduler: Registering RDD 61 (parquet at RFormula.scala:434) as input to shuffle 4
21/02/17 01:25:49 INFO DAGScheduler: Got job 13 (parquet at RFormula.scala:434) with 1 output partitions
21/02/17 01:25:49 INFO DAGScheduler: Final stage: ResultStage 17 (parquet at RFormula.scala:434)
21/02/17 01:25:49 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 16)
21/02/17 01:25:49 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 16)
21/02/17 01:25:49 INFO DAGScheduler: Submitting ShuffleMapStage 16 (MapPartitionsRDD[61] at parquet at RFormula.scala:434), which has no missing parents
21/02/17 01:25:49 INFO MemoryStore: Block broadcast_17 stored as values in memory (estimated size 7.7 KiB, free 912.3 MiB)
21/02/17 01:25:49 INFO MemoryStore: Block broadcast_17_piece0 stored as bytes in memory (estimated size 4.2 KiB, free 912.3 MiB)
21/02/17 01:25:49 INFO BlockManagerInfo: Added broadcast_17_piece0 in memory on localhost:41017 (size: 4.2 KiB, free: 912.3 MiB)
21/02/17 01:25:49 INFO SparkContext: Created broadcast 17 from broadcast at DAGScheduler.scala:1200
21/02/17 01:25:49 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 16 (MapPartitionsRDD[61] at parquet at RFormula.scala:434) (first 15 tasks are for partitions Vector(0))
21/02/17 01:25:49 INFO TaskSchedulerImpl: Adding task set 16.0 with 1 tasks
21/02/17 01:25:49 INFO TaskSetManager: Starting task 0.0 in stage 16.0 (TID 16, localhost, executor driver, partition 0, PROCESS_LOCAL, 7658 bytes)
21/02/17 01:25:49 INFO Executor: Running task 0.0 in stage 16.0 (TID 16)
21/02/17 01:25:49 INFO Executor: Finished task 0.0 in stage 16.0 (TID 16). 1614 bytes result sent to driver
21/02/17 01:25:49 INFO TaskSetManager: Finished task 0.0 in stage 16.0 (TID 16) in 6 ms on localhost (executor driver) (1/1)
21/02/17 01:25:49 INFO TaskSchedulerImpl: Removed TaskSet 16.0, whose tasks have all completed, from pool 
21/02/17 01:25:49 INFO DAGScheduler: ShuffleMapStage 16 (parquet at RFormula.scala:434) finished in 0.012 s
21/02/17 01:25:49 INFO DAGScheduler: looking for newly runnable stages
21/02/17 01:25:49 INFO DAGScheduler: running: Set()
21/02/17 01:25:49 INFO DAGScheduler: waiting: Set(ResultStage 17)
21/02/17 01:25:49 INFO DAGScheduler: failed: Set()
21/02/17 01:25:49 INFO DAGScheduler: Submitting ResultStage 17 (ShuffledRowRDD[62] at parquet at RFormula.scala:434), which has no missing parents
21/02/17 01:25:49 INFO MemoryStore: Block broadcast_18 stored as values in memory (estimated size 175.1 KiB, free 912.1 MiB)
21/02/17 01:25:49 INFO MemoryStore: Block broadcast_18_piece0 stored as bytes in memory (estimated size 61.7 KiB, free 912.1 MiB)
21/02/17 01:25:49 INFO BlockManagerInfo: Added broadcast_18_piece0 in memory on localhost:41017 (size: 61.7 KiB, free: 912.2 MiB)
21/02/17 01:25:49 INFO SparkContext: Created broadcast 18 from broadcast at DAGScheduler.scala:1200
21/02/17 01:25:49 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 17 (ShuffledRowRDD[62] at parquet at RFormula.scala:434) (first 15 tasks are for partitions Vector(0))
21/02/17 01:25:49 INFO TaskSchedulerImpl: Adding task set 17.0 with 1 tasks
21/02/17 01:25:49 INFO TaskSetManager: Starting task 0.0 in stage 17.0 (TID 17, localhost, executor driver, partition 0, NODE_LOCAL, 7325 bytes)
21/02/17 01:25:49 INFO Executor: Running task 0.0 in stage 17.0 (TID 17)
21/02/17 01:25:49 INFO ShuffleBlockFetcherIterator: Getting 1 (156.0 B) non-empty blocks including 1 (156.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
21/02/17 01:25:49 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
21/02/17 01:25:49 INFO FileOutputCommitter: File Output Committer Algorithm version is 2
21/02/17 01:25:49 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
21/02/17 01:25:49 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
21/02/17 01:25:49 INFO FileOutputCommitter: File Output Committer Algorithm version is 2
21/02/17 01:25:49 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
21/02/17 01:25:49 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
21/02/17 01:25:49 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:
{
  "type" : "struct",
  "fields" : [ {
    "name" : "label",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "terms",
    "type" : {
      "type" : "array",
      "elementType" : {
        "type" : "array",
        "elementType" : "string",
        "containsNull" : true
      },
      "containsNull" : true
    },
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "hasIntercept",
    "type" : "boolean",
    "nullable" : false,
    "metadata" : { }
  } ]
}
and corresponding Parquet message type:
message spark_schema {
  optional binary label (UTF8);
  optional group terms (LIST) {
    repeated group list {
      optional group element (LIST) {
        repeated group list {
          optional binary element (UTF8);
        }
      }
    }
  }
  required boolean hasIntercept;
}

       
21/02/17 01:25:49 INFO CodecPool: Got brand-new compressor [.snappy]
21/02/17 01:25:49 INFO BlockManagerInfo: Removed broadcast_17_piece0 on localhost:41017 in memory (size: 4.2 KiB, free: 912.2 MiB)
21/02/17 01:25:49 INFO FileOutputCommitter: Saved output of task 'attempt_20210217012548_0017_m_000000_17' to file:/tmp/RtmpLTlh4o/file2171a4eb3a620/stages/0_r_formula__8e049f4c_a0ea_471a_862c_cafd520f5953/data
21/02/17 01:25:49 INFO SparkHadoopMapRedUtil: attempt_20210217012548_0017_m_000000_17: Committed
21/02/17 01:25:49 INFO Executor: Finished task 0.0 in stage 17.0 (TID 17). 3281 bytes result sent to driver
21/02/17 01:25:49 INFO TaskSetManager: Finished task 0.0 in stage 17.0 (TID 17) in 514 ms on localhost (executor driver) (1/1)
21/02/17 01:25:49 INFO TaskSchedulerImpl: Removed TaskSet 17.0, whose tasks have all completed, from pool 
21/02/17 01:25:49 INFO DAGScheduler: ResultStage 17 (parquet at RFormula.scala:434) finished in 0.532 s
21/02/17 01:25:49 INFO DAGScheduler: Job 13 is finished. Cancelling potential speculative or zombie tasks for this job
21/02/17 01:25:49 INFO TaskSchedulerImpl: Killing all running tasks in stage 17: Stage finished
21/02/17 01:25:49 INFO DAGScheduler: Job 13 finished: parquet at RFormula.scala:434, took 0.548193 s
21/02/17 01:25:49 INFO FileFormatWriter: Write Job 7f73697d-a6e2-4dfe-8ba7-cae13338ebe0 committed.
21/02/17 01:25:49 INFO FileFormatWriter: Finished processing stats for write job 7f73697d-a6e2-4dfe-8ba7-cae13338ebe0.
21/02/17 01:25:49 INFO HadoopMapRedCommitProtocol: Using output committer class org.apache.hadoop.mapred.FileOutputCommitter
21/02/17 01:25:49 INFO FileOutputCommitter: File Output Committer Algorithm version is 2
21/02/17 01:25:49 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
21/02/17 01:25:49 INFO SparkContext: Starting job: runJob at SparkHadoopWriter.scala:78
21/02/17 01:25:49 INFO DAGScheduler: Got job 14 (runJob at SparkHadoopWriter.scala:78) with 1 output partitions
21/02/17 01:25:49 INFO DAGScheduler: Final stage: ResultStage 18 (runJob at SparkHadoopWriter.scala:78)
21/02/17 01:25:49 INFO DAGScheduler: Parents of final stage: List()
21/02/17 01:25:49 INFO DAGScheduler: Missing parents: List()
21/02/17 01:25:49 INFO DAGScheduler: Submitting ResultStage 18 (MapPartitionsRDD[66] at saveAsTextFile at ReadWrite.scala:413), which has no missing parents
21/02/17 01:25:49 INFO MemoryStore: Block broadcast_19 stored as values in memory (estimated size 84.1 KiB, free 912.0 MiB)
21/02/17 01:25:49 INFO MemoryStore: Block broadcast_19_piece0 stored as bytes in memory (estimated size 30.0 KiB, free 912.0 MiB)
21/02/17 01:25:49 INFO BlockManagerInfo: Added broadcast_19_piece0 in memory on localhost:41017 (size: 30.0 KiB, free: 912.2 MiB)
21/02/17 01:25:49 INFO SparkContext: Created broadcast 19 from broadcast at DAGScheduler.scala:1200
21/02/17 01:25:49 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 18 (MapPartitionsRDD[66] at saveAsTextFile at ReadWrite.scala:413) (first 15 tasks are for partitions Vector(0))
21/02/17 01:25:49 INFO TaskSchedulerImpl: Adding task set 18.0 with 1 tasks
21/02/17 01:25:49 INFO TaskSetManager: Starting task 0.0 in stage 18.0 (TID 18, localhost, executor driver, partition 0, PROCESS_LOCAL, 7662 bytes)
21/02/17 01:25:49 INFO Executor: Running task 0.0 in stage 18.0 (TID 18)
21/02/17 01:25:49 INFO HadoopMapRedCommitProtocol: Using output committer class org.apache.hadoop.mapred.FileOutputCommitter
21/02/17 01:25:49 INFO FileOutputCommitter: File Output Committer Algorithm version is 2
21/02/17 01:25:49 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
21/02/17 01:25:49 INFO FileOutputCommitter: Saved output of task 'attempt_20210217012549_0066_m_000000_0' to file:/tmp/RtmpLTlh4o/file2171a4eb3a620/stages/0_r_formula__8e049f4c_a0ea_471a_862c_cafd520f5953/pipelineModel/metadata
21/02/17 01:25:49 INFO SparkHadoopMapRedUtil: attempt_20210217012549_0066_m_000000_0: Committed
21/02/17 01:25:49 INFO Executor: Finished task 0.0 in stage 18.0 (TID 18). 1158 bytes result sent to driver
21/02/17 01:25:49 INFO TaskSetManager: Finished task 0.0 in stage 18.0 (TID 18) in 20 ms on localhost (executor driver) (1/1)
21/02/17 01:25:49 INFO TaskSchedulerImpl: Removed TaskSet 18.0, whose tasks have all completed, from pool 
21/02/17 01:25:49 INFO DAGScheduler: ResultStage 18 (runJob at SparkHadoopWriter.scala:78) finished in 0.035 s
21/02/17 01:25:49 INFO DAGScheduler: Job 14 is finished. Cancelling potential speculative or zombie tasks for this job
21/02/17 01:25:49 INFO TaskSchedulerImpl: Killing all running tasks in stage 18: Stage finished
21/02/17 01:25:49 INFO DAGScheduler: Job 14 finished: runJob at SparkHadoopWriter.scala:78, took 0.037870 s
21/02/17 01:25:49 INFO SparkHadoopWriter: Job job_20210217012549_0066 committed.
21/02/17 01:25:49 INFO HadoopMapRedCommitProtocol: Using output committer class org.apache.hadoop.mapred.FileOutputCommitter
21/02/17 01:25:49 INFO FileOutputCommitter: File Output Committer Algorithm version is 2
21/02/17 01:25:49 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
21/02/17 01:25:49 INFO SparkContext: Starting job: runJob at SparkHadoopWriter.scala:78
21/02/17 01:25:49 INFO DAGScheduler: Got job 15 (runJob at SparkHadoopWriter.scala:78) with 1 output partitions
21/02/17 01:25:49 INFO DAGScheduler: Final stage: ResultStage 19 (runJob at SparkHadoopWriter.scala:78)
21/02/17 01:25:49 INFO DAGScheduler: Parents of final stage: List()
21/02/17 01:25:49 INFO DAGScheduler: Missing parents: List()
21/02/17 01:25:49 INFO DAGScheduler: Submitting ResultStage 19 (MapPartitionsRDD[68] at saveAsTextFile at ReadWrite.scala:413), which has no missing parents
21/02/17 01:25:49 INFO MemoryStore: Block broadcast_20 stored as values in memory (estimated size 84.2 KiB, free 911.9 MiB)
21/02/17 01:25:49 INFO MemoryStore: Block broadcast_20_piece0 stored as bytes in memory (estimated size 30.0 KiB, free 911.8 MiB)
21/02/17 01:25:49 INFO BlockManagerInfo: Added broadcast_20_piece0 in memory on localhost:41017 (size: 30.0 KiB, free: 912.2 MiB)
21/02/17 01:25:49 INFO SparkContext: Created broadcast 20 from broadcast at DAGScheduler.scala:1200
21/02/17 01:25:49 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 19 (MapPartitionsRDD[68] at saveAsTextFile at ReadWrite.scala:413) (first 15 tasks are for partitions Vector(0))
21/02/17 01:25:49 INFO TaskSchedulerImpl: Adding task set 19.0 with 1 tasks
21/02/17 01:25:49 INFO TaskSetManager: Starting task 0.0 in stage 19.0 (TID 19, localhost, executor driver, partition 0, PROCESS_LOCAL, 7729 bytes)
21/02/17 01:25:49 INFO Executor: Running task 0.0 in stage 19.0 (TID 19)
21/02/17 01:25:49 INFO HadoopMapRedCommitProtocol: Using output committer class org.apache.hadoop.mapred.FileOutputCommitter
21/02/17 01:25:49 INFO FileOutputCommitter: File Output Committer Algorithm version is 2
21/02/17 01:25:49 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
21/02/17 01:25:49 INFO FileOutputCommitter: Saved output of task 'attempt_20210217012549_0068_m_000000_0' to file:/tmp/RtmpLTlh4o/file2171a4eb3a620/stages/0_r_formula__8e049f4c_a0ea_471a_862c_cafd520f5953/pipelineModel/stages/0_r_formula__8e049f4c_a0ea_471a_862c_cafd520f5953/metadata
21/02/17 01:25:49 INFO SparkHadoopMapRedUtil: attempt_20210217012549_0068_m_000000_0: Committed
21/02/17 01:25:49 INFO Executor: Finished task 0.0 in stage 19.0 (TID 19). 1158 bytes result sent to driver
21/02/17 01:25:49 INFO TaskSetManager: Finished task 0.0 in stage 19.0 (TID 19) in 18 ms on localhost (executor driver) (1/1)
21/02/17 01:25:49 INFO TaskSchedulerImpl: Removed TaskSet 19.0, whose tasks have all completed, from pool 
21/02/17 01:25:49 INFO DAGScheduler: ResultStage 19 (runJob at SparkHadoopWriter.scala:78) finished in 0.029 s
21/02/17 01:25:49 INFO DAGScheduler: Job 15 is finished. Cancelling potential speculative or zombie tasks for this job
21/02/17 01:25:49 INFO TaskSchedulerImpl: Killing all running tasks in stage 19: Stage finished
21/02/17 01:25:49 INFO DAGScheduler: Job 15 finished: runJob at SparkHadoopWriter.scala:78, took 0.031833 s
21/02/17 01:25:49 INFO SparkHadoopWriter: Job job_20210217012549_0068 committed.
21/02/17 01:25:49 INFO HadoopMapRedCommitProtocol: Using output committer class org.apache.hadoop.mapred.FileOutputCommitter
21/02/17 01:25:49 INFO FileOutputCommitter: File Output Committer Algorithm version is 2
21/02/17 01:25:49 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
21/02/17 01:25:49 INFO SparkContext: Starting job: runJob at SparkHadoopWriter.scala:78
21/02/17 01:25:49 INFO DAGScheduler: Got job 16 (runJob at SparkHadoopWriter.scala:78) with 1 output partitions
21/02/17 01:25:49 INFO DAGScheduler: Final stage: ResultStage 20 (runJob at SparkHadoopWriter.scala:78)
21/02/17 01:25:49 INFO DAGScheduler: Parents of final stage: List()
21/02/17 01:25:49 INFO DAGScheduler: Missing parents: List()
21/02/17 01:25:49 INFO DAGScheduler: Submitting ResultStage 20 (MapPartitionsRDD[70] at saveAsTextFile at ReadWrite.scala:413), which has no missing parents
21/02/17 01:25:49 INFO MemoryStore: Block broadcast_21 stored as values in memory (estimated size 84.1 KiB, free 911.8 MiB)
21/02/17 01:25:49 INFO MemoryStore: Block broadcast_21_piece0 stored as bytes in memory (estimated size 30.0 KiB, free 911.7 MiB)
21/02/17 01:25:49 INFO BlockManagerInfo: Added broadcast_21_piece0 in memory on localhost:41017 (size: 30.0 KiB, free: 912.1 MiB)
21/02/17 01:25:49 INFO SparkContext: Created broadcast 21 from broadcast at DAGScheduler.scala:1200
21/02/17 01:25:49 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 20 (MapPartitionsRDD[70] at saveAsTextFile at ReadWrite.scala:413) (first 15 tasks are for partitions Vector(0))
21/02/17 01:25:49 INFO TaskSchedulerImpl: Adding task set 20.0 with 1 tasks
21/02/17 01:25:49 INFO TaskSetManager: Starting task 0.0 in stage 20.0 (TID 20, localhost, executor driver, partition 0, PROCESS_LOCAL, 7539 bytes)
21/02/17 01:25:49 INFO Executor: Running task 0.0 in stage 20.0 (TID 20)
21/02/17 01:25:49 INFO HadoopMapRedCommitProtocol: Using output committer class org.apache.hadoop.mapred.FileOutputCommitter
21/02/17 01:25:49 INFO FileOutputCommitter: File Output Committer Algorithm version is 2
21/02/17 01:25:49 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
21/02/17 01:25:49 INFO FileOutputCommitter: Saved output of task 'attempt_20210217012549_0070_m_000000_0' to file:/tmp/RtmpLTlh4o/file2171a4eb3a620/stages/0_r_formula__8e049f4c_a0ea_471a_862c_cafd520f5953/pipelineModel/stages/1_vectorAttrRewriter_8ea264265f11/metadata
21/02/17 01:25:49 INFO SparkHadoopMapRedUtil: attempt_20210217012549_0070_m_000000_0: Committed
21/02/17 01:25:49 INFO Executor: Finished task 0.0 in stage 20.0 (TID 20). 1158 bytes result sent to driver
21/02/17 01:25:49 INFO TaskSetManager: Finished task 0.0 in stage 20.0 (TID 20) in 16 ms on localhost (executor driver) (1/1)
21/02/17 01:25:49 INFO TaskSchedulerImpl: Removed TaskSet 20.0, whose tasks have all completed, from pool 
21/02/17 01:25:49 INFO DAGScheduler: ResultStage 20 (runJob at SparkHadoopWriter.scala:78) finished in 0.024 s
21/02/17 01:25:49 INFO DAGScheduler: Job 16 is finished. Cancelling potential speculative or zombie tasks for this job
21/02/17 01:25:49 INFO TaskSchedulerImpl: Killing all running tasks in stage 20: Stage finished
21/02/17 01:25:49 INFO DAGScheduler: Job 16 finished: runJob at SparkHadoopWriter.scala:78, took 0.027120 s
21/02/17 01:25:49 INFO SparkHadoopWriter: Job job_20210217012549_0070 committed.
21/02/17 01:25:49 INFO ParquetFileFormat: Using default output committer for Parquet: org.apache.parquet.hadoop.ParquetOutputCommitter
21/02/17 01:25:49 INFO FileOutputCommitter: File Output Committer Algorithm version is 2
21/02/17 01:25:49 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
21/02/17 01:25:49 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
21/02/17 01:25:49 INFO FileOutputCommitter: File Output Committer Algorithm version is 2
21/02/17 01:25:49 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
21/02/17 01:25:49 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
21/02/17 01:25:49 INFO CodeGenerator: Code generated in 12.483543 ms
21/02/17 01:25:49 INFO SparkContext: Starting job: parquet at RFormula.scala:599
21/02/17 01:25:49 INFO DAGScheduler: Registering RDD 73 (parquet at RFormula.scala:599) as input to shuffle 5
21/02/17 01:25:49 INFO DAGScheduler: Got job 17 (parquet at RFormula.scala:599) with 1 output partitions
21/02/17 01:25:49 INFO DAGScheduler: Final stage: ResultStage 22 (parquet at RFormula.scala:599)
21/02/17 01:25:49 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 21)
21/02/17 01:25:49 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 21)
21/02/17 01:25:49 INFO DAGScheduler: Submitting ShuffleMapStage 21 (MapPartitionsRDD[73] at parquet at RFormula.scala:599), which has no missing parents
21/02/17 01:25:49 INFO MemoryStore: Block broadcast_22 stored as values in memory (estimated size 7.7 KiB, free 911.7 MiB)
21/02/17 01:25:49 INFO MemoryStore: Block broadcast_22_piece0 stored as bytes in memory (estimated size 4.2 KiB, free 911.7 MiB)
21/02/17 01:25:49 INFO BlockManagerInfo: Added broadcast_22_piece0 in memory on localhost:41017 (size: 4.2 KiB, free: 912.1 MiB)
21/02/17 01:25:49 INFO SparkContext: Created broadcast 22 from broadcast at DAGScheduler.scala:1200
21/02/17 01:25:49 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 21 (MapPartitionsRDD[73] at parquet at RFormula.scala:599) (first 15 tasks are for partitions Vector(0))
21/02/17 01:25:49 INFO TaskSchedulerImpl: Adding task set 21.0 with 1 tasks
21/02/17 01:25:49 INFO TaskSetManager: Starting task 0.0 in stage 21.0 (TID 21, localhost, executor driver, partition 0, PROCESS_LOCAL, 7554 bytes)
21/02/17 01:25:49 INFO Executor: Running task 0.0 in stage 21.0 (TID 21)
21/02/17 01:25:49 INFO Executor: Finished task 0.0 in stage 21.0 (TID 21). 1614 bytes result sent to driver
21/02/17 01:25:49 INFO TaskSetManager: Finished task 0.0 in stage 21.0 (TID 21) in 5 ms on localhost (executor driver) (1/1)
21/02/17 01:25:49 INFO TaskSchedulerImpl: Removed TaskSet 21.0, whose tasks have all completed, from pool 
21/02/17 01:25:49 INFO DAGScheduler: ShuffleMapStage 21 (parquet at RFormula.scala:599) finished in 0.010 s
21/02/17 01:25:49 INFO DAGScheduler: looking for newly runnable stages
21/02/17 01:25:49 INFO DAGScheduler: running: Set()
21/02/17 01:25:49 INFO DAGScheduler: waiting: Set(ResultStage 22)
21/02/17 01:25:49 INFO DAGScheduler: failed: Set()
21/02/17 01:25:49 INFO DAGScheduler: Submitting ResultStage 22 (ShuffledRowRDD[74] at parquet at RFormula.scala:599), which has no missing parents
21/02/17 01:25:49 INFO MemoryStore: Block broadcast_23 stored as values in memory (estimated size 175.1 KiB, free 911.5 MiB)
21/02/17 01:25:49 INFO MemoryStore: Block broadcast_23_piece0 stored as bytes in memory (estimated size 61.8 KiB, free 911.5 MiB)
21/02/17 01:25:49 INFO BlockManagerInfo: Added broadcast_23_piece0 in memory on localhost:41017 (size: 61.8 KiB, free: 912.1 MiB)
21/02/17 01:25:49 INFO SparkContext: Created broadcast 23 from broadcast at DAGScheduler.scala:1200
21/02/17 01:25:49 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 22 (ShuffledRowRDD[74] at parquet at RFormula.scala:599) (first 15 tasks are for partitions Vector(0))
21/02/17 01:25:49 INFO TaskSchedulerImpl: Adding task set 22.0 with 1 tasks
21/02/17 01:25:49 INFO TaskSetManager: Starting task 0.0 in stage 22.0 (TID 22, localhost, executor driver, partition 0, NODE_LOCAL, 7325 bytes)
21/02/17 01:25:49 INFO Executor: Running task 0.0 in stage 22.0 (TID 22)
21/02/17 01:25:49 INFO ShuffleBlockFetcherIterator: Getting 1 (88.0 B) non-empty blocks including 1 (88.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
21/02/17 01:25:49 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
21/02/17 01:25:49 INFO FileOutputCommitter: File Output Committer Algorithm version is 2
21/02/17 01:25:49 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
21/02/17 01:25:49 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
21/02/17 01:25:49 INFO FileOutputCommitter: File Output Committer Algorithm version is 2
21/02/17 01:25:49 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
21/02/17 01:25:49 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
21/02/17 01:25:49 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:
{
  "type" : "struct",
  "fields" : [ {
    "name" : "vectorCol",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "prefixesToRewrite",
    "type" : {
      "type" : "map",
      "keyType" : "string",
      "valueType" : "string",
      "valueContainsNull" : true
    },
    "nullable" : true,
    "metadata" : { }
  } ]
}
and corresponding Parquet message type:
message spark_schema {
  optional binary vectorCol (UTF8);
  optional group prefixesToRewrite (MAP) {
    repeated group key_value {
      required binary key (UTF8);
      optional binary value (UTF8);
    }
  }
}

       
21/02/17 01:25:49 INFO FileOutputCommitter: Saved output of task 'attempt_20210217012549_0022_m_000000_22' to file:/tmp/RtmpLTlh4o/file2171a4eb3a620/stages/0_r_formula__8e049f4c_a0ea_471a_862c_cafd520f5953/pipelineModel/stages/1_vectorAttrRewriter_8ea264265f11/data
21/02/17 01:25:49 INFO SparkHadoopMapRedUtil: attempt_20210217012549_0022_m_000000_22: Committed
21/02/17 01:25:49 INFO Executor: Finished task 0.0 in stage 22.0 (TID 22). 3195 bytes result sent to driver
21/02/17 01:25:49 INFO TaskSetManager: Finished task 0.0 in stage 22.0 (TID 22) in 42 ms on localhost (executor driver) (1/1)
21/02/17 01:25:49 INFO TaskSchedulerImpl: Removed TaskSet 22.0, whose tasks have all completed, from pool 
21/02/17 01:25:49 INFO DAGScheduler: ResultStage 22 (parquet at RFormula.scala:599) finished in 0.066 s
21/02/17 01:25:49 INFO DAGScheduler: Job 17 is finished. Cancelling potential speculative or zombie tasks for this job
21/02/17 01:25:49 INFO TaskSchedulerImpl: Killing all running tasks in stage 22: Stage finished
21/02/17 01:25:49 INFO DAGScheduler: Job 17 finished: parquet at RFormula.scala:599, took 0.080088 s
21/02/17 01:25:49 INFO FileFormatWriter: Write Job f790eb55-57e9-4365-bed7-503d22d0bc00 committed.
21/02/17 01:25:49 INFO FileFormatWriter: Finished processing stats for write job f790eb55-57e9-4365-bed7-503d22d0bc00.
21/02/17 01:25:49 INFO HadoopMapRedCommitProtocol: Using output committer class org.apache.hadoop.mapred.FileOutputCommitter
21/02/17 01:25:49 INFO FileOutputCommitter: File Output Committer Algorithm version is 2
21/02/17 01:25:49 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
21/02/17 01:25:49 INFO SparkContext: Starting job: runJob at SparkHadoopWriter.scala:78
21/02/17 01:25:49 INFO DAGScheduler: Got job 18 (runJob at SparkHadoopWriter.scala:78) with 1 output partitions
21/02/17 01:25:49 INFO DAGScheduler: Final stage: ResultStage 23 (runJob at SparkHadoopWriter.scala:78)
21/02/17 01:25:49 INFO DAGScheduler: Parents of final stage: List()
21/02/17 01:25:49 INFO DAGScheduler: Missing parents: List()
21/02/17 01:25:49 INFO DAGScheduler: Submitting ResultStage 23 (MapPartitionsRDD[78] at saveAsTextFile at ReadWrite.scala:413), which has no missing parents
21/02/17 01:25:49 INFO MemoryStore: Block broadcast_24 stored as values in memory (estimated size 84.1 KiB, free 911.4 MiB)
21/02/17 01:25:49 INFO MemoryStore: Block broadcast_24_piece0 stored as bytes in memory (estimated size 30.0 KiB, free 911.4 MiB)
21/02/17 01:25:49 INFO BlockManagerInfo: Added broadcast_24_piece0 in memory on localhost:41017 (size: 30.0 KiB, free: 912.1 MiB)
21/02/17 01:25:49 INFO SparkContext: Created broadcast 24 from broadcast at DAGScheduler.scala:1200
21/02/17 01:25:49 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 23 (MapPartitionsRDD[78] at saveAsTextFile at ReadWrite.scala:413) (first 15 tasks are for partitions Vector(0))
21/02/17 01:25:49 INFO TaskSchedulerImpl: Adding task set 23.0 with 1 tasks
21/02/17 01:25:49 INFO TaskSetManager: Starting task 0.0 in stage 23.0 (TID 23, localhost, executor driver, partition 0, PROCESS_LOCAL, 7522 bytes)
21/02/17 01:25:49 INFO Executor: Running task 0.0 in stage 23.0 (TID 23)
21/02/17 01:25:49 INFO HadoopMapRedCommitProtocol: Using output committer class org.apache.hadoop.mapred.FileOutputCommitter
21/02/17 01:25:49 INFO FileOutputCommitter: File Output Committer Algorithm version is 2
21/02/17 01:25:49 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
21/02/17 01:25:49 INFO FileOutputCommitter: Saved output of task 'attempt_20210217012549_0078_m_000000_0' to file:/tmp/RtmpLTlh4o/file2171a4eb3a620/stages/0_r_formula__8e049f4c_a0ea_471a_862c_cafd520f5953/pipelineModel/stages/2_columnPruner_233f6ca0fca6/metadata
21/02/17 01:25:49 INFO SparkHadoopMapRedUtil: attempt_20210217012549_0078_m_000000_0: Committed
21/02/17 01:25:49 INFO Executor: Finished task 0.0 in stage 23.0 (TID 23). 1158 bytes result sent to driver
21/02/17 01:25:49 INFO TaskSetManager: Finished task 0.0 in stage 23.0 (TID 23) in 14 ms on localhost (executor driver) (1/1)
21/02/17 01:25:49 INFO TaskSchedulerImpl: Removed TaskSet 23.0, whose tasks have all completed, from pool 
21/02/17 01:25:49 INFO DAGScheduler: ResultStage 23 (runJob at SparkHadoopWriter.scala:78) finished in 0.025 s
21/02/17 01:25:49 INFO DAGScheduler: Job 18 is finished. Cancelling potential speculative or zombie tasks for this job
21/02/17 01:25:49 INFO TaskSchedulerImpl: Killing all running tasks in stage 23: Stage finished
21/02/17 01:25:49 INFO DAGScheduler: Job 18 finished: runJob at SparkHadoopWriter.scala:78, took 0.026574 s
21/02/17 01:25:49 INFO SparkHadoopWriter: Job job_20210217012549_0078 committed.
21/02/17 01:25:50 INFO ParquetFileFormat: Using default output committer for Parquet: org.apache.parquet.hadoop.ParquetOutputCommitter
21/02/17 01:25:50 INFO FileOutputCommitter: File Output Committer Algorithm version is 2
21/02/17 01:25:50 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
21/02/17 01:25:50 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
21/02/17 01:25:50 INFO FileOutputCommitter: File Output Committer Algorithm version is 2
21/02/17 01:25:50 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
21/02/17 01:25:50 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
21/02/17 01:25:50 INFO CodeGenerator: Code generated in 6.843813 ms
21/02/17 01:25:50 INFO SparkContext: Starting job: parquet at RFormula.scala:508
21/02/17 01:25:50 INFO DAGScheduler: Registering RDD 81 (parquet at RFormula.scala:508) as input to shuffle 6
21/02/17 01:25:50 INFO DAGScheduler: Got job 19 (parquet at RFormula.scala:508) with 1 output partitions
21/02/17 01:25:50 INFO DAGScheduler: Final stage: ResultStage 25 (parquet at RFormula.scala:508)
21/02/17 01:25:50 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 24)
21/02/17 01:25:50 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 24)
21/02/17 01:25:50 INFO DAGScheduler: Submitting ShuffleMapStage 24 (MapPartitionsRDD[81] at parquet at RFormula.scala:508), which has no missing parents
21/02/17 01:25:50 INFO MemoryStore: Block broadcast_25 stored as values in memory (estimated size 7.6 KiB, free 911.4 MiB)
21/02/17 01:25:50 INFO MemoryStore: Block broadcast_25_piece0 stored as bytes in memory (estimated size 4.1 KiB, free 911.4 MiB)
21/02/17 01:25:50 INFO BlockManagerInfo: Added broadcast_25_piece0 in memory on localhost:41017 (size: 4.1 KiB, free: 912.0 MiB)
21/02/17 01:25:50 INFO SparkContext: Created broadcast 25 from broadcast at DAGScheduler.scala:1200
21/02/17 01:25:50 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 24 (MapPartitionsRDD[81] at parquet at RFormula.scala:508) (first 15 tasks are for partitions Vector(0))
21/02/17 01:25:50 INFO TaskSchedulerImpl: Adding task set 24.0 with 1 tasks
21/02/17 01:25:50 INFO TaskSetManager: Starting task 0.0 in stage 24.0 (TID 24, localhost, executor driver, partition 0, PROCESS_LOCAL, 7522 bytes)
21/02/17 01:25:50 INFO Executor: Running task 0.0 in stage 24.0 (TID 24)
21/02/17 01:25:50 INFO Executor: Finished task 0.0 in stage 24.0 (TID 24). 1614 bytes result sent to driver
21/02/17 01:25:50 INFO TaskSetManager: Finished task 0.0 in stage 24.0 (TID 24) in 6 ms on localhost (executor driver) (1/1)
21/02/17 01:25:50 INFO TaskSchedulerImpl: Removed TaskSet 24.0, whose tasks have all completed, from pool 
21/02/17 01:25:50 INFO DAGScheduler: ShuffleMapStage 24 (parquet at RFormula.scala:508) finished in 0.010 s
21/02/17 01:25:50 INFO DAGScheduler: looking for newly runnable stages
21/02/17 01:25:50 INFO DAGScheduler: running: Set()
21/02/17 01:25:50 INFO DAGScheduler: waiting: Set(ResultStage 25)
21/02/17 01:25:50 INFO DAGScheduler: failed: Set()
21/02/17 01:25:50 INFO DAGScheduler: Submitting ResultStage 25 (ShuffledRowRDD[82] at parquet at RFormula.scala:508), which has no missing parents
21/02/17 01:25:50 INFO MemoryStore: Block broadcast_26 stored as values in memory (estimated size 175.0 KiB, free 911.2 MiB)
21/02/17 01:25:50 INFO MemoryStore: Block broadcast_26_piece0 stored as bytes in memory (estimated size 61.7 KiB, free 911.1 MiB)
21/02/17 01:25:50 INFO BlockManagerInfo: Added broadcast_26_piece0 in memory on localhost:41017 (size: 61.7 KiB, free: 912.0 MiB)
21/02/17 01:25:50 INFO SparkContext: Created broadcast 26 from broadcast at DAGScheduler.scala:1200
21/02/17 01:25:50 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 25 (ShuffledRowRDD[82] at parquet at RFormula.scala:508) (first 15 tasks are for partitions Vector(0))
21/02/17 01:25:50 INFO TaskSchedulerImpl: Adding task set 25.0 with 1 tasks
21/02/17 01:25:50 INFO TaskSetManager: Starting task 0.0 in stage 25.0 (TID 25, localhost, executor driver, partition 0, NODE_LOCAL, 7325 bytes)
21/02/17 01:25:50 INFO Executor: Running task 0.0 in stage 25.0 (TID 25)
21/02/17 01:25:50 INFO ShuffleBlockFetcherIterator: Getting 1 (72.0 B) non-empty blocks including 1 (72.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
21/02/17 01:25:50 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
21/02/17 01:25:50 INFO FileOutputCommitter: File Output Committer Algorithm version is 2
21/02/17 01:25:50 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
21/02/17 01:25:50 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
21/02/17 01:25:50 INFO FileOutputCommitter: File Output Committer Algorithm version is 2
21/02/17 01:25:50 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
21/02/17 01:25:50 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
21/02/17 01:25:50 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:
{
  "type" : "struct",
  "fields" : [ {
    "name" : "columnsToPrune",
    "type" : {
      "type" : "array",
      "elementType" : "string",
      "containsNull" : true
    },
    "nullable" : true,
    "metadata" : { }
  } ]
}
and corresponding Parquet message type:
message spark_schema {
  optional group columnsToPrune (LIST) {
    repeated group list {
      optional binary element (UTF8);
    }
  }
}

       
21/02/17 01:25:50 INFO FileOutputCommitter: Saved output of task 'attempt_20210217012550_0025_m_000000_25' to file:/tmp/RtmpLTlh4o/file2171a4eb3a620/stages/0_r_formula__8e049f4c_a0ea_471a_862c_cafd520f5953/pipelineModel/stages/2_columnPruner_233f6ca0fca6/data
21/02/17 01:25:50 INFO SparkHadoopMapRedUtil: attempt_20210217012550_0025_m_000000_25: Committed
21/02/17 01:25:50 INFO Executor: Finished task 0.0 in stage 25.0 (TID 25). 3195 bytes result sent to driver
21/02/17 01:25:50 INFO TaskSetManager: Finished task 0.0 in stage 25.0 (TID 25) in 20 ms on localhost (executor driver) (1/1)
21/02/17 01:25:50 INFO TaskSchedulerImpl: Removed TaskSet 25.0, whose tasks have all completed, from pool 
21/02/17 01:25:50 INFO DAGScheduler: ResultStage 25 (parquet at RFormula.scala:508) finished in 0.038 s
21/02/17 01:25:50 INFO DAGScheduler: Job 19 is finished. Cancelling potential speculative or zombie tasks for this job
21/02/17 01:25:50 INFO TaskSchedulerImpl: Killing all running tasks in stage 25: Stage finished
21/02/17 01:25:50 INFO DAGScheduler: Job 19 finished: parquet at RFormula.scala:508, took 0.051833 s
21/02/17 01:25:50 INFO FileFormatWriter: Write Job a6d45bcc-9be1-4060-b4b4-9335f6ece29d committed.
21/02/17 01:25:50 INFO FileFormatWriter: Finished processing stats for write job a6d45bcc-9be1-4060-b4b4-9335f6ece29d.
21/02/17 01:25:50 INFO Instrumentation: [ba1d8592] training finished
21/02/17 01:25:50 INFO Instrumentation: [2e164aaf] training finished
21/02/17 01:25:50 INFO HadoopMapRedCommitProtocol: Using output committer class org.apache.hadoop.mapred.FileOutputCommitter
21/02/17 01:25:50 INFO FileOutputCommitter: File Output Committer Algorithm version is 2
21/02/17 01:25:50 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
21/02/17 01:25:50 INFO SparkContext: Starting job: runJob at SparkHadoopWriter.scala:78
21/02/17 01:25:50 INFO DAGScheduler: Got job 20 (runJob at SparkHadoopWriter.scala:78) with 1 output partitions
21/02/17 01:25:50 INFO DAGScheduler: Final stage: ResultStage 26 (runJob at SparkHadoopWriter.scala:78)
21/02/17 01:25:50 INFO DAGScheduler: Parents of final stage: List()
21/02/17 01:25:50 INFO DAGScheduler: Missing parents: List()
21/02/17 01:25:50 INFO DAGScheduler: Submitting ResultStage 26 (MapPartitionsRDD[86] at saveAsTextFile at DefaultXGBoostParamsWriter.scala:52), which has no missing parents
21/02/17 01:25:50 INFO MemoryStore: Block broadcast_27 stored as values in memory (estimated size 84.0 KiB, free 911.0 MiB)
21/02/17 01:25:50 INFO MemoryStore: Block broadcast_27_piece0 stored as bytes in memory (estimated size 30.0 KiB, free 911.0 MiB)
21/02/17 01:25:50 INFO BlockManagerInfo: Added broadcast_27_piece0 in memory on localhost:41017 (size: 30.0 KiB, free: 912.0 MiB)
21/02/17 01:25:50 INFO SparkContext: Created broadcast 27 from broadcast at DAGScheduler.scala:1200
21/02/17 01:25:50 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 26 (MapPartitionsRDD[86] at saveAsTextFile at DefaultXGBoostParamsWriter.scala:52) (first 15 tasks are for partitions Vector(0))
21/02/17 01:25:50 INFO TaskSchedulerImpl: Adding task set 26.0 with 1 tasks
21/02/17 01:25:50 INFO TaskSetManager: Starting task 0.0 in stage 26.0 (TID 26, localhost, executor driver, partition 0, PROCESS_LOCAL, 8635 bytes)
21/02/17 01:25:50 INFO Executor: Running task 0.0 in stage 26.0 (TID 26)
21/02/17 01:25:50 INFO HadoopMapRedCommitProtocol: Using output committer class org.apache.hadoop.mapred.FileOutputCommitter
21/02/17 01:25:50 INFO FileOutputCommitter: File Output Committer Algorithm version is 2
21/02/17 01:25:50 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
21/02/17 01:25:50 INFO FileOutputCommitter: Saved output of task 'attempt_20210217012550_0086_m_000000_0' to file:/tmp/RtmpLTlh4o/file2171a4eb3a620/stages/1_xgboost_regressor__86dd124b_3cb5_4868_8a73_d1d41c2e0270/metadata
21/02/17 01:25:50 INFO SparkHadoopMapRedUtil: attempt_20210217012550_0086_m_000000_0: Committed
21/02/17 01:25:50 INFO Executor: Finished task 0.0 in stage 26.0 (TID 26). 1158 bytes result sent to driver
21/02/17 01:25:50 INFO TaskSetManager: Finished task 0.0 in stage 26.0 (TID 26) in 14 ms on localhost (executor driver) (1/1)
21/02/17 01:25:50 INFO TaskSchedulerImpl: Removed TaskSet 26.0, whose tasks have all completed, from pool 
21/02/17 01:25:50 INFO DAGScheduler: ResultStage 26 (runJob at SparkHadoopWriter.scala:78) finished in 0.027 s
21/02/17 01:25:50 INFO DAGScheduler: Job 20 is finished. Cancelling potential speculative or zombie tasks for this job
21/02/17 01:25:50 INFO TaskSchedulerImpl: Killing all running tasks in stage 26: Stage finished
21/02/17 01:25:50 INFO DAGScheduler: Job 20 finished: runJob at SparkHadoopWriter.scala:78, took 0.028758 s
21/02/17 01:25:50 INFO SparkHadoopWriter: Job job_20210217012550_0086 committed.
21/02/17 01:25:50 INFO Instrumentation: [da340b0e] training finished
21/02/17 01:25:50 INFO Instrumentation: [420ac6e5] training finished
21/02/17 01:25:50 INFO HiveMetaStore: 0: get_database: default
21/02/17 01:25:50 INFO audit: ugi=yitaoli	ip=unknown-ip-addr	cmd=get_database: default	
21/02/17 01:25:50 INFO HiveMetaStore: 0: get_database: default
21/02/17 01:25:50 INFO audit: ugi=yitaoli	ip=unknown-ip-addr	cmd=get_database: default	
21/02/17 01:25:50 INFO HiveMetaStore: 0: get_tables: db=default pat=*
21/02/17 01:25:50 INFO audit: ugi=yitaoli	ip=unknown-ip-addr	cmd=get_tables: db=default pat=*	
21/02/17 01:25:50 INFO CodeGenerator: Code generated in 5.444046 ms
21/02/17 01:25:50 INFO SparkContext: Starting job: collect at utils.scala:54
21/02/17 01:25:50 INFO DAGScheduler: Got job 21 (collect at utils.scala:54) with 2 output partitions
21/02/17 01:25:50 INFO DAGScheduler: Final stage: ResultStage 27 (collect at utils.scala:54)
21/02/17 01:25:50 INFO DAGScheduler: Parents of final stage: List()
21/02/17 01:25:50 INFO DAGScheduler: Missing parents: List()
21/02/17 01:25:50 INFO DAGScheduler: Submitting ResultStage 27 (MapPartitionsRDD[92] at map at utils.scala:54), which has no missing parents
21/02/17 01:25:50 INFO MemoryStore: Block broadcast_28 stored as values in memory (estimated size 10.7 KiB, free 911.0 MiB)
21/02/17 01:25:50 INFO MemoryStore: Block broadcast_28_piece0 stored as bytes in memory (estimated size 4.9 KiB, free 911.0 MiB)
21/02/17 01:25:50 INFO BlockManagerInfo: Added broadcast_28_piece0 in memory on localhost:41017 (size: 4.9 KiB, free: 912.0 MiB)
21/02/17 01:25:50 INFO SparkContext: Created broadcast 28 from broadcast at DAGScheduler.scala:1200
21/02/17 01:25:50 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 27 (MapPartitionsRDD[92] at map at utils.scala:54) (first 15 tasks are for partitions Vector(0, 1))
21/02/17 01:25:50 INFO TaskSchedulerImpl: Adding task set 27.0 with 2 tasks
21/02/17 01:25:50 INFO TaskSetManager: Starting task 0.0 in stage 27.0 (TID 27, localhost, executor driver, partition 0, PROCESS_LOCAL, 7533 bytes)
21/02/17 01:25:50 INFO TaskSetManager: Starting task 1.0 in stage 27.0 (TID 28, localhost, executor driver, partition 1, PROCESS_LOCAL, 7581 bytes)
21/02/17 01:25:50 INFO Executor: Running task 0.0 in stage 27.0 (TID 27)
21/02/17 01:25:50 INFO Executor: Running task 1.0 in stage 27.0 (TID 28)
21/02/17 01:25:50 INFO CodeGenerator: Code generated in 5.019236 ms
21/02/17 01:25:50 INFO Executor: Finished task 1.0 in stage 27.0 (TID 28). 1155 bytes result sent to driver
21/02/17 01:25:50 INFO Executor: Finished task 0.0 in stage 27.0 (TID 27). 1110 bytes result sent to driver
21/02/17 01:25:50 INFO TaskSetManager: Finished task 1.0 in stage 27.0 (TID 28) in 27 ms on localhost (executor driver) (1/2)
21/02/17 01:25:50 INFO TaskSetManager: Finished task 0.0 in stage 27.0 (TID 27) in 27 ms on localhost (executor driver) (2/2)
21/02/17 01:25:50 INFO TaskSchedulerImpl: Removed TaskSet 27.0, whose tasks have all completed, from pool 
21/02/17 01:25:50 INFO DAGScheduler: ResultStage 27 (collect at utils.scala:54) finished in 0.031 s
21/02/17 01:25:50 INFO DAGScheduler: Job 21 is finished. Cancelling potential speculative or zombie tasks for this job
21/02/17 01:25:50 INFO TaskSchedulerImpl: Killing all running tasks in stage 27: Stage finished
21/02/17 01:25:50 INFO DAGScheduler: Job 21 finished: collect at utils.scala:54, took 0.033760 s
21/02/17 01:25:50 INFO InMemoryFileIndex: It took 7 ms to list leaf files for 1 paths.
21/02/17 01:25:50 INFO InMemoryFileIndex: It took 0 ms to list leaf files for 1 paths.
21/02/17 01:25:50 INFO FileSourceStrategy: Pruning directories with: 
21/02/17 01:25:50 INFO FileSourceStrategy: Pushed Filters: 
21/02/17 01:25:50 INFO FileSourceStrategy: Post-Scan Filters: 
21/02/17 01:25:50 INFO FileSourceStrategy: Output Data Schema: struct<value: string>
21/02/17 01:25:50 INFO MemoryStore: Block broadcast_29 stored as values in memory (estimated size 313.9 KiB, free 910.7 MiB)
21/02/17 01:25:50 INFO MemoryStore: Block broadcast_29_piece0 stored as bytes in memory (estimated size 28.3 KiB, free 910.7 MiB)
21/02/17 01:25:50 INFO BlockManagerInfo: Added broadcast_29_piece0 in memory on localhost:41017 (size: 28.3 KiB, free: 911.9 MiB)
21/02/17 01:25:50 INFO SparkContext: Created broadcast 29 from json at NativeMethodAccessorImpl.java:0
21/02/17 01:25:50 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
21/02/17 01:25:50 INFO SparkContext: Starting job: json at NativeMethodAccessorImpl.java:0
21/02/17 01:25:50 INFO DAGScheduler: Got job 22 (json at NativeMethodAccessorImpl.java:0) with 1 output partitions
21/02/17 01:25:50 INFO DAGScheduler: Final stage: ResultStage 28 (json at NativeMethodAccessorImpl.java:0)
21/02/17 01:25:50 INFO DAGScheduler: Parents of final stage: List()
21/02/17 01:25:50 INFO DAGScheduler: Missing parents: List()
21/02/17 01:25:50 INFO DAGScheduler: Submitting ResultStage 28 (MapPartitionsRDD[96] at json at NativeMethodAccessorImpl.java:0), which has no missing parents
21/02/17 01:25:50 INFO MemoryStore: Block broadcast_30 stored as values in memory (estimated size 14.4 KiB, free 910.7 MiB)
21/02/17 01:25:50 INFO MemoryStore: Block broadcast_30_piece0 stored as bytes in memory (estimated size 6.8 KiB, free 910.6 MiB)
21/02/17 01:25:50 INFO BlockManagerInfo: Added broadcast_30_piece0 in memory on localhost:41017 (size: 6.8 KiB, free: 911.9 MiB)
21/02/17 01:25:50 INFO SparkContext: Created broadcast 30 from broadcast at DAGScheduler.scala:1200
21/02/17 01:25:50 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 28 (MapPartitionsRDD[96] at json at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
21/02/17 01:25:50 INFO TaskSchedulerImpl: Adding task set 28.0 with 1 tasks
21/02/17 01:25:50 INFO TaskSetManager: Starting task 0.0 in stage 28.0 (TID 29, localhost, executor driver, partition 0, PROCESS_LOCAL, 7757 bytes)
21/02/17 01:25:50 INFO Executor: Running task 0.0 in stage 28.0 (TID 29)
21/02/17 01:25:50 INFO BlockManagerInfo: Removed broadcast_19_piece0 on localhost:41017 in memory (size: 30.0 KiB, free: 911.9 MiB)
21/02/17 01:25:50 INFO BlockManagerInfo: Removed broadcast_28_piece0 on localhost:41017 in memory (size: 4.9 KiB, free: 912.0 MiB)
21/02/17 01:25:50 INFO BlockManagerInfo: Removed broadcast_24_piece0 on localhost:41017 in memory (size: 30.0 KiB, free: 912.0 MiB)
21/02/17 01:25:50 INFO BlockManagerInfo: Removed broadcast_23_piece0 on localhost:41017 in memory (size: 61.8 KiB, free: 912.0 MiB)
21/02/17 01:25:50 INFO BlockManagerInfo: Removed broadcast_22_piece0 on localhost:41017 in memory (size: 4.2 KiB, free: 912.0 MiB)
21/02/17 01:25:50 INFO BlockManagerInfo: Removed broadcast_27_piece0 on localhost:41017 in memory (size: 30.0 KiB, free: 912.1 MiB)
21/02/17 01:25:50 INFO BlockManagerInfo: Removed broadcast_26_piece0 on localhost:41017 in memory (size: 61.7 KiB, free: 912.1 MiB)
21/02/17 01:25:50 INFO BlockManagerInfo: Removed broadcast_20_piece0 on localhost:41017 in memory (size: 30.0 KiB, free: 912.2 MiB)
21/02/17 01:25:50 INFO BlockManagerInfo: Removed broadcast_21_piece0 on localhost:41017 in memory (size: 30.0 KiB, free: 912.2 MiB)
21/02/17 01:25:50 INFO BlockManagerInfo: Removed broadcast_25_piece0 on localhost:41017 in memory (size: 4.1 KiB, free: 912.2 MiB)
21/02/17 01:25:50 INFO FileScanRDD: Reading File path: file:///tmp/RtmpLTlh4o/file2171a4eb3a620/metadata/part-00000, range: 0-306, partition values: [empty row]
21/02/17 01:25:50 INFO CodeGenerator: Code generated in 4.69432 ms
21/02/17 01:25:50 INFO Executor: Finished task 0.0 in stage 28.0 (TID 29). 2251 bytes result sent to driver
21/02/17 01:25:50 INFO TaskSetManager: Finished task 0.0 in stage 28.0 (TID 29) in 81 ms on localhost (executor driver) (1/1)
21/02/17 01:25:50 INFO TaskSchedulerImpl: Removed TaskSet 28.0, whose tasks have all completed, from pool 
21/02/17 01:25:50 INFO DAGScheduler: ResultStage 28 (json at NativeMethodAccessorImpl.java:0) finished in 0.100 s
21/02/17 01:25:50 INFO DAGScheduler: Job 22 is finished. Cancelling potential speculative or zombie tasks for this job
21/02/17 01:25:50 INFO TaskSchedulerImpl: Killing all running tasks in stage 28: Stage finished
21/02/17 01:25:50 INFO DAGScheduler: Job 22 finished: json at NativeMethodAccessorImpl.java:0, took 0.103599 s
21/02/17 01:25:50 INFO HiveMetaStore: 0: get_database: default
21/02/17 01:25:50 INFO audit: ugi=yitaoli	ip=unknown-ip-addr	cmd=get_database: default	
21/02/17 01:25:50 INFO HiveMetaStore: 0: get_database: default
21/02/17 01:25:50 INFO audit: ugi=yitaoli	ip=unknown-ip-addr	cmd=get_database: default	
21/02/17 01:25:50 INFO HiveMetaStore: 0: get_tables: db=default pat=*
21/02/17 01:25:50 INFO audit: ugi=yitaoli	ip=unknown-ip-addr	cmd=get_tables: db=default pat=*	
21/02/17 01:25:50 INFO CodeGenerator: Code generated in 5.012512 ms
21/02/17 01:25:50 INFO CodeGenerator: Code generated in 5.617579 ms
21/02/17 01:25:50 INFO CodeGenerator: Code generated in 6.305749 ms
21/02/17 01:25:50 INFO CodeGenerator: Code generated in 4.026188 ms
21/02/17 01:25:50 INFO SparkContext: Starting job: count at utils.scala:135
21/02/17 01:25:50 INFO DAGScheduler: Registering RDD 99 (count at utils.scala:135) as input to shuffle 7
21/02/17 01:25:50 INFO DAGScheduler: Got job 23 (count at utils.scala:135) with 1 output partitions
21/02/17 01:25:50 INFO DAGScheduler: Final stage: ResultStage 30 (count at utils.scala:135)
21/02/17 01:25:50 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 29)
21/02/17 01:25:50 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 29)
21/02/17 01:25:50 INFO DAGScheduler: Submitting ShuffleMapStage 29 (MapPartitionsRDD[99] at count at utils.scala:135), which has no missing parents
21/02/17 01:25:50 INFO MemoryStore: Block broadcast_31 stored as values in memory (estimated size 10.1 KiB, free 911.7 MiB)
21/02/17 01:25:50 INFO MemoryStore: Block broadcast_31_piece0 stored as bytes in memory (estimated size 5.3 KiB, free 911.7 MiB)
21/02/17 01:25:50 INFO BlockManagerInfo: Added broadcast_31_piece0 in memory on localhost:41017 (size: 5.3 KiB, free: 912.2 MiB)
21/02/17 01:25:50 INFO SparkContext: Created broadcast 31 from broadcast at DAGScheduler.scala:1200
21/02/17 01:25:50 INFO DAGScheduler: Submitting 2 missing tasks from ShuffleMapStage 29 (MapPartitionsRDD[99] at count at utils.scala:135) (first 15 tasks are for partitions Vector(0, 1))
21/02/17 01:25:50 INFO TaskSchedulerImpl: Adding task set 29.0 with 2 tasks
21/02/17 01:25:50 INFO TaskSetManager: Starting task 0.0 in stage 29.0 (TID 30, localhost, executor driver, partition 0, PROCESS_LOCAL, 7498 bytes)
21/02/17 01:25:50 INFO TaskSetManager: Starting task 1.0 in stage 29.0 (TID 31, localhost, executor driver, partition 1, PROCESS_LOCAL, 7498 bytes)
21/02/17 01:25:50 INFO Executor: Running task 1.0 in stage 29.0 (TID 31)
21/02/17 01:25:50 INFO Executor: Running task 0.0 in stage 29.0 (TID 30)
21/02/17 01:25:50 INFO Executor: Finished task 1.0 in stage 29.0 (TID 31). 1833 bytes result sent to driver
21/02/17 01:25:50 INFO Executor: Finished task 0.0 in stage 29.0 (TID 30). 1833 bytes result sent to driver
21/02/17 01:25:50 INFO TaskSetManager: Finished task 1.0 in stage 29.0 (TID 31) in 9 ms on localhost (executor driver) (1/2)
21/02/17 01:25:50 INFO TaskSetManager: Finished task 0.0 in stage 29.0 (TID 30) in 9 ms on localhost (executor driver) (2/2)
21/02/17 01:25:50 INFO TaskSchedulerImpl: Removed TaskSet 29.0, whose tasks have all completed, from pool 
21/02/17 01:25:50 INFO DAGScheduler: ShuffleMapStage 29 (count at utils.scala:135) finished in 0.013 s
21/02/17 01:25:50 INFO DAGScheduler: looking for newly runnable stages
21/02/17 01:25:50 INFO DAGScheduler: running: Set()
21/02/17 01:25:50 INFO DAGScheduler: waiting: Set(ResultStage 30)
21/02/17 01:25:50 INFO DAGScheduler: failed: Set()
21/02/17 01:25:50 INFO DAGScheduler: Submitting ResultStage 30 (MapPartitionsRDD[102] at count at utils.scala:135), which has no missing parents
21/02/17 01:25:50 INFO MemoryStore: Block broadcast_32 stored as values in memory (estimated size 10.1 KiB, free 911.7 MiB)
21/02/17 01:25:50 INFO MemoryStore: Block broadcast_32_piece0 stored as bytes in memory (estimated size 5.0 KiB, free 911.7 MiB)
21/02/17 01:25:50 INFO BlockManagerInfo: Added broadcast_32_piece0 in memory on localhost:41017 (size: 5.0 KiB, free: 912.2 MiB)
21/02/17 01:25:50 INFO SparkContext: Created broadcast 32 from broadcast at DAGScheduler.scala:1200
21/02/17 01:25:50 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 30 (MapPartitionsRDD[102] at count at utils.scala:135) (first 15 tasks are for partitions Vector(0))
21/02/17 01:25:50 INFO TaskSchedulerImpl: Adding task set 30.0 with 1 tasks
21/02/17 01:25:50 INFO TaskSetManager: Starting task 0.0 in stage 30.0 (TID 32, localhost, executor driver, partition 0, NODE_LOCAL, 7325 bytes)
21/02/17 01:25:50 INFO Executor: Running task 0.0 in stage 30.0 (TID 32)
21/02/17 01:25:50 INFO ShuffleBlockFetcherIterator: Getting 2 (120.0 B) non-empty blocks including 2 (120.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
21/02/17 01:25:50 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
21/02/17 01:25:50 INFO Executor: Finished task 0.0 in stage 30.0 (TID 32). 2648 bytes result sent to driver
21/02/17 01:25:50 INFO TaskSetManager: Finished task 0.0 in stage 30.0 (TID 32) in 6 ms on localhost (executor driver) (1/1)
21/02/17 01:25:50 INFO TaskSchedulerImpl: Removed TaskSet 30.0, whose tasks have all completed, from pool 
21/02/17 01:25:50 INFO DAGScheduler: ResultStage 30 (count at utils.scala:135) finished in 0.010 s
21/02/17 01:25:50 INFO DAGScheduler: Job 23 is finished. Cancelling potential speculative or zombie tasks for this job
21/02/17 01:25:50 INFO TaskSchedulerImpl: Killing all running tasks in stage 30: Stage finished
21/02/17 01:25:50 INFO DAGScheduler: Job 23 finished: count at utils.scala:135, took 0.027157 s
21/02/17 01:25:50 INFO FileSourceStrategy: Pruning directories with: 
21/02/17 01:25:50 INFO FileSourceStrategy: Pushed Filters: 
21/02/17 01:25:50 INFO FileSourceStrategy: Post-Scan Filters: 
21/02/17 01:25:50 INFO FileSourceStrategy: Output Data Schema: struct<class: string, paramMap: struct<stageUids: array<string>>, sparkVersion: string, timestamp: bigint, uid: string ... 3 more fields>
21/02/17 01:25:50 INFO CodeGenerator: Code generated in 6.705914 ms
21/02/17 01:25:50 INFO MemoryStore: Block broadcast_33 stored as values in memory (estimated size 313.9 KiB, free 911.4 MiB)
21/02/17 01:25:50 INFO MemoryStore: Block broadcast_33_piece0 stored as bytes in memory (estimated size 28.3 KiB, free 911.3 MiB)
21/02/17 01:25:50 INFO BlockManagerInfo: Added broadcast_33_piece0 in memory on localhost:41017 (size: 28.3 KiB, free: 912.2 MiB)
21/02/17 01:25:50 INFO SparkContext: Created broadcast 33 from sql at <unknown>:0
21/02/17 01:25:50 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
21/02/17 01:25:50 INFO SparkContext: Starting job: sql at <unknown>:0
21/02/17 01:25:50 INFO DAGScheduler: Registering RDD 109 (sql at <unknown>:0) as input to shuffle 8
21/02/17 01:25:50 INFO DAGScheduler: Got job 24 (sql at <unknown>:0) with 1 output partitions
21/02/17 01:25:50 INFO DAGScheduler: Final stage: ResultStage 32 (sql at <unknown>:0)
21/02/17 01:25:50 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 31)
21/02/17 01:25:50 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 31)
21/02/17 01:25:50 INFO DAGScheduler: Submitting ShuffleMapStage 31 (MapPartitionsRDD[109] at sql at <unknown>:0), which has no missing parents
21/02/17 01:25:50 INFO MemoryStore: Block broadcast_34 stored as values in memory (estimated size 21.5 KiB, free 911.3 MiB)
21/02/17 01:25:50 INFO MemoryStore: Block broadcast_34_piece0 stored as bytes in memory (estimated size 10.1 KiB, free 911.3 MiB)
21/02/17 01:25:50 INFO BlockManagerInfo: Added broadcast_34_piece0 in memory on localhost:41017 (size: 10.1 KiB, free: 912.2 MiB)
21/02/17 01:25:50 INFO SparkContext: Created broadcast 34 from broadcast at DAGScheduler.scala:1200
21/02/17 01:25:50 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 31 (MapPartitionsRDD[109] at sql at <unknown>:0) (first 15 tasks are for partitions Vector(0))
21/02/17 01:25:50 INFO TaskSchedulerImpl: Adding task set 31.0 with 1 tasks
21/02/17 01:25:50 INFO TaskSetManager: Starting task 0.0 in stage 31.0 (TID 33, localhost, executor driver, partition 0, PROCESS_LOCAL, 7746 bytes)
21/02/17 01:25:50 INFO Executor: Running task 0.0 in stage 31.0 (TID 33)
21/02/17 01:25:50 INFO FileScanRDD: Reading File path: file:///tmp/RtmpLTlh4o/file2171a4eb3a620/metadata/part-00000, range: 0-306, partition values: [empty row]
21/02/17 01:25:50 INFO CodeGenerator: Code generated in 8.018529 ms
21/02/17 01:25:50 INFO MemoryStore: Block rdd_105_0 stored as values in memory (estimated size 1296.0 B, free 911.3 MiB)
21/02/17 01:25:50 INFO BlockManagerInfo: Added rdd_105_0 in memory on localhost:41017 (size: 1296.0 B, free: 912.2 MiB)
21/02/17 01:25:50 INFO CodeGenerator: Code generated in 8.271508 ms
21/02/17 01:25:50 INFO Executor: Finished task 0.0 in stage 31.0 (TID 33). 2067 bytes result sent to driver
21/02/17 01:25:50 INFO TaskSetManager: Finished task 0.0 in stage 31.0 (TID 33) in 48 ms on localhost (executor driver) (1/1)
21/02/17 01:25:50 INFO TaskSchedulerImpl: Removed TaskSet 31.0, whose tasks have all completed, from pool 
21/02/17 01:25:50 INFO DAGScheduler: ShuffleMapStage 31 (sql at <unknown>:0) finished in 0.053 s
21/02/17 01:25:50 INFO DAGScheduler: looking for newly runnable stages
21/02/17 01:25:50 INFO DAGScheduler: running: Set()
21/02/17 01:25:50 INFO DAGScheduler: waiting: Set(ResultStage 32)
21/02/17 01:25:50 INFO DAGScheduler: failed: Set()
21/02/17 01:25:50 INFO DAGScheduler: Submitting ResultStage 32 (MapPartitionsRDD[112] at sql at <unknown>:0), which has no missing parents
21/02/17 01:25:50 INFO MemoryStore: Block broadcast_35 stored as values in memory (estimated size 10.1 KiB, free 911.3 MiB)
21/02/17 01:25:50 INFO MemoryStore: Block broadcast_35_piece0 stored as bytes in memory (estimated size 5.0 KiB, free 911.3 MiB)
21/02/17 01:25:50 INFO BlockManagerInfo: Added broadcast_35_piece0 in memory on localhost:41017 (size: 5.0 KiB, free: 912.1 MiB)
21/02/17 01:25:50 INFO SparkContext: Created broadcast 35 from broadcast at DAGScheduler.scala:1200
21/02/17 01:25:50 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 32 (MapPartitionsRDD[112] at sql at <unknown>:0) (first 15 tasks are for partitions Vector(0))
21/02/17 01:25:50 INFO TaskSchedulerImpl: Adding task set 32.0 with 1 tasks
21/02/17 01:25:50 INFO TaskSetManager: Starting task 0.0 in stage 32.0 (TID 34, localhost, executor driver, partition 0, NODE_LOCAL, 7325 bytes)
21/02/17 01:25:50 INFO Executor: Running task 0.0 in stage 32.0 (TID 34)
21/02/17 01:25:50 INFO ShuffleBlockFetcherIterator: Getting 1 (60.0 B) non-empty blocks including 1 (60.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
21/02/17 01:25:50 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
21/02/17 01:25:50 INFO Executor: Finished task 0.0 in stage 32.0 (TID 34). 2648 bytes result sent to driver
21/02/17 01:25:50 INFO TaskSetManager: Finished task 0.0 in stage 32.0 (TID 34) in 4 ms on localhost (executor driver) (1/1)
21/02/17 01:25:50 INFO TaskSchedulerImpl: Removed TaskSet 32.0, whose tasks have all completed, from pool 
21/02/17 01:25:50 INFO DAGScheduler: ResultStage 32 (sql at <unknown>:0) finished in 0.008 s
21/02/17 01:25:50 INFO DAGScheduler: Job 24 is finished. Cancelling potential speculative or zombie tasks for this job
21/02/17 01:25:50 INFO TaskSchedulerImpl: Killing all running tasks in stage 32: Stage finished
21/02/17 01:25:50 INFO DAGScheduler: Job 24 finished: sql at <unknown>:0, took 0.065230 s
21/02/17 01:25:51 INFO SparkContext: Starting job: collect at utils.scala:137
21/02/17 01:25:51 INFO DAGScheduler: Registering RDD 116 (collect at utils.scala:137) as input to shuffle 9
21/02/17 01:25:51 INFO DAGScheduler: Got job 25 (collect at utils.scala:137) with 1 output partitions
21/02/17 01:25:51 INFO DAGScheduler: Final stage: ResultStage 34 (collect at utils.scala:137)
21/02/17 01:25:51 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 33)
21/02/17 01:25:51 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 33)
21/02/17 01:25:51 INFO DAGScheduler: Submitting ShuffleMapStage 33 (MapPartitionsRDD[116] at collect at utils.scala:137), which has no missing parents
21/02/17 01:25:51 INFO MemoryStore: Block broadcast_36 stored as values in memory (estimated size 21.5 KiB, free 911.3 MiB)
21/02/17 01:25:51 INFO MemoryStore: Block broadcast_36_piece0 stored as bytes in memory (estimated size 10.1 KiB, free 911.3 MiB)
21/02/17 01:25:51 INFO BlockManagerInfo: Added broadcast_36_piece0 in memory on localhost:41017 (size: 10.1 KiB, free: 912.1 MiB)
21/02/17 01:25:51 INFO SparkContext: Created broadcast 36 from broadcast at DAGScheduler.scala:1200
21/02/17 01:25:51 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 33 (MapPartitionsRDD[116] at collect at utils.scala:137) (first 15 tasks are for partitions Vector(0))
21/02/17 01:25:51 INFO TaskSchedulerImpl: Adding task set 33.0 with 1 tasks
21/02/17 01:25:51 INFO TaskSetManager: Starting task 0.0 in stage 33.0 (TID 35, localhost, executor driver, partition 0, PROCESS_LOCAL, 7746 bytes)
21/02/17 01:25:51 INFO Executor: Running task 0.0 in stage 33.0 (TID 35)
21/02/17 01:25:51 INFO BlockManager: Found block rdd_105_0 locally
21/02/17 01:25:51 INFO Executor: Finished task 0.0 in stage 33.0 (TID 35). 2067 bytes result sent to driver
21/02/17 01:25:51 INFO TaskSetManager: Finished task 0.0 in stage 33.0 (TID 35) in 6 ms on localhost (executor driver) (1/1)
21/02/17 01:25:51 INFO TaskSchedulerImpl: Removed TaskSet 33.0, whose tasks have all completed, from pool 
21/02/17 01:25:51 INFO DAGScheduler: ShuffleMapStage 33 (collect at utils.scala:137) finished in 0.011 s
21/02/17 01:25:51 INFO DAGScheduler: looking for newly runnable stages
21/02/17 01:25:51 INFO DAGScheduler: running: Set()
21/02/17 01:25:51 INFO DAGScheduler: waiting: Set(ResultStage 34)
21/02/17 01:25:51 INFO DAGScheduler: failed: Set()
21/02/17 01:25:51 INFO DAGScheduler: Submitting ResultStage 34 (MapPartitionsRDD[119] at collect at utils.scala:137), which has no missing parents
21/02/17 01:25:51 INFO MemoryStore: Block broadcast_37 stored as values in memory (estimated size 10.1 KiB, free 911.3 MiB)
21/02/17 01:25:51 INFO MemoryStore: Block broadcast_37_piece0 stored as bytes in memory (estimated size 5.0 KiB, free 911.3 MiB)
21/02/17 01:25:51 INFO BlockManagerInfo: Added broadcast_37_piece0 in memory on localhost:41017 (size: 5.0 KiB, free: 912.1 MiB)
21/02/17 01:25:51 INFO SparkContext: Created broadcast 37 from broadcast at DAGScheduler.scala:1200
21/02/17 01:25:51 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 34 (MapPartitionsRDD[119] at collect at utils.scala:137) (first 15 tasks are for partitions Vector(0))
21/02/17 01:25:51 INFO TaskSchedulerImpl: Adding task set 34.0 with 1 tasks
21/02/17 01:25:51 INFO TaskSetManager: Starting task 0.0 in stage 34.0 (TID 36, localhost, executor driver, partition 0, NODE_LOCAL, 7325 bytes)
21/02/17 01:25:51 INFO Executor: Running task 0.0 in stage 34.0 (TID 36)
21/02/17 01:25:51 INFO ShuffleBlockFetcherIterator: Getting 1 (60.0 B) non-empty blocks including 1 (60.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
21/02/17 01:25:51 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
21/02/17 01:25:51 INFO Executor: Finished task 0.0 in stage 34.0 (TID 36). 2648 bytes result sent to driver
21/02/17 01:25:51 INFO TaskSetManager: Finished task 0.0 in stage 34.0 (TID 36) in 5 ms on localhost (executor driver) (1/1)
21/02/17 01:25:51 INFO TaskSchedulerImpl: Removed TaskSet 34.0, whose tasks have all completed, from pool 
21/02/17 01:25:51 INFO DAGScheduler: ResultStage 34 (collect at utils.scala:137) finished in 0.009 s
21/02/17 01:25:51 INFO DAGScheduler: Job 25 is finished. Cancelling potential speculative or zombie tasks for this job
21/02/17 01:25:51 INFO TaskSchedulerImpl: Killing all running tasks in stage 34: Stage finished
21/02/17 01:25:51 INFO DAGScheduler: Job 25 finished: collect at utils.scala:137, took 0.024198 s
21/02/17 01:25:51 INFO CodeGenerator: Code generated in 5.731791 ms
21/02/17 01:25:51 INFO CodeGenerator: Code generated in 8.470769 ms
21/02/17 01:25:51 INFO CodeGenerator: Code generated in 5.203648 ms
21/02/17 01:25:51 INFO SparkContext: Starting job: count at utils.scala:135
21/02/17 01:25:51 INFO DAGScheduler: Registering RDD 123 (count at utils.scala:135) as input to shuffle 10
21/02/17 01:25:51 INFO DAGScheduler: Got job 26 (count at utils.scala:135) with 1 output partitions
21/02/17 01:25:51 INFO DAGScheduler: Final stage: ResultStage 36 (count at utils.scala:135)
21/02/17 01:25:51 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 35)
21/02/17 01:25:51 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 35)
21/02/17 01:25:51 INFO DAGScheduler: Submitting ShuffleMapStage 35 (MapPartitionsRDD[123] at count at utils.scala:135), which has no missing parents
21/02/17 01:25:51 INFO MemoryStore: Block broadcast_38 stored as values in memory (estimated size 20.9 KiB, free 911.2 MiB)
21/02/17 01:25:51 INFO MemoryStore: Block broadcast_38_piece0 stored as bytes in memory (estimated size 9.9 KiB, free 911.2 MiB)
21/02/17 01:25:51 INFO BlockManagerInfo: Added broadcast_38_piece0 in memory on localhost:41017 (size: 9.9 KiB, free: 912.1 MiB)
21/02/17 01:25:51 INFO SparkContext: Created broadcast 38 from broadcast at DAGScheduler.scala:1200
21/02/17 01:25:51 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 35 (MapPartitionsRDD[123] at count at utils.scala:135) (first 15 tasks are for partitions Vector(0))
21/02/17 01:25:51 INFO TaskSchedulerImpl: Adding task set 35.0 with 1 tasks
21/02/17 01:25:51 INFO TaskSetManager: Starting task 0.0 in stage 35.0 (TID 37, localhost, executor driver, partition 0, PROCESS_LOCAL, 7746 bytes)
21/02/17 01:25:51 INFO Executor: Running task 0.0 in stage 35.0 (TID 37)
21/02/17 01:25:51 INFO BlockManager: Found block rdd_105_0 locally
21/02/17 01:25:51 INFO Executor: Finished task 0.0 in stage 35.0 (TID 37). 2067 bytes result sent to driver
21/02/17 01:25:51 INFO TaskSetManager: Finished task 0.0 in stage 35.0 (TID 37) in 9 ms on localhost (executor driver) (1/1)
21/02/17 01:25:51 INFO TaskSchedulerImpl: Removed TaskSet 35.0, whose tasks have all completed, from pool 
21/02/17 01:25:51 INFO DAGScheduler: ShuffleMapStage 35 (count at utils.scala:135) finished in 0.014 s
21/02/17 01:25:51 INFO DAGScheduler: looking for newly runnable stages
21/02/17 01:25:51 INFO DAGScheduler: running: Set()
21/02/17 01:25:51 INFO DAGScheduler: waiting: Set(ResultStage 36)
21/02/17 01:25:51 INFO DAGScheduler: failed: Set()
21/02/17 01:25:51 INFO DAGScheduler: Submitting ResultStage 36 (MapPartitionsRDD[126] at count at utils.scala:135), which has no missing parents
21/02/17 01:25:51 INFO MemoryStore: Block broadcast_39 stored as values in memory (estimated size 12.1 KiB, free 911.2 MiB)
21/02/17 01:25:51 INFO MemoryStore: Block broadcast_39_piece0 stored as bytes in memory (estimated size 5.3 KiB, free 911.2 MiB)
21/02/17 01:25:51 INFO BlockManagerInfo: Added broadcast_39_piece0 in memory on localhost:41017 (size: 5.3 KiB, free: 912.1 MiB)
21/02/17 01:25:51 INFO SparkContext: Created broadcast 39 from broadcast at DAGScheduler.scala:1200
21/02/17 01:25:51 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 36 (MapPartitionsRDD[126] at count at utils.scala:135) (first 15 tasks are for partitions Vector(0))
21/02/17 01:25:51 INFO TaskSchedulerImpl: Adding task set 36.0 with 1 tasks
21/02/17 01:25:51 INFO TaskSetManager: Starting task 0.0 in stage 36.0 (TID 38, localhost, executor driver, partition 0, NODE_LOCAL, 7325 bytes)
21/02/17 01:25:51 INFO Executor: Running task 0.0 in stage 36.0 (TID 38)
21/02/17 01:25:51 INFO ShuffleBlockFetcherIterator: Getting 1 (49.0 B) non-empty blocks including 1 (49.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
21/02/17 01:25:51 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
21/02/17 01:25:51 INFO Executor: Finished task 0.0 in stage 36.0 (TID 38). 2896 bytes result sent to driver
21/02/17 01:25:51 INFO TaskSetManager: Finished task 0.0 in stage 36.0 (TID 38) in 6 ms on localhost (executor driver) (1/1)
21/02/17 01:25:51 INFO TaskSchedulerImpl: Removed TaskSet 36.0, whose tasks have all completed, from pool 
21/02/17 01:25:51 INFO DAGScheduler: ResultStage 36 (count at utils.scala:135) finished in 0.011 s
21/02/17 01:25:51 INFO DAGScheduler: Job 26 is finished. Cancelling potential speculative or zombie tasks for this job
21/02/17 01:25:51 INFO TaskSchedulerImpl: Killing all running tasks in stage 36: Stage finished
21/02/17 01:25:51 INFO DAGScheduler: Job 26 finished: count at utils.scala:135, took 0.027351 s
21/02/17 01:25:51 INFO SparkContext: Starting job: collect at utils.scala:137
21/02/17 01:25:51 INFO DAGScheduler: Got job 27 (collect at utils.scala:137) with 1 output partitions
21/02/17 01:25:51 INFO DAGScheduler: Final stage: ResultStage 37 (collect at utils.scala:137)
21/02/17 01:25:51 INFO DAGScheduler: Parents of final stage: List()
21/02/17 01:25:51 INFO DAGScheduler: Missing parents: List()
21/02/17 01:25:51 INFO DAGScheduler: Submitting ResultStage 37 (MapPartitionsRDD[128] at collect at utils.scala:137), which has no missing parents
21/02/17 01:25:51 INFO MemoryStore: Block broadcast_40 stored as values in memory (estimated size 7.2 KiB, free 911.2 MiB)
21/02/17 01:25:51 INFO MemoryStore: Block broadcast_40_piece0 stored as bytes in memory (estimated size 3.7 KiB, free 911.2 MiB)
21/02/17 01:25:51 INFO BlockManagerInfo: Added broadcast_40_piece0 in memory on localhost:41017 (size: 3.7 KiB, free: 912.1 MiB)
21/02/17 01:25:51 INFO SparkContext: Created broadcast 40 from broadcast at DAGScheduler.scala:1200
21/02/17 01:25:51 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 37 (MapPartitionsRDD[128] at collect at utils.scala:137) (first 15 tasks are for partitions Vector(0))
21/02/17 01:25:51 INFO TaskSchedulerImpl: Adding task set 37.0 with 1 tasks
21/02/17 01:25:51 INFO TaskSetManager: Starting task 0.0 in stage 37.0 (TID 39, localhost, executor driver, partition 0, PROCESS_LOCAL, 7561 bytes)
21/02/17 01:25:51 INFO Executor: Running task 0.0 in stage 37.0 (TID 39)
21/02/17 01:25:51 INFO Executor: Finished task 0.0 in stage 37.0 (TID 39). 1354 bytes result sent to driver
21/02/17 01:25:51 INFO TaskSetManager: Finished task 0.0 in stage 37.0 (TID 39) in 4 ms on localhost (executor driver) (1/1)
21/02/17 01:25:51 INFO TaskSchedulerImpl: Removed TaskSet 37.0, whose tasks have all completed, from pool 
21/02/17 01:25:51 INFO DAGScheduler: ResultStage 37 (collect at utils.scala:137) finished in 0.007 s
21/02/17 01:25:51 INFO DAGScheduler: Job 27 is finished. Cancelling potential speculative or zombie tasks for this job
21/02/17 01:25:51 INFO TaskSchedulerImpl: Killing all running tasks in stage 37: Stage finished
21/02/17 01:25:51 INFO DAGScheduler: Job 27 finished: collect at utils.scala:137, took 0.008801 s
21/02/17 01:25:51 INFO SparkContext: Starting job: count at utils.scala:135
21/02/17 01:25:51 INFO DAGScheduler: Registering RDD 130 (count at utils.scala:135) as input to shuffle 11
21/02/17 01:25:51 INFO DAGScheduler: Got job 28 (count at utils.scala:135) with 1 output partitions
21/02/17 01:25:51 INFO DAGScheduler: Final stage: ResultStage 39 (count at utils.scala:135)
21/02/17 01:25:51 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 38)
21/02/17 01:25:51 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 38)
21/02/17 01:25:51 INFO DAGScheduler: Submitting ShuffleMapStage 38 (MapPartitionsRDD[130] at count at utils.scala:135), which has no missing parents
21/02/17 01:25:51 INFO MemoryStore: Block broadcast_41 stored as values in memory (estimated size 10.0 KiB, free 911.2 MiB)
21/02/17 01:25:51 INFO MemoryStore: Block broadcast_41_piece0 stored as bytes in memory (estimated size 5.2 KiB, free 911.2 MiB)
21/02/17 01:25:51 INFO BlockManagerInfo: Added broadcast_41_piece0 in memory on localhost:41017 (size: 5.2 KiB, free: 912.1 MiB)
21/02/17 01:25:51 INFO SparkContext: Created broadcast 41 from broadcast at DAGScheduler.scala:1200
21/02/17 01:25:51 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 38 (MapPartitionsRDD[130] at count at utils.scala:135) (first 15 tasks are for partitions Vector(0))
21/02/17 01:25:51 INFO TaskSchedulerImpl: Adding task set 38.0 with 1 tasks
21/02/17 01:25:51 INFO TaskSetManager: Starting task 0.0 in stage 38.0 (TID 40, localhost, executor driver, partition 0, PROCESS_LOCAL, 7550 bytes)
21/02/17 01:25:51 INFO Executor: Running task 0.0 in stage 38.0 (TID 40)
21/02/17 01:25:51 INFO Executor: Finished task 0.0 in stage 38.0 (TID 40). 1833 bytes result sent to driver
21/02/17 01:25:51 INFO TaskSetManager: Finished task 0.0 in stage 38.0 (TID 40) in 4 ms on localhost (executor driver) (1/1)
21/02/17 01:25:51 INFO TaskSchedulerImpl: Removed TaskSet 38.0, whose tasks have all completed, from pool 
21/02/17 01:25:51 INFO DAGScheduler: ShuffleMapStage 38 (count at utils.scala:135) finished in 0.008 s
21/02/17 01:25:51 INFO DAGScheduler: looking for newly runnable stages
21/02/17 01:25:51 INFO DAGScheduler: running: Set()
21/02/17 01:25:51 INFO DAGScheduler: waiting: Set(ResultStage 39)
21/02/17 01:25:51 INFO DAGScheduler: failed: Set()
21/02/17 01:25:51 INFO DAGScheduler: Submitting ResultStage 39 (MapPartitionsRDD[133] at count at utils.scala:135), which has no missing parents
21/02/17 01:25:51 INFO MemoryStore: Block broadcast_42 stored as values in memory (estimated size 10.1 KiB, free 911.2 MiB)
21/02/17 01:25:51 INFO MemoryStore: Block broadcast_42_piece0 stored as bytes in memory (estimated size 5.0 KiB, free 911.2 MiB)
21/02/17 01:25:51 INFO BlockManagerInfo: Added broadcast_42_piece0 in memory on localhost:41017 (size: 5.0 KiB, free: 912.1 MiB)
21/02/17 01:25:51 INFO BlockManagerInfo: Removed broadcast_40_piece0 on localhost:41017 in memory (size: 3.7 KiB, free: 912.1 MiB)
21/02/17 01:25:51 INFO SparkContext: Created broadcast 42 from broadcast at DAGScheduler.scala:1200
21/02/17 01:25:51 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 39 (MapPartitionsRDD[133] at count at utils.scala:135) (first 15 tasks are for partitions Vector(0))
21/02/17 01:25:51 INFO TaskSchedulerImpl: Adding task set 39.0 with 1 tasks
21/02/17 01:25:51 INFO BlockManagerInfo: Removed broadcast_31_piece0 on localhost:41017 in memory (size: 5.3 KiB, free: 912.1 MiB)
21/02/17 01:25:51 INFO TaskSetManager: Starting task 0.0 in stage 39.0 (TID 41, localhost, executor driver, partition 0, NODE_LOCAL, 7325 bytes)
21/02/17 01:25:51 INFO Executor: Running task 0.0 in stage 39.0 (TID 41)
21/02/17 01:25:51 INFO BlockManagerInfo: Removed broadcast_34_piece0 on localhost:41017 in memory (size: 10.1 KiB, free: 912.1 MiB)
21/02/17 01:25:51 INFO ShuffleBlockFetcherIterator: Getting 1 (60.0 B) non-empty blocks including 1 (60.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
21/02/17 01:25:51 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
21/02/17 01:25:51 INFO BlockManagerInfo: Removed broadcast_38_piece0 on localhost:41017 in memory (size: 9.9 KiB, free: 912.1 MiB)
21/02/17 01:25:51 INFO Executor: Finished task 0.0 in stage 39.0 (TID 41). 2648 bytes result sent to driver
21/02/17 01:25:51 INFO BlockManagerInfo: Removed broadcast_30_piece0 on localhost:41017 in memory (size: 6.8 KiB, free: 912.1 MiB)
21/02/17 01:25:51 INFO TaskSetManager: Finished task 0.0 in stage 39.0 (TID 41) in 6 ms on localhost (executor driver) (1/1)
21/02/17 01:25:51 INFO TaskSchedulerImpl: Removed TaskSet 39.0, whose tasks have all completed, from pool 
21/02/17 01:25:51 INFO DAGScheduler: ResultStage 39 (count at utils.scala:135) finished in 0.020 s
21/02/17 01:25:51 INFO DAGScheduler: Job 28 is finished. Cancelling potential speculative or zombie tasks for this job
21/02/17 01:25:51 INFO TaskSchedulerImpl: Killing all running tasks in stage 39: Stage finished
21/02/17 01:25:51 INFO DAGScheduler: Job 28 finished: count at utils.scala:135, took 0.030915 s
21/02/17 01:25:51 INFO BlockManagerInfo: Removed broadcast_36_piece0 on localhost:41017 in memory (size: 10.1 KiB, free: 912.1 MiB)
21/02/17 01:25:51 INFO BlockManagerInfo: Removed broadcast_35_piece0 on localhost:41017 in memory (size: 5.0 KiB, free: 912.2 MiB)
21/02/17 01:25:51 INFO BlockManagerInfo: Removed broadcast_32_piece0 on localhost:41017 in memory (size: 5.0 KiB, free: 912.2 MiB)
21/02/17 01:25:51 INFO BlockManagerInfo: Removed broadcast_39_piece0 on localhost:41017 in memory (size: 5.3 KiB, free: 912.2 MiB)
21/02/17 01:25:51 INFO BlockManagerInfo: Removed broadcast_29_piece0 on localhost:41017 in memory (size: 28.3 KiB, free: 912.2 MiB)
21/02/17 01:25:51 INFO BlockManagerInfo: Removed broadcast_37_piece0 on localhost:41017 in memory (size: 5.0 KiB, free: 912.2 MiB)
21/02/17 01:25:51 INFO SparkContext: Starting job: collect at utils.scala:137
21/02/17 01:25:51 INFO DAGScheduler: Got job 29 (collect at utils.scala:137) with 1 output partitions
21/02/17 01:25:51 INFO DAGScheduler: Final stage: ResultStage 40 (collect at utils.scala:137)
21/02/17 01:25:51 INFO DAGScheduler: Parents of final stage: List()
21/02/17 01:25:51 INFO DAGScheduler: Missing parents: List()
21/02/17 01:25:51 INFO DAGScheduler: Submitting ResultStage 40 (MapPartitionsRDD[136] at collect at utils.scala:137), which has no missing parents
21/02/17 01:25:51 INFO MemoryStore: Block broadcast_43 stored as values in memory (estimated size 16.7 KiB, free 911.7 MiB)
21/02/17 01:25:51 INFO MemoryStore: Block broadcast_43_piece0 stored as bytes in memory (estimated size 8.0 KiB, free 911.7 MiB)
21/02/17 01:25:51 INFO BlockManagerInfo: Added broadcast_43_piece0 in memory on localhost:41017 (size: 8.0 KiB, free: 912.2 MiB)
21/02/17 01:25:51 INFO SparkContext: Created broadcast 43 from broadcast at DAGScheduler.scala:1200
21/02/17 01:25:51 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 40 (MapPartitionsRDD[136] at collect at utils.scala:137) (first 15 tasks are for partitions Vector(0))
21/02/17 01:25:51 INFO TaskSchedulerImpl: Adding task set 40.0 with 1 tasks
21/02/17 01:25:51 INFO TaskSetManager: Starting task 0.0 in stage 40.0 (TID 42, localhost, executor driver, partition 0, PROCESS_LOCAL, 7757 bytes)
21/02/17 01:25:51 INFO Executor: Running task 0.0 in stage 40.0 (TID 42)
21/02/17 01:25:51 INFO BlockManager: Found block rdd_105_0 locally
21/02/17 01:25:51 INFO CodeGenerator: Code generated in 8.735025 ms
21/02/17 01:25:51 INFO Executor: Finished task 0.0 in stage 40.0 (TID 42). 1606 bytes result sent to driver
21/02/17 01:25:51 INFO TaskSetManager: Finished task 0.0 in stage 40.0 (TID 42) in 15 ms on localhost (executor driver) (1/1)
21/02/17 01:25:51 INFO TaskSchedulerImpl: Removed TaskSet 40.0, whose tasks have all completed, from pool 
21/02/17 01:25:51 INFO DAGScheduler: ResultStage 40 (collect at utils.scala:137) finished in 0.020 s
21/02/17 01:25:51 INFO DAGScheduler: Job 29 is finished. Cancelling potential speculative or zombie tasks for this job
21/02/17 01:25:51 INFO TaskSchedulerImpl: Killing all running tasks in stage 40: Stage finished
21/02/17 01:25:51 INFO DAGScheduler: Job 29 finished: collect at utils.scala:137, took 0.021604 s
21/02/17 01:25:51 INFO CodeGenerator: Code generated in 6.476836 ms
21/02/17 01:25:51 INFO SparkContext: Starting job: count at utils.scala:135
21/02/17 01:25:51 INFO DAGScheduler: Registering RDD 140 (count at utils.scala:135) as input to shuffle 12
21/02/17 01:25:51 INFO DAGScheduler: Got job 30 (count at utils.scala:135) with 1 output partitions
21/02/17 01:25:51 INFO DAGScheduler: Final stage: ResultStage 42 (count at utils.scala:135)
21/02/17 01:25:51 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 41)
21/02/17 01:25:51 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 41)
21/02/17 01:25:51 INFO DAGScheduler: Submitting ShuffleMapStage 41 (MapPartitionsRDD[140] at count at utils.scala:135), which has no missing parents
21/02/17 01:25:51 INFO MemoryStore: Block broadcast_44 stored as values in memory (estimated size 21.5 KiB, free 911.7 MiB)
21/02/17 01:25:51 INFO MemoryStore: Block broadcast_44_piece0 stored as bytes in memory (estimated size 10.1 KiB, free 911.6 MiB)
21/02/17 01:25:51 INFO BlockManagerInfo: Added broadcast_44_piece0 in memory on localhost:41017 (size: 10.1 KiB, free: 912.2 MiB)
21/02/17 01:25:51 INFO SparkContext: Created broadcast 44 from broadcast at DAGScheduler.scala:1200
21/02/17 01:25:51 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 41 (MapPartitionsRDD[140] at count at utils.scala:135) (first 15 tasks are for partitions Vector(0))
21/02/17 01:25:51 INFO TaskSchedulerImpl: Adding task set 41.0 with 1 tasks
21/02/17 01:25:51 INFO TaskSetManager: Starting task 0.0 in stage 41.0 (TID 43, localhost, executor driver, partition 0, PROCESS_LOCAL, 7746 bytes)
21/02/17 01:25:51 INFO Executor: Running task 0.0 in stage 41.0 (TID 43)
21/02/17 01:25:51 INFO BlockManager: Found block rdd_105_0 locally
21/02/17 01:25:51 INFO Executor: Finished task 0.0 in stage 41.0 (TID 43). 2067 bytes result sent to driver
21/02/17 01:25:51 INFO TaskSetManager: Finished task 0.0 in stage 41.0 (TID 43) in 7 ms on localhost (executor driver) (1/1)
21/02/17 01:25:51 INFO TaskSchedulerImpl: Removed TaskSet 41.0, whose tasks have all completed, from pool 
21/02/17 01:25:51 INFO DAGScheduler: ShuffleMapStage 41 (count at utils.scala:135) finished in 0.012 s
21/02/17 01:25:51 INFO DAGScheduler: looking for newly runnable stages
21/02/17 01:25:51 INFO DAGScheduler: running: Set()
21/02/17 01:25:51 INFO DAGScheduler: waiting: Set(ResultStage 42)
21/02/17 01:25:51 INFO DAGScheduler: failed: Set()
21/02/17 01:25:51 INFO DAGScheduler: Submitting ResultStage 42 (MapPartitionsRDD[143] at count at utils.scala:135), which has no missing parents
21/02/17 01:25:51 INFO MemoryStore: Block broadcast_45 stored as values in memory (estimated size 10.1 KiB, free 911.6 MiB)
21/02/17 01:25:51 INFO MemoryStore: Block broadcast_45_piece0 stored as bytes in memory (estimated size 5.0 KiB, free 911.6 MiB)
21/02/17 01:25:51 INFO BlockManagerInfo: Added broadcast_45_piece0 in memory on localhost:41017 (size: 5.0 KiB, free: 912.2 MiB)
21/02/17 01:25:51 INFO SparkContext: Created broadcast 45 from broadcast at DAGScheduler.scala:1200
21/02/17 01:25:51 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 42 (MapPartitionsRDD[143] at count at utils.scala:135) (first 15 tasks are for partitions Vector(0))
21/02/17 01:25:51 INFO TaskSchedulerImpl: Adding task set 42.0 with 1 tasks
21/02/17 01:25:51 INFO TaskSetManager: Starting task 0.0 in stage 42.0 (TID 44, localhost, executor driver, partition 0, NODE_LOCAL, 7325 bytes)
21/02/17 01:25:51 INFO Executor: Running task 0.0 in stage 42.0 (TID 44)
21/02/17 01:25:51 INFO ShuffleBlockFetcherIterator: Getting 1 (60.0 B) non-empty blocks including 1 (60.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
21/02/17 01:25:51 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
21/02/17 01:25:51 INFO Executor: Finished task 0.0 in stage 42.0 (TID 44). 2648 bytes result sent to driver
21/02/17 01:25:51 INFO TaskSetManager: Finished task 0.0 in stage 42.0 (TID 44) in 3 ms on localhost (executor driver) (1/1)
21/02/17 01:25:51 INFO TaskSchedulerImpl: Removed TaskSet 42.0, whose tasks have all completed, from pool 
21/02/17 01:25:51 INFO DAGScheduler: ResultStage 42 (count at utils.scala:135) finished in 0.007 s
21/02/17 01:25:51 INFO DAGScheduler: Job 30 is finished. Cancelling potential speculative or zombie tasks for this job
21/02/17 01:25:51 INFO TaskSchedulerImpl: Killing all running tasks in stage 42: Stage finished
21/02/17 01:25:51 INFO DAGScheduler: Job 30 finished: count at utils.scala:135, took 0.022785 s
21/02/17 01:25:51 INFO MapPartitionsRDD: Removing RDD 105 from persistence list
21/02/17 01:25:51 INFO BlockManager: Removing RDD 105
21/02/17 01:25:51 INFO MemoryStore: Block broadcast_46 stored as values in memory (estimated size 294.6 KiB, free 911.3 MiB)
21/02/17 01:25:51 INFO MemoryStore: Block broadcast_46_piece0 stored as bytes in memory (estimated size 27.2 KiB, free 911.3 MiB)
21/02/17 01:25:51 INFO BlockManagerInfo: Added broadcast_46_piece0 in memory on localhost:41017 (size: 27.2 KiB, free: 912.1 MiB)
21/02/17 01:25:51 INFO SparkContext: Created broadcast 46 from textFile at ReadWrite.scala:587
21/02/17 01:25:51 INFO FileInputFormat: Total input files to process : 1
21/02/17 01:25:51 INFO SparkContext: Starting job: first at ReadWrite.scala:587
21/02/17 01:25:51 INFO DAGScheduler: Got job 31 (first at ReadWrite.scala:587) with 1 output partitions
21/02/17 01:25:51 INFO DAGScheduler: Final stage: ResultStage 43 (first at ReadWrite.scala:587)
21/02/17 01:25:51 INFO DAGScheduler: Parents of final stage: List()
21/02/17 01:25:51 INFO DAGScheduler: Missing parents: List()
21/02/17 01:25:51 INFO DAGScheduler: Submitting ResultStage 43 (/tmp/RtmpLTlh4o/file2171a4eb3a620/metadata MapPartitionsRDD[145] at textFile at ReadWrite.scala:587), which has no missing parents
21/02/17 01:25:51 INFO MemoryStore: Block broadcast_47 stored as values in memory (estimated size 4.1 KiB, free 911.3 MiB)
21/02/17 01:25:51 INFO MemoryStore: Block broadcast_47_piece0 stored as bytes in memory (estimated size 2.4 KiB, free 911.3 MiB)
21/02/17 01:25:51 INFO BlockManagerInfo: Added broadcast_47_piece0 in memory on localhost:41017 (size: 2.4 KiB, free: 912.1 MiB)
21/02/17 01:25:51 INFO SparkContext: Created broadcast 47 from broadcast at DAGScheduler.scala:1200
21/02/17 01:25:51 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 43 (/tmp/RtmpLTlh4o/file2171a4eb3a620/metadata MapPartitionsRDD[145] at textFile at ReadWrite.scala:587) (first 15 tasks are for partitions Vector(0))
21/02/17 01:25:51 INFO TaskSchedulerImpl: Adding task set 43.0 with 1 tasks
21/02/17 01:25:51 INFO TaskSetManager: Starting task 0.0 in stage 43.0 (TID 45, localhost, executor driver, partition 0, PROCESS_LOCAL, 7399 bytes)
21/02/17 01:25:51 INFO Executor: Running task 0.0 in stage 43.0 (TID 45)
21/02/17 01:25:51 INFO HadoopRDD: Input split: file:/tmp/RtmpLTlh4o/file2171a4eb3a620/metadata/part-00000:0+306
21/02/17 01:25:51 INFO Executor: Finished task 0.0 in stage 43.0 (TID 45). 1234 bytes result sent to driver
21/02/17 01:25:51 INFO TaskSetManager: Finished task 0.0 in stage 43.0 (TID 45) in 20 ms on localhost (executor driver) (1/1)
21/02/17 01:25:51 INFO TaskSchedulerImpl: Removed TaskSet 43.0, whose tasks have all completed, from pool 
21/02/17 01:25:51 INFO DAGScheduler: ResultStage 43 (first at ReadWrite.scala:587) finished in 0.023 s
21/02/17 01:25:51 INFO DAGScheduler: Job 31 is finished. Cancelling potential speculative or zombie tasks for this job
21/02/17 01:25:51 INFO TaskSchedulerImpl: Killing all running tasks in stage 43: Stage finished
21/02/17 01:25:51 INFO DAGScheduler: Job 31 finished: first at ReadWrite.scala:587, took 0.026284 s
21/02/17 01:25:51 INFO MemoryStore: Block broadcast_48 stored as values in memory (estimated size 294.6 KiB, free 911.0 MiB)
21/02/17 01:25:51 INFO MemoryStore: Block broadcast_48_piece0 stored as bytes in memory (estimated size 27.2 KiB, free 911.0 MiB)
21/02/17 01:25:51 INFO BlockManagerInfo: Added broadcast_48_piece0 in memory on localhost:41017 (size: 27.2 KiB, free: 912.1 MiB)
21/02/17 01:25:51 INFO SparkContext: Created broadcast 48 from textFile at ReadWrite.scala:587
21/02/17 01:25:51 INFO FileInputFormat: Total input files to process : 1
21/02/17 01:25:51 INFO SparkContext: Starting job: first at ReadWrite.scala:587
21/02/17 01:25:51 INFO DAGScheduler: Got job 32 (first at ReadWrite.scala:587) with 1 output partitions
21/02/17 01:25:51 INFO DAGScheduler: Final stage: ResultStage 44 (first at ReadWrite.scala:587)
21/02/17 01:25:51 INFO DAGScheduler: Parents of final stage: List()
21/02/17 01:25:51 INFO DAGScheduler: Missing parents: List()
21/02/17 01:25:51 INFO DAGScheduler: Submitting ResultStage 44 (/tmp/RtmpLTlh4o/file2171a4eb3a620/stages/0_r_formula__8e049f4c_a0ea_471a_862c_cafd520f5953/metadata MapPartitionsRDD[147] at textFile at ReadWrite.scala:587), which has no missing parents
21/02/17 01:25:51 INFO MemoryStore: Block broadcast_49 stored as values in memory (estimated size 4.2 KiB, free 911.0 MiB)
21/02/17 01:25:51 INFO MemoryStore: Block broadcast_49_piece0 stored as bytes in memory (estimated size 2.5 KiB, free 911.0 MiB)
21/02/17 01:25:51 INFO BlockManagerInfo: Added broadcast_49_piece0 in memory on localhost:41017 (size: 2.5 KiB, free: 912.1 MiB)
21/02/17 01:25:51 INFO SparkContext: Created broadcast 49 from broadcast at DAGScheduler.scala:1200
21/02/17 01:25:51 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 44 (/tmp/RtmpLTlh4o/file2171a4eb3a620/stages/0_r_formula__8e049f4c_a0ea_471a_862c_cafd520f5953/metadata MapPartitionsRDD[147] at textFile at ReadWrite.scala:587) (first 15 tasks are for partitions Vector(0))
21/02/17 01:25:51 INFO TaskSchedulerImpl: Adding task set 44.0 with 1 tasks
21/02/17 01:25:51 INFO TaskSetManager: Starting task 0.0 in stage 44.0 (TID 46, localhost, executor driver, partition 0, PROCESS_LOCAL, 7456 bytes)
21/02/17 01:25:51 INFO Executor: Running task 0.0 in stage 44.0 (TID 46)
21/02/17 01:25:51 INFO HadoopRDD: Input split: file:/tmp/RtmpLTlh4o/file2171a4eb3a620/stages/0_r_formula__8e049f4c_a0ea_471a_862c_cafd520f5953/metadata/part-00000:0+447
21/02/17 01:25:51 INFO Executor: Finished task 0.0 in stage 44.0 (TID 46). 1375 bytes result sent to driver
21/02/17 01:25:51 INFO TaskSetManager: Finished task 0.0 in stage 44.0 (TID 46) in 3 ms on localhost (executor driver) (1/1)
21/02/17 01:25:51 INFO TaskSchedulerImpl: Removed TaskSet 44.0, whose tasks have all completed, from pool 
21/02/17 01:25:51 INFO DAGScheduler: ResultStage 44 (first at ReadWrite.scala:587) finished in 0.007 s
21/02/17 01:25:51 INFO DAGScheduler: Job 32 is finished. Cancelling potential speculative or zombie tasks for this job
21/02/17 01:25:51 INFO TaskSchedulerImpl: Killing all running tasks in stage 44: Stage finished
21/02/17 01:25:51 INFO DAGScheduler: Job 32 finished: first at ReadWrite.scala:587, took 0.008535 s
21/02/17 01:25:51 INFO MemoryStore: Block broadcast_50 stored as values in memory (estimated size 294.6 KiB, free 910.7 MiB)
21/02/17 01:25:51 INFO MemoryStore: Block broadcast_50_piece0 stored as bytes in memory (estimated size 27.2 KiB, free 910.7 MiB)
21/02/17 01:25:51 INFO BlockManagerInfo: Added broadcast_50_piece0 in memory on localhost:41017 (size: 27.2 KiB, free: 912.1 MiB)
21/02/17 01:25:51 INFO SparkContext: Created broadcast 50 from textFile at ReadWrite.scala:587
21/02/17 01:25:51 INFO FileInputFormat: Total input files to process : 1
21/02/17 01:25:51 INFO SparkContext: Starting job: first at ReadWrite.scala:587
21/02/17 01:25:51 INFO DAGScheduler: Got job 33 (first at ReadWrite.scala:587) with 1 output partitions
21/02/17 01:25:51 INFO DAGScheduler: Final stage: ResultStage 45 (first at ReadWrite.scala:587)
21/02/17 01:25:51 INFO DAGScheduler: Parents of final stage: List()
21/02/17 01:25:51 INFO DAGScheduler: Missing parents: List()
21/02/17 01:25:51 INFO DAGScheduler: Submitting ResultStage 45 (/tmp/RtmpLTlh4o/file2171a4eb3a620/stages/0_r_formula__8e049f4c_a0ea_471a_862c_cafd520f5953/metadata MapPartitionsRDD[149] at textFile at ReadWrite.scala:587), which has no missing parents
21/02/17 01:25:51 INFO MemoryStore: Block broadcast_51 stored as values in memory (estimated size 4.2 KiB, free 910.7 MiB)
21/02/17 01:25:51 INFO MemoryStore: Block broadcast_51_piece0 stored as bytes in memory (estimated size 2.5 KiB, free 910.7 MiB)
21/02/17 01:25:51 INFO BlockManagerInfo: Added broadcast_51_piece0 in memory on localhost:41017 (size: 2.5 KiB, free: 912.1 MiB)
21/02/17 01:25:51 INFO SparkContext: Created broadcast 51 from broadcast at DAGScheduler.scala:1200
21/02/17 01:25:51 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 45 (/tmp/RtmpLTlh4o/file2171a4eb3a620/stages/0_r_formula__8e049f4c_a0ea_471a_862c_cafd520f5953/metadata MapPartitionsRDD[149] at textFile at ReadWrite.scala:587) (first 15 tasks are for partitions Vector(0))
21/02/17 01:25:51 INFO TaskSchedulerImpl: Adding task set 45.0 with 1 tasks
21/02/17 01:25:51 INFO TaskSetManager: Starting task 0.0 in stage 45.0 (TID 47, localhost, executor driver, partition 0, PROCESS_LOCAL, 7456 bytes)
21/02/17 01:25:51 INFO Executor: Running task 0.0 in stage 45.0 (TID 47)
21/02/17 01:25:51 INFO HadoopRDD: Input split: file:/tmp/RtmpLTlh4o/file2171a4eb3a620/stages/0_r_formula__8e049f4c_a0ea_471a_862c_cafd520f5953/metadata/part-00000:0+447
21/02/17 01:25:51 INFO Executor: Finished task 0.0 in stage 45.0 (TID 47). 1375 bytes result sent to driver
21/02/17 01:25:51 INFO TaskSetManager: Finished task 0.0 in stage 45.0 (TID 47) in 4 ms on localhost (executor driver) (1/1)
21/02/17 01:25:51 INFO TaskSchedulerImpl: Removed TaskSet 45.0, whose tasks have all completed, from pool 
21/02/17 01:25:51 INFO DAGScheduler: ResultStage 45 (first at ReadWrite.scala:587) finished in 0.008 s
21/02/17 01:25:51 INFO DAGScheduler: Job 33 is finished. Cancelling potential speculative or zombie tasks for this job
21/02/17 01:25:51 INFO TaskSchedulerImpl: Killing all running tasks in stage 45: Stage finished
21/02/17 01:25:51 INFO DAGScheduler: Job 33 finished: first at ReadWrite.scala:587, took 0.009579 s
21/02/17 01:25:51 INFO InMemoryFileIndex: It took 1 ms to list leaf files for 1 paths.
21/02/17 01:25:51 INFO SparkContext: Starting job: parquet at RFormula.scala:450
21/02/17 01:25:51 INFO DAGScheduler: Got job 34 (parquet at RFormula.scala:450) with 1 output partitions
21/02/17 01:25:51 INFO DAGScheduler: Final stage: ResultStage 46 (parquet at RFormula.scala:450)
21/02/17 01:25:51 INFO DAGScheduler: Parents of final stage: List()
21/02/17 01:25:51 INFO DAGScheduler: Missing parents: List()
21/02/17 01:25:51 INFO DAGScheduler: Submitting ResultStage 46 (MapPartitionsRDD[151] at parquet at RFormula.scala:450), which has no missing parents
21/02/17 01:25:51 INFO MemoryStore: Block broadcast_52 stored as values in memory (estimated size 86.6 KiB, free 910.6 MiB)
21/02/17 01:25:51 INFO MemoryStore: Block broadcast_52_piece0 stored as bytes in memory (estimated size 30.8 KiB, free 910.6 MiB)
21/02/17 01:25:51 INFO BlockManagerInfo: Added broadcast_52_piece0 in memory on localhost:41017 (size: 30.8 KiB, free: 912.1 MiB)
21/02/17 01:25:51 INFO SparkContext: Created broadcast 52 from broadcast at DAGScheduler.scala:1200
21/02/17 01:25:51 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 46 (MapPartitionsRDD[151] at parquet at RFormula.scala:450) (first 15 tasks are for partitions Vector(0))
21/02/17 01:25:51 INFO TaskSchedulerImpl: Adding task set 46.0 with 1 tasks
21/02/17 01:25:51 INFO TaskSetManager: Starting task 0.0 in stage 46.0 (TID 48, localhost, executor driver, partition 0, PROCESS_LOCAL, 7616 bytes)
21/02/17 01:25:51 INFO Executor: Running task 0.0 in stage 46.0 (TID 48)
21/02/17 01:25:51 INFO Executor: Finished task 0.0 in stage 46.0 (TID 48). 1835 bytes result sent to driver
21/02/17 01:25:51 INFO TaskSetManager: Finished task 0.0 in stage 46.0 (TID 48) in 34 ms on localhost (executor driver) (1/1)
21/02/17 01:25:51 INFO TaskSchedulerImpl: Removed TaskSet 46.0, whose tasks have all completed, from pool 
21/02/17 01:25:51 INFO DAGScheduler: ResultStage 46 (parquet at RFormula.scala:450) finished in 0.046 s
21/02/17 01:25:51 INFO DAGScheduler: Job 34 is finished. Cancelling potential speculative or zombie tasks for this job
21/02/17 01:25:51 INFO TaskSchedulerImpl: Killing all running tasks in stage 46: Stage finished
21/02/17 01:25:51 INFO DAGScheduler: Job 34 finished: parquet at RFormula.scala:450, took 0.048245 s
21/02/17 01:25:51 INFO FileSourceStrategy: Pruning directories with: 
21/02/17 01:25:51 INFO FileSourceStrategy: Pushed Filters: 
21/02/17 01:25:51 INFO FileSourceStrategy: Post-Scan Filters: 
21/02/17 01:25:51 INFO FileSourceStrategy: Output Data Schema: struct<label: string, terms: array<array<string>>, hasIntercept: boolean ... 1 more fields>
21/02/17 01:25:51 INFO MemoryStore: Block broadcast_53 stored as values in memory (estimated size 319.0 KiB, free 910.2 MiB)
21/02/17 01:25:51 INFO MemoryStore: Block broadcast_53_piece0 stored as bytes in memory (estimated size 29.0 KiB, free 910.2 MiB)
21/02/17 01:25:51 INFO BlockManagerInfo: Added broadcast_53_piece0 in memory on localhost:41017 (size: 29.0 KiB, free: 912.0 MiB)
21/02/17 01:25:51 INFO SparkContext: Created broadcast 53 from head at RFormula.scala:450
21/02/17 01:25:51 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
21/02/17 01:25:51 INFO SparkContext: Starting job: head at RFormula.scala:450
21/02/17 01:25:51 INFO DAGScheduler: Got job 35 (head at RFormula.scala:450) with 1 output partitions
21/02/17 01:25:51 INFO DAGScheduler: Final stage: ResultStage 47 (head at RFormula.scala:450)
21/02/17 01:25:51 INFO DAGScheduler: Parents of final stage: List()
21/02/17 01:25:51 INFO DAGScheduler: Missing parents: List()
21/02/17 01:25:51 INFO DAGScheduler: Submitting ResultStage 47 (MapPartitionsRDD[154] at head at RFormula.scala:450), which has no missing parents
21/02/17 01:25:51 INFO MemoryStore: Block broadcast_54 stored as values in memory (estimated size 9.1 KiB, free 910.2 MiB)
21/02/17 01:25:51 INFO MemoryStore: Block broadcast_54_piece0 stored as bytes in memory (estimated size 4.9 KiB, free 910.2 MiB)
21/02/17 01:25:51 INFO BlockManagerInfo: Added broadcast_54_piece0 in memory on localhost:41017 (size: 4.9 KiB, free: 912.0 MiB)
21/02/17 01:25:51 INFO SparkContext: Created broadcast 54 from broadcast at DAGScheduler.scala:1200
21/02/17 01:25:51 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 47 (MapPartitionsRDD[154] at head at RFormula.scala:450) (first 15 tasks are for partitions Vector(0))
21/02/17 01:25:51 INFO TaskSchedulerImpl: Adding task set 47.0 with 1 tasks
21/02/17 01:25:51 INFO TaskSetManager: Starting task 0.0 in stage 47.0 (TID 49, localhost, executor driver, partition 0, PROCESS_LOCAL, 7867 bytes)
21/02/17 01:25:51 INFO Executor: Running task 0.0 in stage 47.0 (TID 49)
21/02/17 01:25:51 INFO CodeGenerator: Code generated in 8.980131 ms
21/02/17 01:25:51 INFO FileScanRDD: Reading File path: file:///tmp/RtmpLTlh4o/file2171a4eb3a620/stages/0_r_formula__8e049f4c_a0ea_471a_862c_cafd520f5953/data/part-00000-03cb630e-4826-41d4-807f-56a345a6b89f-c000.snappy.parquet, range: 0-1140, partition values: [empty row]
21/02/17 01:25:51 INFO CodecPool: Got brand-new decompressor [.snappy]
21/02/17 01:25:52 INFO Executor: Finished task 0.0 in stage 47.0 (TID 49). 1790 bytes result sent to driver
21/02/17 01:25:52 INFO TaskSetManager: Finished task 0.0 in stage 47.0 (TID 49) in 93 ms on localhost (executor driver) (1/1)
21/02/17 01:25:52 INFO TaskSchedulerImpl: Removed TaskSet 47.0, whose tasks have all completed, from pool 
21/02/17 01:25:52 INFO DAGScheduler: ResultStage 47 (head at RFormula.scala:450) finished in 0.101 s
21/02/17 01:25:52 INFO DAGScheduler: Job 35 is finished. Cancelling potential speculative or zombie tasks for this job
21/02/17 01:25:52 INFO TaskSchedulerImpl: Killing all running tasks in stage 47: Stage finished
21/02/17 01:25:52 INFO DAGScheduler: Job 35 finished: head at RFormula.scala:450, took 0.103807 s
21/02/17 01:25:52 INFO CodeGenerator: Code generated in 14.839663 ms
21/02/17 01:25:52 INFO MemoryStore: Block broadcast_55 stored as values in memory (estimated size 294.6 KiB, free 909.9 MiB)
21/02/17 01:25:52 INFO MemoryStore: Block broadcast_55_piece0 stored as bytes in memory (estimated size 27.2 KiB, free 909.9 MiB)
21/02/17 01:25:52 INFO BlockManagerInfo: Added broadcast_55_piece0 in memory on localhost:41017 (size: 27.2 KiB, free: 912.0 MiB)
21/02/17 01:25:52 INFO SparkContext: Created broadcast 55 from textFile at ReadWrite.scala:587
21/02/17 01:25:52 INFO FileInputFormat: Total input files to process : 1
21/02/17 01:25:52 INFO SparkContext: Starting job: first at ReadWrite.scala:587
21/02/17 01:25:52 INFO DAGScheduler: Got job 36 (first at ReadWrite.scala:587) with 1 output partitions
21/02/17 01:25:52 INFO DAGScheduler: Final stage: ResultStage 48 (first at ReadWrite.scala:587)
21/02/17 01:25:52 INFO DAGScheduler: Parents of final stage: List()
21/02/17 01:25:52 INFO DAGScheduler: Missing parents: List()
21/02/17 01:25:52 INFO DAGScheduler: Submitting ResultStage 48 (/tmp/RtmpLTlh4o/file2171a4eb3a620/stages/0_r_formula__8e049f4c_a0ea_471a_862c_cafd520f5953/pipelineModel/metadata MapPartitionsRDD[156] at textFile at ReadWrite.scala:587), which has no missing parents
21/02/17 01:25:52 INFO MemoryStore: Block broadcast_56 stored as values in memory (estimated size 4.2 KiB, free 909.9 MiB)
21/02/17 01:25:52 INFO MemoryStore: Block broadcast_56_piece0 stored as bytes in memory (estimated size 2.5 KiB, free 909.9 MiB)
21/02/17 01:25:52 INFO BlockManagerInfo: Added broadcast_56_piece0 in memory on localhost:41017 (size: 2.5 KiB, free: 912.0 MiB)
21/02/17 01:25:52 INFO SparkContext: Created broadcast 56 from broadcast at DAGScheduler.scala:1200
21/02/17 01:25:52 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 48 (/tmp/RtmpLTlh4o/file2171a4eb3a620/stages/0_r_formula__8e049f4c_a0ea_471a_862c_cafd520f5953/pipelineModel/metadata MapPartitionsRDD[156] at textFile at ReadWrite.scala:587) (first 15 tasks are for partitions Vector(0))
21/02/17 01:25:52 INFO TaskSchedulerImpl: Adding task set 48.0 with 1 tasks
21/02/17 01:25:52 INFO TaskSetManager: Starting task 0.0 in stage 48.0 (TID 50, localhost, executor driver, partition 0, PROCESS_LOCAL, 7471 bytes)
21/02/17 01:25:52 INFO Executor: Running task 0.0 in stage 48.0 (TID 50)
21/02/17 01:25:52 INFO HadoopRDD: Input split: file:/tmp/RtmpLTlh4o/file2171a4eb3a620/stages/0_r_formula__8e049f4c_a0ea_471a_862c_cafd520f5953/pipelineModel/metadata/part-00000:0+311
21/02/17 01:25:52 INFO Executor: Finished task 0.0 in stage 48.0 (TID 50). 1196 bytes result sent to driver
21/02/17 01:25:52 INFO TaskSetManager: Finished task 0.0 in stage 48.0 (TID 50) in 4 ms on localhost (executor driver) (1/1)
21/02/17 01:25:52 INFO TaskSchedulerImpl: Removed TaskSet 48.0, whose tasks have all completed, from pool 
21/02/17 01:25:52 INFO DAGScheduler: ResultStage 48 (first at ReadWrite.scala:587) finished in 0.007 s
21/02/17 01:25:52 INFO DAGScheduler: Job 36 is finished. Cancelling potential speculative or zombie tasks for this job
21/02/17 01:25:52 INFO TaskSchedulerImpl: Killing all running tasks in stage 48: Stage finished
21/02/17 01:25:52 INFO DAGScheduler: Job 36 finished: first at ReadWrite.scala:587, took 0.008659 s
21/02/17 01:25:52 INFO MemoryStore: Block broadcast_57 stored as values in memory (estimated size 294.6 KiB, free 909.6 MiB)
21/02/17 01:25:52 INFO MemoryStore: Block broadcast_57_piece0 stored as bytes in memory (estimated size 27.2 KiB, free 909.6 MiB)
21/02/17 01:25:52 INFO BlockManagerInfo: Added broadcast_57_piece0 in memory on localhost:41017 (size: 27.2 KiB, free: 912.0 MiB)
21/02/17 01:25:52 INFO SparkContext: Created broadcast 57 from textFile at ReadWrite.scala:587
21/02/17 01:25:52 INFO FileInputFormat: Total input files to process : 1
21/02/17 01:25:52 INFO SparkContext: Starting job: first at ReadWrite.scala:587
21/02/17 01:25:52 INFO DAGScheduler: Got job 37 (first at ReadWrite.scala:587) with 1 output partitions
21/02/17 01:25:52 INFO DAGScheduler: Final stage: ResultStage 49 (first at ReadWrite.scala:587)
21/02/17 01:25:52 INFO DAGScheduler: Parents of final stage: List()
21/02/17 01:25:52 INFO DAGScheduler: Missing parents: List()
21/02/17 01:25:52 INFO DAGScheduler: Submitting ResultStage 49 (/tmp/RtmpLTlh4o/file2171a4eb3a620/stages/0_r_formula__8e049f4c_a0ea_471a_862c_cafd520f5953/pipelineModel/stages/0_r_formula__8e049f4c_a0ea_471a_862c_cafd520f5953/metadata MapPartitionsRDD[158] at textFile at ReadWrite.scala:587), which has no missing parents
21/02/17 01:25:52 INFO MemoryStore: Block broadcast_58 stored as values in memory (estimated size 4.3 KiB, free 909.6 MiB)
21/02/17 01:25:52 INFO MemoryStore: Block broadcast_58_piece0 stored as bytes in memory (estimated size 2.5 KiB, free 909.6 MiB)
21/02/17 01:25:52 INFO BlockManagerInfo: Added broadcast_58_piece0 in memory on localhost:41017 (size: 2.5 KiB, free: 912.0 MiB)
21/02/17 01:25:52 INFO SparkContext: Created broadcast 58 from broadcast at DAGScheduler.scala:1200
21/02/17 01:25:52 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 49 (/tmp/RtmpLTlh4o/file2171a4eb3a620/stages/0_r_formula__8e049f4c_a0ea_471a_862c_cafd520f5953/pipelineModel/stages/0_r_formula__8e049f4c_a0ea_471a_862c_cafd520f5953/metadata MapPartitionsRDD[158] at textFile at ReadWrite.scala:587) (first 15 tasks are for partitions Vector(0))
21/02/17 01:25:52 INFO TaskSchedulerImpl: Adding task set 49.0 with 1 tasks
21/02/17 01:25:52 INFO TaskSetManager: Starting task 0.0 in stage 49.0 (TID 51, localhost, executor driver, partition 0, PROCESS_LOCAL, 7531 bytes)
21/02/17 01:25:52 INFO Executor: Running task 0.0 in stage 49.0 (TID 51)
21/02/17 01:25:52 INFO HadoopRDD: Input split: file:/tmp/RtmpLTlh4o/file2171a4eb3a620/stages/0_r_formula__8e049f4c_a0ea_471a_862c_cafd520f5953/pipelineModel/stages/0_r_formula__8e049f4c_a0ea_471a_862c_cafd520f5953/metadata/part-00000:0+378
21/02/17 01:25:52 INFO Executor: Finished task 0.0 in stage 49.0 (TID 51). 1306 bytes result sent to driver
21/02/17 01:25:52 INFO TaskSetManager: Finished task 0.0 in stage 49.0 (TID 51) in 4 ms on localhost (executor driver) (1/1)
21/02/17 01:25:52 INFO TaskSchedulerImpl: Removed TaskSet 49.0, whose tasks have all completed, from pool 
21/02/17 01:25:52 INFO DAGScheduler: ResultStage 49 (first at ReadWrite.scala:587) finished in 0.007 s
21/02/17 01:25:52 INFO DAGScheduler: Job 37 is finished. Cancelling potential speculative or zombie tasks for this job
21/02/17 01:25:52 INFO TaskSchedulerImpl: Killing all running tasks in stage 49: Stage finished
21/02/17 01:25:52 INFO DAGScheduler: Job 37 finished: first at ReadWrite.scala:587, took 0.008392 s
21/02/17 01:25:52 INFO MemoryStore: Block broadcast_59 stored as values in memory (estimated size 294.6 KiB, free 909.3 MiB)
21/02/17 01:25:52 INFO MemoryStore: Block broadcast_59_piece0 stored as bytes in memory (estimated size 27.2 KiB, free 909.2 MiB)
21/02/17 01:25:52 INFO BlockManagerInfo: Added broadcast_59_piece0 in memory on localhost:41017 (size: 27.2 KiB, free: 911.9 MiB)
21/02/17 01:25:52 INFO SparkContext: Created broadcast 59 from textFile at ReadWrite.scala:587
21/02/17 01:25:52 INFO FileInputFormat: Total input files to process : 1
21/02/17 01:25:52 INFO SparkContext: Starting job: first at ReadWrite.scala:587
21/02/17 01:25:52 INFO DAGScheduler: Got job 38 (first at ReadWrite.scala:587) with 1 output partitions
21/02/17 01:25:52 INFO DAGScheduler: Final stage: ResultStage 50 (first at ReadWrite.scala:587)
21/02/17 01:25:52 INFO DAGScheduler: Parents of final stage: List()
21/02/17 01:25:52 INFO DAGScheduler: Missing parents: List()
21/02/17 01:25:52 INFO DAGScheduler: Submitting ResultStage 50 (/tmp/RtmpLTlh4o/file2171a4eb3a620/stages/0_r_formula__8e049f4c_a0ea_471a_862c_cafd520f5953/pipelineModel/stages/0_r_formula__8e049f4c_a0ea_471a_862c_cafd520f5953/metadata MapPartitionsRDD[160] at textFile at ReadWrite.scala:587), which has no missing parents
21/02/17 01:25:52 INFO MemoryStore: Block broadcast_60 stored as values in memory (estimated size 4.3 KiB, free 909.2 MiB)
21/02/17 01:25:52 INFO MemoryStore: Block broadcast_60_piece0 stored as bytes in memory (estimated size 2.5 KiB, free 909.2 MiB)
21/02/17 01:25:52 INFO BlockManagerInfo: Added broadcast_60_piece0 in memory on localhost:41017 (size: 2.5 KiB, free: 911.9 MiB)
21/02/17 01:25:52 INFO SparkContext: Created broadcast 60 from broadcast at DAGScheduler.scala:1200
21/02/17 01:25:52 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 50 (/tmp/RtmpLTlh4o/file2171a4eb3a620/stages/0_r_formula__8e049f4c_a0ea_471a_862c_cafd520f5953/pipelineModel/stages/0_r_formula__8e049f4c_a0ea_471a_862c_cafd520f5953/metadata MapPartitionsRDD[160] at textFile at ReadWrite.scala:587) (first 15 tasks are for partitions Vector(0))
21/02/17 01:25:52 INFO TaskSchedulerImpl: Adding task set 50.0 with 1 tasks
21/02/17 01:25:52 INFO TaskSetManager: Starting task 0.0 in stage 50.0 (TID 52, localhost, executor driver, partition 0, PROCESS_LOCAL, 7531 bytes)
21/02/17 01:25:52 INFO Executor: Running task 0.0 in stage 50.0 (TID 52)
21/02/17 01:25:52 INFO HadoopRDD: Input split: file:/tmp/RtmpLTlh4o/file2171a4eb3a620/stages/0_r_formula__8e049f4c_a0ea_471a_862c_cafd520f5953/pipelineModel/stages/0_r_formula__8e049f4c_a0ea_471a_862c_cafd520f5953/metadata/part-00000:0+378
21/02/17 01:25:52 INFO Executor: Finished task 0.0 in stage 50.0 (TID 52). 1306 bytes result sent to driver
21/02/17 01:25:52 INFO TaskSetManager: Finished task 0.0 in stage 50.0 (TID 52) in 4 ms on localhost (executor driver) (1/1)
21/02/17 01:25:52 INFO TaskSchedulerImpl: Removed TaskSet 50.0, whose tasks have all completed, from pool 
21/02/17 01:25:52 INFO DAGScheduler: ResultStage 50 (first at ReadWrite.scala:587) finished in 0.007 s
21/02/17 01:25:52 INFO DAGScheduler: Job 38 is finished. Cancelling potential speculative or zombie tasks for this job
21/02/17 01:25:52 INFO TaskSchedulerImpl: Killing all running tasks in stage 50: Stage finished
21/02/17 01:25:52 INFO DAGScheduler: Job 38 finished: first at ReadWrite.scala:587, took 0.008277 s
21/02/17 01:25:52 INFO MemoryStore: Block broadcast_61 stored as values in memory (estimated size 294.6 KiB, free 908.9 MiB)
21/02/17 01:25:52 INFO MemoryStore: Block broadcast_61_piece0 stored as bytes in memory (estimated size 27.2 KiB, free 908.9 MiB)
21/02/17 01:25:52 INFO BlockManagerInfo: Added broadcast_61_piece0 in memory on localhost:41017 (size: 27.2 KiB, free: 911.9 MiB)
21/02/17 01:25:52 INFO SparkContext: Created broadcast 61 from textFile at ReadWrite.scala:587
21/02/17 01:25:52 INFO FileInputFormat: Total input files to process : 1
21/02/17 01:25:52 INFO SparkContext: Starting job: first at ReadWrite.scala:587
21/02/17 01:25:52 INFO DAGScheduler: Got job 39 (first at ReadWrite.scala:587) with 1 output partitions
21/02/17 01:25:52 INFO DAGScheduler: Final stage: ResultStage 51 (first at ReadWrite.scala:587)
21/02/17 01:25:52 INFO DAGScheduler: Parents of final stage: List()
21/02/17 01:25:52 INFO DAGScheduler: Missing parents: List()
21/02/17 01:25:52 INFO DAGScheduler: Submitting ResultStage 51 (/tmp/RtmpLTlh4o/file2171a4eb3a620/stages/0_r_formula__8e049f4c_a0ea_471a_862c_cafd520f5953/pipelineModel/stages/1_vectorAttrRewriter_8ea264265f11/metadata MapPartitionsRDD[162] at textFile at ReadWrite.scala:587), which has no missing parents
21/02/17 01:25:52 INFO MemoryStore: Block broadcast_62 stored as values in memory (estimated size 4.2 KiB, free 908.9 MiB)
21/02/17 01:25:52 INFO MemoryStore: Block broadcast_62_piece0 stored as bytes in memory (estimated size 2.5 KiB, free 908.9 MiB)
21/02/17 01:25:52 INFO BlockManagerInfo: Added broadcast_62_piece0 in memory on localhost:41017 (size: 2.5 KiB, free: 911.9 MiB)
21/02/17 01:25:52 INFO SparkContext: Created broadcast 62 from broadcast at DAGScheduler.scala:1200
21/02/17 01:25:52 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 51 (/tmp/RtmpLTlh4o/file2171a4eb3a620/stages/0_r_formula__8e049f4c_a0ea_471a_862c_cafd520f5953/pipelineModel/stages/1_vectorAttrRewriter_8ea264265f11/metadata MapPartitionsRDD[162] at textFile at ReadWrite.scala:587) (first 15 tasks are for partitions Vector(0))
21/02/17 01:25:52 INFO TaskSchedulerImpl: Adding task set 51.0 with 1 tasks
21/02/17 01:25:52 INFO TaskSetManager: Starting task 0.0 in stage 51.0 (TID 53, localhost, executor driver, partition 0, PROCESS_LOCAL, 7515 bytes)
21/02/17 01:25:52 INFO Executor: Running task 0.0 in stage 51.0 (TID 53)
21/02/17 01:25:52 INFO HadoopRDD: Input split: file:/tmp/RtmpLTlh4o/file2171a4eb3a620/stages/0_r_formula__8e049f4c_a0ea_471a_862c_cafd520f5953/pipelineModel/stages/1_vectorAttrRewriter_8ea264265f11/metadata/part-00000:0+188
21/02/17 01:25:52 INFO Executor: Finished task 0.0 in stage 51.0 (TID 53). 1113 bytes result sent to driver
21/02/17 01:25:52 INFO TaskSetManager: Finished task 0.0 in stage 51.0 (TID 53) in 3 ms on localhost (executor driver) (1/1)
21/02/17 01:25:52 INFO TaskSchedulerImpl: Removed TaskSet 51.0, whose tasks have all completed, from pool 
21/02/17 01:25:52 INFO DAGScheduler: ResultStage 51 (first at ReadWrite.scala:587) finished in 0.007 s
21/02/17 01:25:52 INFO DAGScheduler: Job 39 is finished. Cancelling potential speculative or zombie tasks for this job
21/02/17 01:25:52 INFO TaskSchedulerImpl: Killing all running tasks in stage 51: Stage finished
21/02/17 01:25:52 INFO DAGScheduler: Job 39 finished: first at ReadWrite.scala:587, took 0.007979 s
21/02/17 01:25:52 INFO MemoryStore: Block broadcast_63 stored as values in memory (estimated size 294.6 KiB, free 908.6 MiB)
21/02/17 01:25:52 INFO MemoryStore: Block broadcast_63_piece0 stored as bytes in memory (estimated size 27.2 KiB, free 908.6 MiB)
21/02/17 01:25:52 INFO BlockManagerInfo: Added broadcast_63_piece0 in memory on localhost:41017 (size: 27.2 KiB, free: 911.9 MiB)
21/02/17 01:25:52 INFO SparkContext: Created broadcast 63 from textFile at ReadWrite.scala:587
21/02/17 01:25:52 INFO FileInputFormat: Total input files to process : 1
21/02/17 01:25:52 INFO BlockManagerInfo: Removed broadcast_41_piece0 on localhost:41017 in memory (size: 5.2 KiB, free: 911.9 MiB)
21/02/17 01:25:52 INFO SparkContext: Starting job: first at ReadWrite.scala:587
21/02/17 01:25:52 INFO DAGScheduler: Got job 40 (first at ReadWrite.scala:587) with 1 output partitions
21/02/17 01:25:52 INFO DAGScheduler: Final stage: ResultStage 52 (first at ReadWrite.scala:587)
21/02/17 01:25:52 INFO DAGScheduler: Parents of final stage: List()
21/02/17 01:25:52 INFO DAGScheduler: Missing parents: List()
21/02/17 01:25:52 INFO BlockManagerInfo: Removed broadcast_51_piece0 on localhost:41017 in memory (size: 2.5 KiB, free: 911.9 MiB)
21/02/17 01:25:52 INFO DAGScheduler: Submitting ResultStage 52 (/tmp/RtmpLTlh4o/file2171a4eb3a620/stages/0_r_formula__8e049f4c_a0ea_471a_862c_cafd520f5953/pipelineModel/stages/1_vectorAttrRewriter_8ea264265f11/metadata MapPartitionsRDD[164] at textFile at ReadWrite.scala:587), which has no missing parents
21/02/17 01:25:52 INFO MemoryStore: Block broadcast_64 stored as values in memory (estimated size 4.2 KiB, free 908.6 MiB)
21/02/17 01:25:52 INFO BlockManagerInfo: Removed broadcast_59_piece0 on localhost:41017 in memory (size: 27.2 KiB, free: 911.9 MiB)
21/02/17 01:25:52 INFO MemoryStore: Block broadcast_64_piece0 stored as bytes in memory (estimated size 2.5 KiB, free 908.9 MiB)
21/02/17 01:25:52 INFO BlockManagerInfo: Added broadcast_64_piece0 in memory on localhost:41017 (size: 2.5 KiB, free: 911.9 MiB)
21/02/17 01:25:52 INFO SparkContext: Created broadcast 64 from broadcast at DAGScheduler.scala:1200
21/02/17 01:25:52 INFO BlockManagerInfo: Removed broadcast_50_piece0 on localhost:41017 in memory (size: 27.2 KiB, free: 911.9 MiB)
21/02/17 01:25:52 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 52 (/tmp/RtmpLTlh4o/file2171a4eb3a620/stages/0_r_formula__8e049f4c_a0ea_471a_862c_cafd520f5953/pipelineModel/stages/1_vectorAttrRewriter_8ea264265f11/metadata MapPartitionsRDD[164] at textFile at ReadWrite.scala:587) (first 15 tasks are for partitions Vector(0))
21/02/17 01:25:52 INFO TaskSchedulerImpl: Adding task set 52.0 with 1 tasks
21/02/17 01:25:52 INFO TaskSetManager: Starting task 0.0 in stage 52.0 (TID 54, localhost, executor driver, partition 0, PROCESS_LOCAL, 7515 bytes)
21/02/17 01:25:52 INFO Executor: Running task 0.0 in stage 52.0 (TID 54)
21/02/17 01:25:52 INFO BlockManagerInfo: Removed broadcast_52_piece0 on localhost:41017 in memory (size: 30.8 KiB, free: 912.0 MiB)
21/02/17 01:25:52 INFO BlockManagerInfo: Removed broadcast_44_piece0 on localhost:41017 in memory (size: 10.1 KiB, free: 912.0 MiB)
21/02/17 01:25:52 INFO HadoopRDD: Input split: file:/tmp/RtmpLTlh4o/file2171a4eb3a620/stages/0_r_formula__8e049f4c_a0ea_471a_862c_cafd520f5953/pipelineModel/stages/1_vectorAttrRewriter_8ea264265f11/metadata/part-00000:0+188
21/02/17 01:25:52 INFO BlockManagerInfo: Removed broadcast_33_piece0 on localhost:41017 in memory (size: 28.3 KiB, free: 912.0 MiB)
21/02/17 01:25:52 INFO BlockManagerInfo: Removed broadcast_57_piece0 on localhost:41017 in memory (size: 27.2 KiB, free: 912.0 MiB)
21/02/17 01:25:52 INFO Executor: Finished task 0.0 in stage 52.0 (TID 54). 1113 bytes result sent to driver
21/02/17 01:25:52 INFO BlockManagerInfo: Removed broadcast_49_piece0 on localhost:41017 in memory (size: 2.5 KiB, free: 912.0 MiB)
21/02/17 01:25:52 INFO TaskSetManager: Finished task 0.0 in stage 52.0 (TID 54) in 6 ms on localhost (executor driver) (1/1)
21/02/17 01:25:52 INFO TaskSchedulerImpl: Removed TaskSet 52.0, whose tasks have all completed, from pool 
21/02/17 01:25:52 INFO DAGScheduler: ResultStage 52 (first at ReadWrite.scala:587) finished in 0.010 s
21/02/17 01:25:52 INFO DAGScheduler: Job 40 is finished. Cancelling potential speculative or zombie tasks for this job
21/02/17 01:25:52 INFO TaskSchedulerImpl: Killing all running tasks in stage 52: Stage finished
21/02/17 01:25:52 INFO DAGScheduler: Job 40 finished: first at ReadWrite.scala:587, took 0.011784 s
21/02/17 01:25:52 INFO BlockManagerInfo: Removed broadcast_45_piece0 on localhost:41017 in memory (size: 5.0 KiB, free: 912.0 MiB)
21/02/17 01:25:52 INFO BlockManagerInfo: Removed broadcast_58_piece0 on localhost:41017 in memory (size: 2.5 KiB, free: 912.0 MiB)
21/02/17 01:25:52 INFO BlockManagerInfo: Removed broadcast_61_piece0 on localhost:41017 in memory (size: 27.2 KiB, free: 912.1 MiB)
21/02/17 01:25:52 INFO BlockManagerInfo: Removed broadcast_47_piece0 on localhost:41017 in memory (size: 2.4 KiB, free: 912.1 MiB)
21/02/17 01:25:52 INFO BlockManagerInfo: Removed broadcast_43_piece0 on localhost:41017 in memory (size: 8.0 KiB, free: 912.1 MiB)
21/02/17 01:25:52 INFO InMemoryFileIndex: It took 0 ms to list leaf files for 1 paths.
21/02/17 01:25:52 INFO BlockManagerInfo: Removed broadcast_60_piece0 on localhost:41017 in memory (size: 2.5 KiB, free: 912.1 MiB)
21/02/17 01:25:52 INFO BlockManagerInfo: Removed broadcast_46_piece0 on localhost:41017 in memory (size: 27.2 KiB, free: 912.1 MiB)
21/02/17 01:25:52 INFO BlockManagerInfo: Removed broadcast_54_piece0 on localhost:41017 in memory (size: 4.9 KiB, free: 912.1 MiB)
21/02/17 01:25:52 INFO BlockManagerInfo: Removed broadcast_55_piece0 on localhost:41017 in memory (size: 27.2 KiB, free: 912.1 MiB)
21/02/17 01:25:52 INFO BlockManagerInfo: Removed broadcast_56_piece0 on localhost:41017 in memory (size: 2.5 KiB, free: 912.1 MiB)
21/02/17 01:25:52 INFO BlockManager: Removing RDD 105
21/02/17 01:25:52 INFO BlockManagerInfo: Removed broadcast_42_piece0 on localhost:41017 in memory (size: 5.0 KiB, free: 912.1 MiB)
21/02/17 01:25:52 INFO BlockManagerInfo: Removed broadcast_62_piece0 on localhost:41017 in memory (size: 2.5 KiB, free: 912.1 MiB)
21/02/17 01:25:52 INFO BlockManagerInfo: Removed broadcast_48_piece0 on localhost:41017 in memory (size: 27.2 KiB, free: 912.2 MiB)
21/02/17 01:25:52 INFO BlockManagerInfo: Removed broadcast_53_piece0 on localhost:41017 in memory (size: 29.0 KiB, free: 912.2 MiB)
21/02/17 01:25:52 INFO SparkContext: Starting job: parquet at RFormula.scala:612
21/02/17 01:25:52 INFO DAGScheduler: Got job 41 (parquet at RFormula.scala:612) with 1 output partitions
21/02/17 01:25:52 INFO DAGScheduler: Final stage: ResultStage 53 (parquet at RFormula.scala:612)
21/02/17 01:25:52 INFO DAGScheduler: Parents of final stage: List()
21/02/17 01:25:52 INFO DAGScheduler: Missing parents: List()
21/02/17 01:25:52 INFO DAGScheduler: Submitting ResultStage 53 (MapPartitionsRDD[166] at parquet at RFormula.scala:612), which has no missing parents
21/02/17 01:25:52 INFO MemoryStore: Block broadcast_65 stored as values in memory (estimated size 86.6 KiB, free 911.7 MiB)
21/02/17 01:25:52 INFO MemoryStore: Block broadcast_65_piece0 stored as bytes in memory (estimated size 30.8 KiB, free 911.6 MiB)
21/02/17 01:25:52 INFO BlockManagerInfo: Added broadcast_65_piece0 in memory on localhost:41017 (size: 30.8 KiB, free: 912.2 MiB)
21/02/17 01:25:52 INFO SparkContext: Created broadcast 65 from broadcast at DAGScheduler.scala:1200
21/02/17 01:25:52 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 53 (MapPartitionsRDD[166] at parquet at RFormula.scala:612) (first 15 tasks are for partitions Vector(0))
21/02/17 01:25:52 INFO TaskSchedulerImpl: Adding task set 53.0 with 1 tasks
21/02/17 01:25:52 INFO TaskSetManager: Starting task 0.0 in stage 53.0 (TID 55, localhost, executor driver, partition 0, PROCESS_LOCAL, 7671 bytes)
21/02/17 01:25:52 INFO Executor: Running task 0.0 in stage 53.0 (TID 55)
21/02/17 01:25:52 INFO Executor: Finished task 0.0 in stage 53.0 (TID 55). 1769 bytes result sent to driver
21/02/17 01:25:52 INFO TaskSetManager: Finished task 0.0 in stage 53.0 (TID 55) in 7 ms on localhost (executor driver) (1/1)
21/02/17 01:25:52 INFO TaskSchedulerImpl: Removed TaskSet 53.0, whose tasks have all completed, from pool 
21/02/17 01:25:52 INFO DAGScheduler: ResultStage 53 (parquet at RFormula.scala:612) finished in 0.016 s
21/02/17 01:25:52 INFO DAGScheduler: Job 41 is finished. Cancelling potential speculative or zombie tasks for this job
21/02/17 01:25:52 INFO TaskSchedulerImpl: Killing all running tasks in stage 53: Stage finished
21/02/17 01:25:52 INFO DAGScheduler: Job 41 finished: parquet at RFormula.scala:612, took 0.017500 s
21/02/17 01:25:52 INFO FileSourceStrategy: Pruning directories with: 
21/02/17 01:25:52 INFO FileSourceStrategy: Pushed Filters: 
21/02/17 01:25:52 INFO FileSourceStrategy: Post-Scan Filters: 
21/02/17 01:25:52 INFO FileSourceStrategy: Output Data Schema: struct<vectorCol: string, prefixesToRewrite: map<string,string>>
21/02/17 01:25:52 INFO MemoryStore: Block broadcast_66 stored as values in memory (estimated size 318.7 KiB, free 911.3 MiB)
21/02/17 01:25:52 INFO MemoryStore: Block broadcast_66_piece0 stored as bytes in memory (estimated size 29.0 KiB, free 911.3 MiB)
21/02/17 01:25:52 INFO BlockManagerInfo: Added broadcast_66_piece0 in memory on localhost:41017 (size: 29.0 KiB, free: 912.1 MiB)
21/02/17 01:25:52 INFO SparkContext: Created broadcast 66 from head at RFormula.scala:612
21/02/17 01:25:52 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
21/02/17 01:25:52 INFO SparkContext: Starting job: head at RFormula.scala:612
21/02/17 01:25:52 INFO DAGScheduler: Got job 42 (head at RFormula.scala:612) with 1 output partitions
21/02/17 01:25:52 INFO DAGScheduler: Final stage: ResultStage 54 (head at RFormula.scala:612)
21/02/17 01:25:52 INFO DAGScheduler: Parents of final stage: List()
21/02/17 01:25:52 INFO DAGScheduler: Missing parents: List()
21/02/17 01:25:52 INFO DAGScheduler: Submitting ResultStage 54 (MapPartitionsRDD[169] at head at RFormula.scala:612), which has no missing parents
21/02/17 01:25:52 INFO MemoryStore: Block broadcast_67 stored as values in memory (estimated size 9.1 KiB, free 911.3 MiB)
21/02/17 01:25:52 INFO MemoryStore: Block broadcast_67_piece0 stored as bytes in memory (estimated size 4.8 KiB, free 911.3 MiB)
21/02/17 01:25:52 INFO BlockManagerInfo: Added broadcast_67_piece0 in memory on localhost:41017 (size: 4.8 KiB, free: 912.1 MiB)
21/02/17 01:25:52 INFO SparkContext: Created broadcast 67 from broadcast at DAGScheduler.scala:1200
21/02/17 01:25:52 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 54 (MapPartitionsRDD[169] at head at RFormula.scala:612) (first 15 tasks are for partitions Vector(0))
21/02/17 01:25:52 INFO TaskSchedulerImpl: Adding task set 54.0 with 1 tasks
21/02/17 01:25:52 INFO TaskSetManager: Starting task 0.0 in stage 54.0 (TID 56, localhost, executor driver, partition 0, PROCESS_LOCAL, 7922 bytes)
21/02/17 01:25:52 INFO Executor: Running task 0.0 in stage 54.0 (TID 56)
21/02/17 01:25:52 INFO FileScanRDD: Reading File path: file:///tmp/RtmpLTlh4o/file2171a4eb3a620/stages/0_r_formula__8e049f4c_a0ea_471a_862c_cafd520f5953/pipelineModel/stages/1_vectorAttrRewriter_8ea264265f11/data/part-00000-6d9dbafb-b1db-40c8-8d4c-8d30e98a3eae-c000.snappy.parquet, range: 0-927, partition values: [empty row]
21/02/17 01:25:52 INFO Executor: Finished task 0.0 in stage 54.0 (TID 56). 1728 bytes result sent to driver
21/02/17 01:25:52 INFO TaskSetManager: Finished task 0.0 in stage 54.0 (TID 56) in 12 ms on localhost (executor driver) (1/1)
21/02/17 01:25:52 INFO TaskSchedulerImpl: Removed TaskSet 54.0, whose tasks have all completed, from pool 
21/02/17 01:25:52 INFO DAGScheduler: ResultStage 54 (head at RFormula.scala:612) finished in 0.017 s
21/02/17 01:25:52 INFO DAGScheduler: Job 42 is finished. Cancelling potential speculative or zombie tasks for this job
21/02/17 01:25:52 INFO TaskSchedulerImpl: Killing all running tasks in stage 54: Stage finished
21/02/17 01:25:52 INFO DAGScheduler: Job 42 finished: head at RFormula.scala:612, took 0.017793 s
21/02/17 01:25:52 INFO CodeGenerator: Code generated in 13.30934 ms
21/02/17 01:25:52 INFO MemoryStore: Block broadcast_68 stored as values in memory (estimated size 294.6 KiB, free 911.0 MiB)
21/02/17 01:25:52 INFO MemoryStore: Block broadcast_68_piece0 stored as bytes in memory (estimated size 27.2 KiB, free 911.0 MiB)
21/02/17 01:25:52 INFO BlockManagerInfo: Added broadcast_68_piece0 in memory on localhost:41017 (size: 27.2 KiB, free: 912.1 MiB)
21/02/17 01:25:52 INFO SparkContext: Created broadcast 68 from textFile at ReadWrite.scala:587
21/02/17 01:25:52 INFO FileInputFormat: Total input files to process : 1
21/02/17 01:25:52 INFO SparkContext: Starting job: first at ReadWrite.scala:587
21/02/17 01:25:52 INFO DAGScheduler: Got job 43 (first at ReadWrite.scala:587) with 1 output partitions
21/02/17 01:25:52 INFO DAGScheduler: Final stage: ResultStage 55 (first at ReadWrite.scala:587)
21/02/17 01:25:52 INFO DAGScheduler: Parents of final stage: List()
21/02/17 01:25:52 INFO DAGScheduler: Missing parents: List()
21/02/17 01:25:52 INFO DAGScheduler: Submitting ResultStage 55 (/tmp/RtmpLTlh4o/file2171a4eb3a620/stages/0_r_formula__8e049f4c_a0ea_471a_862c_cafd520f5953/pipelineModel/stages/2_columnPruner_233f6ca0fca6/metadata MapPartitionsRDD[171] at textFile at ReadWrite.scala:587), which has no missing parents
21/02/17 01:25:52 INFO MemoryStore: Block broadcast_69 stored as values in memory (estimated size 4.2 KiB, free 911.0 MiB)
21/02/17 01:25:52 INFO MemoryStore: Block broadcast_69_piece0 stored as bytes in memory (estimated size 2.5 KiB, free 911.0 MiB)
21/02/17 01:25:52 INFO BlockManagerInfo: Added broadcast_69_piece0 in memory on localhost:41017 (size: 2.5 KiB, free: 912.1 MiB)
21/02/17 01:25:52 INFO SparkContext: Created broadcast 69 from broadcast at DAGScheduler.scala:1200
21/02/17 01:25:52 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 55 (/tmp/RtmpLTlh4o/file2171a4eb3a620/stages/0_r_formula__8e049f4c_a0ea_471a_862c_cafd520f5953/pipelineModel/stages/2_columnPruner_233f6ca0fca6/metadata MapPartitionsRDD[171] at textFile at ReadWrite.scala:587) (first 15 tasks are for partitions Vector(0))
21/02/17 01:25:52 INFO TaskSchedulerImpl: Adding task set 55.0 with 1 tasks
21/02/17 01:25:52 INFO TaskSetManager: Starting task 0.0 in stage 55.0 (TID 57, localhost, executor driver, partition 0, PROCESS_LOCAL, 7506 bytes)
21/02/17 01:25:52 INFO Executor: Running task 0.0 in stage 55.0 (TID 57)
21/02/17 01:25:52 INFO HadoopRDD: Input split: file:/tmp/RtmpLTlh4o/file2171a4eb3a620/stages/0_r_formula__8e049f4c_a0ea_471a_862c_cafd520f5953/pipelineModel/stages/2_columnPruner_233f6ca0fca6/metadata/part-00000:0+171
21/02/17 01:25:52 INFO Executor: Finished task 0.0 in stage 55.0 (TID 57). 1096 bytes result sent to driver
21/02/17 01:25:52 INFO TaskSetManager: Finished task 0.0 in stage 55.0 (TID 57) in 4 ms on localhost (executor driver) (1/1)
21/02/17 01:25:52 INFO TaskSchedulerImpl: Removed TaskSet 55.0, whose tasks have all completed, from pool 
21/02/17 01:25:52 INFO DAGScheduler: ResultStage 55 (first at ReadWrite.scala:587) finished in 0.006 s
21/02/17 01:25:52 INFO DAGScheduler: Job 43 is finished. Cancelling potential speculative or zombie tasks for this job
21/02/17 01:25:52 INFO TaskSchedulerImpl: Killing all running tasks in stage 55: Stage finished
21/02/17 01:25:52 INFO DAGScheduler: Job 43 finished: first at ReadWrite.scala:587, took 0.007949 s
21/02/17 01:25:52 INFO MemoryStore: Block broadcast_70 stored as values in memory (estimated size 294.6 KiB, free 910.7 MiB)
21/02/17 01:25:52 INFO MemoryStore: Block broadcast_70_piece0 stored as bytes in memory (estimated size 27.2 KiB, free 910.6 MiB)
21/02/17 01:25:52 INFO BlockManagerInfo: Added broadcast_70_piece0 in memory on localhost:41017 (size: 27.2 KiB, free: 912.1 MiB)
21/02/17 01:25:52 INFO SparkContext: Created broadcast 70 from textFile at ReadWrite.scala:587
21/02/17 01:25:52 INFO FileInputFormat: Total input files to process : 1
21/02/17 01:25:52 INFO SparkContext: Starting job: first at ReadWrite.scala:587
21/02/17 01:25:52 INFO DAGScheduler: Got job 44 (first at ReadWrite.scala:587) with 1 output partitions
21/02/17 01:25:52 INFO DAGScheduler: Final stage: ResultStage 56 (first at ReadWrite.scala:587)
21/02/17 01:25:52 INFO DAGScheduler: Parents of final stage: List()
21/02/17 01:25:52 INFO DAGScheduler: Missing parents: List()
21/02/17 01:25:52 INFO DAGScheduler: Submitting ResultStage 56 (/tmp/RtmpLTlh4o/file2171a4eb3a620/stages/0_r_formula__8e049f4c_a0ea_471a_862c_cafd520f5953/pipelineModel/stages/2_columnPruner_233f6ca0fca6/metadata MapPartitionsRDD[173] at textFile at ReadWrite.scala:587), which has no missing parents
21/02/17 01:25:52 INFO MemoryStore: Block broadcast_71 stored as values in memory (estimated size 4.2 KiB, free 910.6 MiB)
21/02/17 01:25:52 INFO MemoryStore: Block broadcast_71_piece0 stored as bytes in memory (estimated size 2.5 KiB, free 910.6 MiB)
21/02/17 01:25:52 INFO BlockManagerInfo: Added broadcast_71_piece0 in memory on localhost:41017 (size: 2.5 KiB, free: 912.1 MiB)
21/02/17 01:25:52 INFO SparkContext: Created broadcast 71 from broadcast at DAGScheduler.scala:1200
21/02/17 01:25:52 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 56 (/tmp/RtmpLTlh4o/file2171a4eb3a620/stages/0_r_formula__8e049f4c_a0ea_471a_862c_cafd520f5953/pipelineModel/stages/2_columnPruner_233f6ca0fca6/metadata MapPartitionsRDD[173] at textFile at ReadWrite.scala:587) (first 15 tasks are for partitions Vector(0))
21/02/17 01:25:52 INFO TaskSchedulerImpl: Adding task set 56.0 with 1 tasks
21/02/17 01:25:52 INFO TaskSetManager: Starting task 0.0 in stage 56.0 (TID 58, localhost, executor driver, partition 0, PROCESS_LOCAL, 7506 bytes)
21/02/17 01:25:52 INFO Executor: Running task 0.0 in stage 56.0 (TID 58)
21/02/17 01:25:52 INFO HadoopRDD: Input split: file:/tmp/RtmpLTlh4o/file2171a4eb3a620/stages/0_r_formula__8e049f4c_a0ea_471a_862c_cafd520f5953/pipelineModel/stages/2_columnPruner_233f6ca0fca6/metadata/part-00000:0+171
21/02/17 01:25:52 INFO Executor: Finished task 0.0 in stage 56.0 (TID 58). 1053 bytes result sent to driver
21/02/17 01:25:52 INFO TaskSetManager: Finished task 0.0 in stage 56.0 (TID 58) in 3 ms on localhost (executor driver) (1/1)
21/02/17 01:25:52 INFO TaskSchedulerImpl: Removed TaskSet 56.0, whose tasks have all completed, from pool 
21/02/17 01:25:52 INFO DAGScheduler: ResultStage 56 (first at ReadWrite.scala:587) finished in 0.006 s
21/02/17 01:25:52 INFO DAGScheduler: Job 44 is finished. Cancelling potential speculative or zombie tasks for this job
21/02/17 01:25:52 INFO TaskSchedulerImpl: Killing all running tasks in stage 56: Stage finished
21/02/17 01:25:52 INFO DAGScheduler: Job 44 finished: first at ReadWrite.scala:587, took 0.007043 s
21/02/17 01:25:52 INFO InMemoryFileIndex: It took 0 ms to list leaf files for 1 paths.
21/02/17 01:25:52 INFO SparkContext: Starting job: parquet at RFormula.scala:521
21/02/17 01:25:52 INFO DAGScheduler: Got job 45 (parquet at RFormula.scala:521) with 1 output partitions
21/02/17 01:25:52 INFO DAGScheduler: Final stage: ResultStage 57 (parquet at RFormula.scala:521)
21/02/17 01:25:52 INFO DAGScheduler: Parents of final stage: List()
21/02/17 01:25:52 INFO DAGScheduler: Missing parents: List()
21/02/17 01:25:52 INFO DAGScheduler: Submitting ResultStage 57 (MapPartitionsRDD[175] at parquet at RFormula.scala:521), which has no missing parents
21/02/17 01:25:52 INFO MemoryStore: Block broadcast_72 stored as values in memory (estimated size 86.6 KiB, free 910.5 MiB)
21/02/17 01:25:52 INFO MemoryStore: Block broadcast_72_piece0 stored as bytes in memory (estimated size 30.8 KiB, free 910.5 MiB)
21/02/17 01:25:52 INFO BlockManagerInfo: Added broadcast_72_piece0 in memory on localhost:41017 (size: 30.8 KiB, free: 912.1 MiB)
21/02/17 01:25:52 INFO SparkContext: Created broadcast 72 from broadcast at DAGScheduler.scala:1200
21/02/17 01:25:52 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 57 (MapPartitionsRDD[175] at parquet at RFormula.scala:521) (first 15 tasks are for partitions Vector(0))
21/02/17 01:25:52 INFO TaskSchedulerImpl: Adding task set 57.0 with 1 tasks
21/02/17 01:25:52 INFO TaskSetManager: Starting task 0.0 in stage 57.0 (TID 59, localhost, executor driver, partition 0, PROCESS_LOCAL, 7665 bytes)
21/02/17 01:25:52 INFO Executor: Running task 0.0 in stage 57.0 (TID 59)
21/02/17 01:25:52 INFO Executor: Finished task 0.0 in stage 57.0 (TID 59). 1705 bytes result sent to driver
21/02/17 01:25:52 INFO TaskSetManager: Finished task 0.0 in stage 57.0 (TID 59) in 7 ms on localhost (executor driver) (1/1)
21/02/17 01:25:52 INFO TaskSchedulerImpl: Removed TaskSet 57.0, whose tasks have all completed, from pool 
21/02/17 01:25:52 INFO DAGScheduler: ResultStage 57 (parquet at RFormula.scala:521) finished in 0.014 s
21/02/17 01:25:52 INFO DAGScheduler: Job 45 is finished. Cancelling potential speculative or zombie tasks for this job
21/02/17 01:25:52 INFO TaskSchedulerImpl: Killing all running tasks in stage 57: Stage finished
21/02/17 01:25:52 INFO DAGScheduler: Job 45 finished: parquet at RFormula.scala:521, took 0.015292 s
21/02/17 01:25:52 INFO FileSourceStrategy: Pruning directories with: 
21/02/17 01:25:52 INFO FileSourceStrategy: Pushed Filters: 
21/02/17 01:25:52 INFO FileSourceStrategy: Post-Scan Filters: 
21/02/17 01:25:52 INFO FileSourceStrategy: Output Data Schema: struct<columnsToPrune: array<string>>
21/02/17 01:25:52 INFO MemoryStore: Block broadcast_73 stored as values in memory (estimated size 318.3 KiB, free 910.2 MiB)
21/02/17 01:25:52 INFO MemoryStore: Block broadcast_73_piece0 stored as bytes in memory (estimated size 28.9 KiB, free 910.2 MiB)
21/02/17 01:25:52 INFO BlockManagerInfo: Added broadcast_73_piece0 in memory on localhost:41017 (size: 28.9 KiB, free: 912.0 MiB)
21/02/17 01:25:52 INFO SparkContext: Created broadcast 73 from head at RFormula.scala:521
21/02/17 01:25:52 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
21/02/17 01:25:52 INFO SparkContext: Starting job: head at RFormula.scala:521
21/02/17 01:25:52 INFO DAGScheduler: Got job 46 (head at RFormula.scala:521) with 1 output partitions
21/02/17 01:25:52 INFO DAGScheduler: Final stage: ResultStage 58 (head at RFormula.scala:521)
21/02/17 01:25:52 INFO DAGScheduler: Parents of final stage: List()
21/02/17 01:25:52 INFO DAGScheduler: Missing parents: List()
21/02/17 01:25:52 INFO DAGScheduler: Submitting ResultStage 58 (MapPartitionsRDD[178] at head at RFormula.scala:521), which has no missing parents
21/02/17 01:25:52 INFO MemoryStore: Block broadcast_74 stored as values in memory (estimated size 8.9 KiB, free 910.2 MiB)
21/02/17 01:25:52 INFO MemoryStore: Block broadcast_74_piece0 stored as bytes in memory (estimated size 4.8 KiB, free 910.2 MiB)
21/02/17 01:25:52 INFO BlockManagerInfo: Added broadcast_74_piece0 in memory on localhost:41017 (size: 4.8 KiB, free: 912.0 MiB)
21/02/17 01:25:52 INFO SparkContext: Created broadcast 74 from broadcast at DAGScheduler.scala:1200
21/02/17 01:25:52 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 58 (MapPartitionsRDD[178] at head at RFormula.scala:521) (first 15 tasks are for partitions Vector(0))
21/02/17 01:25:52 INFO TaskSchedulerImpl: Adding task set 58.0 with 1 tasks
21/02/17 01:25:52 INFO TaskSetManager: Starting task 0.0 in stage 58.0 (TID 60, localhost, executor driver, partition 0, PROCESS_LOCAL, 7916 bytes)
21/02/17 01:25:52 INFO Executor: Running task 0.0 in stage 58.0 (TID 60)
21/02/17 01:25:52 INFO FileScanRDD: Reading File path: file:///tmp/RtmpLTlh4o/file2171a4eb3a620/stages/0_r_formula__8e049f4c_a0ea_471a_862c_cafd520f5953/pipelineModel/stages/2_columnPruner_233f6ca0fca6/data/part-00000-2238baab-1ceb-487a-b4bf-6c5ccd94a27f-c000.snappy.parquet, range: 0-510, partition values: [empty row]
21/02/17 01:25:52 INFO Executor: Finished task 0.0 in stage 58.0 (TID 60). 1709 bytes result sent to driver
21/02/17 01:25:52 INFO TaskSetManager: Finished task 0.0 in stage 58.0 (TID 60) in 7 ms on localhost (executor driver) (1/1)
21/02/17 01:25:52 INFO TaskSchedulerImpl: Removed TaskSet 58.0, whose tasks have all completed, from pool 
21/02/17 01:25:52 INFO DAGScheduler: ResultStage 58 (head at RFormula.scala:521) finished in 0.011 s
21/02/17 01:25:52 INFO DAGScheduler: Job 46 is finished. Cancelling potential speculative or zombie tasks for this job
21/02/17 01:25:52 INFO TaskSchedulerImpl: Killing all running tasks in stage 58: Stage finished
21/02/17 01:25:52 INFO DAGScheduler: Job 46 finished: head at RFormula.scala:521, took 0.012120 s
21/02/17 01:25:52 INFO CodeGenerator: Code generated in 12.548789 ms
21/02/17 01:25:52 INFO Instrumentation: [12b119de] training finished
21/02/17 01:25:52 INFO Instrumentation: [e32a3cd4] training finished
21/02/17 01:25:52 INFO MemoryStore: Block broadcast_75 stored as values in memory (estimated size 294.6 KiB, free 909.9 MiB)
21/02/17 01:25:52 INFO MemoryStore: Block broadcast_75_piece0 stored as bytes in memory (estimated size 27.2 KiB, free 909.9 MiB)
21/02/17 01:25:52 INFO BlockManagerInfo: Added broadcast_75_piece0 in memory on localhost:41017 (size: 27.2 KiB, free: 912.0 MiB)
21/02/17 01:25:52 INFO SparkContext: Created broadcast 75 from textFile at ReadWrite.scala:587
21/02/17 01:25:52 INFO FileInputFormat: Total input files to process : 1
21/02/17 01:25:52 INFO SparkContext: Starting job: first at ReadWrite.scala:587
21/02/17 01:25:52 INFO DAGScheduler: Got job 47 (first at ReadWrite.scala:587) with 1 output partitions
21/02/17 01:25:52 INFO DAGScheduler: Final stage: ResultStage 59 (first at ReadWrite.scala:587)
21/02/17 01:25:52 INFO DAGScheduler: Parents of final stage: List()
21/02/17 01:25:52 INFO DAGScheduler: Missing parents: List()
21/02/17 01:25:52 INFO DAGScheduler: Submitting ResultStage 59 (/tmp/RtmpLTlh4o/file2171a4eb3a620/stages/1_xgboost_regressor__86dd124b_3cb5_4868_8a73_d1d41c2e0270/metadata MapPartitionsRDD[180] at textFile at ReadWrite.scala:587), which has no missing parents
21/02/17 01:25:52 INFO MemoryStore: Block broadcast_76 stored as values in memory (estimated size 4.2 KiB, free 909.8 MiB)
21/02/17 01:25:52 INFO MemoryStore: Block broadcast_76_piece0 stored as bytes in memory (estimated size 2.5 KiB, free 909.8 MiB)
21/02/17 01:25:52 INFO BlockManagerInfo: Added broadcast_76_piece0 in memory on localhost:41017 (size: 2.5 KiB, free: 912.0 MiB)
21/02/17 01:25:52 INFO SparkContext: Created broadcast 76 from broadcast at DAGScheduler.scala:1200
21/02/17 01:25:52 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 59 (/tmp/RtmpLTlh4o/file2171a4eb3a620/stages/1_xgboost_regressor__86dd124b_3cb5_4868_8a73_d1d41c2e0270/metadata MapPartitionsRDD[180] at textFile at ReadWrite.scala:587) (first 15 tasks are for partitions Vector(0))
21/02/17 01:25:52 INFO TaskSchedulerImpl: Adding task set 59.0 with 1 tasks
21/02/17 01:25:52 INFO TaskSetManager: Starting task 0.0 in stage 59.0 (TID 61, localhost, executor driver, partition 0, PROCESS_LOCAL, 7464 bytes)
21/02/17 01:25:52 INFO Executor: Running task 0.0 in stage 59.0 (TID 61)
21/02/17 01:25:52 INFO HadoopRDD: Input split: file:/tmp/RtmpLTlh4o/file2171a4eb3a620/stages/1_xgboost_regressor__86dd124b_3cb5_4868_8a73_d1d41c2e0270/metadata/part-00000:0+1284
21/02/17 01:25:52 INFO Executor: Finished task 0.0 in stage 59.0 (TID 61). 2217 bytes result sent to driver
21/02/17 01:25:52 INFO TaskSetManager: Finished task 0.0 in stage 59.0 (TID 61) in 4 ms on localhost (executor driver) (1/1)
21/02/17 01:25:52 INFO TaskSchedulerImpl: Removed TaskSet 59.0, whose tasks have all completed, from pool 
21/02/17 01:25:52 INFO DAGScheduler: ResultStage 59 (first at ReadWrite.scala:587) finished in 0.006 s
21/02/17 01:25:52 INFO DAGScheduler: Job 47 is finished. Cancelling potential speculative or zombie tasks for this job
21/02/17 01:25:52 INFO TaskSchedulerImpl: Killing all running tasks in stage 59: Stage finished
21/02/17 01:25:52 INFO DAGScheduler: Job 47 finished: first at ReadWrite.scala:587, took 0.007991 s
21/02/17 01:25:52 INFO MemoryStore: Block broadcast_77 stored as values in memory (estimated size 294.6 KiB, free 909.6 MiB)
21/02/17 01:25:52 INFO MemoryStore: Block broadcast_77_piece0 stored as bytes in memory (estimated size 27.2 KiB, free 909.5 MiB)
21/02/17 01:25:52 INFO BlockManagerInfo: Added broadcast_77_piece0 in memory on localhost:41017 (size: 27.2 KiB, free: 912.0 MiB)
21/02/17 01:25:52 INFO SparkContext: Created broadcast 77 from textFile at DefaultXGBoostParamsReader.scala:82
21/02/17 01:25:52 INFO FileInputFormat: Total input files to process : 1
21/02/17 01:25:52 INFO SparkContext: Starting job: first at DefaultXGBoostParamsReader.scala:82
21/02/17 01:25:52 INFO DAGScheduler: Got job 48 (first at DefaultXGBoostParamsReader.scala:82) with 1 output partitions
21/02/17 01:25:52 INFO DAGScheduler: Final stage: ResultStage 60 (first at DefaultXGBoostParamsReader.scala:82)
21/02/17 01:25:52 INFO DAGScheduler: Parents of final stage: List()
21/02/17 01:25:52 INFO DAGScheduler: Missing parents: List()
21/02/17 01:25:52 INFO DAGScheduler: Submitting ResultStage 60 (/tmp/RtmpLTlh4o/file2171a4eb3a620/stages/1_xgboost_regressor__86dd124b_3cb5_4868_8a73_d1d41c2e0270/metadata MapPartitionsRDD[182] at textFile at DefaultXGBoostParamsReader.scala:82), which has no missing parents
21/02/17 01:25:52 INFO MemoryStore: Block broadcast_78 stored as values in memory (estimated size 4.2 KiB, free 909.5 MiB)
21/02/17 01:25:52 INFO MemoryStore: Block broadcast_78_piece0 stored as bytes in memory (estimated size 2.5 KiB, free 909.5 MiB)
21/02/17 01:25:52 INFO BlockManagerInfo: Added broadcast_78_piece0 in memory on localhost:41017 (size: 2.5 KiB, free: 912.0 MiB)
21/02/17 01:25:52 INFO SparkContext: Created broadcast 78 from broadcast at DAGScheduler.scala:1200
21/02/17 01:25:52 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 60 (/tmp/RtmpLTlh4o/file2171a4eb3a620/stages/1_xgboost_regressor__86dd124b_3cb5_4868_8a73_d1d41c2e0270/metadata MapPartitionsRDD[182] at textFile at DefaultXGBoostParamsReader.scala:82) (first 15 tasks are for partitions Vector(0))
21/02/17 01:25:52 INFO TaskSchedulerImpl: Adding task set 60.0 with 1 tasks
21/02/17 01:25:52 INFO TaskSetManager: Starting task 0.0 in stage 60.0 (TID 62, localhost, executor driver, partition 0, PROCESS_LOCAL, 7464 bytes)
21/02/17 01:25:52 INFO Executor: Running task 0.0 in stage 60.0 (TID 62)
21/02/17 01:25:52 INFO HadoopRDD: Input split: file:/tmp/RtmpLTlh4o/file2171a4eb3a620/stages/1_xgboost_regressor__86dd124b_3cb5_4868_8a73_d1d41c2e0270/metadata/part-00000:0+1284
21/02/17 01:25:52 INFO Executor: Finished task 0.0 in stage 60.0 (TID 62). 2217 bytes result sent to driver
21/02/17 01:25:52 INFO TaskSetManager: Finished task 0.0 in stage 60.0 (TID 62) in 4 ms on localhost (executor driver) (1/1)
21/02/17 01:25:52 INFO TaskSchedulerImpl: Removed TaskSet 60.0, whose tasks have all completed, from pool 
21/02/17 01:25:52 INFO DAGScheduler: ResultStage 60 (first at DefaultXGBoostParamsReader.scala:82) finished in 0.006 s
21/02/17 01:25:52 INFO DAGScheduler: Job 48 is finished. Cancelling potential speculative or zombie tasks for this job
21/02/17 01:25:52 INFO TaskSchedulerImpl: Killing all running tasks in stage 60: Stage finished
21/02/17 01:25:52 INFO DAGScheduler: Job 48 finished: first at DefaultXGBoostParamsReader.scala:82, took 0.007569 s
21/02/17 01:25:52 INFO Instrumentation: [80114dc9] training finished
21/02/17 01:25:52 INFO Instrumentation: [f30642cf] training finished
21/02/17 01:25:52 INFO Instrumentation: [dc23ca1e] training finished
21/02/17 01:25:52 INFO MemoryStore: Block broadcast_79 stored as values in memory (estimated size 64.0 B, free 909.5 MiB)
21/02/17 01:25:52 INFO MemoryStore: Block broadcast_79_piece0 stored as bytes in memory (estimated size 515.0 B, free 909.5 MiB)
21/02/17 01:25:52 INFO BlockManagerInfo: Added broadcast_79_piece0 in memory on localhost:41017 (size: 515.0 B, free: 912.0 MiB)
21/02/17 01:25:52 INFO SparkContext: Created broadcast 79 from broadcast at XGBoostRegressor.scala:279
21/02/17 01:25:52 INFO Instrumentation: [134da1d5] training finished
21/02/17 01:25:52 INFO SparkContext: Starting job: collect at utils.scala:137
21/02/17 01:25:52 INFO DAGScheduler: Got job 49 (collect at utils.scala:137) with 1 output partitions
21/02/17 01:25:52 INFO DAGScheduler: Final stage: ResultStage 61 (collect at utils.scala:137)
21/02/17 01:25:52 INFO DAGScheduler: Parents of final stage: List()
21/02/17 01:25:52 INFO DAGScheduler: Missing parents: List()
21/02/17 01:25:52 INFO DAGScheduler: Submitting ResultStage 61 (MapPartitionsRDD[192] at collect at utils.scala:137), which has no missing parents
21/02/17 01:25:52 INFO MemoryStore: Block broadcast_80 stored as values in memory (estimated size 7.3 KiB, free 909.5 MiB)
21/02/17 01:25:52 INFO MemoryStore: Block broadcast_80_piece0 stored as bytes in memory (estimated size 3.7 KiB, free 909.5 MiB)
21/02/17 01:25:52 INFO BlockManagerInfo: Added broadcast_80_piece0 in memory on localhost:41017 (size: 3.7 KiB, free: 912.0 MiB)
21/02/17 01:25:52 INFO SparkContext: Created broadcast 80 from broadcast at DAGScheduler.scala:1200
21/02/17 01:25:52 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 61 (MapPartitionsRDD[192] at collect at utils.scala:137) (first 15 tasks are for partitions Vector(0))
21/02/17 01:25:52 INFO TaskSchedulerImpl: Adding task set 61.0 with 1 tasks
21/02/17 01:25:52 INFO TaskSetManager: Starting task 0.0 in stage 61.0 (TID 63, localhost, executor driver, partition 0, PROCESS_LOCAL, 7561 bytes)
21/02/17 01:25:52 INFO Executor: Running task 0.0 in stage 61.0 (TID 63)
21/02/17 01:25:52 INFO Executor: Finished task 0.0 in stage 61.0 (TID 63). 1354 bytes result sent to driver
21/02/17 01:25:52 INFO TaskSetManager: Finished task 0.0 in stage 61.0 (TID 63) in 3 ms on localhost (executor driver) (1/1)
21/02/17 01:25:52 INFO TaskSchedulerImpl: Removed TaskSet 61.0, whose tasks have all completed, from pool 
21/02/17 01:25:52 INFO DAGScheduler: ResultStage 61 (collect at utils.scala:137) finished in 0.005 s
21/02/17 01:25:52 INFO DAGScheduler: Job 49 is finished. Cancelling potential speculative or zombie tasks for this job
21/02/17 01:25:52 INFO TaskSchedulerImpl: Killing all running tasks in stage 61: Stage finished
21/02/17 01:25:52 INFO DAGScheduler: Job 49 finished: collect at utils.scala:137, took 0.006982 s
21/02/17 01:25:52 INFO SparkContext: Starting job: count at utils.scala:135
21/02/17 01:25:52 INFO DAGScheduler: Registering RDD 194 (count at utils.scala:135) as input to shuffle 13
21/02/17 01:25:52 INFO DAGScheduler: Got job 50 (count at utils.scala:135) with 1 output partitions
21/02/17 01:25:52 INFO DAGScheduler: Final stage: ResultStage 63 (count at utils.scala:135)
21/02/17 01:25:52 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 62)
21/02/17 01:25:52 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 62)
21/02/17 01:25:52 INFO DAGScheduler: Submitting ShuffleMapStage 62 (MapPartitionsRDD[194] at count at utils.scala:135), which has no missing parents
21/02/17 01:25:52 INFO MemoryStore: Block broadcast_81 stored as values in memory (estimated size 10.0 KiB, free 909.5 MiB)
21/02/17 01:25:52 INFO MemoryStore: Block broadcast_81_piece0 stored as bytes in memory (estimated size 5.2 KiB, free 909.5 MiB)
21/02/17 01:25:52 INFO BlockManagerInfo: Added broadcast_81_piece0 in memory on localhost:41017 (size: 5.2 KiB, free: 912.0 MiB)
21/02/17 01:25:52 INFO SparkContext: Created broadcast 81 from broadcast at DAGScheduler.scala:1200
21/02/17 01:25:52 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 62 (MapPartitionsRDD[194] at count at utils.scala:135) (first 15 tasks are for partitions Vector(0))
21/02/17 01:25:52 INFO TaskSchedulerImpl: Adding task set 62.0 with 1 tasks
21/02/17 01:25:52 INFO TaskSetManager: Starting task 0.0 in stage 62.0 (TID 64, localhost, executor driver, partition 0, PROCESS_LOCAL, 7550 bytes)
21/02/17 01:25:52 INFO Executor: Running task 0.0 in stage 62.0 (TID 64)
21/02/17 01:25:52 INFO BlockManagerInfo: Removed broadcast_75_piece0 on localhost:41017 in memory (size: 27.2 KiB, free: 912.0 MiB)
21/02/17 01:25:52 INFO Executor: Finished task 0.0 in stage 62.0 (TID 64). 1833 bytes result sent to driver
21/02/17 01:25:52 INFO TaskSetManager: Finished task 0.0 in stage 62.0 (TID 64) in 3 ms on localhost (executor driver) (1/1)
21/02/17 01:25:52 INFO TaskSchedulerImpl: Removed TaskSet 62.0, whose tasks have all completed, from pool 
21/02/17 01:25:52 INFO BlockManagerInfo: Removed broadcast_66_piece0 on localhost:41017 in memory (size: 29.0 KiB, free: 912.0 MiB)
21/02/17 01:25:52 INFO DAGScheduler: ShuffleMapStage 62 (count at utils.scala:135) finished in 0.021 s
21/02/17 01:25:52 INFO DAGScheduler: looking for newly runnable stages
21/02/17 01:25:52 INFO DAGScheduler: running: Set()
21/02/17 01:25:52 INFO DAGScheduler: waiting: Set(ResultStage 63)
21/02/17 01:25:52 INFO DAGScheduler: failed: Set()
21/02/17 01:25:52 INFO DAGScheduler: Submitting ResultStage 63 (MapPartitionsRDD[197] at count at utils.scala:135), which has no missing parents
21/02/17 01:25:52 INFO BlockManagerInfo: Removed broadcast_71_piece0 on localhost:41017 in memory (size: 2.5 KiB, free: 912.0 MiB)
21/02/17 01:25:52 INFO BlockManagerInfo: Removed broadcast_69_piece0 on localhost:41017 in memory (size: 2.5 KiB, free: 912.0 MiB)
21/02/17 01:25:52 INFO MemoryStore: Block broadcast_82 stored as values in memory (estimated size 10.1 KiB, free 910.2 MiB)
21/02/17 01:25:52 INFO BlockManagerInfo: Removed broadcast_70_piece0 on localhost:41017 in memory (size: 27.2 KiB, free: 912.0 MiB)
21/02/17 01:25:52 INFO MemoryStore: Block broadcast_82_piece0 stored as bytes in memory (estimated size 5.0 KiB, free 910.5 MiB)
21/02/17 01:25:52 INFO BlockManagerInfo: Added broadcast_82_piece0 in memory on localhost:41017 (size: 5.0 KiB, free: 912.0 MiB)
21/02/17 01:25:52 INFO SparkContext: Created broadcast 82 from broadcast at DAGScheduler.scala:1200
21/02/17 01:25:52 INFO BlockManagerInfo: Removed broadcast_68_piece0 on localhost:41017 in memory (size: 27.2 KiB, free: 912.1 MiB)
21/02/17 01:25:52 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 63 (MapPartitionsRDD[197] at count at utils.scala:135) (first 15 tasks are for partitions Vector(0))
21/02/17 01:25:52 INFO TaskSchedulerImpl: Adding task set 63.0 with 1 tasks
21/02/17 01:25:52 INFO BlockManagerInfo: Removed broadcast_80_piece0 on localhost:41017 in memory (size: 3.7 KiB, free: 912.1 MiB)
21/02/17 01:25:52 INFO TaskSetManager: Starting task 0.0 in stage 63.0 (TID 65, localhost, executor driver, partition 0, NODE_LOCAL, 7325 bytes)
21/02/17 01:25:52 INFO Executor: Running task 0.0 in stage 63.0 (TID 65)
21/02/17 01:25:52 INFO BlockManagerInfo: Removed broadcast_74_piece0 on localhost:41017 in memory (size: 4.8 KiB, free: 912.1 MiB)
21/02/17 01:25:52 INFO BlockManagerInfo: Removed broadcast_64_piece0 on localhost:41017 in memory (size: 2.5 KiB, free: 912.1 MiB)
21/02/17 01:25:52 INFO BlockManagerInfo: Removed broadcast_77_piece0 on localhost:41017 in memory (size: 27.2 KiB, free: 912.1 MiB)
21/02/17 01:25:52 INFO ShuffleBlockFetcherIterator: Getting 1 (60.0 B) non-empty blocks including 1 (60.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
21/02/17 01:25:52 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
21/02/17 01:25:52 INFO BlockManagerInfo: Removed broadcast_63_piece0 on localhost:41017 in memory (size: 27.2 KiB, free: 912.1 MiB)
21/02/17 01:25:52 INFO Executor: Finished task 0.0 in stage 63.0 (TID 65). 2648 bytes result sent to driver
21/02/17 01:25:52 INFO BlockManagerInfo: Removed broadcast_65_piece0 on localhost:41017 in memory (size: 30.8 KiB, free: 912.2 MiB)
21/02/17 01:25:52 INFO TaskSetManager: Finished task 0.0 in stage 63.0 (TID 65) in 3 ms on localhost (executor driver) (1/1)
21/02/17 01:25:52 INFO TaskSchedulerImpl: Removed TaskSet 63.0, whose tasks have all completed, from pool 
21/02/17 01:25:52 INFO DAGScheduler: ResultStage 63 (count at utils.scala:135) finished in 0.006 s
21/02/17 01:25:52 INFO DAGScheduler: Job 50 is finished. Cancelling potential speculative or zombie tasks for this job
21/02/17 01:25:52 INFO TaskSchedulerImpl: Killing all running tasks in stage 63: Stage finished
21/02/17 01:25:52 INFO BlockManagerInfo: Removed broadcast_67_piece0 on localhost:41017 in memory (size: 4.8 KiB, free: 912.2 MiB)
21/02/17 01:25:52 INFO DAGScheduler: Job 50 finished: count at utils.scala:135, took 0.029649 s
21/02/17 01:25:52 INFO BlockManagerInfo: Removed broadcast_76_piece0 on localhost:41017 in memory (size: 2.5 KiB, free: 912.2 MiB)
21/02/17 01:25:52 INFO BlockManagerInfo: Removed broadcast_73_piece0 on localhost:41017 in memory (size: 28.9 KiB, free: 912.2 MiB)
21/02/17 01:25:52 INFO BlockManagerInfo: Removed broadcast_78_piece0 on localhost:41017 in memory (size: 2.5 KiB, free: 912.2 MiB)
21/02/17 01:25:52 INFO BlockManagerInfo: Removed broadcast_72_piece0 on localhost:41017 in memory (size: 30.8 KiB, free: 912.2 MiB)
21/02/17 01:25:53 INFO SparkContext: Starting job: collect at utils.scala:137
21/02/17 01:25:53 INFO DAGScheduler: Got job 51 (collect at utils.scala:137) with 1 output partitions
21/02/17 01:25:53 INFO DAGScheduler: Final stage: ResultStage 64 (collect at utils.scala:137)
21/02/17 01:25:53 INFO DAGScheduler: Parents of final stage: List()
21/02/17 01:25:53 INFO DAGScheduler: Missing parents: List()
21/02/17 01:25:53 INFO DAGScheduler: Submitting ResultStage 64 (MapPartitionsRDD[199] at collect at utils.scala:137), which has no missing parents
21/02/17 01:25:53 INFO MemoryStore: Block broadcast_83 stored as values in memory (estimated size 71.2 KiB, free 912.0 MiB)
21/02/17 01:25:53 INFO MemoryStore: Block broadcast_83_piece0 stored as bytes in memory (estimated size 28.3 KiB, free 911.9 MiB)
21/02/17 01:25:53 INFO BlockManagerInfo: Added broadcast_83_piece0 in memory on localhost:41017 (size: 28.3 KiB, free: 912.2 MiB)
21/02/17 01:25:53 INFO SparkContext: Created broadcast 83 from broadcast at DAGScheduler.scala:1200
21/02/17 01:25:53 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 64 (MapPartitionsRDD[199] at collect at utils.scala:137) (first 15 tasks are for partitions Vector(0))
21/02/17 01:25:53 INFO TaskSchedulerImpl: Adding task set 64.0 with 1 tasks
21/02/17 01:25:53 INFO TaskSetManager: Starting task 0.0 in stage 64.0 (TID 66, localhost, executor driver, partition 0, PROCESS_LOCAL, 18492 bytes)
21/02/17 01:25:53 INFO Executor: Running task 0.0 in stage 64.0 (TID 66)
21/02/17 01:25:53 INFO BlockManager: Found block rdd_23_0 locally
21/02/17 01:25:53 INFO Executor: Finished task 0.0 in stage 64.0 (TID 66). 1912 bytes result sent to driver
21/02/17 01:25:53 INFO TaskSetManager: Finished task 0.0 in stage 64.0 (TID 66) in 30 ms on localhost (executor driver) (1/1)
21/02/17 01:25:53 INFO TaskSchedulerImpl: Removed TaskSet 64.0, whose tasks have all completed, from pool 
21/02/17 01:25:53 INFO DAGScheduler: ResultStage 64 (collect at utils.scala:137) finished in 0.035 s
21/02/17 01:25:53 INFO DAGScheduler: Job 51 is finished. Cancelling potential speculative or zombie tasks for this job
21/02/17 01:25:53 INFO TaskSchedulerImpl: Killing all running tasks in stage 64: Stage finished
21/02/17 01:25:53 INFO DAGScheduler: Job 51 finished: collect at utils.scala:137, took 0.037041 s
21/02/17 01:25:53 INFO SparkContext: Starting job: count at utils.scala:135
21/02/17 01:25:53 INFO DAGScheduler: Registering RDD 201 (count at utils.scala:135) as input to shuffle 14
21/02/17 01:25:53 INFO DAGScheduler: Got job 52 (count at utils.scala:135) with 1 output partitions
21/02/17 01:25:53 INFO DAGScheduler: Final stage: ResultStage 66 (count at utils.scala:135)
21/02/17 01:25:53 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 65)
21/02/17 01:25:53 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 65)
21/02/17 01:25:53 INFO DAGScheduler: Submitting ShuffleMapStage 65 (MapPartitionsRDD[201] at count at utils.scala:135), which has no missing parents
21/02/17 01:25:53 INFO MemoryStore: Block broadcast_84 stored as values in memory (estimated size 72.7 KiB, free 911.9 MiB)
21/02/17 01:25:53 INFO MemoryStore: Block broadcast_84_piece0 stored as bytes in memory (estimated size 29.0 KiB, free 911.8 MiB)
21/02/17 01:25:53 INFO BlockManagerInfo: Added broadcast_84_piece0 in memory on localhost:41017 (size: 29.0 KiB, free: 912.2 MiB)
21/02/17 01:25:53 INFO SparkContext: Created broadcast 84 from broadcast at DAGScheduler.scala:1200
21/02/17 01:25:53 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 65 (MapPartitionsRDD[201] at count at utils.scala:135) (first 15 tasks are for partitions Vector(0))
21/02/17 01:25:53 INFO TaskSchedulerImpl: Adding task set 65.0 with 1 tasks
21/02/17 01:25:53 INFO TaskSetManager: Starting task 0.0 in stage 65.0 (TID 67, localhost, executor driver, partition 0, PROCESS_LOCAL, 18481 bytes)
21/02/17 01:25:53 INFO Executor: Running task 0.0 in stage 65.0 (TID 67)
21/02/17 01:25:53 INFO BlockManager: Found block rdd_23_0 locally
21/02/17 01:25:53 INFO Executor: Finished task 0.0 in stage 65.0 (TID 67). 2253 bytes result sent to driver
21/02/17 01:25:53 INFO TaskSetManager: Finished task 0.0 in stage 65.0 (TID 67) in 23 ms on localhost (executor driver) (1/1)
21/02/17 01:25:53 INFO TaskSchedulerImpl: Removed TaskSet 65.0, whose tasks have all completed, from pool 
21/02/17 01:25:53 INFO DAGScheduler: ShuffleMapStage 65 (count at utils.scala:135) finished in 0.027 s
21/02/17 01:25:53 INFO DAGScheduler: looking for newly runnable stages
21/02/17 01:25:53 INFO DAGScheduler: running: Set()
21/02/17 01:25:53 INFO DAGScheduler: waiting: Set(ResultStage 66)
21/02/17 01:25:53 INFO DAGScheduler: failed: Set()
21/02/17 01:25:53 INFO DAGScheduler: Submitting ResultStage 66 (MapPartitionsRDD[204] at count at utils.scala:135), which has no missing parents
21/02/17 01:25:53 INFO MemoryStore: Block broadcast_85 stored as values in memory (estimated size 10.1 KiB, free 911.8 MiB)
21/02/17 01:25:53 INFO MemoryStore: Block broadcast_85_piece0 stored as bytes in memory (estimated size 5.0 KiB, free 911.8 MiB)
21/02/17 01:25:53 INFO BlockManagerInfo: Added broadcast_85_piece0 in memory on localhost:41017 (size: 5.0 KiB, free: 912.2 MiB)
21/02/17 01:25:53 INFO SparkContext: Created broadcast 85 from broadcast at DAGScheduler.scala:1200
21/02/17 01:25:53 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 66 (MapPartitionsRDD[204] at count at utils.scala:135) (first 15 tasks are for partitions Vector(0))
21/02/17 01:25:53 INFO TaskSchedulerImpl: Adding task set 66.0 with 1 tasks
21/02/17 01:25:53 INFO TaskSetManager: Starting task 0.0 in stage 66.0 (TID 68, localhost, executor driver, partition 0, NODE_LOCAL, 7325 bytes)
21/02/17 01:25:53 INFO Executor: Running task 0.0 in stage 66.0 (TID 68)
21/02/17 01:25:53 INFO ShuffleBlockFetcherIterator: Getting 1 (60.0 B) non-empty blocks including 1 (60.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
21/02/17 01:25:53 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
21/02/17 01:25:53 INFO Executor: Finished task 0.0 in stage 66.0 (TID 68). 2648 bytes result sent to driver
21/02/17 01:25:53 INFO TaskSetManager: Finished task 0.0 in stage 66.0 (TID 68) in 4 ms on localhost (executor driver) (1/1)
21/02/17 01:25:53 INFO TaskSchedulerImpl: Removed TaskSet 66.0, whose tasks have all completed, from pool 
21/02/17 01:25:53 INFO DAGScheduler: ResultStage 66 (count at utils.scala:135) finished in 0.006 s
21/02/17 01:25:53 INFO DAGScheduler: Job 52 is finished. Cancelling potential speculative or zombie tasks for this job
21/02/17 01:25:53 INFO TaskSchedulerImpl: Killing all running tasks in stage 66: Stage finished
21/02/17 01:25:53 INFO DAGScheduler: Job 52 finished: count at utils.scala:135, took 0.036690 s
21/02/17 01:25:55 INFO SparkContext: Invoking stop() from shutdown hook
21/02/17 01:25:55 INFO SparkUI: Stopped Spark web UI at http://localhost:4040
21/02/17 01:25:55 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!
21/02/17 01:25:55 INFO MemoryStore: MemoryStore cleared
21/02/17 01:25:55 INFO BlockManager: BlockManager stopped
21/02/17 01:25:55 INFO BlockManagerMaster: BlockManagerMaster stopped
21/02/17 01:25:55 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!
21/02/17 01:25:55 INFO SparkContext: Successfully stopped SparkContext
21/02/17 01:25:55 INFO ShutdownHookManager: Shutdown hook called
21/02/17 01:25:55 INFO ShutdownHookManager: Deleting directory /tmp/spark-9514903e-b69e-4b6a-a584-f45f8e6233e1
21/02/17 01:25:55 INFO ShutdownHookManager: Deleting directory /tmp/spark-a38c6647-1a67-4a7f-9f82-3ad2a125e026
21/02/17 01:26:10 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
21/02/17 01:26:10 INFO SparkContext: Running Spark version 2.3.0
21/02/17 01:26:10 INFO SparkContext: Submitted application: sparklyr
21/02/17 01:26:10 INFO SecurityManager: Changing view acls to: yitaoli
21/02/17 01:26:10 INFO SecurityManager: Changing modify acls to: yitaoli
21/02/17 01:26:10 INFO SecurityManager: Changing view acls groups to: 
21/02/17 01:26:10 INFO SecurityManager: Changing modify acls groups to: 
21/02/17 01:26:10 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(yitaoli); groups with view permissions: Set(); users  with modify permissions: Set(yitaoli); groups with modify permissions: Set()
21/02/17 01:26:10 INFO Utils: Successfully started service 'sparkDriver' on port 43025.
21/02/17 01:26:10 INFO SparkEnv: Registering MapOutputTracker
21/02/17 01:26:11 INFO SparkEnv: Registering BlockManagerMaster
21/02/17 01:26:11 INFO BlockManagerMasterEndpoint: Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
21/02/17 01:26:11 INFO BlockManagerMasterEndpoint: BlockManagerMasterEndpoint up
21/02/17 01:26:11 INFO DiskBlockManager: Created local directory at /tmp/blockmgr-8882ff19-60a7-423d-9f86-738659cf61d5
21/02/17 01:26:11 INFO MemoryStore: MemoryStore started with capacity 912.3 MB
21/02/17 01:26:11 INFO SparkEnv: Registering OutputCommitCoordinator
21/02/17 01:26:11 INFO Utils: Successfully started service 'SparkUI' on port 4040.
21/02/17 01:26:11 INFO SparkUI: Bound SparkUI to 127.0.0.1, and started at http://localhost:4040
21/02/17 01:26:11 INFO SparkContext: Added JAR file:///home/yitaoli/R/x86_64-pc-linux-gnu-library/4.0/sparkxgb/java/sparkxgb-2.3-2.11.jar at spark://localhost:43025/jars/sparkxgb-2.3-2.11.jar with timestamp 1613525171267
21/02/17 01:26:11 INFO SparkContext: Added JAR file:///home/yitaoli/.ivy2/jars/ml.dmlc_xgboost4j-spark_2.11-1.1.2.jar at spark://localhost:43025/jars/ml.dmlc_xgboost4j-spark_2.11-1.1.2.jar with timestamp 1613525171268
21/02/17 01:26:11 INFO SparkContext: Added JAR file:///home/yitaoli/.ivy2/jars/ml.dmlc_xgboost4j_2.11-1.1.2.jar at spark://localhost:43025/jars/ml.dmlc_xgboost4j_2.11-1.1.2.jar with timestamp 1613525171268
21/02/17 01:26:11 INFO SparkContext: Added JAR file:///home/yitaoli/.ivy2/jars/com.esotericsoftware.kryo_kryo-2.22.jar at spark://localhost:43025/jars/com.esotericsoftware.kryo_kryo-2.22.jar with timestamp 1613525171268
21/02/17 01:26:11 INFO SparkContext: Added JAR file:///home/yitaoli/.ivy2/jars/org.scala-lang_scala-compiler-2.11.12.jar at spark://localhost:43025/jars/org.scala-lang_scala-compiler-2.11.12.jar with timestamp 1613525171268
21/02/17 01:26:11 INFO SparkContext: Added JAR file:///home/yitaoli/.ivy2/jars/org.scala-lang_scala-reflect-2.11.12.jar at spark://localhost:43025/jars/org.scala-lang_scala-reflect-2.11.12.jar with timestamp 1613525171268
21/02/17 01:26:11 INFO SparkContext: Added JAR file:///home/yitaoli/.ivy2/jars/commons-logging_commons-logging-1.2.jar at spark://localhost:43025/jars/commons-logging_commons-logging-1.2.jar with timestamp 1613525171268
21/02/17 01:26:11 INFO SparkContext: Added JAR file:///home/yitaoli/.ivy2/jars/com.typesafe.akka_akka-actor_2.11-2.5.23.jar at spark://localhost:43025/jars/com.typesafe.akka_akka-actor_2.11-2.5.23.jar with timestamp 1613525171269
21/02/17 01:26:11 INFO SparkContext: Added JAR file:///home/yitaoli/.ivy2/jars/com.typesafe_config-1.3.3.jar at spark://localhost:43025/jars/com.typesafe_config-1.3.3.jar with timestamp 1613525171269
21/02/17 01:26:11 INFO SparkContext: Added JAR file:///home/yitaoli/.ivy2/jars/org.scala-lang.modules_scala-java8-compat_2.11-0.7.0.jar at spark://localhost:43025/jars/org.scala-lang.modules_scala-java8-compat_2.11-0.7.0.jar with timestamp 1613525171269
21/02/17 01:26:11 INFO SparkContext: Added JAR file:///home/yitaoli/.ivy2/jars/org.scala-lang.modules_scala-xml_2.11-1.0.5.jar at spark://localhost:43025/jars/org.scala-lang.modules_scala-xml_2.11-1.0.5.jar with timestamp 1613525171269
21/02/17 01:26:11 INFO SparkContext: Added JAR file:///home/yitaoli/.ivy2/jars/org.scala-lang.modules_scala-parser-combinators_2.11-1.0.4.jar at spark://localhost:43025/jars/org.scala-lang.modules_scala-parser-combinators_2.11-1.0.4.jar with timestamp 1613525171269
21/02/17 01:26:11 INFO SparkContext: Added JAR file:/home/yitaoli/R/x86_64-pc-linux-gnu-library/4.0/sparklyr/java/sparklyr-2.3-2.11.jar at spark://localhost:43025/jars/sparklyr-2.3-2.11.jar with timestamp 1613525171269
21/02/17 01:26:11 INFO Executor: Starting executor ID driver on host localhost
21/02/17 01:26:11 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 33095.
21/02/17 01:26:11 INFO NettyBlockTransferService: Server created on localhost:33095
21/02/17 01:26:11 INFO BlockManager: Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
21/02/17 01:26:11 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, localhost, 33095, None)
21/02/17 01:26:11 INFO BlockManagerMasterEndpoint: Registering block manager localhost:33095 with 912.3 MB RAM, BlockManagerId(driver, localhost, 33095, None)
21/02/17 01:26:11 INFO BlockManagerMaster: Registered BlockManager BlockManagerId(driver, localhost, 33095, None)
21/02/17 01:26:11 INFO BlockManager: Initialized BlockManager: BlockManagerId(driver, localhost, 33095, None)
21/02/17 01:26:11 INFO SharedState: loading hive config file: file:/home/yitaoli/spark/spark-2.3.0-bin-hadoop2.7/conf/hive-site.xml
21/02/17 01:26:11 INFO SharedState: Setting hive.metastore.warehouse.dir ('null') to the value of spark.sql.warehouse.dir ('file:/home/yitaoli/sparkxgb/tests/testthat/spark-warehouse').
21/02/17 01:26:11 INFO SharedState: Warehouse path is 'file:/home/yitaoli/sparkxgb/tests/testthat/spark-warehouse'.
21/02/17 01:26:11 INFO StateStoreCoordinatorRef: Registered StateStoreCoordinator endpoint
21/02/17 01:26:12 INFO HiveUtils: Initializing HiveMetastoreConnection version 1.2.1 using Spark classes.
21/02/17 01:26:13 INFO HiveMetaStore: 0: Opening raw store with implemenation class:org.apache.hadoop.hive.metastore.ObjectStore
21/02/17 01:26:13 INFO ObjectStore: ObjectStore, initialize called
21/02/17 01:26:13 INFO Persistence: Property hive.metastore.integral.jdo.pushdown unknown - will be ignored
21/02/17 01:26:13 INFO Persistence: Property datanucleus.cache.level2 unknown - will be ignored
21/02/17 01:26:14 INFO ObjectStore: Setting MetaStore object pin classes with hive.metastore.cache.pinobjtypes="Table,StorageDescriptor,SerDeInfo,Partition,Database,Type,FieldSchema,Order"
21/02/17 01:26:14 INFO Datastore: The class "org.apache.hadoop.hive.metastore.model.MFieldSchema" is tagged as "embedded-only" so does not have its own datastore table.
21/02/17 01:26:14 INFO Datastore: The class "org.apache.hadoop.hive.metastore.model.MOrder" is tagged as "embedded-only" so does not have its own datastore table.
21/02/17 01:26:15 INFO Datastore: The class "org.apache.hadoop.hive.metastore.model.MFieldSchema" is tagged as "embedded-only" so does not have its own datastore table.
21/02/17 01:26:15 INFO Datastore: The class "org.apache.hadoop.hive.metastore.model.MOrder" is tagged as "embedded-only" so does not have its own datastore table.
21/02/17 01:26:15 INFO MetaStoreDirectSql: Using direct SQL, underlying DB is DERBY
21/02/17 01:26:15 INFO ObjectStore: Initialized ObjectStore
21/02/17 01:26:15 WARN ObjectStore: Version information not found in metastore. hive.metastore.schema.verification is not enabled so recording the schema version 1.2.0
21/02/17 01:26:15 WARN ObjectStore: Failed to get database default, returning NoSuchObjectException
21/02/17 01:26:15 INFO HiveMetaStore: Added admin role in metastore
21/02/17 01:26:15 INFO HiveMetaStore: Added public role in metastore
21/02/17 01:26:15 INFO HiveMetaStore: No user is added in admin role, since config is empty
21/02/17 01:26:15 INFO HiveMetaStore: 0: get_all_databases
21/02/17 01:26:15 INFO audit: ugi=yitaoli	ip=unknown-ip-addr	cmd=get_all_databases	
21/02/17 01:26:15 INFO HiveMetaStore: 0: get_functions: db=default pat=*
21/02/17 01:26:15 INFO audit: ugi=yitaoli	ip=unknown-ip-addr	cmd=get_functions: db=default pat=*	
21/02/17 01:26:15 INFO Datastore: The class "org.apache.hadoop.hive.metastore.model.MResourceUri" is tagged as "embedded-only" so does not have its own datastore table.
21/02/17 01:26:15 INFO SessionState: Created local directory: /tmp/99f11ecf-5912-4787-be19-66299179c2d8_resources
21/02/17 01:26:15 INFO SessionState: Created HDFS directory: /tmp/hive/yitaoli/99f11ecf-5912-4787-be19-66299179c2d8
21/02/17 01:26:15 INFO SessionState: Created local directory: /tmp/yitaoli/99f11ecf-5912-4787-be19-66299179c2d8
21/02/17 01:26:15 INFO SessionState: Created HDFS directory: /tmp/hive/yitaoli/99f11ecf-5912-4787-be19-66299179c2d8/_tmp_space.db
21/02/17 01:26:15 INFO HiveClientImpl: Warehouse location for Hive client (version 1.2.2) is file:/home/yitaoli/sparkxgb/tests/testthat/spark-warehouse
21/02/17 01:26:15 INFO HiveMetaStore: 0: get_database: default
21/02/17 01:26:15 INFO audit: ugi=yitaoli	ip=unknown-ip-addr	cmd=get_database: default	
21/02/17 01:26:15 INFO HiveMetaStore: 0: get_database: global_temp
21/02/17 01:26:15 INFO audit: ugi=yitaoli	ip=unknown-ip-addr	cmd=get_database: global_temp	
21/02/17 01:26:15 WARN ObjectStore: Failed to get database global_temp, returning NoSuchObjectException
21/02/17 01:26:15 INFO HiveMetaStore: 0: get_table : db=default tbl=iris
21/02/17 01:26:15 INFO audit: ugi=yitaoli	ip=unknown-ip-addr	cmd=get_table : db=default tbl=iris	
21/02/17 01:26:16 INFO HiveMetaStore: 0: get_database: default
21/02/17 01:26:16 INFO audit: ugi=yitaoli	ip=unknown-ip-addr	cmd=get_database: default	
21/02/17 01:26:16 INFO HiveMetaStore: 0: get_database: default
21/02/17 01:26:16 INFO audit: ugi=yitaoli	ip=unknown-ip-addr	cmd=get_database: default	
21/02/17 01:26:16 INFO HiveMetaStore: 0: get_tables: db=default pat=*
21/02/17 01:26:16 INFO audit: ugi=yitaoli	ip=unknown-ip-addr	cmd=get_tables: db=default pat=*	
21/02/17 01:26:16 INFO SparkContext: Starting job: collect at utils.scala:61
21/02/17 01:26:16 INFO DAGScheduler: Got job 0 (collect at utils.scala:61) with 1 output partitions
21/02/17 01:26:16 INFO DAGScheduler: Final stage: ResultStage 0 (collect at utils.scala:61)
21/02/17 01:26:16 INFO DAGScheduler: Parents of final stage: List()
21/02/17 01:26:16 INFO DAGScheduler: Missing parents: List()
21/02/17 01:26:16 INFO DAGScheduler: Submitting ResultStage 0 (MapPartitionsRDD[4] at map at utils.scala:54), which has no missing parents
21/02/17 01:26:16 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 5.9 KB, free 912.3 MB)
21/02/17 01:26:16 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 3.3 KB, free 912.3 MB)
21/02/17 01:26:16 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on localhost:33095 (size: 3.3 KB, free: 912.3 MB)
21/02/17 01:26:16 INFO SparkContext: Created broadcast 0 from broadcast at DAGScheduler.scala:1039
21/02/17 01:26:16 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 0 (MapPartitionsRDD[4] at map at utils.scala:54) (first 15 tasks are for partitions Vector(0))
21/02/17 01:26:16 INFO TaskSchedulerImpl: Adding task set 0.0 with 1 tasks
21/02/17 01:26:16 INFO TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0, localhost, executor driver, partition 0, PROCESS_LOCAL, 7880 bytes)
21/02/17 01:26:16 INFO Executor: Running task 0.0 in stage 0.0 (TID 0)
21/02/17 01:26:16 INFO Executor: Fetching spark://localhost:43025/jars/sparkxgb-2.3-2.11.jar with timestamp 1613525171267
21/02/17 01:26:16 INFO TransportClientFactory: Successfully created connection to localhost/127.0.0.1:43025 after 11 ms (0 ms spent in bootstraps)
21/02/17 01:26:16 INFO Utils: Fetching spark://localhost:43025/jars/sparkxgb-2.3-2.11.jar to /tmp/spark-ae8699b3-2e18-4a1f-854a-4115adcb4f27/userFiles-c6657642-0222-4c65-9453-5c4900f97804/fetchFileTemp7896947915483076076.tmp
21/02/17 01:26:16 INFO Executor: Adding file:/tmp/spark-ae8699b3-2e18-4a1f-854a-4115adcb4f27/userFiles-c6657642-0222-4c65-9453-5c4900f97804/sparkxgb-2.3-2.11.jar to class loader
21/02/17 01:26:16 INFO Executor: Fetching spark://localhost:43025/jars/org.scala-lang_scala-compiler-2.11.12.jar with timestamp 1613525171268
21/02/17 01:26:16 INFO Utils: Fetching spark://localhost:43025/jars/org.scala-lang_scala-compiler-2.11.12.jar to /tmp/spark-ae8699b3-2e18-4a1f-854a-4115adcb4f27/userFiles-c6657642-0222-4c65-9453-5c4900f97804/fetchFileTemp5406125962091885857.tmp
21/02/17 01:26:16 INFO Executor: Adding file:/tmp/spark-ae8699b3-2e18-4a1f-854a-4115adcb4f27/userFiles-c6657642-0222-4c65-9453-5c4900f97804/org.scala-lang_scala-compiler-2.11.12.jar to class loader
21/02/17 01:26:16 INFO Executor: Fetching spark://localhost:43025/jars/org.scala-lang.modules_scala-xml_2.11-1.0.5.jar with timestamp 1613525171269
21/02/17 01:26:16 INFO Utils: Fetching spark://localhost:43025/jars/org.scala-lang.modules_scala-xml_2.11-1.0.5.jar to /tmp/spark-ae8699b3-2e18-4a1f-854a-4115adcb4f27/userFiles-c6657642-0222-4c65-9453-5c4900f97804/fetchFileTemp4684977251118565785.tmp
21/02/17 01:26:16 INFO Executor: Adding file:/tmp/spark-ae8699b3-2e18-4a1f-854a-4115adcb4f27/userFiles-c6657642-0222-4c65-9453-5c4900f97804/org.scala-lang.modules_scala-xml_2.11-1.0.5.jar to class loader
21/02/17 01:26:16 INFO Executor: Fetching spark://localhost:43025/jars/com.esotericsoftware.kryo_kryo-2.22.jar with timestamp 1613525171268
21/02/17 01:26:16 INFO Utils: Fetching spark://localhost:43025/jars/com.esotericsoftware.kryo_kryo-2.22.jar to /tmp/spark-ae8699b3-2e18-4a1f-854a-4115adcb4f27/userFiles-c6657642-0222-4c65-9453-5c4900f97804/fetchFileTemp1340925408830618331.tmp
21/02/17 01:26:16 INFO Executor: Adding file:/tmp/spark-ae8699b3-2e18-4a1f-854a-4115adcb4f27/userFiles-c6657642-0222-4c65-9453-5c4900f97804/com.esotericsoftware.kryo_kryo-2.22.jar to class loader
21/02/17 01:26:16 INFO Executor: Fetching spark://localhost:43025/jars/ml.dmlc_xgboost4j-spark_2.11-1.1.2.jar with timestamp 1613525171268
21/02/17 01:26:16 INFO Utils: Fetching spark://localhost:43025/jars/ml.dmlc_xgboost4j-spark_2.11-1.1.2.jar to /tmp/spark-ae8699b3-2e18-4a1f-854a-4115adcb4f27/userFiles-c6657642-0222-4c65-9453-5c4900f97804/fetchFileTemp90507808141224242.tmp
21/02/17 01:26:16 INFO Executor: Adding file:/tmp/spark-ae8699b3-2e18-4a1f-854a-4115adcb4f27/userFiles-c6657642-0222-4c65-9453-5c4900f97804/ml.dmlc_xgboost4j-spark_2.11-1.1.2.jar to class loader
21/02/17 01:26:16 INFO Executor: Fetching spark://localhost:43025/jars/sparklyr-2.3-2.11.jar with timestamp 1613525171269
21/02/17 01:26:16 INFO Utils: Fetching spark://localhost:43025/jars/sparklyr-2.3-2.11.jar to /tmp/spark-ae8699b3-2e18-4a1f-854a-4115adcb4f27/userFiles-c6657642-0222-4c65-9453-5c4900f97804/fetchFileTemp8416981381476353823.tmp
21/02/17 01:26:16 INFO Executor: Adding file:/tmp/spark-ae8699b3-2e18-4a1f-854a-4115adcb4f27/userFiles-c6657642-0222-4c65-9453-5c4900f97804/sparklyr-2.3-2.11.jar to class loader
21/02/17 01:26:16 INFO Executor: Fetching spark://localhost:43025/jars/com.typesafe_config-1.3.3.jar with timestamp 1613525171269
21/02/17 01:26:16 INFO Utils: Fetching spark://localhost:43025/jars/com.typesafe_config-1.3.3.jar to /tmp/spark-ae8699b3-2e18-4a1f-854a-4115adcb4f27/userFiles-c6657642-0222-4c65-9453-5c4900f97804/fetchFileTemp6962645067459041425.tmp
21/02/17 01:26:16 INFO Executor: Adding file:/tmp/spark-ae8699b3-2e18-4a1f-854a-4115adcb4f27/userFiles-c6657642-0222-4c65-9453-5c4900f97804/com.typesafe_config-1.3.3.jar to class loader
21/02/17 01:26:16 INFO Executor: Fetching spark://localhost:43025/jars/commons-logging_commons-logging-1.2.jar with timestamp 1613525171268
21/02/17 01:26:16 INFO Utils: Fetching spark://localhost:43025/jars/commons-logging_commons-logging-1.2.jar to /tmp/spark-ae8699b3-2e18-4a1f-854a-4115adcb4f27/userFiles-c6657642-0222-4c65-9453-5c4900f97804/fetchFileTemp352367191182150024.tmp
21/02/17 01:26:16 INFO Executor: Adding file:/tmp/spark-ae8699b3-2e18-4a1f-854a-4115adcb4f27/userFiles-c6657642-0222-4c65-9453-5c4900f97804/commons-logging_commons-logging-1.2.jar to class loader
21/02/17 01:26:16 INFO Executor: Fetching spark://localhost:43025/jars/org.scala-lang.modules_scala-parser-combinators_2.11-1.0.4.jar with timestamp 1613525171269
21/02/17 01:26:16 INFO Utils: Fetching spark://localhost:43025/jars/org.scala-lang.modules_scala-parser-combinators_2.11-1.0.4.jar to /tmp/spark-ae8699b3-2e18-4a1f-854a-4115adcb4f27/userFiles-c6657642-0222-4c65-9453-5c4900f97804/fetchFileTemp8341200687892729630.tmp
21/02/17 01:26:16 INFO Executor: Adding file:/tmp/spark-ae8699b3-2e18-4a1f-854a-4115adcb4f27/userFiles-c6657642-0222-4c65-9453-5c4900f97804/org.scala-lang.modules_scala-parser-combinators_2.11-1.0.4.jar to class loader
21/02/17 01:26:16 INFO Executor: Fetching spark://localhost:43025/jars/ml.dmlc_xgboost4j_2.11-1.1.2.jar with timestamp 1613525171268
21/02/17 01:26:16 INFO Utils: Fetching spark://localhost:43025/jars/ml.dmlc_xgboost4j_2.11-1.1.2.jar to /tmp/spark-ae8699b3-2e18-4a1f-854a-4115adcb4f27/userFiles-c6657642-0222-4c65-9453-5c4900f97804/fetchFileTemp7600389683022555648.tmp
21/02/17 01:26:16 INFO Executor: Adding file:/tmp/spark-ae8699b3-2e18-4a1f-854a-4115adcb4f27/userFiles-c6657642-0222-4c65-9453-5c4900f97804/ml.dmlc_xgboost4j_2.11-1.1.2.jar to class loader
21/02/17 01:26:16 INFO Executor: Fetching spark://localhost:43025/jars/org.scala-lang_scala-reflect-2.11.12.jar with timestamp 1613525171268
21/02/17 01:26:16 INFO Utils: Fetching spark://localhost:43025/jars/org.scala-lang_scala-reflect-2.11.12.jar to /tmp/spark-ae8699b3-2e18-4a1f-854a-4115adcb4f27/userFiles-c6657642-0222-4c65-9453-5c4900f97804/fetchFileTemp1033575869853668071.tmp
21/02/17 01:26:16 INFO Executor: Adding file:/tmp/spark-ae8699b3-2e18-4a1f-854a-4115adcb4f27/userFiles-c6657642-0222-4c65-9453-5c4900f97804/org.scala-lang_scala-reflect-2.11.12.jar to class loader
21/02/17 01:26:16 INFO Executor: Fetching spark://localhost:43025/jars/org.scala-lang.modules_scala-java8-compat_2.11-0.7.0.jar with timestamp 1613525171269
21/02/17 01:26:16 INFO Utils: Fetching spark://localhost:43025/jars/org.scala-lang.modules_scala-java8-compat_2.11-0.7.0.jar to /tmp/spark-ae8699b3-2e18-4a1f-854a-4115adcb4f27/userFiles-c6657642-0222-4c65-9453-5c4900f97804/fetchFileTemp1689103259871804749.tmp
21/02/17 01:26:16 INFO Executor: Adding file:/tmp/spark-ae8699b3-2e18-4a1f-854a-4115adcb4f27/userFiles-c6657642-0222-4c65-9453-5c4900f97804/org.scala-lang.modules_scala-java8-compat_2.11-0.7.0.jar to class loader
21/02/17 01:26:16 INFO Executor: Fetching spark://localhost:43025/jars/com.typesafe.akka_akka-actor_2.11-2.5.23.jar with timestamp 1613525171269
21/02/17 01:26:16 INFO Utils: Fetching spark://localhost:43025/jars/com.typesafe.akka_akka-actor_2.11-2.5.23.jar to /tmp/spark-ae8699b3-2e18-4a1f-854a-4115adcb4f27/userFiles-c6657642-0222-4c65-9453-5c4900f97804/fetchFileTemp4325790958668109548.tmp
21/02/17 01:26:17 INFO Executor: Adding file:/tmp/spark-ae8699b3-2e18-4a1f-854a-4115adcb4f27/userFiles-c6657642-0222-4c65-9453-5c4900f97804/com.typesafe.akka_akka-actor_2.11-2.5.23.jar to class loader
21/02/17 01:26:17 INFO CodeGenerator: Code generated in 153.258832 ms
21/02/17 01:26:17 INFO Executor: Finished task 0.0 in stage 0.0 (TID 0). 1013 bytes result sent to driver
21/02/17 01:26:17 INFO TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in 413 ms on localhost (executor driver) (1/1)
21/02/17 01:26:17 INFO TaskSchedulerImpl: Removed TaskSet 0.0, whose tasks have all completed, from pool 
21/02/17 01:26:17 INFO DAGScheduler: ResultStage 0 (collect at utils.scala:61) finished in 0.506 s
21/02/17 01:26:17 INFO DAGScheduler: Job 0 finished: collect at utils.scala:61, took 0.539743 s
21/02/17 01:26:17 INFO CodeGenerator: Code generated in 8.788936 ms
21/02/17 01:26:17 INFO CodeGenerator: Code generated in 11.861955 ms
21/02/17 01:26:17 INFO SparkContext: Starting job: collect at utils.scala:135
21/02/17 01:26:17 INFO DAGScheduler: Got job 1 (collect at utils.scala:135) with 1 output partitions
21/02/17 01:26:17 INFO DAGScheduler: Final stage: ResultStage 1 (collect at utils.scala:135)
21/02/17 01:26:17 INFO DAGScheduler: Parents of final stage: List()
21/02/17 01:26:17 INFO DAGScheduler: Missing parents: List()
21/02/17 01:26:17 INFO DAGScheduler: Submitting ResultStage 1 (MapPartitionsRDD[9] at collect at utils.scala:135), which has no missing parents
21/02/17 01:26:17 INFO MemoryStore: Block broadcast_1 stored as values in memory (estimated size 6.4 KB, free 912.3 MB)
21/02/17 01:26:17 INFO MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 3.2 KB, free 912.3 MB)
21/02/17 01:26:17 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on localhost:33095 (size: 3.2 KB, free: 912.3 MB)
21/02/17 01:26:17 INFO SparkContext: Created broadcast 1 from broadcast at DAGScheduler.scala:1039
21/02/17 01:26:17 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 1 (MapPartitionsRDD[9] at collect at utils.scala:135) (first 15 tasks are for partitions Vector(0))
21/02/17 01:26:17 INFO TaskSchedulerImpl: Adding task set 1.0 with 1 tasks
21/02/17 01:26:17 INFO TaskSetManager: Starting task 0.0 in stage 1.0 (TID 1, localhost, executor driver, partition 0, PROCESS_LOCAL, 8067 bytes)
21/02/17 01:26:17 INFO Executor: Running task 0.0 in stage 1.0 (TID 1)
21/02/17 01:26:17 INFO CodeGenerator: Code generated in 6.777079 ms
21/02/17 01:26:17 INFO Executor: Finished task 0.0 in stage 1.0 (TID 1). 1286 bytes result sent to driver
21/02/17 01:26:17 INFO TaskSetManager: Finished task 0.0 in stage 1.0 (TID 1) in 21 ms on localhost (executor driver) (1/1)
21/02/17 01:26:17 INFO TaskSchedulerImpl: Removed TaskSet 1.0, whose tasks have all completed, from pool 
21/02/17 01:26:17 INFO DAGScheduler: ResultStage 1 (collect at utils.scala:135) finished in 0.028 s
21/02/17 01:26:17 INFO DAGScheduler: Job 1 finished: collect at utils.scala:135, took 0.030037 s
21/02/17 01:26:17 INFO CodeGenerator: Code generated in 12.296897 ms
21/02/17 01:26:17 INFO CodeGenerator: Code generated in 9.694341 ms
21/02/17 01:26:17 INFO SparkContext: Starting job: count at utils.scala:135
21/02/17 01:26:17 INFO DAGScheduler: Registering RDD 12 (count at utils.scala:135)
21/02/17 01:26:17 INFO DAGScheduler: Got job 2 (count at utils.scala:135) with 1 output partitions
21/02/17 01:26:17 INFO DAGScheduler: Final stage: ResultStage 3 (count at utils.scala:135)
21/02/17 01:26:17 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 2)
21/02/17 01:26:17 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 2)
21/02/17 01:26:17 INFO DAGScheduler: Submitting ShuffleMapStage 2 (MapPartitionsRDD[12] at count at utils.scala:135), which has no missing parents
21/02/17 01:26:17 INFO MemoryStore: Block broadcast_2 stored as values in memory (estimated size 8.9 KB, free 912.3 MB)
21/02/17 01:26:17 INFO MemoryStore: Block broadcast_2_piece0 stored as bytes in memory (estimated size 4.5 KB, free 912.3 MB)
21/02/17 01:26:17 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on localhost:33095 (size: 4.5 KB, free: 912.3 MB)
21/02/17 01:26:17 INFO SparkContext: Created broadcast 2 from broadcast at DAGScheduler.scala:1039
21/02/17 01:26:17 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 2 (MapPartitionsRDD[12] at count at utils.scala:135) (first 15 tasks are for partitions Vector(0))
21/02/17 01:26:17 INFO TaskSchedulerImpl: Adding task set 2.0 with 1 tasks
21/02/17 01:26:17 INFO TaskSetManager: Starting task 0.0 in stage 2.0 (TID 2, localhost, executor driver, partition 0, PROCESS_LOCAL, 8056 bytes)
21/02/17 01:26:17 INFO Executor: Running task 0.0 in stage 2.0 (TID 2)
21/02/17 01:26:17 INFO Executor: Finished task 0.0 in stage 2.0 (TID 2). 1542 bytes result sent to driver
21/02/17 01:26:17 INFO TaskSetManager: Finished task 0.0 in stage 2.0 (TID 2) in 42 ms on localhost (executor driver) (1/1)
21/02/17 01:26:17 INFO TaskSchedulerImpl: Removed TaskSet 2.0, whose tasks have all completed, from pool 
21/02/17 01:26:17 INFO DAGScheduler: ShuffleMapStage 2 (count at utils.scala:135) finished in 0.052 s
21/02/17 01:26:17 INFO DAGScheduler: looking for newly runnable stages
21/02/17 01:26:17 INFO DAGScheduler: running: Set()
21/02/17 01:26:17 INFO DAGScheduler: waiting: Set(ResultStage 3)
21/02/17 01:26:17 INFO DAGScheduler: failed: Set()
21/02/17 01:26:17 INFO DAGScheduler: Submitting ResultStage 3 (MapPartitionsRDD[15] at count at utils.scala:135), which has no missing parents
21/02/17 01:26:17 INFO MemoryStore: Block broadcast_3 stored as values in memory (estimated size 7.3 KB, free 912.3 MB)
21/02/17 01:26:17 INFO MemoryStore: Block broadcast_3_piece0 stored as bytes in memory (estimated size 3.8 KB, free 912.3 MB)
21/02/17 01:26:17 INFO BlockManagerInfo: Added broadcast_3_piece0 in memory on localhost:33095 (size: 3.8 KB, free: 912.3 MB)
21/02/17 01:26:17 INFO SparkContext: Created broadcast 3 from broadcast at DAGScheduler.scala:1039
21/02/17 01:26:17 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 3 (MapPartitionsRDD[15] at count at utils.scala:135) (first 15 tasks are for partitions Vector(0))
21/02/17 01:26:17 INFO TaskSchedulerImpl: Adding task set 3.0 with 1 tasks
21/02/17 01:26:17 INFO TaskSetManager: Starting task 0.0 in stage 3.0 (TID 3, localhost, executor driver, partition 0, NODE_LOCAL, 7754 bytes)
21/02/17 01:26:17 INFO Executor: Running task 0.0 in stage 3.0 (TID 3)
21/02/17 01:26:17 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
21/02/17 01:26:17 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 4 ms
21/02/17 01:26:17 INFO Executor: Finished task 0.0 in stage 3.0 (TID 3). 1782 bytes result sent to driver
21/02/17 01:26:17 INFO TaskSetManager: Finished task 0.0 in stage 3.0 (TID 3) in 29 ms on localhost (executor driver) (1/1)
21/02/17 01:26:17 INFO TaskSchedulerImpl: Removed TaskSet 3.0, whose tasks have all completed, from pool 
21/02/17 01:26:17 INFO DAGScheduler: ResultStage 3 (count at utils.scala:135) finished in 0.038 s
21/02/17 01:26:17 INFO DAGScheduler: Job 2 finished: count at utils.scala:135, took 0.104662 s
21/02/17 01:26:18 INFO SparkContext: Starting job: collect at utils.scala:135
21/02/17 01:26:18 INFO DAGScheduler: Got job 3 (collect at utils.scala:135) with 1 output partitions
21/02/17 01:26:18 INFO DAGScheduler: Final stage: ResultStage 4 (collect at utils.scala:135)
21/02/17 01:26:18 INFO DAGScheduler: Parents of final stage: List()
21/02/17 01:26:18 INFO DAGScheduler: Missing parents: List()
21/02/17 01:26:18 INFO DAGScheduler: Submitting ResultStage 4 (MapPartitionsRDD[20] at collect at utils.scala:135), which has no missing parents
21/02/17 01:26:18 INFO MemoryStore: Block broadcast_4 stored as values in memory (estimated size 6.4 KB, free 912.3 MB)
21/02/17 01:26:18 INFO MemoryStore: Block broadcast_4_piece0 stored as bytes in memory (estimated size 3.2 KB, free 912.2 MB)
21/02/17 01:26:18 INFO BlockManagerInfo: Added broadcast_4_piece0 in memory on localhost:33095 (size: 3.2 KB, free: 912.3 MB)
21/02/17 01:26:18 INFO SparkContext: Created broadcast 4 from broadcast at DAGScheduler.scala:1039
21/02/17 01:26:18 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 4 (MapPartitionsRDD[20] at collect at utils.scala:135) (first 15 tasks are for partitions Vector(0))
21/02/17 01:26:18 INFO TaskSchedulerImpl: Adding task set 4.0 with 1 tasks
21/02/17 01:26:18 INFO TaskSetManager: Starting task 0.0 in stage 4.0 (TID 4, localhost, executor driver, partition 0, PROCESS_LOCAL, 8067 bytes)
21/02/17 01:26:18 INFO Executor: Running task 0.0 in stage 4.0 (TID 4)
21/02/17 01:26:18 INFO Executor: Finished task 0.0 in stage 4.0 (TID 4). 1243 bytes result sent to driver
21/02/17 01:26:18 INFO TaskSetManager: Finished task 0.0 in stage 4.0 (TID 4) in 5 ms on localhost (executor driver) (1/1)
21/02/17 01:26:18 INFO TaskSchedulerImpl: Removed TaskSet 4.0, whose tasks have all completed, from pool 
21/02/17 01:26:18 INFO DAGScheduler: ResultStage 4 (collect at utils.scala:135) finished in 0.010 s
21/02/17 01:26:18 INFO DAGScheduler: Job 3 finished: collect at utils.scala:135, took 0.012963 s
21/02/17 01:26:18 INFO SparkContext: Starting job: count at utils.scala:135
21/02/17 01:26:18 INFO DAGScheduler: Registering RDD 23 (count at utils.scala:135)
21/02/17 01:26:18 INFO DAGScheduler: Got job 4 (count at utils.scala:135) with 1 output partitions
21/02/17 01:26:18 INFO DAGScheduler: Final stage: ResultStage 6 (count at utils.scala:135)
21/02/17 01:26:18 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 5)
21/02/17 01:26:18 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 5)
21/02/17 01:26:18 INFO DAGScheduler: Submitting ShuffleMapStage 5 (MapPartitionsRDD[23] at count at utils.scala:135), which has no missing parents
21/02/17 01:26:18 INFO MemoryStore: Block broadcast_5 stored as values in memory (estimated size 8.9 KB, free 912.2 MB)
21/02/17 01:26:18 INFO MemoryStore: Block broadcast_5_piece0 stored as bytes in memory (estimated size 4.5 KB, free 912.2 MB)
21/02/17 01:26:18 INFO BlockManagerInfo: Added broadcast_5_piece0 in memory on localhost:33095 (size: 4.5 KB, free: 912.3 MB)
21/02/17 01:26:18 INFO SparkContext: Created broadcast 5 from broadcast at DAGScheduler.scala:1039
21/02/17 01:26:18 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 5 (MapPartitionsRDD[23] at count at utils.scala:135) (first 15 tasks are for partitions Vector(0))
21/02/17 01:26:18 INFO TaskSchedulerImpl: Adding task set 5.0 with 1 tasks
21/02/17 01:26:18 INFO TaskSetManager: Starting task 0.0 in stage 5.0 (TID 5, localhost, executor driver, partition 0, PROCESS_LOCAL, 8056 bytes)
21/02/17 01:26:18 INFO Executor: Running task 0.0 in stage 5.0 (TID 5)
21/02/17 01:26:18 INFO Executor: Finished task 0.0 in stage 5.0 (TID 5). 1499 bytes result sent to driver
21/02/17 01:26:18 INFO TaskSetManager: Finished task 0.0 in stage 5.0 (TID 5) in 5 ms on localhost (executor driver) (1/1)
21/02/17 01:26:18 INFO TaskSchedulerImpl: Removed TaskSet 5.0, whose tasks have all completed, from pool 
21/02/17 01:26:18 INFO DAGScheduler: ShuffleMapStage 5 (count at utils.scala:135) finished in 0.013 s
21/02/17 01:26:18 INFO DAGScheduler: looking for newly runnable stages
21/02/17 01:26:18 INFO DAGScheduler: running: Set()
21/02/17 01:26:18 INFO DAGScheduler: waiting: Set(ResultStage 6)
21/02/17 01:26:18 INFO DAGScheduler: failed: Set()
21/02/17 01:26:18 INFO DAGScheduler: Submitting ResultStage 6 (MapPartitionsRDD[26] at count at utils.scala:135), which has no missing parents
21/02/17 01:26:18 INFO MemoryStore: Block broadcast_6 stored as values in memory (estimated size 7.3 KB, free 912.2 MB)
21/02/17 01:26:18 INFO MemoryStore: Block broadcast_6_piece0 stored as bytes in memory (estimated size 3.8 KB, free 912.2 MB)
21/02/17 01:26:18 INFO BlockManagerInfo: Added broadcast_6_piece0 in memory on localhost:33095 (size: 3.8 KB, free: 912.3 MB)
21/02/17 01:26:18 INFO SparkContext: Created broadcast 6 from broadcast at DAGScheduler.scala:1039
21/02/17 01:26:18 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 6 (MapPartitionsRDD[26] at count at utils.scala:135) (first 15 tasks are for partitions Vector(0))
21/02/17 01:26:18 INFO TaskSchedulerImpl: Adding task set 6.0 with 1 tasks
21/02/17 01:26:18 INFO TaskSetManager: Starting task 0.0 in stage 6.0 (TID 6, localhost, executor driver, partition 0, NODE_LOCAL, 7754 bytes)
21/02/17 01:26:18 INFO Executor: Running task 0.0 in stage 6.0 (TID 6)
21/02/17 01:26:18 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
21/02/17 01:26:18 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
21/02/17 01:26:18 INFO Executor: Finished task 0.0 in stage 6.0 (TID 6). 1739 bytes result sent to driver
21/02/17 01:26:18 INFO TaskSetManager: Finished task 0.0 in stage 6.0 (TID 6) in 4 ms on localhost (executor driver) (1/1)
21/02/17 01:26:18 INFO TaskSchedulerImpl: Removed TaskSet 6.0, whose tasks have all completed, from pool 
21/02/17 01:26:18 INFO DAGScheduler: ResultStage 6 (count at utils.scala:135) finished in 0.009 s
21/02/17 01:26:18 INFO DAGScheduler: Job 4 finished: count at utils.scala:135, took 0.025711 s
21/02/17 01:26:18 INFO ContextCleaner: Cleaned accumulator 125
21/02/17 01:26:18 INFO ContextCleaner: Cleaned accumulator 18
21/02/17 01:26:18 INFO ContextCleaner: Cleaned accumulator 197
21/02/17 01:26:18 INFO ContextCleaner: Cleaned accumulator 114
21/02/17 01:26:18 INFO ContextCleaner: Cleaned accumulator 10
21/02/17 01:26:18 INFO ContextCleaner: Cleaned accumulator 94
21/02/17 01:26:18 INFO ContextCleaner: Cleaned accumulator 33
21/02/17 01:26:18 INFO ContextCleaner: Cleaned accumulator 176
21/02/17 01:26:18 INFO BlockManagerInfo: Removed broadcast_0_piece0 on localhost:33095 in memory (size: 3.3 KB, free: 912.3 MB)
21/02/17 01:26:18 INFO ContextCleaner: Cleaned accumulator 82
21/02/17 01:26:18 INFO ContextCleaner: Cleaned accumulator 102
21/02/17 01:26:18 INFO ContextCleaner: Cleaned accumulator 193
21/02/17 01:26:18 INFO ContextCleaner: Cleaned accumulator 107
21/02/17 01:26:18 INFO ContextCleaner: Cleaned accumulator 87
21/02/17 01:26:18 INFO ContextCleaner: Cleaned accumulator 56
21/02/17 01:26:18 INFO ContextCleaner: Cleaned accumulator 149
21/02/17 01:26:18 INFO ContextCleaner: Cleaned accumulator 79
21/02/17 01:26:18 INFO ContextCleaner: Cleaned accumulator 68
21/02/17 01:26:18 INFO ContextCleaner: Cleaned accumulator 36
21/02/17 01:26:18 INFO ContextCleaner: Cleaned accumulator 104
21/02/17 01:26:18 INFO ContextCleaner: Cleaned accumulator 11
21/02/17 01:26:18 INFO ContextCleaner: Cleaned accumulator 24
21/02/17 01:26:18 INFO ContextCleaner: Cleaned accumulator 198
21/02/17 01:26:18 INFO ContextCleaner: Cleaned accumulator 76
21/02/17 01:26:18 INFO ContextCleaner: Cleaned accumulator 14
21/02/17 01:26:18 INFO ContextCleaner: Cleaned accumulator 203
21/02/17 01:26:18 INFO ContextCleaner: Cleaned accumulator 16
21/02/17 01:26:18 INFO ContextCleaner: Cleaned accumulator 190
21/02/17 01:26:18 INFO ContextCleaner: Cleaned accumulator 91
21/02/17 01:26:18 INFO ContextCleaner: Cleaned accumulator 28
21/02/17 01:26:18 INFO ContextCleaner: Cleaned accumulator 165
21/02/17 01:26:18 INFO ContextCleaner: Cleaned accumulator 128
21/02/17 01:26:18 INFO ContextCleaner: Cleaned shuffle 0
21/02/17 01:26:18 INFO ContextCleaner: Cleaned accumulator 90
21/02/17 01:26:18 INFO ContextCleaner: Cleaned accumulator 101
21/02/17 01:26:18 INFO ContextCleaner: Cleaned accumulator 49
21/02/17 01:26:18 INFO ContextCleaner: Cleaned accumulator 127
21/02/17 01:26:18 INFO ContextCleaner: Cleaned accumulator 155
21/02/17 01:26:18 INFO ContextCleaner: Cleaned accumulator 61
21/02/17 01:26:18 INFO ContextCleaner: Cleaned accumulator 109
21/02/17 01:26:18 INFO ContextCleaner: Cleaned accumulator 45
21/02/17 01:26:18 INFO ContextCleaner: Cleaned accumulator 29
21/02/17 01:26:18 INFO ContextCleaner: Cleaned accumulator 78
21/02/17 01:26:18 INFO ContextCleaner: Cleaned accumulator 98
21/02/17 01:26:18 INFO ContextCleaner: Cleaned accumulator 95
21/02/17 01:26:18 INFO ContextCleaner: Cleaned accumulator 115
21/02/17 01:26:18 INFO ContextCleaner: Cleaned accumulator 210
21/02/17 01:26:18 INFO ContextCleaner: Cleaned accumulator 144
21/02/17 01:26:18 INFO ContextCleaner: Cleaned accumulator 161
21/02/17 01:26:18 INFO ContextCleaner: Cleaned accumulator 202
21/02/17 01:26:18 INFO ContextCleaner: Cleaned accumulator 206
21/02/17 01:26:18 INFO ContextCleaner: Cleaned accumulator 209
21/02/17 01:26:18 INFO ContextCleaner: Cleaned shuffle 1
21/02/17 01:26:18 INFO ContextCleaner: Cleaned accumulator 184
21/02/17 01:26:18 INFO ContextCleaner: Cleaned accumulator 136
21/02/17 01:26:18 INFO ContextCleaner: Cleaned accumulator 145
21/02/17 01:26:18 INFO ContextCleaner: Cleaned accumulator 160
21/02/17 01:26:18 INFO ContextCleaner: Cleaned accumulator 96
21/02/17 01:26:18 INFO ContextCleaner: Cleaned accumulator 103
21/02/17 01:26:18 INFO ContextCleaner: Cleaned accumulator 89
21/02/17 01:26:18 INFO ContextCleaner: Cleaned accumulator 8
21/02/17 01:26:18 INFO BlockManagerInfo: Removed broadcast_6_piece0 on localhost:33095 in memory (size: 3.8 KB, free: 912.3 MB)
21/02/17 01:26:18 INFO ContextCleaner: Cleaned accumulator 2
21/02/17 01:26:18 INFO ContextCleaner: Cleaned accumulator 120
21/02/17 01:26:18 INFO ContextCleaner: Cleaned accumulator 154
21/02/17 01:26:18 INFO ContextCleaner: Cleaned accumulator 147
21/02/17 01:26:18 INFO ContextCleaner: Cleaned accumulator 27
21/02/17 01:26:18 INFO ContextCleaner: Cleaned accumulator 175
21/02/17 01:26:18 INFO ContextCleaner: Cleaned accumulator 180
21/02/17 01:26:18 INFO ContextCleaner: Cleaned accumulator 122
21/02/17 01:26:18 INFO ContextCleaner: Cleaned accumulator 112
21/02/17 01:26:18 INFO ContextCleaner: Cleaned accumulator 167
21/02/17 01:26:18 INFO ContextCleaner: Cleaned accumulator 191
21/02/17 01:26:18 INFO ContextCleaner: Cleaned accumulator 66
21/02/17 01:26:18 INFO ContextCleaner: Cleaned accumulator 142
21/02/17 01:26:18 INFO ContextCleaner: Cleaned accumulator 39
21/02/17 01:26:18 INFO ContextCleaner: Cleaned accumulator 116
21/02/17 01:26:18 INFO ContextCleaner: Cleaned accumulator 43
21/02/17 01:26:18 INFO ContextCleaner: Cleaned accumulator 105
21/02/17 01:26:18 INFO BlockManagerInfo: Removed broadcast_3_piece0 on localhost:33095 in memory (size: 3.8 KB, free: 912.3 MB)
21/02/17 01:26:18 INFO ContextCleaner: Cleaned accumulator 139
21/02/17 01:26:18 INFO ContextCleaner: Cleaned accumulator 93
21/02/17 01:26:18 INFO ContextCleaner: Cleaned accumulator 204
21/02/17 01:26:18 INFO ContextCleaner: Cleaned accumulator 6
21/02/17 01:26:18 INFO ContextCleaner: Cleaned accumulator 172
21/02/17 01:26:18 INFO ContextCleaner: Cleaned accumulator 21
21/02/17 01:26:18 INFO ContextCleaner: Cleaned accumulator 17
21/02/17 01:26:18 INFO ContextCleaner: Cleaned accumulator 38
21/02/17 01:26:18 INFO ContextCleaner: Cleaned accumulator 200
21/02/17 01:26:18 INFO ContextCleaner: Cleaned accumulator 185
21/02/17 01:26:18 INFO ContextCleaner: Cleaned accumulator 131
21/02/17 01:26:18 INFO ContextCleaner: Cleaned accumulator 41
21/02/17 01:26:18 INFO ContextCleaner: Cleaned accumulator 58
21/02/17 01:26:18 INFO ContextCleaner: Cleaned accumulator 99
21/02/17 01:26:18 INFO ContextCleaner: Cleaned accumulator 126
21/02/17 01:26:18 INFO ContextCleaner: Cleaned accumulator 173
21/02/17 01:26:18 INFO ContextCleaner: Cleaned accumulator 51
21/02/17 01:26:18 INFO ContextCleaner: Cleaned accumulator 158
21/02/17 01:26:18 INFO ContextCleaner: Cleaned accumulator 20
21/02/17 01:26:18 INFO BlockManagerInfo: Removed broadcast_5_piece0 on localhost:33095 in memory (size: 4.5 KB, free: 912.3 MB)
21/02/17 01:26:18 INFO ContextCleaner: Cleaned accumulator 44
21/02/17 01:26:18 INFO ContextCleaner: Cleaned accumulator 74
21/02/17 01:26:18 INFO ContextCleaner: Cleaned accumulator 194
21/02/17 01:26:18 INFO ContextCleaner: Cleaned accumulator 170
21/02/17 01:26:18 INFO ContextCleaner: Cleaned accumulator 80
21/02/17 01:26:18 INFO ContextCleaner: Cleaned accumulator 153
21/02/17 01:26:18 INFO ContextCleaner: Cleaned accumulator 132
21/02/17 01:26:18 INFO ContextCleaner: Cleaned accumulator 84
21/02/17 01:26:18 INFO ContextCleaner: Cleaned accumulator 164
21/02/17 01:26:18 INFO ContextCleaner: Cleaned accumulator 71
21/02/17 01:26:18 INFO ContextCleaner: Cleaned accumulator 159
21/02/17 01:26:18 INFO ContextCleaner: Cleaned accumulator 174
21/02/17 01:26:18 INFO ContextCleaner: Cleaned accumulator 23
21/02/17 01:26:18 INFO ContextCleaner: Cleaned accumulator 140
21/02/17 01:26:18 INFO ContextCleaner: Cleaned accumulator 12
21/02/17 01:26:18 INFO ContextCleaner: Cleaned accumulator 143
21/02/17 01:26:18 INFO ContextCleaner: Cleaned accumulator 181
21/02/17 01:26:18 INFO ContextCleaner: Cleaned accumulator 52
21/02/17 01:26:18 INFO ContextCleaner: Cleaned accumulator 211
21/02/17 01:26:18 INFO ContextCleaner: Cleaned accumulator 54
21/02/17 01:26:18 INFO ContextCleaner: Cleaned accumulator 15
21/02/17 01:26:18 INFO ContextCleaner: Cleaned accumulator 72
21/02/17 01:26:18 INFO ContextCleaner: Cleaned accumulator 26
21/02/17 01:26:18 INFO ContextCleaner: Cleaned accumulator 70
21/02/17 01:26:18 INFO BlockManagerInfo: Removed broadcast_4_piece0 on localhost:33095 in memory (size: 3.2 KB, free: 912.3 MB)
21/02/17 01:26:18 INFO ContextCleaner: Cleaned accumulator 157
21/02/17 01:26:18 INFO ContextCleaner: Cleaned accumulator 35
21/02/17 01:26:18 INFO ContextCleaner: Cleaned accumulator 7
21/02/17 01:26:18 INFO ContextCleaner: Cleaned accumulator 92
21/02/17 01:26:18 INFO ContextCleaner: Cleaned accumulator 138
21/02/17 01:26:18 INFO ContextCleaner: Cleaned accumulator 207
21/02/17 01:26:18 INFO ContextCleaner: Cleaned accumulator 188
21/02/17 01:26:18 INFO ContextCleaner: Cleaned accumulator 81
21/02/17 01:26:18 INFO ContextCleaner: Cleaned accumulator 162
21/02/17 01:26:18 INFO ContextCleaner: Cleaned accumulator 97
21/02/17 01:26:18 INFO ContextCleaner: Cleaned accumulator 201
21/02/17 01:26:18 INFO ContextCleaner: Cleaned accumulator 19
21/02/17 01:26:18 INFO ContextCleaner: Cleaned accumulator 156
21/02/17 01:26:18 INFO ContextCleaner: Cleaned accumulator 199
21/02/17 01:26:18 INFO ContextCleaner: Cleaned accumulator 169
21/02/17 01:26:18 INFO ContextCleaner: Cleaned accumulator 64
21/02/17 01:26:18 INFO ContextCleaner: Cleaned accumulator 135
21/02/17 01:26:18 INFO ContextCleaner: Cleaned accumulator 192
21/02/17 01:26:18 INFO ContextCleaner: Cleaned accumulator 208
21/02/17 01:26:18 INFO ContextCleaner: Cleaned accumulator 186
21/02/17 01:26:18 INFO ContextCleaner: Cleaned accumulator 205
21/02/17 01:26:18 INFO ContextCleaner: Cleaned accumulator 5
21/02/17 01:26:18 INFO ContextCleaner: Cleaned accumulator 137
21/02/17 01:26:18 INFO ContextCleaner: Cleaned accumulator 40
21/02/17 01:26:18 INFO ContextCleaner: Cleaned accumulator 151
21/02/17 01:26:18 INFO ContextCleaner: Cleaned accumulator 88
21/02/17 01:26:18 INFO ContextCleaner: Cleaned accumulator 196
21/02/17 01:26:18 INFO ContextCleaner: Cleaned accumulator 148
21/02/17 01:26:18 INFO ContextCleaner: Cleaned accumulator 57
21/02/17 01:26:18 INFO ContextCleaner: Cleaned accumulator 4
21/02/17 01:26:18 INFO ContextCleaner: Cleaned accumulator 77
21/02/17 01:26:18 INFO ContextCleaner: Cleaned accumulator 55
21/02/17 01:26:18 INFO ContextCleaner: Cleaned accumulator 32
21/02/17 01:26:18 INFO ContextCleaner: Cleaned accumulator 124
21/02/17 01:26:18 INFO ContextCleaner: Cleaned accumulator 100
21/02/17 01:26:18 INFO ContextCleaner: Cleaned accumulator 166
21/02/17 01:26:18 INFO ContextCleaner: Cleaned accumulator 67
21/02/17 01:26:18 INFO ContextCleaner: Cleaned accumulator 163
21/02/17 01:26:18 INFO ContextCleaner: Cleaned accumulator 62
21/02/17 01:26:18 INFO ContextCleaner: Cleaned accumulator 60
21/02/17 01:26:18 INFO ContextCleaner: Cleaned accumulator 168
21/02/17 01:26:18 INFO ContextCleaner: Cleaned accumulator 73
21/02/17 01:26:18 INFO ContextCleaner: Cleaned accumulator 3
21/02/17 01:26:18 INFO ContextCleaner: Cleaned accumulator 178
21/02/17 01:26:18 INFO ContextCleaner: Cleaned accumulator 30
21/02/17 01:26:18 INFO ContextCleaner: Cleaned accumulator 46
21/02/17 01:26:18 INFO ContextCleaner: Cleaned accumulator 152
21/02/17 01:26:18 INFO ContextCleaner: Cleaned accumulator 150
21/02/17 01:26:18 INFO ContextCleaner: Cleaned accumulator 85
21/02/17 01:26:18 INFO ContextCleaner: Cleaned accumulator 187
21/02/17 01:26:18 INFO ContextCleaner: Cleaned accumulator 83
21/02/17 01:26:18 INFO ContextCleaner: Cleaned accumulator 182
21/02/17 01:26:18 INFO ContextCleaner: Cleaned accumulator 141
21/02/17 01:26:18 INFO ContextCleaner: Cleaned accumulator 37
21/02/17 01:26:18 INFO ContextCleaner: Cleaned accumulator 177
21/02/17 01:26:18 INFO ContextCleaner: Cleaned accumulator 110
21/02/17 01:26:18 INFO ContextCleaner: Cleaned accumulator 75
21/02/17 01:26:18 INFO ContextCleaner: Cleaned accumulator 108
21/02/17 01:26:18 INFO ContextCleaner: Cleaned accumulator 133
21/02/17 01:26:18 INFO ContextCleaner: Cleaned accumulator 130
21/02/17 01:26:18 INFO ContextCleaner: Cleaned accumulator 50
21/02/17 01:26:18 INFO ContextCleaner: Cleaned accumulator 171
21/02/17 01:26:18 INFO ContextCleaner: Cleaned accumulator 69
21/02/17 01:26:18 INFO ContextCleaner: Cleaned accumulator 59
21/02/17 01:26:18 INFO ContextCleaner: Cleaned accumulator 53
21/02/17 01:26:18 INFO ContextCleaner: Cleaned accumulator 106
21/02/17 01:26:18 INFO ContextCleaner: Cleaned accumulator 22
21/02/17 01:26:18 INFO ContextCleaner: Cleaned accumulator 134
21/02/17 01:26:18 INFO ContextCleaner: Cleaned accumulator 189
21/02/17 01:26:18 INFO ContextCleaner: Cleaned accumulator 117
21/02/17 01:26:18 INFO ContextCleaner: Cleaned accumulator 121
21/02/17 01:26:18 INFO ContextCleaner: Cleaned accumulator 65
21/02/17 01:26:18 INFO ContextCleaner: Cleaned accumulator 195
21/02/17 01:26:18 INFO ContextCleaner: Cleaned accumulator 129
21/02/17 01:26:18 INFO ContextCleaner: Cleaned accumulator 113
21/02/17 01:26:18 INFO ContextCleaner: Cleaned accumulator 123
21/02/17 01:26:18 INFO BlockManagerInfo: Removed broadcast_1_piece0 on localhost:33095 in memory (size: 3.2 KB, free: 912.3 MB)
21/02/17 01:26:18 INFO ContextCleaner: Cleaned accumulator 48
21/02/17 01:26:18 INFO ContextCleaner: Cleaned accumulator 183
21/02/17 01:26:18 INFO ContextCleaner: Cleaned accumulator 13
21/02/17 01:26:18 INFO ContextCleaner: Cleaned accumulator 47
21/02/17 01:26:18 INFO ContextCleaner: Cleaned accumulator 34
21/02/17 01:26:18 INFO ContextCleaner: Cleaned accumulator 1
21/02/17 01:26:18 INFO ContextCleaner: Cleaned accumulator 86
21/02/17 01:26:18 INFO ContextCleaner: Cleaned accumulator 111
21/02/17 01:26:18 INFO ContextCleaner: Cleaned accumulator 31
21/02/17 01:26:18 INFO ContextCleaner: Cleaned accumulator 146
21/02/17 01:26:18 INFO ContextCleaner: Cleaned accumulator 63
21/02/17 01:26:18 INFO BlockManagerInfo: Removed broadcast_2_piece0 on localhost:33095 in memory (size: 4.5 KB, free: 912.3 MB)
21/02/17 01:26:18 INFO ContextCleaner: Cleaned accumulator 179
21/02/17 01:26:18 INFO ContextCleaner: Cleaned accumulator 25
21/02/17 01:26:18 INFO ContextCleaner: Cleaned accumulator 9
21/02/17 01:26:18 INFO ContextCleaner: Cleaned accumulator 42
21/02/17 01:26:18 INFO CodeGenerator: Code generated in 45.144143 ms
21/02/17 01:26:18 INFO XGBoostSpark: Running XGBoost 1.1.2 with parameters:
alpha -> 0.0
min_child_weight -> 1.0
sample_type -> uniform
base_score -> 0.5
rabit_timeout -> -1
colsample_bylevel -> 1.0
grow_policy -> depthwise
skip_drop -> 0.0
lambda_bias -> 0.0
silent -> 0
scale_pos_weight -> 1.0
seed -> 0
cache_training_set -> false
features_col -> features
num_early_stopping_rounds -> 0
label_col -> label
num_workers -> 1
subsample -> 1.0
lambda -> 1.0
max_depth -> 6
tree_limit -> 0
custom_eval -> null
dmlc_worker_connect_retry -> 5
rate_drop -> 0.0
max_bin -> 16
train_test_ratio -> 1.0
use_external_memory -> false
objective -> reg:linear
eval_metric -> rmse
num_round -> 1
maximize_evaluation_metrics -> false
timeout_request_workers -> 1800000
missing -> NaN
rabit_ring_reduce_threshold -> 32768
checkpoint_path -> 
tracker_conf -> TrackerConf(0,python)
tree_method -> auto
max_delta_step -> 0.0
eta -> 0.3
verbosity -> 1
colsample_bytree -> 1.0
objective_type -> regression
normalize_type -> tree
allow_non_zero_for_missing -> false
custom_obj -> null
gamma -> 0.0
sketch_eps -> 0.03
nthread -> 1
prediction_col -> prediction
checkpoint_interval -> -1
21/02/17 01:26:18 WARN XGBoostSpark: train_test_ratio is deprecated since XGBoost 0.82, we recommend to explicitly pass a training and multiple evaluation datasets by passing 'eval_sets' and 'eval_set_names'
21/02/17 01:26:18 INFO RabitTracker$TrackerProcessLogger: 2021-02-17 01:26:18,984 INFO start listen on 192.168.2.12:9091
21/02/17 01:26:19 INFO XGBoostSpark: starting training with timeout set as 1800000 ms for waiting for resources
21/02/17 01:26:19 INFO SparkContext: Starting job: foreachPartition at XGBoost.scala:565
21/02/17 01:26:19 INFO DAGScheduler: Got job 5 (foreachPartition at XGBoost.scala:565) with 1 output partitions
21/02/17 01:26:19 INFO DAGScheduler: Final stage: ResultStage 7 (foreachPartition at XGBoost.scala:565)
21/02/17 01:26:19 INFO DAGScheduler: Parents of final stage: List()
21/02/17 01:26:19 INFO DAGScheduler: Missing parents: List()
21/02/17 01:26:19 INFO DAGScheduler: Submitting ResultStage 7 (MapPartitionsRDD[35] at mapPartitions at XGBoost.scala:450), which has no missing parents
21/02/17 01:26:19 INFO MemoryStore: Block broadcast_7 stored as values in memory (estimated size 33.9 KB, free 912.3 MB)
21/02/17 01:26:19 INFO MemoryStore: Block broadcast_7_piece0 stored as bytes in memory (estimated size 14.2 KB, free 912.3 MB)
21/02/17 01:26:19 INFO BlockManagerInfo: Added broadcast_7_piece0 in memory on localhost:33095 (size: 14.2 KB, free: 912.3 MB)
21/02/17 01:26:19 INFO SparkContext: Created broadcast 7 from broadcast at DAGScheduler.scala:1039
21/02/17 01:26:19 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 7 (MapPartitionsRDD[35] at mapPartitions at XGBoost.scala:450) (first 15 tasks are for partitions Vector(0))
21/02/17 01:26:19 INFO TaskSchedulerImpl: Adding task set 7.0 with 1 tasks
21/02/17 01:26:19 INFO TaskSetManager: Starting task 0.0 in stage 7.0 (TID 7, localhost, executor driver, partition 0, PROCESS_LOCAL, 18998 bytes)
21/02/17 01:26:19 INFO Executor: Running task 0.0 in stage 7.0 (TID 7)
21/02/17 01:26:19 INFO CodeGenerator: Code generated in 12.950358 ms
21/02/17 01:26:19 INFO MemoryStore: Block rdd_17_0 stored as values in memory (estimated size 5.6 KB, free 912.2 MB)
21/02/17 01:26:19 INFO BlockManagerInfo: Added rdd_17_0 in memory on localhost:33095 (size: 5.6 KB, free: 912.3 MB)
21/02/17 01:26:19 INFO CodeGenerator: Code generated in 3.372707 ms
21/02/17 01:26:19 INFO CodeGenerator: Code generated in 22.446556 ms
21/02/17 01:26:19 INFO CodeGenerator: Code generated in 10.490341 ms
21/02/17 01:26:19 INFO RabitTracker$TrackerProcessLogger: /tmp/tracker5807438410003031057.py:330: DeprecationWarning: isAlive() is deprecated, use is_alive() instead
21/02/17 01:26:19 INFO RabitTracker$TrackerProcessLogger:   while self.thread.isAlive():
21/02/17 01:26:19 INFO RabitTracker$TrackerProcessLogger: 2021-02-17 01:26:19,276 DEBUG Recieve start signal from 192.168.2.12; assign rank 0
21/02/17 01:26:19 INFO RabitTracker$TrackerProcessLogger: 2021-02-17 01:26:19,276 INFO @tracker All of 1 nodes getting started
21/02/17 01:26:19 INFO RabitTracker$TrackerProcessLogger: 2021-02-17 01:26:19,284 INFO [0]	train-rmse:2.633044
21/02/17 01:26:19 INFO RabitTracker$TrackerProcessLogger: 2021-02-17 01:26:19,284 DEBUG Recieve shutdown signal from 0
21/02/17 01:26:19 INFO RabitTracker$TrackerProcessLogger: 2021-02-17 01:26:19,285 INFO @tracker All nodes finishes job
21/02/17 01:26:19 INFO RabitTracker$TrackerProcessLogger: 2021-02-17 01:26:19,285 INFO @tracker 0.008493900299072266 secs between node start and job finish
21/02/17 01:26:19 INFO MemoryStore: Block rdd_35_0 stored as values in memory (estimated size 192.0 B, free 912.2 MB)
21/02/17 01:26:19 INFO BlockManagerInfo: Added rdd_35_0 in memory on localhost:33095 (size: 192.0 B, free: 912.3 MB)
21/02/17 01:26:19 INFO RabitTracker$TrackerProcessLogger: Tracker Process ends with exit code 0
21/02/17 01:26:19 INFO RabitTracker: Tracker Process ends with exit code 0
21/02/17 01:26:19 INFO XGBoostSpark: Rabit returns with exit code 0
21/02/17 01:26:19 INFO Executor: 1 block locks were not released by TID = 7:
[rdd_35_0]
21/02/17 01:26:19 INFO Executor: Finished task 0.0 in stage 7.0 (TID 7). 1260 bytes result sent to driver
21/02/17 01:26:19 INFO TaskSetManager: Finished task 0.0 in stage 7.0 (TID 7) in 238 ms on localhost (executor driver) (1/1)
21/02/17 01:26:19 INFO TaskSchedulerImpl: Removed TaskSet 7.0, whose tasks have all completed, from pool 
21/02/17 01:26:19 INFO DAGScheduler: ResultStage 7 (foreachPartition at XGBoost.scala:565) finished in 0.282 s
21/02/17 01:26:19 INFO DAGScheduler: Job 5 finished: foreachPartition at XGBoost.scala:565, took 0.287798 s
21/02/17 01:26:19 INFO SparkContext: Starting job: first at XGBoost.scala:685
21/02/17 01:26:19 INFO DAGScheduler: Got job 6 (first at XGBoost.scala:685) with 1 output partitions
21/02/17 01:26:19 INFO DAGScheduler: Final stage: ResultStage 8 (first at XGBoost.scala:685)
21/02/17 01:26:19 INFO DAGScheduler: Parents of final stage: List()
21/02/17 01:26:19 INFO DAGScheduler: Missing parents: List()
21/02/17 01:26:19 INFO DAGScheduler: Submitting ResultStage 8 (MapPartitionsRDD[35] at mapPartitions at XGBoost.scala:450), which has no missing parents
21/02/17 01:26:19 INFO MemoryStore: Block broadcast_8 stored as values in memory (estimated size 34.0 KB, free 912.2 MB)
21/02/17 01:26:19 INFO MemoryStore: Block broadcast_8_piece0 stored as bytes in memory (estimated size 14.3 KB, free 912.2 MB)
21/02/17 01:26:19 INFO BlockManagerInfo: Added broadcast_8_piece0 in memory on localhost:33095 (size: 14.3 KB, free: 912.3 MB)
21/02/17 01:26:19 INFO SparkContext: Created broadcast 8 from broadcast at DAGScheduler.scala:1039
21/02/17 01:26:19 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 8 (MapPartitionsRDD[35] at mapPartitions at XGBoost.scala:450) (first 15 tasks are for partitions Vector(0))
21/02/17 01:26:19 INFO TaskSchedulerImpl: Adding task set 8.0 with 1 tasks
21/02/17 01:26:19 INFO TaskSetManager: Starting task 0.0 in stage 8.0 (TID 8, localhost, executor driver, partition 0, PROCESS_LOCAL, 18998 bytes)
21/02/17 01:26:19 INFO Executor: Running task 0.0 in stage 8.0 (TID 8)
21/02/17 01:26:19 INFO BlockManager: Found block rdd_35_0 locally
21/02/17 01:26:19 INFO Executor: 1 block locks were not released by TID = 8:
[rdd_35_0]
21/02/17 01:26:19 INFO Executor: Finished task 0.0 in stage 8.0 (TID 8). 2551 bytes result sent to driver
21/02/17 01:26:19 INFO TaskSetManager: Finished task 0.0 in stage 8.0 (TID 8) in 9 ms on localhost (executor driver) (1/1)
21/02/17 01:26:19 INFO TaskSchedulerImpl: Removed TaskSet 8.0, whose tasks have all completed, from pool 
21/02/17 01:26:19 INFO DAGScheduler: ResultStage 8 (first at XGBoost.scala:685) finished in 0.018 s
21/02/17 01:26:19 INFO DAGScheduler: Job 6 finished: first at XGBoost.scala:685, took 0.021090 s
21/02/17 01:26:19 INFO MapPartitionsRDD: Removing RDD 35 from persistence list
21/02/17 01:26:19 INFO BlockManager: Removing RDD 35
21/02/17 01:26:19 INFO MemoryStore: Block broadcast_9 stored as values in memory (estimated size 64.0 B, free 912.2 MB)
21/02/17 01:26:19 INFO MemoryStore: Block broadcast_9_piece0 stored as bytes in memory (estimated size 510.0 B, free 912.2 MB)
21/02/17 01:26:19 INFO BlockManagerInfo: Added broadcast_9_piece0 in memory on localhost:33095 (size: 510.0 B, free: 912.3 MB)
21/02/17 01:26:19 INFO SparkContext: Created broadcast 9 from broadcast at XGBoostRegressor.scala:271
21/02/17 01:26:19 INFO CodeGenerator: Code generated in 19.981919 ms
21/02/17 01:26:19 INFO CodeGenerator: Code generated in 8.384201 ms
21/02/17 01:26:19 INFO CodeGenerator: Code generated in 7.195304 ms
21/02/17 01:26:19 INFO SparkContext: Starting job: collect at utils.scala:135
21/02/17 01:26:19 INFO DAGScheduler: Got job 7 (collect at utils.scala:135) with 1 output partitions
21/02/17 01:26:19 INFO DAGScheduler: Final stage: ResultStage 9 (collect at utils.scala:135)
21/02/17 01:26:19 INFO DAGScheduler: Parents of final stage: List()
21/02/17 01:26:19 INFO DAGScheduler: Missing parents: List()
21/02/17 01:26:19 INFO DAGScheduler: Submitting ResultStage 9 (MapPartitionsRDD[46] at collect at utils.scala:135), which has no missing parents
21/02/17 01:26:19 INFO MemoryStore: Block broadcast_10 stored as values in memory (estimated size 6.5 KB, free 912.2 MB)
21/02/17 01:26:19 INFO MemoryStore: Block broadcast_10_piece0 stored as bytes in memory (estimated size 3.2 KB, free 912.2 MB)
21/02/17 01:26:19 INFO BlockManagerInfo: Added broadcast_10_piece0 in memory on localhost:33095 (size: 3.2 KB, free: 912.3 MB)
21/02/17 01:26:19 INFO SparkContext: Created broadcast 10 from broadcast at DAGScheduler.scala:1039
21/02/17 01:26:19 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 9 (MapPartitionsRDD[46] at collect at utils.scala:135) (first 15 tasks are for partitions Vector(0))
21/02/17 01:26:19 INFO TaskSchedulerImpl: Adding task set 9.0 with 1 tasks
21/02/17 01:26:19 INFO TaskSetManager: Starting task 0.0 in stage 9.0 (TID 9, localhost, executor driver, partition 0, PROCESS_LOCAL, 8067 bytes)
21/02/17 01:26:19 INFO Executor: Running task 0.0 in stage 9.0 (TID 9)
21/02/17 01:26:19 INFO Executor: Finished task 0.0 in stage 9.0 (TID 9). 1286 bytes result sent to driver
21/02/17 01:26:19 INFO TaskSetManager: Finished task 0.0 in stage 9.0 (TID 9) in 5 ms on localhost (executor driver) (1/1)
21/02/17 01:26:19 INFO TaskSchedulerImpl: Removed TaskSet 9.0, whose tasks have all completed, from pool 
21/02/17 01:26:19 INFO DAGScheduler: ResultStage 9 (collect at utils.scala:135) finished in 0.010 s
21/02/17 01:26:19 INFO DAGScheduler: Job 7 finished: collect at utils.scala:135, took 0.012207 s
21/02/17 01:26:19 INFO SparkContext: Starting job: count at utils.scala:135
21/02/17 01:26:19 INFO DAGScheduler: Registering RDD 49 (count at utils.scala:135)
21/02/17 01:26:19 INFO DAGScheduler: Got job 8 (count at utils.scala:135) with 1 output partitions
21/02/17 01:26:19 INFO DAGScheduler: Final stage: ResultStage 11 (count at utils.scala:135)
21/02/17 01:26:19 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 10)
21/02/17 01:26:19 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 10)
21/02/17 01:26:19 INFO DAGScheduler: Submitting ShuffleMapStage 10 (MapPartitionsRDD[49] at count at utils.scala:135), which has no missing parents
21/02/17 01:26:19 INFO MemoryStore: Block broadcast_11 stored as values in memory (estimated size 8.9 KB, free 912.2 MB)
21/02/17 01:26:19 INFO MemoryStore: Block broadcast_11_piece0 stored as bytes in memory (estimated size 4.5 KB, free 912.2 MB)
21/02/17 01:26:19 INFO BlockManagerInfo: Added broadcast_11_piece0 in memory on localhost:33095 (size: 4.5 KB, free: 912.3 MB)
21/02/17 01:26:19 INFO SparkContext: Created broadcast 11 from broadcast at DAGScheduler.scala:1039
21/02/17 01:26:19 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 10 (MapPartitionsRDD[49] at count at utils.scala:135) (first 15 tasks are for partitions Vector(0))
21/02/17 01:26:19 INFO TaskSchedulerImpl: Adding task set 10.0 with 1 tasks
21/02/17 01:26:19 INFO TaskSetManager: Starting task 0.0 in stage 10.0 (TID 10, localhost, executor driver, partition 0, PROCESS_LOCAL, 8056 bytes)
21/02/17 01:26:19 INFO Executor: Running task 0.0 in stage 10.0 (TID 10)
21/02/17 01:26:19 INFO Executor: Finished task 0.0 in stage 10.0 (TID 10). 1499 bytes result sent to driver
21/02/17 01:26:19 INFO TaskSetManager: Finished task 0.0 in stage 10.0 (TID 10) in 5 ms on localhost (executor driver) (1/1)
21/02/17 01:26:19 INFO TaskSchedulerImpl: Removed TaskSet 10.0, whose tasks have all completed, from pool 
21/02/17 01:26:19 INFO DAGScheduler: ShuffleMapStage 10 (count at utils.scala:135) finished in 0.012 s
21/02/17 01:26:19 INFO DAGScheduler: looking for newly runnable stages
21/02/17 01:26:19 INFO DAGScheduler: running: Set()
21/02/17 01:26:19 INFO DAGScheduler: waiting: Set(ResultStage 11)
21/02/17 01:26:19 INFO DAGScheduler: failed: Set()
21/02/17 01:26:19 INFO DAGScheduler: Submitting ResultStage 11 (MapPartitionsRDD[52] at count at utils.scala:135), which has no missing parents
21/02/17 01:26:19 INFO MemoryStore: Block broadcast_12 stored as values in memory (estimated size 7.3 KB, free 912.2 MB)
21/02/17 01:26:19 INFO MemoryStore: Block broadcast_12_piece0 stored as bytes in memory (estimated size 3.8 KB, free 912.2 MB)
21/02/17 01:26:19 INFO BlockManagerInfo: Added broadcast_12_piece0 in memory on localhost:33095 (size: 3.8 KB, free: 912.3 MB)
21/02/17 01:26:19 INFO SparkContext: Created broadcast 12 from broadcast at DAGScheduler.scala:1039
21/02/17 01:26:19 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 11 (MapPartitionsRDD[52] at count at utils.scala:135) (first 15 tasks are for partitions Vector(0))
21/02/17 01:26:19 INFO TaskSchedulerImpl: Adding task set 11.0 with 1 tasks
21/02/17 01:26:19 INFO TaskSetManager: Starting task 0.0 in stage 11.0 (TID 11, localhost, executor driver, partition 0, NODE_LOCAL, 7754 bytes)
21/02/17 01:26:19 INFO Executor: Running task 0.0 in stage 11.0 (TID 11)
21/02/17 01:26:19 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
21/02/17 01:26:19 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
21/02/17 01:26:19 INFO Executor: Finished task 0.0 in stage 11.0 (TID 11). 1782 bytes result sent to driver
21/02/17 01:26:19 INFO TaskSetManager: Finished task 0.0 in stage 11.0 (TID 11) in 6 ms on localhost (executor driver) (1/1)
21/02/17 01:26:19 INFO TaskSchedulerImpl: Removed TaskSet 11.0, whose tasks have all completed, from pool 
21/02/17 01:26:19 INFO DAGScheduler: ResultStage 11 (count at utils.scala:135) finished in 0.010 s
21/02/17 01:26:19 INFO DAGScheduler: Job 8 finished: count at utils.scala:135, took 0.025540 s
21/02/17 01:26:20 INFO CodeGenerator: Code generated in 6.464747 ms
21/02/17 01:26:20 INFO CodeGenerator: Code generated in 6.914842 ms
21/02/17 01:26:20 INFO SparkContext: Starting job: collect at utils.scala:135
21/02/17 01:26:20 INFO DAGScheduler: Got job 9 (collect at utils.scala:135) with 1 output partitions
21/02/17 01:26:20 INFO DAGScheduler: Final stage: ResultStage 12 (collect at utils.scala:135)
21/02/17 01:26:20 INFO DAGScheduler: Parents of final stage: List()
21/02/17 01:26:20 INFO DAGScheduler: Missing parents: List()
21/02/17 01:26:20 INFO DAGScheduler: Submitting ResultStage 12 (MapPartitionsRDD[55] at collect at utils.scala:135), which has no missing parents
21/02/17 01:26:20 INFO MemoryStore: Block broadcast_13 stored as values in memory (estimated size 61.1 KB, free 912.1 MB)
21/02/17 01:26:20 INFO MemoryStore: Block broadcast_13_piece0 stored as bytes in memory (estimated size 25.3 KB, free 912.1 MB)
21/02/17 01:26:20 INFO BlockManagerInfo: Added broadcast_13_piece0 in memory on localhost:33095 (size: 25.3 KB, free: 912.2 MB)
21/02/17 01:26:20 INFO SparkContext: Created broadcast 13 from broadcast at DAGScheduler.scala:1039
21/02/17 01:26:20 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 12 (MapPartitionsRDD[55] at collect at utils.scala:135) (first 15 tasks are for partitions Vector(0))
21/02/17 01:26:20 INFO TaskSchedulerImpl: Adding task set 12.0 with 1 tasks
21/02/17 01:26:20 INFO TaskSetManager: Starting task 0.0 in stage 12.0 (TID 12, localhost, executor driver, partition 0, PROCESS_LOCAL, 18998 bytes)
21/02/17 01:26:20 INFO Executor: Running task 0.0 in stage 12.0 (TID 12)
21/02/17 01:26:20 INFO BlockManager: Found block rdd_17_0 locally
21/02/17 01:26:20 INFO CodeGenerator: Code generated in 9.689134 ms
21/02/17 01:26:20 INFO CodeGenerator: Code generated in 18.902206 ms
21/02/17 01:26:20 INFO CodeGenerator: Code generated in 42.975122 ms
21/02/17 01:26:20 INFO Executor: Finished task 0.0 in stage 12.0 (TID 12). 1815 bytes result sent to driver
21/02/17 01:26:20 INFO TaskSetManager: Finished task 0.0 in stage 12.0 (TID 12) in 132 ms on localhost (executor driver) (1/1)
21/02/17 01:26:20 INFO TaskSchedulerImpl: Removed TaskSet 12.0, whose tasks have all completed, from pool 
21/02/17 01:26:20 INFO DAGScheduler: ResultStage 12 (collect at utils.scala:135) finished in 0.138 s
21/02/17 01:26:20 INFO DAGScheduler: Job 9 finished: collect at utils.scala:135, took 0.140559 s
21/02/17 01:26:20 INFO CodeGenerator: Code generated in 7.555687 ms
21/02/17 01:26:20 INFO SparkContext: Starting job: count at utils.scala:135
21/02/17 01:26:20 INFO DAGScheduler: Registering RDD 58 (count at utils.scala:135)
21/02/17 01:26:20 INFO DAGScheduler: Got job 10 (count at utils.scala:135) with 1 output partitions
21/02/17 01:26:20 INFO DAGScheduler: Final stage: ResultStage 14 (count at utils.scala:135)
21/02/17 01:26:20 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 13)
21/02/17 01:26:20 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 13)
21/02/17 01:26:20 INFO DAGScheduler: Submitting ShuffleMapStage 13 (MapPartitionsRDD[58] at count at utils.scala:135), which has no missing parents
21/02/17 01:26:20 INFO MemoryStore: Block broadcast_14 stored as values in memory (estimated size 62.0 KB, free 912.0 MB)
21/02/17 01:26:20 INFO MemoryStore: Block broadcast_14_piece0 stored as bytes in memory (estimated size 25.8 KB, free 912.0 MB)
21/02/17 01:26:20 INFO BlockManagerInfo: Added broadcast_14_piece0 in memory on localhost:33095 (size: 25.8 KB, free: 912.2 MB)
21/02/17 01:26:20 INFO SparkContext: Created broadcast 14 from broadcast at DAGScheduler.scala:1039
21/02/17 01:26:20 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 13 (MapPartitionsRDD[58] at count at utils.scala:135) (first 15 tasks are for partitions Vector(0))
21/02/17 01:26:20 INFO TaskSchedulerImpl: Adding task set 13.0 with 1 tasks
21/02/17 01:26:20 INFO TaskSetManager: Starting task 0.0 in stage 13.0 (TID 13, localhost, executor driver, partition 0, PROCESS_LOCAL, 18987 bytes)
21/02/17 01:26:20 INFO Executor: Running task 0.0 in stage 13.0 (TID 13)
21/02/17 01:26:20 INFO BlockManager: Found block rdd_17_0 locally
21/02/17 01:26:20 INFO Executor: Finished task 0.0 in stage 13.0 (TID 13). 1933 bytes result sent to driver
21/02/17 01:26:20 INFO TaskSetManager: Finished task 0.0 in stage 13.0 (TID 13) in 31 ms on localhost (executor driver) (1/1)
21/02/17 01:26:20 INFO TaskSchedulerImpl: Removed TaskSet 13.0, whose tasks have all completed, from pool 
21/02/17 01:26:20 INFO DAGScheduler: ShuffleMapStage 13 (count at utils.scala:135) finished in 0.040 s
21/02/17 01:26:20 INFO DAGScheduler: looking for newly runnable stages
21/02/17 01:26:20 INFO DAGScheduler: running: Set()
21/02/17 01:26:20 INFO DAGScheduler: waiting: Set(ResultStage 14)
21/02/17 01:26:20 INFO DAGScheduler: failed: Set()
21/02/17 01:26:20 INFO DAGScheduler: Submitting ResultStage 14 (MapPartitionsRDD[61] at count at utils.scala:135), which has no missing parents
21/02/17 01:26:20 INFO MemoryStore: Block broadcast_15 stored as values in memory (estimated size 7.3 KB, free 912.0 MB)
21/02/17 01:26:20 INFO MemoryStore: Block broadcast_15_piece0 stored as bytes in memory (estimated size 3.8 KB, free 912.0 MB)
21/02/17 01:26:20 INFO BlockManagerInfo: Added broadcast_15_piece0 in memory on localhost:33095 (size: 3.8 KB, free: 912.2 MB)
21/02/17 01:26:20 INFO SparkContext: Created broadcast 15 from broadcast at DAGScheduler.scala:1039
21/02/17 01:26:20 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 14 (MapPartitionsRDD[61] at count at utils.scala:135) (first 15 tasks are for partitions Vector(0))
21/02/17 01:26:20 INFO TaskSchedulerImpl: Adding task set 14.0 with 1 tasks
21/02/17 01:26:20 INFO TaskSetManager: Starting task 0.0 in stage 14.0 (TID 14, localhost, executor driver, partition 0, NODE_LOCAL, 7754 bytes)
21/02/17 01:26:20 INFO Executor: Running task 0.0 in stage 14.0 (TID 14)
21/02/17 01:26:20 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
21/02/17 01:26:20 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
21/02/17 01:26:20 INFO Executor: Finished task 0.0 in stage 14.0 (TID 14). 1782 bytes result sent to driver
21/02/17 01:26:20 INFO TaskSetManager: Finished task 0.0 in stage 14.0 (TID 14) in 5 ms on localhost (executor driver) (1/1)
21/02/17 01:26:20 INFO TaskSchedulerImpl: Removed TaskSet 14.0, whose tasks have all completed, from pool 
21/02/17 01:26:20 INFO DAGScheduler: ResultStage 14 (count at utils.scala:135) finished in 0.010 s
21/02/17 01:26:20 INFO DAGScheduler: Job 10 finished: count at utils.scala:135, took 0.054002 s
21/02/17 01:26:20 INFO deprecation: mapred.output.dir is deprecated. Instead, use mapreduce.output.fileoutputformat.outputdir
21/02/17 01:26:20 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
21/02/17 01:26:20 INFO SparkContext: Starting job: runJob at SparkHadoopWriter.scala:78
21/02/17 01:26:20 INFO DAGScheduler: Got job 11 (runJob at SparkHadoopWriter.scala:78) with 1 output partitions
21/02/17 01:26:20 INFO DAGScheduler: Final stage: ResultStage 15 (runJob at SparkHadoopWriter.scala:78)
21/02/17 01:26:20 INFO DAGScheduler: Parents of final stage: List()
21/02/17 01:26:20 INFO DAGScheduler: Missing parents: List()
21/02/17 01:26:20 INFO DAGScheduler: Submitting ResultStage 15 (MapPartitionsRDD[63] at saveAsTextFile at ReadWrite.scala:283), which has no missing parents
21/02/17 01:26:20 INFO MemoryStore: Block broadcast_16 stored as values in memory (estimated size 71.0 KB, free 911.9 MB)
21/02/17 01:26:20 INFO MemoryStore: Block broadcast_16_piece0 stored as bytes in memory (estimated size 25.3 KB, free 911.9 MB)
21/02/17 01:26:20 INFO BlockManagerInfo: Added broadcast_16_piece0 in memory on localhost:33095 (size: 25.3 KB, free: 912.2 MB)
21/02/17 01:26:20 INFO SparkContext: Created broadcast 16 from broadcast at DAGScheduler.scala:1039
21/02/17 01:26:20 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 15 (MapPartitionsRDD[63] at saveAsTextFile at ReadWrite.scala:283) (first 15 tasks are for partitions Vector(0))
21/02/17 01:26:20 INFO TaskSchedulerImpl: Adding task set 15.0 with 1 tasks
21/02/17 01:26:20 INFO TaskSetManager: Starting task 0.0 in stage 15.0 (TID 15, localhost, executor driver, partition 0, PROCESS_LOCAL, 8142 bytes)
21/02/17 01:26:20 INFO Executor: Running task 0.0 in stage 15.0 (TID 15)
21/02/17 01:26:20 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
21/02/17 01:26:20 INFO FileOutputCommitter: Saved output of task 'attempt_20210217012620_0063_m_000000_0' to file:/tmp/Rtmpghpjcc/file21a0918c1fafd/metadata/_temporary/0/task_20210217012620_0063_m_000000
21/02/17 01:26:20 INFO SparkHadoopMapRedUtil: attempt_20210217012620_0063_m_000000_0: Committed
21/02/17 01:26:20 INFO Executor: Finished task 0.0 in stage 15.0 (TID 15). 1072 bytes result sent to driver
21/02/17 01:26:20 INFO TaskSetManager: Finished task 0.0 in stage 15.0 (TID 15) in 37 ms on localhost (executor driver) (1/1)
21/02/17 01:26:20 INFO TaskSchedulerImpl: Removed TaskSet 15.0, whose tasks have all completed, from pool 
21/02/17 01:26:20 INFO DAGScheduler: ResultStage 15 (runJob at SparkHadoopWriter.scala:78) finished in 0.052 s
21/02/17 01:26:20 INFO DAGScheduler: Job 11 finished: runJob at SparkHadoopWriter.scala:78, took 0.053595 s
21/02/17 01:26:20 INFO SparkHadoopWriter: Job job_20210217012620_0063 committed.
21/02/17 01:26:20 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
21/02/17 01:26:20 INFO SparkContext: Starting job: runJob at SparkHadoopWriter.scala:78
21/02/17 01:26:20 INFO DAGScheduler: Got job 12 (runJob at SparkHadoopWriter.scala:78) with 1 output partitions
21/02/17 01:26:20 INFO DAGScheduler: Final stage: ResultStage 16 (runJob at SparkHadoopWriter.scala:78)
21/02/17 01:26:20 INFO DAGScheduler: Parents of final stage: List()
21/02/17 01:26:20 INFO DAGScheduler: Missing parents: List()
21/02/17 01:26:20 INFO DAGScheduler: Submitting ResultStage 16 (MapPartitionsRDD[65] at saveAsTextFile at ReadWrite.scala:283), which has no missing parents
21/02/17 01:26:20 INFO MemoryStore: Block broadcast_17 stored as values in memory (estimated size 71.1 KB, free 911.8 MB)
21/02/17 01:26:20 INFO MemoryStore: Block broadcast_17_piece0 stored as bytes in memory (estimated size 25.4 KB, free 911.8 MB)
21/02/17 01:26:20 INFO BlockManagerInfo: Added broadcast_17_piece0 in memory on localhost:33095 (size: 25.4 KB, free: 912.2 MB)
21/02/17 01:26:20 INFO SparkContext: Created broadcast 17 from broadcast at DAGScheduler.scala:1039
21/02/17 01:26:20 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 16 (MapPartitionsRDD[65] at saveAsTextFile at ReadWrite.scala:283) (first 15 tasks are for partitions Vector(0))
21/02/17 01:26:20 INFO TaskSchedulerImpl: Adding task set 16.0 with 1 tasks
21/02/17 01:26:20 INFO ContextCleaner: Cleaned accumulator 415
21/02/17 01:26:20 INFO ContextCleaner: Cleaned accumulator 397
21/02/17 01:26:20 INFO ContextCleaner: Cleaned accumulator 284
21/02/17 01:26:20 INFO ContextCleaner: Cleaned accumulator 298
21/02/17 01:26:20 INFO TaskSetManager: Starting task 0.0 in stage 16.0 (TID 16, localhost, executor driver, partition 0, PROCESS_LOCAL, 8216 bytes)
21/02/17 01:26:20 INFO ContextCleaner: Cleaned accumulator 226
21/02/17 01:26:20 INFO ContextCleaner: Cleaned accumulator 465
21/02/17 01:26:20 INFO ContextCleaner: Cleaned accumulator 255
21/02/17 01:26:20 INFO ContextCleaner: Cleaned accumulator 367
21/02/17 01:26:20 INFO ContextCleaner: Cleaned accumulator 395
21/02/17 01:26:20 INFO ContextCleaner: Cleaned accumulator 273
21/02/17 01:26:20 INFO ContextCleaner: Cleaned accumulator 473
21/02/17 01:26:20 INFO ContextCleaner: Cleaned accumulator 356
21/02/17 01:26:20 INFO Executor: Running task 0.0 in stage 16.0 (TID 16)
21/02/17 01:26:20 INFO ContextCleaner: Cleaned accumulator 268
21/02/17 01:26:20 INFO ContextCleaner: Cleaned accumulator 369
21/02/17 01:26:20 INFO ContextCleaner: Cleaned accumulator 227
21/02/17 01:26:20 INFO ContextCleaner: Cleaned accumulator 233
21/02/17 01:26:20 INFO ContextCleaner: Cleaned accumulator 437
21/02/17 01:26:20 INFO ContextCleaner: Cleaned accumulator 276
21/02/17 01:26:20 INFO ContextCleaner: Cleaned accumulator 237
21/02/17 01:26:20 INFO ContextCleaner: Cleaned accumulator 327
21/02/17 01:26:20 INFO ContextCleaner: Cleaned accumulator 452
21/02/17 01:26:20 INFO ContextCleaner: Cleaned accumulator 476
21/02/17 01:26:20 INFO ContextCleaner: Cleaned accumulator 375
21/02/17 01:26:20 INFO ContextCleaner: Cleaned accumulator 411
21/02/17 01:26:20 INFO ContextCleaner: Cleaned accumulator 222
21/02/17 01:26:20 INFO ContextCleaner: Cleaned accumulator 272
21/02/17 01:26:20 INFO ContextCleaner: Cleaned accumulator 368
21/02/17 01:26:20 INFO ContextCleaner: Cleaned accumulator 409
21/02/17 01:26:20 INFO ContextCleaner: Cleaned accumulator 316
21/02/17 01:26:20 INFO ContextCleaner: Cleaned accumulator 318
21/02/17 01:26:20 INFO ContextCleaner: Cleaned accumulator 321
21/02/17 01:26:20 INFO ContextCleaner: Cleaned accumulator 469
21/02/17 01:26:20 INFO ContextCleaner: Cleaned accumulator 294
21/02/17 01:26:20 INFO BlockManagerInfo: Removed broadcast_7_piece0 on localhost:33095 in memory (size: 14.2 KB, free: 912.2 MB)
21/02/17 01:26:20 INFO ContextCleaner: Cleaned accumulator 401
21/02/17 01:26:20 INFO ContextCleaner: Cleaned accumulator 402
21/02/17 01:26:20 INFO ContextCleaner: Cleaned accumulator 225
21/02/17 01:26:20 INFO ContextCleaner: Cleaned accumulator 363
21/02/17 01:26:20 INFO ContextCleaner: Cleaned accumulator 462
21/02/17 01:26:20 INFO ContextCleaner: Cleaned accumulator 289
21/02/17 01:26:20 INFO ContextCleaner: Cleaned accumulator 333
21/02/17 01:26:20 INFO ContextCleaner: Cleaned accumulator 432
21/02/17 01:26:20 INFO ContextCleaner: Cleaned accumulator 400
21/02/17 01:26:20 INFO ContextCleaner: Cleaned accumulator 241
21/02/17 01:26:20 INFO ContextCleaner: Cleaned accumulator 228
21/02/17 01:26:20 INFO ContextCleaner: Cleaned accumulator 459
21/02/17 01:26:20 INFO ContextCleaner: Cleaned accumulator 244
21/02/17 01:26:20 INFO ContextCleaner: Cleaned accumulator 220
21/02/17 01:26:20 INFO ContextCleaner: Cleaned accumulator 301
21/02/17 01:26:20 INFO ContextCleaner: Cleaned accumulator 466
21/02/17 01:26:20 INFO ContextCleaner: Cleaned accumulator 376
21/02/17 01:26:20 INFO ContextCleaner: Cleaned accumulator 319
21/02/17 01:26:20 INFO ContextCleaner: Cleaned accumulator 343
21/02/17 01:26:20 INFO ContextCleaner: Cleaned accumulator 391
21/02/17 01:26:20 INFO ContextCleaner: Cleaned accumulator 410
21/02/17 01:26:20 INFO ContextCleaner: Cleaned accumulator 257
21/02/17 01:26:20 INFO ContextCleaner: Cleaned accumulator 429
21/02/17 01:26:20 INFO ContextCleaner: Cleaned accumulator 218
21/02/17 01:26:20 INFO ContextCleaner: Cleaned accumulator 340
21/02/17 01:26:20 INFO ContextCleaner: Cleaned accumulator 280
21/02/17 01:26:20 INFO ContextCleaner: Cleaned accumulator 434
21/02/17 01:26:20 INFO ContextCleaner: Cleaned accumulator 420
21/02/17 01:26:20 INFO ContextCleaner: Cleaned accumulator 374
21/02/17 01:26:20 INFO ContextCleaner: Cleaned accumulator 425
21/02/17 01:26:20 INFO ContextCleaner: Cleaned accumulator 229
21/02/17 01:26:20 INFO ContextCleaner: Cleaned accumulator 441
21/02/17 01:26:20 INFO ContextCleaner: Cleaned accumulator 428
21/02/17 01:26:20 INFO ContextCleaner: Cleaned accumulator 413
21/02/17 01:26:20 INFO ContextCleaner: Cleaned accumulator 447
21/02/17 01:26:20 INFO ContextCleaner: Cleaned accumulator 317
21/02/17 01:26:20 INFO ContextCleaner: Cleaned accumulator 355
21/02/17 01:26:20 INFO ContextCleaner: Cleaned accumulator 264
21/02/17 01:26:20 INFO ContextCleaner: Cleaned accumulator 372
21/02/17 01:26:20 INFO ContextCleaner: Cleaned accumulator 385
21/02/17 01:26:20 INFO ContextCleaner: Cleaned accumulator 380
21/02/17 01:26:20 INFO ContextCleaner: Cleaned accumulator 359
21/02/17 01:26:20 INFO ContextCleaner: Cleaned accumulator 456
21/02/17 01:26:20 INFO ContextCleaner: Cleaned accumulator 299
21/02/17 01:26:20 INFO ContextCleaner: Cleaned accumulator 360
21/02/17 01:26:20 INFO ContextCleaner: Cleaned accumulator 246
21/02/17 01:26:20 INFO ContextCleaner: Cleaned accumulator 453
21/02/17 01:26:20 INFO ContextCleaner: Cleaned accumulator 238
21/02/17 01:26:20 INFO ContextCleaner: Cleaned accumulator 354
21/02/17 01:26:20 INFO ContextCleaner: Cleaned accumulator 332
21/02/17 01:26:20 INFO ContextCleaner: Cleaned accumulator 392
21/02/17 01:26:20 INFO ContextCleaner: Cleaned accumulator 296
21/02/17 01:26:20 INFO ContextCleaner: Cleaned accumulator 232
21/02/17 01:26:20 INFO ContextCleaner: Cleaned accumulator 431
21/02/17 01:26:20 INFO ContextCleaner: Cleaned accumulator 306
21/02/17 01:26:20 INFO ContextCleaner: Cleaned accumulator 352
21/02/17 01:26:20 INFO ContextCleaner: Cleaned accumulator 460
21/02/17 01:26:20 INFO ContextCleaner: Cleaned accumulator 351
21/02/17 01:26:20 INFO ContextCleaner: Cleaned accumulator 373
21/02/17 01:26:20 INFO ContextCleaner: Cleaned accumulator 357
21/02/17 01:26:20 INFO ContextCleaner: Cleaned accumulator 440
21/02/17 01:26:20 INFO ContextCleaner: Cleaned accumulator 214
21/02/17 01:26:20 INFO ContextCleaner: Cleaned accumulator 248
21/02/17 01:26:20 INFO ContextCleaner: Cleaned accumulator 249
21/02/17 01:26:20 INFO ContextCleaner: Cleaned accumulator 393
21/02/17 01:26:20 INFO ContextCleaner: Cleaned accumulator 311
21/02/17 01:26:20 INFO ContextCleaner: Cleaned accumulator 254
21/02/17 01:26:20 INFO ContextCleaner: Cleaned accumulator 260
21/02/17 01:26:20 INFO ContextCleaner: Cleaned accumulator 245
21/02/17 01:26:20 INFO ContextCleaner: Cleaned accumulator 250
21/02/17 01:26:20 INFO ContextCleaner: Cleaned accumulator 313
21/02/17 01:26:20 INFO BlockManagerInfo: Removed broadcast_14_piece0 on localhost:33095 in memory (size: 25.8 KB, free: 912.2 MB)
21/02/17 01:26:20 INFO ContextCleaner: Cleaned accumulator 310
21/02/17 01:26:20 INFO ContextCleaner: Cleaned accumulator 251
21/02/17 01:26:20 INFO ContextCleaner: Cleaned accumulator 312
21/02/17 01:26:20 INFO ContextCleaner: Cleaned accumulator 326
21/02/17 01:26:20 INFO ContextCleaner: Cleaned accumulator 345
21/02/17 01:26:20 INFO ContextCleaner: Cleaned accumulator 370
21/02/17 01:26:20 INFO BlockManagerInfo: Removed broadcast_15_piece0 on localhost:33095 in memory (size: 3.8 KB, free: 912.2 MB)
21/02/17 01:26:20 INFO ContextCleaner: Cleaned accumulator 419
21/02/17 01:26:20 INFO ContextCleaner: Cleaned accumulator 365
21/02/17 01:26:20 INFO ContextCleaner: Cleaned accumulator 381
21/02/17 01:26:20 INFO ContextCleaner: Cleaned shuffle 3
21/02/17 01:26:20 INFO ContextCleaner: Cleaned accumulator 303
21/02/17 01:26:20 INFO ContextCleaner: Cleaned accumulator 346
21/02/17 01:26:20 INFO ContextCleaner: Cleaned accumulator 212
21/02/17 01:26:20 INFO ContextCleaner: Cleaned accumulator 274
21/02/17 01:26:20 INFO ContextCleaner: Cleaned accumulator 438
21/02/17 01:26:20 INFO ContextCleaner: Cleaned accumulator 279
21/02/17 01:26:20 INFO ContextCleaner: Cleaned accumulator 213
21/02/17 01:26:20 INFO ContextCleaner: Cleaned accumulator 328
21/02/17 01:26:20 INFO ContextCleaner: Cleaned accumulator 270
21/02/17 01:26:20 INFO ContextCleaner: Cleaned accumulator 252
21/02/17 01:26:20 INFO ContextCleaner: Cleaned accumulator 283
21/02/17 01:26:20 INFO ContextCleaner: Cleaned accumulator 285
21/02/17 01:26:20 INFO ContextCleaner: Cleaned accumulator 383
21/02/17 01:26:20 INFO ContextCleaner: Cleaned accumulator 277
21/02/17 01:26:20 INFO ContextCleaner: Cleaned accumulator 282
21/02/17 01:26:20 INFO ContextCleaner: Cleaned accumulator 399
21/02/17 01:26:20 INFO ContextCleaner: Cleaned accumulator 217
21/02/17 01:26:20 INFO ContextCleaner: Cleaned accumulator 444
21/02/17 01:26:20 INFO BlockManagerInfo: Removed broadcast_10_piece0 on localhost:33095 in memory (size: 3.2 KB, free: 912.2 MB)
21/02/17 01:26:20 INFO ContextCleaner: Cleaned accumulator 336
21/02/17 01:26:20 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
21/02/17 01:26:20 INFO BlockManagerInfo: Removed broadcast_12_piece0 on localhost:33095 in memory (size: 3.8 KB, free: 912.2 MB)
21/02/17 01:26:20 INFO ContextCleaner: Cleaned accumulator 239
21/02/17 01:26:20 INFO ContextCleaner: Cleaned accumulator 398
21/02/17 01:26:20 INFO ContextCleaner: Cleaned accumulator 297
21/02/17 01:26:20 INFO ContextCleaner: Cleaned accumulator 295
21/02/17 01:26:20 INFO ContextCleaner: Cleaned accumulator 412
21/02/17 01:26:20 INFO ContextCleaner: Cleaned accumulator 263
21/02/17 01:26:20 INFO ContextCleaner: Cleaned accumulator 281
21/02/17 01:26:20 INFO ContextCleaner: Cleaned accumulator 423
21/02/17 01:26:20 INFO BlockManagerInfo: Removed broadcast_11_piece0 on localhost:33095 in memory (size: 4.5 KB, free: 912.2 MB)
21/02/17 01:26:20 INFO ContextCleaner: Cleaned accumulator 416
21/02/17 01:26:20 INFO ContextCleaner: Cleaned accumulator 430
21/02/17 01:26:20 INFO ContextCleaner: Cleaned accumulator 358
21/02/17 01:26:20 INFO ContextCleaner: Cleaned accumulator 418
21/02/17 01:26:20 INFO ContextCleaner: Cleaned accumulator 348
21/02/17 01:26:20 INFO ContextCleaner: Cleaned accumulator 335
21/02/17 01:26:20 INFO ContextCleaner: Cleaned accumulator 235
21/02/17 01:26:20 INFO ContextCleaner: Cleaned accumulator 322
21/02/17 01:26:20 INFO BlockManagerInfo: Removed broadcast_16_piece0 on localhost:33095 in memory (size: 25.3 KB, free: 912.2 MB)
21/02/17 01:26:20 INFO ContextCleaner: Cleaned accumulator 290
21/02/17 01:26:20 INFO ContextCleaner: Cleaned accumulator 315
21/02/17 01:26:20 INFO ContextCleaner: Cleaned accumulator 287
21/02/17 01:26:20 INFO ContextCleaner: Cleaned accumulator 442
21/02/17 01:26:20 INFO ContextCleaner: Cleaned accumulator 445
21/02/17 01:26:20 INFO ContextCleaner: Cleaned accumulator 396
21/02/17 01:26:20 INFO ContextCleaner: Cleaned accumulator 403
21/02/17 01:26:20 INFO ContextCleaner: Cleaned accumulator 449
21/02/17 01:26:20 INFO ContextCleaner: Cleaned accumulator 454
21/02/17 01:26:20 INFO ContextCleaner: Cleaned accumulator 382
21/02/17 01:26:20 INFO ContextCleaner: Cleaned accumulator 236
21/02/17 01:26:20 INFO ContextCleaner: Cleaned accumulator 261
21/02/17 01:26:20 INFO ContextCleaner: Cleaned accumulator 324
21/02/17 01:26:20 INFO BlockManagerInfo: Removed broadcast_13_piece0 on localhost:33095 in memory (size: 25.3 KB, free: 912.3 MB)
21/02/17 01:26:20 INFO ContextCleaner: Cleaned accumulator 468
21/02/17 01:26:20 INFO ContextCleaner: Cleaned accumulator 242
21/02/17 01:26:20 INFO ContextCleaner: Cleaned accumulator 325
21/02/17 01:26:20 INFO ContextCleaner: Cleaned accumulator 286
21/02/17 01:26:20 INFO ContextCleaner: Cleaned accumulator 269
21/02/17 01:26:20 INFO ContextCleaner: Cleaned accumulator 231
21/02/17 01:26:20 INFO ContextCleaner: Cleaned accumulator 450
21/02/17 01:26:20 INFO ContextCleaner: Cleaned accumulator 379
21/02/17 01:26:20 INFO ContextCleaner: Cleaned accumulator 386
21/02/17 01:26:20 INFO ContextCleaner: Cleaned accumulator 426
21/02/17 01:26:20 INFO ContextCleaner: Cleaned accumulator 377
21/02/17 01:26:20 INFO ContextCleaner: Cleaned accumulator 361
21/02/17 01:26:20 INFO ContextCleaner: Cleaned accumulator 422
21/02/17 01:26:20 INFO ContextCleaner: Cleaned accumulator 339
21/02/17 01:26:20 INFO ContextCleaner: Cleaned accumulator 331
21/02/17 01:26:20 INFO ContextCleaner: Cleaned accumulator 305
21/02/17 01:26:20 INFO ContextCleaner: Cleaned accumulator 302
21/02/17 01:26:20 INFO ContextCleaner: Cleaned accumulator 364
21/02/17 01:26:20 INFO ContextCleaner: Cleaned accumulator 461
21/02/17 01:26:20 INFO ContextCleaner: Cleaned accumulator 304
21/02/17 01:26:20 INFO ContextCleaner: Cleaned accumulator 371
21/02/17 01:26:20 INFO ContextCleaner: Cleaned accumulator 378
21/02/17 01:26:20 INFO ContextCleaner: Cleaned accumulator 458
21/02/17 01:26:20 INFO FileOutputCommitter: Saved output of task 'attempt_20210217012620_0065_m_000000_0' to file:/tmp/Rtmpghpjcc/file21a0918c1fafd/stages/0_r_formula__013240c4_f8a9_47ce_a2a5_e082efc573d3/metadata/_temporary/0/task_20210217012620_0065_m_000000
21/02/17 01:26:20 INFO ContextCleaner: Cleaned accumulator 455
21/02/17 01:26:20 INFO SparkHadoopMapRedUtil: attempt_20210217012620_0065_m_000000_0: Committed
21/02/17 01:26:20 INFO ContextCleaner: Cleaned accumulator 329
21/02/17 01:26:20 INFO ContextCleaner: Cleaned accumulator 350
21/02/17 01:26:20 INFO ContextCleaner: Cleaned accumulator 243
21/02/17 01:26:20 INFO ContextCleaner: Cleaned accumulator 427
21/02/17 01:26:20 INFO ContextCleaner: Cleaned accumulator 433
21/02/17 01:26:20 INFO ContextCleaner: Cleaned accumulator 216
21/02/17 01:26:20 INFO ContextCleaner: Cleaned accumulator 262
21/02/17 01:26:20 INFO ContextCleaner: Cleaned accumulator 417
21/02/17 01:26:20 INFO ContextCleaner: Cleaned accumulator 334
21/02/17 01:26:20 INFO ContextCleaner: Cleaned accumulator 347
21/02/17 01:26:20 INFO ContextCleaner: Cleaned accumulator 259
21/02/17 01:26:20 INFO ContextCleaner: Cleaned accumulator 309
21/02/17 01:26:20 INFO ContextCleaner: Cleaned accumulator 414
21/02/17 01:26:20 INFO ContextCleaner: Cleaned accumulator 366
21/02/17 01:26:20 INFO ContextCleaner: Cleaned accumulator 389
21/02/17 01:26:20 INFO ContextCleaner: Cleaned accumulator 384
21/02/17 01:26:20 INFO ContextCleaner: Cleaned accumulator 463
21/02/17 01:26:20 INFO ContextCleaner: Cleaned accumulator 443
21/02/17 01:26:20 INFO ContextCleaner: Cleaned accumulator 439
21/02/17 01:26:20 INFO ContextCleaner: Cleaned accumulator 300
21/02/17 01:26:20 INFO ContextCleaner: Cleaned accumulator 451
21/02/17 01:26:20 INFO ContextCleaner: Cleaned accumulator 471
21/02/17 01:26:20 INFO ContextCleaner: Cleaned accumulator 457
21/02/17 01:26:20 INFO ContextCleaner: Cleaned accumulator 271
21/02/17 01:26:20 INFO ContextCleaner: Cleaned accumulator 421
21/02/17 01:26:20 INFO ContextCleaner: Cleaned accumulator 344
21/02/17 01:26:20 INFO ContextCleaner: Cleaned accumulator 353
21/02/17 01:26:20 INFO ContextCleaner: Cleaned accumulator 278
21/02/17 01:26:20 INFO ContextCleaner: Cleaned accumulator 408
21/02/17 01:26:20 INFO Executor: Finished task 0.0 in stage 16.0 (TID 16). 1029 bytes result sent to driver
21/02/17 01:26:20 INFO ContextCleaner: Cleaned accumulator 258
21/02/17 01:26:20 INFO ContextCleaner: Cleaned accumulator 338
21/02/17 01:26:20 INFO ContextCleaner: Cleaned accumulator 405
21/02/17 01:26:20 INFO ContextCleaner: Cleaned accumulator 467
21/02/17 01:26:20 INFO ContextCleaner: Cleaned accumulator 288
21/02/17 01:26:20 INFO ContextCleaner: Cleaned accumulator 292
21/02/17 01:26:20 INFO ContextCleaner: Cleaned accumulator 341
21/02/17 01:26:20 INFO ContextCleaner: Cleaned accumulator 475
21/02/17 01:26:20 INFO ContextCleaner: Cleaned accumulator 404
21/02/17 01:26:20 INFO ContextCleaner: Cleaned accumulator 314
21/02/17 01:26:20 INFO ContextCleaner: Cleaned accumulator 256
21/02/17 01:26:20 INFO ContextCleaner: Cleaned accumulator 349
21/02/17 01:26:20 INFO ContextCleaner: Cleaned accumulator 240
21/02/17 01:26:20 INFO ContextCleaner: Cleaned accumulator 362
21/02/17 01:26:20 INFO ContextCleaner: Cleaned accumulator 394
21/02/17 01:26:20 INFO ContextCleaner: Cleaned accumulator 308
21/02/17 01:26:20 INFO ContextCleaner: Cleaned accumulator 470
21/02/17 01:26:20 INFO TaskSetManager: Finished task 0.0 in stage 16.0 (TID 16) in 16 ms on localhost (executor driver) (1/1)
21/02/17 01:26:20 INFO TaskSchedulerImpl: Removed TaskSet 16.0, whose tasks have all completed, from pool 
21/02/17 01:26:20 INFO DAGScheduler: ResultStage 16 (runJob at SparkHadoopWriter.scala:78) finished in 0.059 s
21/02/17 01:26:20 INFO DAGScheduler: Job 12 finished: runJob at SparkHadoopWriter.scala:78, took 0.061275 s
21/02/17 01:26:20 INFO BlockManager: Removing RDD 35
21/02/17 01:26:20 INFO ContextCleaner: Cleaned RDD 35
21/02/17 01:26:20 INFO ContextCleaner: Cleaned accumulator 224
21/02/17 01:26:20 INFO ContextCleaner: Cleaned accumulator 406
21/02/17 01:26:20 INFO ContextCleaner: Cleaned accumulator 407
21/02/17 01:26:20 INFO ContextCleaner: Cleaned accumulator 320
21/02/17 01:26:20 INFO ContextCleaner: Cleaned accumulator 342
21/02/17 01:26:20 INFO ContextCleaner: Cleaned accumulator 330
21/02/17 01:26:20 INFO ContextCleaner: Cleaned accumulator 435
21/02/17 01:26:20 INFO ContextCleaner: Cleaned accumulator 291
21/02/17 01:26:20 INFO ContextCleaner: Cleaned accumulator 275
21/02/17 01:26:20 INFO ContextCleaner: Cleaned accumulator 219
21/02/17 01:26:20 INFO ContextCleaner: Cleaned accumulator 293
21/02/17 01:26:20 INFO ContextCleaner: Cleaned accumulator 436
21/02/17 01:26:20 INFO ContextCleaner: Cleaned accumulator 337
21/02/17 01:26:20 INFO ContextCleaner: Cleaned accumulator 247
21/02/17 01:26:20 INFO ContextCleaner: Cleaned accumulator 253
21/02/17 01:26:20 INFO ContextCleaner: Cleaned accumulator 215
21/02/17 01:26:20 INFO ContextCleaner: Cleaned accumulator 446
21/02/17 01:26:20 INFO ContextCleaner: Cleaned accumulator 323
21/02/17 01:26:20 INFO ContextCleaner: Cleaned shuffle 2
21/02/17 01:26:20 INFO ContextCleaner: Cleaned accumulator 234
21/02/17 01:26:20 INFO ContextCleaner: Cleaned accumulator 474
21/02/17 01:26:20 INFO ContextCleaner: Cleaned accumulator 387
21/02/17 01:26:20 INFO ContextCleaner: Cleaned accumulator 464
21/02/17 01:26:20 INFO ContextCleaner: Cleaned accumulator 388
21/02/17 01:26:20 INFO ContextCleaner: Cleaned accumulator 230
21/02/17 01:26:20 INFO ContextCleaner: Cleaned accumulator 307
21/02/17 01:26:20 INFO ContextCleaner: Cleaned accumulator 221
21/02/17 01:26:20 INFO ContextCleaner: Cleaned accumulator 424
21/02/17 01:26:20 INFO ContextCleaner: Cleaned accumulator 448
21/02/17 01:26:20 INFO ContextCleaner: Cleaned accumulator 472
21/02/17 01:26:20 INFO ContextCleaner: Cleaned accumulator 223
21/02/17 01:26:20 INFO BlockManagerInfo: Removed broadcast_8_piece0 on localhost:33095 in memory (size: 14.3 KB, free: 912.3 MB)
21/02/17 01:26:20 INFO ContextCleaner: Cleaned accumulator 390
21/02/17 01:26:20 INFO SparkHadoopWriter: Job job_20210217012620_0065 committed.
21/02/17 01:26:20 INFO ParquetFileFormat: Using default output committer for Parquet: org.apache.parquet.hadoop.ParquetOutputCommitter
21/02/17 01:26:20 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
21/02/17 01:26:20 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
21/02/17 01:26:20 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
21/02/17 01:26:20 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
21/02/17 01:26:20 INFO CodeGenerator: Code generated in 7.249935 ms
21/02/17 01:26:20 INFO SparkContext: Starting job: parquet at RFormula.scala:421
21/02/17 01:26:20 INFO DAGScheduler: Registering RDD 68 (parquet at RFormula.scala:421)
21/02/17 01:26:20 INFO DAGScheduler: Got job 13 (parquet at RFormula.scala:421) with 1 output partitions
21/02/17 01:26:20 INFO DAGScheduler: Final stage: ResultStage 18 (parquet at RFormula.scala:421)
21/02/17 01:26:20 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 17)
21/02/17 01:26:20 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 17)
21/02/17 01:26:20 INFO DAGScheduler: Submitting ShuffleMapStage 17 (MapPartitionsRDD[68] at parquet at RFormula.scala:421), which has no missing parents
21/02/17 01:26:20 INFO MemoryStore: Block broadcast_18 stored as values in memory (estimated size 4.8 KB, free 912.2 MB)
21/02/17 01:26:20 INFO MemoryStore: Block broadcast_18_piece0 stored as bytes in memory (estimated size 2.9 KB, free 912.2 MB)
21/02/17 01:26:20 INFO BlockManagerInfo: Added broadcast_18_piece0 in memory on localhost:33095 (size: 2.9 KB, free: 912.3 MB)
21/02/17 01:26:20 INFO SparkContext: Created broadcast 18 from broadcast at DAGScheduler.scala:1039
21/02/17 01:26:20 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 17 (MapPartitionsRDD[68] at parquet at RFormula.scala:421) (first 15 tasks are for partitions Vector(0))
21/02/17 01:26:20 INFO TaskSchedulerImpl: Adding task set 17.0 with 1 tasks
21/02/17 01:26:20 INFO TaskSetManager: Starting task 0.0 in stage 17.0 (TID 17, localhost, executor driver, partition 0, PROCESS_LOCAL, 8164 bytes)
21/02/17 01:26:20 INFO Executor: Running task 0.0 in stage 17.0 (TID 17)
21/02/17 01:26:20 INFO Executor: Finished task 0.0 in stage 17.0 (TID 17). 1247 bytes result sent to driver
21/02/17 01:26:20 INFO TaskSetManager: Finished task 0.0 in stage 17.0 (TID 17) in 4 ms on localhost (executor driver) (1/1)
21/02/17 01:26:20 INFO TaskSchedulerImpl: Removed TaskSet 17.0, whose tasks have all completed, from pool 
21/02/17 01:26:20 INFO DAGScheduler: ShuffleMapStage 17 (parquet at RFormula.scala:421) finished in 0.010 s
21/02/17 01:26:20 INFO DAGScheduler: looking for newly runnable stages
21/02/17 01:26:20 INFO DAGScheduler: running: Set()
21/02/17 01:26:20 INFO DAGScheduler: waiting: Set(ResultStage 18)
21/02/17 01:26:20 INFO DAGScheduler: failed: Set()
21/02/17 01:26:20 INFO DAGScheduler: Submitting ResultStage 18 (ShuffledRowRDD[69] at parquet at RFormula.scala:421), which has no missing parents
21/02/17 01:26:20 INFO MemoryStore: Block broadcast_19 stored as values in memory (estimated size 148.5 KB, free 912.0 MB)
21/02/17 01:26:20 INFO MemoryStore: Block broadcast_19_piece0 stored as bytes in memory (estimated size 52.8 KB, free 912.0 MB)
21/02/17 01:26:20 INFO BlockManagerInfo: Added broadcast_19_piece0 in memory on localhost:33095 (size: 52.8 KB, free: 912.2 MB)
21/02/17 01:26:20 INFO SparkContext: Created broadcast 19 from broadcast at DAGScheduler.scala:1039
21/02/17 01:26:20 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 18 (ShuffledRowRDD[69] at parquet at RFormula.scala:421) (first 15 tasks are for partitions Vector(0))
21/02/17 01:26:20 INFO TaskSchedulerImpl: Adding task set 18.0 with 1 tasks
21/02/17 01:26:20 INFO TaskSetManager: Starting task 0.0 in stage 18.0 (TID 18, localhost, executor driver, partition 0, NODE_LOCAL, 7754 bytes)
21/02/17 01:26:20 INFO Executor: Running task 0.0 in stage 18.0 (TID 18)
21/02/17 01:26:20 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
21/02/17 01:26:20 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
21/02/17 01:26:20 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
21/02/17 01:26:20 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
21/02/17 01:26:20 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
21/02/17 01:26:20 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
21/02/17 01:26:20 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:
{
  "type" : "struct",
  "fields" : [ {
    "name" : "label",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "terms",
    "type" : {
      "type" : "array",
      "elementType" : {
        "type" : "array",
        "elementType" : "string",
        "containsNull" : true
      },
      "containsNull" : true
    },
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "hasIntercept",
    "type" : "boolean",
    "nullable" : false,
    "metadata" : { }
  } ]
}
and corresponding Parquet message type:
message spark_schema {
  optional binary label (UTF8);
  optional group terms (LIST) {
    repeated group list {
      optional group element (LIST) {
        repeated group list {
          optional binary element (UTF8);
        }
      }
    }
  }
  required boolean hasIntercept;
}

       
21/02/17 01:26:20 INFO CodecPool: Got brand-new compressor [.snappy]
21/02/17 01:26:21 INFO FileOutputCommitter: Saved output of task 'attempt_20210217012620_0018_m_000000_0' to file:/tmp/Rtmpghpjcc/file21a0918c1fafd/stages/0_r_formula__013240c4_f8a9_47ce_a2a5_e082efc573d3/data/_temporary/0/task_20210217012620_0018_m_000000
21/02/17 01:26:21 INFO SparkHadoopMapRedUtil: attempt_20210217012620_0018_m_000000_0: Committed
21/02/17 01:26:21 INFO Executor: Finished task 0.0 in stage 18.0 (TID 18). 2351 bytes result sent to driver
21/02/17 01:26:21 INFO TaskSetManager: Finished task 0.0 in stage 18.0 (TID 18) in 248 ms on localhost (executor driver) (1/1)
21/02/17 01:26:21 INFO TaskSchedulerImpl: Removed TaskSet 18.0, whose tasks have all completed, from pool 
21/02/17 01:26:21 INFO DAGScheduler: ResultStage 18 (parquet at RFormula.scala:421) finished in 0.265 s
21/02/17 01:26:21 INFO DAGScheduler: Job 13 finished: parquet at RFormula.scala:421, took 0.277691 s
21/02/17 01:26:21 INFO FileFormatWriter: Job null committed.
21/02/17 01:26:21 INFO FileFormatWriter: Finished processing stats for job null.
21/02/17 01:26:21 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
21/02/17 01:26:21 INFO SparkContext: Starting job: runJob at SparkHadoopWriter.scala:78
21/02/17 01:26:21 INFO DAGScheduler: Got job 14 (runJob at SparkHadoopWriter.scala:78) with 1 output partitions
21/02/17 01:26:21 INFO DAGScheduler: Final stage: ResultStage 19 (runJob at SparkHadoopWriter.scala:78)
21/02/17 01:26:21 INFO DAGScheduler: Parents of final stage: List()
21/02/17 01:26:21 INFO DAGScheduler: Missing parents: List()
21/02/17 01:26:21 INFO DAGScheduler: Submitting ResultStage 19 (MapPartitionsRDD[72] at saveAsTextFile at ReadWrite.scala:283), which has no missing parents
21/02/17 01:26:21 INFO MemoryStore: Block broadcast_20 stored as values in memory (estimated size 71.1 KB, free 911.9 MB)
21/02/17 01:26:21 INFO MemoryStore: Block broadcast_20_piece0 stored as bytes in memory (estimated size 25.5 KB, free 911.9 MB)
21/02/17 01:26:21 INFO BlockManagerInfo: Added broadcast_20_piece0 in memory on localhost:33095 (size: 25.5 KB, free: 912.2 MB)
21/02/17 01:26:21 INFO SparkContext: Created broadcast 20 from broadcast at DAGScheduler.scala:1039
21/02/17 01:26:21 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 19 (MapPartitionsRDD[72] at saveAsTextFile at ReadWrite.scala:283) (first 15 tasks are for partitions Vector(0))
21/02/17 01:26:21 INFO TaskSchedulerImpl: Adding task set 19.0 with 1 tasks
21/02/17 01:26:21 INFO TaskSetManager: Starting task 0.0 in stage 19.0 (TID 19, localhost, executor driver, partition 0, PROCESS_LOCAL, 8147 bytes)
21/02/17 01:26:21 INFO Executor: Running task 0.0 in stage 19.0 (TID 19)
21/02/17 01:26:21 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
21/02/17 01:26:21 INFO FileOutputCommitter: Saved output of task 'attempt_20210217012621_0072_m_000000_0' to file:/tmp/Rtmpghpjcc/file21a0918c1fafd/stages/0_r_formula__013240c4_f8a9_47ce_a2a5_e082efc573d3/pipelineModel/metadata/_temporary/0/task_20210217012621_0072_m_000000
21/02/17 01:26:21 INFO SparkHadoopMapRedUtil: attempt_20210217012621_0072_m_000000_0: Committed
21/02/17 01:26:21 INFO Executor: Finished task 0.0 in stage 19.0 (TID 19). 1072 bytes result sent to driver
21/02/17 01:26:21 INFO TaskSetManager: Finished task 0.0 in stage 19.0 (TID 19) in 13 ms on localhost (executor driver) (1/1)
21/02/17 01:26:21 INFO TaskSchedulerImpl: Removed TaskSet 19.0, whose tasks have all completed, from pool 
21/02/17 01:26:21 INFO DAGScheduler: ResultStage 19 (runJob at SparkHadoopWriter.scala:78) finished in 0.027 s
21/02/17 01:26:21 INFO DAGScheduler: Job 14 finished: runJob at SparkHadoopWriter.scala:78, took 0.028749 s
21/02/17 01:26:21 INFO SparkHadoopWriter: Job job_20210217012621_0072 committed.
21/02/17 01:26:21 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
21/02/17 01:26:21 INFO SparkContext: Starting job: runJob at SparkHadoopWriter.scala:78
21/02/17 01:26:21 INFO DAGScheduler: Got job 15 (runJob at SparkHadoopWriter.scala:78) with 1 output partitions
21/02/17 01:26:21 INFO DAGScheduler: Final stage: ResultStage 20 (runJob at SparkHadoopWriter.scala:78)
21/02/17 01:26:21 INFO DAGScheduler: Parents of final stage: List()
21/02/17 01:26:21 INFO DAGScheduler: Missing parents: List()
21/02/17 01:26:21 INFO DAGScheduler: Submitting ResultStage 20 (MapPartitionsRDD[74] at saveAsTextFile at ReadWrite.scala:283), which has no missing parents
21/02/17 01:26:21 INFO MemoryStore: Block broadcast_21 stored as values in memory (estimated size 71.3 KB, free 911.8 MB)
21/02/17 01:26:21 INFO MemoryStore: Block broadcast_21_piece0 stored as bytes in memory (estimated size 25.5 KB, free 911.8 MB)
21/02/17 01:26:21 INFO BlockManagerInfo: Added broadcast_21_piece0 in memory on localhost:33095 (size: 25.5 KB, free: 912.2 MB)
21/02/17 01:26:21 INFO SparkContext: Created broadcast 21 from broadcast at DAGScheduler.scala:1039
21/02/17 01:26:21 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 20 (MapPartitionsRDD[74] at saveAsTextFile at ReadWrite.scala:283) (first 15 tasks are for partitions Vector(0))
21/02/17 01:26:21 INFO TaskSchedulerImpl: Adding task set 20.0 with 1 tasks
21/02/17 01:26:21 INFO TaskSetManager: Starting task 0.0 in stage 20.0 (TID 20, localhost, executor driver, partition 0, PROCESS_LOCAL, 8097 bytes)
21/02/17 01:26:21 INFO Executor: Running task 0.0 in stage 20.0 (TID 20)
21/02/17 01:26:21 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
21/02/17 01:26:21 INFO FileOutputCommitter: Saved output of task 'attempt_20210217012621_0074_m_000000_0' to file:/tmp/Rtmpghpjcc/file21a0918c1fafd/stages/0_r_formula__013240c4_f8a9_47ce_a2a5_e082efc573d3/pipelineModel/stages/0_r_formula__013240c4_f8a9_47ce_a2a5_e082efc573d3/metadata/_temporary/0/task_20210217012621_0074_m_000000
21/02/17 01:26:21 INFO SparkHadoopMapRedUtil: attempt_20210217012621_0074_m_000000_0: Committed
21/02/17 01:26:21 INFO Executor: Finished task 0.0 in stage 20.0 (TID 20). 1029 bytes result sent to driver
21/02/17 01:26:21 INFO TaskSetManager: Finished task 0.0 in stage 20.0 (TID 20) in 16 ms on localhost (executor driver) (1/1)
21/02/17 01:26:21 INFO TaskSchedulerImpl: Removed TaskSet 20.0, whose tasks have all completed, from pool 
21/02/17 01:26:21 INFO DAGScheduler: ResultStage 20 (runJob at SparkHadoopWriter.scala:78) finished in 0.029 s
21/02/17 01:26:21 INFO DAGScheduler: Job 15 finished: runJob at SparkHadoopWriter.scala:78, took 0.031595 s
21/02/17 01:26:21 INFO SparkHadoopWriter: Job job_20210217012621_0074 committed.
21/02/17 01:26:21 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
21/02/17 01:26:21 INFO SparkContext: Starting job: runJob at SparkHadoopWriter.scala:78
21/02/17 01:26:21 INFO DAGScheduler: Got job 16 (runJob at SparkHadoopWriter.scala:78) with 1 output partitions
21/02/17 01:26:21 INFO DAGScheduler: Final stage: ResultStage 21 (runJob at SparkHadoopWriter.scala:78)
21/02/17 01:26:21 INFO DAGScheduler: Parents of final stage: List()
21/02/17 01:26:21 INFO DAGScheduler: Missing parents: List()
21/02/17 01:26:21 INFO DAGScheduler: Submitting ResultStage 21 (MapPartitionsRDD[76] at saveAsTextFile at ReadWrite.scala:283), which has no missing parents
21/02/17 01:26:21 INFO MemoryStore: Block broadcast_22 stored as values in memory (estimated size 71.2 KB, free 911.7 MB)
21/02/17 01:26:21 INFO MemoryStore: Block broadcast_22_piece0 stored as bytes in memory (estimated size 25.6 KB, free 911.7 MB)
21/02/17 01:26:21 INFO BlockManagerInfo: Added broadcast_22_piece0 in memory on localhost:33095 (size: 25.6 KB, free: 912.1 MB)
21/02/17 01:26:21 INFO SparkContext: Created broadcast 22 from broadcast at DAGScheduler.scala:1039
21/02/17 01:26:21 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 21 (MapPartitionsRDD[76] at saveAsTextFile at ReadWrite.scala:283) (first 15 tasks are for partitions Vector(0))
21/02/17 01:26:21 INFO TaskSchedulerImpl: Adding task set 21.0 with 1 tasks
21/02/17 01:26:21 INFO TaskSetManager: Starting task 0.0 in stage 21.0 (TID 21, localhost, executor driver, partition 0, PROCESS_LOCAL, 8024 bytes)
21/02/17 01:26:21 INFO Executor: Running task 0.0 in stage 21.0 (TID 21)
21/02/17 01:26:21 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
21/02/17 01:26:21 INFO FileOutputCommitter: Saved output of task 'attempt_20210217012621_0076_m_000000_0' to file:/tmp/Rtmpghpjcc/file21a0918c1fafd/stages/0_r_formula__013240c4_f8a9_47ce_a2a5_e082efc573d3/pipelineModel/stages/1_vectorAttrRewriter_b19e0489b37d/metadata/_temporary/0/task_20210217012621_0076_m_000000
21/02/17 01:26:21 INFO SparkHadoopMapRedUtil: attempt_20210217012621_0076_m_000000_0: Committed
21/02/17 01:26:21 INFO Executor: Finished task 0.0 in stage 21.0 (TID 21). 1029 bytes result sent to driver
21/02/17 01:26:21 INFO TaskSetManager: Finished task 0.0 in stage 21.0 (TID 21) in 15 ms on localhost (executor driver) (1/1)
21/02/17 01:26:21 INFO TaskSchedulerImpl: Removed TaskSet 21.0, whose tasks have all completed, from pool 
21/02/17 01:26:21 INFO DAGScheduler: ResultStage 21 (runJob at SparkHadoopWriter.scala:78) finished in 0.028 s
21/02/17 01:26:21 INFO DAGScheduler: Job 16 finished: runJob at SparkHadoopWriter.scala:78, took 0.030301 s
21/02/17 01:26:21 INFO SparkHadoopWriter: Job job_20210217012621_0076 committed.
21/02/17 01:26:21 INFO ParquetFileFormat: Using default output committer for Parquet: org.apache.parquet.hadoop.ParquetOutputCommitter
21/02/17 01:26:21 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
21/02/17 01:26:21 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
21/02/17 01:26:21 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
21/02/17 01:26:21 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
21/02/17 01:26:21 INFO CodeGenerator: Code generated in 8.350357 ms
21/02/17 01:26:21 INFO SparkContext: Starting job: parquet at RFormula.scala:586
21/02/17 01:26:21 INFO DAGScheduler: Registering RDD 79 (parquet at RFormula.scala:586)
21/02/17 01:26:21 INFO DAGScheduler: Got job 17 (parquet at RFormula.scala:586) with 1 output partitions
21/02/17 01:26:21 INFO DAGScheduler: Final stage: ResultStage 23 (parquet at RFormula.scala:586)
21/02/17 01:26:21 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 22)
21/02/17 01:26:21 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 22)
21/02/17 01:26:21 INFO DAGScheduler: Submitting ShuffleMapStage 22 (MapPartitionsRDD[79] at parquet at RFormula.scala:586), which has no missing parents
21/02/17 01:26:21 INFO MemoryStore: Block broadcast_23 stored as values in memory (estimated size 4.8 KB, free 911.7 MB)
21/02/17 01:26:21 INFO MemoryStore: Block broadcast_23_piece0 stored as bytes in memory (estimated size 2.8 KB, free 911.7 MB)
21/02/17 01:26:21 INFO BlockManagerInfo: Added broadcast_23_piece0 in memory on localhost:33095 (size: 2.8 KB, free: 912.1 MB)
21/02/17 01:26:21 INFO SparkContext: Created broadcast 23 from broadcast at DAGScheduler.scala:1039
21/02/17 01:26:21 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 22 (MapPartitionsRDD[79] at parquet at RFormula.scala:586) (first 15 tasks are for partitions Vector(0))
21/02/17 01:26:21 INFO TaskSchedulerImpl: Adding task set 22.0 with 1 tasks
21/02/17 01:26:21 INFO TaskSetManager: Starting task 0.0 in stage 22.0 (TID 22, localhost, executor driver, partition 0, PROCESS_LOCAL, 8060 bytes)
21/02/17 01:26:21 INFO Executor: Running task 0.0 in stage 22.0 (TID 22)
21/02/17 01:26:21 INFO Executor: Finished task 0.0 in stage 22.0 (TID 22). 1247 bytes result sent to driver
21/02/17 01:26:21 INFO TaskSetManager: Finished task 0.0 in stage 22.0 (TID 22) in 4 ms on localhost (executor driver) (1/1)
21/02/17 01:26:21 INFO TaskSchedulerImpl: Removed TaskSet 22.0, whose tasks have all completed, from pool 
21/02/17 01:26:21 INFO DAGScheduler: ShuffleMapStage 22 (parquet at RFormula.scala:586) finished in 0.008 s
21/02/17 01:26:21 INFO DAGScheduler: looking for newly runnable stages
21/02/17 01:26:21 INFO DAGScheduler: running: Set()
21/02/17 01:26:21 INFO DAGScheduler: waiting: Set(ResultStage 23)
21/02/17 01:26:21 INFO DAGScheduler: failed: Set()
21/02/17 01:26:21 INFO DAGScheduler: Submitting ResultStage 23 (ShuffledRowRDD[80] at parquet at RFormula.scala:586), which has no missing parents
21/02/17 01:26:21 INFO MemoryStore: Block broadcast_24 stored as values in memory (estimated size 148.5 KB, free 911.6 MB)
21/02/17 01:26:21 INFO MemoryStore: Block broadcast_24_piece0 stored as bytes in memory (estimated size 52.9 KB, free 911.5 MB)
21/02/17 01:26:21 INFO BlockManagerInfo: Added broadcast_24_piece0 in memory on localhost:33095 (size: 52.9 KB, free: 912.1 MB)
21/02/17 01:26:21 INFO SparkContext: Created broadcast 24 from broadcast at DAGScheduler.scala:1039
21/02/17 01:26:21 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 23 (ShuffledRowRDD[80] at parquet at RFormula.scala:586) (first 15 tasks are for partitions Vector(0))
21/02/17 01:26:21 INFO TaskSchedulerImpl: Adding task set 23.0 with 1 tasks
21/02/17 01:26:21 INFO TaskSetManager: Starting task 0.0 in stage 23.0 (TID 23, localhost, executor driver, partition 0, NODE_LOCAL, 7754 bytes)
21/02/17 01:26:21 INFO Executor: Running task 0.0 in stage 23.0 (TID 23)
21/02/17 01:26:21 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
21/02/17 01:26:21 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
21/02/17 01:26:21 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
21/02/17 01:26:21 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
21/02/17 01:26:21 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
21/02/17 01:26:21 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
21/02/17 01:26:21 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:
{
  "type" : "struct",
  "fields" : [ {
    "name" : "vectorCol",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "prefixesToRewrite",
    "type" : {
      "type" : "map",
      "keyType" : "string",
      "valueType" : "string",
      "valueContainsNull" : true
    },
    "nullable" : true,
    "metadata" : { }
  } ]
}
and corresponding Parquet message type:
message spark_schema {
  optional binary vectorCol (UTF8);
  optional group prefixesToRewrite (MAP) {
    repeated group key_value {
      required binary key (UTF8);
      optional binary value (UTF8);
    }
  }
}

       
21/02/17 01:26:21 INFO FileOutputCommitter: Saved output of task 'attempt_20210217012621_0023_m_000000_0' to file:/tmp/Rtmpghpjcc/file21a0918c1fafd/stages/0_r_formula__013240c4_f8a9_47ce_a2a5_e082efc573d3/pipelineModel/stages/1_vectorAttrRewriter_b19e0489b37d/data/_temporary/0/task_20210217012621_0023_m_000000
21/02/17 01:26:21 INFO SparkHadoopMapRedUtil: attempt_20210217012621_0023_m_000000_0: Committed
21/02/17 01:26:21 INFO Executor: Finished task 0.0 in stage 23.0 (TID 23). 2308 bytes result sent to driver
21/02/17 01:26:21 INFO TaskSetManager: Finished task 0.0 in stage 23.0 (TID 23) in 33 ms on localhost (executor driver) (1/1)
21/02/17 01:26:21 INFO TaskSchedulerImpl: Removed TaskSet 23.0, whose tasks have all completed, from pool 
21/02/17 01:26:21 INFO DAGScheduler: ResultStage 23 (parquet at RFormula.scala:586) finished in 0.054 s
21/02/17 01:26:21 INFO DAGScheduler: Job 17 finished: parquet at RFormula.scala:586, took 0.065708 s
21/02/17 01:26:21 INFO FileFormatWriter: Job null committed.
21/02/17 01:26:21 INFO FileFormatWriter: Finished processing stats for job null.
21/02/17 01:26:21 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
21/02/17 01:26:21 INFO SparkContext: Starting job: runJob at SparkHadoopWriter.scala:78
21/02/17 01:26:21 INFO DAGScheduler: Got job 18 (runJob at SparkHadoopWriter.scala:78) with 1 output partitions
21/02/17 01:26:21 INFO DAGScheduler: Final stage: ResultStage 24 (runJob at SparkHadoopWriter.scala:78)
21/02/17 01:26:21 INFO DAGScheduler: Parents of final stage: List()
21/02/17 01:26:21 INFO DAGScheduler: Missing parents: List()
21/02/17 01:26:21 INFO DAGScheduler: Submitting ResultStage 24 (MapPartitionsRDD[83] at saveAsTextFile at ReadWrite.scala:283), which has no missing parents
21/02/17 01:26:21 INFO MemoryStore: Block broadcast_25 stored as values in memory (estimated size 71.2 KB, free 911.4 MB)
21/02/17 01:26:21 INFO MemoryStore: Block broadcast_25_piece0 stored as bytes in memory (estimated size 25.6 KB, free 911.4 MB)
21/02/17 01:26:21 INFO BlockManagerInfo: Added broadcast_25_piece0 in memory on localhost:33095 (size: 25.6 KB, free: 912.1 MB)
21/02/17 01:26:21 INFO SparkContext: Created broadcast 25 from broadcast at DAGScheduler.scala:1039
21/02/17 01:26:21 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 24 (MapPartitionsRDD[83] at saveAsTextFile at ReadWrite.scala:283) (first 15 tasks are for partitions Vector(0))
21/02/17 01:26:21 INFO TaskSchedulerImpl: Adding task set 24.0 with 1 tasks
21/02/17 01:26:21 INFO TaskSetManager: Starting task 0.0 in stage 24.0 (TID 24, localhost, executor driver, partition 0, PROCESS_LOCAL, 8007 bytes)
21/02/17 01:26:21 INFO Executor: Running task 0.0 in stage 24.0 (TID 24)
21/02/17 01:26:21 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
21/02/17 01:26:21 INFO FileOutputCommitter: Saved output of task 'attempt_20210217012621_0083_m_000000_0' to file:/tmp/Rtmpghpjcc/file21a0918c1fafd/stages/0_r_formula__013240c4_f8a9_47ce_a2a5_e082efc573d3/pipelineModel/stages/2_columnPruner_3b1b690af86d/metadata/_temporary/0/task_20210217012621_0083_m_000000
21/02/17 01:26:21 INFO SparkHadoopMapRedUtil: attempt_20210217012621_0083_m_000000_0: Committed
21/02/17 01:26:21 INFO Executor: Finished task 0.0 in stage 24.0 (TID 24). 1029 bytes result sent to driver
21/02/17 01:26:21 INFO TaskSetManager: Finished task 0.0 in stage 24.0 (TID 24) in 13 ms on localhost (executor driver) (1/1)
21/02/17 01:26:21 INFO TaskSchedulerImpl: Removed TaskSet 24.0, whose tasks have all completed, from pool 
21/02/17 01:26:21 INFO DAGScheduler: ResultStage 24 (runJob at SparkHadoopWriter.scala:78) finished in 0.027 s
21/02/17 01:26:21 INFO DAGScheduler: Job 18 finished: runJob at SparkHadoopWriter.scala:78, took 0.028244 s
21/02/17 01:26:21 INFO SparkHadoopWriter: Job job_20210217012621_0083 committed.
21/02/17 01:26:21 INFO ParquetFileFormat: Using default output committer for Parquet: org.apache.parquet.hadoop.ParquetOutputCommitter
21/02/17 01:26:21 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
21/02/17 01:26:21 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
21/02/17 01:26:21 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
21/02/17 01:26:21 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
21/02/17 01:26:21 INFO CodeGenerator: Code generated in 7.399638 ms
21/02/17 01:26:21 INFO SparkContext: Starting job: parquet at RFormula.scala:495
21/02/17 01:26:21 INFO DAGScheduler: Registering RDD 86 (parquet at RFormula.scala:495)
21/02/17 01:26:21 INFO DAGScheduler: Got job 19 (parquet at RFormula.scala:495) with 1 output partitions
21/02/17 01:26:21 INFO DAGScheduler: Final stage: ResultStage 26 (parquet at RFormula.scala:495)
21/02/17 01:26:21 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 25)
21/02/17 01:26:21 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 25)
21/02/17 01:26:21 INFO DAGScheduler: Submitting ShuffleMapStage 25 (MapPartitionsRDD[86] at parquet at RFormula.scala:495), which has no missing parents
21/02/17 01:26:21 INFO MemoryStore: Block broadcast_26 stored as values in memory (estimated size 4.7 KB, free 911.4 MB)
21/02/17 01:26:21 INFO MemoryStore: Block broadcast_26_piece0 stored as bytes in memory (estimated size 2.8 KB, free 911.4 MB)
21/02/17 01:26:21 INFO BlockManagerInfo: Added broadcast_26_piece0 in memory on localhost:33095 (size: 2.8 KB, free: 912.1 MB)
21/02/17 01:26:21 INFO SparkContext: Created broadcast 26 from broadcast at DAGScheduler.scala:1039
21/02/17 01:26:21 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 25 (MapPartitionsRDD[86] at parquet at RFormula.scala:495) (first 15 tasks are for partitions Vector(0))
21/02/17 01:26:21 INFO TaskSchedulerImpl: Adding task set 25.0 with 1 tasks
21/02/17 01:26:21 INFO TaskSetManager: Starting task 0.0 in stage 25.0 (TID 25, localhost, executor driver, partition 0, PROCESS_LOCAL, 8028 bytes)
21/02/17 01:26:21 INFO Executor: Running task 0.0 in stage 25.0 (TID 25)
21/02/17 01:26:21 INFO Executor: Finished task 0.0 in stage 25.0 (TID 25). 1247 bytes result sent to driver
21/02/17 01:26:21 INFO TaskSetManager: Finished task 0.0 in stage 25.0 (TID 25) in 3 ms on localhost (executor driver) (1/1)
21/02/17 01:26:21 INFO TaskSchedulerImpl: Removed TaskSet 25.0, whose tasks have all completed, from pool 
21/02/17 01:26:21 INFO DAGScheduler: ShuffleMapStage 25 (parquet at RFormula.scala:495) finished in 0.008 s
21/02/17 01:26:21 INFO DAGScheduler: looking for newly runnable stages
21/02/17 01:26:21 INFO DAGScheduler: running: Set()
21/02/17 01:26:21 INFO DAGScheduler: waiting: Set(ResultStage 26)
21/02/17 01:26:21 INFO DAGScheduler: failed: Set()
21/02/17 01:26:21 INFO DAGScheduler: Submitting ResultStage 26 (ShuffledRowRDD[87] at parquet at RFormula.scala:495), which has no missing parents
21/02/17 01:26:21 INFO MemoryStore: Block broadcast_27 stored as values in memory (estimated size 148.3 KB, free 911.3 MB)
21/02/17 01:26:21 INFO MemoryStore: Block broadcast_27_piece0 stored as bytes in memory (estimated size 52.8 KB, free 911.2 MB)
21/02/17 01:26:21 INFO BlockManagerInfo: Added broadcast_27_piece0 in memory on localhost:33095 (size: 52.8 KB, free: 912.0 MB)
21/02/17 01:26:21 INFO SparkContext: Created broadcast 27 from broadcast at DAGScheduler.scala:1039
21/02/17 01:26:21 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 26 (ShuffledRowRDD[87] at parquet at RFormula.scala:495) (first 15 tasks are for partitions Vector(0))
21/02/17 01:26:21 INFO TaskSchedulerImpl: Adding task set 26.0 with 1 tasks
21/02/17 01:26:21 INFO TaskSetManager: Starting task 0.0 in stage 26.0 (TID 26, localhost, executor driver, partition 0, NODE_LOCAL, 7754 bytes)
21/02/17 01:26:21 INFO Executor: Running task 0.0 in stage 26.0 (TID 26)
21/02/17 01:26:21 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
21/02/17 01:26:21 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
21/02/17 01:26:21 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
21/02/17 01:26:21 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
21/02/17 01:26:21 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
21/02/17 01:26:21 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
21/02/17 01:26:21 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:
{
  "type" : "struct",
  "fields" : [ {
    "name" : "columnsToPrune",
    "type" : {
      "type" : "array",
      "elementType" : "string",
      "containsNull" : true
    },
    "nullable" : true,
    "metadata" : { }
  } ]
}
and corresponding Parquet message type:
message spark_schema {
  optional group columnsToPrune (LIST) {
    repeated group list {
      optional binary element (UTF8);
    }
  }
}

       
21/02/17 01:26:21 INFO FileOutputCommitter: Saved output of task 'attempt_20210217012621_0026_m_000000_0' to file:/tmp/Rtmpghpjcc/file21a0918c1fafd/stages/0_r_formula__013240c4_f8a9_47ce_a2a5_e082efc573d3/pipelineModel/stages/2_columnPruner_3b1b690af86d/data/_temporary/0/task_20210217012621_0026_m_000000
21/02/17 01:26:21 INFO SparkHadoopMapRedUtil: attempt_20210217012621_0026_m_000000_0: Committed
21/02/17 01:26:21 INFO Executor: Finished task 0.0 in stage 26.0 (TID 26). 2308 bytes result sent to driver
21/02/17 01:26:21 INFO TaskSetManager: Finished task 0.0 in stage 26.0 (TID 26) in 18 ms on localhost (executor driver) (1/1)
21/02/17 01:26:21 INFO TaskSchedulerImpl: Removed TaskSet 26.0, whose tasks have all completed, from pool 
21/02/17 01:26:21 INFO DAGScheduler: ResultStage 26 (parquet at RFormula.scala:495) finished in 0.039 s
21/02/17 01:26:21 INFO DAGScheduler: Job 19 finished: parquet at RFormula.scala:495, took 0.049000 s
21/02/17 01:26:21 INFO FileFormatWriter: Job null committed.
21/02/17 01:26:21 INFO FileFormatWriter: Finished processing stats for job null.
21/02/17 01:26:23 INFO SparkContext: Invoking stop() from shutdown hook
21/02/17 01:26:23 INFO SparkUI: Stopped Spark web UI at http://localhost:4040
21/02/17 01:26:23 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!
21/02/17 01:26:23 INFO MemoryStore: MemoryStore cleared
21/02/17 01:26:23 INFO BlockManager: BlockManager stopped
21/02/17 01:26:23 INFO BlockManagerMaster: BlockManagerMaster stopped
21/02/17 01:26:23 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!
21/02/17 01:26:23 INFO SparkContext: Successfully stopped SparkContext
21/02/17 01:26:23 INFO ShutdownHookManager: Shutdown hook called
21/02/17 01:26:23 INFO ShutdownHookManager: Deleting directory /tmp/spark-17e5cbf6-4e53-449e-b4d9-6b2aeebbd98b
21/02/17 01:26:23 INFO ShutdownHookManager: Deleting directory /tmp/spark-ae8699b3-2e18-4a1f-854a-4115adcb4f27
21/02/17 01:29:47 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
21/02/17 01:29:48 INFO SparkContext: Running Spark version 2.3.0
21/02/17 01:29:48 INFO SparkContext: Submitted application: sparklyr
21/02/17 01:29:48 INFO SecurityManager: Changing view acls to: yitaoli
21/02/17 01:29:48 INFO SecurityManager: Changing modify acls to: yitaoli
21/02/17 01:29:48 INFO SecurityManager: Changing view acls groups to: 
21/02/17 01:29:48 INFO SecurityManager: Changing modify acls groups to: 
21/02/17 01:29:48 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(yitaoli); groups with view permissions: Set(); users  with modify permissions: Set(yitaoli); groups with modify permissions: Set()
21/02/17 01:29:48 INFO Utils: Successfully started service 'sparkDriver' on port 43321.
21/02/17 01:29:48 INFO SparkEnv: Registering MapOutputTracker
21/02/17 01:29:48 INFO SparkEnv: Registering BlockManagerMaster
21/02/17 01:29:48 INFO BlockManagerMasterEndpoint: Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
21/02/17 01:29:48 INFO BlockManagerMasterEndpoint: BlockManagerMasterEndpoint up
21/02/17 01:29:48 INFO DiskBlockManager: Created local directory at /tmp/blockmgr-137abee6-683e-4bfc-8ac0-e6db7a0c5588
21/02/17 01:29:48 INFO MemoryStore: MemoryStore started with capacity 912.3 MB
21/02/17 01:29:48 INFO SparkEnv: Registering OutputCommitCoordinator
21/02/17 01:29:49 INFO Utils: Successfully started service 'SparkUI' on port 4040.
21/02/17 01:29:49 INFO SparkUI: Bound SparkUI to 127.0.0.1, and started at http://localhost:4040
21/02/17 01:29:49 INFO SparkContext: Added JAR file:///home/yitaoli/R/x86_64-pc-linux-gnu-library/4.0/sparkxgb/java/sparkxgb-2.3-2.11.jar at spark://localhost:43321/jars/sparkxgb-2.3-2.11.jar with timestamp 1613525389115
21/02/17 01:29:49 INFO SparkContext: Added JAR file:///home/yitaoli/.ivy2/jars/ml.dmlc_xgboost4j-spark_2.11-1.1.2.jar at spark://localhost:43321/jars/ml.dmlc_xgboost4j-spark_2.11-1.1.2.jar with timestamp 1613525389115
21/02/17 01:29:49 INFO SparkContext: Added JAR file:///home/yitaoli/.ivy2/jars/org.json4s_json4s-jackson_2.12-3.6.10.jar at spark://localhost:43321/jars/org.json4s_json4s-jackson_2.12-3.6.10.jar with timestamp 1613525389115
21/02/17 01:29:49 INFO SparkContext: Added JAR file:///home/yitaoli/.ivy2/jars/ml.dmlc_xgboost4j_2.11-1.1.2.jar at spark://localhost:43321/jars/ml.dmlc_xgboost4j_2.11-1.1.2.jar with timestamp 1613525389116
21/02/17 01:29:49 INFO SparkContext: Added JAR file:///home/yitaoli/.ivy2/jars/com.esotericsoftware.kryo_kryo-2.22.jar at spark://localhost:43321/jars/com.esotericsoftware.kryo_kryo-2.22.jar with timestamp 1613525389116
21/02/17 01:29:49 INFO SparkContext: Added JAR file:///home/yitaoli/.ivy2/jars/org.scala-lang_scala-compiler-2.11.12.jar at spark://localhost:43321/jars/org.scala-lang_scala-compiler-2.11.12.jar with timestamp 1613525389116
21/02/17 01:29:49 INFO SparkContext: Added JAR file:///home/yitaoli/.ivy2/jars/org.scala-lang_scala-reflect-2.11.12.jar at spark://localhost:43321/jars/org.scala-lang_scala-reflect-2.11.12.jar with timestamp 1613525389116
21/02/17 01:29:49 INFO SparkContext: Added JAR file:///home/yitaoli/.ivy2/jars/commons-logging_commons-logging-1.2.jar at spark://localhost:43321/jars/commons-logging_commons-logging-1.2.jar with timestamp 1613525389116
21/02/17 01:29:49 INFO SparkContext: Added JAR file:///home/yitaoli/.ivy2/jars/com.typesafe.akka_akka-actor_2.11-2.5.23.jar at spark://localhost:43321/jars/com.typesafe.akka_akka-actor_2.11-2.5.23.jar with timestamp 1613525389116
21/02/17 01:29:49 INFO SparkContext: Added JAR file:///home/yitaoli/.ivy2/jars/com.typesafe_config-1.3.3.jar at spark://localhost:43321/jars/com.typesafe_config-1.3.3.jar with timestamp 1613525389116
21/02/17 01:29:49 INFO SparkContext: Added JAR file:///home/yitaoli/.ivy2/jars/org.scala-lang.modules_scala-java8-compat_2.11-0.7.0.jar at spark://localhost:43321/jars/org.scala-lang.modules_scala-java8-compat_2.11-0.7.0.jar with timestamp 1613525389116
21/02/17 01:29:49 INFO SparkContext: Added JAR file:///home/yitaoli/.ivy2/jars/org.scala-lang.modules_scala-xml_2.11-1.0.5.jar at spark://localhost:43321/jars/org.scala-lang.modules_scala-xml_2.11-1.0.5.jar with timestamp 1613525389116
21/02/17 01:29:49 INFO SparkContext: Added JAR file:///home/yitaoli/.ivy2/jars/org.scala-lang.modules_scala-parser-combinators_2.11-1.0.4.jar at spark://localhost:43321/jars/org.scala-lang.modules_scala-parser-combinators_2.11-1.0.4.jar with timestamp 1613525389116
21/02/17 01:29:49 INFO SparkContext: Added JAR file:///home/yitaoli/.ivy2/jars/org.json4s_json4s-core_2.12-3.6.10.jar at spark://localhost:43321/jars/org.json4s_json4s-core_2.12-3.6.10.jar with timestamp 1613525389116
21/02/17 01:29:49 INFO SparkContext: Added JAR file:///home/yitaoli/.ivy2/jars/com.fasterxml.jackson.core_jackson-databind-2.9.10.6.jar at spark://localhost:43321/jars/com.fasterxml.jackson.core_jackson-databind-2.9.10.6.jar with timestamp 1613525389116
21/02/17 01:29:49 INFO SparkContext: Added JAR file:///home/yitaoli/.ivy2/jars/org.json4s_json4s-ast_2.12-3.6.10.jar at spark://localhost:43321/jars/org.json4s_json4s-ast_2.12-3.6.10.jar with timestamp 1613525389116
21/02/17 01:29:49 INFO SparkContext: Added JAR file:///home/yitaoli/.ivy2/jars/org.json4s_json4s-scalap_2.12-3.6.10.jar at spark://localhost:43321/jars/org.json4s_json4s-scalap_2.12-3.6.10.jar with timestamp 1613525389116
21/02/17 01:29:49 INFO SparkContext: Added JAR file:///home/yitaoli/.ivy2/jars/com.thoughtworks.paranamer_paranamer-2.8.jar at spark://localhost:43321/jars/com.thoughtworks.paranamer_paranamer-2.8.jar with timestamp 1613525389117
21/02/17 01:29:49 INFO SparkContext: Added JAR file:///home/yitaoli/.ivy2/jars/com.fasterxml.jackson.core_jackson-annotations-2.9.10.jar at spark://localhost:43321/jars/com.fasterxml.jackson.core_jackson-annotations-2.9.10.jar with timestamp 1613525389117
21/02/17 01:29:49 INFO SparkContext: Added JAR file:///home/yitaoli/.ivy2/jars/com.fasterxml.jackson.core_jackson-core-2.9.10.jar at spark://localhost:43321/jars/com.fasterxml.jackson.core_jackson-core-2.9.10.jar with timestamp 1613525389117
21/02/17 01:29:49 INFO SparkContext: Added JAR file:/home/yitaoli/R/x86_64-pc-linux-gnu-library/4.0/sparklyr/java/sparklyr-2.3-2.11.jar at spark://localhost:43321/jars/sparklyr-2.3-2.11.jar with timestamp 1613525389117
21/02/17 01:29:49 INFO Executor: Starting executor ID driver on host localhost
21/02/17 01:29:49 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 34957.
21/02/17 01:29:49 INFO NettyBlockTransferService: Server created on localhost:34957
21/02/17 01:29:49 INFO BlockManager: Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
21/02/17 01:29:49 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, localhost, 34957, None)
21/02/17 01:29:49 INFO BlockManagerMasterEndpoint: Registering block manager localhost:34957 with 912.3 MB RAM, BlockManagerId(driver, localhost, 34957, None)
21/02/17 01:29:49 INFO BlockManagerMaster: Registered BlockManager BlockManagerId(driver, localhost, 34957, None)
21/02/17 01:29:49 INFO BlockManager: Initialized BlockManager: BlockManagerId(driver, localhost, 34957, None)
21/02/17 01:29:49 INFO SharedState: loading hive config file: file:/home/yitaoli/spark/spark-2.3.0-bin-hadoop2.7/conf/hive-site.xml
21/02/17 01:29:49 INFO SharedState: Setting hive.metastore.warehouse.dir ('null') to the value of spark.sql.warehouse.dir ('file:/home/yitaoli/sparkxgb/tests/testthat/spark-warehouse').
21/02/17 01:29:49 INFO SharedState: Warehouse path is 'file:/home/yitaoli/sparkxgb/tests/testthat/spark-warehouse'.
21/02/17 01:29:49 INFO StateStoreCoordinatorRef: Registered StateStoreCoordinator endpoint
21/02/17 01:29:50 INFO HiveUtils: Initializing HiveMetastoreConnection version 1.2.1 using Spark classes.
21/02/17 01:29:51 INFO HiveMetaStore: 0: Opening raw store with implemenation class:org.apache.hadoop.hive.metastore.ObjectStore
21/02/17 01:29:51 INFO ObjectStore: ObjectStore, initialize called
21/02/17 01:29:51 INFO Persistence: Property hive.metastore.integral.jdo.pushdown unknown - will be ignored
21/02/17 01:29:51 INFO Persistence: Property datanucleus.cache.level2 unknown - will be ignored
21/02/17 01:29:52 INFO ObjectStore: Setting MetaStore object pin classes with hive.metastore.cache.pinobjtypes="Table,StorageDescriptor,SerDeInfo,Partition,Database,Type,FieldSchema,Order"
21/02/17 01:29:52 INFO Datastore: The class "org.apache.hadoop.hive.metastore.model.MFieldSchema" is tagged as "embedded-only" so does not have its own datastore table.
21/02/17 01:29:52 INFO Datastore: The class "org.apache.hadoop.hive.metastore.model.MOrder" is tagged as "embedded-only" so does not have its own datastore table.
21/02/17 01:29:53 INFO Datastore: The class "org.apache.hadoop.hive.metastore.model.MFieldSchema" is tagged as "embedded-only" so does not have its own datastore table.
21/02/17 01:29:53 INFO Datastore: The class "org.apache.hadoop.hive.metastore.model.MOrder" is tagged as "embedded-only" so does not have its own datastore table.
21/02/17 01:29:53 INFO MetaStoreDirectSql: Using direct SQL, underlying DB is DERBY
21/02/17 01:29:53 INFO ObjectStore: Initialized ObjectStore
21/02/17 01:29:53 WARN ObjectStore: Version information not found in metastore. hive.metastore.schema.verification is not enabled so recording the schema version 1.2.0
21/02/17 01:29:53 WARN ObjectStore: Failed to get database default, returning NoSuchObjectException
21/02/17 01:29:53 INFO HiveMetaStore: Added admin role in metastore
21/02/17 01:29:53 INFO HiveMetaStore: Added public role in metastore
21/02/17 01:29:53 INFO HiveMetaStore: No user is added in admin role, since config is empty
21/02/17 01:29:53 INFO HiveMetaStore: 0: get_all_databases
21/02/17 01:29:53 INFO audit: ugi=yitaoli	ip=unknown-ip-addr	cmd=get_all_databases	
21/02/17 01:29:53 INFO HiveMetaStore: 0: get_functions: db=default pat=*
21/02/17 01:29:53 INFO audit: ugi=yitaoli	ip=unknown-ip-addr	cmd=get_functions: db=default pat=*	
21/02/17 01:29:53 INFO Datastore: The class "org.apache.hadoop.hive.metastore.model.MResourceUri" is tagged as "embedded-only" so does not have its own datastore table.
21/02/17 01:29:53 INFO SessionState: Created local directory: /tmp/73a273a4-757d-4b6e-8ccd-c68420770eba_resources
21/02/17 01:29:53 INFO SessionState: Created HDFS directory: /tmp/hive/yitaoli/73a273a4-757d-4b6e-8ccd-c68420770eba
21/02/17 01:29:53 INFO SessionState: Created local directory: /tmp/yitaoli/73a273a4-757d-4b6e-8ccd-c68420770eba
21/02/17 01:29:53 INFO SessionState: Created HDFS directory: /tmp/hive/yitaoli/73a273a4-757d-4b6e-8ccd-c68420770eba/_tmp_space.db
21/02/17 01:29:53 INFO HiveClientImpl: Warehouse location for Hive client (version 1.2.2) is file:/home/yitaoli/sparkxgb/tests/testthat/spark-warehouse
21/02/17 01:29:53 INFO HiveMetaStore: 0: get_database: default
21/02/17 01:29:53 INFO audit: ugi=yitaoli	ip=unknown-ip-addr	cmd=get_database: default	
21/02/17 01:29:53 INFO HiveMetaStore: 0: get_database: global_temp
21/02/17 01:29:53 INFO audit: ugi=yitaoli	ip=unknown-ip-addr	cmd=get_database: global_temp	
21/02/17 01:29:53 WARN ObjectStore: Failed to get database global_temp, returning NoSuchObjectException
21/02/17 01:29:53 INFO HiveMetaStore: 0: get_table : db=default tbl=iris
21/02/17 01:29:53 INFO audit: ugi=yitaoli	ip=unknown-ip-addr	cmd=get_table : db=default tbl=iris	
21/02/17 01:29:54 INFO HiveMetaStore: 0: get_database: default
21/02/17 01:29:54 INFO audit: ugi=yitaoli	ip=unknown-ip-addr	cmd=get_database: default	
21/02/17 01:29:54 INFO HiveMetaStore: 0: get_database: default
21/02/17 01:29:54 INFO audit: ugi=yitaoli	ip=unknown-ip-addr	cmd=get_database: default	
21/02/17 01:29:54 INFO HiveMetaStore: 0: get_tables: db=default pat=*
21/02/17 01:29:54 INFO audit: ugi=yitaoli	ip=unknown-ip-addr	cmd=get_tables: db=default pat=*	
21/02/17 01:29:54 INFO SparkContext: Starting job: collect at utils.scala:61
21/02/17 01:29:54 INFO DAGScheduler: Got job 0 (collect at utils.scala:61) with 1 output partitions
21/02/17 01:29:54 INFO DAGScheduler: Final stage: ResultStage 0 (collect at utils.scala:61)
21/02/17 01:29:54 INFO DAGScheduler: Parents of final stage: List()
21/02/17 01:29:54 INFO DAGScheduler: Missing parents: List()
21/02/17 01:29:54 INFO DAGScheduler: Submitting ResultStage 0 (MapPartitionsRDD[4] at map at utils.scala:54), which has no missing parents
21/02/17 01:29:54 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 5.9 KB, free 912.3 MB)
21/02/17 01:29:54 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 3.3 KB, free 912.3 MB)
21/02/17 01:29:54 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on localhost:34957 (size: 3.3 KB, free: 912.3 MB)
21/02/17 01:29:54 INFO SparkContext: Created broadcast 0 from broadcast at DAGScheduler.scala:1039
21/02/17 01:29:54 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 0 (MapPartitionsRDD[4] at map at utils.scala:54) (first 15 tasks are for partitions Vector(0))
21/02/17 01:29:54 INFO TaskSchedulerImpl: Adding task set 0.0 with 1 tasks
21/02/17 01:29:54 INFO TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0, localhost, executor driver, partition 0, PROCESS_LOCAL, 7880 bytes)
21/02/17 01:29:54 INFO Executor: Running task 0.0 in stage 0.0 (TID 0)
21/02/17 01:29:54 INFO Executor: Fetching spark://localhost:43321/jars/com.fasterxml.jackson.core_jackson-annotations-2.9.10.jar with timestamp 1613525389117
21/02/17 01:29:54 INFO TransportClientFactory: Successfully created connection to localhost/127.0.0.1:43321 after 11 ms (0 ms spent in bootstraps)
21/02/17 01:29:54 INFO Utils: Fetching spark://localhost:43321/jars/com.fasterxml.jackson.core_jackson-annotations-2.9.10.jar to /tmp/spark-7d5a3c76-94d0-4892-a5db-ceb513008a9e/userFiles-15a5b4f2-4bef-433a-a2c9-0b6b0e6eda52/fetchFileTemp666297191028292438.tmp
21/02/17 01:29:54 INFO Executor: Adding file:/tmp/spark-7d5a3c76-94d0-4892-a5db-ceb513008a9e/userFiles-15a5b4f2-4bef-433a-a2c9-0b6b0e6eda52/com.fasterxml.jackson.core_jackson-annotations-2.9.10.jar to class loader
21/02/17 01:29:54 INFO Executor: Fetching spark://localhost:43321/jars/com.thoughtworks.paranamer_paranamer-2.8.jar with timestamp 1613525389117
21/02/17 01:29:54 INFO Utils: Fetching spark://localhost:43321/jars/com.thoughtworks.paranamer_paranamer-2.8.jar to /tmp/spark-7d5a3c76-94d0-4892-a5db-ceb513008a9e/userFiles-15a5b4f2-4bef-433a-a2c9-0b6b0e6eda52/fetchFileTemp463792688458326221.tmp
21/02/17 01:29:54 INFO Executor: Adding file:/tmp/spark-7d5a3c76-94d0-4892-a5db-ceb513008a9e/userFiles-15a5b4f2-4bef-433a-a2c9-0b6b0e6eda52/com.thoughtworks.paranamer_paranamer-2.8.jar to class loader
21/02/17 01:29:54 INFO Executor: Fetching spark://localhost:43321/jars/org.scala-lang.modules_scala-parser-combinators_2.11-1.0.4.jar with timestamp 1613525389116
21/02/17 01:29:54 INFO Utils: Fetching spark://localhost:43321/jars/org.scala-lang.modules_scala-parser-combinators_2.11-1.0.4.jar to /tmp/spark-7d5a3c76-94d0-4892-a5db-ceb513008a9e/userFiles-15a5b4f2-4bef-433a-a2c9-0b6b0e6eda52/fetchFileTemp8954703911604408670.tmp
21/02/17 01:29:54 INFO Executor: Adding file:/tmp/spark-7d5a3c76-94d0-4892-a5db-ceb513008a9e/userFiles-15a5b4f2-4bef-433a-a2c9-0b6b0e6eda52/org.scala-lang.modules_scala-parser-combinators_2.11-1.0.4.jar to class loader
21/02/17 01:29:54 INFO Executor: Fetching spark://localhost:43321/jars/sparkxgb-2.3-2.11.jar with timestamp 1613525389115
21/02/17 01:29:54 INFO Utils: Fetching spark://localhost:43321/jars/sparkxgb-2.3-2.11.jar to /tmp/spark-7d5a3c76-94d0-4892-a5db-ceb513008a9e/userFiles-15a5b4f2-4bef-433a-a2c9-0b6b0e6eda52/fetchFileTemp6442327619878773951.tmp
21/02/17 01:29:54 INFO Executor: Adding file:/tmp/spark-7d5a3c76-94d0-4892-a5db-ceb513008a9e/userFiles-15a5b4f2-4bef-433a-a2c9-0b6b0e6eda52/sparkxgb-2.3-2.11.jar to class loader
21/02/17 01:29:54 INFO Executor: Fetching spark://localhost:43321/jars/ml.dmlc_xgboost4j_2.11-1.1.2.jar with timestamp 1613525389116
21/02/17 01:29:54 INFO Utils: Fetching spark://localhost:43321/jars/ml.dmlc_xgboost4j_2.11-1.1.2.jar to /tmp/spark-7d5a3c76-94d0-4892-a5db-ceb513008a9e/userFiles-15a5b4f2-4bef-433a-a2c9-0b6b0e6eda52/fetchFileTemp9187583989093977788.tmp
21/02/17 01:29:54 INFO Executor: Adding file:/tmp/spark-7d5a3c76-94d0-4892-a5db-ceb513008a9e/userFiles-15a5b4f2-4bef-433a-a2c9-0b6b0e6eda52/ml.dmlc_xgboost4j_2.11-1.1.2.jar to class loader
21/02/17 01:29:54 INFO Executor: Fetching spark://localhost:43321/jars/org.json4s_json4s-jackson_2.12-3.6.10.jar with timestamp 1613525389115
21/02/17 01:29:54 INFO Utils: Fetching spark://localhost:43321/jars/org.json4s_json4s-jackson_2.12-3.6.10.jar to /tmp/spark-7d5a3c76-94d0-4892-a5db-ceb513008a9e/userFiles-15a5b4f2-4bef-433a-a2c9-0b6b0e6eda52/fetchFileTemp7204787226794824138.tmp
21/02/17 01:29:54 INFO Executor: Adding file:/tmp/spark-7d5a3c76-94d0-4892-a5db-ceb513008a9e/userFiles-15a5b4f2-4bef-433a-a2c9-0b6b0e6eda52/org.json4s_json4s-jackson_2.12-3.6.10.jar to class loader
21/02/17 01:29:54 INFO Executor: Fetching spark://localhost:43321/jars/org.scala-lang_scala-compiler-2.11.12.jar with timestamp 1613525389116
21/02/17 01:29:54 INFO Utils: Fetching spark://localhost:43321/jars/org.scala-lang_scala-compiler-2.11.12.jar to /tmp/spark-7d5a3c76-94d0-4892-a5db-ceb513008a9e/userFiles-15a5b4f2-4bef-433a-a2c9-0b6b0e6eda52/fetchFileTemp6891027918025378165.tmp
21/02/17 01:29:54 INFO Executor: Adding file:/tmp/spark-7d5a3c76-94d0-4892-a5db-ceb513008a9e/userFiles-15a5b4f2-4bef-433a-a2c9-0b6b0e6eda52/org.scala-lang_scala-compiler-2.11.12.jar to class loader
21/02/17 01:29:54 INFO Executor: Fetching spark://localhost:43321/jars/org.json4s_json4s-ast_2.12-3.6.10.jar with timestamp 1613525389116
21/02/17 01:29:54 INFO Utils: Fetching spark://localhost:43321/jars/org.json4s_json4s-ast_2.12-3.6.10.jar to /tmp/spark-7d5a3c76-94d0-4892-a5db-ceb513008a9e/userFiles-15a5b4f2-4bef-433a-a2c9-0b6b0e6eda52/fetchFileTemp9093201441177286388.tmp
21/02/17 01:29:54 INFO Executor: Adding file:/tmp/spark-7d5a3c76-94d0-4892-a5db-ceb513008a9e/userFiles-15a5b4f2-4bef-433a-a2c9-0b6b0e6eda52/org.json4s_json4s-ast_2.12-3.6.10.jar to class loader
21/02/17 01:29:54 INFO Executor: Fetching spark://localhost:43321/jars/sparklyr-2.3-2.11.jar with timestamp 1613525389117
21/02/17 01:29:54 INFO Utils: Fetching spark://localhost:43321/jars/sparklyr-2.3-2.11.jar to /tmp/spark-7d5a3c76-94d0-4892-a5db-ceb513008a9e/userFiles-15a5b4f2-4bef-433a-a2c9-0b6b0e6eda52/fetchFileTemp3679851995252953768.tmp
21/02/17 01:29:54 INFO Executor: Adding file:/tmp/spark-7d5a3c76-94d0-4892-a5db-ceb513008a9e/userFiles-15a5b4f2-4bef-433a-a2c9-0b6b0e6eda52/sparklyr-2.3-2.11.jar to class loader
21/02/17 01:29:54 INFO Executor: Fetching spark://localhost:43321/jars/com.typesafe_config-1.3.3.jar with timestamp 1613525389116
21/02/17 01:29:54 INFO Utils: Fetching spark://localhost:43321/jars/com.typesafe_config-1.3.3.jar to /tmp/spark-7d5a3c76-94d0-4892-a5db-ceb513008a9e/userFiles-15a5b4f2-4bef-433a-a2c9-0b6b0e6eda52/fetchFileTemp9163164369375729410.tmp
21/02/17 01:29:54 INFO Executor: Adding file:/tmp/spark-7d5a3c76-94d0-4892-a5db-ceb513008a9e/userFiles-15a5b4f2-4bef-433a-a2c9-0b6b0e6eda52/com.typesafe_config-1.3.3.jar to class loader
21/02/17 01:29:54 INFO Executor: Fetching spark://localhost:43321/jars/com.esotericsoftware.kryo_kryo-2.22.jar with timestamp 1613525389116
21/02/17 01:29:54 INFO Utils: Fetching spark://localhost:43321/jars/com.esotericsoftware.kryo_kryo-2.22.jar to /tmp/spark-7d5a3c76-94d0-4892-a5db-ceb513008a9e/userFiles-15a5b4f2-4bef-433a-a2c9-0b6b0e6eda52/fetchFileTemp1259422892104942987.tmp
21/02/17 01:29:54 INFO Executor: Adding file:/tmp/spark-7d5a3c76-94d0-4892-a5db-ceb513008a9e/userFiles-15a5b4f2-4bef-433a-a2c9-0b6b0e6eda52/com.esotericsoftware.kryo_kryo-2.22.jar to class loader
21/02/17 01:29:54 INFO Executor: Fetching spark://localhost:43321/jars/org.json4s_json4s-scalap_2.12-3.6.10.jar with timestamp 1613525389116
21/02/17 01:29:54 INFO Utils: Fetching spark://localhost:43321/jars/org.json4s_json4s-scalap_2.12-3.6.10.jar to /tmp/spark-7d5a3c76-94d0-4892-a5db-ceb513008a9e/userFiles-15a5b4f2-4bef-433a-a2c9-0b6b0e6eda52/fetchFileTemp5608327714573204473.tmp
21/02/17 01:29:54 INFO Executor: Adding file:/tmp/spark-7d5a3c76-94d0-4892-a5db-ceb513008a9e/userFiles-15a5b4f2-4bef-433a-a2c9-0b6b0e6eda52/org.json4s_json4s-scalap_2.12-3.6.10.jar to class loader
21/02/17 01:29:54 INFO Executor: Fetching spark://localhost:43321/jars/com.fasterxml.jackson.core_jackson-core-2.9.10.jar with timestamp 1613525389117
21/02/17 01:29:54 INFO Utils: Fetching spark://localhost:43321/jars/com.fasterxml.jackson.core_jackson-core-2.9.10.jar to /tmp/spark-7d5a3c76-94d0-4892-a5db-ceb513008a9e/userFiles-15a5b4f2-4bef-433a-a2c9-0b6b0e6eda52/fetchFileTemp5130020186345271071.tmp
21/02/17 01:29:54 INFO Executor: Adding file:/tmp/spark-7d5a3c76-94d0-4892-a5db-ceb513008a9e/userFiles-15a5b4f2-4bef-433a-a2c9-0b6b0e6eda52/com.fasterxml.jackson.core_jackson-core-2.9.10.jar to class loader
21/02/17 01:29:54 INFO Executor: Fetching spark://localhost:43321/jars/com.typesafe.akka_akka-actor_2.11-2.5.23.jar with timestamp 1613525389116
21/02/17 01:29:54 INFO Utils: Fetching spark://localhost:43321/jars/com.typesafe.akka_akka-actor_2.11-2.5.23.jar to /tmp/spark-7d5a3c76-94d0-4892-a5db-ceb513008a9e/userFiles-15a5b4f2-4bef-433a-a2c9-0b6b0e6eda52/fetchFileTemp8010398455784350230.tmp
21/02/17 01:29:54 INFO Executor: Adding file:/tmp/spark-7d5a3c76-94d0-4892-a5db-ceb513008a9e/userFiles-15a5b4f2-4bef-433a-a2c9-0b6b0e6eda52/com.typesafe.akka_akka-actor_2.11-2.5.23.jar to class loader
21/02/17 01:29:54 INFO Executor: Fetching spark://localhost:43321/jars/ml.dmlc_xgboost4j-spark_2.11-1.1.2.jar with timestamp 1613525389115
21/02/17 01:29:54 INFO Utils: Fetching spark://localhost:43321/jars/ml.dmlc_xgboost4j-spark_2.11-1.1.2.jar to /tmp/spark-7d5a3c76-94d0-4892-a5db-ceb513008a9e/userFiles-15a5b4f2-4bef-433a-a2c9-0b6b0e6eda52/fetchFileTemp4298280818548986428.tmp
21/02/17 01:29:54 INFO Executor: Adding file:/tmp/spark-7d5a3c76-94d0-4892-a5db-ceb513008a9e/userFiles-15a5b4f2-4bef-433a-a2c9-0b6b0e6eda52/ml.dmlc_xgboost4j-spark_2.11-1.1.2.jar to class loader
21/02/17 01:29:54 INFO Executor: Fetching spark://localhost:43321/jars/org.scala-lang_scala-reflect-2.11.12.jar with timestamp 1613525389116
21/02/17 01:29:54 INFO Utils: Fetching spark://localhost:43321/jars/org.scala-lang_scala-reflect-2.11.12.jar to /tmp/spark-7d5a3c76-94d0-4892-a5db-ceb513008a9e/userFiles-15a5b4f2-4bef-433a-a2c9-0b6b0e6eda52/fetchFileTemp922848398531123804.tmp
21/02/17 01:29:54 INFO Executor: Adding file:/tmp/spark-7d5a3c76-94d0-4892-a5db-ceb513008a9e/userFiles-15a5b4f2-4bef-433a-a2c9-0b6b0e6eda52/org.scala-lang_scala-reflect-2.11.12.jar to class loader
21/02/17 01:29:54 INFO Executor: Fetching spark://localhost:43321/jars/commons-logging_commons-logging-1.2.jar with timestamp 1613525389116
21/02/17 01:29:54 INFO Utils: Fetching spark://localhost:43321/jars/commons-logging_commons-logging-1.2.jar to /tmp/spark-7d5a3c76-94d0-4892-a5db-ceb513008a9e/userFiles-15a5b4f2-4bef-433a-a2c9-0b6b0e6eda52/fetchFileTemp4762292001562265638.tmp
21/02/17 01:29:54 INFO Executor: Adding file:/tmp/spark-7d5a3c76-94d0-4892-a5db-ceb513008a9e/userFiles-15a5b4f2-4bef-433a-a2c9-0b6b0e6eda52/commons-logging_commons-logging-1.2.jar to class loader
21/02/17 01:29:54 INFO Executor: Fetching spark://localhost:43321/jars/org.json4s_json4s-core_2.12-3.6.10.jar with timestamp 1613525389116
21/02/17 01:29:54 INFO Utils: Fetching spark://localhost:43321/jars/org.json4s_json4s-core_2.12-3.6.10.jar to /tmp/spark-7d5a3c76-94d0-4892-a5db-ceb513008a9e/userFiles-15a5b4f2-4bef-433a-a2c9-0b6b0e6eda52/fetchFileTemp781308151014287744.tmp
21/02/17 01:29:54 INFO Executor: Adding file:/tmp/spark-7d5a3c76-94d0-4892-a5db-ceb513008a9e/userFiles-15a5b4f2-4bef-433a-a2c9-0b6b0e6eda52/org.json4s_json4s-core_2.12-3.6.10.jar to class loader
21/02/17 01:29:54 INFO Executor: Fetching spark://localhost:43321/jars/com.fasterxml.jackson.core_jackson-databind-2.9.10.6.jar with timestamp 1613525389116
21/02/17 01:29:54 INFO Utils: Fetching spark://localhost:43321/jars/com.fasterxml.jackson.core_jackson-databind-2.9.10.6.jar to /tmp/spark-7d5a3c76-94d0-4892-a5db-ceb513008a9e/userFiles-15a5b4f2-4bef-433a-a2c9-0b6b0e6eda52/fetchFileTemp8447897782108080156.tmp
21/02/17 01:29:54 INFO Executor: Adding file:/tmp/spark-7d5a3c76-94d0-4892-a5db-ceb513008a9e/userFiles-15a5b4f2-4bef-433a-a2c9-0b6b0e6eda52/com.fasterxml.jackson.core_jackson-databind-2.9.10.6.jar to class loader
21/02/17 01:29:54 INFO Executor: Fetching spark://localhost:43321/jars/org.scala-lang.modules_scala-java8-compat_2.11-0.7.0.jar with timestamp 1613525389116
21/02/17 01:29:54 INFO Utils: Fetching spark://localhost:43321/jars/org.scala-lang.modules_scala-java8-compat_2.11-0.7.0.jar to /tmp/spark-7d5a3c76-94d0-4892-a5db-ceb513008a9e/userFiles-15a5b4f2-4bef-433a-a2c9-0b6b0e6eda52/fetchFileTemp8430510361604321292.tmp
21/02/17 01:29:54 INFO Executor: Adding file:/tmp/spark-7d5a3c76-94d0-4892-a5db-ceb513008a9e/userFiles-15a5b4f2-4bef-433a-a2c9-0b6b0e6eda52/org.scala-lang.modules_scala-java8-compat_2.11-0.7.0.jar to class loader
21/02/17 01:29:54 INFO Executor: Fetching spark://localhost:43321/jars/org.scala-lang.modules_scala-xml_2.11-1.0.5.jar with timestamp 1613525389116
21/02/17 01:29:54 INFO Utils: Fetching spark://localhost:43321/jars/org.scala-lang.modules_scala-xml_2.11-1.0.5.jar to /tmp/spark-7d5a3c76-94d0-4892-a5db-ceb513008a9e/userFiles-15a5b4f2-4bef-433a-a2c9-0b6b0e6eda52/fetchFileTemp988524918833603446.tmp
21/02/17 01:29:54 INFO Executor: Adding file:/tmp/spark-7d5a3c76-94d0-4892-a5db-ceb513008a9e/userFiles-15a5b4f2-4bef-433a-a2c9-0b6b0e6eda52/org.scala-lang.modules_scala-xml_2.11-1.0.5.jar to class loader
21/02/17 01:29:55 INFO CodeGenerator: Code generated in 163.813627 ms
21/02/17 01:29:55 INFO Executor: Finished task 0.0 in stage 0.0 (TID 0). 970 bytes result sent to driver
21/02/17 01:29:55 INFO TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in 449 ms on localhost (executor driver) (1/1)
21/02/17 01:29:55 INFO TaskSchedulerImpl: Removed TaskSet 0.0, whose tasks have all completed, from pool 
21/02/17 01:29:55 INFO DAGScheduler: ResultStage 0 (collect at utils.scala:61) finished in 0.545 s
21/02/17 01:29:55 INFO DAGScheduler: Job 0 finished: collect at utils.scala:61, took 0.578350 s
21/02/17 01:29:55 INFO CodeGenerator: Code generated in 12.287701 ms
21/02/17 01:29:55 INFO CodeGenerator: Code generated in 14.516226 ms
21/02/17 01:29:55 INFO SparkContext: Starting job: collect at utils.scala:135
21/02/17 01:29:55 INFO DAGScheduler: Got job 1 (collect at utils.scala:135) with 1 output partitions
21/02/17 01:29:55 INFO DAGScheduler: Final stage: ResultStage 1 (collect at utils.scala:135)
21/02/17 01:29:55 INFO DAGScheduler: Parents of final stage: List()
21/02/17 01:29:55 INFO DAGScheduler: Missing parents: List()
21/02/17 01:29:55 INFO DAGScheduler: Submitting ResultStage 1 (MapPartitionsRDD[9] at collect at utils.scala:135), which has no missing parents
21/02/17 01:29:55 INFO MemoryStore: Block broadcast_1 stored as values in memory (estimated size 6.4 KB, free 912.3 MB)
21/02/17 01:29:55 INFO MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 3.2 KB, free 912.3 MB)
21/02/17 01:29:55 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on localhost:34957 (size: 3.2 KB, free: 912.3 MB)
21/02/17 01:29:55 INFO SparkContext: Created broadcast 1 from broadcast at DAGScheduler.scala:1039
21/02/17 01:29:55 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 1 (MapPartitionsRDD[9] at collect at utils.scala:135) (first 15 tasks are for partitions Vector(0))
21/02/17 01:29:55 INFO TaskSchedulerImpl: Adding task set 1.0 with 1 tasks
21/02/17 01:29:55 INFO TaskSetManager: Starting task 0.0 in stage 1.0 (TID 1, localhost, executor driver, partition 0, PROCESS_LOCAL, 8067 bytes)
21/02/17 01:29:55 INFO Executor: Running task 0.0 in stage 1.0 (TID 1)
21/02/17 01:29:55 INFO CodeGenerator: Code generated in 9.556947 ms
21/02/17 01:29:55 INFO Executor: Finished task 0.0 in stage 1.0 (TID 1). 1286 bytes result sent to driver
21/02/17 01:29:55 INFO TaskSetManager: Finished task 0.0 in stage 1.0 (TID 1) in 26 ms on localhost (executor driver) (1/1)
21/02/17 01:29:55 INFO TaskSchedulerImpl: Removed TaskSet 1.0, whose tasks have all completed, from pool 
21/02/17 01:29:55 INFO DAGScheduler: ResultStage 1 (collect at utils.scala:135) finished in 0.036 s
21/02/17 01:29:55 INFO DAGScheduler: Job 1 finished: collect at utils.scala:135, took 0.038568 s
21/02/17 01:29:55 INFO CodeGenerator: Code generated in 16.930738 ms
21/02/17 01:29:55 INFO CodeGenerator: Code generated in 14.120749 ms
21/02/17 01:29:55 INFO SparkContext: Starting job: count at utils.scala:135
21/02/17 01:29:55 INFO DAGScheduler: Registering RDD 12 (count at utils.scala:135)
21/02/17 01:29:55 INFO DAGScheduler: Got job 2 (count at utils.scala:135) with 1 output partitions
21/02/17 01:29:55 INFO DAGScheduler: Final stage: ResultStage 3 (count at utils.scala:135)
21/02/17 01:29:55 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 2)
21/02/17 01:29:55 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 2)
21/02/17 01:29:55 INFO DAGScheduler: Submitting ShuffleMapStage 2 (MapPartitionsRDD[12] at count at utils.scala:135), which has no missing parents
21/02/17 01:29:55 INFO MemoryStore: Block broadcast_2 stored as values in memory (estimated size 8.9 KB, free 912.3 MB)
21/02/17 01:29:55 INFO MemoryStore: Block broadcast_2_piece0 stored as bytes in memory (estimated size 4.5 KB, free 912.3 MB)
21/02/17 01:29:55 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on localhost:34957 (size: 4.5 KB, free: 912.3 MB)
21/02/17 01:29:55 INFO SparkContext: Created broadcast 2 from broadcast at DAGScheduler.scala:1039
21/02/17 01:29:55 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 2 (MapPartitionsRDD[12] at count at utils.scala:135) (first 15 tasks are for partitions Vector(0))
21/02/17 01:29:55 INFO TaskSchedulerImpl: Adding task set 2.0 with 1 tasks
21/02/17 01:29:55 INFO TaskSetManager: Starting task 0.0 in stage 2.0 (TID 2, localhost, executor driver, partition 0, PROCESS_LOCAL, 8056 bytes)
21/02/17 01:29:55 INFO Executor: Running task 0.0 in stage 2.0 (TID 2)
21/02/17 01:29:55 INFO Executor: Finished task 0.0 in stage 2.0 (TID 2). 1499 bytes result sent to driver
21/02/17 01:29:55 INFO TaskSetManager: Finished task 0.0 in stage 2.0 (TID 2) in 31 ms on localhost (executor driver) (1/1)
21/02/17 01:29:55 INFO TaskSchedulerImpl: Removed TaskSet 2.0, whose tasks have all completed, from pool 
21/02/17 01:29:55 INFO DAGScheduler: ShuffleMapStage 2 (count at utils.scala:135) finished in 0.045 s
21/02/17 01:29:55 INFO DAGScheduler: looking for newly runnable stages
21/02/17 01:29:55 INFO DAGScheduler: running: Set()
21/02/17 01:29:55 INFO DAGScheduler: waiting: Set(ResultStage 3)
21/02/17 01:29:55 INFO DAGScheduler: failed: Set()
21/02/17 01:29:55 INFO DAGScheduler: Submitting ResultStage 3 (MapPartitionsRDD[15] at count at utils.scala:135), which has no missing parents
21/02/17 01:29:55 INFO MemoryStore: Block broadcast_3 stored as values in memory (estimated size 7.3 KB, free 912.3 MB)
21/02/17 01:29:55 INFO MemoryStore: Block broadcast_3_piece0 stored as bytes in memory (estimated size 3.8 KB, free 912.3 MB)
21/02/17 01:29:55 INFO BlockManagerInfo: Added broadcast_3_piece0 in memory on localhost:34957 (size: 3.8 KB, free: 912.3 MB)
21/02/17 01:29:55 INFO SparkContext: Created broadcast 3 from broadcast at DAGScheduler.scala:1039
21/02/17 01:29:55 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 3 (MapPartitionsRDD[15] at count at utils.scala:135) (first 15 tasks are for partitions Vector(0))
21/02/17 01:29:55 INFO TaskSchedulerImpl: Adding task set 3.0 with 1 tasks
21/02/17 01:29:55 INFO TaskSetManager: Starting task 0.0 in stage 3.0 (TID 3, localhost, executor driver, partition 0, NODE_LOCAL, 7754 bytes)
21/02/17 01:29:55 INFO Executor: Running task 0.0 in stage 3.0 (TID 3)
21/02/17 01:29:55 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
21/02/17 01:29:55 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 3 ms
21/02/17 01:29:55 INFO Executor: Finished task 0.0 in stage 3.0 (TID 3). 1782 bytes result sent to driver
21/02/17 01:29:55 INFO TaskSetManager: Finished task 0.0 in stage 3.0 (TID 3) in 25 ms on localhost (executor driver) (1/1)
21/02/17 01:29:55 INFO TaskSchedulerImpl: Removed TaskSet 3.0, whose tasks have all completed, from pool 
21/02/17 01:29:55 INFO DAGScheduler: ResultStage 3 (count at utils.scala:135) finished in 0.034 s
21/02/17 01:29:55 INFO DAGScheduler: Job 2 finished: count at utils.scala:135, took 0.095147 s
21/02/17 01:29:55 INFO SparkContext: Starting job: collect at utils.scala:135
21/02/17 01:29:55 INFO DAGScheduler: Got job 3 (collect at utils.scala:135) with 1 output partitions
21/02/17 01:29:55 INFO DAGScheduler: Final stage: ResultStage 4 (collect at utils.scala:135)
21/02/17 01:29:55 INFO DAGScheduler: Parents of final stage: List()
21/02/17 01:29:55 INFO DAGScheduler: Missing parents: List()
21/02/17 01:29:55 INFO DAGScheduler: Submitting ResultStage 4 (MapPartitionsRDD[20] at collect at utils.scala:135), which has no missing parents
21/02/17 01:29:55 INFO MemoryStore: Block broadcast_4 stored as values in memory (estimated size 6.4 KB, free 912.3 MB)
21/02/17 01:29:55 INFO MemoryStore: Block broadcast_4_piece0 stored as bytes in memory (estimated size 3.2 KB, free 912.2 MB)
21/02/17 01:29:55 INFO BlockManagerInfo: Added broadcast_4_piece0 in memory on localhost:34957 (size: 3.2 KB, free: 912.3 MB)
21/02/17 01:29:55 INFO SparkContext: Created broadcast 4 from broadcast at DAGScheduler.scala:1039
21/02/17 01:29:55 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 4 (MapPartitionsRDD[20] at collect at utils.scala:135) (first 15 tasks are for partitions Vector(0))
21/02/17 01:29:55 INFO TaskSchedulerImpl: Adding task set 4.0 with 1 tasks
21/02/17 01:29:55 INFO TaskSetManager: Starting task 0.0 in stage 4.0 (TID 4, localhost, executor driver, partition 0, PROCESS_LOCAL, 8067 bytes)
21/02/17 01:29:55 INFO Executor: Running task 0.0 in stage 4.0 (TID 4)
21/02/17 01:29:55 INFO Executor: Finished task 0.0 in stage 4.0 (TID 4). 1286 bytes result sent to driver
21/02/17 01:29:55 INFO TaskSetManager: Finished task 0.0 in stage 4.0 (TID 4) in 6 ms on localhost (executor driver) (1/1)
21/02/17 01:29:55 INFO TaskSchedulerImpl: Removed TaskSet 4.0, whose tasks have all completed, from pool 
21/02/17 01:29:55 INFO DAGScheduler: ResultStage 4 (collect at utils.scala:135) finished in 0.012 s
21/02/17 01:29:55 INFO DAGScheduler: Job 3 finished: collect at utils.scala:135, took 0.013320 s
21/02/17 01:29:55 INFO SparkContext: Starting job: count at utils.scala:135
21/02/17 01:29:55 INFO DAGScheduler: Registering RDD 23 (count at utils.scala:135)
21/02/17 01:29:55 INFO DAGScheduler: Got job 4 (count at utils.scala:135) with 1 output partitions
21/02/17 01:29:55 INFO DAGScheduler: Final stage: ResultStage 6 (count at utils.scala:135)
21/02/17 01:29:55 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 5)
21/02/17 01:29:55 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 5)
21/02/17 01:29:55 INFO DAGScheduler: Submitting ShuffleMapStage 5 (MapPartitionsRDD[23] at count at utils.scala:135), which has no missing parents
21/02/17 01:29:55 INFO MemoryStore: Block broadcast_5 stored as values in memory (estimated size 8.9 KB, free 912.2 MB)
21/02/17 01:29:55 INFO MemoryStore: Block broadcast_5_piece0 stored as bytes in memory (estimated size 4.5 KB, free 912.2 MB)
21/02/17 01:29:55 INFO BlockManagerInfo: Added broadcast_5_piece0 in memory on localhost:34957 (size: 4.5 KB, free: 912.3 MB)
21/02/17 01:29:55 INFO SparkContext: Created broadcast 5 from broadcast at DAGScheduler.scala:1039
21/02/17 01:29:55 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 5 (MapPartitionsRDD[23] at count at utils.scala:135) (first 15 tasks are for partitions Vector(0))
21/02/17 01:29:55 INFO TaskSchedulerImpl: Adding task set 5.0 with 1 tasks
21/02/17 01:29:55 INFO TaskSetManager: Starting task 0.0 in stage 5.0 (TID 5, localhost, executor driver, partition 0, PROCESS_LOCAL, 8056 bytes)
21/02/17 01:29:55 INFO Executor: Running task 0.0 in stage 5.0 (TID 5)
21/02/17 01:29:55 INFO Executor: Finished task 0.0 in stage 5.0 (TID 5). 1499 bytes result sent to driver
21/02/17 01:29:55 INFO TaskSetManager: Finished task 0.0 in stage 5.0 (TID 5) in 5 ms on localhost (executor driver) (1/1)
21/02/17 01:29:55 INFO TaskSchedulerImpl: Removed TaskSet 5.0, whose tasks have all completed, from pool 
21/02/17 01:29:55 INFO DAGScheduler: ShuffleMapStage 5 (count at utils.scala:135) finished in 0.011 s
21/02/17 01:29:55 INFO DAGScheduler: looking for newly runnable stages
21/02/17 01:29:55 INFO DAGScheduler: running: Set()
21/02/17 01:29:55 INFO DAGScheduler: waiting: Set(ResultStage 6)
21/02/17 01:29:55 INFO DAGScheduler: failed: Set()
21/02/17 01:29:55 INFO DAGScheduler: Submitting ResultStage 6 (MapPartitionsRDD[26] at count at utils.scala:135), which has no missing parents
21/02/17 01:29:55 INFO MemoryStore: Block broadcast_6 stored as values in memory (estimated size 7.3 KB, free 912.2 MB)
21/02/17 01:29:55 INFO MemoryStore: Block broadcast_6_piece0 stored as bytes in memory (estimated size 3.8 KB, free 912.2 MB)
21/02/17 01:29:55 INFO BlockManagerInfo: Added broadcast_6_piece0 in memory on localhost:34957 (size: 3.8 KB, free: 912.3 MB)
21/02/17 01:29:55 INFO SparkContext: Created broadcast 6 from broadcast at DAGScheduler.scala:1039
21/02/17 01:29:55 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 6 (MapPartitionsRDD[26] at count at utils.scala:135) (first 15 tasks are for partitions Vector(0))
21/02/17 01:29:55 INFO TaskSchedulerImpl: Adding task set 6.0 with 1 tasks
21/02/17 01:29:55 INFO TaskSetManager: Starting task 0.0 in stage 6.0 (TID 6, localhost, executor driver, partition 0, NODE_LOCAL, 7754 bytes)
21/02/17 01:29:55 INFO Executor: Running task 0.0 in stage 6.0 (TID 6)
21/02/17 01:29:55 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
21/02/17 01:29:55 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
21/02/17 01:29:55 INFO Executor: Finished task 0.0 in stage 6.0 (TID 6). 1825 bytes result sent to driver
21/02/17 01:29:55 INFO TaskSetManager: Finished task 0.0 in stage 6.0 (TID 6) in 5 ms on localhost (executor driver) (1/1)
21/02/17 01:29:55 INFO TaskSchedulerImpl: Removed TaskSet 6.0, whose tasks have all completed, from pool 
21/02/17 01:29:55 INFO DAGScheduler: ResultStage 6 (count at utils.scala:135) finished in 0.011 s
21/02/17 01:29:55 INFO DAGScheduler: Job 4 finished: count at utils.scala:135, took 0.026015 s
21/02/17 01:29:56 INFO ContextCleaner: Cleaned accumulator 117
21/02/17 01:29:56 INFO ContextCleaner: Cleaned accumulator 61
21/02/17 01:29:56 INFO ContextCleaner: Cleaned accumulator 189
21/02/17 01:29:56 INFO ContextCleaner: Cleaned accumulator 24
21/02/17 01:29:56 INFO ContextCleaner: Cleaned accumulator 87
21/02/17 01:29:56 INFO ContextCleaner: Cleaned accumulator 198
21/02/17 01:29:56 INFO ContextCleaner: Cleaned accumulator 141
21/02/17 01:29:56 INFO ContextCleaner: Cleaned accumulator 174
21/02/17 01:29:56 INFO ContextCleaner: Cleaned accumulator 107
21/02/17 01:29:56 INFO ContextCleaner: Cleaned accumulator 127
21/02/17 01:29:56 INFO ContextCleaner: Cleaned accumulator 170
21/02/17 01:29:56 INFO ContextCleaner: Cleaned accumulator 81
21/02/17 01:29:56 INFO ContextCleaner: Cleaned accumulator 135
21/02/17 01:29:56 INFO ContextCleaner: Cleaned accumulator 183
21/02/17 01:29:56 INFO ContextCleaner: Cleaned accumulator 185
21/02/17 01:29:56 INFO ContextCleaner: Cleaned accumulator 190
21/02/17 01:29:56 INFO ContextCleaner: Cleaned accumulator 187
21/02/17 01:29:56 INFO ContextCleaner: Cleaned accumulator 123
21/02/17 01:29:56 INFO ContextCleaner: Cleaned accumulator 62
21/02/17 01:29:56 INFO ContextCleaner: Cleaned accumulator 20
21/02/17 01:29:56 INFO ContextCleaner: Cleaned accumulator 72
21/02/17 01:29:56 INFO ContextCleaner: Cleaned accumulator 29
21/02/17 01:29:56 INFO ContextCleaner: Cleaned accumulator 15
21/02/17 01:29:56 INFO ContextCleaner: Cleaned accumulator 101
21/02/17 01:29:56 INFO ContextCleaner: Cleaned accumulator 196
21/02/17 01:29:56 INFO ContextCleaner: Cleaned accumulator 210
21/02/17 01:29:56 INFO ContextCleaner: Cleaned accumulator 2
21/02/17 01:29:56 INFO ContextCleaner: Cleaned accumulator 146
21/02/17 01:29:56 INFO ContextCleaner: Cleaned accumulator 35
21/02/17 01:29:56 INFO ContextCleaner: Cleaned accumulator 200
21/02/17 01:29:56 INFO ContextCleaner: Cleaned accumulator 84
21/02/17 01:29:56 INFO ContextCleaner: Cleaned accumulator 136
21/02/17 01:29:56 INFO BlockManagerInfo: Removed broadcast_1_piece0 on localhost:34957 in memory (size: 3.2 KB, free: 912.3 MB)
21/02/17 01:29:56 INFO ContextCleaner: Cleaned accumulator 30
21/02/17 01:29:56 INFO ContextCleaner: Cleaned accumulator 177
21/02/17 01:29:56 INFO ContextCleaner: Cleaned accumulator 82
21/02/17 01:29:56 INFO ContextCleaner: Cleaned accumulator 47
21/02/17 01:29:56 INFO ContextCleaner: Cleaned accumulator 39
21/02/17 01:29:56 INFO ContextCleaner: Cleaned accumulator 186
21/02/17 01:29:56 INFO ContextCleaner: Cleaned accumulator 207
21/02/17 01:29:56 INFO ContextCleaner: Cleaned accumulator 130
21/02/17 01:29:56 INFO ContextCleaner: Cleaned accumulator 23
21/02/17 01:29:56 INFO ContextCleaner: Cleaned accumulator 83
21/02/17 01:29:56 INFO ContextCleaner: Cleaned accumulator 77
21/02/17 01:29:56 INFO ContextCleaner: Cleaned accumulator 97
21/02/17 01:29:56 INFO ContextCleaner: Cleaned accumulator 73
21/02/17 01:29:56 INFO ContextCleaner: Cleaned accumulator 137
21/02/17 01:29:56 INFO ContextCleaner: Cleaned accumulator 209
21/02/17 01:29:56 INFO ContextCleaner: Cleaned accumulator 32
21/02/17 01:29:56 INFO ContextCleaner: Cleaned accumulator 165
21/02/17 01:29:56 INFO ContextCleaner: Cleaned accumulator 33
21/02/17 01:29:56 INFO ContextCleaner: Cleaned accumulator 150
21/02/17 01:29:56 INFO ContextCleaner: Cleaned accumulator 148
21/02/17 01:29:56 INFO ContextCleaner: Cleaned accumulator 181
21/02/17 01:29:56 INFO ContextCleaner: Cleaned accumulator 131
21/02/17 01:29:56 INFO ContextCleaner: Cleaned accumulator 129
21/02/17 01:29:56 INFO ContextCleaner: Cleaned accumulator 14
21/02/17 01:29:56 INFO ContextCleaner: Cleaned accumulator 105
21/02/17 01:29:56 INFO ContextCleaner: Cleaned accumulator 7
21/02/17 01:29:56 INFO ContextCleaner: Cleaned accumulator 5
21/02/17 01:29:56 INFO ContextCleaner: Cleaned accumulator 180
21/02/17 01:29:56 INFO ContextCleaner: Cleaned accumulator 49
21/02/17 01:29:56 INFO ContextCleaner: Cleaned accumulator 204
21/02/17 01:29:56 INFO ContextCleaner: Cleaned accumulator 93
21/02/17 01:29:56 INFO ContextCleaner: Cleaned accumulator 19
21/02/17 01:29:56 INFO ContextCleaner: Cleaned accumulator 58
21/02/17 01:29:56 INFO ContextCleaner: Cleaned accumulator 46
21/02/17 01:29:56 INFO ContextCleaner: Cleaned accumulator 161
21/02/17 01:29:56 INFO ContextCleaner: Cleaned accumulator 176
21/02/17 01:29:56 INFO ContextCleaner: Cleaned accumulator 98
21/02/17 01:29:56 INFO ContextCleaner: Cleaned accumulator 22
21/02/17 01:29:56 INFO ContextCleaner: Cleaned accumulator 151
21/02/17 01:29:56 INFO ContextCleaner: Cleaned accumulator 1
21/02/17 01:29:56 INFO ContextCleaner: Cleaned accumulator 133
21/02/17 01:29:56 INFO ContextCleaner: Cleaned accumulator 104
21/02/17 01:29:56 INFO ContextCleaner: Cleaned accumulator 173
21/02/17 01:29:56 INFO ContextCleaner: Cleaned accumulator 37
21/02/17 01:29:56 INFO ContextCleaner: Cleaned accumulator 134
21/02/17 01:29:56 INFO ContextCleaner: Cleaned shuffle 0
21/02/17 01:29:56 INFO ContextCleaner: Cleaned accumulator 192
21/02/17 01:29:56 INFO ContextCleaner: Cleaned accumulator 116
21/02/17 01:29:56 INFO ContextCleaner: Cleaned accumulator 64
21/02/17 01:29:56 INFO ContextCleaner: Cleaned accumulator 28
21/02/17 01:29:56 INFO ContextCleaner: Cleaned accumulator 206
21/02/17 01:29:56 INFO ContextCleaner: Cleaned accumulator 140
21/02/17 01:29:56 INFO ContextCleaner: Cleaned accumulator 55
21/02/17 01:29:56 INFO ContextCleaner: Cleaned accumulator 65
21/02/17 01:29:56 INFO ContextCleaner: Cleaned accumulator 78
21/02/17 01:29:56 INFO ContextCleaner: Cleaned accumulator 85
21/02/17 01:29:56 INFO ContextCleaner: Cleaned accumulator 34
21/02/17 01:29:56 INFO ContextCleaner: Cleaned accumulator 154
21/02/17 01:29:56 INFO BlockManagerInfo: Removed broadcast_6_piece0 on localhost:34957 in memory (size: 3.8 KB, free: 912.3 MB)
21/02/17 01:29:56 INFO ContextCleaner: Cleaned accumulator 132
21/02/17 01:29:56 INFO ContextCleaner: Cleaned accumulator 166
21/02/17 01:29:56 INFO ContextCleaner: Cleaned accumulator 18
21/02/17 01:29:56 INFO ContextCleaner: Cleaned accumulator 193
21/02/17 01:29:56 INFO ContextCleaner: Cleaned accumulator 26
21/02/17 01:29:56 INFO ContextCleaner: Cleaned accumulator 171
21/02/17 01:29:56 INFO ContextCleaner: Cleaned accumulator 27
21/02/17 01:29:56 INFO ContextCleaner: Cleaned accumulator 175
21/02/17 01:29:56 INFO ContextCleaner: Cleaned accumulator 208
21/02/17 01:29:56 INFO ContextCleaner: Cleaned accumulator 45
21/02/17 01:29:56 INFO ContextCleaner: Cleaned accumulator 145
21/02/17 01:29:56 INFO ContextCleaner: Cleaned accumulator 52
21/02/17 01:29:56 INFO ContextCleaner: Cleaned accumulator 126
21/02/17 01:29:56 INFO ContextCleaner: Cleaned accumulator 149
21/02/17 01:29:56 INFO ContextCleaner: Cleaned accumulator 143
21/02/17 01:29:56 INFO ContextCleaner: Cleaned accumulator 79
21/02/17 01:29:56 INFO ContextCleaner: Cleaned accumulator 184
21/02/17 01:29:56 INFO ContextCleaner: Cleaned accumulator 142
21/02/17 01:29:56 INFO ContextCleaner: Cleaned accumulator 94
21/02/17 01:29:56 INFO ContextCleaner: Cleaned accumulator 199
21/02/17 01:29:56 INFO ContextCleaner: Cleaned accumulator 12
21/02/17 01:29:56 INFO ContextCleaner: Cleaned accumulator 4
21/02/17 01:29:56 INFO ContextCleaner: Cleaned accumulator 191
21/02/17 01:29:56 INFO ContextCleaner: Cleaned accumulator 96
21/02/17 01:29:56 INFO BlockManagerInfo: Removed broadcast_5_piece0 on localhost:34957 in memory (size: 4.5 KB, free: 912.3 MB)
21/02/17 01:29:56 INFO ContextCleaner: Cleaned accumulator 164
21/02/17 01:29:56 INFO ContextCleaner: Cleaned accumulator 76
21/02/17 01:29:56 INFO ContextCleaner: Cleaned accumulator 66
21/02/17 01:29:56 INFO ContextCleaner: Cleaned accumulator 68
21/02/17 01:29:56 INFO ContextCleaner: Cleaned accumulator 108
21/02/17 01:29:56 INFO ContextCleaner: Cleaned accumulator 160
21/02/17 01:29:56 INFO ContextCleaner: Cleaned accumulator 122
21/02/17 01:29:56 INFO ContextCleaner: Cleaned accumulator 113
21/02/17 01:29:56 INFO ContextCleaner: Cleaned accumulator 91
21/02/17 01:29:56 INFO ContextCleaner: Cleaned accumulator 44
21/02/17 01:29:56 INFO ContextCleaner: Cleaned accumulator 69
21/02/17 01:29:56 INFO ContextCleaner: Cleaned accumulator 159
21/02/17 01:29:56 INFO ContextCleaner: Cleaned accumulator 9
21/02/17 01:29:56 INFO ContextCleaner: Cleaned accumulator 88
21/02/17 01:29:56 INFO ContextCleaner: Cleaned accumulator 111
21/02/17 01:29:56 INFO ContextCleaner: Cleaned accumulator 8
21/02/17 01:29:56 INFO ContextCleaner: Cleaned accumulator 25
21/02/17 01:29:56 INFO ContextCleaner: Cleaned accumulator 158
21/02/17 01:29:56 INFO ContextCleaner: Cleaned accumulator 60
21/02/17 01:29:56 INFO ContextCleaner: Cleaned accumulator 205
21/02/17 01:29:56 INFO ContextCleaner: Cleaned accumulator 59
21/02/17 01:29:56 INFO ContextCleaner: Cleaned accumulator 50
21/02/17 01:29:56 INFO ContextCleaner: Cleaned accumulator 21
21/02/17 01:29:56 INFO ContextCleaner: Cleaned accumulator 167
21/02/17 01:29:56 INFO ContextCleaner: Cleaned accumulator 179
21/02/17 01:29:56 INFO ContextCleaner: Cleaned accumulator 10
21/02/17 01:29:56 INFO ContextCleaner: Cleaned accumulator 70
21/02/17 01:29:56 INFO ContextCleaner: Cleaned accumulator 172
21/02/17 01:29:56 INFO ContextCleaner: Cleaned accumulator 56
21/02/17 01:29:56 INFO ContextCleaner: Cleaned accumulator 120
21/02/17 01:29:56 INFO ContextCleaner: Cleaned accumulator 169
21/02/17 01:29:56 INFO ContextCleaner: Cleaned accumulator 51
21/02/17 01:29:56 INFO ContextCleaner: Cleaned accumulator 74
21/02/17 01:29:56 INFO BlockManagerInfo: Removed broadcast_0_piece0 on localhost:34957 in memory (size: 3.3 KB, free: 912.3 MB)
21/02/17 01:29:56 INFO ContextCleaner: Cleaned accumulator 153
21/02/17 01:29:56 INFO ContextCleaner: Cleaned accumulator 128
21/02/17 01:29:56 INFO ContextCleaner: Cleaned accumulator 178
21/02/17 01:29:56 INFO ContextCleaner: Cleaned accumulator 54
21/02/17 01:29:56 INFO ContextCleaner: Cleaned accumulator 57
21/02/17 01:29:56 INFO ContextCleaner: Cleaned accumulator 115
21/02/17 01:29:56 INFO ContextCleaner: Cleaned accumulator 188
21/02/17 01:29:56 INFO ContextCleaner: Cleaned accumulator 36
21/02/17 01:29:56 INFO ContextCleaner: Cleaned accumulator 95
21/02/17 01:29:56 INFO ContextCleaner: Cleaned accumulator 125
21/02/17 01:29:56 INFO ContextCleaner: Cleaned accumulator 211
21/02/17 01:29:56 INFO ContextCleaner: Cleaned accumulator 6
21/02/17 01:29:56 INFO ContextCleaner: Cleaned accumulator 162
21/02/17 01:29:56 INFO ContextCleaner: Cleaned accumulator 152
21/02/17 01:29:56 INFO ContextCleaner: Cleaned accumulator 43
21/02/17 01:29:56 INFO ContextCleaner: Cleaned accumulator 147
21/02/17 01:29:56 INFO ContextCleaner: Cleaned accumulator 202
21/02/17 01:29:56 INFO ContextCleaner: Cleaned accumulator 157
21/02/17 01:29:56 INFO ContextCleaner: Cleaned accumulator 31
21/02/17 01:29:56 INFO ContextCleaner: Cleaned accumulator 75
21/02/17 01:29:56 INFO BlockManagerInfo: Removed broadcast_4_piece0 on localhost:34957 in memory (size: 3.2 KB, free: 912.3 MB)
21/02/17 01:29:56 INFO ContextCleaner: Cleaned accumulator 156
21/02/17 01:29:56 INFO BlockManagerInfo: Removed broadcast_3_piece0 on localhost:34957 in memory (size: 3.8 KB, free: 912.3 MB)
21/02/17 01:29:56 INFO ContextCleaner: Cleaned accumulator 144
21/02/17 01:29:56 INFO ContextCleaner: Cleaned accumulator 63
21/02/17 01:29:56 INFO ContextCleaner: Cleaned accumulator 11
21/02/17 01:29:56 INFO ContextCleaner: Cleaned accumulator 106
21/02/17 01:29:56 INFO ContextCleaner: Cleaned accumulator 182
21/02/17 01:29:56 INFO ContextCleaner: Cleaned accumulator 17
21/02/17 01:29:56 INFO ContextCleaner: Cleaned accumulator 71
21/02/17 01:29:56 INFO ContextCleaner: Cleaned accumulator 103
21/02/17 01:29:56 INFO ContextCleaner: Cleaned accumulator 201
21/02/17 01:29:56 INFO ContextCleaner: Cleaned accumulator 92
21/02/17 01:29:56 INFO ContextCleaner: Cleaned accumulator 138
21/02/17 01:29:56 INFO ContextCleaner: Cleaned accumulator 110
21/02/17 01:29:56 INFO ContextCleaner: Cleaned accumulator 53
21/02/17 01:29:56 INFO ContextCleaner: Cleaned accumulator 109
21/02/17 01:29:56 INFO ContextCleaner: Cleaned accumulator 155
21/02/17 01:29:56 INFO ContextCleaner: Cleaned accumulator 100
21/02/17 01:29:56 INFO ContextCleaner: Cleaned accumulator 89
21/02/17 01:29:56 INFO ContextCleaner: Cleaned accumulator 195
21/02/17 01:29:56 INFO ContextCleaner: Cleaned accumulator 16
21/02/17 01:29:56 INFO ContextCleaner: Cleaned accumulator 41
21/02/17 01:29:56 INFO ContextCleaner: Cleaned accumulator 38
21/02/17 01:29:56 INFO ContextCleaner: Cleaned accumulator 121
21/02/17 01:29:56 INFO ContextCleaner: Cleaned accumulator 163
21/02/17 01:29:56 INFO ContextCleaner: Cleaned accumulator 194
21/02/17 01:29:56 INFO ContextCleaner: Cleaned accumulator 48
21/02/17 01:29:56 INFO ContextCleaner: Cleaned accumulator 40
21/02/17 01:29:56 INFO ContextCleaner: Cleaned accumulator 80
21/02/17 01:29:56 INFO ContextCleaner: Cleaned accumulator 3
21/02/17 01:29:56 INFO ContextCleaner: Cleaned accumulator 102
21/02/17 01:29:56 INFO ContextCleaner: Cleaned accumulator 67
21/02/17 01:29:56 INFO ContextCleaner: Cleaned accumulator 139
21/02/17 01:29:56 INFO ContextCleaner: Cleaned accumulator 112
21/02/17 01:29:56 INFO ContextCleaner: Cleaned accumulator 168
21/02/17 01:29:56 INFO ContextCleaner: Cleaned shuffle 1
21/02/17 01:29:56 INFO ContextCleaner: Cleaned accumulator 203
21/02/17 01:29:56 INFO ContextCleaner: Cleaned accumulator 90
21/02/17 01:29:56 INFO ContextCleaner: Cleaned accumulator 13
21/02/17 01:29:56 INFO ContextCleaner: Cleaned accumulator 114
21/02/17 01:29:56 INFO ContextCleaner: Cleaned accumulator 197
21/02/17 01:29:56 INFO ContextCleaner: Cleaned accumulator 99
21/02/17 01:29:56 INFO ContextCleaner: Cleaned accumulator 124
21/02/17 01:29:56 INFO BlockManagerInfo: Removed broadcast_2_piece0 on localhost:34957 in memory (size: 4.5 KB, free: 912.3 MB)
21/02/17 01:29:56 INFO ContextCleaner: Cleaned accumulator 86
21/02/17 01:29:56 INFO ContextCleaner: Cleaned accumulator 42
21/02/17 01:29:56 INFO CodeGenerator: Code generated in 40.639743 ms
21/02/17 01:29:56 INFO XGBoostSpark: Running XGBoost 1.1.2 with parameters:
alpha -> 0.0
min_child_weight -> 1.0
sample_type -> uniform
base_score -> 0.5
rabit_timeout -> -1
colsample_bylevel -> 1.0
grow_policy -> depthwise
skip_drop -> 0.0
lambda_bias -> 0.0
silent -> 0
scale_pos_weight -> 1.0
seed -> 0
cache_training_set -> false
features_col -> features
num_early_stopping_rounds -> 0
label_col -> label
num_workers -> 1
subsample -> 1.0
lambda -> 1.0
max_depth -> 6
tree_limit -> 0
custom_eval -> null
dmlc_worker_connect_retry -> 5
rate_drop -> 0.0
max_bin -> 16
train_test_ratio -> 1.0
use_external_memory -> false
objective -> reg:linear
eval_metric -> rmse
num_round -> 1
maximize_evaluation_metrics -> false
timeout_request_workers -> 1800000
missing -> NaN
rabit_ring_reduce_threshold -> 32768
checkpoint_path -> 
tracker_conf -> TrackerConf(0,python)
tree_method -> auto
max_delta_step -> 0.0
eta -> 0.3
verbosity -> 1
colsample_bytree -> 1.0
objective_type -> regression
normalize_type -> tree
allow_non_zero_for_missing -> false
custom_obj -> null
gamma -> 0.0
sketch_eps -> 0.03
nthread -> 1
prediction_col -> prediction
checkpoint_interval -> -1
21/02/17 01:29:56 WARN XGBoostSpark: train_test_ratio is deprecated since XGBoost 0.82, we recommend to explicitly pass a training and multiple evaluation datasets by passing 'eval_sets' and 'eval_set_names'
21/02/17 01:29:56 INFO RabitTracker$TrackerProcessLogger: 2021-02-17 01:29:56,909 INFO start listen on 192.168.2.12:9091
21/02/17 01:29:56 INFO XGBoostSpark: starting training with timeout set as 1800000 ms for waiting for resources
21/02/17 01:29:56 INFO SparkContext: Starting job: foreachPartition at XGBoost.scala:565
21/02/17 01:29:56 INFO DAGScheduler: Got job 5 (foreachPartition at XGBoost.scala:565) with 1 output partitions
21/02/17 01:29:56 INFO DAGScheduler: Final stage: ResultStage 7 (foreachPartition at XGBoost.scala:565)
21/02/17 01:29:56 INFO DAGScheduler: Parents of final stage: List()
21/02/17 01:29:56 INFO DAGScheduler: Missing parents: List()
21/02/17 01:29:56 INFO DAGScheduler: Submitting ResultStage 7 (MapPartitionsRDD[35] at mapPartitions at XGBoost.scala:450), which has no missing parents
21/02/17 01:29:56 INFO MemoryStore: Block broadcast_7 stored as values in memory (estimated size 33.9 KB, free 912.3 MB)
21/02/17 01:29:56 INFO MemoryStore: Block broadcast_7_piece0 stored as bytes in memory (estimated size 14.2 KB, free 912.3 MB)
21/02/17 01:29:56 INFO BlockManagerInfo: Added broadcast_7_piece0 in memory on localhost:34957 (size: 14.2 KB, free: 912.3 MB)
21/02/17 01:29:56 INFO SparkContext: Created broadcast 7 from broadcast at DAGScheduler.scala:1039
21/02/17 01:29:56 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 7 (MapPartitionsRDD[35] at mapPartitions at XGBoost.scala:450) (first 15 tasks are for partitions Vector(0))
21/02/17 01:29:56 INFO TaskSchedulerImpl: Adding task set 7.0 with 1 tasks
21/02/17 01:29:56 INFO TaskSetManager: Starting task 0.0 in stage 7.0 (TID 7, localhost, executor driver, partition 0, PROCESS_LOCAL, 18998 bytes)
21/02/17 01:29:56 INFO Executor: Running task 0.0 in stage 7.0 (TID 7)
21/02/17 01:29:57 INFO CodeGenerator: Code generated in 13.000233 ms
21/02/17 01:29:57 INFO MemoryStore: Block rdd_17_0 stored as values in memory (estimated size 5.6 KB, free 912.2 MB)
21/02/17 01:29:57 INFO BlockManagerInfo: Added rdd_17_0 in memory on localhost:34957 (size: 5.6 KB, free: 912.3 MB)
21/02/17 01:29:57 INFO CodeGenerator: Code generated in 3.493651 ms
21/02/17 01:29:57 INFO CodeGenerator: Code generated in 24.108715 ms
21/02/17 01:29:57 INFO CodeGenerator: Code generated in 10.555 ms
21/02/17 01:29:57 INFO RabitTracker$TrackerProcessLogger: /tmp/tracker2018264470159349674.py:330: DeprecationWarning: isAlive() is deprecated, use is_alive() instead
21/02/17 01:29:57 INFO RabitTracker$TrackerProcessLogger:   while self.thread.isAlive():
21/02/17 01:29:57 INFO RabitTracker$TrackerProcessLogger: 2021-02-17 01:29:57,194 DEBUG Recieve start signal from 192.168.2.12; assign rank 0
21/02/17 01:29:57 INFO RabitTracker$TrackerProcessLogger: 2021-02-17 01:29:57,194 INFO @tracker All of 1 nodes getting started
21/02/17 01:29:57 INFO RabitTracker$TrackerProcessLogger: 2021-02-17 01:29:57,202 INFO [0]	train-rmse:2.633044
21/02/17 01:29:57 INFO RabitTracker$TrackerProcessLogger: 2021-02-17 01:29:57,203 DEBUG Recieve shutdown signal from 0
21/02/17 01:29:57 INFO RabitTracker$TrackerProcessLogger: 2021-02-17 01:29:57,203 INFO @tracker All nodes finishes job
21/02/17 01:29:57 INFO RabitTracker$TrackerProcessLogger: 2021-02-17 01:29:57,203 INFO @tracker 0.008727550506591797 secs between node start and job finish
21/02/17 01:29:57 INFO MemoryStore: Block rdd_35_0 stored as values in memory (estimated size 192.0 B, free 912.2 MB)
21/02/17 01:29:57 INFO BlockManagerInfo: Added rdd_35_0 in memory on localhost:34957 (size: 192.0 B, free: 912.3 MB)
21/02/17 01:29:57 INFO RabitTracker: Tracker Process ends with exit code 0
21/02/17 01:29:57 INFO RabitTracker$TrackerProcessLogger: Tracker Process ends with exit code 0
21/02/17 01:29:57 INFO XGBoostSpark: Rabit returns with exit code 0
21/02/17 01:29:57 INFO Executor: 1 block locks were not released by TID = 7:
[rdd_35_0]
21/02/17 01:29:57 INFO Executor: Finished task 0.0 in stage 7.0 (TID 7). 1260 bytes result sent to driver
21/02/17 01:29:57 INFO TaskSetManager: Finished task 0.0 in stage 7.0 (TID 7) in 230 ms on localhost (executor driver) (1/1)
21/02/17 01:29:57 INFO TaskSchedulerImpl: Removed TaskSet 7.0, whose tasks have all completed, from pool 
21/02/17 01:29:57 INFO DAGScheduler: ResultStage 7 (foreachPartition at XGBoost.scala:565) finished in 0.273 s
21/02/17 01:29:57 INFO DAGScheduler: Job 5 finished: foreachPartition at XGBoost.scala:565, took 0.278242 s
21/02/17 01:29:57 INFO SparkContext: Starting job: first at XGBoost.scala:685
21/02/17 01:29:57 INFO DAGScheduler: Got job 6 (first at XGBoost.scala:685) with 1 output partitions
21/02/17 01:29:57 INFO DAGScheduler: Final stage: ResultStage 8 (first at XGBoost.scala:685)
21/02/17 01:29:57 INFO DAGScheduler: Parents of final stage: List()
21/02/17 01:29:57 INFO DAGScheduler: Missing parents: List()
21/02/17 01:29:57 INFO DAGScheduler: Submitting ResultStage 8 (MapPartitionsRDD[35] at mapPartitions at XGBoost.scala:450), which has no missing parents
21/02/17 01:29:57 INFO MemoryStore: Block broadcast_8 stored as values in memory (estimated size 34.0 KB, free 912.2 MB)
21/02/17 01:29:57 INFO MemoryStore: Block broadcast_8_piece0 stored as bytes in memory (estimated size 14.3 KB, free 912.2 MB)
21/02/17 01:29:57 INFO BlockManagerInfo: Added broadcast_8_piece0 in memory on localhost:34957 (size: 14.3 KB, free: 912.3 MB)
21/02/17 01:29:57 INFO SparkContext: Created broadcast 8 from broadcast at DAGScheduler.scala:1039
21/02/17 01:29:57 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 8 (MapPartitionsRDD[35] at mapPartitions at XGBoost.scala:450) (first 15 tasks are for partitions Vector(0))
21/02/17 01:29:57 INFO TaskSchedulerImpl: Adding task set 8.0 with 1 tasks
21/02/17 01:29:57 INFO TaskSetManager: Starting task 0.0 in stage 8.0 (TID 8, localhost, executor driver, partition 0, PROCESS_LOCAL, 18998 bytes)
21/02/17 01:29:57 INFO Executor: Running task 0.0 in stage 8.0 (TID 8)
21/02/17 01:29:57 INFO BlockManager: Found block rdd_35_0 locally
21/02/17 01:29:57 INFO Executor: 1 block locks were not released by TID = 8:
[rdd_35_0]
21/02/17 01:29:57 INFO Executor: Finished task 0.0 in stage 8.0 (TID 8). 2551 bytes result sent to driver
21/02/17 01:29:57 INFO TaskSetManager: Finished task 0.0 in stage 8.0 (TID 8) in 8 ms on localhost (executor driver) (1/1)
21/02/17 01:29:57 INFO TaskSchedulerImpl: Removed TaskSet 8.0, whose tasks have all completed, from pool 
21/02/17 01:29:57 INFO DAGScheduler: ResultStage 8 (first at XGBoost.scala:685) finished in 0.016 s
21/02/17 01:29:57 INFO DAGScheduler: Job 6 finished: first at XGBoost.scala:685, took 0.019442 s
21/02/17 01:29:57 INFO MapPartitionsRDD: Removing RDD 35 from persistence list
21/02/17 01:29:57 INFO BlockManager: Removing RDD 35
21/02/17 01:29:57 INFO MemoryStore: Block broadcast_9 stored as values in memory (estimated size 64.0 B, free 912.2 MB)
21/02/17 01:29:57 INFO MemoryStore: Block broadcast_9_piece0 stored as bytes in memory (estimated size 510.0 B, free 912.2 MB)
21/02/17 01:29:57 INFO BlockManagerInfo: Added broadcast_9_piece0 in memory on localhost:34957 (size: 510.0 B, free: 912.3 MB)
21/02/17 01:29:57 INFO SparkContext: Created broadcast 9 from broadcast at XGBoostRegressor.scala:271
21/02/17 01:29:57 INFO CodeGenerator: Code generated in 26.865619 ms
21/02/17 01:29:57 INFO CodeGenerator: Code generated in 5.947568 ms
21/02/17 01:29:57 INFO CodeGenerator: Code generated in 5.215814 ms
21/02/17 01:29:57 INFO SparkContext: Starting job: collect at utils.scala:135
21/02/17 01:29:57 INFO DAGScheduler: Got job 7 (collect at utils.scala:135) with 1 output partitions
21/02/17 01:29:57 INFO DAGScheduler: Final stage: ResultStage 9 (collect at utils.scala:135)
21/02/17 01:29:57 INFO DAGScheduler: Parents of final stage: List()
21/02/17 01:29:57 INFO DAGScheduler: Missing parents: List()
21/02/17 01:29:57 INFO DAGScheduler: Submitting ResultStage 9 (MapPartitionsRDD[46] at collect at utils.scala:135), which has no missing parents
21/02/17 01:29:57 INFO MemoryStore: Block broadcast_10 stored as values in memory (estimated size 6.5 KB, free 912.2 MB)
21/02/17 01:29:57 INFO MemoryStore: Block broadcast_10_piece0 stored as bytes in memory (estimated size 3.2 KB, free 912.2 MB)
21/02/17 01:29:57 INFO BlockManagerInfo: Added broadcast_10_piece0 in memory on localhost:34957 (size: 3.2 KB, free: 912.3 MB)
21/02/17 01:29:57 INFO SparkContext: Created broadcast 10 from broadcast at DAGScheduler.scala:1039
21/02/17 01:29:57 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 9 (MapPartitionsRDD[46] at collect at utils.scala:135) (first 15 tasks are for partitions Vector(0))
21/02/17 01:29:57 INFO TaskSchedulerImpl: Adding task set 9.0 with 1 tasks
21/02/17 01:29:57 INFO TaskSetManager: Starting task 0.0 in stage 9.0 (TID 9, localhost, executor driver, partition 0, PROCESS_LOCAL, 8067 bytes)
21/02/17 01:29:57 INFO Executor: Running task 0.0 in stage 9.0 (TID 9)
21/02/17 01:29:57 INFO Executor: Finished task 0.0 in stage 9.0 (TID 9). 1286 bytes result sent to driver
21/02/17 01:29:57 INFO TaskSetManager: Finished task 0.0 in stage 9.0 (TID 9) in 5 ms on localhost (executor driver) (1/1)
21/02/17 01:29:57 INFO TaskSchedulerImpl: Removed TaskSet 9.0, whose tasks have all completed, from pool 
21/02/17 01:29:57 INFO DAGScheduler: ResultStage 9 (collect at utils.scala:135) finished in 0.009 s
21/02/17 01:29:57 INFO DAGScheduler: Job 7 finished: collect at utils.scala:135, took 0.010879 s
21/02/17 01:29:57 INFO SparkContext: Starting job: count at utils.scala:135
21/02/17 01:29:57 INFO DAGScheduler: Registering RDD 49 (count at utils.scala:135)
21/02/17 01:29:57 INFO DAGScheduler: Got job 8 (count at utils.scala:135) with 1 output partitions
21/02/17 01:29:57 INFO DAGScheduler: Final stage: ResultStage 11 (count at utils.scala:135)
21/02/17 01:29:57 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 10)
21/02/17 01:29:57 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 10)
21/02/17 01:29:57 INFO DAGScheduler: Submitting ShuffleMapStage 10 (MapPartitionsRDD[49] at count at utils.scala:135), which has no missing parents
21/02/17 01:29:57 INFO MemoryStore: Block broadcast_11 stored as values in memory (estimated size 8.9 KB, free 912.2 MB)
21/02/17 01:29:57 INFO MemoryStore: Block broadcast_11_piece0 stored as bytes in memory (estimated size 4.5 KB, free 912.2 MB)
21/02/17 01:29:57 INFO BlockManagerInfo: Added broadcast_11_piece0 in memory on localhost:34957 (size: 4.5 KB, free: 912.3 MB)
21/02/17 01:29:57 INFO SparkContext: Created broadcast 11 from broadcast at DAGScheduler.scala:1039
21/02/17 01:29:57 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 10 (MapPartitionsRDD[49] at count at utils.scala:135) (first 15 tasks are for partitions Vector(0))
21/02/17 01:29:57 INFO TaskSchedulerImpl: Adding task set 10.0 with 1 tasks
21/02/17 01:29:57 INFO TaskSetManager: Starting task 0.0 in stage 10.0 (TID 10, localhost, executor driver, partition 0, PROCESS_LOCAL, 8056 bytes)
21/02/17 01:29:57 INFO Executor: Running task 0.0 in stage 10.0 (TID 10)
21/02/17 01:29:57 INFO Executor: Finished task 0.0 in stage 10.0 (TID 10). 1456 bytes result sent to driver
21/02/17 01:29:57 INFO TaskSetManager: Finished task 0.0 in stage 10.0 (TID 10) in 5 ms on localhost (executor driver) (1/1)
21/02/17 01:29:57 INFO TaskSchedulerImpl: Removed TaskSet 10.0, whose tasks have all completed, from pool 
21/02/17 01:29:57 INFO DAGScheduler: ShuffleMapStage 10 (count at utils.scala:135) finished in 0.011 s
21/02/17 01:29:57 INFO DAGScheduler: looking for newly runnable stages
21/02/17 01:29:57 INFO DAGScheduler: running: Set()
21/02/17 01:29:57 INFO DAGScheduler: waiting: Set(ResultStage 11)
21/02/17 01:29:57 INFO DAGScheduler: failed: Set()
21/02/17 01:29:57 INFO DAGScheduler: Submitting ResultStage 11 (MapPartitionsRDD[52] at count at utils.scala:135), which has no missing parents
21/02/17 01:29:57 INFO MemoryStore: Block broadcast_12 stored as values in memory (estimated size 7.3 KB, free 912.2 MB)
21/02/17 01:29:57 INFO MemoryStore: Block broadcast_12_piece0 stored as bytes in memory (estimated size 3.8 KB, free 912.2 MB)
21/02/17 01:29:57 INFO BlockManagerInfo: Added broadcast_12_piece0 in memory on localhost:34957 (size: 3.8 KB, free: 912.3 MB)
21/02/17 01:29:57 INFO SparkContext: Created broadcast 12 from broadcast at DAGScheduler.scala:1039
21/02/17 01:29:57 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 11 (MapPartitionsRDD[52] at count at utils.scala:135) (first 15 tasks are for partitions Vector(0))
21/02/17 01:29:57 INFO TaskSchedulerImpl: Adding task set 11.0 with 1 tasks
21/02/17 01:29:57 INFO TaskSetManager: Starting task 0.0 in stage 11.0 (TID 11, localhost, executor driver, partition 0, NODE_LOCAL, 7754 bytes)
21/02/17 01:29:57 INFO Executor: Running task 0.0 in stage 11.0 (TID 11)
21/02/17 01:29:57 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
21/02/17 01:29:57 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
21/02/17 01:29:57 INFO Executor: Finished task 0.0 in stage 11.0 (TID 11). 1782 bytes result sent to driver
21/02/17 01:29:57 INFO TaskSetManager: Finished task 0.0 in stage 11.0 (TID 11) in 5 ms on localhost (executor driver) (1/1)
21/02/17 01:29:57 INFO TaskSchedulerImpl: Removed TaskSet 11.0, whose tasks have all completed, from pool 
21/02/17 01:29:57 INFO DAGScheduler: ResultStage 11 (count at utils.scala:135) finished in 0.010 s
21/02/17 01:29:57 INFO DAGScheduler: Job 8 finished: count at utils.scala:135, took 0.026112 s
21/02/17 01:29:58 INFO CodeGenerator: Code generated in 6.664164 ms
21/02/17 01:29:58 INFO CodeGenerator: Code generated in 5.857123 ms
21/02/17 01:29:58 INFO SparkContext: Starting job: collect at utils.scala:135
21/02/17 01:29:58 INFO DAGScheduler: Got job 9 (collect at utils.scala:135) with 1 output partitions
21/02/17 01:29:58 INFO DAGScheduler: Final stage: ResultStage 12 (collect at utils.scala:135)
21/02/17 01:29:58 INFO DAGScheduler: Parents of final stage: List()
21/02/17 01:29:58 INFO DAGScheduler: Missing parents: List()
21/02/17 01:29:58 INFO DAGScheduler: Submitting ResultStage 12 (MapPartitionsRDD[55] at collect at utils.scala:135), which has no missing parents
21/02/17 01:29:58 INFO MemoryStore: Block broadcast_13 stored as values in memory (estimated size 61.1 KB, free 912.1 MB)
21/02/17 01:29:58 INFO MemoryStore: Block broadcast_13_piece0 stored as bytes in memory (estimated size 25.3 KB, free 912.1 MB)
21/02/17 01:29:58 INFO BlockManagerInfo: Added broadcast_13_piece0 in memory on localhost:34957 (size: 25.3 KB, free: 912.2 MB)
21/02/17 01:29:58 INFO SparkContext: Created broadcast 13 from broadcast at DAGScheduler.scala:1039
21/02/17 01:29:58 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 12 (MapPartitionsRDD[55] at collect at utils.scala:135) (first 15 tasks are for partitions Vector(0))
21/02/17 01:29:58 INFO TaskSchedulerImpl: Adding task set 12.0 with 1 tasks
21/02/17 01:29:58 INFO TaskSetManager: Starting task 0.0 in stage 12.0 (TID 12, localhost, executor driver, partition 0, PROCESS_LOCAL, 18998 bytes)
21/02/17 01:29:58 INFO Executor: Running task 0.0 in stage 12.0 (TID 12)
21/02/17 01:29:58 INFO BlockManager: Found block rdd_17_0 locally
21/02/17 01:29:58 INFO CodeGenerator: Code generated in 11.347877 ms
21/02/17 01:29:58 INFO CodeGenerator: Code generated in 18.858253 ms
21/02/17 01:29:58 INFO CodeGenerator: Code generated in 39.740848 ms
21/02/17 01:29:58 INFO Executor: Finished task 0.0 in stage 12.0 (TID 12). 1815 bytes result sent to driver
21/02/17 01:29:58 INFO TaskSetManager: Finished task 0.0 in stage 12.0 (TID 12) in 137 ms on localhost (executor driver) (1/1)
21/02/17 01:29:58 INFO TaskSchedulerImpl: Removed TaskSet 12.0, whose tasks have all completed, from pool 
21/02/17 01:29:58 INFO DAGScheduler: ResultStage 12 (collect at utils.scala:135) finished in 0.144 s
21/02/17 01:29:58 INFO DAGScheduler: Job 9 finished: collect at utils.scala:135, took 0.145956 s
21/02/17 01:29:58 INFO CodeGenerator: Code generated in 6.904634 ms
21/02/17 01:29:58 INFO SparkContext: Starting job: count at utils.scala:135
21/02/17 01:29:58 INFO DAGScheduler: Registering RDD 58 (count at utils.scala:135)
21/02/17 01:29:58 INFO DAGScheduler: Got job 10 (count at utils.scala:135) with 1 output partitions
21/02/17 01:29:58 INFO DAGScheduler: Final stage: ResultStage 14 (count at utils.scala:135)
21/02/17 01:29:58 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 13)
21/02/17 01:29:58 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 13)
21/02/17 01:29:58 INFO DAGScheduler: Submitting ShuffleMapStage 13 (MapPartitionsRDD[58] at count at utils.scala:135), which has no missing parents
21/02/17 01:29:58 INFO MemoryStore: Block broadcast_14 stored as values in memory (estimated size 62.0 KB, free 912.0 MB)
21/02/17 01:29:58 INFO MemoryStore: Block broadcast_14_piece0 stored as bytes in memory (estimated size 25.8 KB, free 912.0 MB)
21/02/17 01:29:58 INFO BlockManagerInfo: Added broadcast_14_piece0 in memory on localhost:34957 (size: 25.8 KB, free: 912.2 MB)
21/02/17 01:29:58 INFO SparkContext: Created broadcast 14 from broadcast at DAGScheduler.scala:1039
21/02/17 01:29:58 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 13 (MapPartitionsRDD[58] at count at utils.scala:135) (first 15 tasks are for partitions Vector(0))
21/02/17 01:29:58 INFO TaskSchedulerImpl: Adding task set 13.0 with 1 tasks
21/02/17 01:29:58 INFO TaskSetManager: Starting task 0.0 in stage 13.0 (TID 13, localhost, executor driver, partition 0, PROCESS_LOCAL, 18987 bytes)
21/02/17 01:29:58 INFO Executor: Running task 0.0 in stage 13.0 (TID 13)
21/02/17 01:29:58 INFO BlockManager: Found block rdd_17_0 locally
21/02/17 01:29:58 INFO Executor: Finished task 0.0 in stage 13.0 (TID 13). 1933 bytes result sent to driver
21/02/17 01:29:58 INFO TaskSetManager: Finished task 0.0 in stage 13.0 (TID 13) in 44 ms on localhost (executor driver) (1/1)
21/02/17 01:29:58 INFO TaskSchedulerImpl: Removed TaskSet 13.0, whose tasks have all completed, from pool 
21/02/17 01:29:58 INFO DAGScheduler: ShuffleMapStage 13 (count at utils.scala:135) finished in 0.051 s
21/02/17 01:29:58 INFO DAGScheduler: looking for newly runnable stages
21/02/17 01:29:58 INFO DAGScheduler: running: Set()
21/02/17 01:29:58 INFO DAGScheduler: waiting: Set(ResultStage 14)
21/02/17 01:29:58 INFO DAGScheduler: failed: Set()
21/02/17 01:29:58 INFO DAGScheduler: Submitting ResultStage 14 (MapPartitionsRDD[61] at count at utils.scala:135), which has no missing parents
21/02/17 01:29:58 INFO MemoryStore: Block broadcast_15 stored as values in memory (estimated size 7.3 KB, free 912.0 MB)
21/02/17 01:29:58 INFO MemoryStore: Block broadcast_15_piece0 stored as bytes in memory (estimated size 3.8 KB, free 912.0 MB)
21/02/17 01:29:58 INFO BlockManagerInfo: Added broadcast_15_piece0 in memory on localhost:34957 (size: 3.8 KB, free: 912.2 MB)
21/02/17 01:29:58 INFO SparkContext: Created broadcast 15 from broadcast at DAGScheduler.scala:1039
21/02/17 01:29:58 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 14 (MapPartitionsRDD[61] at count at utils.scala:135) (first 15 tasks are for partitions Vector(0))
21/02/17 01:29:58 INFO TaskSchedulerImpl: Adding task set 14.0 with 1 tasks
21/02/17 01:29:58 INFO TaskSetManager: Starting task 0.0 in stage 14.0 (TID 14, localhost, executor driver, partition 0, NODE_LOCAL, 7754 bytes)
21/02/17 01:29:58 INFO Executor: Running task 0.0 in stage 14.0 (TID 14)
21/02/17 01:29:58 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
21/02/17 01:29:58 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
21/02/17 01:29:58 INFO Executor: Finished task 0.0 in stage 14.0 (TID 14). 1782 bytes result sent to driver
21/02/17 01:29:58 INFO TaskSetManager: Finished task 0.0 in stage 14.0 (TID 14) in 4 ms on localhost (executor driver) (1/1)
21/02/17 01:29:58 INFO TaskSchedulerImpl: Removed TaskSet 14.0, whose tasks have all completed, from pool 
21/02/17 01:29:58 INFO DAGScheduler: ResultStage 14 (count at utils.scala:135) finished in 0.009 s
21/02/17 01:29:58 INFO DAGScheduler: Job 10 finished: count at utils.scala:135, took 0.062988 s
21/02/17 01:29:58 INFO deprecation: mapred.output.dir is deprecated. Instead, use mapreduce.output.fileoutputformat.outputdir
21/02/17 01:29:58 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
21/02/17 01:29:58 INFO SparkContext: Starting job: runJob at SparkHadoopWriter.scala:78
21/02/17 01:29:58 INFO DAGScheduler: Got job 11 (runJob at SparkHadoopWriter.scala:78) with 1 output partitions
21/02/17 01:29:58 INFO DAGScheduler: Final stage: ResultStage 15 (runJob at SparkHadoopWriter.scala:78)
21/02/17 01:29:58 INFO DAGScheduler: Parents of final stage: List()
21/02/17 01:29:58 INFO DAGScheduler: Missing parents: List()
21/02/17 01:29:58 INFO DAGScheduler: Submitting ResultStage 15 (MapPartitionsRDD[63] at saveAsTextFile at ReadWrite.scala:283), which has no missing parents
21/02/17 01:29:58 INFO MemoryStore: Block broadcast_16 stored as values in memory (estimated size 71.0 KB, free 911.9 MB)
21/02/17 01:29:58 INFO MemoryStore: Block broadcast_16_piece0 stored as bytes in memory (estimated size 25.3 KB, free 911.9 MB)
21/02/17 01:29:58 INFO BlockManagerInfo: Added broadcast_16_piece0 in memory on localhost:34957 (size: 25.3 KB, free: 912.2 MB)
21/02/17 01:29:58 INFO SparkContext: Created broadcast 16 from broadcast at DAGScheduler.scala:1039
21/02/17 01:29:58 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 15 (MapPartitionsRDD[63] at saveAsTextFile at ReadWrite.scala:283) (first 15 tasks are for partitions Vector(0))
21/02/17 01:29:58 INFO TaskSchedulerImpl: Adding task set 15.0 with 1 tasks
21/02/17 01:29:58 INFO TaskSetManager: Starting task 0.0 in stage 15.0 (TID 15, localhost, executor driver, partition 0, PROCESS_LOCAL, 8142 bytes)
21/02/17 01:29:58 INFO Executor: Running task 0.0 in stage 15.0 (TID 15)
21/02/17 01:29:58 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
21/02/17 01:29:58 INFO FileOutputCommitter: Saved output of task 'attempt_20210217012958_0063_m_000000_0' to file:/tmp/Rtmpf0aMkz/file21d2743d02267/metadata/_temporary/0/task_20210217012958_0063_m_000000
21/02/17 01:29:58 INFO SparkHadoopMapRedUtil: attempt_20210217012958_0063_m_000000_0: Committed
21/02/17 01:29:58 INFO Executor: Finished task 0.0 in stage 15.0 (TID 15). 1072 bytes result sent to driver
21/02/17 01:29:58 INFO TaskSetManager: Finished task 0.0 in stage 15.0 (TID 15) in 37 ms on localhost (executor driver) (1/1)
21/02/17 01:29:58 INFO TaskSchedulerImpl: Removed TaskSet 15.0, whose tasks have all completed, from pool 
21/02/17 01:29:58 INFO DAGScheduler: ResultStage 15 (runJob at SparkHadoopWriter.scala:78) finished in 0.050 s
21/02/17 01:29:58 INFO DAGScheduler: Job 11 finished: runJob at SparkHadoopWriter.scala:78, took 0.051638 s
21/02/17 01:29:58 INFO SparkHadoopWriter: Job job_20210217012958_0063 committed.
21/02/17 01:29:58 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
21/02/17 01:29:58 INFO SparkContext: Starting job: runJob at SparkHadoopWriter.scala:78
21/02/17 01:29:58 INFO DAGScheduler: Got job 12 (runJob at SparkHadoopWriter.scala:78) with 1 output partitions
21/02/17 01:29:58 INFO DAGScheduler: Final stage: ResultStage 16 (runJob at SparkHadoopWriter.scala:78)
21/02/17 01:29:58 INFO DAGScheduler: Parents of final stage: List()
21/02/17 01:29:58 INFO DAGScheduler: Missing parents: List()
21/02/17 01:29:58 INFO DAGScheduler: Submitting ResultStage 16 (MapPartitionsRDD[65] at saveAsTextFile at ReadWrite.scala:283), which has no missing parents
21/02/17 01:29:58 INFO MemoryStore: Block broadcast_17 stored as values in memory (estimated size 71.1 KB, free 911.8 MB)
21/02/17 01:29:58 INFO MemoryStore: Block broadcast_17_piece0 stored as bytes in memory (estimated size 25.4 KB, free 911.8 MB)
21/02/17 01:29:58 INFO BlockManagerInfo: Added broadcast_17_piece0 in memory on localhost:34957 (size: 25.4 KB, free: 912.2 MB)
21/02/17 01:29:58 INFO SparkContext: Created broadcast 17 from broadcast at DAGScheduler.scala:1039
21/02/17 01:29:58 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 16 (MapPartitionsRDD[65] at saveAsTextFile at ReadWrite.scala:283) (first 15 tasks are for partitions Vector(0))
21/02/17 01:29:58 INFO TaskSchedulerImpl: Adding task set 16.0 with 1 tasks
21/02/17 01:29:58 INFO TaskSetManager: Starting task 0.0 in stage 16.0 (TID 16, localhost, executor driver, partition 0, PROCESS_LOCAL, 8216 bytes)
21/02/17 01:29:58 INFO Executor: Running task 0.0 in stage 16.0 (TID 16)
21/02/17 01:29:58 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
21/02/17 01:29:58 INFO FileOutputCommitter: Saved output of task 'attempt_20210217012958_0065_m_000000_0' to file:/tmp/Rtmpf0aMkz/file21d2743d02267/stages/0_r_formula__4a78c67a_b2d6_47f3_b339_f6bd796b0af6/metadata/_temporary/0/task_20210217012958_0065_m_000000
21/02/17 01:29:58 INFO SparkHadoopMapRedUtil: attempt_20210217012958_0065_m_000000_0: Committed
21/02/17 01:29:58 INFO Executor: Finished task 0.0 in stage 16.0 (TID 16). 1029 bytes result sent to driver
21/02/17 01:29:58 INFO TaskSetManager: Finished task 0.0 in stage 16.0 (TID 16) in 13 ms on localhost (executor driver) (1/1)
21/02/17 01:29:58 INFO TaskSchedulerImpl: Removed TaskSet 16.0, whose tasks have all completed, from pool 
21/02/17 01:29:58 INFO DAGScheduler: ResultStage 16 (runJob at SparkHadoopWriter.scala:78) finished in 0.024 s
21/02/17 01:29:58 INFO DAGScheduler: Job 12 finished: runJob at SparkHadoopWriter.scala:78, took 0.025359 s
21/02/17 01:29:58 INFO SparkHadoopWriter: Job job_20210217012958_0065 committed.
21/02/17 01:29:58 INFO ParquetFileFormat: Using default output committer for Parquet: org.apache.parquet.hadoop.ParquetOutputCommitter
21/02/17 01:29:58 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
21/02/17 01:29:58 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
21/02/17 01:29:58 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
21/02/17 01:29:58 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
21/02/17 01:29:58 INFO ContextCleaner: Cleaned accumulator 500
21/02/17 01:29:58 INFO CodeGenerator: Code generated in 29.908585 ms
21/02/17 01:29:58 INFO BlockManagerInfo: Removed broadcast_11_piece0 on localhost:34957 in memory (size: 4.5 KB, free: 912.2 MB)
21/02/17 01:29:58 INFO ContextCleaner: Cleaned accumulator 299
21/02/17 01:29:58 INFO ContextCleaner: Cleaned accumulator 376
21/02/17 01:29:58 INFO ContextCleaner: Cleaned accumulator 292
21/02/17 01:29:58 INFO ContextCleaner: Cleaned accumulator 394
21/02/17 01:29:58 INFO ContextCleaner: Cleaned accumulator 282
21/02/17 01:29:58 INFO ContextCleaner: Cleaned accumulator 317
21/02/17 01:29:58 INFO ContextCleaner: Cleaned accumulator 297
21/02/17 01:29:58 INFO ContextCleaner: Cleaned accumulator 261
21/02/17 01:29:58 INFO ContextCleaner: Cleaned accumulator 389
21/02/17 01:29:58 INFO ContextCleaner: Cleaned accumulator 345
21/02/17 01:29:58 INFO ContextCleaner: Cleaned accumulator 377
21/02/17 01:29:58 INFO ContextCleaner: Cleaned accumulator 272
21/02/17 01:29:58 INFO ContextCleaner: Cleaned accumulator 381
21/02/17 01:29:58 INFO ContextCleaner: Cleaned accumulator 395
21/02/17 01:29:58 INFO ContextCleaner: Cleaned accumulator 412
21/02/17 01:29:58 INFO ContextCleaner: Cleaned accumulator 477
21/02/17 01:29:58 INFO ContextCleaner: Cleaned accumulator 434
21/02/17 01:29:58 INFO ContextCleaner: Cleaned accumulator 400
21/02/17 01:29:58 INFO ContextCleaner: Cleaned accumulator 246
21/02/17 01:29:58 INFO ContextCleaner: Cleaned accumulator 302
21/02/17 01:29:58 INFO ContextCleaner: Cleaned accumulator 321
21/02/17 01:29:58 INFO ContextCleaner: Cleaned accumulator 336
21/02/17 01:29:58 INFO ContextCleaner: Cleaned accumulator 325
21/02/17 01:29:58 INFO ContextCleaner: Cleaned accumulator 492
21/02/17 01:29:58 INFO ContextCleaner: Cleaned accumulator 391
21/02/17 01:29:58 INFO ContextCleaner: Cleaned accumulator 264
21/02/17 01:29:58 INFO ContextCleaner: Cleaned accumulator 244
21/02/17 01:29:58 INFO BlockManagerInfo: Removed broadcast_10_piece0 on localhost:34957 in memory (size: 3.2 KB, free: 912.2 MB)
21/02/17 01:29:58 INFO ContextCleaner: Cleaned accumulator 343
21/02/17 01:29:58 INFO ContextCleaner: Cleaned accumulator 356
21/02/17 01:29:58 INFO ContextCleaner: Cleaned accumulator 328
21/02/17 01:29:58 INFO ContextCleaner: Cleaned accumulator 277
21/02/17 01:29:58 INFO ContextCleaner: Cleaned accumulator 497
21/02/17 01:29:58 INFO ContextCleaner: Cleaned accumulator 324
21/02/17 01:29:58 INFO ContextCleaner: Cleaned accumulator 220
21/02/17 01:29:58 INFO ContextCleaner: Cleaned accumulator 444
21/02/17 01:29:58 INFO ContextCleaner: Cleaned accumulator 258
21/02/17 01:29:58 INFO ContextCleaner: Cleaned accumulator 409
21/02/17 01:29:58 INFO ContextCleaner: Cleaned accumulator 215
21/02/17 01:29:58 INFO BlockManagerInfo: Removed broadcast_14_piece0 on localhost:34957 in memory (size: 25.8 KB, free: 912.2 MB)
21/02/17 01:29:58 INFO ContextCleaner: Cleaned accumulator 323
21/02/17 01:29:58 INFO ContextCleaner: Cleaned accumulator 364
21/02/17 01:29:58 INFO ContextCleaner: Cleaned accumulator 249
21/02/17 01:29:58 INFO ContextCleaner: Cleaned accumulator 414
21/02/17 01:29:58 INFO ContextCleaner: Cleaned accumulator 228
21/02/17 01:29:58 INFO ContextCleaner: Cleaned accumulator 481
21/02/17 01:29:58 INFO ContextCleaner: Cleaned accumulator 493
21/02/17 01:29:58 INFO ContextCleaner: Cleaned accumulator 399
21/02/17 01:29:58 INFO ContextCleaner: Cleaned accumulator 296
21/02/17 01:29:58 INFO ContextCleaner: Cleaned accumulator 403
21/02/17 01:29:58 INFO ContextCleaner: Cleaned accumulator 283
21/02/17 01:29:58 INFO ContextCleaner: Cleaned accumulator 467
21/02/17 01:29:58 INFO ContextCleaner: Cleaned accumulator 470
21/02/17 01:29:58 INFO ContextCleaner: Cleaned accumulator 474
21/02/17 01:29:58 INFO ContextCleaner: Cleaned accumulator 450
21/02/17 01:29:58 INFO ContextCleaner: Cleaned accumulator 254
21/02/17 01:29:58 INFO ContextCleaner: Cleaned accumulator 491
21/02/17 01:29:58 INFO ContextCleaner: Cleaned accumulator 217
21/02/17 01:29:58 INFO ContextCleaner: Cleaned accumulator 483
21/02/17 01:29:58 INFO ContextCleaner: Cleaned accumulator 426
21/02/17 01:29:58 INFO ContextCleaner: Cleaned accumulator 230
21/02/17 01:29:58 INFO ContextCleaner: Cleaned accumulator 489
21/02/17 01:29:58 INFO ContextCleaner: Cleaned accumulator 424
21/02/17 01:29:58 INFO ContextCleaner: Cleaned accumulator 243
21/02/17 01:29:58 INFO ContextCleaner: Cleaned accumulator 252
21/02/17 01:29:58 INFO ContextCleaner: Cleaned accumulator 330
21/02/17 01:29:58 INFO ContextCleaner: Cleaned accumulator 498
21/02/17 01:29:58 INFO ContextCleaner: Cleaned accumulator 288
21/02/17 01:29:58 INFO ContextCleaner: Cleaned accumulator 454
21/02/17 01:29:58 INFO ContextCleaner: Cleaned accumulator 398
21/02/17 01:29:58 INFO ContextCleaner: Cleaned accumulator 219
21/02/17 01:29:58 INFO ContextCleaner: Cleaned accumulator 375
21/02/17 01:29:58 INFO ContextCleaner: Cleaned accumulator 241
21/02/17 01:29:58 INFO ContextCleaner: Cleaned accumulator 233
21/02/17 01:29:58 INFO ContextCleaner: Cleaned accumulator 251
21/02/17 01:29:58 INFO ContextCleaner: Cleaned accumulator 263
21/02/17 01:29:58 INFO ContextCleaner: Cleaned accumulator 422
21/02/17 01:29:58 INFO ContextCleaner: Cleaned accumulator 440
21/02/17 01:29:58 INFO ContextCleaner: Cleaned accumulator 367
21/02/17 01:29:58 INFO ContextCleaner: Cleaned accumulator 382
21/02/17 01:29:58 INFO ContextCleaner: Cleaned accumulator 280
21/02/17 01:29:58 INFO ContextCleaner: Cleaned accumulator 326
21/02/17 01:29:58 INFO ContextCleaner: Cleaned accumulator 316
21/02/17 01:29:58 INFO BlockManager: Removing RDD 35
21/02/17 01:29:58 INFO ContextCleaner: Cleaned RDD 35
21/02/17 01:29:58 INFO ContextCleaner: Cleaned accumulator 495
21/02/17 01:29:58 INFO ContextCleaner: Cleaned accumulator 290
21/02/17 01:29:58 INFO ContextCleaner: Cleaned accumulator 229
21/02/17 01:29:58 INFO ContextCleaner: Cleaned accumulator 387
21/02/17 01:29:58 INFO ContextCleaner: Cleaned accumulator 482
21/02/17 01:29:58 INFO ContextCleaner: Cleaned accumulator 385
21/02/17 01:29:58 INFO BlockManagerInfo: Removed broadcast_15_piece0 on localhost:34957 in memory (size: 3.8 KB, free: 912.2 MB)
21/02/17 01:29:58 INFO ContextCleaner: Cleaned accumulator 294
21/02/17 01:29:58 INFO ContextCleaner: Cleaned accumulator 256
21/02/17 01:29:58 INFO ContextCleaner: Cleaned accumulator 275
21/02/17 01:29:58 INFO ContextCleaner: Cleaned accumulator 502
21/02/17 01:29:58 INFO ContextCleaner: Cleaned accumulator 268
21/02/17 01:29:58 INFO ContextCleaner: Cleaned accumulator 342
21/02/17 01:29:58 INFO ContextCleaner: Cleaned accumulator 411
21/02/17 01:29:58 INFO ContextCleaner: Cleaned accumulator 234
21/02/17 01:29:58 INFO ContextCleaner: Cleaned accumulator 365
21/02/17 01:29:58 INFO ContextCleaner: Cleaned accumulator 362
21/02/17 01:29:58 INFO ContextCleaner: Cleaned accumulator 392
21/02/17 01:29:58 INFO ContextCleaner: Cleaned accumulator 372
21/02/17 01:29:58 INFO ContextCleaner: Cleaned accumulator 449
21/02/17 01:29:58 INFO ContextCleaner: Cleaned accumulator 402
21/02/17 01:29:58 INFO ContextCleaner: Cleaned accumulator 260
21/02/17 01:29:58 INFO ContextCleaner: Cleaned accumulator 484
21/02/17 01:29:58 INFO ContextCleaner: Cleaned accumulator 293
21/02/17 01:29:58 INFO ContextCleaner: Cleaned accumulator 425
21/02/17 01:29:58 INFO ContextCleaner: Cleaned accumulator 431
21/02/17 01:29:58 INFO ContextCleaner: Cleaned accumulator 347
21/02/17 01:29:58 INFO ContextCleaner: Cleaned accumulator 354
21/02/17 01:29:58 INFO ContextCleaner: Cleaned accumulator 463
21/02/17 01:29:58 INFO ContextCleaner: Cleaned accumulator 344
21/02/17 01:29:58 INFO ContextCleaner: Cleaned accumulator 419
21/02/17 01:29:58 INFO ContextCleaner: Cleaned accumulator 212
21/02/17 01:29:58 INFO ContextCleaner: Cleaned accumulator 242
21/02/17 01:29:58 INFO ContextCleaner: Cleaned accumulator 374
21/02/17 01:29:58 INFO ContextCleaner: Cleaned accumulator 279
21/02/17 01:29:58 INFO ContextCleaner: Cleaned accumulator 466
21/02/17 01:29:58 INFO ContextCleaner: Cleaned accumulator 421
21/02/17 01:29:58 INFO ContextCleaner: Cleaned accumulator 358
21/02/17 01:29:58 INFO ContextCleaner: Cleaned accumulator 406
21/02/17 01:29:58 INFO ContextCleaner: Cleaned accumulator 436
21/02/17 01:29:58 INFO ContextCleaner: Cleaned accumulator 485
21/02/17 01:29:58 INFO ContextCleaner: Cleaned accumulator 379
21/02/17 01:29:58 INFO ContextCleaner: Cleaned accumulator 222
21/02/17 01:29:58 INFO ContextCleaner: Cleaned accumulator 499
21/02/17 01:29:58 INFO ContextCleaner: Cleaned accumulator 346
21/02/17 01:29:58 INFO ContextCleaner: Cleaned accumulator 472
21/02/17 01:29:58 INFO ContextCleaner: Cleaned accumulator 332
21/02/17 01:29:58 INFO ContextCleaner: Cleaned accumulator 315
21/02/17 01:29:58 INFO ContextCleaner: Cleaned accumulator 370
21/02/17 01:29:58 INFO ContextCleaner: Cleaned accumulator 351
21/02/17 01:29:58 INFO ContextCleaner: Cleaned accumulator 479
21/02/17 01:29:58 INFO ContextCleaner: Cleaned accumulator 349
21/02/17 01:29:58 INFO ContextCleaner: Cleaned accumulator 396
21/02/17 01:29:58 INFO ContextCleaner: Cleaned accumulator 259
21/02/17 01:29:58 INFO ContextCleaner: Cleaned accumulator 231
21/02/17 01:29:58 INFO ContextCleaner: Cleaned accumulator 428
21/02/17 01:29:58 INFO ContextCleaner: Cleaned accumulator 247
21/02/17 01:29:58 INFO ContextCleaner: Cleaned accumulator 285
21/02/17 01:29:58 INFO ContextCleaner: Cleaned accumulator 447
21/02/17 01:29:58 INFO ContextCleaner: Cleaned accumulator 300
21/02/17 01:29:58 INFO ContextCleaner: Cleaned accumulator 337
21/02/17 01:29:58 INFO ContextCleaner: Cleaned accumulator 214
21/02/17 01:29:58 INFO ContextCleaner: Cleaned accumulator 310
21/02/17 01:29:58 INFO ContextCleaner: Cleaned accumulator 239
21/02/17 01:29:58 INFO ContextCleaner: Cleaned accumulator 236
21/02/17 01:29:58 INFO ContextCleaner: Cleaned accumulator 278
21/02/17 01:29:58 INFO ContextCleaner: Cleaned accumulator 456
21/02/17 01:29:58 INFO ContextCleaner: Cleaned accumulator 475
21/02/17 01:29:58 INFO ContextCleaner: Cleaned accumulator 253
21/02/17 01:29:58 INFO ContextCleaner: Cleaned accumulator 335
21/02/17 01:29:58 INFO ContextCleaner: Cleaned accumulator 435
21/02/17 01:29:58 INFO ContextCleaner: Cleaned accumulator 420
21/02/17 01:29:58 INFO ContextCleaner: Cleaned accumulator 270
21/02/17 01:29:58 INFO ContextCleaner: Cleaned accumulator 295
21/02/17 01:29:58 INFO ContextCleaner: Cleaned accumulator 446
21/02/17 01:29:58 INFO ContextCleaner: Cleaned accumulator 338
21/02/17 01:29:58 INFO ContextCleaner: Cleaned accumulator 453
21/02/17 01:29:58 INFO ContextCleaner: Cleaned accumulator 255
21/02/17 01:29:58 INFO ContextCleaner: Cleaned accumulator 329
21/02/17 01:29:58 INFO ContextCleaner: Cleaned accumulator 445
21/02/17 01:29:58 INFO ContextCleaner: Cleaned accumulator 318
21/02/17 01:29:58 INFO ContextCleaner: Cleaned accumulator 303
21/02/17 01:29:58 INFO ContextCleaner: Cleaned accumulator 269
21/02/17 01:29:58 INFO ContextCleaner: Cleaned accumulator 289
21/02/17 01:29:58 INFO ContextCleaner: Cleaned accumulator 224
21/02/17 01:29:58 INFO ContextCleaner: Cleaned accumulator 319
21/02/17 01:29:58 INFO ContextCleaner: Cleaned accumulator 388
21/02/17 01:29:58 INFO ContextCleaner: Cleaned accumulator 271
21/02/17 01:29:58 INFO ContextCleaner: Cleaned accumulator 257
21/02/17 01:29:58 INFO ContextCleaner: Cleaned accumulator 413
21/02/17 01:29:58 INFO ContextCleaner: Cleaned accumulator 235
21/02/17 01:29:58 INFO ContextCleaner: Cleaned accumulator 471
21/02/17 01:29:58 INFO ContextCleaner: Cleaned accumulator 383
21/02/17 01:29:58 INFO ContextCleaner: Cleaned accumulator 213
21/02/17 01:29:58 INFO ContextCleaner: Cleaned accumulator 333
21/02/17 01:29:58 INFO ContextCleaner: Cleaned accumulator 352
21/02/17 01:29:58 INFO BlockManagerInfo: Removed broadcast_12_piece0 on localhost:34957 in memory (size: 3.8 KB, free: 912.2 MB)
21/02/17 01:29:58 INFO ContextCleaner: Cleaned accumulator 442
21/02/17 01:29:58 INFO ContextCleaner: Cleaned accumulator 487
21/02/17 01:29:58 INFO ContextCleaner: Cleaned accumulator 390
21/02/17 01:29:58 INFO ContextCleaner: Cleaned accumulator 340
21/02/17 01:29:58 INFO ContextCleaner: Cleaned accumulator 378
21/02/17 01:29:58 INFO ContextCleaner: Cleaned accumulator 461
21/02/17 01:29:58 INFO ContextCleaner: Cleaned accumulator 429
21/02/17 01:29:58 INFO ContextCleaner: Cleaned accumulator 468
21/02/17 01:29:58 INFO ContextCleaner: Cleaned accumulator 410
21/02/17 01:29:58 INFO ContextCleaner: Cleaned shuffle 2
21/02/17 01:29:58 INFO ContextCleaner: Cleaned accumulator 432
21/02/17 01:29:58 INFO ContextCleaner: Cleaned accumulator 373
21/02/17 01:29:58 INFO ContextCleaner: Cleaned accumulator 439
21/02/17 01:29:58 INFO ContextCleaner: Cleaned accumulator 488
21/02/17 01:29:58 INFO ContextCleaner: Cleaned accumulator 384
21/02/17 01:29:58 INFO ContextCleaner: Cleaned accumulator 353
21/02/17 01:29:58 INFO ContextCleaner: Cleaned accumulator 494
21/02/17 01:29:58 INFO ContextCleaner: Cleaned accumulator 339
21/02/17 01:29:58 INFO ContextCleaner: Cleaned accumulator 306
21/02/17 01:29:58 INFO ContextCleaner: Cleaned accumulator 320
21/02/17 01:29:58 INFO ContextCleaner: Cleaned accumulator 291
21/02/17 01:29:58 INFO ContextCleaner: Cleaned accumulator 273
21/02/17 01:29:58 INFO ContextCleaner: Cleaned accumulator 281
21/02/17 01:29:58 INFO ContextCleaner: Cleaned accumulator 460
21/02/17 01:29:58 INFO ContextCleaner: Cleaned accumulator 240
21/02/17 01:29:58 INFO ContextCleaner: Cleaned accumulator 355
21/02/17 01:29:58 INFO ContextCleaner: Cleaned accumulator 276
21/02/17 01:29:58 INFO ContextCleaner: Cleaned accumulator 464
21/02/17 01:29:58 INFO ContextCleaner: Cleaned accumulator 341
21/02/17 01:29:58 INFO ContextCleaner: Cleaned accumulator 496
21/02/17 01:29:58 INFO ContextCleaner: Cleaned accumulator 448
21/02/17 01:29:58 INFO ContextCleaner: Cleaned accumulator 465
21/02/17 01:29:58 INFO ContextCleaner: Cleaned accumulator 490
21/02/17 01:29:58 INFO ContextCleaner: Cleaned accumulator 457
21/02/17 01:29:58 INFO ContextCleaner: Cleaned accumulator 227
21/02/17 01:29:58 INFO ContextCleaner: Cleaned accumulator 223
21/02/17 01:29:58 INFO ContextCleaner: Cleaned accumulator 418
21/02/17 01:29:58 INFO ContextCleaner: Cleaned accumulator 250
21/02/17 01:29:58 INFO ContextCleaner: Cleaned accumulator 404
21/02/17 01:29:58 INFO ContextCleaner: Cleaned accumulator 286
21/02/17 01:29:58 INFO ContextCleaner: Cleaned accumulator 322
21/02/17 01:29:58 INFO ContextCleaner: Cleaned accumulator 327
21/02/17 01:29:58 INFO ContextCleaner: Cleaned accumulator 459
21/02/17 01:29:58 INFO ContextCleaner: Cleaned accumulator 331
21/02/17 01:29:58 INFO ContextCleaner: Cleaned accumulator 248
21/02/17 01:29:58 INFO ContextCleaner: Cleaned accumulator 305
21/02/17 01:29:58 INFO ContextCleaner: Cleaned accumulator 218
21/02/17 01:29:58 INFO ContextCleaner: Cleaned accumulator 313
21/02/17 01:29:58 INFO ContextCleaner: Cleaned accumulator 366
21/02/17 01:29:58 INFO ContextCleaner: Cleaned accumulator 368
21/02/17 01:29:58 INFO ContextCleaner: Cleaned accumulator 469
21/02/17 01:29:58 INFO ContextCleaner: Cleaned accumulator 415
21/02/17 01:29:58 INFO ContextCleaner: Cleaned accumulator 363
21/02/17 01:29:58 INFO ContextCleaner: Cleaned accumulator 408
21/02/17 01:29:58 INFO ContextCleaner: Cleaned accumulator 284
21/02/17 01:29:58 INFO ContextCleaner: Cleaned accumulator 221
21/02/17 01:29:58 INFO BlockManagerInfo: Removed broadcast_8_piece0 on localhost:34957 in memory (size: 14.3 KB, free: 912.2 MB)
21/02/17 01:29:58 INFO ContextCleaner: Cleaned accumulator 405
21/02/17 01:29:58 INFO ContextCleaner: Cleaned accumulator 441
21/02/17 01:29:58 INFO ContextCleaner: Cleaned accumulator 311
21/02/17 01:29:58 INFO ContextCleaner: Cleaned shuffle 3
21/02/17 01:29:58 INFO ContextCleaner: Cleaned accumulator 334
21/02/17 01:29:58 INFO ContextCleaner: Cleaned accumulator 357
21/02/17 01:29:58 INFO ContextCleaner: Cleaned accumulator 225
21/02/17 01:29:58 INFO ContextCleaner: Cleaned accumulator 455
21/02/17 01:29:58 INFO ContextCleaner: Cleaned accumulator 473
21/02/17 01:29:58 INFO ContextCleaner: Cleaned accumulator 369
21/02/17 01:29:58 INFO ContextCleaner: Cleaned accumulator 462
21/02/17 01:29:58 INFO ContextCleaner: Cleaned accumulator 237
21/02/17 01:29:58 INFO ContextCleaner: Cleaned accumulator 478
21/02/17 01:29:58 INFO ContextCleaner: Cleaned accumulator 416
21/02/17 01:29:58 INFO ContextCleaner: Cleaned accumulator 423
21/02/17 01:29:58 INFO ContextCleaner: Cleaned accumulator 274
21/02/17 01:29:58 INFO ContextCleaner: Cleaned accumulator 301
21/02/17 01:29:58 INFO ContextCleaner: Cleaned accumulator 348
21/02/17 01:29:58 INFO ContextCleaner: Cleaned accumulator 245
21/02/17 01:29:58 INFO BlockManagerInfo: Removed broadcast_17_piece0 on localhost:34957 in memory (size: 25.4 KB, free: 912.2 MB)
21/02/17 01:29:58 INFO ContextCleaner: Cleaned accumulator 486
21/02/17 01:29:58 INFO ContextCleaner: Cleaned accumulator 438
21/02/17 01:29:58 INFO ContextCleaner: Cleaned accumulator 501
21/02/17 01:29:58 INFO ContextCleaner: Cleaned accumulator 359
21/02/17 01:29:58 INFO ContextCleaner: Cleaned accumulator 451
21/02/17 01:29:58 INFO BlockManagerInfo: Removed broadcast_13_piece0 on localhost:34957 in memory (size: 25.3 KB, free: 912.3 MB)
21/02/17 01:29:58 INFO ContextCleaner: Cleaned accumulator 298
21/02/17 01:29:58 INFO ContextCleaner: Cleaned accumulator 407
21/02/17 01:29:58 INFO ContextCleaner: Cleaned accumulator 308
21/02/17 01:29:58 INFO ContextCleaner: Cleaned accumulator 452
21/02/17 01:29:58 INFO ContextCleaner: Cleaned accumulator 262
21/02/17 01:29:58 INFO ContextCleaner: Cleaned accumulator 417
21/02/17 01:29:58 INFO ContextCleaner: Cleaned accumulator 433
21/02/17 01:29:58 INFO ContextCleaner: Cleaned accumulator 386
21/02/17 01:29:58 INFO ContextCleaner: Cleaned accumulator 430
21/02/17 01:29:58 INFO ContextCleaner: Cleaned accumulator 226
21/02/17 01:29:58 INFO ContextCleaner: Cleaned accumulator 232
21/02/17 01:29:58 INFO ContextCleaner: Cleaned accumulator 371
21/02/17 01:29:58 INFO ContextCleaner: Cleaned accumulator 314
21/02/17 01:29:58 INFO ContextCleaner: Cleaned accumulator 312
21/02/17 01:29:58 INFO ContextCleaner: Cleaned accumulator 458
21/02/17 01:29:58 INFO ContextCleaner: Cleaned accumulator 427
21/02/17 01:29:58 INFO ContextCleaner: Cleaned accumulator 480
21/02/17 01:29:58 INFO ContextCleaner: Cleaned accumulator 304
21/02/17 01:29:58 INFO ContextCleaner: Cleaned accumulator 287
21/02/17 01:29:58 INFO ContextCleaner: Cleaned accumulator 216
21/02/17 01:29:58 INFO ContextCleaner: Cleaned accumulator 437
21/02/17 01:29:58 INFO ContextCleaner: Cleaned accumulator 380
21/02/17 01:29:58 INFO ContextCleaner: Cleaned accumulator 476
21/02/17 01:29:58 INFO ContextCleaner: Cleaned accumulator 360
21/02/17 01:29:58 INFO ContextCleaner: Cleaned accumulator 401
21/02/17 01:29:58 INFO ContextCleaner: Cleaned accumulator 307
21/02/17 01:29:58 INFO ContextCleaner: Cleaned accumulator 238
21/02/17 01:29:58 INFO BlockManagerInfo: Removed broadcast_7_piece0 on localhost:34957 in memory (size: 14.2 KB, free: 912.3 MB)
21/02/17 01:29:58 INFO ContextCleaner: Cleaned accumulator 393
21/02/17 01:29:58 INFO ContextCleaner: Cleaned accumulator 397
21/02/17 01:29:58 INFO ContextCleaner: Cleaned accumulator 309
21/02/17 01:29:58 INFO ContextCleaner: Cleaned accumulator 350
21/02/17 01:29:58 INFO BlockManagerInfo: Removed broadcast_16_piece0 on localhost:34957 in memory (size: 25.3 KB, free: 912.3 MB)
21/02/17 01:29:58 INFO ContextCleaner: Cleaned accumulator 443
21/02/17 01:29:58 INFO ContextCleaner: Cleaned accumulator 361
21/02/17 01:29:58 INFO SparkContext: Starting job: parquet at RFormula.scala:421
21/02/17 01:29:58 INFO DAGScheduler: Registering RDD 68 (parquet at RFormula.scala:421)
21/02/17 01:29:58 INFO DAGScheduler: Got job 13 (parquet at RFormula.scala:421) with 1 output partitions
21/02/17 01:29:58 INFO DAGScheduler: Final stage: ResultStage 18 (parquet at RFormula.scala:421)
21/02/17 01:29:58 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 17)
21/02/17 01:29:58 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 17)
21/02/17 01:29:58 INFO DAGScheduler: Submitting ShuffleMapStage 17 (MapPartitionsRDD[68] at parquet at RFormula.scala:421), which has no missing parents
21/02/17 01:29:58 INFO MemoryStore: Block broadcast_18 stored as values in memory (estimated size 4.8 KB, free 912.3 MB)
21/02/17 01:29:58 INFO MemoryStore: Block broadcast_18_piece0 stored as bytes in memory (estimated size 2.9 KB, free 912.3 MB)
21/02/17 01:29:58 INFO BlockManagerInfo: Added broadcast_18_piece0 in memory on localhost:34957 (size: 2.9 KB, free: 912.3 MB)
21/02/17 01:29:58 INFO SparkContext: Created broadcast 18 from broadcast at DAGScheduler.scala:1039
21/02/17 01:29:58 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 17 (MapPartitionsRDD[68] at parquet at RFormula.scala:421) (first 15 tasks are for partitions Vector(0))
21/02/17 01:29:58 INFO TaskSchedulerImpl: Adding task set 17.0 with 1 tasks
21/02/17 01:29:58 INFO TaskSetManager: Starting task 0.0 in stage 17.0 (TID 17, localhost, executor driver, partition 0, PROCESS_LOCAL, 8164 bytes)
21/02/17 01:29:58 INFO Executor: Running task 0.0 in stage 17.0 (TID 17)
21/02/17 01:29:58 INFO Executor: Finished task 0.0 in stage 17.0 (TID 17). 1247 bytes result sent to driver
21/02/17 01:29:58 INFO TaskSetManager: Finished task 0.0 in stage 17.0 (TID 17) in 4 ms on localhost (executor driver) (1/1)
21/02/17 01:29:58 INFO TaskSchedulerImpl: Removed TaskSet 17.0, whose tasks have all completed, from pool 
21/02/17 01:29:58 INFO DAGScheduler: ShuffleMapStage 17 (parquet at RFormula.scala:421) finished in 0.011 s
21/02/17 01:29:58 INFO DAGScheduler: looking for newly runnable stages
21/02/17 01:29:58 INFO DAGScheduler: running: Set()
21/02/17 01:29:58 INFO DAGScheduler: waiting: Set(ResultStage 18)
21/02/17 01:29:58 INFO DAGScheduler: failed: Set()
21/02/17 01:29:58 INFO DAGScheduler: Submitting ResultStage 18 (ShuffledRowRDD[69] at parquet at RFormula.scala:421), which has no missing parents
21/02/17 01:29:58 INFO MemoryStore: Block broadcast_19 stored as values in memory (estimated size 151.0 KB, free 912.1 MB)
21/02/17 01:29:58 INFO MemoryStore: Block broadcast_19_piece0 stored as bytes in memory (estimated size 53.5 KB, free 912.1 MB)
21/02/17 01:29:58 INFO BlockManagerInfo: Added broadcast_19_piece0 in memory on localhost:34957 (size: 53.5 KB, free: 912.2 MB)
21/02/17 01:29:58 INFO SparkContext: Created broadcast 19 from broadcast at DAGScheduler.scala:1039
21/02/17 01:29:58 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 18 (ShuffledRowRDD[69] at parquet at RFormula.scala:421) (first 15 tasks are for partitions Vector(0))
21/02/17 01:29:58 INFO TaskSchedulerImpl: Adding task set 18.0 with 1 tasks
21/02/17 01:29:58 INFO TaskSetManager: Starting task 0.0 in stage 18.0 (TID 18, localhost, executor driver, partition 0, NODE_LOCAL, 7754 bytes)
21/02/17 01:29:58 INFO Executor: Running task 0.0 in stage 18.0 (TID 18)
21/02/17 01:29:58 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
21/02/17 01:29:58 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
21/02/17 01:29:58 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
21/02/17 01:29:58 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
21/02/17 01:29:58 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
21/02/17 01:29:58 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
21/02/17 01:29:58 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:
{
  "type" : "struct",
  "fields" : [ {
    "name" : "label",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "terms",
    "type" : {
      "type" : "array",
      "elementType" : {
        "type" : "array",
        "elementType" : "string",
        "containsNull" : true
      },
      "containsNull" : true
    },
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "hasIntercept",
    "type" : "boolean",
    "nullable" : false,
    "metadata" : { }
  } ]
}
and corresponding Parquet message type:
message spark_schema {
  optional binary label (UTF8);
  optional group terms (LIST) {
    repeated group list {
      optional group element (LIST) {
        repeated group list {
          optional binary element (UTF8);
        }
      }
    }
  }
  required boolean hasIntercept;
}

       
21/02/17 01:29:58 INFO CodecPool: Got brand-new compressor [.snappy]
21/02/17 01:29:59 INFO FileOutputCommitter: Saved output of task 'attempt_20210217012958_0018_m_000000_0' to file:/tmp/Rtmpf0aMkz/file21d2743d02267/stages/0_r_formula__4a78c67a_b2d6_47f3_b339_f6bd796b0af6/data/_temporary/0/task_20210217012958_0018_m_000000
21/02/17 01:29:59 INFO SparkHadoopMapRedUtil: attempt_20210217012958_0018_m_000000_0: Committed
21/02/17 01:29:59 INFO Executor: Finished task 0.0 in stage 18.0 (TID 18). 2351 bytes result sent to driver
21/02/17 01:29:59 INFO TaskSetManager: Finished task 0.0 in stage 18.0 (TID 18) in 182 ms on localhost (executor driver) (1/1)
21/02/17 01:29:59 INFO TaskSchedulerImpl: Removed TaskSet 18.0, whose tasks have all completed, from pool 
21/02/17 01:29:59 INFO DAGScheduler: ResultStage 18 (parquet at RFormula.scala:421) finished in 0.199 s
21/02/17 01:29:59 INFO DAGScheduler: Job 13 finished: parquet at RFormula.scala:421, took 0.212807 s
21/02/17 01:29:59 INFO FileFormatWriter: Job null committed.
21/02/17 01:29:59 INFO FileFormatWriter: Finished processing stats for job null.
21/02/17 01:29:59 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
21/02/17 01:29:59 INFO SparkContext: Starting job: runJob at SparkHadoopWriter.scala:78
21/02/17 01:29:59 INFO DAGScheduler: Got job 14 (runJob at SparkHadoopWriter.scala:78) with 1 output partitions
21/02/17 01:29:59 INFO DAGScheduler: Final stage: ResultStage 19 (runJob at SparkHadoopWriter.scala:78)
21/02/17 01:29:59 INFO DAGScheduler: Parents of final stage: List()
21/02/17 01:29:59 INFO DAGScheduler: Missing parents: List()
21/02/17 01:29:59 INFO DAGScheduler: Submitting ResultStage 19 (MapPartitionsRDD[72] at saveAsTextFile at ReadWrite.scala:283), which has no missing parents
21/02/17 01:29:59 INFO MemoryStore: Block broadcast_20 stored as values in memory (estimated size 71.1 KB, free 912.0 MB)
21/02/17 01:29:59 INFO MemoryStore: Block broadcast_20_piece0 stored as bytes in memory (estimated size 25.5 KB, free 912.0 MB)
21/02/17 01:29:59 INFO BlockManagerInfo: Added broadcast_20_piece0 in memory on localhost:34957 (size: 25.5 KB, free: 912.2 MB)
21/02/17 01:29:59 INFO SparkContext: Created broadcast 20 from broadcast at DAGScheduler.scala:1039
21/02/17 01:29:59 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 19 (MapPartitionsRDD[72] at saveAsTextFile at ReadWrite.scala:283) (first 15 tasks are for partitions Vector(0))
21/02/17 01:29:59 INFO TaskSchedulerImpl: Adding task set 19.0 with 1 tasks
21/02/17 01:29:59 INFO TaskSetManager: Starting task 0.0 in stage 19.0 (TID 19, localhost, executor driver, partition 0, PROCESS_LOCAL, 8147 bytes)
21/02/17 01:29:59 INFO Executor: Running task 0.0 in stage 19.0 (TID 19)
21/02/17 01:29:59 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
21/02/17 01:29:59 INFO FileOutputCommitter: Saved output of task 'attempt_20210217012959_0072_m_000000_0' to file:/tmp/Rtmpf0aMkz/file21d2743d02267/stages/0_r_formula__4a78c67a_b2d6_47f3_b339_f6bd796b0af6/pipelineModel/metadata/_temporary/0/task_20210217012959_0072_m_000000
21/02/17 01:29:59 INFO SparkHadoopMapRedUtil: attempt_20210217012959_0072_m_000000_0: Committed
21/02/17 01:29:59 INFO Executor: Finished task 0.0 in stage 19.0 (TID 19). 1029 bytes result sent to driver
21/02/17 01:29:59 INFO TaskSetManager: Finished task 0.0 in stage 19.0 (TID 19) in 16 ms on localhost (executor driver) (1/1)
21/02/17 01:29:59 INFO TaskSchedulerImpl: Removed TaskSet 19.0, whose tasks have all completed, from pool 
21/02/17 01:29:59 INFO DAGScheduler: ResultStage 19 (runJob at SparkHadoopWriter.scala:78) finished in 0.033 s
21/02/17 01:29:59 INFO DAGScheduler: Job 14 finished: runJob at SparkHadoopWriter.scala:78, took 0.033942 s
21/02/17 01:29:59 INFO SparkHadoopWriter: Job job_20210217012959_0072 committed.
21/02/17 01:29:59 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
21/02/17 01:29:59 INFO SparkContext: Starting job: runJob at SparkHadoopWriter.scala:78
21/02/17 01:29:59 INFO DAGScheduler: Got job 15 (runJob at SparkHadoopWriter.scala:78) with 1 output partitions
21/02/17 01:29:59 INFO DAGScheduler: Final stage: ResultStage 20 (runJob at SparkHadoopWriter.scala:78)
21/02/17 01:29:59 INFO DAGScheduler: Parents of final stage: List()
21/02/17 01:29:59 INFO DAGScheduler: Missing parents: List()
21/02/17 01:29:59 INFO DAGScheduler: Submitting ResultStage 20 (MapPartitionsRDD[74] at saveAsTextFile at ReadWrite.scala:283), which has no missing parents
21/02/17 01:29:59 INFO MemoryStore: Block broadcast_21 stored as values in memory (estimated size 71.3 KB, free 911.9 MB)
21/02/17 01:29:59 INFO MemoryStore: Block broadcast_21_piece0 stored as bytes in memory (estimated size 25.5 KB, free 911.9 MB)
21/02/17 01:29:59 INFO BlockManagerInfo: Added broadcast_21_piece0 in memory on localhost:34957 (size: 25.5 KB, free: 912.2 MB)
21/02/17 01:29:59 INFO SparkContext: Created broadcast 21 from broadcast at DAGScheduler.scala:1039
21/02/17 01:29:59 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 20 (MapPartitionsRDD[74] at saveAsTextFile at ReadWrite.scala:283) (first 15 tasks are for partitions Vector(0))
21/02/17 01:29:59 INFO TaskSchedulerImpl: Adding task set 20.0 with 1 tasks
21/02/17 01:29:59 INFO TaskSetManager: Starting task 0.0 in stage 20.0 (TID 20, localhost, executor driver, partition 0, PROCESS_LOCAL, 8097 bytes)
21/02/17 01:29:59 INFO Executor: Running task 0.0 in stage 20.0 (TID 20)
21/02/17 01:29:59 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
21/02/17 01:29:59 INFO FileOutputCommitter: Saved output of task 'attempt_20210217012959_0074_m_000000_0' to file:/tmp/Rtmpf0aMkz/file21d2743d02267/stages/0_r_formula__4a78c67a_b2d6_47f3_b339_f6bd796b0af6/pipelineModel/stages/0_r_formula__4a78c67a_b2d6_47f3_b339_f6bd796b0af6/metadata/_temporary/0/task_20210217012959_0074_m_000000
21/02/17 01:29:59 INFO SparkHadoopMapRedUtil: attempt_20210217012959_0074_m_000000_0: Committed
21/02/17 01:29:59 INFO Executor: Finished task 0.0 in stage 20.0 (TID 20). 1029 bytes result sent to driver
21/02/17 01:29:59 INFO TaskSetManager: Finished task 0.0 in stage 20.0 (TID 20) in 16 ms on localhost (executor driver) (1/1)
21/02/17 01:29:59 INFO TaskSchedulerImpl: Removed TaskSet 20.0, whose tasks have all completed, from pool 
21/02/17 01:29:59 INFO DAGScheduler: ResultStage 20 (runJob at SparkHadoopWriter.scala:78) finished in 0.029 s
21/02/17 01:29:59 INFO DAGScheduler: Job 15 finished: runJob at SparkHadoopWriter.scala:78, took 0.031165 s
21/02/17 01:29:59 INFO SparkHadoopWriter: Job job_20210217012959_0074 committed.
21/02/17 01:29:59 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
21/02/17 01:29:59 INFO SparkContext: Starting job: runJob at SparkHadoopWriter.scala:78
21/02/17 01:29:59 INFO DAGScheduler: Got job 16 (runJob at SparkHadoopWriter.scala:78) with 1 output partitions
21/02/17 01:29:59 INFO DAGScheduler: Final stage: ResultStage 21 (runJob at SparkHadoopWriter.scala:78)
21/02/17 01:29:59 INFO DAGScheduler: Parents of final stage: List()
21/02/17 01:29:59 INFO DAGScheduler: Missing parents: List()
21/02/17 01:29:59 INFO DAGScheduler: Submitting ResultStage 21 (MapPartitionsRDD[76] at saveAsTextFile at ReadWrite.scala:283), which has no missing parents
21/02/17 01:29:59 INFO MemoryStore: Block broadcast_22 stored as values in memory (estimated size 71.2 KB, free 911.8 MB)
21/02/17 01:29:59 INFO MemoryStore: Block broadcast_22_piece0 stored as bytes in memory (estimated size 25.6 KB, free 911.8 MB)
21/02/17 01:29:59 INFO BlockManagerInfo: Added broadcast_22_piece0 in memory on localhost:34957 (size: 25.6 KB, free: 912.2 MB)
21/02/17 01:29:59 INFO SparkContext: Created broadcast 22 from broadcast at DAGScheduler.scala:1039
21/02/17 01:29:59 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 21 (MapPartitionsRDD[76] at saveAsTextFile at ReadWrite.scala:283) (first 15 tasks are for partitions Vector(0))
21/02/17 01:29:59 INFO TaskSchedulerImpl: Adding task set 21.0 with 1 tasks
21/02/17 01:29:59 INFO TaskSetManager: Starting task 0.0 in stage 21.0 (TID 21, localhost, executor driver, partition 0, PROCESS_LOCAL, 8024 bytes)
21/02/17 01:29:59 INFO Executor: Running task 0.0 in stage 21.0 (TID 21)
21/02/17 01:29:59 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
21/02/17 01:29:59 INFO FileOutputCommitter: Saved output of task 'attempt_20210217012959_0076_m_000000_0' to file:/tmp/Rtmpf0aMkz/file21d2743d02267/stages/0_r_formula__4a78c67a_b2d6_47f3_b339_f6bd796b0af6/pipelineModel/stages/1_vectorAttrRewriter_7786f50e1861/metadata/_temporary/0/task_20210217012959_0076_m_000000
21/02/17 01:29:59 INFO SparkHadoopMapRedUtil: attempt_20210217012959_0076_m_000000_0: Committed
21/02/17 01:29:59 INFO Executor: Finished task 0.0 in stage 21.0 (TID 21). 1029 bytes result sent to driver
21/02/17 01:29:59 INFO TaskSetManager: Finished task 0.0 in stage 21.0 (TID 21) in 11 ms on localhost (executor driver) (1/1)
21/02/17 01:29:59 INFO TaskSchedulerImpl: Removed TaskSet 21.0, whose tasks have all completed, from pool 
21/02/17 01:29:59 INFO DAGScheduler: ResultStage 21 (runJob at SparkHadoopWriter.scala:78) finished in 0.020 s
21/02/17 01:29:59 INFO DAGScheduler: Job 16 finished: runJob at SparkHadoopWriter.scala:78, took 0.022047 s
21/02/17 01:29:59 INFO SparkHadoopWriter: Job job_20210217012959_0076 committed.
21/02/17 01:29:59 INFO ParquetFileFormat: Using default output committer for Parquet: org.apache.parquet.hadoop.ParquetOutputCommitter
21/02/17 01:29:59 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
21/02/17 01:29:59 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
21/02/17 01:29:59 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
21/02/17 01:29:59 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
21/02/17 01:29:59 INFO CodeGenerator: Code generated in 10.501046 ms
21/02/17 01:29:59 INFO SparkContext: Starting job: parquet at RFormula.scala:586
21/02/17 01:29:59 INFO DAGScheduler: Registering RDD 79 (parquet at RFormula.scala:586)
21/02/17 01:29:59 INFO DAGScheduler: Got job 17 (parquet at RFormula.scala:586) with 1 output partitions
21/02/17 01:29:59 INFO DAGScheduler: Final stage: ResultStage 23 (parquet at RFormula.scala:586)
21/02/17 01:29:59 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 22)
21/02/17 01:29:59 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 22)
21/02/17 01:29:59 INFO DAGScheduler: Submitting ShuffleMapStage 22 (MapPartitionsRDD[79] at parquet at RFormula.scala:586), which has no missing parents
21/02/17 01:29:59 INFO MemoryStore: Block broadcast_23 stored as values in memory (estimated size 4.8 KB, free 911.8 MB)
21/02/17 01:29:59 INFO MemoryStore: Block broadcast_23_piece0 stored as bytes in memory (estimated size 2.8 KB, free 911.8 MB)
21/02/17 01:29:59 INFO BlockManagerInfo: Added broadcast_23_piece0 in memory on localhost:34957 (size: 2.8 KB, free: 912.2 MB)
21/02/17 01:29:59 INFO SparkContext: Created broadcast 23 from broadcast at DAGScheduler.scala:1039
21/02/17 01:29:59 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 22 (MapPartitionsRDD[79] at parquet at RFormula.scala:586) (first 15 tasks are for partitions Vector(0))
21/02/17 01:29:59 INFO TaskSchedulerImpl: Adding task set 22.0 with 1 tasks
21/02/17 01:29:59 INFO TaskSetManager: Starting task 0.0 in stage 22.0 (TID 22, localhost, executor driver, partition 0, PROCESS_LOCAL, 8060 bytes)
21/02/17 01:29:59 INFO Executor: Running task 0.0 in stage 22.0 (TID 22)
21/02/17 01:29:59 INFO Executor: Finished task 0.0 in stage 22.0 (TID 22). 1247 bytes result sent to driver
21/02/17 01:29:59 INFO TaskSetManager: Finished task 0.0 in stage 22.0 (TID 22) in 4 ms on localhost (executor driver) (1/1)
21/02/17 01:29:59 INFO TaskSchedulerImpl: Removed TaskSet 22.0, whose tasks have all completed, from pool 
21/02/17 01:29:59 INFO DAGScheduler: ShuffleMapStage 22 (parquet at RFormula.scala:586) finished in 0.009 s
21/02/17 01:29:59 INFO DAGScheduler: looking for newly runnable stages
21/02/17 01:29:59 INFO DAGScheduler: running: Set()
21/02/17 01:29:59 INFO DAGScheduler: waiting: Set(ResultStage 23)
21/02/17 01:29:59 INFO DAGScheduler: failed: Set()
21/02/17 01:29:59 INFO DAGScheduler: Submitting ResultStage 23 (ShuffledRowRDD[80] at parquet at RFormula.scala:586), which has no missing parents
21/02/17 01:29:59 INFO MemoryStore: Block broadcast_24 stored as values in memory (estimated size 151.0 KB, free 911.6 MB)
21/02/17 01:29:59 INFO MemoryStore: Block broadcast_24_piece0 stored as bytes in memory (estimated size 53.5 KB, free 911.6 MB)
21/02/17 01:29:59 INFO BlockManagerInfo: Added broadcast_24_piece0 in memory on localhost:34957 (size: 53.5 KB, free: 912.1 MB)
21/02/17 01:29:59 INFO SparkContext: Created broadcast 24 from broadcast at DAGScheduler.scala:1039
21/02/17 01:29:59 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 23 (ShuffledRowRDD[80] at parquet at RFormula.scala:586) (first 15 tasks are for partitions Vector(0))
21/02/17 01:29:59 INFO TaskSchedulerImpl: Adding task set 23.0 with 1 tasks
21/02/17 01:29:59 INFO TaskSetManager: Starting task 0.0 in stage 23.0 (TID 23, localhost, executor driver, partition 0, NODE_LOCAL, 7754 bytes)
21/02/17 01:29:59 INFO Executor: Running task 0.0 in stage 23.0 (TID 23)
21/02/17 01:29:59 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
21/02/17 01:29:59 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
21/02/17 01:29:59 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
21/02/17 01:29:59 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
21/02/17 01:29:59 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
21/02/17 01:29:59 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
21/02/17 01:29:59 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:
{
  "type" : "struct",
  "fields" : [ {
    "name" : "vectorCol",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "prefixesToRewrite",
    "type" : {
      "type" : "map",
      "keyType" : "string",
      "valueType" : "string",
      "valueContainsNull" : true
    },
    "nullable" : true,
    "metadata" : { }
  } ]
}
and corresponding Parquet message type:
message spark_schema {
  optional binary vectorCol (UTF8);
  optional group prefixesToRewrite (MAP) {
    repeated group key_value {
      required binary key (UTF8);
      optional binary value (UTF8);
    }
  }
}

       
21/02/17 01:29:59 INFO FileOutputCommitter: Saved output of task 'attempt_20210217012959_0023_m_000000_0' to file:/tmp/Rtmpf0aMkz/file21d2743d02267/stages/0_r_formula__4a78c67a_b2d6_47f3_b339_f6bd796b0af6/pipelineModel/stages/1_vectorAttrRewriter_7786f50e1861/data/_temporary/0/task_20210217012959_0023_m_000000
21/02/17 01:29:59 INFO SparkHadoopMapRedUtil: attempt_20210217012959_0023_m_000000_0: Committed
21/02/17 01:29:59 INFO Executor: Finished task 0.0 in stage 23.0 (TID 23). 2308 bytes result sent to driver
21/02/17 01:29:59 INFO TaskSetManager: Finished task 0.0 in stage 23.0 (TID 23) in 32 ms on localhost (executor driver) (1/1)
21/02/17 01:29:59 INFO TaskSchedulerImpl: Removed TaskSet 23.0, whose tasks have all completed, from pool 
21/02/17 01:29:59 INFO DAGScheduler: ResultStage 23 (parquet at RFormula.scala:586) finished in 0.053 s
21/02/17 01:29:59 INFO DAGScheduler: Job 17 finished: parquet at RFormula.scala:586, took 0.065008 s
21/02/17 01:29:59 INFO FileFormatWriter: Job null committed.
21/02/17 01:29:59 INFO FileFormatWriter: Finished processing stats for job null.
21/02/17 01:29:59 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
21/02/17 01:29:59 INFO SparkContext: Starting job: runJob at SparkHadoopWriter.scala:78
21/02/17 01:29:59 INFO DAGScheduler: Got job 18 (runJob at SparkHadoopWriter.scala:78) with 1 output partitions
21/02/17 01:29:59 INFO DAGScheduler: Final stage: ResultStage 24 (runJob at SparkHadoopWriter.scala:78)
21/02/17 01:29:59 INFO DAGScheduler: Parents of final stage: List()
21/02/17 01:29:59 INFO DAGScheduler: Missing parents: List()
21/02/17 01:29:59 INFO DAGScheduler: Submitting ResultStage 24 (MapPartitionsRDD[83] at saveAsTextFile at ReadWrite.scala:283), which has no missing parents
21/02/17 01:29:59 INFO MemoryStore: Block broadcast_25 stored as values in memory (estimated size 71.2 KB, free 911.5 MB)
21/02/17 01:29:59 INFO MemoryStore: Block broadcast_25_piece0 stored as bytes in memory (estimated size 25.6 KB, free 911.5 MB)
21/02/17 01:29:59 INFO BlockManagerInfo: Added broadcast_25_piece0 in memory on localhost:34957 (size: 25.6 KB, free: 912.1 MB)
21/02/17 01:29:59 INFO SparkContext: Created broadcast 25 from broadcast at DAGScheduler.scala:1039
21/02/17 01:29:59 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 24 (MapPartitionsRDD[83] at saveAsTextFile at ReadWrite.scala:283) (first 15 tasks are for partitions Vector(0))
21/02/17 01:29:59 INFO TaskSchedulerImpl: Adding task set 24.0 with 1 tasks
21/02/17 01:29:59 INFO TaskSetManager: Starting task 0.0 in stage 24.0 (TID 24, localhost, executor driver, partition 0, PROCESS_LOCAL, 8007 bytes)
21/02/17 01:29:59 INFO Executor: Running task 0.0 in stage 24.0 (TID 24)
21/02/17 01:29:59 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
21/02/17 01:29:59 INFO FileOutputCommitter: Saved output of task 'attempt_20210217012959_0083_m_000000_0' to file:/tmp/Rtmpf0aMkz/file21d2743d02267/stages/0_r_formula__4a78c67a_b2d6_47f3_b339_f6bd796b0af6/pipelineModel/stages/2_columnPruner_c4e56117ce30/metadata/_temporary/0/task_20210217012959_0083_m_000000
21/02/17 01:29:59 INFO SparkHadoopMapRedUtil: attempt_20210217012959_0083_m_000000_0: Committed
21/02/17 01:29:59 INFO Executor: Finished task 0.0 in stage 24.0 (TID 24). 1029 bytes result sent to driver
21/02/17 01:29:59 INFO TaskSetManager: Finished task 0.0 in stage 24.0 (TID 24) in 9 ms on localhost (executor driver) (1/1)
21/02/17 01:29:59 INFO TaskSchedulerImpl: Removed TaskSet 24.0, whose tasks have all completed, from pool 
21/02/17 01:29:59 INFO DAGScheduler: ResultStage 24 (runJob at SparkHadoopWriter.scala:78) finished in 0.019 s
21/02/17 01:29:59 INFO DAGScheduler: Job 18 finished: runJob at SparkHadoopWriter.scala:78, took 0.020839 s
21/02/17 01:29:59 INFO SparkHadoopWriter: Job job_20210217012959_0083 committed.
21/02/17 01:29:59 INFO ParquetFileFormat: Using default output committer for Parquet: org.apache.parquet.hadoop.ParquetOutputCommitter
21/02/17 01:29:59 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
21/02/17 01:29:59 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
21/02/17 01:29:59 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
21/02/17 01:29:59 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
21/02/17 01:29:59 INFO CodeGenerator: Code generated in 5.386086 ms
21/02/17 01:29:59 INFO SparkContext: Starting job: parquet at RFormula.scala:495
21/02/17 01:29:59 INFO DAGScheduler: Registering RDD 86 (parquet at RFormula.scala:495)
21/02/17 01:29:59 INFO DAGScheduler: Got job 19 (parquet at RFormula.scala:495) with 1 output partitions
21/02/17 01:29:59 INFO DAGScheduler: Final stage: ResultStage 26 (parquet at RFormula.scala:495)
21/02/17 01:29:59 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 25)
21/02/17 01:29:59 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 25)
21/02/17 01:29:59 INFO DAGScheduler: Submitting ShuffleMapStage 25 (MapPartitionsRDD[86] at parquet at RFormula.scala:495), which has no missing parents
21/02/17 01:29:59 INFO MemoryStore: Block broadcast_26 stored as values in memory (estimated size 4.7 KB, free 911.5 MB)
21/02/17 01:29:59 INFO MemoryStore: Block broadcast_26_piece0 stored as bytes in memory (estimated size 2.8 KB, free 911.5 MB)
21/02/17 01:29:59 INFO BlockManagerInfo: Added broadcast_26_piece0 in memory on localhost:34957 (size: 2.8 KB, free: 912.1 MB)
21/02/17 01:29:59 INFO SparkContext: Created broadcast 26 from broadcast at DAGScheduler.scala:1039
21/02/17 01:29:59 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 25 (MapPartitionsRDD[86] at parquet at RFormula.scala:495) (first 15 tasks are for partitions Vector(0))
21/02/17 01:29:59 INFO TaskSchedulerImpl: Adding task set 25.0 with 1 tasks
21/02/17 01:29:59 INFO TaskSetManager: Starting task 0.0 in stage 25.0 (TID 25, localhost, executor driver, partition 0, PROCESS_LOCAL, 8028 bytes)
21/02/17 01:29:59 INFO Executor: Running task 0.0 in stage 25.0 (TID 25)
21/02/17 01:29:59 INFO Executor: Finished task 0.0 in stage 25.0 (TID 25). 1204 bytes result sent to driver
21/02/17 01:29:59 INFO TaskSetManager: Finished task 0.0 in stage 25.0 (TID 25) in 4 ms on localhost (executor driver) (1/1)
21/02/17 01:29:59 INFO TaskSchedulerImpl: Removed TaskSet 25.0, whose tasks have all completed, from pool 
21/02/17 01:29:59 INFO DAGScheduler: ShuffleMapStage 25 (parquet at RFormula.scala:495) finished in 0.008 s
21/02/17 01:29:59 INFO DAGScheduler: looking for newly runnable stages
21/02/17 01:29:59 INFO DAGScheduler: running: Set()
21/02/17 01:29:59 INFO DAGScheduler: waiting: Set(ResultStage 26)
21/02/17 01:29:59 INFO DAGScheduler: failed: Set()
21/02/17 01:29:59 INFO DAGScheduler: Submitting ResultStage 26 (ShuffledRowRDD[87] at parquet at RFormula.scala:495), which has no missing parents
21/02/17 01:29:59 INFO MemoryStore: Block broadcast_27 stored as values in memory (estimated size 150.8 KB, free 911.3 MB)
21/02/17 01:29:59 INFO MemoryStore: Block broadcast_27_piece0 stored as bytes in memory (estimated size 53.4 KB, free 911.3 MB)
21/02/17 01:29:59 INFO BlockManagerInfo: Added broadcast_27_piece0 in memory on localhost:34957 (size: 53.4 KB, free: 912.0 MB)
21/02/17 01:29:59 INFO SparkContext: Created broadcast 27 from broadcast at DAGScheduler.scala:1039
21/02/17 01:29:59 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 26 (ShuffledRowRDD[87] at parquet at RFormula.scala:495) (first 15 tasks are for partitions Vector(0))
21/02/17 01:29:59 INFO TaskSchedulerImpl: Adding task set 26.0 with 1 tasks
21/02/17 01:29:59 INFO TaskSetManager: Starting task 0.0 in stage 26.0 (TID 26, localhost, executor driver, partition 0, NODE_LOCAL, 7754 bytes)
21/02/17 01:29:59 INFO Executor: Running task 0.0 in stage 26.0 (TID 26)
21/02/17 01:29:59 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
21/02/17 01:29:59 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
21/02/17 01:29:59 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
21/02/17 01:29:59 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
21/02/17 01:29:59 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
21/02/17 01:29:59 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
21/02/17 01:29:59 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:
{
  "type" : "struct",
  "fields" : [ {
    "name" : "columnsToPrune",
    "type" : {
      "type" : "array",
      "elementType" : "string",
      "containsNull" : true
    },
    "nullable" : true,
    "metadata" : { }
  } ]
}
and corresponding Parquet message type:
message spark_schema {
  optional group columnsToPrune (LIST) {
    repeated group list {
      optional binary element (UTF8);
    }
  }
}

       
21/02/17 01:29:59 INFO FileOutputCommitter: Saved output of task 'attempt_20210217012959_0026_m_000000_0' to file:/tmp/Rtmpf0aMkz/file21d2743d02267/stages/0_r_formula__4a78c67a_b2d6_47f3_b339_f6bd796b0af6/pipelineModel/stages/2_columnPruner_c4e56117ce30/data/_temporary/0/task_20210217012959_0026_m_000000
21/02/17 01:29:59 INFO SparkHadoopMapRedUtil: attempt_20210217012959_0026_m_000000_0: Committed
21/02/17 01:29:59 INFO Executor: Finished task 0.0 in stage 26.0 (TID 26). 2308 bytes result sent to driver
21/02/17 01:29:59 INFO TaskSetManager: Finished task 0.0 in stage 26.0 (TID 26) in 16 ms on localhost (executor driver) (1/1)
21/02/17 01:29:59 INFO TaskSchedulerImpl: Removed TaskSet 26.0, whose tasks have all completed, from pool 
21/02/17 01:29:59 INFO DAGScheduler: ResultStage 26 (parquet at RFormula.scala:495) finished in 0.029 s
21/02/17 01:29:59 INFO DAGScheduler: Job 19 finished: parquet at RFormula.scala:495, took 0.040409 s
21/02/17 01:29:59 INFO FileFormatWriter: Job null committed.
21/02/17 01:29:59 INFO FileFormatWriter: Finished processing stats for job null.
21/02/17 01:30:01 INFO SparkContext: Invoking stop() from shutdown hook
21/02/17 01:30:01 INFO SparkUI: Stopped Spark web UI at http://localhost:4040
21/02/17 01:30:01 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!
21/02/17 01:30:01 INFO MemoryStore: MemoryStore cleared
21/02/17 01:30:01 INFO BlockManager: BlockManager stopped
21/02/17 01:30:01 INFO BlockManagerMaster: BlockManagerMaster stopped
21/02/17 01:30:01 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!
21/02/17 01:30:01 INFO SparkContext: Successfully stopped SparkContext
21/02/17 01:30:01 INFO ShutdownHookManager: Shutdown hook called
21/02/17 01:30:01 INFO ShutdownHookManager: Deleting directory /tmp/spark-7d5a3c76-94d0-4892-a5db-ceb513008a9e
21/02/17 01:30:01 INFO ShutdownHookManager: Deleting directory /tmp/spark-d82bde2b-f1c1-4b27-95f7-1327e1081667
21/02/17 01:33:57 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
21/02/17 01:33:58 INFO SecurityManager: Changing view acls to: yitaoli
21/02/17 01:33:58 INFO SecurityManager: Changing modify acls to: yitaoli
21/02/17 01:33:58 INFO SecurityManager: Changing view acls groups to: 
21/02/17 01:33:58 INFO SecurityManager: Changing modify acls groups to: 
21/02/17 01:33:58 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(yitaoli); groups with view permissions: Set(); users  with modify permissions: Set(yitaoli); groups with modify permissions: Set()
21/02/17 01:33:58 INFO HiveConf: Found configuration file file:/home/yitaoli/spark/spark-3.0.0-bin-hadoop3.2/conf/hive-site.xml
21/02/17 01:33:58 INFO SparkContext: Running Spark version 3.0.0
21/02/17 01:33:58 INFO ResourceUtils: ==============================================================
21/02/17 01:33:58 INFO ResourceUtils: Resources for spark.driver:

21/02/17 01:33:58 INFO ResourceUtils: ==============================================================
21/02/17 01:33:58 INFO SparkContext: Submitted application: sparklyr
21/02/17 01:33:58 INFO SecurityManager: Changing view acls to: yitaoli
21/02/17 01:33:58 INFO SecurityManager: Changing modify acls to: yitaoli
21/02/17 01:33:58 INFO SecurityManager: Changing view acls groups to: 
21/02/17 01:33:58 INFO SecurityManager: Changing modify acls groups to: 
21/02/17 01:33:58 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(yitaoli); groups with view permissions: Set(); users  with modify permissions: Set(yitaoli); groups with modify permissions: Set()
21/02/17 01:33:58 INFO Utils: Successfully started service 'sparkDriver' on port 37753.
21/02/17 01:33:58 INFO SparkEnv: Registering MapOutputTracker
21/02/17 01:33:58 INFO SparkEnv: Registering BlockManagerMaster
21/02/17 01:33:58 INFO BlockManagerMasterEndpoint: Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
21/02/17 01:33:58 INFO BlockManagerMasterEndpoint: BlockManagerMasterEndpoint up
21/02/17 01:33:58 INFO SparkEnv: Registering BlockManagerMasterHeartbeat
21/02/17 01:33:58 INFO DiskBlockManager: Created local directory at /tmp/blockmgr-b8210247-2bc9-40a9-b71a-464861749d7c
21/02/17 01:33:59 INFO MemoryStore: MemoryStore started with capacity 912.3 MiB
21/02/17 01:33:59 INFO SparkEnv: Registering OutputCommitCoordinator
21/02/17 01:33:59 INFO Utils: Successfully started service 'SparkUI' on port 4040.
21/02/17 01:33:59 INFO SparkUI: Bound SparkUI to 127.0.0.1, and started at http://localhost:4040
21/02/17 01:33:59 INFO SparkContext: Added JAR file:///home/yitaoli/.ivy2/jars/ml.dmlc_xgboost4j-spark_2.12-1.3.1.jar at spark://localhost:37753/jars/ml.dmlc_xgboost4j-spark_2.12-1.3.1.jar with timestamp 1613525639278
21/02/17 01:33:59 INFO SparkContext: Added JAR file:///home/yitaoli/.ivy2/jars/org.json4s_json4s-jackson_2.12-3.6.10.jar at spark://localhost:37753/jars/org.json4s_json4s-jackson_2.12-3.6.10.jar with timestamp 1613525639278
21/02/17 01:33:59 INFO SparkContext: Added JAR file:///home/yitaoli/.ivy2/jars/ml.dmlc_xgboost4j_2.12-1.3.1.jar at spark://localhost:37753/jars/ml.dmlc_xgboost4j_2.12-1.3.1.jar with timestamp 1613525639278
21/02/17 01:33:59 INFO SparkContext: Added JAR file:///home/yitaoli/.ivy2/jars/com.esotericsoftware_kryo-4.0.2.jar at spark://localhost:37753/jars/com.esotericsoftware_kryo-4.0.2.jar with timestamp 1613525639278
21/02/17 01:33:59 INFO SparkContext: Added JAR file:///home/yitaoli/.ivy2/jars/org.scala-lang_scala-compiler-2.12.8.jar at spark://localhost:37753/jars/org.scala-lang_scala-compiler-2.12.8.jar with timestamp 1613525639278
21/02/17 01:33:59 INFO SparkContext: Added JAR file:///home/yitaoli/.ivy2/jars/org.scala-lang_scala-reflect-2.12.8.jar at spark://localhost:37753/jars/org.scala-lang_scala-reflect-2.12.8.jar with timestamp 1613525639279
21/02/17 01:33:59 INFO SparkContext: Added JAR file:///home/yitaoli/.ivy2/jars/commons-logging_commons-logging-1.2.jar at spark://localhost:37753/jars/commons-logging_commons-logging-1.2.jar with timestamp 1613525639279
21/02/17 01:33:59 INFO SparkContext: Added JAR file:///home/yitaoli/.ivy2/jars/com.typesafe.akka_akka-actor_2.12-2.5.23.jar at spark://localhost:37753/jars/com.typesafe.akka_akka-actor_2.12-2.5.23.jar with timestamp 1613525639279
21/02/17 01:33:59 INFO SparkContext: Added JAR file:///home/yitaoli/.ivy2/jars/org.scalatest_scalatest_2.12-3.0.5.jar at spark://localhost:37753/jars/org.scalatest_scalatest_2.12-3.0.5.jar with timestamp 1613525639279
21/02/17 01:33:59 INFO SparkContext: Added JAR file:///home/yitaoli/.ivy2/jars/com.typesafe_config-1.3.3.jar at spark://localhost:37753/jars/com.typesafe_config-1.3.3.jar with timestamp 1613525639279
21/02/17 01:33:59 INFO SparkContext: Added JAR file:///home/yitaoli/.ivy2/jars/org.scala-lang.modules_scala-java8-compat_2.12-0.8.0.jar at spark://localhost:37753/jars/org.scala-lang.modules_scala-java8-compat_2.12-0.8.0.jar with timestamp 1613525639279
21/02/17 01:33:59 INFO SparkContext: Added JAR file:///home/yitaoli/.ivy2/jars/org.scalactic_scalactic_2.12-3.0.5.jar at spark://localhost:37753/jars/org.scalactic_scalactic_2.12-3.0.5.jar with timestamp 1613525639279
21/02/17 01:33:59 INFO SparkContext: Added JAR file:///home/yitaoli/.ivy2/jars/org.scala-lang.modules_scala-xml_2.12-1.0.6.jar at spark://localhost:37753/jars/org.scala-lang.modules_scala-xml_2.12-1.0.6.jar with timestamp 1613525639279
21/02/17 01:33:59 INFO SparkContext: Added JAR file:///home/yitaoli/.ivy2/jars/com.esotericsoftware_reflectasm-1.11.3.jar at spark://localhost:37753/jars/com.esotericsoftware_reflectasm-1.11.3.jar with timestamp 1613525639279
21/02/17 01:33:59 INFO SparkContext: Added JAR file:///home/yitaoli/.ivy2/jars/com.esotericsoftware_minlog-1.3.0.jar at spark://localhost:37753/jars/com.esotericsoftware_minlog-1.3.0.jar with timestamp 1613525639279
21/02/17 01:33:59 INFO SparkContext: Added JAR file:///home/yitaoli/.ivy2/jars/org.objenesis_objenesis-2.5.1.jar at spark://localhost:37753/jars/org.objenesis_objenesis-2.5.1.jar with timestamp 1613525639279
21/02/17 01:33:59 INFO SparkContext: Added JAR file:///home/yitaoli/.ivy2/jars/org.ow2.asm_asm-5.0.4.jar at spark://localhost:37753/jars/org.ow2.asm_asm-5.0.4.jar with timestamp 1613525639279
21/02/17 01:33:59 INFO SparkContext: Added JAR file:///home/yitaoli/.ivy2/jars/org.json4s_json4s-core_2.12-3.6.10.jar at spark://localhost:37753/jars/org.json4s_json4s-core_2.12-3.6.10.jar with timestamp 1613525639280
21/02/17 01:33:59 INFO SparkContext: Added JAR file:///home/yitaoli/.ivy2/jars/com.fasterxml.jackson.core_jackson-databind-2.9.10.6.jar at spark://localhost:37753/jars/com.fasterxml.jackson.core_jackson-databind-2.9.10.6.jar with timestamp 1613525639280
21/02/17 01:33:59 INFO SparkContext: Added JAR file:///home/yitaoli/.ivy2/jars/org.json4s_json4s-ast_2.12-3.6.10.jar at spark://localhost:37753/jars/org.json4s_json4s-ast_2.12-3.6.10.jar with timestamp 1613525639280
21/02/17 01:33:59 INFO SparkContext: Added JAR file:///home/yitaoli/.ivy2/jars/org.json4s_json4s-scalap_2.12-3.6.10.jar at spark://localhost:37753/jars/org.json4s_json4s-scalap_2.12-3.6.10.jar with timestamp 1613525639280
21/02/17 01:33:59 INFO SparkContext: Added JAR file:///home/yitaoli/.ivy2/jars/com.thoughtworks.paranamer_paranamer-2.8.jar at spark://localhost:37753/jars/com.thoughtworks.paranamer_paranamer-2.8.jar with timestamp 1613525639280
21/02/17 01:33:59 INFO SparkContext: Added JAR file:///home/yitaoli/.ivy2/jars/com.fasterxml.jackson.core_jackson-annotations-2.9.10.jar at spark://localhost:37753/jars/com.fasterxml.jackson.core_jackson-annotations-2.9.10.jar with timestamp 1613525639280
21/02/17 01:33:59 INFO SparkContext: Added JAR file:///home/yitaoli/.ivy2/jars/com.fasterxml.jackson.core_jackson-core-2.9.10.jar at spark://localhost:37753/jars/com.fasterxml.jackson.core_jackson-core-2.9.10.jar with timestamp 1613525639280
21/02/17 01:33:59 INFO SparkContext: Added JAR file:/home/yitaoli/R/x86_64-pc-linux-gnu-library/4.0/sparklyr/java/sparklyr-3.0-2.12.jar at spark://localhost:37753/jars/sparklyr-3.0-2.12.jar with timestamp 1613525639280
21/02/17 01:33:59 INFO Executor: Starting executor ID driver on host localhost
21/02/17 01:33:59 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 35117.
21/02/17 01:33:59 INFO NettyBlockTransferService: Server created on localhost:35117
21/02/17 01:33:59 INFO BlockManager: Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
21/02/17 01:33:59 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, localhost, 35117, None)
21/02/17 01:33:59 INFO BlockManagerMasterEndpoint: Registering block manager localhost:35117 with 912.3 MiB RAM, BlockManagerId(driver, localhost, 35117, None)
21/02/17 01:33:59 INFO BlockManagerMaster: Registered BlockManager BlockManagerId(driver, localhost, 35117, None)
21/02/17 01:33:59 INFO BlockManager: Initialized BlockManager: BlockManagerId(driver, localhost, 35117, None)
21/02/17 01:33:59 INFO SharedState: loading hive config file: file:/home/yitaoli/spark/spark-3.0.0-bin-hadoop3.2/conf/hive-site.xml
21/02/17 01:33:59 INFO SharedState: Setting hive.metastore.warehouse.dir ('null') to the value of spark.sql.warehouse.dir ('file:/home/yitaoli/sparkxgb/tests/testthat/spark-warehouse').
21/02/17 01:33:59 INFO SharedState: Warehouse path is 'file:/home/yitaoli/sparkxgb/tests/testthat/spark-warehouse'.
21/02/17 01:34:01 INFO HiveUtils: Initializing HiveMetastoreConnection version 2.3.7 using Spark classes.
21/02/17 01:34:01 INFO HiveConf: Found configuration file file:/home/yitaoli/spark/spark-3.0.0-bin-hadoop3.2/conf/hive-site.xml
21/02/17 01:34:01 INFO SessionState: Created HDFS directory: /tmp/hive/yitaoli/feff7595-aea3-464c-9161-a2c26aa5be3b
21/02/17 01:34:01 INFO SessionState: Created local directory: /tmp/yitaoli/feff7595-aea3-464c-9161-a2c26aa5be3b
21/02/17 01:34:01 INFO SessionState: Created HDFS directory: /tmp/hive/yitaoli/feff7595-aea3-464c-9161-a2c26aa5be3b/_tmp_space.db
21/02/17 01:34:01 INFO HiveClientImpl: Warehouse location for Hive client (version 2.3.7) is file:/home/yitaoli/sparkxgb/tests/testthat/spark-warehouse
21/02/17 01:34:02 WARN HiveConf: HiveConf of name hive.stats.jdbc.timeout does not exist
21/02/17 01:34:02 WARN HiveConf: HiveConf of name hive.stats.retries.wait does not exist
21/02/17 01:34:02 INFO HiveMetaStore: 0: Opening raw store with implementation class:org.apache.hadoop.hive.metastore.ObjectStore
21/02/17 01:34:02 INFO ObjectStore: ObjectStore, initialize called
21/02/17 01:34:02 INFO Persistence: Property hive.metastore.integral.jdo.pushdown unknown - will be ignored
21/02/17 01:34:02 INFO Persistence: Property datanucleus.cache.level2 unknown - will be ignored
21/02/17 01:34:03 INFO ObjectStore: Setting MetaStore object pin classes with hive.metastore.cache.pinobjtypes="Table,StorageDescriptor,SerDeInfo,Partition,Database,Type,FieldSchema,Order"
21/02/17 01:34:04 INFO MetaStoreDirectSql: Using direct SQL, underlying DB is DERBY
21/02/17 01:34:04 INFO ObjectStore: Initialized ObjectStore
21/02/17 01:34:04 WARN ObjectStore: Version information not found in metastore. hive.metastore.schema.verification is not enabled so recording the schema version 2.3.0
21/02/17 01:34:04 WARN ObjectStore: setMetaStoreSchemaVersion called but recording version is disabled: version = 2.3.0, comment = Set by MetaStore yitaoli@127.0.1.1
21/02/17 01:34:04 WARN ObjectStore: Failed to get database default, returning NoSuchObjectException
21/02/17 01:34:04 INFO HiveMetaStore: Added admin role in metastore
21/02/17 01:34:04 INFO HiveMetaStore: Added public role in metastore
21/02/17 01:34:04 INFO HiveMetaStore: No user is added in admin role, since config is empty
21/02/17 01:34:04 INFO HiveMetaStore: 0: get_all_functions
21/02/17 01:34:04 INFO audit: ugi=yitaoli	ip=unknown-ip-addr	cmd=get_all_functions	
21/02/17 01:34:04 INFO HiveMetaStore: 0: get_database: default
21/02/17 01:34:04 INFO audit: ugi=yitaoli	ip=unknown-ip-addr	cmd=get_database: default	
21/02/17 01:34:04 INFO HiveMetaStore: 0: get_database: default
21/02/17 01:34:04 INFO audit: ugi=yitaoli	ip=unknown-ip-addr	cmd=get_database: default	
21/02/17 01:34:04 INFO HiveMetaStore: 0: get_table : db=default tbl=iris
21/02/17 01:34:04 INFO audit: ugi=yitaoli	ip=unknown-ip-addr	cmd=get_table : db=default tbl=iris	
21/02/17 01:34:05 INFO HiveMetaStore: 0: get_database: global_temp
21/02/17 01:34:05 INFO audit: ugi=yitaoli	ip=unknown-ip-addr	cmd=get_database: global_temp	
21/02/17 01:34:05 WARN ObjectStore: Failed to get database global_temp, returning NoSuchObjectException
21/02/17 01:34:05 INFO HiveMetaStore: 0: get_database: default
21/02/17 01:34:05 INFO audit: ugi=yitaoli	ip=unknown-ip-addr	cmd=get_database: default	
21/02/17 01:34:05 INFO HiveMetaStore: 0: get_database: default
21/02/17 01:34:05 INFO audit: ugi=yitaoli	ip=unknown-ip-addr	cmd=get_database: default	
21/02/17 01:34:05 INFO HiveMetaStore: 0: get_tables: db=default pat=*
21/02/17 01:34:05 INFO audit: ugi=yitaoli	ip=unknown-ip-addr	cmd=get_tables: db=default pat=*	
21/02/17 01:34:05 INFO SparkContext: Starting job: collect at utils.scala:54
21/02/17 01:34:05 INFO DAGScheduler: Job 0 finished: collect at utils.scala:54, took 0.003818 s
21/02/17 01:34:06 INFO CodeGenerator: Code generated in 194.945399 ms
21/02/17 01:34:06 INFO SparkContext: Starting job: collect at utils.scala:137
21/02/17 01:34:06 INFO DAGScheduler: Got job 1 (collect at utils.scala:137) with 1 output partitions
21/02/17 01:34:06 INFO DAGScheduler: Final stage: ResultStage 0 (collect at utils.scala:137)
21/02/17 01:34:06 INFO DAGScheduler: Parents of final stage: List()
21/02/17 01:34:06 INFO DAGScheduler: Missing parents: List()
21/02/17 01:34:06 INFO DAGScheduler: Submitting ResultStage 0 (MapPartitionsRDD[9] at collect at utils.scala:137), which has no missing parents
21/02/17 01:34:06 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 6.5 KiB, free 912.3 MiB)
21/02/17 01:34:06 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 3.2 KiB, free 912.3 MiB)
21/02/17 01:34:06 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on localhost:35117 (size: 3.2 KiB, free: 912.3 MiB)
21/02/17 01:34:06 INFO SparkContext: Created broadcast 0 from broadcast at DAGScheduler.scala:1200
21/02/17 01:34:06 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 0 (MapPartitionsRDD[9] at collect at utils.scala:137) (first 15 tasks are for partitions Vector(0))
21/02/17 01:34:06 INFO TaskSchedulerImpl: Adding task set 0.0 with 1 tasks
21/02/17 01:34:06 INFO TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0, localhost, executor driver, partition 0, PROCESS_LOCAL, 7561 bytes)
21/02/17 01:34:06 INFO Executor: Running task 0.0 in stage 0.0 (TID 0)
21/02/17 01:34:06 INFO Executor: Fetching spark://localhost:37753/jars/org.ow2.asm_asm-5.0.4.jar with timestamp 1613525639279
21/02/17 01:34:06 INFO TransportClientFactory: Successfully created connection to localhost/127.0.0.1:37753 after 10 ms (0 ms spent in bootstraps)
21/02/17 01:34:06 INFO Utils: Fetching spark://localhost:37753/jars/org.ow2.asm_asm-5.0.4.jar to /tmp/spark-12f582a0-84bc-44b5-a912-d296fadb2980/userFiles-e051a0ba-fd1a-4a35-949c-0ca08882d01a/fetchFileTemp2539226067331120602.tmp
21/02/17 01:34:06 INFO Executor: Adding file:/tmp/spark-12f582a0-84bc-44b5-a912-d296fadb2980/userFiles-e051a0ba-fd1a-4a35-949c-0ca08882d01a/org.ow2.asm_asm-5.0.4.jar to class loader
21/02/17 01:34:06 INFO Executor: Fetching spark://localhost:37753/jars/org.scala-lang.modules_scala-java8-compat_2.12-0.8.0.jar with timestamp 1613525639279
21/02/17 01:34:06 INFO Utils: Fetching spark://localhost:37753/jars/org.scala-lang.modules_scala-java8-compat_2.12-0.8.0.jar to /tmp/spark-12f582a0-84bc-44b5-a912-d296fadb2980/userFiles-e051a0ba-fd1a-4a35-949c-0ca08882d01a/fetchFileTemp6347283314720327441.tmp
21/02/17 01:34:06 INFO Executor: Adding file:/tmp/spark-12f582a0-84bc-44b5-a912-d296fadb2980/userFiles-e051a0ba-fd1a-4a35-949c-0ca08882d01a/org.scala-lang.modules_scala-java8-compat_2.12-0.8.0.jar to class loader
21/02/17 01:34:06 INFO Executor: Fetching spark://localhost:37753/jars/ml.dmlc_xgboost4j_2.12-1.3.1.jar with timestamp 1613525639278
21/02/17 01:34:06 INFO Utils: Fetching spark://localhost:37753/jars/ml.dmlc_xgboost4j_2.12-1.3.1.jar to /tmp/spark-12f582a0-84bc-44b5-a912-d296fadb2980/userFiles-e051a0ba-fd1a-4a35-949c-0ca08882d01a/fetchFileTemp3232326127962359360.tmp
21/02/17 01:34:06 INFO Executor: Adding file:/tmp/spark-12f582a0-84bc-44b5-a912-d296fadb2980/userFiles-e051a0ba-fd1a-4a35-949c-0ca08882d01a/ml.dmlc_xgboost4j_2.12-1.3.1.jar to class loader
21/02/17 01:34:06 INFO Executor: Fetching spark://localhost:37753/jars/org.json4s_json4s-ast_2.12-3.6.10.jar with timestamp 1613525639280
21/02/17 01:34:06 INFO Utils: Fetching spark://localhost:37753/jars/org.json4s_json4s-ast_2.12-3.6.10.jar to /tmp/spark-12f582a0-84bc-44b5-a912-d296fadb2980/userFiles-e051a0ba-fd1a-4a35-949c-0ca08882d01a/fetchFileTemp2269665991231625814.tmp
21/02/17 01:34:06 INFO Executor: Adding file:/tmp/spark-12f582a0-84bc-44b5-a912-d296fadb2980/userFiles-e051a0ba-fd1a-4a35-949c-0ca08882d01a/org.json4s_json4s-ast_2.12-3.6.10.jar to class loader
21/02/17 01:34:06 INFO Executor: Fetching spark://localhost:37753/jars/com.fasterxml.jackson.core_jackson-databind-2.9.10.6.jar with timestamp 1613525639280
21/02/17 01:34:06 INFO Utils: Fetching spark://localhost:37753/jars/com.fasterxml.jackson.core_jackson-databind-2.9.10.6.jar to /tmp/spark-12f582a0-84bc-44b5-a912-d296fadb2980/userFiles-e051a0ba-fd1a-4a35-949c-0ca08882d01a/fetchFileTemp7796338710542933640.tmp
21/02/17 01:34:06 INFO Executor: Adding file:/tmp/spark-12f582a0-84bc-44b5-a912-d296fadb2980/userFiles-e051a0ba-fd1a-4a35-949c-0ca08882d01a/com.fasterxml.jackson.core_jackson-databind-2.9.10.6.jar to class loader
21/02/17 01:34:06 INFO Executor: Fetching spark://localhost:37753/jars/com.fasterxml.jackson.core_jackson-annotations-2.9.10.jar with timestamp 1613525639280
21/02/17 01:34:06 INFO Utils: Fetching spark://localhost:37753/jars/com.fasterxml.jackson.core_jackson-annotations-2.9.10.jar to /tmp/spark-12f582a0-84bc-44b5-a912-d296fadb2980/userFiles-e051a0ba-fd1a-4a35-949c-0ca08882d01a/fetchFileTemp556694842796638171.tmp
21/02/17 01:34:06 INFO Executor: Adding file:/tmp/spark-12f582a0-84bc-44b5-a912-d296fadb2980/userFiles-e051a0ba-fd1a-4a35-949c-0ca08882d01a/com.fasterxml.jackson.core_jackson-annotations-2.9.10.jar to class loader
21/02/17 01:34:06 INFO Executor: Fetching spark://localhost:37753/jars/commons-logging_commons-logging-1.2.jar with timestamp 1613525639279
21/02/17 01:34:06 INFO Utils: Fetching spark://localhost:37753/jars/commons-logging_commons-logging-1.2.jar to /tmp/spark-12f582a0-84bc-44b5-a912-d296fadb2980/userFiles-e051a0ba-fd1a-4a35-949c-0ca08882d01a/fetchFileTemp3084275826496787986.tmp
21/02/17 01:34:06 INFO Executor: Adding file:/tmp/spark-12f582a0-84bc-44b5-a912-d296fadb2980/userFiles-e051a0ba-fd1a-4a35-949c-0ca08882d01a/commons-logging_commons-logging-1.2.jar to class loader
21/02/17 01:34:06 INFO Executor: Fetching spark://localhost:37753/jars/org.json4s_json4s-scalap_2.12-3.6.10.jar with timestamp 1613525639280
21/02/17 01:34:06 INFO Utils: Fetching spark://localhost:37753/jars/org.json4s_json4s-scalap_2.12-3.6.10.jar to /tmp/spark-12f582a0-84bc-44b5-a912-d296fadb2980/userFiles-e051a0ba-fd1a-4a35-949c-0ca08882d01a/fetchFileTemp936673324637862539.tmp
21/02/17 01:34:06 INFO Executor: Adding file:/tmp/spark-12f582a0-84bc-44b5-a912-d296fadb2980/userFiles-e051a0ba-fd1a-4a35-949c-0ca08882d01a/org.json4s_json4s-scalap_2.12-3.6.10.jar to class loader
21/02/17 01:34:06 INFO Executor: Fetching spark://localhost:37753/jars/ml.dmlc_xgboost4j-spark_2.12-1.3.1.jar with timestamp 1613525639278
21/02/17 01:34:06 INFO Utils: Fetching spark://localhost:37753/jars/ml.dmlc_xgboost4j-spark_2.12-1.3.1.jar to /tmp/spark-12f582a0-84bc-44b5-a912-d296fadb2980/userFiles-e051a0ba-fd1a-4a35-949c-0ca08882d01a/fetchFileTemp5109989010700289572.tmp
21/02/17 01:34:06 INFO Executor: Adding file:/tmp/spark-12f582a0-84bc-44b5-a912-d296fadb2980/userFiles-e051a0ba-fd1a-4a35-949c-0ca08882d01a/ml.dmlc_xgboost4j-spark_2.12-1.3.1.jar to class loader
21/02/17 01:34:06 INFO Executor: Fetching spark://localhost:37753/jars/com.esotericsoftware_reflectasm-1.11.3.jar with timestamp 1613525639279
21/02/17 01:34:06 INFO Utils: Fetching spark://localhost:37753/jars/com.esotericsoftware_reflectasm-1.11.3.jar to /tmp/spark-12f582a0-84bc-44b5-a912-d296fadb2980/userFiles-e051a0ba-fd1a-4a35-949c-0ca08882d01a/fetchFileTemp4871577057958897839.tmp
21/02/17 01:34:06 INFO Executor: Adding file:/tmp/spark-12f582a0-84bc-44b5-a912-d296fadb2980/userFiles-e051a0ba-fd1a-4a35-949c-0ca08882d01a/com.esotericsoftware_reflectasm-1.11.3.jar to class loader
21/02/17 01:34:06 INFO Executor: Fetching spark://localhost:37753/jars/org.scalactic_scalactic_2.12-3.0.5.jar with timestamp 1613525639279
21/02/17 01:34:06 INFO Utils: Fetching spark://localhost:37753/jars/org.scalactic_scalactic_2.12-3.0.5.jar to /tmp/spark-12f582a0-84bc-44b5-a912-d296fadb2980/userFiles-e051a0ba-fd1a-4a35-949c-0ca08882d01a/fetchFileTemp7943677789412682275.tmp
21/02/17 01:34:06 INFO Executor: Adding file:/tmp/spark-12f582a0-84bc-44b5-a912-d296fadb2980/userFiles-e051a0ba-fd1a-4a35-949c-0ca08882d01a/org.scalactic_scalactic_2.12-3.0.5.jar to class loader
21/02/17 01:34:06 INFO Executor: Fetching spark://localhost:37753/jars/com.esotericsoftware_minlog-1.3.0.jar with timestamp 1613525639279
21/02/17 01:34:06 INFO Utils: Fetching spark://localhost:37753/jars/com.esotericsoftware_minlog-1.3.0.jar to /tmp/spark-12f582a0-84bc-44b5-a912-d296fadb2980/userFiles-e051a0ba-fd1a-4a35-949c-0ca08882d01a/fetchFileTemp4240768629975762584.tmp
21/02/17 01:34:06 INFO Executor: Adding file:/tmp/spark-12f582a0-84bc-44b5-a912-d296fadb2980/userFiles-e051a0ba-fd1a-4a35-949c-0ca08882d01a/com.esotericsoftware_minlog-1.3.0.jar to class loader
21/02/17 01:34:06 INFO Executor: Fetching spark://localhost:37753/jars/com.fasterxml.jackson.core_jackson-core-2.9.10.jar with timestamp 1613525639280
21/02/17 01:34:06 INFO Utils: Fetching spark://localhost:37753/jars/com.fasterxml.jackson.core_jackson-core-2.9.10.jar to /tmp/spark-12f582a0-84bc-44b5-a912-d296fadb2980/userFiles-e051a0ba-fd1a-4a35-949c-0ca08882d01a/fetchFileTemp5508342490928723186.tmp
21/02/17 01:34:06 INFO Executor: Adding file:/tmp/spark-12f582a0-84bc-44b5-a912-d296fadb2980/userFiles-e051a0ba-fd1a-4a35-949c-0ca08882d01a/com.fasterxml.jackson.core_jackson-core-2.9.10.jar to class loader
21/02/17 01:34:06 INFO Executor: Fetching spark://localhost:37753/jars/org.scala-lang.modules_scala-xml_2.12-1.0.6.jar with timestamp 1613525639279
21/02/17 01:34:06 INFO Utils: Fetching spark://localhost:37753/jars/org.scala-lang.modules_scala-xml_2.12-1.0.6.jar to /tmp/spark-12f582a0-84bc-44b5-a912-d296fadb2980/userFiles-e051a0ba-fd1a-4a35-949c-0ca08882d01a/fetchFileTemp8657515577789678159.tmp
21/02/17 01:34:06 INFO Executor: Adding file:/tmp/spark-12f582a0-84bc-44b5-a912-d296fadb2980/userFiles-e051a0ba-fd1a-4a35-949c-0ca08882d01a/org.scala-lang.modules_scala-xml_2.12-1.0.6.jar to class loader
21/02/17 01:34:06 INFO Executor: Fetching spark://localhost:37753/jars/com.typesafe_config-1.3.3.jar with timestamp 1613525639279
21/02/17 01:34:06 INFO Utils: Fetching spark://localhost:37753/jars/com.typesafe_config-1.3.3.jar to /tmp/spark-12f582a0-84bc-44b5-a912-d296fadb2980/userFiles-e051a0ba-fd1a-4a35-949c-0ca08882d01a/fetchFileTemp3773384958086560751.tmp
21/02/17 01:34:06 INFO Executor: Adding file:/tmp/spark-12f582a0-84bc-44b5-a912-d296fadb2980/userFiles-e051a0ba-fd1a-4a35-949c-0ca08882d01a/com.typesafe_config-1.3.3.jar to class loader
21/02/17 01:34:06 INFO Executor: Fetching spark://localhost:37753/jars/com.thoughtworks.paranamer_paranamer-2.8.jar with timestamp 1613525639280
21/02/17 01:34:06 INFO Utils: Fetching spark://localhost:37753/jars/com.thoughtworks.paranamer_paranamer-2.8.jar to /tmp/spark-12f582a0-84bc-44b5-a912-d296fadb2980/userFiles-e051a0ba-fd1a-4a35-949c-0ca08882d01a/fetchFileTemp4231420370131127865.tmp
21/02/17 01:34:06 INFO Executor: Adding file:/tmp/spark-12f582a0-84bc-44b5-a912-d296fadb2980/userFiles-e051a0ba-fd1a-4a35-949c-0ca08882d01a/com.thoughtworks.paranamer_paranamer-2.8.jar to class loader
21/02/17 01:34:06 INFO Executor: Fetching spark://localhost:37753/jars/org.scala-lang_scala-reflect-2.12.8.jar with timestamp 1613525639279
21/02/17 01:34:06 INFO Utils: Fetching spark://localhost:37753/jars/org.scala-lang_scala-reflect-2.12.8.jar to /tmp/spark-12f582a0-84bc-44b5-a912-d296fadb2980/userFiles-e051a0ba-fd1a-4a35-949c-0ca08882d01a/fetchFileTemp2101683807045234322.tmp
21/02/17 01:34:06 INFO Executor: Adding file:/tmp/spark-12f582a0-84bc-44b5-a912-d296fadb2980/userFiles-e051a0ba-fd1a-4a35-949c-0ca08882d01a/org.scala-lang_scala-reflect-2.12.8.jar to class loader
21/02/17 01:34:06 INFO Executor: Fetching spark://localhost:37753/jars/org.scalatest_scalatest_2.12-3.0.5.jar with timestamp 1613525639279
21/02/17 01:34:06 INFO Utils: Fetching spark://localhost:37753/jars/org.scalatest_scalatest_2.12-3.0.5.jar to /tmp/spark-12f582a0-84bc-44b5-a912-d296fadb2980/userFiles-e051a0ba-fd1a-4a35-949c-0ca08882d01a/fetchFileTemp1664722180525540189.tmp
21/02/17 01:34:06 INFO Executor: Adding file:/tmp/spark-12f582a0-84bc-44b5-a912-d296fadb2980/userFiles-e051a0ba-fd1a-4a35-949c-0ca08882d01a/org.scalatest_scalatest_2.12-3.0.5.jar to class loader
21/02/17 01:34:06 INFO Executor: Fetching spark://localhost:37753/jars/com.typesafe.akka_akka-actor_2.12-2.5.23.jar with timestamp 1613525639279
21/02/17 01:34:06 INFO Utils: Fetching spark://localhost:37753/jars/com.typesafe.akka_akka-actor_2.12-2.5.23.jar to /tmp/spark-12f582a0-84bc-44b5-a912-d296fadb2980/userFiles-e051a0ba-fd1a-4a35-949c-0ca08882d01a/fetchFileTemp5448343849379331408.tmp
21/02/17 01:34:06 INFO Executor: Adding file:/tmp/spark-12f582a0-84bc-44b5-a912-d296fadb2980/userFiles-e051a0ba-fd1a-4a35-949c-0ca08882d01a/com.typesafe.akka_akka-actor_2.12-2.5.23.jar to class loader
21/02/17 01:34:06 INFO Executor: Fetching spark://localhost:37753/jars/com.esotericsoftware_kryo-4.0.2.jar with timestamp 1613525639278
21/02/17 01:34:06 INFO Utils: Fetching spark://localhost:37753/jars/com.esotericsoftware_kryo-4.0.2.jar to /tmp/spark-12f582a0-84bc-44b5-a912-d296fadb2980/userFiles-e051a0ba-fd1a-4a35-949c-0ca08882d01a/fetchFileTemp186234090807537812.tmp
21/02/17 01:34:06 INFO Executor: Adding file:/tmp/spark-12f582a0-84bc-44b5-a912-d296fadb2980/userFiles-e051a0ba-fd1a-4a35-949c-0ca08882d01a/com.esotericsoftware_kryo-4.0.2.jar to class loader
21/02/17 01:34:06 INFO Executor: Fetching spark://localhost:37753/jars/org.scala-lang_scala-compiler-2.12.8.jar with timestamp 1613525639278
21/02/17 01:34:06 INFO Utils: Fetching spark://localhost:37753/jars/org.scala-lang_scala-compiler-2.12.8.jar to /tmp/spark-12f582a0-84bc-44b5-a912-d296fadb2980/userFiles-e051a0ba-fd1a-4a35-949c-0ca08882d01a/fetchFileTemp5871412219004504492.tmp
21/02/17 01:34:06 INFO Executor: Adding file:/tmp/spark-12f582a0-84bc-44b5-a912-d296fadb2980/userFiles-e051a0ba-fd1a-4a35-949c-0ca08882d01a/org.scala-lang_scala-compiler-2.12.8.jar to class loader
21/02/17 01:34:06 INFO Executor: Fetching spark://localhost:37753/jars/org.json4s_json4s-jackson_2.12-3.6.10.jar with timestamp 1613525639278
21/02/17 01:34:06 INFO Utils: Fetching spark://localhost:37753/jars/org.json4s_json4s-jackson_2.12-3.6.10.jar to /tmp/spark-12f582a0-84bc-44b5-a912-d296fadb2980/userFiles-e051a0ba-fd1a-4a35-949c-0ca08882d01a/fetchFileTemp3995257763792505853.tmp
21/02/17 01:34:06 INFO Executor: Adding file:/tmp/spark-12f582a0-84bc-44b5-a912-d296fadb2980/userFiles-e051a0ba-fd1a-4a35-949c-0ca08882d01a/org.json4s_json4s-jackson_2.12-3.6.10.jar to class loader
21/02/17 01:34:06 INFO Executor: Fetching spark://localhost:37753/jars/org.json4s_json4s-core_2.12-3.6.10.jar with timestamp 1613525639280
21/02/17 01:34:06 INFO Utils: Fetching spark://localhost:37753/jars/org.json4s_json4s-core_2.12-3.6.10.jar to /tmp/spark-12f582a0-84bc-44b5-a912-d296fadb2980/userFiles-e051a0ba-fd1a-4a35-949c-0ca08882d01a/fetchFileTemp1983200687907634289.tmp
21/02/17 01:34:06 INFO Executor: Adding file:/tmp/spark-12f582a0-84bc-44b5-a912-d296fadb2980/userFiles-e051a0ba-fd1a-4a35-949c-0ca08882d01a/org.json4s_json4s-core_2.12-3.6.10.jar to class loader
21/02/17 01:34:06 INFO Executor: Fetching spark://localhost:37753/jars/sparklyr-3.0-2.12.jar with timestamp 1613525639280
21/02/17 01:34:06 INFO Utils: Fetching spark://localhost:37753/jars/sparklyr-3.0-2.12.jar to /tmp/spark-12f582a0-84bc-44b5-a912-d296fadb2980/userFiles-e051a0ba-fd1a-4a35-949c-0ca08882d01a/fetchFileTemp5505883834350824045.tmp
21/02/17 01:34:06 INFO Executor: Adding file:/tmp/spark-12f582a0-84bc-44b5-a912-d296fadb2980/userFiles-e051a0ba-fd1a-4a35-949c-0ca08882d01a/sparklyr-3.0-2.12.jar to class loader
21/02/17 01:34:06 INFO Executor: Fetching spark://localhost:37753/jars/org.objenesis_objenesis-2.5.1.jar with timestamp 1613525639279
21/02/17 01:34:06 INFO Utils: Fetching spark://localhost:37753/jars/org.objenesis_objenesis-2.5.1.jar to /tmp/spark-12f582a0-84bc-44b5-a912-d296fadb2980/userFiles-e051a0ba-fd1a-4a35-949c-0ca08882d01a/fetchFileTemp6777045165324817179.tmp
21/02/17 01:34:06 INFO Executor: Adding file:/tmp/spark-12f582a0-84bc-44b5-a912-d296fadb2980/userFiles-e051a0ba-fd1a-4a35-949c-0ca08882d01a/org.objenesis_objenesis-2.5.1.jar to class loader
21/02/17 01:34:07 INFO Executor: Finished task 0.0 in stage 0.0 (TID 0). 1397 bytes result sent to driver
21/02/17 01:34:07 INFO TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in 434 ms on localhost (executor driver) (1/1)
21/02/17 01:34:07 INFO TaskSchedulerImpl: Removed TaskSet 0.0, whose tasks have all completed, from pool 
21/02/17 01:34:07 INFO DAGScheduler: ResultStage 0 (collect at utils.scala:137) finished in 0.553 s
21/02/17 01:34:07 INFO DAGScheduler: Job 1 is finished. Cancelling potential speculative or zombie tasks for this job
21/02/17 01:34:07 INFO TaskSchedulerImpl: Killing all running tasks in stage 0: Stage finished
21/02/17 01:34:07 INFO DAGScheduler: Job 1 finished: collect at utils.scala:137, took 0.594967 s
21/02/17 01:34:07 INFO CodeGenerator: Code generated in 11.346409 ms
21/02/17 01:34:07 INFO CodeGenerator: Code generated in 14.68081 ms
21/02/17 01:34:07 INFO CodeGenerator: Code generated in 13.567152 ms
21/02/17 01:34:07 INFO SparkContext: Starting job: count at utils.scala:135
21/02/17 01:34:07 INFO DAGScheduler: Registering RDD 11 (count at utils.scala:135) as input to shuffle 0
21/02/17 01:34:07 INFO DAGScheduler: Got job 2 (count at utils.scala:135) with 1 output partitions
21/02/17 01:34:07 INFO DAGScheduler: Final stage: ResultStage 2 (count at utils.scala:135)
21/02/17 01:34:07 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 1)
21/02/17 01:34:07 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 1)
21/02/17 01:34:07 INFO DAGScheduler: Submitting ShuffleMapStage 1 (MapPartitionsRDD[11] at count at utils.scala:135), which has no missing parents
21/02/17 01:34:07 INFO MemoryStore: Block broadcast_1 stored as values in memory (estimated size 10.0 KiB, free 912.3 MiB)
21/02/17 01:34:07 INFO MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 5.2 KiB, free 912.3 MiB)
21/02/17 01:34:07 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on localhost:35117 (size: 5.2 KiB, free: 912.3 MiB)
21/02/17 01:34:07 INFO SparkContext: Created broadcast 1 from broadcast at DAGScheduler.scala:1200
21/02/17 01:34:07 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 1 (MapPartitionsRDD[11] at count at utils.scala:135) (first 15 tasks are for partitions Vector(0))
21/02/17 01:34:07 INFO TaskSchedulerImpl: Adding task set 1.0 with 1 tasks
21/02/17 01:34:07 INFO TaskSetManager: Starting task 0.0 in stage 1.0 (TID 1, localhost, executor driver, partition 0, PROCESS_LOCAL, 7550 bytes)
21/02/17 01:34:07 INFO Executor: Running task 0.0 in stage 1.0 (TID 1)
21/02/17 01:34:07 INFO Executor: Finished task 0.0 in stage 1.0 (TID 1). 1833 bytes result sent to driver
21/02/17 01:34:07 INFO TaskSetManager: Finished task 0.0 in stage 1.0 (TID 1) in 40 ms on localhost (executor driver) (1/1)
21/02/17 01:34:07 INFO TaskSchedulerImpl: Removed TaskSet 1.0, whose tasks have all completed, from pool 
21/02/17 01:34:07 INFO DAGScheduler: ShuffleMapStage 1 (count at utils.scala:135) finished in 0.052 s
21/02/17 01:34:07 INFO DAGScheduler: looking for newly runnable stages
21/02/17 01:34:07 INFO DAGScheduler: running: Set()
21/02/17 01:34:07 INFO DAGScheduler: waiting: Set(ResultStage 2)
21/02/17 01:34:07 INFO DAGScheduler: failed: Set()
21/02/17 01:34:07 INFO DAGScheduler: Submitting ResultStage 2 (MapPartitionsRDD[14] at count at utils.scala:135), which has no missing parents
21/02/17 01:34:07 INFO MemoryStore: Block broadcast_2 stored as values in memory (estimated size 10.1 KiB, free 912.3 MiB)
21/02/17 01:34:07 INFO MemoryStore: Block broadcast_2_piece0 stored as bytes in memory (estimated size 5.0 KiB, free 912.3 MiB)
21/02/17 01:34:07 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on localhost:35117 (size: 5.0 KiB, free: 912.3 MiB)
21/02/17 01:34:07 INFO SparkContext: Created broadcast 2 from broadcast at DAGScheduler.scala:1200
21/02/17 01:34:07 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 2 (MapPartitionsRDD[14] at count at utils.scala:135) (first 15 tasks are for partitions Vector(0))
21/02/17 01:34:07 INFO TaskSchedulerImpl: Adding task set 2.0 with 1 tasks
21/02/17 01:34:07 INFO TaskSetManager: Starting task 0.0 in stage 2.0 (TID 2, localhost, executor driver, partition 0, NODE_LOCAL, 7325 bytes)
21/02/17 01:34:07 INFO Executor: Running task 0.0 in stage 2.0 (TID 2)
21/02/17 01:34:07 INFO ShuffleBlockFetcherIterator: Getting 1 (60.0 B) non-empty blocks including 1 (60.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
21/02/17 01:34:07 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 5 ms
21/02/17 01:34:07 INFO Executor: Finished task 0.0 in stage 2.0 (TID 2). 2648 bytes result sent to driver
21/02/17 01:34:07 INFO TaskSetManager: Finished task 0.0 in stage 2.0 (TID 2) in 33 ms on localhost (executor driver) (1/1)
21/02/17 01:34:07 INFO TaskSchedulerImpl: Removed TaskSet 2.0, whose tasks have all completed, from pool 
21/02/17 01:34:07 INFO DAGScheduler: ResultStage 2 (count at utils.scala:135) finished in 0.041 s
21/02/17 01:34:07 INFO DAGScheduler: Job 2 is finished. Cancelling potential speculative or zombie tasks for this job
21/02/17 01:34:07 INFO TaskSchedulerImpl: Killing all running tasks in stage 2: Stage finished
21/02/17 01:34:07 INFO DAGScheduler: Job 2 finished: count at utils.scala:135, took 0.113745 s
21/02/17 01:34:07 INFO SparkContext: Starting job: collect at utils.scala:137
21/02/17 01:34:07 INFO DAGScheduler: Got job 3 (collect at utils.scala:137) with 1 output partitions
21/02/17 01:34:07 INFO DAGScheduler: Final stage: ResultStage 3 (collect at utils.scala:137)
21/02/17 01:34:07 INFO DAGScheduler: Parents of final stage: List()
21/02/17 01:34:07 INFO DAGScheduler: Missing parents: List()
21/02/17 01:34:07 INFO DAGScheduler: Submitting ResultStage 3 (MapPartitionsRDD[16] at collect at utils.scala:137), which has no missing parents
21/02/17 01:34:07 INFO MemoryStore: Block broadcast_3 stored as values in memory (estimated size 7.2 KiB, free 912.3 MiB)
21/02/17 01:34:07 INFO MemoryStore: Block broadcast_3_piece0 stored as bytes in memory (estimated size 3.7 KiB, free 912.3 MiB)
21/02/17 01:34:07 INFO BlockManagerInfo: Added broadcast_3_piece0 in memory on localhost:35117 (size: 3.7 KiB, free: 912.3 MiB)
21/02/17 01:34:07 INFO SparkContext: Created broadcast 3 from broadcast at DAGScheduler.scala:1200
21/02/17 01:34:07 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 3 (MapPartitionsRDD[16] at collect at utils.scala:137) (first 15 tasks are for partitions Vector(0))
21/02/17 01:34:07 INFO TaskSchedulerImpl: Adding task set 3.0 with 1 tasks
21/02/17 01:34:07 INFO TaskSetManager: Starting task 0.0 in stage 3.0 (TID 3, localhost, executor driver, partition 0, PROCESS_LOCAL, 7561 bytes)
21/02/17 01:34:07 INFO Executor: Running task 0.0 in stage 3.0 (TID 3)
21/02/17 01:34:07 INFO Executor: Finished task 0.0 in stage 3.0 (TID 3). 1397 bytes result sent to driver
21/02/17 01:34:07 INFO TaskSetManager: Finished task 0.0 in stage 3.0 (TID 3) in 6 ms on localhost (executor driver) (1/1)
21/02/17 01:34:07 INFO TaskSchedulerImpl: Removed TaskSet 3.0, whose tasks have all completed, from pool 
21/02/17 01:34:07 INFO DAGScheduler: ResultStage 3 (collect at utils.scala:137) finished in 0.010 s
21/02/17 01:34:07 INFO DAGScheduler: Job 3 is finished. Cancelling potential speculative or zombie tasks for this job
21/02/17 01:34:07 INFO TaskSchedulerImpl: Killing all running tasks in stage 3: Stage finished
21/02/17 01:34:07 INFO DAGScheduler: Job 3 finished: collect at utils.scala:137, took 0.013624 s
21/02/17 01:34:07 INFO SparkContext: Starting job: count at utils.scala:135
21/02/17 01:34:07 INFO DAGScheduler: Registering RDD 18 (count at utils.scala:135) as input to shuffle 1
21/02/17 01:34:07 INFO DAGScheduler: Got job 4 (count at utils.scala:135) with 1 output partitions
21/02/17 01:34:07 INFO DAGScheduler: Final stage: ResultStage 5 (count at utils.scala:135)
21/02/17 01:34:07 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 4)
21/02/17 01:34:07 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 4)
21/02/17 01:34:07 INFO DAGScheduler: Submitting ShuffleMapStage 4 (MapPartitionsRDD[18] at count at utils.scala:135), which has no missing parents
21/02/17 01:34:07 INFO MemoryStore: Block broadcast_4 stored as values in memory (estimated size 10.0 KiB, free 912.2 MiB)
21/02/17 01:34:07 INFO MemoryStore: Block broadcast_4_piece0 stored as bytes in memory (estimated size 5.2 KiB, free 912.2 MiB)
21/02/17 01:34:07 INFO BlockManagerInfo: Added broadcast_4_piece0 in memory on localhost:35117 (size: 5.2 KiB, free: 912.3 MiB)
21/02/17 01:34:07 INFO SparkContext: Created broadcast 4 from broadcast at DAGScheduler.scala:1200
21/02/17 01:34:07 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 4 (MapPartitionsRDD[18] at count at utils.scala:135) (first 15 tasks are for partitions Vector(0))
21/02/17 01:34:07 INFO TaskSchedulerImpl: Adding task set 4.0 with 1 tasks
21/02/17 01:34:07 INFO TaskSetManager: Starting task 0.0 in stage 4.0 (TID 4, localhost, executor driver, partition 0, PROCESS_LOCAL, 7550 bytes)
21/02/17 01:34:07 INFO Executor: Running task 0.0 in stage 4.0 (TID 4)
21/02/17 01:34:07 INFO Executor: Finished task 0.0 in stage 4.0 (TID 4). 1833 bytes result sent to driver
21/02/17 01:34:07 INFO TaskSetManager: Finished task 0.0 in stage 4.0 (TID 4) in 7 ms on localhost (executor driver) (1/1)
21/02/17 01:34:07 INFO TaskSchedulerImpl: Removed TaskSet 4.0, whose tasks have all completed, from pool 
21/02/17 01:34:07 INFO DAGScheduler: ShuffleMapStage 4 (count at utils.scala:135) finished in 0.013 s
21/02/17 01:34:07 INFO DAGScheduler: looking for newly runnable stages
21/02/17 01:34:07 INFO DAGScheduler: running: Set()
21/02/17 01:34:07 INFO DAGScheduler: waiting: Set(ResultStage 5)
21/02/17 01:34:07 INFO DAGScheduler: failed: Set()
21/02/17 01:34:07 INFO DAGScheduler: Submitting ResultStage 5 (MapPartitionsRDD[21] at count at utils.scala:135), which has no missing parents
21/02/17 01:34:07 INFO MemoryStore: Block broadcast_5 stored as values in memory (estimated size 10.1 KiB, free 912.2 MiB)
21/02/17 01:34:07 INFO MemoryStore: Block broadcast_5_piece0 stored as bytes in memory (estimated size 5.0 KiB, free 912.2 MiB)
21/02/17 01:34:07 INFO BlockManagerInfo: Added broadcast_5_piece0 in memory on localhost:35117 (size: 5.0 KiB, free: 912.3 MiB)
21/02/17 01:34:07 INFO SparkContext: Created broadcast 5 from broadcast at DAGScheduler.scala:1200
21/02/17 01:34:07 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 5 (MapPartitionsRDD[21] at count at utils.scala:135) (first 15 tasks are for partitions Vector(0))
21/02/17 01:34:07 INFO TaskSchedulerImpl: Adding task set 5.0 with 1 tasks
21/02/17 01:34:07 INFO TaskSetManager: Starting task 0.0 in stage 5.0 (TID 5, localhost, executor driver, partition 0, NODE_LOCAL, 7325 bytes)
21/02/17 01:34:07 INFO Executor: Running task 0.0 in stage 5.0 (TID 5)
21/02/17 01:34:07 INFO ShuffleBlockFetcherIterator: Getting 1 (60.0 B) non-empty blocks including 1 (60.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
21/02/17 01:34:07 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
21/02/17 01:34:07 INFO Executor: Finished task 0.0 in stage 5.0 (TID 5). 2648 bytes result sent to driver
21/02/17 01:34:07 INFO TaskSetManager: Finished task 0.0 in stage 5.0 (TID 5) in 6 ms on localhost (executor driver) (1/1)
21/02/17 01:34:07 INFO TaskSchedulerImpl: Removed TaskSet 5.0, whose tasks have all completed, from pool 
21/02/17 01:34:07 INFO DAGScheduler: ResultStage 5 (count at utils.scala:135) finished in 0.034 s
21/02/17 01:34:07 INFO DAGScheduler: Job 4 is finished. Cancelling potential speculative or zombie tasks for this job
21/02/17 01:34:07 INFO TaskSchedulerImpl: Killing all running tasks in stage 5: Stage finished
21/02/17 01:34:07 INFO DAGScheduler: Job 4 finished: count at utils.scala:135, took 0.053264 s
21/02/17 01:34:07 INFO BlockManagerInfo: Removed broadcast_2_piece0 on localhost:35117 in memory (size: 5.0 KiB, free: 912.3 MiB)
21/02/17 01:34:07 INFO BlockManagerInfo: Removed broadcast_1_piece0 on localhost:35117 in memory (size: 5.2 KiB, free: 912.3 MiB)
21/02/17 01:34:07 INFO BlockManagerInfo: Removed broadcast_0_piece0 on localhost:35117 in memory (size: 3.2 KiB, free: 912.3 MiB)
21/02/17 01:34:07 INFO BlockManagerInfo: Removed broadcast_3_piece0 on localhost:35117 in memory (size: 3.7 KiB, free: 912.3 MiB)
21/02/17 01:34:08 INFO Instrumentation: [8cba549b] training finished
21/02/17 01:34:08 INFO Instrumentation: [773a814b] training finished
21/02/17 01:34:08 INFO CodeGenerator: Code generated in 31.827122 ms
21/02/17 01:34:08 INFO CodeGenerator: Code generated in 9.843858 ms
21/02/17 01:34:08 INFO XGBoostSpark: Running XGBoost 1.3.1 with parameters:
alpha -> 0.0
min_child_weight -> 1.0
sample_type -> uniform
base_score -> 0.5
rabit_timeout -> -1
colsample_bylevel -> 1.0
grow_policy -> depthwise
skip_drop -> 0.0
lambda_bias -> 0.0
silent -> 0
scale_pos_weight -> 1.0
seed -> 0
cache_training_set -> false
features_col -> features
num_early_stopping_rounds -> 0
label_col -> label
num_workers -> 1
subsample -> 1.0
lambda -> 1.0
max_depth -> 6
kill_spark_context_on_worker_failure -> true
tree_limit -> 0
custom_eval -> null
dmlc_worker_connect_retry -> 5
rate_drop -> 0.0
max_bin -> 16
train_test_ratio -> 1.0
use_external_memory -> false
objective -> reg:linear
eval_metric -> rmse
num_round -> 1
maximize_evaluation_metrics -> false
timeout_request_workers -> 1800000
missing -> NaN
rabit_ring_reduce_threshold -> 32768
checkpoint_path -> 
tracker_conf -> TrackerConf(0,python)
tree_method -> auto
max_delta_step -> 0.0
eta -> 0.3
verbosity -> 1
colsample_bytree -> 1.0
objective_type -> regression
normalize_type -> tree
allow_non_zero_for_missing -> false
custom_obj -> null
gamma -> 0.0
sketch_eps -> 0.03
nthread -> 1
prediction_col -> prediction
checkpoint_interval -> -1
21/02/17 01:34:08 WARN XGBoostSpark: train_test_ratio is deprecated since XGBoost 0.82, we recommend to explicitly pass a training and multiple evaluation datasets by passing 'eval_sets' and 'eval_set_names'
21/02/17 01:34:08 INFO RabitTracker$TrackerProcessLogger: 2021-02-17 01:34:08,806 INFO start listen on 192.168.2.12:9091
21/02/17 01:34:08 INFO XGBoostSpark: starting training with timeout set as 1800000 ms for waiting for resources
21/02/17 01:34:08 INFO SparkContext: Starting job: foreachPartition at XGBoost.scala:612
21/02/17 01:34:08 INFO DAGScheduler: Got job 5 (foreachPartition at XGBoost.scala:612) with 1 output partitions
21/02/17 01:34:08 INFO DAGScheduler: Final stage: ResultStage 6 (foreachPartition at XGBoost.scala:612)
21/02/17 01:34:08 INFO DAGScheduler: Parents of final stage: List()
21/02/17 01:34:08 INFO DAGScheduler: Missing parents: List()
21/02/17 01:34:08 INFO DAGScheduler: Submitting ResultStage 6 (MapPartitionsRDD[32] at mapPartitions at XGBoost.scala:493), which has no missing parents
21/02/17 01:34:08 INFO MemoryStore: Block broadcast_6 stored as values in memory (estimated size 41.0 KiB, free 912.2 MiB)
21/02/17 01:34:08 INFO MemoryStore: Block broadcast_6_piece0 stored as bytes in memory (estimated size 16.8 KiB, free 912.2 MiB)
21/02/17 01:34:08 INFO BlockManagerInfo: Added broadcast_6_piece0 in memory on localhost:35117 (size: 16.8 KiB, free: 912.3 MiB)
21/02/17 01:34:08 INFO SparkContext: Created broadcast 6 from broadcast at DAGScheduler.scala:1200
21/02/17 01:34:08 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 6 (MapPartitionsRDD[32] at mapPartitions at XGBoost.scala:493) (first 15 tasks are for partitions Vector(0))
21/02/17 01:34:08 INFO TaskSchedulerImpl: Adding task set 6.0 with 1 tasks
21/02/17 01:34:08 INFO TaskSetManager: Starting task 0.0 in stage 6.0 (TID 6, localhost, executor driver, partition 0, PROCESS_LOCAL, 18492 bytes)
21/02/17 01:34:08 INFO Executor: Running task 0.0 in stage 6.0 (TID 6)
21/02/17 01:34:09 INFO MemoryStore: Block rdd_23_0 stored as values in memory (estimated size 5.6 KiB, free 912.2 MiB)
21/02/17 01:34:09 INFO BlockManagerInfo: Added rdd_23_0 in memory on localhost:35117 (size: 5.6 KiB, free: 912.3 MiB)
21/02/17 01:34:09 INFO CodeGenerator: Code generated in 8.111616 ms
21/02/17 01:34:09 INFO CodeGenerator: Code generated in 19.843824 ms
21/02/17 01:34:09 INFO CodeGenerator: Code generated in 8.829454 ms
21/02/17 01:34:09 INFO RabitTracker$TrackerProcessLogger: /tmp/tracker239808958107134653.py:330: DeprecationWarning: isAlive() is deprecated, use is_alive() instead
21/02/17 01:34:09 INFO RabitTracker$TrackerProcessLogger:   while self.thread.isAlive():
21/02/17 01:34:09 INFO RabitTracker$TrackerProcessLogger: 2021-02-17 01:34:09,164 DEBUG Recieve start signal from 192.168.2.12; assign rank 0
21/02/17 01:34:09 INFO RabitTracker$TrackerProcessLogger: 2021-02-17 01:34:09,164 INFO @tracker All of 1 nodes getting started
21/02/17 01:34:09 INFO RabitTracker$TrackerProcessLogger: 2021-02-17 01:34:09,173 INFO [0]	train-rmse:2.633044
21/02/17 01:34:09 INFO RabitTracker$TrackerProcessLogger: 2021-02-17 01:34:09,174 DEBUG Recieve shutdown signal from 0
21/02/17 01:34:09 INFO RabitTracker$TrackerProcessLogger: 2021-02-17 01:34:09,174 INFO @tracker All nodes finishes job
21/02/17 01:34:09 INFO RabitTracker$TrackerProcessLogger: 2021-02-17 01:34:09,174 INFO @tracker 0.009334564208984375 secs between node start and job finish
21/02/17 01:34:09 INFO MemoryStore: Block rdd_32_0 stored as values in memory (estimated size 192.0 B, free 912.2 MiB)
21/02/17 01:34:09 INFO BlockManagerInfo: Added rdd_32_0 in memory on localhost:35117 (size: 192.0 B, free: 912.3 MiB)
21/02/17 01:34:09 INFO RabitTracker: Tracker Process ends with exit code 0
21/02/17 01:34:09 INFO RabitTracker$TrackerProcessLogger: Tracker Process ends with exit code 0
21/02/17 01:34:09 INFO XGBoostSpark: Rabit returns with exit code 0
21/02/17 01:34:09 INFO Executor: 1 block locks were not released by TID = 6:
[rdd_32_0]
21/02/17 01:34:09 INFO Executor: Finished task 0.0 in stage 6.0 (TID 6). 1385 bytes result sent to driver
21/02/17 01:34:09 INFO TaskSetManager: Finished task 0.0 in stage 6.0 (TID 6) in 283 ms on localhost (executor driver) (1/1)
21/02/17 01:34:09 INFO TaskSchedulerImpl: Removed TaskSet 6.0, whose tasks have all completed, from pool 
21/02/17 01:34:09 INFO DAGScheduler: ResultStage 6 (foreachPartition at XGBoost.scala:612) finished in 0.343 s
21/02/17 01:34:09 INFO DAGScheduler: Job 5 is finished. Cancelling potential speculative or zombie tasks for this job
21/02/17 01:34:09 INFO TaskSchedulerImpl: Killing all running tasks in stage 6: Stage finished
21/02/17 01:34:09 INFO DAGScheduler: Job 5 finished: foreachPartition at XGBoost.scala:612, took 0.349778 s
21/02/17 01:34:09 INFO SparkContext: Starting job: first at XGBoost.scala:734
21/02/17 01:34:09 INFO DAGScheduler: Got job 6 (first at XGBoost.scala:734) with 1 output partitions
21/02/17 01:34:09 INFO DAGScheduler: Final stage: ResultStage 7 (first at XGBoost.scala:734)
21/02/17 01:34:09 INFO DAGScheduler: Parents of final stage: List()
21/02/17 01:34:09 INFO DAGScheduler: Missing parents: List()
21/02/17 01:34:09 INFO DAGScheduler: Submitting ResultStage 7 (MapPartitionsRDD[32] at mapPartitions at XGBoost.scala:493), which has no missing parents
21/02/17 01:34:09 INFO MemoryStore: Block broadcast_7 stored as values in memory (estimated size 40.8 KiB, free 912.2 MiB)
21/02/17 01:34:09 INFO MemoryStore: Block broadcast_7_piece0 stored as bytes in memory (estimated size 16.8 KiB, free 912.2 MiB)
21/02/17 01:34:09 INFO BlockManagerInfo: Added broadcast_7_piece0 in memory on localhost:35117 (size: 16.8 KiB, free: 912.3 MiB)
21/02/17 01:34:09 INFO SparkContext: Created broadcast 7 from broadcast at DAGScheduler.scala:1200
21/02/17 01:34:09 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 7 (MapPartitionsRDD[32] at mapPartitions at XGBoost.scala:493) (first 15 tasks are for partitions Vector(0))
21/02/17 01:34:09 INFO TaskSchedulerImpl: Adding task set 7.0 with 1 tasks
21/02/17 01:34:09 INFO TaskSetManager: Starting task 0.0 in stage 7.0 (TID 7, localhost, executor driver, partition 0, PROCESS_LOCAL, 18492 bytes)
21/02/17 01:34:09 INFO Executor: Running task 0.0 in stage 7.0 (TID 7)
21/02/17 01:34:09 INFO BlockManager: Found block rdd_32_0 locally
21/02/17 01:34:09 INFO Executor: 1 block locks were not released by TID = 7:
[rdd_32_0]
21/02/17 01:34:09 INFO Executor: Finished task 0.0 in stage 7.0 (TID 7). 2676 bytes result sent to driver
21/02/17 01:34:09 INFO TaskSetManager: Finished task 0.0 in stage 7.0 (TID 7) in 11 ms on localhost (executor driver) (1/1)
21/02/17 01:34:09 INFO TaskSchedulerImpl: Removed TaskSet 7.0, whose tasks have all completed, from pool 
21/02/17 01:34:09 INFO DAGScheduler: ResultStage 7 (first at XGBoost.scala:734) finished in 0.017 s
21/02/17 01:34:09 INFO DAGScheduler: Job 6 is finished. Cancelling potential speculative or zombie tasks for this job
21/02/17 01:34:09 INFO TaskSchedulerImpl: Killing all running tasks in stage 7: Stage finished
21/02/17 01:34:09 INFO DAGScheduler: Job 6 finished: first at XGBoost.scala:734, took 0.021462 s
21/02/17 01:34:09 INFO MapPartitionsRDD: Removing RDD 32 from persistence list
21/02/17 01:34:09 INFO BlockManager: Removing RDD 32
21/02/17 01:34:09 INFO Instrumentation: [1667ba0a] training finished
21/02/17 01:34:09 INFO Instrumentation: [89a19959] training finished
21/02/17 01:34:09 INFO MemoryStore: Block broadcast_8 stored as values in memory (estimated size 64.0 B, free 912.2 MiB)
21/02/17 01:34:09 INFO MemoryStore: Block broadcast_8_piece0 stored as bytes in memory (estimated size 514.0 B, free 912.2 MiB)
21/02/17 01:34:09 INFO BlockManagerInfo: Added broadcast_8_piece0 in memory on localhost:35117 (size: 514.0 B, free: 912.3 MiB)
21/02/17 01:34:09 INFO SparkContext: Created broadcast 8 from broadcast at XGBoostRegressor.scala:279
21/02/17 01:34:09 INFO CodeGenerator: Code generated in 25.253219 ms
21/02/17 01:34:09 INFO Instrumentation: [57dc0ee8] training finished
21/02/17 01:34:09 INFO CodeGenerator: Code generated in 6.853448 ms
21/02/17 01:34:09 INFO SparkContext: Starting job: collect at utils.scala:137
21/02/17 01:34:09 INFO DAGScheduler: Got job 7 (collect at utils.scala:137) with 1 output partitions
21/02/17 01:34:09 INFO DAGScheduler: Final stage: ResultStage 8 (collect at utils.scala:137)
21/02/17 01:34:09 INFO DAGScheduler: Parents of final stage: List()
21/02/17 01:34:09 INFO DAGScheduler: Missing parents: List()
21/02/17 01:34:09 INFO DAGScheduler: Submitting ResultStage 8 (MapPartitionsRDD[42] at collect at utils.scala:137), which has no missing parents
21/02/17 01:34:09 INFO MemoryStore: Block broadcast_9 stored as values in memory (estimated size 7.3 KiB, free 912.1 MiB)
21/02/17 01:34:09 INFO MemoryStore: Block broadcast_9_piece0 stored as bytes in memory (estimated size 3.7 KiB, free 912.1 MiB)
21/02/17 01:34:09 INFO BlockManagerInfo: Added broadcast_9_piece0 in memory on localhost:35117 (size: 3.7 KiB, free: 912.2 MiB)
21/02/17 01:34:09 INFO SparkContext: Created broadcast 9 from broadcast at DAGScheduler.scala:1200
21/02/17 01:34:09 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 8 (MapPartitionsRDD[42] at collect at utils.scala:137) (first 15 tasks are for partitions Vector(0))
21/02/17 01:34:09 INFO TaskSchedulerImpl: Adding task set 8.0 with 1 tasks
21/02/17 01:34:09 INFO TaskSetManager: Starting task 0.0 in stage 8.0 (TID 8, localhost, executor driver, partition 0, PROCESS_LOCAL, 7561 bytes)
21/02/17 01:34:09 INFO Executor: Running task 0.0 in stage 8.0 (TID 8)
21/02/17 01:34:09 INFO Executor: Finished task 0.0 in stage 8.0 (TID 8). 1397 bytes result sent to driver
21/02/17 01:34:09 INFO TaskSetManager: Finished task 0.0 in stage 8.0 (TID 8) in 6 ms on localhost (executor driver) (1/1)
21/02/17 01:34:09 INFO TaskSchedulerImpl: Removed TaskSet 8.0, whose tasks have all completed, from pool 
21/02/17 01:34:09 INFO DAGScheduler: ResultStage 8 (collect at utils.scala:137) finished in 0.013 s
21/02/17 01:34:09 INFO DAGScheduler: Job 7 is finished. Cancelling potential speculative or zombie tasks for this job
21/02/17 01:34:09 INFO TaskSchedulerImpl: Killing all running tasks in stage 8: Stage finished
21/02/17 01:34:09 INFO DAGScheduler: Job 7 finished: collect at utils.scala:137, took 0.015398 s
21/02/17 01:34:09 INFO CodeGenerator: Code generated in 10.046275 ms
21/02/17 01:34:09 INFO BlockManagerInfo: Removed broadcast_6_piece0 on localhost:35117 in memory (size: 16.8 KiB, free: 912.3 MiB)
21/02/17 01:34:09 INFO BlockManagerInfo: Removed broadcast_5_piece0 on localhost:35117 in memory (size: 5.0 KiB, free: 912.3 MiB)
21/02/17 01:34:09 INFO BlockManagerInfo: Removed broadcast_4_piece0 on localhost:35117 in memory (size: 5.2 KiB, free: 912.3 MiB)
21/02/17 01:34:09 INFO BlockManager: Removing RDD 32
21/02/17 01:34:09 INFO BlockManagerInfo: Removed broadcast_9_piece0 on localhost:35117 in memory (size: 3.7 KiB, free: 912.3 MiB)
21/02/17 01:34:09 INFO BlockManagerInfo: Removed broadcast_7_piece0 on localhost:35117 in memory (size: 16.8 KiB, free: 912.3 MiB)
21/02/17 01:34:09 INFO SparkContext: Starting job: count at utils.scala:135
21/02/17 01:34:09 INFO DAGScheduler: Registering RDD 44 (count at utils.scala:135) as input to shuffle 2
21/02/17 01:34:09 INFO DAGScheduler: Got job 8 (count at utils.scala:135) with 1 output partitions
21/02/17 01:34:09 INFO DAGScheduler: Final stage: ResultStage 10 (count at utils.scala:135)
21/02/17 01:34:09 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 9)
21/02/17 01:34:09 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 9)
21/02/17 01:34:09 INFO DAGScheduler: Submitting ShuffleMapStage 9 (MapPartitionsRDD[44] at count at utils.scala:135), which has no missing parents
21/02/17 01:34:09 INFO MemoryStore: Block broadcast_10 stored as values in memory (estimated size 10.0 KiB, free 912.3 MiB)
21/02/17 01:34:09 INFO MemoryStore: Block broadcast_10_piece0 stored as bytes in memory (estimated size 5.2 KiB, free 912.3 MiB)
21/02/17 01:34:09 INFO BlockManagerInfo: Added broadcast_10_piece0 in memory on localhost:35117 (size: 5.2 KiB, free: 912.3 MiB)
21/02/17 01:34:09 INFO SparkContext: Created broadcast 10 from broadcast at DAGScheduler.scala:1200
21/02/17 01:34:09 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 9 (MapPartitionsRDD[44] at count at utils.scala:135) (first 15 tasks are for partitions Vector(0))
21/02/17 01:34:09 INFO TaskSchedulerImpl: Adding task set 9.0 with 1 tasks
21/02/17 01:34:09 INFO TaskSetManager: Starting task 0.0 in stage 9.0 (TID 9, localhost, executor driver, partition 0, PROCESS_LOCAL, 7550 bytes)
21/02/17 01:34:09 INFO Executor: Running task 0.0 in stage 9.0 (TID 9)
21/02/17 01:34:09 INFO Executor: Finished task 0.0 in stage 9.0 (TID 9). 1833 bytes result sent to driver
21/02/17 01:34:09 INFO TaskSetManager: Finished task 0.0 in stage 9.0 (TID 9) in 5 ms on localhost (executor driver) (1/1)
21/02/17 01:34:09 INFO TaskSchedulerImpl: Removed TaskSet 9.0, whose tasks have all completed, from pool 
21/02/17 01:34:09 INFO DAGScheduler: ShuffleMapStage 9 (count at utils.scala:135) finished in 0.012 s
21/02/17 01:34:09 INFO DAGScheduler: looking for newly runnable stages
21/02/17 01:34:09 INFO DAGScheduler: running: Set()
21/02/17 01:34:09 INFO DAGScheduler: waiting: Set(ResultStage 10)
21/02/17 01:34:09 INFO DAGScheduler: failed: Set()
21/02/17 01:34:09 INFO DAGScheduler: Submitting ResultStage 10 (MapPartitionsRDD[47] at count at utils.scala:135), which has no missing parents
21/02/17 01:34:09 INFO MemoryStore: Block broadcast_11 stored as values in memory (estimated size 10.1 KiB, free 912.3 MiB)
21/02/17 01:34:09 INFO MemoryStore: Block broadcast_11_piece0 stored as bytes in memory (estimated size 5.0 KiB, free 912.3 MiB)
21/02/17 01:34:09 INFO BlockManagerInfo: Added broadcast_11_piece0 in memory on localhost:35117 (size: 5.0 KiB, free: 912.3 MiB)
21/02/17 01:34:09 INFO SparkContext: Created broadcast 11 from broadcast at DAGScheduler.scala:1200
21/02/17 01:34:09 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 10 (MapPartitionsRDD[47] at count at utils.scala:135) (first 15 tasks are for partitions Vector(0))
21/02/17 01:34:09 INFO TaskSchedulerImpl: Adding task set 10.0 with 1 tasks
21/02/17 01:34:09 INFO TaskSetManager: Starting task 0.0 in stage 10.0 (TID 10, localhost, executor driver, partition 0, NODE_LOCAL, 7325 bytes)
21/02/17 01:34:09 INFO Executor: Running task 0.0 in stage 10.0 (TID 10)
21/02/17 01:34:09 INFO ShuffleBlockFetcherIterator: Getting 1 (60.0 B) non-empty blocks including 1 (60.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
21/02/17 01:34:09 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
21/02/17 01:34:09 INFO Executor: Finished task 0.0 in stage 10.0 (TID 10). 2648 bytes result sent to driver
21/02/17 01:34:09 INFO TaskSetManager: Finished task 0.0 in stage 10.0 (TID 10) in 6 ms on localhost (executor driver) (1/1)
21/02/17 01:34:09 INFO TaskSchedulerImpl: Removed TaskSet 10.0, whose tasks have all completed, from pool 
21/02/17 01:34:09 INFO DAGScheduler: ResultStage 10 (count at utils.scala:135) finished in 0.011 s
21/02/17 01:34:09 INFO DAGScheduler: Job 8 is finished. Cancelling potential speculative or zombie tasks for this job
21/02/17 01:34:09 INFO TaskSchedulerImpl: Killing all running tasks in stage 10: Stage finished
21/02/17 01:34:09 INFO DAGScheduler: Job 8 finished: count at utils.scala:135, took 0.027181 s
21/02/17 01:34:10 INFO CodeGenerator: Code generated in 12.86157 ms
21/02/17 01:34:10 INFO SparkContext: Starting job: collect at utils.scala:137
21/02/17 01:34:10 INFO DAGScheduler: Got job 9 (collect at utils.scala:137) with 1 output partitions
21/02/17 01:34:10 INFO DAGScheduler: Final stage: ResultStage 11 (collect at utils.scala:137)
21/02/17 01:34:10 INFO DAGScheduler: Parents of final stage: List()
21/02/17 01:34:10 INFO DAGScheduler: Missing parents: List()
21/02/17 01:34:10 INFO DAGScheduler: Submitting ResultStage 11 (MapPartitionsRDD[49] at collect at utils.scala:137), which has no missing parents
21/02/17 01:34:10 INFO MemoryStore: Block broadcast_12 stored as values in memory (estimated size 71.9 KiB, free 912.2 MiB)
21/02/17 01:34:10 INFO MemoryStore: Block broadcast_12_piece0 stored as bytes in memory (estimated size 28.2 KiB, free 912.2 MiB)
21/02/17 01:34:10 INFO BlockManagerInfo: Added broadcast_12_piece0 in memory on localhost:35117 (size: 28.2 KiB, free: 912.3 MiB)
21/02/17 01:34:10 INFO SparkContext: Created broadcast 12 from broadcast at DAGScheduler.scala:1200
21/02/17 01:34:10 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 11 (MapPartitionsRDD[49] at collect at utils.scala:137) (first 15 tasks are for partitions Vector(0))
21/02/17 01:34:10 INFO TaskSchedulerImpl: Adding task set 11.0 with 1 tasks
21/02/17 01:34:10 INFO TaskSetManager: Starting task 0.0 in stage 11.0 (TID 11, localhost, executor driver, partition 0, PROCESS_LOCAL, 18492 bytes)
21/02/17 01:34:10 INFO Executor: Running task 0.0 in stage 11.0 (TID 11)
21/02/17 01:34:10 INFO BlockManager: Found block rdd_23_0 locally
21/02/17 01:34:10 INFO CodeGenerator: Code generated in 8.640219 ms
21/02/17 01:34:10 INFO CodeGenerator: Code generated in 49.452525 ms
21/02/17 01:34:10 INFO Executor: Finished task 0.0 in stage 11.0 (TID 11). 1912 bytes result sent to driver
21/02/17 01:34:10 INFO TaskSetManager: Finished task 0.0 in stage 11.0 (TID 11) in 167 ms on localhost (executor driver) (1/1)
21/02/17 01:34:10 INFO TaskSchedulerImpl: Removed TaskSet 11.0, whose tasks have all completed, from pool 
21/02/17 01:34:10 INFO DAGScheduler: ResultStage 11 (collect at utils.scala:137) finished in 0.175 s
21/02/17 01:34:10 INFO DAGScheduler: Job 9 is finished. Cancelling potential speculative or zombie tasks for this job
21/02/17 01:34:10 INFO TaskSchedulerImpl: Killing all running tasks in stage 11: Stage finished
21/02/17 01:34:10 INFO DAGScheduler: Job 9 finished: collect at utils.scala:137, took 0.179458 s
21/02/17 01:34:10 INFO CodeGenerator: Code generated in 7.336052 ms
21/02/17 01:34:10 INFO CodeGenerator: Code generated in 10.715507 ms
21/02/17 01:34:10 INFO SparkContext: Starting job: count at utils.scala:135
21/02/17 01:34:10 INFO DAGScheduler: Registering RDD 51 (count at utils.scala:135) as input to shuffle 3
21/02/17 01:34:10 INFO DAGScheduler: Got job 10 (count at utils.scala:135) with 1 output partitions
21/02/17 01:34:10 INFO DAGScheduler: Final stage: ResultStage 13 (count at utils.scala:135)
21/02/17 01:34:10 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 12)
21/02/17 01:34:10 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 12)
21/02/17 01:34:10 INFO DAGScheduler: Submitting ShuffleMapStage 12 (MapPartitionsRDD[51] at count at utils.scala:135), which has no missing parents
21/02/17 01:34:10 INFO MemoryStore: Block broadcast_13 stored as values in memory (estimated size 74.1 KiB, free 912.1 MiB)
21/02/17 01:34:10 INFO MemoryStore: Block broadcast_13_piece0 stored as bytes in memory (estimated size 29.4 KiB, free 912.1 MiB)
21/02/17 01:34:10 INFO BlockManagerInfo: Added broadcast_13_piece0 in memory on localhost:35117 (size: 29.4 KiB, free: 912.2 MiB)
21/02/17 01:34:10 INFO SparkContext: Created broadcast 13 from broadcast at DAGScheduler.scala:1200
21/02/17 01:34:10 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 12 (MapPartitionsRDD[51] at count at utils.scala:135) (first 15 tasks are for partitions Vector(0))
21/02/17 01:34:10 INFO TaskSchedulerImpl: Adding task set 12.0 with 1 tasks
21/02/17 01:34:10 INFO TaskSetManager: Starting task 0.0 in stage 12.0 (TID 12, localhost, executor driver, partition 0, PROCESS_LOCAL, 18481 bytes)
21/02/17 01:34:10 INFO Executor: Running task 0.0 in stage 12.0 (TID 12)
21/02/17 01:34:10 INFO BlockManager: Found block rdd_23_0 locally
21/02/17 01:34:10 INFO Executor: Finished task 0.0 in stage 12.0 (TID 12). 2253 bytes result sent to driver
21/02/17 01:34:10 INFO TaskSetManager: Finished task 0.0 in stage 12.0 (TID 12) in 53 ms on localhost (executor driver) (1/1)
21/02/17 01:34:10 INFO TaskSchedulerImpl: Removed TaskSet 12.0, whose tasks have all completed, from pool 
21/02/17 01:34:10 INFO DAGScheduler: ShuffleMapStage 12 (count at utils.scala:135) finished in 0.061 s
21/02/17 01:34:10 INFO DAGScheduler: looking for newly runnable stages
21/02/17 01:34:10 INFO DAGScheduler: running: Set()
21/02/17 01:34:10 INFO DAGScheduler: waiting: Set(ResultStage 13)
21/02/17 01:34:10 INFO DAGScheduler: failed: Set()
21/02/17 01:34:10 INFO DAGScheduler: Submitting ResultStage 13 (MapPartitionsRDD[54] at count at utils.scala:135), which has no missing parents
21/02/17 01:34:10 INFO MemoryStore: Block broadcast_14 stored as values in memory (estimated size 10.1 KiB, free 912.1 MiB)
21/02/17 01:34:10 INFO MemoryStore: Block broadcast_14_piece0 stored as bytes in memory (estimated size 5.0 KiB, free 912.1 MiB)
21/02/17 01:34:10 INFO BlockManagerInfo: Added broadcast_14_piece0 in memory on localhost:35117 (size: 5.0 KiB, free: 912.2 MiB)
21/02/17 01:34:10 INFO SparkContext: Created broadcast 14 from broadcast at DAGScheduler.scala:1200
21/02/17 01:34:10 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 13 (MapPartitionsRDD[54] at count at utils.scala:135) (first 15 tasks are for partitions Vector(0))
21/02/17 01:34:10 INFO TaskSchedulerImpl: Adding task set 13.0 with 1 tasks
21/02/17 01:34:10 INFO TaskSetManager: Starting task 0.0 in stage 13.0 (TID 13, localhost, executor driver, partition 0, NODE_LOCAL, 7325 bytes)
21/02/17 01:34:10 INFO Executor: Running task 0.0 in stage 13.0 (TID 13)
21/02/17 01:34:10 INFO ShuffleBlockFetcherIterator: Getting 1 (60.0 B) non-empty blocks including 1 (60.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
21/02/17 01:34:10 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
21/02/17 01:34:10 INFO Executor: Finished task 0.0 in stage 13.0 (TID 13). 2648 bytes result sent to driver
21/02/17 01:34:10 INFO TaskSetManager: Finished task 0.0 in stage 13.0 (TID 13) in 5 ms on localhost (executor driver) (1/1)
21/02/17 01:34:10 INFO TaskSchedulerImpl: Removed TaskSet 13.0, whose tasks have all completed, from pool 
21/02/17 01:34:10 INFO DAGScheduler: ResultStage 13 (count at utils.scala:135) finished in 0.010 s
21/02/17 01:34:10 INFO DAGScheduler: Job 10 is finished. Cancelling potential speculative or zombie tasks for this job
21/02/17 01:34:10 INFO TaskSchedulerImpl: Killing all running tasks in stage 13: Stage finished
21/02/17 01:34:10 INFO DAGScheduler: Job 10 finished: count at utils.scala:135, took 0.077143 s
21/02/17 01:34:10 INFO deprecation: mapred.output.dir is deprecated. Instead, use mapreduce.output.fileoutputformat.outputdir
21/02/17 01:34:10 INFO HadoopMapRedCommitProtocol: Using output committer class org.apache.hadoop.mapred.FileOutputCommitter
21/02/17 01:34:10 INFO FileOutputCommitter: File Output Committer Algorithm version is 2
21/02/17 01:34:10 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
21/02/17 01:34:10 INFO SparkContext: Starting job: runJob at SparkHadoopWriter.scala:78
21/02/17 01:34:10 INFO DAGScheduler: Got job 11 (runJob at SparkHadoopWriter.scala:78) with 1 output partitions
21/02/17 01:34:10 INFO DAGScheduler: Final stage: ResultStage 14 (runJob at SparkHadoopWriter.scala:78)
21/02/17 01:34:10 INFO DAGScheduler: Parents of final stage: List()
21/02/17 01:34:10 INFO DAGScheduler: Missing parents: List()
21/02/17 01:34:10 INFO DAGScheduler: Submitting ResultStage 14 (MapPartitionsRDD[56] at saveAsTextFile at ReadWrite.scala:413), which has no missing parents
21/02/17 01:34:10 INFO MemoryStore: Block broadcast_15 stored as values in memory (estimated size 83.9 KiB, free 912.0 MiB)
21/02/17 01:34:10 INFO MemoryStore: Block broadcast_15_piece0 stored as bytes in memory (estimated size 29.9 KiB, free 911.9 MiB)
21/02/17 01:34:10 INFO BlockManagerInfo: Added broadcast_15_piece0 in memory on localhost:35117 (size: 29.9 KiB, free: 912.2 MiB)
21/02/17 01:34:10 INFO SparkContext: Created broadcast 15 from broadcast at DAGScheduler.scala:1200
21/02/17 01:34:10 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 14 (MapPartitionsRDD[56] at saveAsTextFile at ReadWrite.scala:413) (first 15 tasks are for partitions Vector(0))
21/02/17 01:34:10 INFO TaskSchedulerImpl: Adding task set 14.0 with 1 tasks
21/02/17 01:34:10 INFO TaskSetManager: Starting task 0.0 in stage 14.0 (TID 14, localhost, executor driver, partition 0, PROCESS_LOCAL, 7657 bytes)
21/02/17 01:34:10 INFO Executor: Running task 0.0 in stage 14.0 (TID 14)
21/02/17 01:34:10 INFO HadoopMapRedCommitProtocol: Using output committer class org.apache.hadoop.mapred.FileOutputCommitter
21/02/17 01:34:10 INFO FileOutputCommitter: File Output Committer Algorithm version is 2
21/02/17 01:34:10 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
21/02/17 01:34:10 INFO FileOutputCommitter: Saved output of task 'attempt_20210217013410_0056_m_000000_0' to file:/tmp/RtmpE1GwT4/file220626098807e/metadata
21/02/17 01:34:10 INFO SparkHadoopMapRedUtil: attempt_20210217013410_0056_m_000000_0: Committed
21/02/17 01:34:10 INFO Executor: Finished task 0.0 in stage 14.0 (TID 14). 1201 bytes result sent to driver
21/02/17 01:34:10 INFO TaskSetManager: Finished task 0.0 in stage 14.0 (TID 14) in 43 ms on localhost (executor driver) (1/1)
21/02/17 01:34:10 INFO TaskSchedulerImpl: Removed TaskSet 14.0, whose tasks have all completed, from pool 
21/02/17 01:34:10 INFO DAGScheduler: ResultStage 14 (runJob at SparkHadoopWriter.scala:78) finished in 0.056 s
21/02/17 01:34:10 INFO DAGScheduler: Job 11 is finished. Cancelling potential speculative or zombie tasks for this job
21/02/17 01:34:10 INFO TaskSchedulerImpl: Killing all running tasks in stage 14: Stage finished
21/02/17 01:34:10 INFO DAGScheduler: Job 11 finished: runJob at SparkHadoopWriter.scala:78, took 0.058330 s
21/02/17 01:34:10 INFO SparkHadoopWriter: Job job_20210217013410_0056 committed.
21/02/17 01:34:10 INFO HadoopMapRedCommitProtocol: Using output committer class org.apache.hadoop.mapred.FileOutputCommitter
21/02/17 01:34:10 INFO FileOutputCommitter: File Output Committer Algorithm version is 2
21/02/17 01:34:10 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
21/02/17 01:34:10 INFO SparkContext: Starting job: runJob at SparkHadoopWriter.scala:78
21/02/17 01:34:10 INFO DAGScheduler: Got job 12 (runJob at SparkHadoopWriter.scala:78) with 1 output partitions
21/02/17 01:34:10 INFO DAGScheduler: Final stage: ResultStage 15 (runJob at SparkHadoopWriter.scala:78)
21/02/17 01:34:10 INFO DAGScheduler: Parents of final stage: List()
21/02/17 01:34:10 INFO DAGScheduler: Missing parents: List()
21/02/17 01:34:10 INFO DAGScheduler: Submitting ResultStage 15 (MapPartitionsRDD[58] at saveAsTextFile at ReadWrite.scala:413), which has no missing parents
21/02/17 01:34:10 INFO MemoryStore: Block broadcast_16 stored as values in memory (estimated size 84.0 KiB, free 911.9 MiB)
21/02/17 01:34:10 INFO MemoryStore: Block broadcast_16_piece0 stored as bytes in memory (estimated size 29.9 KiB, free 911.8 MiB)
21/02/17 01:34:10 INFO BlockManagerInfo: Added broadcast_16_piece0 in memory on localhost:35117 (size: 29.9 KiB, free: 912.2 MiB)
21/02/17 01:34:10 INFO SparkContext: Created broadcast 16 from broadcast at DAGScheduler.scala:1200
21/02/17 01:34:10 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 15 (MapPartitionsRDD[58] at saveAsTextFile at ReadWrite.scala:413) (first 15 tasks are for partitions Vector(0))
21/02/17 01:34:10 INFO TaskSchedulerImpl: Adding task set 15.0 with 1 tasks
21/02/17 01:34:10 INFO TaskSetManager: Starting task 0.0 in stage 15.0 (TID 15, localhost, executor driver, partition 0, PROCESS_LOCAL, 7798 bytes)
21/02/17 01:34:10 INFO Executor: Running task 0.0 in stage 15.0 (TID 15)
21/02/17 01:34:10 INFO HadoopMapRedCommitProtocol: Using output committer class org.apache.hadoop.mapred.FileOutputCommitter
21/02/17 01:34:10 INFO FileOutputCommitter: File Output Committer Algorithm version is 2
21/02/17 01:34:10 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
21/02/17 01:34:10 INFO FileOutputCommitter: Saved output of task 'attempt_20210217013410_0058_m_000000_0' to file:/tmp/RtmpE1GwT4/file220626098807e/stages/0_r_formula__05ea37d3_e6ba_4801_96be_09a4389f822b/metadata
21/02/17 01:34:10 INFO SparkHadoopMapRedUtil: attempt_20210217013410_0058_m_000000_0: Committed
21/02/17 01:34:10 INFO Executor: Finished task 0.0 in stage 15.0 (TID 15). 1158 bytes result sent to driver
21/02/17 01:34:10 INFO TaskSetManager: Finished task 0.0 in stage 15.0 (TID 15) in 20 ms on localhost (executor driver) (1/1)
21/02/17 01:34:10 INFO TaskSchedulerImpl: Removed TaskSet 15.0, whose tasks have all completed, from pool 
21/02/17 01:34:10 INFO DAGScheduler: ResultStage 15 (runJob at SparkHadoopWriter.scala:78) finished in 0.033 s
21/02/17 01:34:10 INFO DAGScheduler: Job 12 is finished. Cancelling potential speculative or zombie tasks for this job
21/02/17 01:34:10 INFO TaskSchedulerImpl: Killing all running tasks in stage 15: Stage finished
21/02/17 01:34:10 INFO DAGScheduler: Job 12 finished: runJob at SparkHadoopWriter.scala:78, took 0.034760 s
21/02/17 01:34:10 INFO SparkHadoopWriter: Job job_20210217013410_0058 committed.
21/02/17 01:34:11 INFO ParquetFileFormat: Using default output committer for Parquet: org.apache.parquet.hadoop.ParquetOutputCommitter
21/02/17 01:34:11 INFO FileOutputCommitter: File Output Committer Algorithm version is 2
21/02/17 01:34:11 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
21/02/17 01:34:11 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
21/02/17 01:34:11 INFO FileOutputCommitter: File Output Committer Algorithm version is 2
21/02/17 01:34:11 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
21/02/17 01:34:11 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
21/02/17 01:34:11 INFO CodeGenerator: Code generated in 9.353366 ms
21/02/17 01:34:11 INFO SparkContext: Starting job: parquet at RFormula.scala:434
21/02/17 01:34:11 INFO DAGScheduler: Registering RDD 61 (parquet at RFormula.scala:434) as input to shuffle 4
21/02/17 01:34:11 INFO DAGScheduler: Got job 13 (parquet at RFormula.scala:434) with 1 output partitions
21/02/17 01:34:11 INFO DAGScheduler: Final stage: ResultStage 17 (parquet at RFormula.scala:434)
21/02/17 01:34:11 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 16)
21/02/17 01:34:11 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 16)
21/02/17 01:34:11 INFO DAGScheduler: Submitting ShuffleMapStage 16 (MapPartitionsRDD[61] at parquet at RFormula.scala:434), which has no missing parents
21/02/17 01:34:11 INFO MemoryStore: Block broadcast_17 stored as values in memory (estimated size 7.7 KiB, free 911.8 MiB)
21/02/17 01:34:11 INFO MemoryStore: Block broadcast_17_piece0 stored as bytes in memory (estimated size 4.2 KiB, free 911.8 MiB)
21/02/17 01:34:11 INFO BlockManagerInfo: Added broadcast_17_piece0 in memory on localhost:35117 (size: 4.2 KiB, free: 912.2 MiB)
21/02/17 01:34:11 INFO SparkContext: Created broadcast 17 from broadcast at DAGScheduler.scala:1200
21/02/17 01:34:11 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 16 (MapPartitionsRDD[61] at parquet at RFormula.scala:434) (first 15 tasks are for partitions Vector(0))
21/02/17 01:34:11 INFO TaskSchedulerImpl: Adding task set 16.0 with 1 tasks
21/02/17 01:34:11 INFO TaskSetManager: Starting task 0.0 in stage 16.0 (TID 16, localhost, executor driver, partition 0, PROCESS_LOCAL, 7658 bytes)
21/02/17 01:34:11 INFO Executor: Running task 0.0 in stage 16.0 (TID 16)
21/02/17 01:34:11 INFO Executor: Finished task 0.0 in stage 16.0 (TID 16). 1614 bytes result sent to driver
21/02/17 01:34:11 INFO TaskSetManager: Finished task 0.0 in stage 16.0 (TID 16) in 7 ms on localhost (executor driver) (1/1)
21/02/17 01:34:11 INFO TaskSchedulerImpl: Removed TaskSet 16.0, whose tasks have all completed, from pool 
21/02/17 01:34:11 INFO DAGScheduler: ShuffleMapStage 16 (parquet at RFormula.scala:434) finished in 0.013 s
21/02/17 01:34:11 INFO DAGScheduler: looking for newly runnable stages
21/02/17 01:34:11 INFO DAGScheduler: running: Set()
21/02/17 01:34:11 INFO DAGScheduler: waiting: Set(ResultStage 17)
21/02/17 01:34:11 INFO DAGScheduler: failed: Set()
21/02/17 01:34:11 INFO DAGScheduler: Submitting ResultStage 17 (ShuffledRowRDD[62] at parquet at RFormula.scala:434), which has no missing parents
21/02/17 01:34:11 INFO MemoryStore: Block broadcast_18 stored as values in memory (estimated size 177.6 KiB, free 911.6 MiB)
21/02/17 01:34:11 INFO MemoryStore: Block broadcast_18_piece0 stored as bytes in memory (estimated size 62.1 KiB, free 911.6 MiB)
21/02/17 01:34:11 INFO BlockManagerInfo: Added broadcast_18_piece0 in memory on localhost:35117 (size: 62.1 KiB, free: 912.1 MiB)
21/02/17 01:34:11 INFO SparkContext: Created broadcast 18 from broadcast at DAGScheduler.scala:1200
21/02/17 01:34:11 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 17 (ShuffledRowRDD[62] at parquet at RFormula.scala:434) (first 15 tasks are for partitions Vector(0))
21/02/17 01:34:11 INFO TaskSchedulerImpl: Adding task set 17.0 with 1 tasks
21/02/17 01:34:11 INFO TaskSetManager: Starting task 0.0 in stage 17.0 (TID 17, localhost, executor driver, partition 0, NODE_LOCAL, 7325 bytes)
21/02/17 01:34:11 INFO Executor: Running task 0.0 in stage 17.0 (TID 17)
21/02/17 01:34:11 INFO ShuffleBlockFetcherIterator: Getting 1 (156.0 B) non-empty blocks including 1 (156.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
21/02/17 01:34:11 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
21/02/17 01:34:11 INFO FileOutputCommitter: File Output Committer Algorithm version is 2
21/02/17 01:34:11 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
21/02/17 01:34:11 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
21/02/17 01:34:11 INFO FileOutputCommitter: File Output Committer Algorithm version is 2
21/02/17 01:34:11 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
21/02/17 01:34:11 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
21/02/17 01:34:11 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:
{
  "type" : "struct",
  "fields" : [ {
    "name" : "label",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "terms",
    "type" : {
      "type" : "array",
      "elementType" : {
        "type" : "array",
        "elementType" : "string",
        "containsNull" : true
      },
      "containsNull" : true
    },
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "hasIntercept",
    "type" : "boolean",
    "nullable" : false,
    "metadata" : { }
  } ]
}
and corresponding Parquet message type:
message spark_schema {
  optional binary label (UTF8);
  optional group terms (LIST) {
    repeated group list {
      optional group element (LIST) {
        repeated group list {
          optional binary element (UTF8);
        }
      }
    }
  }
  required boolean hasIntercept;
}

       
21/02/17 01:34:11 INFO CodecPool: Got brand-new compressor [.snappy]
21/02/17 01:34:11 INFO BlockManagerInfo: Removed broadcast_13_piece0 on localhost:35117 in memory (size: 29.4 KiB, free: 912.1 MiB)
21/02/17 01:34:11 INFO BlockManagerInfo: Removed broadcast_17_piece0 on localhost:35117 in memory (size: 4.2 KiB, free: 912.1 MiB)
21/02/17 01:34:11 INFO BlockManagerInfo: Removed broadcast_11_piece0 on localhost:35117 in memory (size: 5.0 KiB, free: 912.1 MiB)
21/02/17 01:34:11 INFO BlockManagerInfo: Removed broadcast_10_piece0 on localhost:35117 in memory (size: 5.2 KiB, free: 912.1 MiB)
21/02/17 01:34:11 INFO BlockManagerInfo: Removed broadcast_15_piece0 on localhost:35117 in memory (size: 29.9 KiB, free: 912.2 MiB)
21/02/17 01:34:11 INFO BlockManagerInfo: Removed broadcast_16_piece0 on localhost:35117 in memory (size: 29.9 KiB, free: 912.2 MiB)
21/02/17 01:34:11 INFO BlockManagerInfo: Removed broadcast_14_piece0 on localhost:35117 in memory (size: 5.0 KiB, free: 912.2 MiB)
21/02/17 01:34:11 INFO BlockManagerInfo: Removed broadcast_12_piece0 on localhost:35117 in memory (size: 28.2 KiB, free: 912.2 MiB)
21/02/17 01:34:11 INFO FileOutputCommitter: Saved output of task 'attempt_20210217013411_0017_m_000000_17' to file:/tmp/RtmpE1GwT4/file220626098807e/stages/0_r_formula__05ea37d3_e6ba_4801_96be_09a4389f822b/data
21/02/17 01:34:11 INFO SparkHadoopMapRedUtil: attempt_20210217013411_0017_m_000000_17: Committed
21/02/17 01:34:11 INFO Executor: Finished task 0.0 in stage 17.0 (TID 17). 3281 bytes result sent to driver
21/02/17 01:34:11 INFO TaskSetManager: Finished task 0.0 in stage 17.0 (TID 17) in 547 ms on localhost (executor driver) (1/1)
21/02/17 01:34:11 INFO TaskSchedulerImpl: Removed TaskSet 17.0, whose tasks have all completed, from pool 
21/02/17 01:34:11 INFO DAGScheduler: ResultStage 17 (parquet at RFormula.scala:434) finished in 0.565 s
21/02/17 01:34:11 INFO DAGScheduler: Job 13 is finished. Cancelling potential speculative or zombie tasks for this job
21/02/17 01:34:11 INFO TaskSchedulerImpl: Killing all running tasks in stage 17: Stage finished
21/02/17 01:34:11 INFO DAGScheduler: Job 13 finished: parquet at RFormula.scala:434, took 0.582315 s
21/02/17 01:34:11 INFO FileFormatWriter: Write Job 5c81d673-a0d9-4ad1-9ede-6fc73600868d committed.
21/02/17 01:34:11 INFO FileFormatWriter: Finished processing stats for write job 5c81d673-a0d9-4ad1-9ede-6fc73600868d.
21/02/17 01:34:11 INFO HadoopMapRedCommitProtocol: Using output committer class org.apache.hadoop.mapred.FileOutputCommitter
21/02/17 01:34:11 INFO FileOutputCommitter: File Output Committer Algorithm version is 2
21/02/17 01:34:11 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
21/02/17 01:34:11 INFO SparkContext: Starting job: runJob at SparkHadoopWriter.scala:78
21/02/17 01:34:11 INFO DAGScheduler: Got job 14 (runJob at SparkHadoopWriter.scala:78) with 1 output partitions
21/02/17 01:34:11 INFO DAGScheduler: Final stage: ResultStage 18 (runJob at SparkHadoopWriter.scala:78)
21/02/17 01:34:11 INFO DAGScheduler: Parents of final stage: List()
21/02/17 01:34:11 INFO DAGScheduler: Missing parents: List()
21/02/17 01:34:11 INFO DAGScheduler: Submitting ResultStage 18 (MapPartitionsRDD[66] at saveAsTextFile at ReadWrite.scala:413), which has no missing parents
21/02/17 01:34:11 INFO MemoryStore: Block broadcast_19 stored as values in memory (estimated size 84.1 KiB, free 912.0 MiB)
21/02/17 01:34:11 INFO MemoryStore: Block broadcast_19_piece0 stored as bytes in memory (estimated size 30.0 KiB, free 911.9 MiB)
21/02/17 01:34:11 INFO BlockManagerInfo: Added broadcast_19_piece0 in memory on localhost:35117 (size: 30.0 KiB, free: 912.2 MiB)
21/02/17 01:34:11 INFO SparkContext: Created broadcast 19 from broadcast at DAGScheduler.scala:1200
21/02/17 01:34:11 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 18 (MapPartitionsRDD[66] at saveAsTextFile at ReadWrite.scala:413) (first 15 tasks are for partitions Vector(0))
21/02/17 01:34:11 INFO TaskSchedulerImpl: Adding task set 18.0 with 1 tasks
21/02/17 01:34:11 INFO TaskSetManager: Starting task 0.0 in stage 18.0 (TID 18, localhost, executor driver, partition 0, PROCESS_LOCAL, 7662 bytes)
21/02/17 01:34:11 INFO Executor: Running task 0.0 in stage 18.0 (TID 18)
21/02/17 01:34:11 INFO HadoopMapRedCommitProtocol: Using output committer class org.apache.hadoop.mapred.FileOutputCommitter
21/02/17 01:34:11 INFO FileOutputCommitter: File Output Committer Algorithm version is 2
21/02/17 01:34:11 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
21/02/17 01:34:11 INFO FileOutputCommitter: Saved output of task 'attempt_20210217013411_0066_m_000000_0' to file:/tmp/RtmpE1GwT4/file220626098807e/stages/0_r_formula__05ea37d3_e6ba_4801_96be_09a4389f822b/pipelineModel/metadata
21/02/17 01:34:11 INFO SparkHadoopMapRedUtil: attempt_20210217013411_0066_m_000000_0: Committed
21/02/17 01:34:11 INFO Executor: Finished task 0.0 in stage 18.0 (TID 18). 1158 bytes result sent to driver
21/02/17 01:34:11 INFO TaskSetManager: Finished task 0.0 in stage 18.0 (TID 18) in 21 ms on localhost (executor driver) (1/1)
21/02/17 01:34:11 INFO TaskSchedulerImpl: Removed TaskSet 18.0, whose tasks have all completed, from pool 
21/02/17 01:34:11 INFO DAGScheduler: ResultStage 18 (runJob at SparkHadoopWriter.scala:78) finished in 0.032 s
21/02/17 01:34:11 INFO DAGScheduler: Job 14 is finished. Cancelling potential speculative or zombie tasks for this job
21/02/17 01:34:11 INFO TaskSchedulerImpl: Killing all running tasks in stage 18: Stage finished
21/02/17 01:34:11 INFO DAGScheduler: Job 14 finished: runJob at SparkHadoopWriter.scala:78, took 0.035360 s
21/02/17 01:34:11 INFO SparkHadoopWriter: Job job_20210217013411_0066 committed.
21/02/17 01:34:11 INFO HadoopMapRedCommitProtocol: Using output committer class org.apache.hadoop.mapred.FileOutputCommitter
21/02/17 01:34:11 INFO FileOutputCommitter: File Output Committer Algorithm version is 2
21/02/17 01:34:11 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
21/02/17 01:34:11 INFO SparkContext: Starting job: runJob at SparkHadoopWriter.scala:78
21/02/17 01:34:11 INFO DAGScheduler: Got job 15 (runJob at SparkHadoopWriter.scala:78) with 1 output partitions
21/02/17 01:34:11 INFO DAGScheduler: Final stage: ResultStage 19 (runJob at SparkHadoopWriter.scala:78)
21/02/17 01:34:11 INFO DAGScheduler: Parents of final stage: List()
21/02/17 01:34:11 INFO DAGScheduler: Missing parents: List()
21/02/17 01:34:11 INFO DAGScheduler: Submitting ResultStage 19 (MapPartitionsRDD[68] at saveAsTextFile at ReadWrite.scala:413), which has no missing parents
21/02/17 01:34:11 INFO MemoryStore: Block broadcast_20 stored as values in memory (estimated size 84.2 KiB, free 911.9 MiB)
21/02/17 01:34:11 INFO MemoryStore: Block broadcast_20_piece0 stored as bytes in memory (estimated size 30.0 KiB, free 911.8 MiB)
21/02/17 01:34:11 INFO BlockManagerInfo: Added broadcast_20_piece0 in memory on localhost:35117 (size: 30.0 KiB, free: 912.2 MiB)
21/02/17 01:34:11 INFO SparkContext: Created broadcast 20 from broadcast at DAGScheduler.scala:1200
21/02/17 01:34:11 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 19 (MapPartitionsRDD[68] at saveAsTextFile at ReadWrite.scala:413) (first 15 tasks are for partitions Vector(0))
21/02/17 01:34:11 INFO TaskSchedulerImpl: Adding task set 19.0 with 1 tasks
21/02/17 01:34:11 INFO TaskSetManager: Starting task 0.0 in stage 19.0 (TID 19, localhost, executor driver, partition 0, PROCESS_LOCAL, 7729 bytes)
21/02/17 01:34:11 INFO Executor: Running task 0.0 in stage 19.0 (TID 19)
21/02/17 01:34:11 INFO HadoopMapRedCommitProtocol: Using output committer class org.apache.hadoop.mapred.FileOutputCommitter
21/02/17 01:34:11 INFO FileOutputCommitter: File Output Committer Algorithm version is 2
21/02/17 01:34:11 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
21/02/17 01:34:11 INFO FileOutputCommitter: Saved output of task 'attempt_20210217013411_0068_m_000000_0' to file:/tmp/RtmpE1GwT4/file220626098807e/stages/0_r_formula__05ea37d3_e6ba_4801_96be_09a4389f822b/pipelineModel/stages/0_r_formula__05ea37d3_e6ba_4801_96be_09a4389f822b/metadata
21/02/17 01:34:11 INFO SparkHadoopMapRedUtil: attempt_20210217013411_0068_m_000000_0: Committed
21/02/17 01:34:11 INFO Executor: Finished task 0.0 in stage 19.0 (TID 19). 1158 bytes result sent to driver
21/02/17 01:34:11 INFO TaskSetManager: Finished task 0.0 in stage 19.0 (TID 19) in 21 ms on localhost (executor driver) (1/1)
21/02/17 01:34:11 INFO TaskSchedulerImpl: Removed TaskSet 19.0, whose tasks have all completed, from pool 
21/02/17 01:34:11 INFO DAGScheduler: ResultStage 19 (runJob at SparkHadoopWriter.scala:78) finished in 0.032 s
21/02/17 01:34:11 INFO DAGScheduler: Job 15 is finished. Cancelling potential speculative or zombie tasks for this job
21/02/17 01:34:11 INFO TaskSchedulerImpl: Killing all running tasks in stage 19: Stage finished
21/02/17 01:34:11 INFO DAGScheduler: Job 15 finished: runJob at SparkHadoopWriter.scala:78, took 0.034141 s
21/02/17 01:34:11 INFO SparkHadoopWriter: Job job_20210217013411_0068 committed.
21/02/17 01:34:11 INFO HadoopMapRedCommitProtocol: Using output committer class org.apache.hadoop.mapred.FileOutputCommitter
21/02/17 01:34:11 INFO FileOutputCommitter: File Output Committer Algorithm version is 2
21/02/17 01:34:11 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
21/02/17 01:34:11 INFO SparkContext: Starting job: runJob at SparkHadoopWriter.scala:78
21/02/17 01:34:11 INFO DAGScheduler: Got job 16 (runJob at SparkHadoopWriter.scala:78) with 1 output partitions
21/02/17 01:34:11 INFO DAGScheduler: Final stage: ResultStage 20 (runJob at SparkHadoopWriter.scala:78)
21/02/17 01:34:11 INFO DAGScheduler: Parents of final stage: List()
21/02/17 01:34:11 INFO DAGScheduler: Missing parents: List()
21/02/17 01:34:11 INFO DAGScheduler: Submitting ResultStage 20 (MapPartitionsRDD[70] at saveAsTextFile at ReadWrite.scala:413), which has no missing parents
21/02/17 01:34:11 INFO MemoryStore: Block broadcast_21 stored as values in memory (estimated size 84.1 KiB, free 911.8 MiB)
21/02/17 01:34:11 INFO MemoryStore: Block broadcast_21_piece0 stored as bytes in memory (estimated size 30.0 KiB, free 911.7 MiB)
21/02/17 01:34:11 INFO BlockManagerInfo: Added broadcast_21_piece0 in memory on localhost:35117 (size: 30.0 KiB, free: 912.1 MiB)
21/02/17 01:34:11 INFO SparkContext: Created broadcast 21 from broadcast at DAGScheduler.scala:1200
21/02/17 01:34:11 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 20 (MapPartitionsRDD[70] at saveAsTextFile at ReadWrite.scala:413) (first 15 tasks are for partitions Vector(0))
21/02/17 01:34:11 INFO TaskSchedulerImpl: Adding task set 20.0 with 1 tasks
21/02/17 01:34:11 INFO TaskSetManager: Starting task 0.0 in stage 20.0 (TID 20, localhost, executor driver, partition 0, PROCESS_LOCAL, 7539 bytes)
21/02/17 01:34:11 INFO Executor: Running task 0.0 in stage 20.0 (TID 20)
21/02/17 01:34:11 INFO HadoopMapRedCommitProtocol: Using output committer class org.apache.hadoop.mapred.FileOutputCommitter
21/02/17 01:34:11 INFO FileOutputCommitter: File Output Committer Algorithm version is 2
21/02/17 01:34:11 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
21/02/17 01:34:11 INFO FileOutputCommitter: Saved output of task 'attempt_20210217013411_0070_m_000000_0' to file:/tmp/RtmpE1GwT4/file220626098807e/stages/0_r_formula__05ea37d3_e6ba_4801_96be_09a4389f822b/pipelineModel/stages/1_vectorAttrRewriter_265a52885b23/metadata
21/02/17 01:34:11 INFO SparkHadoopMapRedUtil: attempt_20210217013411_0070_m_000000_0: Committed
21/02/17 01:34:11 INFO Executor: Finished task 0.0 in stage 20.0 (TID 20). 1158 bytes result sent to driver
21/02/17 01:34:11 INFO TaskSetManager: Finished task 0.0 in stage 20.0 (TID 20) in 19 ms on localhost (executor driver) (1/1)
21/02/17 01:34:11 INFO TaskSchedulerImpl: Removed TaskSet 20.0, whose tasks have all completed, from pool 
21/02/17 01:34:11 INFO DAGScheduler: ResultStage 20 (runJob at SparkHadoopWriter.scala:78) finished in 0.029 s
21/02/17 01:34:11 INFO DAGScheduler: Job 16 is finished. Cancelling potential speculative or zombie tasks for this job
21/02/17 01:34:11 INFO TaskSchedulerImpl: Killing all running tasks in stage 20: Stage finished
21/02/17 01:34:11 INFO DAGScheduler: Job 16 finished: runJob at SparkHadoopWriter.scala:78, took 0.030822 s
21/02/17 01:34:11 INFO SparkHadoopWriter: Job job_20210217013411_0070 committed.
21/02/17 01:34:11 INFO ParquetFileFormat: Using default output committer for Parquet: org.apache.parquet.hadoop.ParquetOutputCommitter
21/02/17 01:34:11 INFO FileOutputCommitter: File Output Committer Algorithm version is 2
21/02/17 01:34:11 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
21/02/17 01:34:11 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
21/02/17 01:34:11 INFO FileOutputCommitter: File Output Committer Algorithm version is 2
21/02/17 01:34:11 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
21/02/17 01:34:11 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
21/02/17 01:34:11 INFO CodeGenerator: Code generated in 11.047091 ms
21/02/17 01:34:11 INFO SparkContext: Starting job: parquet at RFormula.scala:599
21/02/17 01:34:11 INFO DAGScheduler: Registering RDD 73 (parquet at RFormula.scala:599) as input to shuffle 5
21/02/17 01:34:11 INFO DAGScheduler: Got job 17 (parquet at RFormula.scala:599) with 1 output partitions
21/02/17 01:34:11 INFO DAGScheduler: Final stage: ResultStage 22 (parquet at RFormula.scala:599)
21/02/17 01:34:11 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 21)
21/02/17 01:34:11 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 21)
21/02/17 01:34:11 INFO DAGScheduler: Submitting ShuffleMapStage 21 (MapPartitionsRDD[73] at parquet at RFormula.scala:599), which has no missing parents
21/02/17 01:34:11 INFO MemoryStore: Block broadcast_22 stored as values in memory (estimated size 7.7 KiB, free 911.7 MiB)
21/02/17 01:34:11 INFO MemoryStore: Block broadcast_22_piece0 stored as bytes in memory (estimated size 4.2 KiB, free 911.7 MiB)
21/02/17 01:34:11 INFO BlockManagerInfo: Added broadcast_22_piece0 in memory on localhost:35117 (size: 4.2 KiB, free: 912.1 MiB)
21/02/17 01:34:11 INFO SparkContext: Created broadcast 22 from broadcast at DAGScheduler.scala:1200
21/02/17 01:34:11 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 21 (MapPartitionsRDD[73] at parquet at RFormula.scala:599) (first 15 tasks are for partitions Vector(0))
21/02/17 01:34:11 INFO TaskSchedulerImpl: Adding task set 21.0 with 1 tasks
21/02/17 01:34:11 INFO TaskSetManager: Starting task 0.0 in stage 21.0 (TID 21, localhost, executor driver, partition 0, PROCESS_LOCAL, 7554 bytes)
21/02/17 01:34:11 INFO Executor: Running task 0.0 in stage 21.0 (TID 21)
21/02/17 01:34:11 INFO Executor: Finished task 0.0 in stage 21.0 (TID 21). 1614 bytes result sent to driver
21/02/17 01:34:11 INFO TaskSetManager: Finished task 0.0 in stage 21.0 (TID 21) in 4 ms on localhost (executor driver) (1/1)
21/02/17 01:34:11 INFO TaskSchedulerImpl: Removed TaskSet 21.0, whose tasks have all completed, from pool 
21/02/17 01:34:11 INFO DAGScheduler: ShuffleMapStage 21 (parquet at RFormula.scala:599) finished in 0.009 s
21/02/17 01:34:11 INFO DAGScheduler: looking for newly runnable stages
21/02/17 01:34:11 INFO DAGScheduler: running: Set()
21/02/17 01:34:11 INFO DAGScheduler: waiting: Set(ResultStage 22)
21/02/17 01:34:11 INFO DAGScheduler: failed: Set()
21/02/17 01:34:11 INFO DAGScheduler: Submitting ResultStage 22 (ShuffledRowRDD[74] at parquet at RFormula.scala:599), which has no missing parents
21/02/17 01:34:11 INFO MemoryStore: Block broadcast_23 stored as values in memory (estimated size 177.6 KiB, free 911.5 MiB)
21/02/17 01:34:11 INFO MemoryStore: Block broadcast_23_piece0 stored as bytes in memory (estimated size 62.2 KiB, free 911.5 MiB)
21/02/17 01:34:11 INFO BlockManagerInfo: Added broadcast_23_piece0 in memory on localhost:35117 (size: 62.2 KiB, free: 912.1 MiB)
21/02/17 01:34:11 INFO SparkContext: Created broadcast 23 from broadcast at DAGScheduler.scala:1200
21/02/17 01:34:11 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 22 (ShuffledRowRDD[74] at parquet at RFormula.scala:599) (first 15 tasks are for partitions Vector(0))
21/02/17 01:34:11 INFO TaskSchedulerImpl: Adding task set 22.0 with 1 tasks
21/02/17 01:34:11 INFO TaskSetManager: Starting task 0.0 in stage 22.0 (TID 22, localhost, executor driver, partition 0, NODE_LOCAL, 7325 bytes)
21/02/17 01:34:11 INFO Executor: Running task 0.0 in stage 22.0 (TID 22)
21/02/17 01:34:11 INFO ShuffleBlockFetcherIterator: Getting 1 (88.0 B) non-empty blocks including 1 (88.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
21/02/17 01:34:11 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
21/02/17 01:34:11 INFO FileOutputCommitter: File Output Committer Algorithm version is 2
21/02/17 01:34:11 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
21/02/17 01:34:11 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
21/02/17 01:34:11 INFO FileOutputCommitter: File Output Committer Algorithm version is 2
21/02/17 01:34:11 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
21/02/17 01:34:11 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
21/02/17 01:34:11 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:
{
  "type" : "struct",
  "fields" : [ {
    "name" : "vectorCol",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "prefixesToRewrite",
    "type" : {
      "type" : "map",
      "keyType" : "string",
      "valueType" : "string",
      "valueContainsNull" : true
    },
    "nullable" : true,
    "metadata" : { }
  } ]
}
and corresponding Parquet message type:
message spark_schema {
  optional binary vectorCol (UTF8);
  optional group prefixesToRewrite (MAP) {
    repeated group key_value {
      required binary key (UTF8);
      optional binary value (UTF8);
    }
  }
}

       
21/02/17 01:34:12 INFO FileOutputCommitter: Saved output of task 'attempt_20210217013411_0022_m_000000_22' to file:/tmp/RtmpE1GwT4/file220626098807e/stages/0_r_formula__05ea37d3_e6ba_4801_96be_09a4389f822b/pipelineModel/stages/1_vectorAttrRewriter_265a52885b23/data
21/02/17 01:34:12 INFO SparkHadoopMapRedUtil: attempt_20210217013411_0022_m_000000_22: Committed
21/02/17 01:34:12 INFO Executor: Finished task 0.0 in stage 22.0 (TID 22). 3195 bytes result sent to driver
21/02/17 01:34:12 INFO TaskSetManager: Finished task 0.0 in stage 22.0 (TID 22) in 33 ms on localhost (executor driver) (1/1)
21/02/17 01:34:12 INFO TaskSchedulerImpl: Removed TaskSet 22.0, whose tasks have all completed, from pool 
21/02/17 01:34:12 INFO DAGScheduler: ResultStage 22 (parquet at RFormula.scala:599) finished in 0.057 s
21/02/17 01:34:12 INFO DAGScheduler: Job 17 is finished. Cancelling potential speculative or zombie tasks for this job
21/02/17 01:34:12 INFO TaskSchedulerImpl: Killing all running tasks in stage 22: Stage finished
21/02/17 01:34:12 INFO DAGScheduler: Job 17 finished: parquet at RFormula.scala:599, took 0.071558 s
21/02/17 01:34:12 INFO FileFormatWriter: Write Job 66a0e995-375a-46d4-9b64-8091c6a1b502 committed.
21/02/17 01:34:12 INFO FileFormatWriter: Finished processing stats for write job 66a0e995-375a-46d4-9b64-8091c6a1b502.
21/02/17 01:34:12 INFO HadoopMapRedCommitProtocol: Using output committer class org.apache.hadoop.mapred.FileOutputCommitter
21/02/17 01:34:12 INFO FileOutputCommitter: File Output Committer Algorithm version is 2
21/02/17 01:34:12 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
21/02/17 01:34:12 INFO SparkContext: Starting job: runJob at SparkHadoopWriter.scala:78
21/02/17 01:34:12 INFO DAGScheduler: Got job 18 (runJob at SparkHadoopWriter.scala:78) with 1 output partitions
21/02/17 01:34:12 INFO DAGScheduler: Final stage: ResultStage 23 (runJob at SparkHadoopWriter.scala:78)
21/02/17 01:34:12 INFO DAGScheduler: Parents of final stage: List()
21/02/17 01:34:12 INFO DAGScheduler: Missing parents: List()
21/02/17 01:34:12 INFO DAGScheduler: Submitting ResultStage 23 (MapPartitionsRDD[78] at saveAsTextFile at ReadWrite.scala:413), which has no missing parents
21/02/17 01:34:12 INFO MemoryStore: Block broadcast_24 stored as values in memory (estimated size 84.1 KiB, free 911.4 MiB)
21/02/17 01:34:12 INFO MemoryStore: Block broadcast_24_piece0 stored as bytes in memory (estimated size 30.0 KiB, free 911.4 MiB)
21/02/17 01:34:12 INFO BlockManagerInfo: Added broadcast_24_piece0 in memory on localhost:35117 (size: 30.0 KiB, free: 912.1 MiB)
21/02/17 01:34:12 INFO SparkContext: Created broadcast 24 from broadcast at DAGScheduler.scala:1200
21/02/17 01:34:12 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 23 (MapPartitionsRDD[78] at saveAsTextFile at ReadWrite.scala:413) (first 15 tasks are for partitions Vector(0))
21/02/17 01:34:12 INFO TaskSchedulerImpl: Adding task set 23.0 with 1 tasks
21/02/17 01:34:12 INFO TaskSetManager: Starting task 0.0 in stage 23.0 (TID 23, localhost, executor driver, partition 0, PROCESS_LOCAL, 7522 bytes)
21/02/17 01:34:12 INFO Executor: Running task 0.0 in stage 23.0 (TID 23)
21/02/17 01:34:12 INFO HadoopMapRedCommitProtocol: Using output committer class org.apache.hadoop.mapred.FileOutputCommitter
21/02/17 01:34:12 INFO FileOutputCommitter: File Output Committer Algorithm version is 2
21/02/17 01:34:12 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
21/02/17 01:34:12 INFO FileOutputCommitter: Saved output of task 'attempt_20210217013412_0078_m_000000_0' to file:/tmp/RtmpE1GwT4/file220626098807e/stages/0_r_formula__05ea37d3_e6ba_4801_96be_09a4389f822b/pipelineModel/stages/2_columnPruner_bce5020be839/metadata
21/02/17 01:34:12 INFO SparkHadoopMapRedUtil: attempt_20210217013412_0078_m_000000_0: Committed
21/02/17 01:34:12 INFO Executor: Finished task 0.0 in stage 23.0 (TID 23). 1158 bytes result sent to driver
21/02/17 01:34:12 INFO TaskSetManager: Finished task 0.0 in stage 23.0 (TID 23) in 14 ms on localhost (executor driver) (1/1)
21/02/17 01:34:12 INFO TaskSchedulerImpl: Removed TaskSet 23.0, whose tasks have all completed, from pool 
21/02/17 01:34:12 INFO DAGScheduler: ResultStage 23 (runJob at SparkHadoopWriter.scala:78) finished in 0.027 s
21/02/17 01:34:12 INFO DAGScheduler: Job 18 is finished. Cancelling potential speculative or zombie tasks for this job
21/02/17 01:34:12 INFO TaskSchedulerImpl: Killing all running tasks in stage 23: Stage finished
21/02/17 01:34:12 INFO DAGScheduler: Job 18 finished: runJob at SparkHadoopWriter.scala:78, took 0.030077 s
21/02/17 01:34:12 INFO SparkHadoopWriter: Job job_20210217013412_0078 committed.
21/02/17 01:34:12 INFO ParquetFileFormat: Using default output committer for Parquet: org.apache.parquet.hadoop.ParquetOutputCommitter
21/02/17 01:34:12 INFO FileOutputCommitter: File Output Committer Algorithm version is 2
21/02/17 01:34:12 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
21/02/17 01:34:12 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
21/02/17 01:34:12 INFO FileOutputCommitter: File Output Committer Algorithm version is 2
21/02/17 01:34:12 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
21/02/17 01:34:12 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
21/02/17 01:34:12 INFO CodeGenerator: Code generated in 6.250088 ms
21/02/17 01:34:12 INFO SparkContext: Starting job: parquet at RFormula.scala:508
21/02/17 01:34:12 INFO DAGScheduler: Registering RDD 81 (parquet at RFormula.scala:508) as input to shuffle 6
21/02/17 01:34:12 INFO DAGScheduler: Got job 19 (parquet at RFormula.scala:508) with 1 output partitions
21/02/17 01:34:12 INFO DAGScheduler: Final stage: ResultStage 25 (parquet at RFormula.scala:508)
21/02/17 01:34:12 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 24)
21/02/17 01:34:12 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 24)
21/02/17 01:34:12 INFO DAGScheduler: Submitting ShuffleMapStage 24 (MapPartitionsRDD[81] at parquet at RFormula.scala:508), which has no missing parents
21/02/17 01:34:12 INFO MemoryStore: Block broadcast_25 stored as values in memory (estimated size 7.6 KiB, free 911.4 MiB)
21/02/17 01:34:12 INFO MemoryStore: Block broadcast_25_piece0 stored as bytes in memory (estimated size 4.1 KiB, free 911.4 MiB)
21/02/17 01:34:12 INFO BlockManagerInfo: Added broadcast_25_piece0 in memory on localhost:35117 (size: 4.1 KiB, free: 912.0 MiB)
21/02/17 01:34:12 INFO SparkContext: Created broadcast 25 from broadcast at DAGScheduler.scala:1200
21/02/17 01:34:12 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 24 (MapPartitionsRDD[81] at parquet at RFormula.scala:508) (first 15 tasks are for partitions Vector(0))
21/02/17 01:34:12 INFO TaskSchedulerImpl: Adding task set 24.0 with 1 tasks
21/02/17 01:34:12 INFO TaskSetManager: Starting task 0.0 in stage 24.0 (TID 24, localhost, executor driver, partition 0, PROCESS_LOCAL, 7522 bytes)
21/02/17 01:34:12 INFO Executor: Running task 0.0 in stage 24.0 (TID 24)
21/02/17 01:34:12 INFO Executor: Finished task 0.0 in stage 24.0 (TID 24). 1614 bytes result sent to driver
21/02/17 01:34:12 INFO TaskSetManager: Finished task 0.0 in stage 24.0 (TID 24) in 4 ms on localhost (executor driver) (1/1)
21/02/17 01:34:12 INFO TaskSchedulerImpl: Removed TaskSet 24.0, whose tasks have all completed, from pool 
21/02/17 01:34:12 INFO DAGScheduler: ShuffleMapStage 24 (parquet at RFormula.scala:508) finished in 0.010 s
21/02/17 01:34:12 INFO DAGScheduler: looking for newly runnable stages
21/02/17 01:34:12 INFO DAGScheduler: running: Set()
21/02/17 01:34:12 INFO DAGScheduler: waiting: Set(ResultStage 25)
21/02/17 01:34:12 INFO DAGScheduler: failed: Set()
21/02/17 01:34:12 INFO DAGScheduler: Submitting ResultStage 25 (ShuffledRowRDD[82] at parquet at RFormula.scala:508), which has no missing parents
21/02/17 01:34:12 INFO MemoryStore: Block broadcast_26 stored as values in memory (estimated size 177.4 KiB, free 911.2 MiB)
21/02/17 01:34:12 INFO MemoryStore: Block broadcast_26_piece0 stored as bytes in memory (estimated size 62.0 KiB, free 911.1 MiB)
21/02/17 01:34:12 INFO BlockManagerInfo: Added broadcast_26_piece0 in memory on localhost:35117 (size: 62.0 KiB, free: 912.0 MiB)
21/02/17 01:34:12 INFO SparkContext: Created broadcast 26 from broadcast at DAGScheduler.scala:1200
21/02/17 01:34:12 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 25 (ShuffledRowRDD[82] at parquet at RFormula.scala:508) (first 15 tasks are for partitions Vector(0))
21/02/17 01:34:12 INFO TaskSchedulerImpl: Adding task set 25.0 with 1 tasks
21/02/17 01:34:12 INFO TaskSetManager: Starting task 0.0 in stage 25.0 (TID 25, localhost, executor driver, partition 0, NODE_LOCAL, 7325 bytes)
21/02/17 01:34:12 INFO Executor: Running task 0.0 in stage 25.0 (TID 25)
21/02/17 01:34:12 INFO ShuffleBlockFetcherIterator: Getting 1 (72.0 B) non-empty blocks including 1 (72.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
21/02/17 01:34:12 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
21/02/17 01:34:12 INFO FileOutputCommitter: File Output Committer Algorithm version is 2
21/02/17 01:34:12 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
21/02/17 01:34:12 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
21/02/17 01:34:12 INFO FileOutputCommitter: File Output Committer Algorithm version is 2
21/02/17 01:34:12 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
21/02/17 01:34:12 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
21/02/17 01:34:12 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:
{
  "type" : "struct",
  "fields" : [ {
    "name" : "columnsToPrune",
    "type" : {
      "type" : "array",
      "elementType" : "string",
      "containsNull" : true
    },
    "nullable" : true,
    "metadata" : { }
  } ]
}
and corresponding Parquet message type:
message spark_schema {
  optional group columnsToPrune (LIST) {
    repeated group list {
      optional binary element (UTF8);
    }
  }
}

       
21/02/17 01:34:12 INFO FileOutputCommitter: Saved output of task 'attempt_20210217013412_0025_m_000000_25' to file:/tmp/RtmpE1GwT4/file220626098807e/stages/0_r_formula__05ea37d3_e6ba_4801_96be_09a4389f822b/pipelineModel/stages/2_columnPruner_bce5020be839/data
21/02/17 01:34:12 INFO SparkHadoopMapRedUtil: attempt_20210217013412_0025_m_000000_25: Committed
21/02/17 01:34:12 INFO Executor: Finished task 0.0 in stage 25.0 (TID 25). 3195 bytes result sent to driver
21/02/17 01:34:12 INFO TaskSetManager: Finished task 0.0 in stage 25.0 (TID 25) in 21 ms on localhost (executor driver) (1/1)
21/02/17 01:34:12 INFO TaskSchedulerImpl: Removed TaskSet 25.0, whose tasks have all completed, from pool 
21/02/17 01:34:12 INFO DAGScheduler: ResultStage 25 (parquet at RFormula.scala:508) finished in 0.037 s
21/02/17 01:34:12 INFO DAGScheduler: Job 19 is finished. Cancelling potential speculative or zombie tasks for this job
21/02/17 01:34:12 INFO TaskSchedulerImpl: Killing all running tasks in stage 25: Stage finished
21/02/17 01:34:12 INFO DAGScheduler: Job 19 finished: parquet at RFormula.scala:508, took 0.050350 s
21/02/17 01:34:12 INFO FileFormatWriter: Write Job e16c944d-40c5-4619-a473-815c44a3ac8c committed.
21/02/17 01:34:12 INFO FileFormatWriter: Finished processing stats for write job e16c944d-40c5-4619-a473-815c44a3ac8c.
21/02/17 01:34:12 INFO Instrumentation: [90737cb9] training finished
21/02/17 01:34:12 INFO Instrumentation: [17652cf5] training finished
21/02/17 01:34:12 INFO HadoopMapRedCommitProtocol: Using output committer class org.apache.hadoop.mapred.FileOutputCommitter
21/02/17 01:34:12 INFO FileOutputCommitter: File Output Committer Algorithm version is 2
21/02/17 01:34:12 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
21/02/17 01:34:12 INFO SparkContext: Starting job: runJob at SparkHadoopWriter.scala:78
21/02/17 01:34:12 INFO DAGScheduler: Got job 20 (runJob at SparkHadoopWriter.scala:78) with 1 output partitions
21/02/17 01:34:12 INFO DAGScheduler: Final stage: ResultStage 26 (runJob at SparkHadoopWriter.scala:78)
21/02/17 01:34:12 INFO DAGScheduler: Parents of final stage: List()
21/02/17 01:34:12 INFO DAGScheduler: Missing parents: List()
21/02/17 01:34:12 INFO DAGScheduler: Submitting ResultStage 26 (MapPartitionsRDD[86] at saveAsTextFile at DefaultXGBoostParamsWriter.scala:52), which has no missing parents
21/02/17 01:34:12 INFO MemoryStore: Block broadcast_27 stored as values in memory (estimated size 84.0 KiB, free 911.0 MiB)
21/02/17 01:34:12 INFO MemoryStore: Block broadcast_27_piece0 stored as bytes in memory (estimated size 30.0 KiB, free 911.0 MiB)
21/02/17 01:34:12 INFO BlockManagerInfo: Added broadcast_27_piece0 in memory on localhost:35117 (size: 30.0 KiB, free: 912.0 MiB)
21/02/17 01:34:12 INFO SparkContext: Created broadcast 27 from broadcast at DAGScheduler.scala:1200
21/02/17 01:34:12 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 26 (MapPartitionsRDD[86] at saveAsTextFile at DefaultXGBoostParamsWriter.scala:52) (first 15 tasks are for partitions Vector(0))
21/02/17 01:34:12 INFO TaskSchedulerImpl: Adding task set 26.0 with 1 tasks
21/02/17 01:34:12 INFO TaskSetManager: Starting task 0.0 in stage 26.0 (TID 26, localhost, executor driver, partition 0, PROCESS_LOCAL, 8635 bytes)
21/02/17 01:34:12 INFO Executor: Running task 0.0 in stage 26.0 (TID 26)
21/02/17 01:34:12 INFO HadoopMapRedCommitProtocol: Using output committer class org.apache.hadoop.mapred.FileOutputCommitter
21/02/17 01:34:12 INFO FileOutputCommitter: File Output Committer Algorithm version is 2
21/02/17 01:34:12 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
21/02/17 01:34:12 INFO FileOutputCommitter: Saved output of task 'attempt_20210217013412_0086_m_000000_0' to file:/tmp/RtmpE1GwT4/file220626098807e/stages/1_xgboost_regressor__3f160205_3c69_46f1_9170_a41f0585fc45/metadata
21/02/17 01:34:12 INFO SparkHadoopMapRedUtil: attempt_20210217013412_0086_m_000000_0: Committed
21/02/17 01:34:12 INFO Executor: Finished task 0.0 in stage 26.0 (TID 26). 1158 bytes result sent to driver
21/02/17 01:34:12 INFO TaskSetManager: Finished task 0.0 in stage 26.0 (TID 26) in 17 ms on localhost (executor driver) (1/1)
21/02/17 01:34:12 INFO TaskSchedulerImpl: Removed TaskSet 26.0, whose tasks have all completed, from pool 
21/02/17 01:34:12 INFO DAGScheduler: ResultStage 26 (runJob at SparkHadoopWriter.scala:78) finished in 0.026 s
21/02/17 01:34:12 INFO DAGScheduler: Job 20 is finished. Cancelling potential speculative or zombie tasks for this job
21/02/17 01:34:12 INFO TaskSchedulerImpl: Killing all running tasks in stage 26: Stage finished
21/02/17 01:34:12 INFO DAGScheduler: Job 20 finished: runJob at SparkHadoopWriter.scala:78, took 0.028897 s
21/02/17 01:34:12 INFO SparkHadoopWriter: Job job_20210217013412_0086 committed.
21/02/17 01:34:12 INFO Instrumentation: [09cb654e] training finished
21/02/17 01:34:12 INFO Instrumentation: [2886b196] training finished
21/02/17 01:34:12 INFO HiveMetaStore: 0: get_database: default
21/02/17 01:34:12 INFO audit: ugi=yitaoli	ip=unknown-ip-addr	cmd=get_database: default	
21/02/17 01:34:12 INFO HiveMetaStore: 0: get_database: default
21/02/17 01:34:12 INFO audit: ugi=yitaoli	ip=unknown-ip-addr	cmd=get_database: default	
21/02/17 01:34:12 INFO HiveMetaStore: 0: get_tables: db=default pat=*
21/02/17 01:34:12 INFO audit: ugi=yitaoli	ip=unknown-ip-addr	cmd=get_tables: db=default pat=*	
21/02/17 01:34:12 INFO CodeGenerator: Code generated in 4.511433 ms
21/02/17 01:34:12 INFO SparkContext: Starting job: collect at utils.scala:54
21/02/17 01:34:12 INFO DAGScheduler: Got job 21 (collect at utils.scala:54) with 2 output partitions
21/02/17 01:34:12 INFO DAGScheduler: Final stage: ResultStage 27 (collect at utils.scala:54)
21/02/17 01:34:12 INFO DAGScheduler: Parents of final stage: List()
21/02/17 01:34:12 INFO DAGScheduler: Missing parents: List()
21/02/17 01:34:12 INFO DAGScheduler: Submitting ResultStage 27 (MapPartitionsRDD[92] at map at utils.scala:54), which has no missing parents
21/02/17 01:34:12 INFO MemoryStore: Block broadcast_28 stored as values in memory (estimated size 12.0 KiB, free 911.0 MiB)
21/02/17 01:34:12 INFO MemoryStore: Block broadcast_28_piece0 stored as bytes in memory (estimated size 5.1 KiB, free 911.0 MiB)
21/02/17 01:34:12 INFO BlockManagerInfo: Added broadcast_28_piece0 in memory on localhost:35117 (size: 5.1 KiB, free: 912.0 MiB)
21/02/17 01:34:12 INFO SparkContext: Created broadcast 28 from broadcast at DAGScheduler.scala:1200
21/02/17 01:34:12 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 27 (MapPartitionsRDD[92] at map at utils.scala:54) (first 15 tasks are for partitions Vector(0, 1))
21/02/17 01:34:12 INFO TaskSchedulerImpl: Adding task set 27.0 with 2 tasks
21/02/17 01:34:12 INFO TaskSetManager: Starting task 0.0 in stage 27.0 (TID 27, localhost, executor driver, partition 0, PROCESS_LOCAL, 7533 bytes)
21/02/17 01:34:12 INFO TaskSetManager: Starting task 1.0 in stage 27.0 (TID 28, localhost, executor driver, partition 1, PROCESS_LOCAL, 7581 bytes)
21/02/17 01:34:12 INFO Executor: Running task 0.0 in stage 27.0 (TID 27)
21/02/17 01:34:12 INFO Executor: Running task 1.0 in stage 27.0 (TID 28)
21/02/17 01:34:12 INFO CodeGenerator: Code generated in 5.519703 ms
21/02/17 01:34:12 INFO Executor: Finished task 1.0 in stage 27.0 (TID 28). 1155 bytes result sent to driver
21/02/17 01:34:12 INFO Executor: Finished task 0.0 in stage 27.0 (TID 27). 1110 bytes result sent to driver
21/02/17 01:34:12 INFO TaskSetManager: Finished task 1.0 in stage 27.0 (TID 28) in 29 ms on localhost (executor driver) (1/2)
21/02/17 01:34:12 INFO TaskSetManager: Finished task 0.0 in stage 27.0 (TID 27) in 29 ms on localhost (executor driver) (2/2)
21/02/17 01:34:12 INFO TaskSchedulerImpl: Removed TaskSet 27.0, whose tasks have all completed, from pool 
21/02/17 01:34:12 INFO DAGScheduler: ResultStage 27 (collect at utils.scala:54) finished in 0.032 s
21/02/17 01:34:12 INFO DAGScheduler: Job 21 is finished. Cancelling potential speculative or zombie tasks for this job
21/02/17 01:34:12 INFO TaskSchedulerImpl: Killing all running tasks in stage 27: Stage finished
21/02/17 01:34:12 INFO DAGScheduler: Job 21 finished: collect at utils.scala:54, took 0.035347 s
21/02/17 01:34:12 INFO InMemoryFileIndex: It took 7 ms to list leaf files for 1 paths.
21/02/17 01:34:12 INFO InMemoryFileIndex: It took 0 ms to list leaf files for 1 paths.
21/02/17 01:34:12 INFO FileSourceStrategy: Pruning directories with: 
21/02/17 01:34:12 INFO FileSourceStrategy: Pushed Filters: 
21/02/17 01:34:12 INFO FileSourceStrategy: Post-Scan Filters: 
21/02/17 01:34:12 INFO FileSourceStrategy: Output Data Schema: struct<value: string>
21/02/17 01:34:12 INFO MemoryStore: Block broadcast_29 stored as values in memory (estimated size 316.4 KiB, free 910.7 MiB)
21/02/17 01:34:12 INFO MemoryStore: Block broadcast_29_piece0 stored as bytes in memory (estimated size 28.9 KiB, free 910.7 MiB)
21/02/17 01:34:12 INFO BlockManagerInfo: Added broadcast_29_piece0 in memory on localhost:35117 (size: 28.9 KiB, free: 911.9 MiB)
21/02/17 01:34:12 INFO SparkContext: Created broadcast 29 from json at NativeMethodAccessorImpl.java:0
21/02/17 01:34:12 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
21/02/17 01:34:12 INFO SparkContext: Starting job: json at NativeMethodAccessorImpl.java:0
21/02/17 01:34:12 INFO DAGScheduler: Got job 22 (json at NativeMethodAccessorImpl.java:0) with 1 output partitions
21/02/17 01:34:12 INFO DAGScheduler: Final stage: ResultStage 28 (json at NativeMethodAccessorImpl.java:0)
21/02/17 01:34:12 INFO DAGScheduler: Parents of final stage: List()
21/02/17 01:34:12 INFO DAGScheduler: Missing parents: List()
21/02/17 01:34:12 INFO DAGScheduler: Submitting ResultStage 28 (MapPartitionsRDD[96] at json at NativeMethodAccessorImpl.java:0), which has no missing parents
21/02/17 01:34:12 INFO MemoryStore: Block broadcast_30 stored as values in memory (estimated size 15.6 KiB, free 910.6 MiB)
21/02/17 01:34:12 INFO MemoryStore: Block broadcast_30_piece0 stored as bytes in memory (estimated size 7.0 KiB, free 910.6 MiB)
21/02/17 01:34:12 INFO BlockManagerInfo: Added broadcast_30_piece0 in memory on localhost:35117 (size: 7.0 KiB, free: 911.9 MiB)
21/02/17 01:34:12 INFO SparkContext: Created broadcast 30 from broadcast at DAGScheduler.scala:1200
21/02/17 01:34:12 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 28 (MapPartitionsRDD[96] at json at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
21/02/17 01:34:12 INFO TaskSchedulerImpl: Adding task set 28.0 with 1 tasks
21/02/17 01:34:12 INFO TaskSetManager: Starting task 0.0 in stage 28.0 (TID 29, localhost, executor driver, partition 0, PROCESS_LOCAL, 7757 bytes)
21/02/17 01:34:12 INFO Executor: Running task 0.0 in stage 28.0 (TID 29)
21/02/17 01:34:12 INFO FileScanRDD: Reading File path: file:///tmp/RtmpE1GwT4/file220626098807e/metadata/part-00000, range: 0-306, partition values: [empty row]
21/02/17 01:34:12 INFO CodeGenerator: Code generated in 6.305175 ms
21/02/17 01:34:12 INFO Executor: Finished task 0.0 in stage 28.0 (TID 29). 2251 bytes result sent to driver
21/02/17 01:34:12 INFO TaskSetManager: Finished task 0.0 in stage 28.0 (TID 29) in 85 ms on localhost (executor driver) (1/1)
21/02/17 01:34:12 INFO TaskSchedulerImpl: Removed TaskSet 28.0, whose tasks have all completed, from pool 
21/02/17 01:34:12 INFO DAGScheduler: ResultStage 28 (json at NativeMethodAccessorImpl.java:0) finished in 0.092 s
21/02/17 01:34:12 INFO DAGScheduler: Job 22 is finished. Cancelling potential speculative or zombie tasks for this job
21/02/17 01:34:12 INFO TaskSchedulerImpl: Killing all running tasks in stage 28: Stage finished
21/02/17 01:34:12 INFO DAGScheduler: Job 22 finished: json at NativeMethodAccessorImpl.java:0, took 0.097023 s
21/02/17 01:34:12 INFO HiveMetaStore: 0: get_database: default
21/02/17 01:34:12 INFO audit: ugi=yitaoli	ip=unknown-ip-addr	cmd=get_database: default	
21/02/17 01:34:12 INFO HiveMetaStore: 0: get_database: default
21/02/17 01:34:12 INFO audit: ugi=yitaoli	ip=unknown-ip-addr	cmd=get_database: default	
21/02/17 01:34:12 INFO HiveMetaStore: 0: get_tables: db=default pat=*
21/02/17 01:34:12 INFO audit: ugi=yitaoli	ip=unknown-ip-addr	cmd=get_tables: db=default pat=*	
21/02/17 01:34:12 INFO CodeGenerator: Code generated in 22.451735 ms
21/02/17 01:34:12 INFO BlockManagerInfo: Removed broadcast_23_piece0 on localhost:35117 in memory (size: 62.2 KiB, free: 912.0 MiB)
21/02/17 01:34:12 INFO CodeGenerator: Code generated in 7.338793 ms
21/02/17 01:34:12 INFO BlockManagerInfo: Removed broadcast_21_piece0 on localhost:35117 in memory (size: 30.0 KiB, free: 912.0 MiB)
21/02/17 01:34:12 INFO BlockManagerInfo: Removed broadcast_20_piece0 on localhost:35117 in memory (size: 30.0 KiB, free: 912.0 MiB)
21/02/17 01:34:12 INFO BlockManagerInfo: Removed broadcast_27_piece0 on localhost:35117 in memory (size: 30.0 KiB, free: 912.1 MiB)
21/02/17 01:34:12 INFO BlockManagerInfo: Removed broadcast_25_piece0 on localhost:35117 in memory (size: 4.1 KiB, free: 912.1 MiB)
21/02/17 01:34:12 INFO BlockManagerInfo: Removed broadcast_19_piece0 on localhost:35117 in memory (size: 30.0 KiB, free: 912.1 MiB)
21/02/17 01:34:12 INFO BlockManagerInfo: Removed broadcast_28_piece0 on localhost:35117 in memory (size: 5.1 KiB, free: 912.1 MiB)
21/02/17 01:34:12 INFO BlockManagerInfo: Removed broadcast_26_piece0 on localhost:35117 in memory (size: 62.0 KiB, free: 912.2 MiB)
21/02/17 01:34:12 INFO BlockManagerInfo: Removed broadcast_29_piece0 on localhost:35117 in memory (size: 28.9 KiB, free: 912.2 MiB)
21/02/17 01:34:12 INFO BlockManagerInfo: Removed broadcast_30_piece0 on localhost:35117 in memory (size: 7.0 KiB, free: 912.2 MiB)
21/02/17 01:34:12 INFO CodeGenerator: Code generated in 9.037332 ms
21/02/17 01:34:12 INFO BlockManagerInfo: Removed broadcast_24_piece0 on localhost:35117 in memory (size: 30.0 KiB, free: 912.2 MiB)
21/02/17 01:34:12 INFO CodeGenerator: Code generated in 6.139123 ms
21/02/17 01:34:12 INFO BlockManagerInfo: Removed broadcast_22_piece0 on localhost:35117 in memory (size: 4.2 KiB, free: 912.2 MiB)
21/02/17 01:34:12 INFO SparkContext: Starting job: count at utils.scala:135
21/02/17 01:34:12 INFO DAGScheduler: Registering RDD 99 (count at utils.scala:135) as input to shuffle 7
21/02/17 01:34:12 INFO DAGScheduler: Got job 23 (count at utils.scala:135) with 1 output partitions
21/02/17 01:34:12 INFO DAGScheduler: Final stage: ResultStage 30 (count at utils.scala:135)
21/02/17 01:34:12 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 29)
21/02/17 01:34:12 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 29)
21/02/17 01:34:12 INFO DAGScheduler: Submitting ShuffleMapStage 29 (MapPartitionsRDD[99] at count at utils.scala:135), which has no missing parents
21/02/17 01:34:12 INFO MemoryStore: Block broadcast_31 stored as values in memory (estimated size 10.1 KiB, free 912.1 MiB)
21/02/17 01:34:12 INFO MemoryStore: Block broadcast_31_piece0 stored as bytes in memory (estimated size 5.3 KiB, free 912.0 MiB)
21/02/17 01:34:12 INFO BlockManagerInfo: Added broadcast_31_piece0 in memory on localhost:35117 (size: 5.3 KiB, free: 912.2 MiB)
21/02/17 01:34:12 INFO SparkContext: Created broadcast 31 from broadcast at DAGScheduler.scala:1200
21/02/17 01:34:12 INFO DAGScheduler: Submitting 2 missing tasks from ShuffleMapStage 29 (MapPartitionsRDD[99] at count at utils.scala:135) (first 15 tasks are for partitions Vector(0, 1))
21/02/17 01:34:12 INFO TaskSchedulerImpl: Adding task set 29.0 with 2 tasks
21/02/17 01:34:12 INFO TaskSetManager: Starting task 0.0 in stage 29.0 (TID 30, localhost, executor driver, partition 0, PROCESS_LOCAL, 7498 bytes)
21/02/17 01:34:12 INFO TaskSetManager: Starting task 1.0 in stage 29.0 (TID 31, localhost, executor driver, partition 1, PROCESS_LOCAL, 7498 bytes)
21/02/17 01:34:12 INFO Executor: Running task 0.0 in stage 29.0 (TID 30)
21/02/17 01:34:12 INFO Executor: Running task 1.0 in stage 29.0 (TID 31)
21/02/17 01:34:12 INFO Executor: Finished task 0.0 in stage 29.0 (TID 30). 1833 bytes result sent to driver
21/02/17 01:34:12 INFO Executor: Finished task 1.0 in stage 29.0 (TID 31). 1833 bytes result sent to driver
21/02/17 01:34:12 INFO TaskSetManager: Finished task 0.0 in stage 29.0 (TID 30) in 7 ms on localhost (executor driver) (1/2)
21/02/17 01:34:12 INFO TaskSetManager: Finished task 1.0 in stage 29.0 (TID 31) in 7 ms on localhost (executor driver) (2/2)
21/02/17 01:34:12 INFO TaskSchedulerImpl: Removed TaskSet 29.0, whose tasks have all completed, from pool 
21/02/17 01:34:12 INFO DAGScheduler: ShuffleMapStage 29 (count at utils.scala:135) finished in 0.013 s
21/02/17 01:34:12 INFO DAGScheduler: looking for newly runnable stages
21/02/17 01:34:12 INFO DAGScheduler: running: Set()
21/02/17 01:34:12 INFO DAGScheduler: waiting: Set(ResultStage 30)
21/02/17 01:34:12 INFO DAGScheduler: failed: Set()
21/02/17 01:34:12 INFO DAGScheduler: Submitting ResultStage 30 (MapPartitionsRDD[102] at count at utils.scala:135), which has no missing parents
21/02/17 01:34:12 INFO MemoryStore: Block broadcast_32 stored as values in memory (estimated size 10.1 KiB, free 912.0 MiB)
21/02/17 01:34:12 INFO MemoryStore: Block broadcast_32_piece0 stored as bytes in memory (estimated size 5.0 KiB, free 912.0 MiB)
21/02/17 01:34:12 INFO BlockManagerInfo: Added broadcast_32_piece0 in memory on localhost:35117 (size: 5.0 KiB, free: 912.2 MiB)
21/02/17 01:34:12 INFO SparkContext: Created broadcast 32 from broadcast at DAGScheduler.scala:1200
21/02/17 01:34:12 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 30 (MapPartitionsRDD[102] at count at utils.scala:135) (first 15 tasks are for partitions Vector(0))
21/02/17 01:34:12 INFO TaskSchedulerImpl: Adding task set 30.0 with 1 tasks
21/02/17 01:34:12 INFO TaskSetManager: Starting task 0.0 in stage 30.0 (TID 32, localhost, executor driver, partition 0, NODE_LOCAL, 7325 bytes)
21/02/17 01:34:12 INFO Executor: Running task 0.0 in stage 30.0 (TID 32)
21/02/17 01:34:12 INFO ShuffleBlockFetcherIterator: Getting 2 (120.0 B) non-empty blocks including 2 (120.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
21/02/17 01:34:12 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
21/02/17 01:34:12 INFO Executor: Finished task 0.0 in stage 30.0 (TID 32). 2648 bytes result sent to driver
21/02/17 01:34:12 INFO TaskSetManager: Finished task 0.0 in stage 30.0 (TID 32) in 6 ms on localhost (executor driver) (1/1)
21/02/17 01:34:12 INFO TaskSchedulerImpl: Removed TaskSet 30.0, whose tasks have all completed, from pool 
21/02/17 01:34:12 INFO DAGScheduler: ResultStage 30 (count at utils.scala:135) finished in 0.011 s
21/02/17 01:34:12 INFO DAGScheduler: Job 23 is finished. Cancelling potential speculative or zombie tasks for this job
21/02/17 01:34:12 INFO TaskSchedulerImpl: Killing all running tasks in stage 30: Stage finished
21/02/17 01:34:12 INFO DAGScheduler: Job 23 finished: count at utils.scala:135, took 0.028424 s
21/02/17 01:34:13 INFO FileSourceStrategy: Pruning directories with: 
21/02/17 01:34:13 INFO FileSourceStrategy: Pushed Filters: 
21/02/17 01:34:13 INFO FileSourceStrategy: Post-Scan Filters: 
21/02/17 01:34:13 INFO FileSourceStrategy: Output Data Schema: struct<class: string, paramMap: struct<stageUids: array<string>>, sparkVersion: string, timestamp: bigint, uid: string ... 3 more fields>
21/02/17 01:34:13 INFO CodeGenerator: Code generated in 6.182961 ms
21/02/17 01:34:13 INFO MemoryStore: Block broadcast_33 stored as values in memory (estimated size 316.4 KiB, free 911.7 MiB)
21/02/17 01:34:13 INFO MemoryStore: Block broadcast_33_piece0 stored as bytes in memory (estimated size 28.9 KiB, free 911.7 MiB)
21/02/17 01:34:13 INFO BlockManagerInfo: Added broadcast_33_piece0 in memory on localhost:35117 (size: 28.9 KiB, free: 912.2 MiB)
21/02/17 01:34:13 INFO SparkContext: Created broadcast 33 from sql at <unknown>:0
21/02/17 01:34:13 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
21/02/17 01:34:13 INFO SparkContext: Starting job: sql at <unknown>:0
21/02/17 01:34:13 INFO DAGScheduler: Registering RDD 109 (sql at <unknown>:0) as input to shuffle 8
21/02/17 01:34:13 INFO DAGScheduler: Got job 24 (sql at <unknown>:0) with 1 output partitions
21/02/17 01:34:13 INFO DAGScheduler: Final stage: ResultStage 32 (sql at <unknown>:0)
21/02/17 01:34:13 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 31)
21/02/17 01:34:13 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 31)
21/02/17 01:34:13 INFO DAGScheduler: Submitting ShuffleMapStage 31 (MapPartitionsRDD[109] at sql at <unknown>:0), which has no missing parents
21/02/17 01:34:13 INFO MemoryStore: Block broadcast_34 stored as values in memory (estimated size 21.5 KiB, free 911.7 MiB)
21/02/17 01:34:13 INFO MemoryStore: Block broadcast_34_piece0 stored as bytes in memory (estimated size 10.1 KiB, free 911.7 MiB)
21/02/17 01:34:13 INFO BlockManagerInfo: Added broadcast_34_piece0 in memory on localhost:35117 (size: 10.1 KiB, free: 912.2 MiB)
21/02/17 01:34:13 INFO SparkContext: Created broadcast 34 from broadcast at DAGScheduler.scala:1200
21/02/17 01:34:13 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 31 (MapPartitionsRDD[109] at sql at <unknown>:0) (first 15 tasks are for partitions Vector(0))
21/02/17 01:34:13 INFO TaskSchedulerImpl: Adding task set 31.0 with 1 tasks
21/02/17 01:34:13 INFO TaskSetManager: Starting task 0.0 in stage 31.0 (TID 33, localhost, executor driver, partition 0, PROCESS_LOCAL, 7746 bytes)
21/02/17 01:34:13 INFO Executor: Running task 0.0 in stage 31.0 (TID 33)
21/02/17 01:34:13 INFO FileScanRDD: Reading File path: file:///tmp/RtmpE1GwT4/file220626098807e/metadata/part-00000, range: 0-306, partition values: [empty row]
21/02/17 01:34:13 INFO CodeGenerator: Code generated in 12.610354 ms
21/02/17 01:34:13 INFO MemoryStore: Block rdd_105_0 stored as values in memory (estimated size 1296.0 B, free 911.7 MiB)
21/02/17 01:34:13 INFO BlockManagerInfo: Added rdd_105_0 in memory on localhost:35117 (size: 1296.0 B, free: 912.2 MiB)
21/02/17 01:34:13 INFO CodeGenerator: Code generated in 9.741344 ms
21/02/17 01:34:13 INFO Executor: Finished task 0.0 in stage 31.0 (TID 33). 2067 bytes result sent to driver
21/02/17 01:34:13 INFO TaskSetManager: Finished task 0.0 in stage 31.0 (TID 33) in 61 ms on localhost (executor driver) (1/1)
21/02/17 01:34:13 INFO TaskSchedulerImpl: Removed TaskSet 31.0, whose tasks have all completed, from pool 
21/02/17 01:34:13 INFO DAGScheduler: ShuffleMapStage 31 (sql at <unknown>:0) finished in 0.068 s
21/02/17 01:34:13 INFO DAGScheduler: looking for newly runnable stages
21/02/17 01:34:13 INFO DAGScheduler: running: Set()
21/02/17 01:34:13 INFO DAGScheduler: waiting: Set(ResultStage 32)
21/02/17 01:34:13 INFO DAGScheduler: failed: Set()
21/02/17 01:34:13 INFO DAGScheduler: Submitting ResultStage 32 (MapPartitionsRDD[112] at sql at <unknown>:0), which has no missing parents
21/02/17 01:34:13 INFO MemoryStore: Block broadcast_35 stored as values in memory (estimated size 10.1 KiB, free 911.7 MiB)
21/02/17 01:34:13 INFO MemoryStore: Block broadcast_35_piece0 stored as bytes in memory (estimated size 5.0 KiB, free 911.6 MiB)
21/02/17 01:34:13 INFO BlockManagerInfo: Added broadcast_35_piece0 in memory on localhost:35117 (size: 5.0 KiB, free: 912.2 MiB)
21/02/17 01:34:13 INFO SparkContext: Created broadcast 35 from broadcast at DAGScheduler.scala:1200
21/02/17 01:34:13 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 32 (MapPartitionsRDD[112] at sql at <unknown>:0) (first 15 tasks are for partitions Vector(0))
21/02/17 01:34:13 INFO TaskSchedulerImpl: Adding task set 32.0 with 1 tasks
21/02/17 01:34:13 INFO TaskSetManager: Starting task 0.0 in stage 32.0 (TID 34, localhost, executor driver, partition 0, NODE_LOCAL, 7325 bytes)
21/02/17 01:34:13 INFO Executor: Running task 0.0 in stage 32.0 (TID 34)
21/02/17 01:34:13 INFO ShuffleBlockFetcherIterator: Getting 1 (60.0 B) non-empty blocks including 1 (60.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
21/02/17 01:34:13 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
21/02/17 01:34:13 INFO Executor: Finished task 0.0 in stage 32.0 (TID 34). 2648 bytes result sent to driver
21/02/17 01:34:13 INFO TaskSetManager: Finished task 0.0 in stage 32.0 (TID 34) in 4 ms on localhost (executor driver) (1/1)
21/02/17 01:34:13 INFO TaskSchedulerImpl: Removed TaskSet 32.0, whose tasks have all completed, from pool 
21/02/17 01:34:13 INFO DAGScheduler: ResultStage 32 (sql at <unknown>:0) finished in 0.009 s
21/02/17 01:34:13 INFO DAGScheduler: Job 24 is finished. Cancelling potential speculative or zombie tasks for this job
21/02/17 01:34:13 INFO TaskSchedulerImpl: Killing all running tasks in stage 32: Stage finished
21/02/17 01:34:13 INFO DAGScheduler: Job 24 finished: sql at <unknown>:0, took 0.081027 s
21/02/17 01:34:13 INFO SparkContext: Starting job: collect at utils.scala:137
21/02/17 01:34:13 INFO DAGScheduler: Registering RDD 116 (collect at utils.scala:137) as input to shuffle 9
21/02/17 01:34:13 INFO DAGScheduler: Got job 25 (collect at utils.scala:137) with 1 output partitions
21/02/17 01:34:13 INFO DAGScheduler: Final stage: ResultStage 34 (collect at utils.scala:137)
21/02/17 01:34:13 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 33)
21/02/17 01:34:13 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 33)
21/02/17 01:34:13 INFO DAGScheduler: Submitting ShuffleMapStage 33 (MapPartitionsRDD[116] at collect at utils.scala:137), which has no missing parents
21/02/17 01:34:13 INFO MemoryStore: Block broadcast_36 stored as values in memory (estimated size 21.5 KiB, free 911.6 MiB)
21/02/17 01:34:13 INFO MemoryStore: Block broadcast_36_piece0 stored as bytes in memory (estimated size 10.1 KiB, free 911.6 MiB)
21/02/17 01:34:13 INFO BlockManagerInfo: Added broadcast_36_piece0 in memory on localhost:35117 (size: 10.1 KiB, free: 912.2 MiB)
21/02/17 01:34:13 INFO SparkContext: Created broadcast 36 from broadcast at DAGScheduler.scala:1200
21/02/17 01:34:13 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 33 (MapPartitionsRDD[116] at collect at utils.scala:137) (first 15 tasks are for partitions Vector(0))
21/02/17 01:34:13 INFO TaskSchedulerImpl: Adding task set 33.0 with 1 tasks
21/02/17 01:34:13 INFO TaskSetManager: Starting task 0.0 in stage 33.0 (TID 35, localhost, executor driver, partition 0, PROCESS_LOCAL, 7746 bytes)
21/02/17 01:34:13 INFO Executor: Running task 0.0 in stage 33.0 (TID 35)
21/02/17 01:34:13 INFO BlockManager: Found block rdd_105_0 locally
21/02/17 01:34:13 INFO Executor: Finished task 0.0 in stage 33.0 (TID 35). 2067 bytes result sent to driver
21/02/17 01:34:13 INFO TaskSetManager: Finished task 0.0 in stage 33.0 (TID 35) in 6 ms on localhost (executor driver) (1/1)
21/02/17 01:34:13 INFO TaskSchedulerImpl: Removed TaskSet 33.0, whose tasks have all completed, from pool 
21/02/17 01:34:13 INFO DAGScheduler: ShuffleMapStage 33 (collect at utils.scala:137) finished in 0.010 s
21/02/17 01:34:13 INFO DAGScheduler: looking for newly runnable stages
21/02/17 01:34:13 INFO DAGScheduler: running: Set()
21/02/17 01:34:13 INFO DAGScheduler: waiting: Set(ResultStage 34)
21/02/17 01:34:13 INFO DAGScheduler: failed: Set()
21/02/17 01:34:13 INFO DAGScheduler: Submitting ResultStage 34 (MapPartitionsRDD[119] at collect at utils.scala:137), which has no missing parents
21/02/17 01:34:13 INFO MemoryStore: Block broadcast_37 stored as values in memory (estimated size 10.1 KiB, free 911.6 MiB)
21/02/17 01:34:13 INFO MemoryStore: Block broadcast_37_piece0 stored as bytes in memory (estimated size 5.0 KiB, free 911.6 MiB)
21/02/17 01:34:13 INFO BlockManagerInfo: Added broadcast_37_piece0 in memory on localhost:35117 (size: 5.0 KiB, free: 912.2 MiB)
21/02/17 01:34:13 INFO SparkContext: Created broadcast 37 from broadcast at DAGScheduler.scala:1200
21/02/17 01:34:13 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 34 (MapPartitionsRDD[119] at collect at utils.scala:137) (first 15 tasks are for partitions Vector(0))
21/02/17 01:34:13 INFO TaskSchedulerImpl: Adding task set 34.0 with 1 tasks
21/02/17 01:34:13 INFO TaskSetManager: Starting task 0.0 in stage 34.0 (TID 36, localhost, executor driver, partition 0, NODE_LOCAL, 7325 bytes)
21/02/17 01:34:13 INFO Executor: Running task 0.0 in stage 34.0 (TID 36)
21/02/17 01:34:13 INFO ShuffleBlockFetcherIterator: Getting 1 (60.0 B) non-empty blocks including 1 (60.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
21/02/17 01:34:13 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
21/02/17 01:34:13 INFO Executor: Finished task 0.0 in stage 34.0 (TID 36). 2648 bytes result sent to driver
21/02/17 01:34:13 INFO TaskSetManager: Finished task 0.0 in stage 34.0 (TID 36) in 5 ms on localhost (executor driver) (1/1)
21/02/17 01:34:13 INFO TaskSchedulerImpl: Removed TaskSet 34.0, whose tasks have all completed, from pool 
21/02/17 01:34:13 INFO DAGScheduler: ResultStage 34 (collect at utils.scala:137) finished in 0.008 s
21/02/17 01:34:13 INFO DAGScheduler: Job 25 is finished. Cancelling potential speculative or zombie tasks for this job
21/02/17 01:34:13 INFO TaskSchedulerImpl: Killing all running tasks in stage 34: Stage finished
21/02/17 01:34:13 INFO DAGScheduler: Job 25 finished: collect at utils.scala:137, took 0.021379 s
21/02/17 01:34:13 INFO CodeGenerator: Code generated in 4.666294 ms
21/02/17 01:34:13 INFO CodeGenerator: Code generated in 7.378605 ms
21/02/17 01:34:13 INFO CodeGenerator: Code generated in 4.951062 ms
21/02/17 01:34:13 INFO SparkContext: Starting job: count at utils.scala:135
21/02/17 01:34:13 INFO DAGScheduler: Registering RDD 123 (count at utils.scala:135) as input to shuffle 10
21/02/17 01:34:13 INFO DAGScheduler: Got job 26 (count at utils.scala:135) with 1 output partitions
21/02/17 01:34:13 INFO DAGScheduler: Final stage: ResultStage 36 (count at utils.scala:135)
21/02/17 01:34:13 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 35)
21/02/17 01:34:13 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 35)
21/02/17 01:34:13 INFO DAGScheduler: Submitting ShuffleMapStage 35 (MapPartitionsRDD[123] at count at utils.scala:135), which has no missing parents
21/02/17 01:34:13 INFO MemoryStore: Block broadcast_38 stored as values in memory (estimated size 20.9 KiB, free 911.6 MiB)
21/02/17 01:34:13 INFO MemoryStore: Block broadcast_38_piece0 stored as bytes in memory (estimated size 9.9 KiB, free 911.6 MiB)
21/02/17 01:34:13 INFO BlockManagerInfo: Added broadcast_38_piece0 in memory on localhost:35117 (size: 9.9 KiB, free: 912.2 MiB)
21/02/17 01:34:13 INFO SparkContext: Created broadcast 38 from broadcast at DAGScheduler.scala:1200
21/02/17 01:34:13 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 35 (MapPartitionsRDD[123] at count at utils.scala:135) (first 15 tasks are for partitions Vector(0))
21/02/17 01:34:13 INFO TaskSchedulerImpl: Adding task set 35.0 with 1 tasks
21/02/17 01:34:13 INFO TaskSetManager: Starting task 0.0 in stage 35.0 (TID 37, localhost, executor driver, partition 0, PROCESS_LOCAL, 7746 bytes)
21/02/17 01:34:13 INFO Executor: Running task 0.0 in stage 35.0 (TID 37)
21/02/17 01:34:13 INFO BlockManager: Found block rdd_105_0 locally
21/02/17 01:34:13 INFO Executor: Finished task 0.0 in stage 35.0 (TID 37). 2067 bytes result sent to driver
21/02/17 01:34:13 INFO TaskSetManager: Finished task 0.0 in stage 35.0 (TID 37) in 8 ms on localhost (executor driver) (1/1)
21/02/17 01:34:13 INFO TaskSchedulerImpl: Removed TaskSet 35.0, whose tasks have all completed, from pool 
21/02/17 01:34:13 INFO DAGScheduler: ShuffleMapStage 35 (count at utils.scala:135) finished in 0.013 s
21/02/17 01:34:13 INFO DAGScheduler: looking for newly runnable stages
21/02/17 01:34:13 INFO DAGScheduler: running: Set()
21/02/17 01:34:13 INFO DAGScheduler: waiting: Set(ResultStage 36)
21/02/17 01:34:13 INFO DAGScheduler: failed: Set()
21/02/17 01:34:13 INFO DAGScheduler: Submitting ResultStage 36 (MapPartitionsRDD[126] at count at utils.scala:135), which has no missing parents
21/02/17 01:34:13 INFO MemoryStore: Block broadcast_39 stored as values in memory (estimated size 12.1 KiB, free 911.6 MiB)
21/02/17 01:34:13 INFO MemoryStore: Block broadcast_39_piece0 stored as bytes in memory (estimated size 5.3 KiB, free 911.6 MiB)
21/02/17 01:34:13 INFO BlockManagerInfo: Added broadcast_39_piece0 in memory on localhost:35117 (size: 5.3 KiB, free: 912.1 MiB)
21/02/17 01:34:13 INFO SparkContext: Created broadcast 39 from broadcast at DAGScheduler.scala:1200
21/02/17 01:34:13 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 36 (MapPartitionsRDD[126] at count at utils.scala:135) (first 15 tasks are for partitions Vector(0))
21/02/17 01:34:13 INFO TaskSchedulerImpl: Adding task set 36.0 with 1 tasks
21/02/17 01:34:13 INFO TaskSetManager: Starting task 0.0 in stage 36.0 (TID 38, localhost, executor driver, partition 0, NODE_LOCAL, 7325 bytes)
21/02/17 01:34:13 INFO Executor: Running task 0.0 in stage 36.0 (TID 38)
21/02/17 01:34:13 INFO ShuffleBlockFetcherIterator: Getting 1 (49.0 B) non-empty blocks including 1 (49.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
21/02/17 01:34:13 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
21/02/17 01:34:13 INFO Executor: Finished task 0.0 in stage 36.0 (TID 38). 2896 bytes result sent to driver
21/02/17 01:34:13 INFO TaskSetManager: Finished task 0.0 in stage 36.0 (TID 38) in 8 ms on localhost (executor driver) (1/1)
21/02/17 01:34:13 INFO TaskSchedulerImpl: Removed TaskSet 36.0, whose tasks have all completed, from pool 
21/02/17 01:34:13 INFO DAGScheduler: ResultStage 36 (count at utils.scala:135) finished in 0.012 s
21/02/17 01:34:13 INFO DAGScheduler: Job 26 is finished. Cancelling potential speculative or zombie tasks for this job
21/02/17 01:34:13 INFO TaskSchedulerImpl: Killing all running tasks in stage 36: Stage finished
21/02/17 01:34:13 INFO DAGScheduler: Job 26 finished: count at utils.scala:135, took 0.029277 s
21/02/17 01:34:13 INFO SparkContext: Starting job: collect at utils.scala:137
21/02/17 01:34:13 INFO DAGScheduler: Got job 27 (collect at utils.scala:137) with 1 output partitions
21/02/17 01:34:13 INFO DAGScheduler: Final stage: ResultStage 37 (collect at utils.scala:137)
21/02/17 01:34:13 INFO DAGScheduler: Parents of final stage: List()
21/02/17 01:34:13 INFO DAGScheduler: Missing parents: List()
21/02/17 01:34:13 INFO DAGScheduler: Submitting ResultStage 37 (MapPartitionsRDD[128] at collect at utils.scala:137), which has no missing parents
21/02/17 01:34:13 INFO MemoryStore: Block broadcast_40 stored as values in memory (estimated size 7.2 KiB, free 911.5 MiB)
21/02/17 01:34:13 INFO MemoryStore: Block broadcast_40_piece0 stored as bytes in memory (estimated size 3.7 KiB, free 911.5 MiB)
21/02/17 01:34:13 INFO BlockManagerInfo: Added broadcast_40_piece0 in memory on localhost:35117 (size: 3.7 KiB, free: 912.1 MiB)
21/02/17 01:34:13 INFO SparkContext: Created broadcast 40 from broadcast at DAGScheduler.scala:1200
21/02/17 01:34:13 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 37 (MapPartitionsRDD[128] at collect at utils.scala:137) (first 15 tasks are for partitions Vector(0))
21/02/17 01:34:13 INFO TaskSchedulerImpl: Adding task set 37.0 with 1 tasks
21/02/17 01:34:13 INFO TaskSetManager: Starting task 0.0 in stage 37.0 (TID 39, localhost, executor driver, partition 0, PROCESS_LOCAL, 7561 bytes)
21/02/17 01:34:13 INFO Executor: Running task 0.0 in stage 37.0 (TID 39)
21/02/17 01:34:13 INFO Executor: Finished task 0.0 in stage 37.0 (TID 39). 1354 bytes result sent to driver
21/02/17 01:34:13 INFO TaskSetManager: Finished task 0.0 in stage 37.0 (TID 39) in 6 ms on localhost (executor driver) (1/1)
21/02/17 01:34:13 INFO TaskSchedulerImpl: Removed TaskSet 37.0, whose tasks have all completed, from pool 
21/02/17 01:34:13 INFO DAGScheduler: ResultStage 37 (collect at utils.scala:137) finished in 0.010 s
21/02/17 01:34:13 INFO DAGScheduler: Job 27 is finished. Cancelling potential speculative or zombie tasks for this job
21/02/17 01:34:13 INFO TaskSchedulerImpl: Killing all running tasks in stage 37: Stage finished
21/02/17 01:34:13 INFO DAGScheduler: Job 27 finished: collect at utils.scala:137, took 0.011852 s
21/02/17 01:34:13 INFO SparkContext: Starting job: count at utils.scala:135
21/02/17 01:34:13 INFO DAGScheduler: Registering RDD 130 (count at utils.scala:135) as input to shuffle 11
21/02/17 01:34:13 INFO DAGScheduler: Got job 28 (count at utils.scala:135) with 1 output partitions
21/02/17 01:34:13 INFO DAGScheduler: Final stage: ResultStage 39 (count at utils.scala:135)
21/02/17 01:34:13 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 38)
21/02/17 01:34:13 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 38)
21/02/17 01:34:13 INFO DAGScheduler: Submitting ShuffleMapStage 38 (MapPartitionsRDD[130] at count at utils.scala:135), which has no missing parents
21/02/17 01:34:13 INFO MemoryStore: Block broadcast_41 stored as values in memory (estimated size 10.0 KiB, free 911.5 MiB)
21/02/17 01:34:13 INFO MemoryStore: Block broadcast_41_piece0 stored as bytes in memory (estimated size 5.2 KiB, free 911.5 MiB)
21/02/17 01:34:13 INFO BlockManagerInfo: Added broadcast_41_piece0 in memory on localhost:35117 (size: 5.2 KiB, free: 912.1 MiB)
21/02/17 01:34:13 INFO SparkContext: Created broadcast 41 from broadcast at DAGScheduler.scala:1200
21/02/17 01:34:13 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 38 (MapPartitionsRDD[130] at count at utils.scala:135) (first 15 tasks are for partitions Vector(0))
21/02/17 01:34:13 INFO TaskSchedulerImpl: Adding task set 38.0 with 1 tasks
21/02/17 01:34:13 INFO TaskSetManager: Starting task 0.0 in stage 38.0 (TID 40, localhost, executor driver, partition 0, PROCESS_LOCAL, 7550 bytes)
21/02/17 01:34:13 INFO Executor: Running task 0.0 in stage 38.0 (TID 40)
21/02/17 01:34:13 INFO Executor: Finished task 0.0 in stage 38.0 (TID 40). 1833 bytes result sent to driver
21/02/17 01:34:13 INFO TaskSetManager: Finished task 0.0 in stage 38.0 (TID 40) in 5 ms on localhost (executor driver) (1/1)
21/02/17 01:34:13 INFO TaskSchedulerImpl: Removed TaskSet 38.0, whose tasks have all completed, from pool 
21/02/17 01:34:13 INFO DAGScheduler: ShuffleMapStage 38 (count at utils.scala:135) finished in 0.011 s
21/02/17 01:34:13 INFO DAGScheduler: looking for newly runnable stages
21/02/17 01:34:13 INFO DAGScheduler: running: Set()
21/02/17 01:34:13 INFO DAGScheduler: waiting: Set(ResultStage 39)
21/02/17 01:34:13 INFO DAGScheduler: failed: Set()
21/02/17 01:34:13 INFO DAGScheduler: Submitting ResultStage 39 (MapPartitionsRDD[133] at count at utils.scala:135), which has no missing parents
21/02/17 01:34:13 INFO MemoryStore: Block broadcast_42 stored as values in memory (estimated size 10.1 KiB, free 911.5 MiB)
21/02/17 01:34:13 INFO MemoryStore: Block broadcast_42_piece0 stored as bytes in memory (estimated size 5.0 KiB, free 911.5 MiB)
21/02/17 01:34:13 INFO BlockManagerInfo: Added broadcast_42_piece0 in memory on localhost:35117 (size: 5.0 KiB, free: 912.1 MiB)
21/02/17 01:34:13 INFO SparkContext: Created broadcast 42 from broadcast at DAGScheduler.scala:1200
21/02/17 01:34:13 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 39 (MapPartitionsRDD[133] at count at utils.scala:135) (first 15 tasks are for partitions Vector(0))
21/02/17 01:34:13 INFO TaskSchedulerImpl: Adding task set 39.0 with 1 tasks
21/02/17 01:34:13 INFO TaskSetManager: Starting task 0.0 in stage 39.0 (TID 41, localhost, executor driver, partition 0, NODE_LOCAL, 7325 bytes)
21/02/17 01:34:13 INFO Executor: Running task 0.0 in stage 39.0 (TID 41)
21/02/17 01:34:13 INFO ShuffleBlockFetcherIterator: Getting 1 (60.0 B) non-empty blocks including 1 (60.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
21/02/17 01:34:13 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
21/02/17 01:34:13 INFO Executor: Finished task 0.0 in stage 39.0 (TID 41). 2648 bytes result sent to driver
21/02/17 01:34:13 INFO TaskSetManager: Finished task 0.0 in stage 39.0 (TID 41) in 5 ms on localhost (executor driver) (1/1)
21/02/17 01:34:13 INFO TaskSchedulerImpl: Removed TaskSet 39.0, whose tasks have all completed, from pool 
21/02/17 01:34:13 INFO DAGScheduler: ResultStage 39 (count at utils.scala:135) finished in 0.011 s
21/02/17 01:34:13 INFO DAGScheduler: Job 28 is finished. Cancelling potential speculative or zombie tasks for this job
21/02/17 01:34:13 INFO TaskSchedulerImpl: Killing all running tasks in stage 39: Stage finished
21/02/17 01:34:13 INFO DAGScheduler: Job 28 finished: count at utils.scala:135, took 0.024165 s
21/02/17 01:34:13 INFO SparkContext: Starting job: collect at utils.scala:137
21/02/17 01:34:13 INFO DAGScheduler: Got job 29 (collect at utils.scala:137) with 1 output partitions
21/02/17 01:34:13 INFO DAGScheduler: Final stage: ResultStage 40 (collect at utils.scala:137)
21/02/17 01:34:13 INFO DAGScheduler: Parents of final stage: List()
21/02/17 01:34:13 INFO DAGScheduler: Missing parents: List()
21/02/17 01:34:13 INFO DAGScheduler: Submitting ResultStage 40 (MapPartitionsRDD[136] at collect at utils.scala:137), which has no missing parents
21/02/17 01:34:13 INFO MemoryStore: Block broadcast_43 stored as values in memory (estimated size 16.7 KiB, free 911.5 MiB)
21/02/17 01:34:13 INFO MemoryStore: Block broadcast_43_piece0 stored as bytes in memory (estimated size 8.0 KiB, free 911.5 MiB)
21/02/17 01:34:13 INFO BlockManagerInfo: Added broadcast_43_piece0 in memory on localhost:35117 (size: 8.0 KiB, free: 912.1 MiB)
21/02/17 01:34:13 INFO SparkContext: Created broadcast 43 from broadcast at DAGScheduler.scala:1200
21/02/17 01:34:13 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 40 (MapPartitionsRDD[136] at collect at utils.scala:137) (first 15 tasks are for partitions Vector(0))
21/02/17 01:34:13 INFO TaskSchedulerImpl: Adding task set 40.0 with 1 tasks
21/02/17 01:34:13 INFO TaskSetManager: Starting task 0.0 in stage 40.0 (TID 42, localhost, executor driver, partition 0, PROCESS_LOCAL, 7757 bytes)
21/02/17 01:34:13 INFO Executor: Running task 0.0 in stage 40.0 (TID 42)
21/02/17 01:34:13 INFO BlockManager: Found block rdd_105_0 locally
21/02/17 01:34:13 INFO CodeGenerator: Code generated in 10.750939 ms
21/02/17 01:34:13 INFO Executor: Finished task 0.0 in stage 40.0 (TID 42). 1606 bytes result sent to driver
21/02/17 01:34:13 INFO TaskSetManager: Finished task 0.0 in stage 40.0 (TID 42) in 20 ms on localhost (executor driver) (1/1)
21/02/17 01:34:13 INFO TaskSchedulerImpl: Removed TaskSet 40.0, whose tasks have all completed, from pool 
21/02/17 01:34:13 INFO DAGScheduler: ResultStage 40 (collect at utils.scala:137) finished in 0.024 s
21/02/17 01:34:13 INFO DAGScheduler: Job 29 is finished. Cancelling potential speculative or zombie tasks for this job
21/02/17 01:34:13 INFO TaskSchedulerImpl: Killing all running tasks in stage 40: Stage finished
21/02/17 01:34:13 INFO DAGScheduler: Job 29 finished: collect at utils.scala:137, took 0.026347 s
21/02/17 01:34:13 INFO CodeGenerator: Code generated in 5.265172 ms
21/02/17 01:34:13 INFO SparkContext: Starting job: count at utils.scala:135
21/02/17 01:34:13 INFO DAGScheduler: Registering RDD 140 (count at utils.scala:135) as input to shuffle 12
21/02/17 01:34:13 INFO DAGScheduler: Got job 30 (count at utils.scala:135) with 1 output partitions
21/02/17 01:34:13 INFO DAGScheduler: Final stage: ResultStage 42 (count at utils.scala:135)
21/02/17 01:34:13 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 41)
21/02/17 01:34:13 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 41)
21/02/17 01:34:13 INFO DAGScheduler: Submitting ShuffleMapStage 41 (MapPartitionsRDD[140] at count at utils.scala:135), which has no missing parents
21/02/17 01:34:13 INFO MemoryStore: Block broadcast_44 stored as values in memory (estimated size 21.5 KiB, free 911.5 MiB)
21/02/17 01:34:13 INFO MemoryStore: Block broadcast_44_piece0 stored as bytes in memory (estimated size 10.1 KiB, free 911.5 MiB)
21/02/17 01:34:13 INFO BlockManagerInfo: Added broadcast_44_piece0 in memory on localhost:35117 (size: 10.1 KiB, free: 912.1 MiB)
21/02/17 01:34:13 INFO SparkContext: Created broadcast 44 from broadcast at DAGScheduler.scala:1200
21/02/17 01:34:13 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 41 (MapPartitionsRDD[140] at count at utils.scala:135) (first 15 tasks are for partitions Vector(0))
21/02/17 01:34:13 INFO TaskSchedulerImpl: Adding task set 41.0 with 1 tasks
21/02/17 01:34:13 INFO TaskSetManager: Starting task 0.0 in stage 41.0 (TID 43, localhost, executor driver, partition 0, PROCESS_LOCAL, 7746 bytes)
21/02/17 01:34:13 INFO Executor: Running task 0.0 in stage 41.0 (TID 43)
21/02/17 01:34:13 INFO BlockManager: Found block rdd_105_0 locally
21/02/17 01:34:13 INFO Executor: Finished task 0.0 in stage 41.0 (TID 43). 2067 bytes result sent to driver
21/02/17 01:34:13 INFO TaskSetManager: Finished task 0.0 in stage 41.0 (TID 43) in 6 ms on localhost (executor driver) (1/1)
21/02/17 01:34:13 INFO TaskSchedulerImpl: Removed TaskSet 41.0, whose tasks have all completed, from pool 
21/02/17 01:34:13 INFO DAGScheduler: ShuffleMapStage 41 (count at utils.scala:135) finished in 0.011 s
21/02/17 01:34:13 INFO DAGScheduler: looking for newly runnable stages
21/02/17 01:34:13 INFO DAGScheduler: running: Set()
21/02/17 01:34:13 INFO DAGScheduler: waiting: Set(ResultStage 42)
21/02/17 01:34:13 INFO DAGScheduler: failed: Set()
21/02/17 01:34:13 INFO DAGScheduler: Submitting ResultStage 42 (MapPartitionsRDD[143] at count at utils.scala:135), which has no missing parents
21/02/17 01:34:13 INFO MemoryStore: Block broadcast_45 stored as values in memory (estimated size 10.1 KiB, free 911.4 MiB)
21/02/17 01:34:13 INFO MemoryStore: Block broadcast_45_piece0 stored as bytes in memory (estimated size 5.0 KiB, free 911.4 MiB)
21/02/17 01:34:13 INFO BlockManagerInfo: Added broadcast_45_piece0 in memory on localhost:35117 (size: 5.0 KiB, free: 912.1 MiB)
21/02/17 01:34:13 INFO SparkContext: Created broadcast 45 from broadcast at DAGScheduler.scala:1200
21/02/17 01:34:13 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 42 (MapPartitionsRDD[143] at count at utils.scala:135) (first 15 tasks are for partitions Vector(0))
21/02/17 01:34:13 INFO TaskSchedulerImpl: Adding task set 42.0 with 1 tasks
21/02/17 01:34:13 INFO TaskSetManager: Starting task 0.0 in stage 42.0 (TID 44, localhost, executor driver, partition 0, NODE_LOCAL, 7325 bytes)
21/02/17 01:34:13 INFO Executor: Running task 0.0 in stage 42.0 (TID 44)
21/02/17 01:34:13 INFO ShuffleBlockFetcherIterator: Getting 1 (60.0 B) non-empty blocks including 1 (60.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
21/02/17 01:34:13 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
21/02/17 01:34:13 INFO Executor: Finished task 0.0 in stage 42.0 (TID 44). 2648 bytes result sent to driver
21/02/17 01:34:13 INFO TaskSetManager: Finished task 0.0 in stage 42.0 (TID 44) in 4 ms on localhost (executor driver) (1/1)
21/02/17 01:34:13 INFO TaskSchedulerImpl: Removed TaskSet 42.0, whose tasks have all completed, from pool 
21/02/17 01:34:13 INFO DAGScheduler: ResultStage 42 (count at utils.scala:135) finished in 0.008 s
21/02/17 01:34:13 INFO DAGScheduler: Job 30 is finished. Cancelling potential speculative or zombie tasks for this job
21/02/17 01:34:13 INFO TaskSchedulerImpl: Killing all running tasks in stage 42: Stage finished
21/02/17 01:34:13 INFO DAGScheduler: Job 30 finished: count at utils.scala:135, took 0.021659 s
21/02/17 01:34:13 INFO MapPartitionsRDD: Removing RDD 105 from persistence list
21/02/17 01:34:13 INFO BlockManager: Removing RDD 105
21/02/17 01:34:13 INFO MemoryStore: Block broadcast_46 stored as values in memory (estimated size 294.6 KiB, free 911.2 MiB)
21/02/17 01:34:13 INFO MemoryStore: Block broadcast_46_piece0 stored as bytes in memory (estimated size 27.2 KiB, free 911.1 MiB)
21/02/17 01:34:13 INFO BlockManagerInfo: Added broadcast_46_piece0 in memory on localhost:35117 (size: 27.2 KiB, free: 912.1 MiB)
21/02/17 01:34:13 INFO SparkContext: Created broadcast 46 from textFile at ReadWrite.scala:587
21/02/17 01:34:13 INFO FileInputFormat: Total input files to process : 1
21/02/17 01:34:13 INFO SparkContext: Starting job: first at ReadWrite.scala:587
21/02/17 01:34:13 INFO DAGScheduler: Got job 31 (first at ReadWrite.scala:587) with 1 output partitions
21/02/17 01:34:13 INFO DAGScheduler: Final stage: ResultStage 43 (first at ReadWrite.scala:587)
21/02/17 01:34:13 INFO DAGScheduler: Parents of final stage: List()
21/02/17 01:34:13 INFO DAGScheduler: Missing parents: List()
21/02/17 01:34:13 INFO DAGScheduler: Submitting ResultStage 43 (/tmp/RtmpE1GwT4/file220626098807e/metadata MapPartitionsRDD[145] at textFile at ReadWrite.scala:587), which has no missing parents
21/02/17 01:34:13 INFO MemoryStore: Block broadcast_47 stored as values in memory (estimated size 4.1 KiB, free 911.1 MiB)
21/02/17 01:34:13 INFO MemoryStore: Block broadcast_47_piece0 stored as bytes in memory (estimated size 2.4 KiB, free 911.1 MiB)
21/02/17 01:34:13 INFO BlockManagerInfo: Added broadcast_47_piece0 in memory on localhost:35117 (size: 2.4 KiB, free: 912.1 MiB)
21/02/17 01:34:13 INFO SparkContext: Created broadcast 47 from broadcast at DAGScheduler.scala:1200
21/02/17 01:34:13 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 43 (/tmp/RtmpE1GwT4/file220626098807e/metadata MapPartitionsRDD[145] at textFile at ReadWrite.scala:587) (first 15 tasks are for partitions Vector(0))
21/02/17 01:34:13 INFO TaskSchedulerImpl: Adding task set 43.0 with 1 tasks
21/02/17 01:34:13 INFO TaskSetManager: Starting task 0.0 in stage 43.0 (TID 45, localhost, executor driver, partition 0, PROCESS_LOCAL, 7399 bytes)
21/02/17 01:34:13 INFO Executor: Running task 0.0 in stage 43.0 (TID 45)
21/02/17 01:34:13 INFO BlockManagerInfo: Removed broadcast_31_piece0 on localhost:35117 in memory (size: 5.3 KiB, free: 912.1 MiB)
21/02/17 01:34:13 INFO BlockManagerInfo: Removed broadcast_33_piece0 on localhost:35117 in memory (size: 28.9 KiB, free: 912.1 MiB)
21/02/17 01:34:13 INFO BlockManagerInfo: Removed broadcast_44_piece0 on localhost:35117 in memory (size: 10.1 KiB, free: 912.1 MiB)
21/02/17 01:34:13 INFO BlockManagerInfo: Removed broadcast_32_piece0 on localhost:35117 in memory (size: 5.0 KiB, free: 912.1 MiB)
21/02/17 01:34:13 INFO BlockManagerInfo: Removed broadcast_42_piece0 on localhost:35117 in memory (size: 5.0 KiB, free: 912.1 MiB)
21/02/17 01:34:13 INFO BlockManagerInfo: Removed broadcast_34_piece0 on localhost:35117 in memory (size: 10.1 KiB, free: 912.1 MiB)
21/02/17 01:34:13 INFO BlockManagerInfo: Removed broadcast_38_piece0 on localhost:35117 in memory (size: 9.9 KiB, free: 912.2 MiB)
21/02/17 01:34:13 INFO HadoopRDD: Input split: file:/tmp/RtmpE1GwT4/file220626098807e/metadata/part-00000:0+306
21/02/17 01:34:13 INFO BlockManagerInfo: Removed broadcast_43_piece0 on localhost:35117 in memory (size: 8.0 KiB, free: 912.2 MiB)
21/02/17 01:34:13 INFO BlockManagerInfo: Removed broadcast_40_piece0 on localhost:35117 in memory (size: 3.7 KiB, free: 912.2 MiB)
21/02/17 01:34:13 INFO Executor: Finished task 0.0 in stage 43.0 (TID 45). 1234 bytes result sent to driver
21/02/17 01:34:13 INFO TaskSetManager: Finished task 0.0 in stage 43.0 (TID 45) in 28 ms on localhost (executor driver) (1/1)
21/02/17 01:34:13 INFO TaskSchedulerImpl: Removed TaskSet 43.0, whose tasks have all completed, from pool 
21/02/17 01:34:13 INFO DAGScheduler: ResultStage 43 (first at ReadWrite.scala:587) finished in 0.045 s
21/02/17 01:34:13 INFO DAGScheduler: Job 31 is finished. Cancelling potential speculative or zombie tasks for this job
21/02/17 01:34:13 INFO TaskSchedulerImpl: Killing all running tasks in stage 43: Stage finished
21/02/17 01:34:13 INFO DAGScheduler: Job 31 finished: first at ReadWrite.scala:587, took 0.048134 s
21/02/17 01:34:13 INFO BlockManagerInfo: Removed broadcast_37_piece0 on localhost:35117 in memory (size: 5.0 KiB, free: 912.2 MiB)
21/02/17 01:34:13 INFO BlockManagerInfo: Removed broadcast_35_piece0 on localhost:35117 in memory (size: 5.0 KiB, free: 912.2 MiB)
21/02/17 01:34:13 INFO BlockManagerInfo: Removed broadcast_36_piece0 on localhost:35117 in memory (size: 10.1 KiB, free: 912.2 MiB)
21/02/17 01:34:13 INFO BlockManagerInfo: Removed broadcast_39_piece0 on localhost:35117 in memory (size: 5.3 KiB, free: 912.2 MiB)
21/02/17 01:34:13 INFO BlockManagerInfo: Removed broadcast_41_piece0 on localhost:35117 in memory (size: 5.2 KiB, free: 912.2 MiB)
21/02/17 01:34:13 INFO BlockManagerInfo: Removed broadcast_45_piece0 on localhost:35117 in memory (size: 5.0 KiB, free: 912.2 MiB)
21/02/17 01:34:13 INFO BlockManager: Removing RDD 105
21/02/17 01:34:13 INFO MemoryStore: Block broadcast_48 stored as values in memory (estimated size 294.6 KiB, free 911.5 MiB)
21/02/17 01:34:13 INFO MemoryStore: Block broadcast_48_piece0 stored as bytes in memory (estimated size 27.2 KiB, free 911.4 MiB)
21/02/17 01:34:13 INFO BlockManagerInfo: Added broadcast_48_piece0 in memory on localhost:35117 (size: 27.2 KiB, free: 912.2 MiB)
21/02/17 01:34:13 INFO SparkContext: Created broadcast 48 from textFile at ReadWrite.scala:587
21/02/17 01:34:13 INFO FileInputFormat: Total input files to process : 1
21/02/17 01:34:13 INFO SparkContext: Starting job: first at ReadWrite.scala:587
21/02/17 01:34:13 INFO DAGScheduler: Got job 32 (first at ReadWrite.scala:587) with 1 output partitions
21/02/17 01:34:13 INFO DAGScheduler: Final stage: ResultStage 44 (first at ReadWrite.scala:587)
21/02/17 01:34:13 INFO DAGScheduler: Parents of final stage: List()
21/02/17 01:34:13 INFO DAGScheduler: Missing parents: List()
21/02/17 01:34:13 INFO DAGScheduler: Submitting ResultStage 44 (/tmp/RtmpE1GwT4/file220626098807e/stages/0_r_formula__05ea37d3_e6ba_4801_96be_09a4389f822b/metadata MapPartitionsRDD[147] at textFile at ReadWrite.scala:587), which has no missing parents
21/02/17 01:34:13 INFO MemoryStore: Block broadcast_49 stored as values in memory (estimated size 4.2 KiB, free 911.4 MiB)
21/02/17 01:34:13 INFO MemoryStore: Block broadcast_49_piece0 stored as bytes in memory (estimated size 2.5 KiB, free 911.4 MiB)
21/02/17 01:34:13 INFO BlockManagerInfo: Added broadcast_49_piece0 in memory on localhost:35117 (size: 2.5 KiB, free: 912.2 MiB)
21/02/17 01:34:13 INFO SparkContext: Created broadcast 49 from broadcast at DAGScheduler.scala:1200
21/02/17 01:34:13 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 44 (/tmp/RtmpE1GwT4/file220626098807e/stages/0_r_formula__05ea37d3_e6ba_4801_96be_09a4389f822b/metadata MapPartitionsRDD[147] at textFile at ReadWrite.scala:587) (first 15 tasks are for partitions Vector(0))
21/02/17 01:34:13 INFO TaskSchedulerImpl: Adding task set 44.0 with 1 tasks
21/02/17 01:34:13 INFO TaskSetManager: Starting task 0.0 in stage 44.0 (TID 46, localhost, executor driver, partition 0, PROCESS_LOCAL, 7456 bytes)
21/02/17 01:34:13 INFO Executor: Running task 0.0 in stage 44.0 (TID 46)
21/02/17 01:34:13 INFO HadoopRDD: Input split: file:/tmp/RtmpE1GwT4/file220626098807e/stages/0_r_formula__05ea37d3_e6ba_4801_96be_09a4389f822b/metadata/part-00000:0+447
21/02/17 01:34:13 INFO Executor: Finished task 0.0 in stage 44.0 (TID 46). 1375 bytes result sent to driver
21/02/17 01:34:13 INFO TaskSetManager: Finished task 0.0 in stage 44.0 (TID 46) in 4 ms on localhost (executor driver) (1/1)
21/02/17 01:34:13 INFO TaskSchedulerImpl: Removed TaskSet 44.0, whose tasks have all completed, from pool 
21/02/17 01:34:13 INFO DAGScheduler: ResultStage 44 (first at ReadWrite.scala:587) finished in 0.009 s
21/02/17 01:34:13 INFO DAGScheduler: Job 32 is finished. Cancelling potential speculative or zombie tasks for this job
21/02/17 01:34:13 INFO TaskSchedulerImpl: Killing all running tasks in stage 44: Stage finished
21/02/17 01:34:13 INFO DAGScheduler: Job 32 finished: first at ReadWrite.scala:587, took 0.010386 s
21/02/17 01:34:13 INFO MemoryStore: Block broadcast_50 stored as values in memory (estimated size 294.6 KiB, free 911.1 MiB)
21/02/17 01:34:13 INFO MemoryStore: Block broadcast_50_piece0 stored as bytes in memory (estimated size 27.2 KiB, free 911.1 MiB)
21/02/17 01:34:14 INFO BlockManagerInfo: Added broadcast_50_piece0 in memory on localhost:35117 (size: 27.2 KiB, free: 912.1 MiB)
21/02/17 01:34:14 INFO SparkContext: Created broadcast 50 from textFile at ReadWrite.scala:587
21/02/17 01:34:14 INFO FileInputFormat: Total input files to process : 1
21/02/17 01:34:14 INFO SparkContext: Starting job: first at ReadWrite.scala:587
21/02/17 01:34:14 INFO DAGScheduler: Got job 33 (first at ReadWrite.scala:587) with 1 output partitions
21/02/17 01:34:14 INFO DAGScheduler: Final stage: ResultStage 45 (first at ReadWrite.scala:587)
21/02/17 01:34:14 INFO DAGScheduler: Parents of final stage: List()
21/02/17 01:34:14 INFO DAGScheduler: Missing parents: List()
21/02/17 01:34:14 INFO DAGScheduler: Submitting ResultStage 45 (/tmp/RtmpE1GwT4/file220626098807e/stages/0_r_formula__05ea37d3_e6ba_4801_96be_09a4389f822b/metadata MapPartitionsRDD[149] at textFile at ReadWrite.scala:587), which has no missing parents
21/02/17 01:34:14 INFO MemoryStore: Block broadcast_51 stored as values in memory (estimated size 4.2 KiB, free 911.1 MiB)
21/02/17 01:34:14 INFO MemoryStore: Block broadcast_51_piece0 stored as bytes in memory (estimated size 2.5 KiB, free 911.1 MiB)
21/02/17 01:34:14 INFO BlockManagerInfo: Added broadcast_51_piece0 in memory on localhost:35117 (size: 2.5 KiB, free: 912.1 MiB)
21/02/17 01:34:14 INFO SparkContext: Created broadcast 51 from broadcast at DAGScheduler.scala:1200
21/02/17 01:34:14 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 45 (/tmp/RtmpE1GwT4/file220626098807e/stages/0_r_formula__05ea37d3_e6ba_4801_96be_09a4389f822b/metadata MapPartitionsRDD[149] at textFile at ReadWrite.scala:587) (first 15 tasks are for partitions Vector(0))
21/02/17 01:34:14 INFO TaskSchedulerImpl: Adding task set 45.0 with 1 tasks
21/02/17 01:34:14 INFO TaskSetManager: Starting task 0.0 in stage 45.0 (TID 47, localhost, executor driver, partition 0, PROCESS_LOCAL, 7456 bytes)
21/02/17 01:34:14 INFO Executor: Running task 0.0 in stage 45.0 (TID 47)
21/02/17 01:34:14 INFO HadoopRDD: Input split: file:/tmp/RtmpE1GwT4/file220626098807e/stages/0_r_formula__05ea37d3_e6ba_4801_96be_09a4389f822b/metadata/part-00000:0+447
21/02/17 01:34:14 INFO Executor: Finished task 0.0 in stage 45.0 (TID 47). 1375 bytes result sent to driver
21/02/17 01:34:14 INFO TaskSetManager: Finished task 0.0 in stage 45.0 (TID 47) in 5 ms on localhost (executor driver) (1/1)
21/02/17 01:34:14 INFO TaskSchedulerImpl: Removed TaskSet 45.0, whose tasks have all completed, from pool 
21/02/17 01:34:14 INFO DAGScheduler: ResultStage 45 (first at ReadWrite.scala:587) finished in 0.010 s
21/02/17 01:34:14 INFO DAGScheduler: Job 33 is finished. Cancelling potential speculative or zombie tasks for this job
21/02/17 01:34:14 INFO TaskSchedulerImpl: Killing all running tasks in stage 45: Stage finished
21/02/17 01:34:14 INFO DAGScheduler: Job 33 finished: first at ReadWrite.scala:587, took 0.010818 s
21/02/17 01:34:14 INFO InMemoryFileIndex: It took 0 ms to list leaf files for 1 paths.
21/02/17 01:34:14 INFO SparkContext: Starting job: parquet at RFormula.scala:450
21/02/17 01:34:14 INFO DAGScheduler: Got job 34 (parquet at RFormula.scala:450) with 1 output partitions
21/02/17 01:34:14 INFO DAGScheduler: Final stage: ResultStage 46 (parquet at RFormula.scala:450)
21/02/17 01:34:14 INFO DAGScheduler: Parents of final stage: List()
21/02/17 01:34:14 INFO DAGScheduler: Missing parents: List()
21/02/17 01:34:14 INFO DAGScheduler: Submitting ResultStage 46 (MapPartitionsRDD[151] at parquet at RFormula.scala:450), which has no missing parents
21/02/17 01:34:14 INFO MemoryStore: Block broadcast_52 stored as values in memory (estimated size 87.9 KiB, free 911.0 MiB)
21/02/17 01:34:14 INFO MemoryStore: Block broadcast_52_piece0 stored as bytes in memory (estimated size 31.1 KiB, free 911.0 MiB)
21/02/17 01:34:14 INFO BlockManagerInfo: Added broadcast_52_piece0 in memory on localhost:35117 (size: 31.1 KiB, free: 912.1 MiB)
21/02/17 01:34:14 INFO SparkContext: Created broadcast 52 from broadcast at DAGScheduler.scala:1200
21/02/17 01:34:14 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 46 (MapPartitionsRDD[151] at parquet at RFormula.scala:450) (first 15 tasks are for partitions Vector(0))
21/02/17 01:34:14 INFO TaskSchedulerImpl: Adding task set 46.0 with 1 tasks
21/02/17 01:34:14 INFO TaskSetManager: Starting task 0.0 in stage 46.0 (TID 48, localhost, executor driver, partition 0, PROCESS_LOCAL, 7616 bytes)
21/02/17 01:34:14 INFO Executor: Running task 0.0 in stage 46.0 (TID 48)
21/02/17 01:34:14 INFO Executor: Finished task 0.0 in stage 46.0 (TID 48). 1835 bytes result sent to driver
21/02/17 01:34:14 INFO TaskSetManager: Finished task 0.0 in stage 46.0 (TID 48) in 35 ms on localhost (executor driver) (1/1)
21/02/17 01:34:14 INFO TaskSchedulerImpl: Removed TaskSet 46.0, whose tasks have all completed, from pool 
21/02/17 01:34:14 INFO DAGScheduler: ResultStage 46 (parquet at RFormula.scala:450) finished in 0.044 s
21/02/17 01:34:14 INFO DAGScheduler: Job 34 is finished. Cancelling potential speculative or zombie tasks for this job
21/02/17 01:34:14 INFO TaskSchedulerImpl: Killing all running tasks in stage 46: Stage finished
21/02/17 01:34:14 INFO DAGScheduler: Job 34 finished: parquet at RFormula.scala:450, took 0.045524 s
21/02/17 01:34:14 INFO FileSourceStrategy: Pruning directories with: 
21/02/17 01:34:14 INFO FileSourceStrategy: Pushed Filters: 
21/02/17 01:34:14 INFO FileSourceStrategy: Post-Scan Filters: 
21/02/17 01:34:14 INFO FileSourceStrategy: Output Data Schema: struct<label: string, terms: array<array<string>>, hasIntercept: boolean ... 1 more fields>
21/02/17 01:34:14 INFO MemoryStore: Block broadcast_53 stored as values in memory (estimated size 321.5 KiB, free 910.7 MiB)
21/02/17 01:34:14 INFO MemoryStore: Block broadcast_53_piece0 stored as bytes in memory (estimated size 29.6 KiB, free 910.6 MiB)
21/02/17 01:34:14 INFO BlockManagerInfo: Added broadcast_53_piece0 in memory on localhost:35117 (size: 29.6 KiB, free: 912.1 MiB)
21/02/17 01:34:14 INFO SparkContext: Created broadcast 53 from head at RFormula.scala:450
21/02/17 01:34:14 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
21/02/17 01:34:14 INFO SparkContext: Starting job: head at RFormula.scala:450
21/02/17 01:34:14 INFO DAGScheduler: Got job 35 (head at RFormula.scala:450) with 1 output partitions
21/02/17 01:34:14 INFO DAGScheduler: Final stage: ResultStage 47 (head at RFormula.scala:450)
21/02/17 01:34:14 INFO DAGScheduler: Parents of final stage: List()
21/02/17 01:34:14 INFO DAGScheduler: Missing parents: List()
21/02/17 01:34:14 INFO DAGScheduler: Submitting ResultStage 47 (MapPartitionsRDD[154] at head at RFormula.scala:450), which has no missing parents
21/02/17 01:34:14 INFO MemoryStore: Block broadcast_54 stored as values in memory (estimated size 9.1 KiB, free 910.6 MiB)
21/02/17 01:34:14 INFO MemoryStore: Block broadcast_54_piece0 stored as bytes in memory (estimated size 4.9 KiB, free 910.6 MiB)
21/02/17 01:34:14 INFO BlockManagerInfo: Added broadcast_54_piece0 in memory on localhost:35117 (size: 4.9 KiB, free: 912.1 MiB)
21/02/17 01:34:14 INFO SparkContext: Created broadcast 54 from broadcast at DAGScheduler.scala:1200
21/02/17 01:34:14 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 47 (MapPartitionsRDD[154] at head at RFormula.scala:450) (first 15 tasks are for partitions Vector(0))
21/02/17 01:34:14 INFO TaskSchedulerImpl: Adding task set 47.0 with 1 tasks
21/02/17 01:34:14 INFO TaskSetManager: Starting task 0.0 in stage 47.0 (TID 49, localhost, executor driver, partition 0, PROCESS_LOCAL, 7867 bytes)
21/02/17 01:34:14 INFO Executor: Running task 0.0 in stage 47.0 (TID 49)
21/02/17 01:34:14 INFO CodeGenerator: Code generated in 7.196712 ms
21/02/17 01:34:14 INFO FileScanRDD: Reading File path: file:///tmp/RtmpE1GwT4/file220626098807e/stages/0_r_formula__05ea37d3_e6ba_4801_96be_09a4389f822b/data/part-00000-559eedfd-8d0f-4b84-8dd0-485fd7e7e145-c000.snappy.parquet, range: 0-1140, partition values: [empty row]
21/02/17 01:34:14 INFO CodecPool: Got brand-new decompressor [.snappy]
21/02/17 01:34:14 INFO Executor: Finished task 0.0 in stage 47.0 (TID 49). 1790 bytes result sent to driver
21/02/17 01:34:14 INFO TaskSetManager: Finished task 0.0 in stage 47.0 (TID 49) in 99 ms on localhost (executor driver) (1/1)
21/02/17 01:34:14 INFO TaskSchedulerImpl: Removed TaskSet 47.0, whose tasks have all completed, from pool 
21/02/17 01:34:14 INFO DAGScheduler: ResultStage 47 (head at RFormula.scala:450) finished in 0.108 s
21/02/17 01:34:14 INFO DAGScheduler: Job 35 is finished. Cancelling potential speculative or zombie tasks for this job
21/02/17 01:34:14 INFO TaskSchedulerImpl: Killing all running tasks in stage 47: Stage finished
21/02/17 01:34:14 INFO DAGScheduler: Job 35 finished: head at RFormula.scala:450, took 0.111048 s
21/02/17 01:34:14 INFO CodeGenerator: Code generated in 13.435697 ms
21/02/17 01:34:14 INFO MemoryStore: Block broadcast_55 stored as values in memory (estimated size 294.6 KiB, free 910.3 MiB)
21/02/17 01:34:14 INFO MemoryStore: Block broadcast_55_piece0 stored as bytes in memory (estimated size 27.2 KiB, free 910.3 MiB)
21/02/17 01:34:14 INFO BlockManagerInfo: Added broadcast_55_piece0 in memory on localhost:35117 (size: 27.2 KiB, free: 912.1 MiB)
21/02/17 01:34:14 INFO SparkContext: Created broadcast 55 from textFile at ReadWrite.scala:587
21/02/17 01:34:14 INFO FileInputFormat: Total input files to process : 1
21/02/17 01:34:14 INFO SparkContext: Starting job: first at ReadWrite.scala:587
21/02/17 01:34:14 INFO DAGScheduler: Got job 36 (first at ReadWrite.scala:587) with 1 output partitions
21/02/17 01:34:14 INFO DAGScheduler: Final stage: ResultStage 48 (first at ReadWrite.scala:587)
21/02/17 01:34:14 INFO DAGScheduler: Parents of final stage: List()
21/02/17 01:34:14 INFO DAGScheduler: Missing parents: List()
21/02/17 01:34:14 INFO DAGScheduler: Submitting ResultStage 48 (/tmp/RtmpE1GwT4/file220626098807e/stages/0_r_formula__05ea37d3_e6ba_4801_96be_09a4389f822b/pipelineModel/metadata MapPartitionsRDD[156] at textFile at ReadWrite.scala:587), which has no missing parents
21/02/17 01:34:14 INFO MemoryStore: Block broadcast_56 stored as values in memory (estimated size 4.2 KiB, free 910.3 MiB)
21/02/17 01:34:14 INFO MemoryStore: Block broadcast_56_piece0 stored as bytes in memory (estimated size 2.5 KiB, free 910.3 MiB)
21/02/17 01:34:14 INFO BlockManagerInfo: Added broadcast_56_piece0 in memory on localhost:35117 (size: 2.5 KiB, free: 912.1 MiB)
21/02/17 01:34:14 INFO SparkContext: Created broadcast 56 from broadcast at DAGScheduler.scala:1200
21/02/17 01:34:14 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 48 (/tmp/RtmpE1GwT4/file220626098807e/stages/0_r_formula__05ea37d3_e6ba_4801_96be_09a4389f822b/pipelineModel/metadata MapPartitionsRDD[156] at textFile at ReadWrite.scala:587) (first 15 tasks are for partitions Vector(0))
21/02/17 01:34:14 INFO TaskSchedulerImpl: Adding task set 48.0 with 1 tasks
21/02/17 01:34:14 INFO TaskSetManager: Starting task 0.0 in stage 48.0 (TID 50, localhost, executor driver, partition 0, PROCESS_LOCAL, 7471 bytes)
21/02/17 01:34:14 INFO Executor: Running task 0.0 in stage 48.0 (TID 50)
21/02/17 01:34:14 INFO HadoopRDD: Input split: file:/tmp/RtmpE1GwT4/file220626098807e/stages/0_r_formula__05ea37d3_e6ba_4801_96be_09a4389f822b/pipelineModel/metadata/part-00000:0+311
21/02/17 01:34:14 INFO Executor: Finished task 0.0 in stage 48.0 (TID 50). 1239 bytes result sent to driver
21/02/17 01:34:14 INFO TaskSetManager: Finished task 0.0 in stage 48.0 (TID 50) in 6 ms on localhost (executor driver) (1/1)
21/02/17 01:34:14 INFO TaskSchedulerImpl: Removed TaskSet 48.0, whose tasks have all completed, from pool 
21/02/17 01:34:14 INFO DAGScheduler: ResultStage 48 (first at ReadWrite.scala:587) finished in 0.009 s
21/02/17 01:34:14 INFO DAGScheduler: Job 36 is finished. Cancelling potential speculative or zombie tasks for this job
21/02/17 01:34:14 INFO TaskSchedulerImpl: Killing all running tasks in stage 48: Stage finished
21/02/17 01:34:14 INFO DAGScheduler: Job 36 finished: first at ReadWrite.scala:587, took 0.011798 s
21/02/17 01:34:14 INFO MemoryStore: Block broadcast_57 stored as values in memory (estimated size 294.6 KiB, free 910.0 MiB)
21/02/17 01:34:14 INFO MemoryStore: Block broadcast_57_piece0 stored as bytes in memory (estimated size 27.2 KiB, free 910.0 MiB)
21/02/17 01:34:14 INFO BlockManagerInfo: Added broadcast_57_piece0 in memory on localhost:35117 (size: 27.2 KiB, free: 912.0 MiB)
21/02/17 01:34:14 INFO SparkContext: Created broadcast 57 from textFile at ReadWrite.scala:587
21/02/17 01:34:14 INFO FileInputFormat: Total input files to process : 1
21/02/17 01:34:14 INFO SparkContext: Starting job: first at ReadWrite.scala:587
21/02/17 01:34:14 INFO DAGScheduler: Got job 37 (first at ReadWrite.scala:587) with 1 output partitions
21/02/17 01:34:14 INFO DAGScheduler: Final stage: ResultStage 49 (first at ReadWrite.scala:587)
21/02/17 01:34:14 INFO DAGScheduler: Parents of final stage: List()
21/02/17 01:34:14 INFO DAGScheduler: Missing parents: List()
21/02/17 01:34:14 INFO DAGScheduler: Submitting ResultStage 49 (/tmp/RtmpE1GwT4/file220626098807e/stages/0_r_formula__05ea37d3_e6ba_4801_96be_09a4389f822b/pipelineModel/stages/0_r_formula__05ea37d3_e6ba_4801_96be_09a4389f822b/metadata MapPartitionsRDD[158] at textFile at ReadWrite.scala:587), which has no missing parents
21/02/17 01:34:14 INFO MemoryStore: Block broadcast_58 stored as values in memory (estimated size 4.3 KiB, free 910.0 MiB)
21/02/17 01:34:14 INFO MemoryStore: Block broadcast_58_piece0 stored as bytes in memory (estimated size 2.5 KiB, free 910.0 MiB)
21/02/17 01:34:14 INFO BlockManagerInfo: Added broadcast_58_piece0 in memory on localhost:35117 (size: 2.5 KiB, free: 912.0 MiB)
21/02/17 01:34:14 INFO SparkContext: Created broadcast 58 from broadcast at DAGScheduler.scala:1200
21/02/17 01:34:14 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 49 (/tmp/RtmpE1GwT4/file220626098807e/stages/0_r_formula__05ea37d3_e6ba_4801_96be_09a4389f822b/pipelineModel/stages/0_r_formula__05ea37d3_e6ba_4801_96be_09a4389f822b/metadata MapPartitionsRDD[158] at textFile at ReadWrite.scala:587) (first 15 tasks are for partitions Vector(0))
21/02/17 01:34:14 INFO TaskSchedulerImpl: Adding task set 49.0 with 1 tasks
21/02/17 01:34:14 INFO TaskSetManager: Starting task 0.0 in stage 49.0 (TID 51, localhost, executor driver, partition 0, PROCESS_LOCAL, 7531 bytes)
21/02/17 01:34:14 INFO Executor: Running task 0.0 in stage 49.0 (TID 51)
21/02/17 01:34:14 INFO HadoopRDD: Input split: file:/tmp/RtmpE1GwT4/file220626098807e/stages/0_r_formula__05ea37d3_e6ba_4801_96be_09a4389f822b/pipelineModel/stages/0_r_formula__05ea37d3_e6ba_4801_96be_09a4389f822b/metadata/part-00000:0+378
21/02/17 01:34:14 INFO Executor: Finished task 0.0 in stage 49.0 (TID 51). 1306 bytes result sent to driver
21/02/17 01:34:14 INFO TaskSetManager: Finished task 0.0 in stage 49.0 (TID 51) in 4 ms on localhost (executor driver) (1/1)
21/02/17 01:34:14 INFO TaskSchedulerImpl: Removed TaskSet 49.0, whose tasks have all completed, from pool 
21/02/17 01:34:14 INFO DAGScheduler: ResultStage 49 (first at ReadWrite.scala:587) finished in 0.007 s
21/02/17 01:34:14 INFO DAGScheduler: Job 37 is finished. Cancelling potential speculative or zombie tasks for this job
21/02/17 01:34:14 INFO TaskSchedulerImpl: Killing all running tasks in stage 49: Stage finished
21/02/17 01:34:14 INFO DAGScheduler: Job 37 finished: first at ReadWrite.scala:587, took 0.008887 s
21/02/17 01:34:14 INFO MemoryStore: Block broadcast_59 stored as values in memory (estimated size 294.6 KiB, free 909.7 MiB)
21/02/17 01:34:14 INFO MemoryStore: Block broadcast_59_piece0 stored as bytes in memory (estimated size 27.2 KiB, free 909.7 MiB)
21/02/17 01:34:14 INFO BlockManagerInfo: Added broadcast_59_piece0 in memory on localhost:35117 (size: 27.2 KiB, free: 912.0 MiB)
21/02/17 01:34:14 INFO SparkContext: Created broadcast 59 from textFile at ReadWrite.scala:587
21/02/17 01:34:14 INFO FileInputFormat: Total input files to process : 1
21/02/17 01:34:14 INFO SparkContext: Starting job: first at ReadWrite.scala:587
21/02/17 01:34:14 INFO DAGScheduler: Got job 38 (first at ReadWrite.scala:587) with 1 output partitions
21/02/17 01:34:14 INFO DAGScheduler: Final stage: ResultStage 50 (first at ReadWrite.scala:587)
21/02/17 01:34:14 INFO DAGScheduler: Parents of final stage: List()
21/02/17 01:34:14 INFO DAGScheduler: Missing parents: List()
21/02/17 01:34:14 INFO DAGScheduler: Submitting ResultStage 50 (/tmp/RtmpE1GwT4/file220626098807e/stages/0_r_formula__05ea37d3_e6ba_4801_96be_09a4389f822b/pipelineModel/stages/0_r_formula__05ea37d3_e6ba_4801_96be_09a4389f822b/metadata MapPartitionsRDD[160] at textFile at ReadWrite.scala:587), which has no missing parents
21/02/17 01:34:14 INFO MemoryStore: Block broadcast_60 stored as values in memory (estimated size 4.3 KiB, free 909.7 MiB)
21/02/17 01:34:14 INFO MemoryStore: Block broadcast_60_piece0 stored as bytes in memory (estimated size 2.5 KiB, free 909.7 MiB)
21/02/17 01:34:14 INFO BlockManagerInfo: Added broadcast_60_piece0 in memory on localhost:35117 (size: 2.5 KiB, free: 912.0 MiB)
21/02/17 01:34:14 INFO SparkContext: Created broadcast 60 from broadcast at DAGScheduler.scala:1200
21/02/17 01:34:14 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 50 (/tmp/RtmpE1GwT4/file220626098807e/stages/0_r_formula__05ea37d3_e6ba_4801_96be_09a4389f822b/pipelineModel/stages/0_r_formula__05ea37d3_e6ba_4801_96be_09a4389f822b/metadata MapPartitionsRDD[160] at textFile at ReadWrite.scala:587) (first 15 tasks are for partitions Vector(0))
21/02/17 01:34:14 INFO TaskSchedulerImpl: Adding task set 50.0 with 1 tasks
21/02/17 01:34:14 INFO TaskSetManager: Starting task 0.0 in stage 50.0 (TID 52, localhost, executor driver, partition 0, PROCESS_LOCAL, 7531 bytes)
21/02/17 01:34:14 INFO Executor: Running task 0.0 in stage 50.0 (TID 52)
21/02/17 01:34:14 INFO HadoopRDD: Input split: file:/tmp/RtmpE1GwT4/file220626098807e/stages/0_r_formula__05ea37d3_e6ba_4801_96be_09a4389f822b/pipelineModel/stages/0_r_formula__05ea37d3_e6ba_4801_96be_09a4389f822b/metadata/part-00000:0+378
21/02/17 01:34:14 INFO Executor: Finished task 0.0 in stage 50.0 (TID 52). 1263 bytes result sent to driver
21/02/17 01:34:14 INFO TaskSetManager: Finished task 0.0 in stage 50.0 (TID 52) in 3 ms on localhost (executor driver) (1/1)
21/02/17 01:34:14 INFO TaskSchedulerImpl: Removed TaskSet 50.0, whose tasks have all completed, from pool 
21/02/17 01:34:14 INFO DAGScheduler: ResultStage 50 (first at ReadWrite.scala:587) finished in 0.007 s
21/02/17 01:34:14 INFO DAGScheduler: Job 38 is finished. Cancelling potential speculative or zombie tasks for this job
21/02/17 01:34:14 INFO TaskSchedulerImpl: Killing all running tasks in stage 50: Stage finished
21/02/17 01:34:14 INFO DAGScheduler: Job 38 finished: first at ReadWrite.scala:587, took 0.008790 s
21/02/17 01:34:14 INFO MemoryStore: Block broadcast_61 stored as values in memory (estimated size 294.6 KiB, free 909.4 MiB)
21/02/17 01:34:14 INFO MemoryStore: Block broadcast_61_piece0 stored as bytes in memory (estimated size 27.2 KiB, free 909.3 MiB)
21/02/17 01:34:14 INFO BlockManagerInfo: Added broadcast_61_piece0 in memory on localhost:35117 (size: 27.2 KiB, free: 912.0 MiB)
21/02/17 01:34:14 INFO SparkContext: Created broadcast 61 from textFile at ReadWrite.scala:587
21/02/17 01:34:14 INFO FileInputFormat: Total input files to process : 1
21/02/17 01:34:14 INFO SparkContext: Starting job: first at ReadWrite.scala:587
21/02/17 01:34:14 INFO DAGScheduler: Got job 39 (first at ReadWrite.scala:587) with 1 output partitions
21/02/17 01:34:14 INFO DAGScheduler: Final stage: ResultStage 51 (first at ReadWrite.scala:587)
21/02/17 01:34:14 INFO DAGScheduler: Parents of final stage: List()
21/02/17 01:34:14 INFO DAGScheduler: Missing parents: List()
21/02/17 01:34:14 INFO DAGScheduler: Submitting ResultStage 51 (/tmp/RtmpE1GwT4/file220626098807e/stages/0_r_formula__05ea37d3_e6ba_4801_96be_09a4389f822b/pipelineModel/stages/1_vectorAttrRewriter_265a52885b23/metadata MapPartitionsRDD[162] at textFile at ReadWrite.scala:587), which has no missing parents
21/02/17 01:34:14 INFO MemoryStore: Block broadcast_62 stored as values in memory (estimated size 4.2 KiB, free 909.3 MiB)
21/02/17 01:34:14 INFO MemoryStore: Block broadcast_62_piece0 stored as bytes in memory (estimated size 2.5 KiB, free 909.3 MiB)
21/02/17 01:34:14 INFO BlockManagerInfo: Added broadcast_62_piece0 in memory on localhost:35117 (size: 2.5 KiB, free: 912.0 MiB)
21/02/17 01:34:14 INFO SparkContext: Created broadcast 62 from broadcast at DAGScheduler.scala:1200
21/02/17 01:34:14 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 51 (/tmp/RtmpE1GwT4/file220626098807e/stages/0_r_formula__05ea37d3_e6ba_4801_96be_09a4389f822b/pipelineModel/stages/1_vectorAttrRewriter_265a52885b23/metadata MapPartitionsRDD[162] at textFile at ReadWrite.scala:587) (first 15 tasks are for partitions Vector(0))
21/02/17 01:34:14 INFO TaskSchedulerImpl: Adding task set 51.0 with 1 tasks
21/02/17 01:34:14 INFO TaskSetManager: Starting task 0.0 in stage 51.0 (TID 53, localhost, executor driver, partition 0, PROCESS_LOCAL, 7515 bytes)
21/02/17 01:34:14 INFO Executor: Running task 0.0 in stage 51.0 (TID 53)
21/02/17 01:34:14 INFO HadoopRDD: Input split: file:/tmp/RtmpE1GwT4/file220626098807e/stages/0_r_formula__05ea37d3_e6ba_4801_96be_09a4389f822b/pipelineModel/stages/1_vectorAttrRewriter_265a52885b23/metadata/part-00000:0+188
21/02/17 01:34:14 INFO Executor: Finished task 0.0 in stage 51.0 (TID 53). 1070 bytes result sent to driver
21/02/17 01:34:14 INFO TaskSetManager: Finished task 0.0 in stage 51.0 (TID 53) in 4 ms on localhost (executor driver) (1/1)
21/02/17 01:34:14 INFO TaskSchedulerImpl: Removed TaskSet 51.0, whose tasks have all completed, from pool 
21/02/17 01:34:14 INFO DAGScheduler: ResultStage 51 (first at ReadWrite.scala:587) finished in 0.006 s
21/02/17 01:34:14 INFO DAGScheduler: Job 39 is finished. Cancelling potential speculative or zombie tasks for this job
21/02/17 01:34:14 INFO TaskSchedulerImpl: Killing all running tasks in stage 51: Stage finished
21/02/17 01:34:14 INFO DAGScheduler: Job 39 finished: first at ReadWrite.scala:587, took 0.007601 s
21/02/17 01:34:14 INFO MemoryStore: Block broadcast_63 stored as values in memory (estimated size 294.6 KiB, free 909.1 MiB)
21/02/17 01:34:14 INFO MemoryStore: Block broadcast_63_piece0 stored as bytes in memory (estimated size 27.2 KiB, free 909.0 MiB)
21/02/17 01:34:14 INFO BlockManagerInfo: Added broadcast_63_piece0 in memory on localhost:35117 (size: 27.2 KiB, free: 911.9 MiB)
21/02/17 01:34:14 INFO SparkContext: Created broadcast 63 from textFile at ReadWrite.scala:587
21/02/17 01:34:14 INFO FileInputFormat: Total input files to process : 1
21/02/17 01:34:14 INFO SparkContext: Starting job: first at ReadWrite.scala:587
21/02/17 01:34:14 INFO DAGScheduler: Got job 40 (first at ReadWrite.scala:587) with 1 output partitions
21/02/17 01:34:14 INFO DAGScheduler: Final stage: ResultStage 52 (first at ReadWrite.scala:587)
21/02/17 01:34:14 INFO DAGScheduler: Parents of final stage: List()
21/02/17 01:34:14 INFO DAGScheduler: Missing parents: List()
21/02/17 01:34:14 INFO DAGScheduler: Submitting ResultStage 52 (/tmp/RtmpE1GwT4/file220626098807e/stages/0_r_formula__05ea37d3_e6ba_4801_96be_09a4389f822b/pipelineModel/stages/1_vectorAttrRewriter_265a52885b23/metadata MapPartitionsRDD[164] at textFile at ReadWrite.scala:587), which has no missing parents
21/02/17 01:34:14 INFO MemoryStore: Block broadcast_64 stored as values in memory (estimated size 4.2 KiB, free 909.0 MiB)
21/02/17 01:34:14 INFO MemoryStore: Block broadcast_64_piece0 stored as bytes in memory (estimated size 2.5 KiB, free 909.0 MiB)
21/02/17 01:34:14 INFO BlockManagerInfo: Added broadcast_64_piece0 in memory on localhost:35117 (size: 2.5 KiB, free: 911.9 MiB)
21/02/17 01:34:14 INFO SparkContext: Created broadcast 64 from broadcast at DAGScheduler.scala:1200
21/02/17 01:34:14 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 52 (/tmp/RtmpE1GwT4/file220626098807e/stages/0_r_formula__05ea37d3_e6ba_4801_96be_09a4389f822b/pipelineModel/stages/1_vectorAttrRewriter_265a52885b23/metadata MapPartitionsRDD[164] at textFile at ReadWrite.scala:587) (first 15 tasks are for partitions Vector(0))
21/02/17 01:34:14 INFO TaskSchedulerImpl: Adding task set 52.0 with 1 tasks
21/02/17 01:34:14 INFO TaskSetManager: Starting task 0.0 in stage 52.0 (TID 54, localhost, executor driver, partition 0, PROCESS_LOCAL, 7515 bytes)
21/02/17 01:34:14 INFO Executor: Running task 0.0 in stage 52.0 (TID 54)
21/02/17 01:34:14 INFO HadoopRDD: Input split: file:/tmp/RtmpE1GwT4/file220626098807e/stages/0_r_formula__05ea37d3_e6ba_4801_96be_09a4389f822b/pipelineModel/stages/1_vectorAttrRewriter_265a52885b23/metadata/part-00000:0+188
21/02/17 01:34:14 INFO Executor: Finished task 0.0 in stage 52.0 (TID 54). 1070 bytes result sent to driver
21/02/17 01:34:14 INFO TaskSetManager: Finished task 0.0 in stage 52.0 (TID 54) in 4 ms on localhost (executor driver) (1/1)
21/02/17 01:34:14 INFO TaskSchedulerImpl: Removed TaskSet 52.0, whose tasks have all completed, from pool 
21/02/17 01:34:14 INFO DAGScheduler: ResultStage 52 (first at ReadWrite.scala:587) finished in 0.006 s
21/02/17 01:34:14 INFO DAGScheduler: Job 40 is finished. Cancelling potential speculative or zombie tasks for this job
21/02/17 01:34:14 INFO TaskSchedulerImpl: Killing all running tasks in stage 52: Stage finished
21/02/17 01:34:14 INFO DAGScheduler: Job 40 finished: first at ReadWrite.scala:587, took 0.007882 s
21/02/17 01:34:14 INFO InMemoryFileIndex: It took 1 ms to list leaf files for 1 paths.
21/02/17 01:34:14 INFO SparkContext: Starting job: parquet at RFormula.scala:612
21/02/17 01:34:14 INFO DAGScheduler: Got job 41 (parquet at RFormula.scala:612) with 1 output partitions
21/02/17 01:34:14 INFO DAGScheduler: Final stage: ResultStage 53 (parquet at RFormula.scala:612)
21/02/17 01:34:14 INFO DAGScheduler: Parents of final stage: List()
21/02/17 01:34:14 INFO DAGScheduler: Missing parents: List()
21/02/17 01:34:14 INFO DAGScheduler: Submitting ResultStage 53 (MapPartitionsRDD[166] at parquet at RFormula.scala:612), which has no missing parents
21/02/17 01:34:14 INFO MemoryStore: Block broadcast_65 stored as values in memory (estimated size 87.9 KiB, free 908.9 MiB)
21/02/17 01:34:14 INFO MemoryStore: Block broadcast_65_piece0 stored as bytes in memory (estimated size 31.1 KiB, free 908.9 MiB)
21/02/17 01:34:14 INFO BlockManagerInfo: Added broadcast_65_piece0 in memory on localhost:35117 (size: 31.1 KiB, free: 911.9 MiB)
21/02/17 01:34:14 INFO SparkContext: Created broadcast 65 from broadcast at DAGScheduler.scala:1200
21/02/17 01:34:14 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 53 (MapPartitionsRDD[166] at parquet at RFormula.scala:612) (first 15 tasks are for partitions Vector(0))
21/02/17 01:34:14 INFO TaskSchedulerImpl: Adding task set 53.0 with 1 tasks
21/02/17 01:34:14 INFO TaskSetManager: Starting task 0.0 in stage 53.0 (TID 55, localhost, executor driver, partition 0, PROCESS_LOCAL, 7671 bytes)
21/02/17 01:34:14 INFO Executor: Running task 0.0 in stage 53.0 (TID 55)
21/02/17 01:34:14 INFO Executor: Finished task 0.0 in stage 53.0 (TID 55). 1769 bytes result sent to driver
21/02/17 01:34:14 INFO TaskSetManager: Finished task 0.0 in stage 53.0 (TID 55) in 8 ms on localhost (executor driver) (1/1)
21/02/17 01:34:14 INFO TaskSchedulerImpl: Removed TaskSet 53.0, whose tasks have all completed, from pool 
21/02/17 01:34:14 INFO DAGScheduler: ResultStage 53 (parquet at RFormula.scala:612) finished in 0.016 s
21/02/17 01:34:14 INFO DAGScheduler: Job 41 is finished. Cancelling potential speculative or zombie tasks for this job
21/02/17 01:34:14 INFO TaskSchedulerImpl: Killing all running tasks in stage 53: Stage finished
21/02/17 01:34:14 INFO DAGScheduler: Job 41 finished: parquet at RFormula.scala:612, took 0.017689 s
21/02/17 01:34:14 INFO FileSourceStrategy: Pruning directories with: 
21/02/17 01:34:14 INFO FileSourceStrategy: Pushed Filters: 
21/02/17 01:34:14 INFO FileSourceStrategy: Post-Scan Filters: 
21/02/17 01:34:14 INFO FileSourceStrategy: Output Data Schema: struct<vectorCol: string, prefixesToRewrite: map<string,string>>
21/02/17 01:34:14 INFO MemoryStore: Block broadcast_66 stored as values in memory (estimated size 321.1 KiB, free 908.6 MiB)
21/02/17 01:34:14 INFO MemoryStore: Block broadcast_66_piece0 stored as bytes in memory (estimated size 29.6 KiB, free 908.6 MiB)
21/02/17 01:34:14 INFO BlockManagerInfo: Added broadcast_66_piece0 in memory on localhost:35117 (size: 29.6 KiB, free: 911.9 MiB)
21/02/17 01:34:14 INFO SparkContext: Created broadcast 66 from head at RFormula.scala:612
21/02/17 01:34:14 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
21/02/17 01:34:14 INFO SparkContext: Starting job: head at RFormula.scala:612
21/02/17 01:34:14 INFO DAGScheduler: Got job 42 (head at RFormula.scala:612) with 1 output partitions
21/02/17 01:34:14 INFO DAGScheduler: Final stage: ResultStage 54 (head at RFormula.scala:612)
21/02/17 01:34:14 INFO DAGScheduler: Parents of final stage: List()
21/02/17 01:34:14 INFO DAGScheduler: Missing parents: List()
21/02/17 01:34:14 INFO DAGScheduler: Submitting ResultStage 54 (MapPartitionsRDD[169] at head at RFormula.scala:612), which has no missing parents
21/02/17 01:34:14 INFO MemoryStore: Block broadcast_67 stored as values in memory (estimated size 9.1 KiB, free 908.6 MiB)
21/02/17 01:34:14 INFO MemoryStore: Block broadcast_67_piece0 stored as bytes in memory (estimated size 4.8 KiB, free 908.5 MiB)
21/02/17 01:34:14 INFO BlockManagerInfo: Added broadcast_67_piece0 in memory on localhost:35117 (size: 4.8 KiB, free: 911.9 MiB)
21/02/17 01:34:14 INFO SparkContext: Created broadcast 67 from broadcast at DAGScheduler.scala:1200
21/02/17 01:34:14 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 54 (MapPartitionsRDD[169] at head at RFormula.scala:612) (first 15 tasks are for partitions Vector(0))
21/02/17 01:34:14 INFO TaskSchedulerImpl: Adding task set 54.0 with 1 tasks
21/02/17 01:34:14 INFO TaskSetManager: Starting task 0.0 in stage 54.0 (TID 56, localhost, executor driver, partition 0, PROCESS_LOCAL, 7922 bytes)
21/02/17 01:34:14 INFO Executor: Running task 0.0 in stage 54.0 (TID 56)
21/02/17 01:34:14 INFO FileScanRDD: Reading File path: file:///tmp/RtmpE1GwT4/file220626098807e/stages/0_r_formula__05ea37d3_e6ba_4801_96be_09a4389f822b/pipelineModel/stages/1_vectorAttrRewriter_265a52885b23/data/part-00000-c5e4e9bd-ae22-484b-b4bd-d64e0df64897-c000.snappy.parquet, range: 0-927, partition values: [empty row]
21/02/17 01:34:14 INFO Executor: Finished task 0.0 in stage 54.0 (TID 56). 1728 bytes result sent to driver
21/02/17 01:34:14 INFO TaskSetManager: Finished task 0.0 in stage 54.0 (TID 56) in 12 ms on localhost (executor driver) (1/1)
21/02/17 01:34:14 INFO TaskSchedulerImpl: Removed TaskSet 54.0, whose tasks have all completed, from pool 
21/02/17 01:34:14 INFO DAGScheduler: ResultStage 54 (head at RFormula.scala:612) finished in 0.017 s
21/02/17 01:34:14 INFO DAGScheduler: Job 42 is finished. Cancelling potential speculative or zombie tasks for this job
21/02/17 01:34:14 INFO TaskSchedulerImpl: Killing all running tasks in stage 54: Stage finished
21/02/17 01:34:14 INFO DAGScheduler: Job 42 finished: head at RFormula.scala:612, took 0.018387 s
21/02/17 01:34:14 INFO CodeGenerator: Code generated in 20.095258 ms
21/02/17 01:34:14 INFO MemoryStore: Block broadcast_68 stored as values in memory (estimated size 294.6 KiB, free 908.3 MiB)
21/02/17 01:34:14 INFO MemoryStore: Block broadcast_68_piece0 stored as bytes in memory (estimated size 27.2 KiB, free 908.2 MiB)
21/02/17 01:34:14 INFO BlockManagerInfo: Added broadcast_68_piece0 in memory on localhost:35117 (size: 27.2 KiB, free: 911.8 MiB)
21/02/17 01:34:14 INFO SparkContext: Created broadcast 68 from textFile at ReadWrite.scala:587
21/02/17 01:34:14 INFO FileInputFormat: Total input files to process : 1
21/02/17 01:34:14 INFO SparkContext: Starting job: first at ReadWrite.scala:587
21/02/17 01:34:14 INFO DAGScheduler: Got job 43 (first at ReadWrite.scala:587) with 1 output partitions
21/02/17 01:34:14 INFO DAGScheduler: Final stage: ResultStage 55 (first at ReadWrite.scala:587)
21/02/17 01:34:14 INFO DAGScheduler: Parents of final stage: List()
21/02/17 01:34:14 INFO DAGScheduler: Missing parents: List()
21/02/17 01:34:14 INFO DAGScheduler: Submitting ResultStage 55 (/tmp/RtmpE1GwT4/file220626098807e/stages/0_r_formula__05ea37d3_e6ba_4801_96be_09a4389f822b/pipelineModel/stages/2_columnPruner_bce5020be839/metadata MapPartitionsRDD[171] at textFile at ReadWrite.scala:587), which has no missing parents
21/02/17 01:34:14 INFO MemoryStore: Block broadcast_69 stored as values in memory (estimated size 4.2 KiB, free 908.2 MiB)
21/02/17 01:34:14 INFO MemoryStore: Block broadcast_69_piece0 stored as bytes in memory (estimated size 2.5 KiB, free 908.2 MiB)
21/02/17 01:34:14 INFO BlockManagerInfo: Added broadcast_69_piece0 in memory on localhost:35117 (size: 2.5 KiB, free: 911.8 MiB)
21/02/17 01:34:14 INFO SparkContext: Created broadcast 69 from broadcast at DAGScheduler.scala:1200
21/02/17 01:34:14 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 55 (/tmp/RtmpE1GwT4/file220626098807e/stages/0_r_formula__05ea37d3_e6ba_4801_96be_09a4389f822b/pipelineModel/stages/2_columnPruner_bce5020be839/metadata MapPartitionsRDD[171] at textFile at ReadWrite.scala:587) (first 15 tasks are for partitions Vector(0))
21/02/17 01:34:14 INFO TaskSchedulerImpl: Adding task set 55.0 with 1 tasks
21/02/17 01:34:14 INFO TaskSetManager: Starting task 0.0 in stage 55.0 (TID 57, localhost, executor driver, partition 0, PROCESS_LOCAL, 7506 bytes)
21/02/17 01:34:14 INFO Executor: Running task 0.0 in stage 55.0 (TID 57)
21/02/17 01:34:14 INFO HadoopRDD: Input split: file:/tmp/RtmpE1GwT4/file220626098807e/stages/0_r_formula__05ea37d3_e6ba_4801_96be_09a4389f822b/pipelineModel/stages/2_columnPruner_bce5020be839/metadata/part-00000:0+171
21/02/17 01:34:14 INFO Executor: Finished task 0.0 in stage 55.0 (TID 57). 1096 bytes result sent to driver
21/02/17 01:34:14 INFO TaskSetManager: Finished task 0.0 in stage 55.0 (TID 57) in 4 ms on localhost (executor driver) (1/1)
21/02/17 01:34:14 INFO TaskSchedulerImpl: Removed TaskSet 55.0, whose tasks have all completed, from pool 
21/02/17 01:34:14 INFO DAGScheduler: ResultStage 55 (first at ReadWrite.scala:587) finished in 0.008 s
21/02/17 01:34:14 INFO DAGScheduler: Job 43 is finished. Cancelling potential speculative or zombie tasks for this job
21/02/17 01:34:14 INFO TaskSchedulerImpl: Killing all running tasks in stage 55: Stage finished
21/02/17 01:34:14 INFO DAGScheduler: Job 43 finished: first at ReadWrite.scala:587, took 0.008863 s
21/02/17 01:34:14 INFO MemoryStore: Block broadcast_70 stored as values in memory (estimated size 294.6 KiB, free 907.9 MiB)
21/02/17 01:34:14 INFO MemoryStore: Block broadcast_70_piece0 stored as bytes in memory (estimated size 27.2 KiB, free 907.9 MiB)
21/02/17 01:34:14 INFO BlockManagerInfo: Added broadcast_70_piece0 in memory on localhost:35117 (size: 27.2 KiB, free: 911.8 MiB)
21/02/17 01:34:14 INFO SparkContext: Created broadcast 70 from textFile at ReadWrite.scala:587
21/02/17 01:34:14 INFO FileInputFormat: Total input files to process : 1
21/02/17 01:34:14 INFO SparkContext: Starting job: first at ReadWrite.scala:587
21/02/17 01:34:14 INFO DAGScheduler: Got job 44 (first at ReadWrite.scala:587) with 1 output partitions
21/02/17 01:34:14 INFO DAGScheduler: Final stage: ResultStage 56 (first at ReadWrite.scala:587)
21/02/17 01:34:14 INFO DAGScheduler: Parents of final stage: List()
21/02/17 01:34:14 INFO DAGScheduler: Missing parents: List()
21/02/17 01:34:14 INFO DAGScheduler: Submitting ResultStage 56 (/tmp/RtmpE1GwT4/file220626098807e/stages/0_r_formula__05ea37d3_e6ba_4801_96be_09a4389f822b/pipelineModel/stages/2_columnPruner_bce5020be839/metadata MapPartitionsRDD[173] at textFile at ReadWrite.scala:587), which has no missing parents
21/02/17 01:34:14 INFO MemoryStore: Block broadcast_71 stored as values in memory (estimated size 4.2 KiB, free 907.9 MiB)
21/02/17 01:34:14 INFO MemoryStore: Block broadcast_71_piece0 stored as bytes in memory (estimated size 2.5 KiB, free 907.9 MiB)
21/02/17 01:34:14 INFO BlockManagerInfo: Added broadcast_71_piece0 in memory on localhost:35117 (size: 2.5 KiB, free: 911.8 MiB)
21/02/17 01:34:14 INFO SparkContext: Created broadcast 71 from broadcast at DAGScheduler.scala:1200
21/02/17 01:34:14 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 56 (/tmp/RtmpE1GwT4/file220626098807e/stages/0_r_formula__05ea37d3_e6ba_4801_96be_09a4389f822b/pipelineModel/stages/2_columnPruner_bce5020be839/metadata MapPartitionsRDD[173] at textFile at ReadWrite.scala:587) (first 15 tasks are for partitions Vector(0))
21/02/17 01:34:14 INFO TaskSchedulerImpl: Adding task set 56.0 with 1 tasks
21/02/17 01:34:14 INFO TaskSetManager: Starting task 0.0 in stage 56.0 (TID 58, localhost, executor driver, partition 0, PROCESS_LOCAL, 7506 bytes)
21/02/17 01:34:14 INFO Executor: Running task 0.0 in stage 56.0 (TID 58)
21/02/17 01:34:14 INFO HadoopRDD: Input split: file:/tmp/RtmpE1GwT4/file220626098807e/stages/0_r_formula__05ea37d3_e6ba_4801_96be_09a4389f822b/pipelineModel/stages/2_columnPruner_bce5020be839/metadata/part-00000:0+171
21/02/17 01:34:14 INFO Executor: Finished task 0.0 in stage 56.0 (TID 58). 1053 bytes result sent to driver
21/02/17 01:34:14 INFO TaskSetManager: Finished task 0.0 in stage 56.0 (TID 58) in 3 ms on localhost (executor driver) (1/1)
21/02/17 01:34:14 INFO TaskSchedulerImpl: Removed TaskSet 56.0, whose tasks have all completed, from pool 
21/02/17 01:34:14 INFO DAGScheduler: ResultStage 56 (first at ReadWrite.scala:587) finished in 0.007 s
21/02/17 01:34:14 INFO DAGScheduler: Job 44 is finished. Cancelling potential speculative or zombie tasks for this job
21/02/17 01:34:14 INFO TaskSchedulerImpl: Killing all running tasks in stage 56: Stage finished
21/02/17 01:34:14 INFO DAGScheduler: Job 44 finished: first at ReadWrite.scala:587, took 0.008277 s
21/02/17 01:34:14 INFO InMemoryFileIndex: It took 0 ms to list leaf files for 1 paths.
21/02/17 01:34:14 INFO SparkContext: Starting job: parquet at RFormula.scala:521
21/02/17 01:34:14 INFO DAGScheduler: Got job 45 (parquet at RFormula.scala:521) with 1 output partitions
21/02/17 01:34:14 INFO DAGScheduler: Final stage: ResultStage 57 (parquet at RFormula.scala:521)
21/02/17 01:34:14 INFO DAGScheduler: Parents of final stage: List()
21/02/17 01:34:14 INFO DAGScheduler: Missing parents: List()
21/02/17 01:34:14 INFO DAGScheduler: Submitting ResultStage 57 (MapPartitionsRDD[175] at parquet at RFormula.scala:521), which has no missing parents
21/02/17 01:34:14 INFO MemoryStore: Block broadcast_72 stored as values in memory (estimated size 87.9 KiB, free 907.8 MiB)
21/02/17 01:34:14 INFO MemoryStore: Block broadcast_72_piece0 stored as bytes in memory (estimated size 31.1 KiB, free 907.8 MiB)
21/02/17 01:34:14 INFO BlockManagerInfo: Added broadcast_72_piece0 in memory on localhost:35117 (size: 31.1 KiB, free: 911.8 MiB)
21/02/17 01:34:14 INFO SparkContext: Created broadcast 72 from broadcast at DAGScheduler.scala:1200
21/02/17 01:34:14 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 57 (MapPartitionsRDD[175] at parquet at RFormula.scala:521) (first 15 tasks are for partitions Vector(0))
21/02/17 01:34:14 INFO TaskSchedulerImpl: Adding task set 57.0 with 1 tasks
21/02/17 01:34:14 INFO TaskSetManager: Starting task 0.0 in stage 57.0 (TID 59, localhost, executor driver, partition 0, PROCESS_LOCAL, 7665 bytes)
21/02/17 01:34:14 INFO Executor: Running task 0.0 in stage 57.0 (TID 59)
21/02/17 01:34:14 INFO Executor: Finished task 0.0 in stage 57.0 (TID 59). 1705 bytes result sent to driver
21/02/17 01:34:14 INFO TaskSetManager: Finished task 0.0 in stage 57.0 (TID 59) in 10 ms on localhost (executor driver) (1/1)
21/02/17 01:34:14 INFO TaskSchedulerImpl: Removed TaskSet 57.0, whose tasks have all completed, from pool 
21/02/17 01:34:14 INFO DAGScheduler: ResultStage 57 (parquet at RFormula.scala:521) finished in 0.019 s
21/02/17 01:34:14 INFO DAGScheduler: Job 45 is finished. Cancelling potential speculative or zombie tasks for this job
21/02/17 01:34:14 INFO TaskSchedulerImpl: Killing all running tasks in stage 57: Stage finished
21/02/17 01:34:14 INFO DAGScheduler: Job 45 finished: parquet at RFormula.scala:521, took 0.021613 s
21/02/17 01:34:14 INFO FileSourceStrategy: Pruning directories with: 
21/02/17 01:34:14 INFO FileSourceStrategy: Pushed Filters: 
21/02/17 01:34:14 INFO FileSourceStrategy: Post-Scan Filters: 
21/02/17 01:34:14 INFO FileSourceStrategy: Output Data Schema: struct<columnsToPrune: array<string>>
21/02/17 01:34:14 INFO MemoryStore: Block broadcast_73 stored as values in memory (estimated size 320.8 KiB, free 907.5 MiB)
21/02/17 01:34:14 INFO MemoryStore: Block broadcast_73_piece0 stored as bytes in memory (estimated size 29.6 KiB, free 907.4 MiB)
21/02/17 01:34:14 INFO BlockManagerInfo: Added broadcast_73_piece0 in memory on localhost:35117 (size: 29.6 KiB, free: 911.8 MiB)
21/02/17 01:34:14 INFO SparkContext: Created broadcast 73 from head at RFormula.scala:521
21/02/17 01:34:14 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
21/02/17 01:34:14 INFO BlockManagerInfo: Removed broadcast_66_piece0 on localhost:35117 in memory (size: 29.6 KiB, free: 911.8 MiB)
21/02/17 01:34:14 INFO BlockManagerInfo: Removed broadcast_47_piece0 on localhost:35117 in memory (size: 2.4 KiB, free: 911.8 MiB)
21/02/17 01:34:14 INFO BlockManagerInfo: Removed broadcast_50_piece0 on localhost:35117 in memory (size: 27.2 KiB, free: 911.8 MiB)
21/02/17 01:34:14 INFO BlockManagerInfo: Removed broadcast_46_piece0 on localhost:35117 in memory (size: 27.2 KiB, free: 911.8 MiB)
21/02/17 01:34:14 INFO SparkContext: Starting job: head at RFormula.scala:521
21/02/17 01:34:14 INFO BlockManagerInfo: Removed broadcast_57_piece0 on localhost:35117 in memory (size: 27.2 KiB, free: 911.9 MiB)
21/02/17 01:34:14 INFO DAGScheduler: Got job 46 (head at RFormula.scala:521) with 1 output partitions
21/02/17 01:34:14 INFO DAGScheduler: Final stage: ResultStage 58 (head at RFormula.scala:521)
21/02/17 01:34:14 INFO DAGScheduler: Parents of final stage: List()
21/02/17 01:34:14 INFO DAGScheduler: Missing parents: List()
21/02/17 01:34:14 INFO DAGScheduler: Submitting ResultStage 58 (MapPartitionsRDD[178] at head at RFormula.scala:521), which has no missing parents
21/02/17 01:34:14 INFO BlockManagerInfo: Removed broadcast_48_piece0 on localhost:35117 in memory (size: 27.2 KiB, free: 911.9 MiB)
21/02/17 01:34:14 INFO BlockManagerInfo: Removed broadcast_64_piece0 on localhost:35117 in memory (size: 2.5 KiB, free: 911.9 MiB)
21/02/17 01:34:14 INFO MemoryStore: Block broadcast_74 stored as values in memory (estimated size 8.9 KiB, free 909.1 MiB)
21/02/17 01:34:14 INFO BlockManagerInfo: Removed broadcast_56_piece0 on localhost:35117 in memory (size: 2.5 KiB, free: 911.9 MiB)
21/02/17 01:34:14 INFO MemoryStore: Block broadcast_74_piece0 stored as bytes in memory (estimated size 4.8 KiB, free 909.1 MiB)
21/02/17 01:34:14 INFO BlockManagerInfo: Added broadcast_74_piece0 in memory on localhost:35117 (size: 4.8 KiB, free: 911.9 MiB)
21/02/17 01:34:14 INFO SparkContext: Created broadcast 74 from broadcast at DAGScheduler.scala:1200
21/02/17 01:34:14 INFO BlockManagerInfo: Removed broadcast_65_piece0 on localhost:35117 in memory (size: 31.1 KiB, free: 911.9 MiB)
21/02/17 01:34:14 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 58 (MapPartitionsRDD[178] at head at RFormula.scala:521) (first 15 tasks are for partitions Vector(0))
21/02/17 01:34:14 INFO TaskSchedulerImpl: Adding task set 58.0 with 1 tasks
21/02/17 01:34:14 INFO BlockManagerInfo: Removed broadcast_72_piece0 on localhost:35117 in memory (size: 31.1 KiB, free: 912.0 MiB)
21/02/17 01:34:14 INFO TaskSetManager: Starting task 0.0 in stage 58.0 (TID 60, localhost, executor driver, partition 0, PROCESS_LOCAL, 7916 bytes)
21/02/17 01:34:14 INFO Executor: Running task 0.0 in stage 58.0 (TID 60)
21/02/17 01:34:14 INFO BlockManagerInfo: Removed broadcast_61_piece0 on localhost:35117 in memory (size: 27.2 KiB, free: 912.0 MiB)
21/02/17 01:34:14 INFO BlockManagerInfo: Removed broadcast_54_piece0 on localhost:35117 in memory (size: 4.9 KiB, free: 912.0 MiB)
21/02/17 01:34:14 INFO BlockManagerInfo: Removed broadcast_70_piece0 on localhost:35117 in memory (size: 27.2 KiB, free: 912.0 MiB)
21/02/17 01:34:14 INFO FileScanRDD: Reading File path: file:///tmp/RtmpE1GwT4/file220626098807e/stages/0_r_formula__05ea37d3_e6ba_4801_96be_09a4389f822b/pipelineModel/stages/2_columnPruner_bce5020be839/data/part-00000-cc2447f4-d539-402b-b519-94d33619bfe3-c000.snappy.parquet, range: 0-510, partition values: [empty row]
21/02/17 01:34:14 INFO BlockManagerInfo: Removed broadcast_60_piece0 on localhost:35117 in memory (size: 2.5 KiB, free: 912.0 MiB)
21/02/17 01:34:14 INFO BlockManagerInfo: Removed broadcast_71_piece0 on localhost:35117 in memory (size: 2.5 KiB, free: 912.0 MiB)
21/02/17 01:34:14 INFO BlockManagerInfo: Removed broadcast_51_piece0 on localhost:35117 in memory (size: 2.5 KiB, free: 912.0 MiB)
21/02/17 01:34:14 INFO BlockManagerInfo: Removed broadcast_55_piece0 on localhost:35117 in memory (size: 27.2 KiB, free: 912.0 MiB)
21/02/17 01:34:14 INFO BlockManagerInfo: Removed broadcast_59_piece0 on localhost:35117 in memory (size: 27.2 KiB, free: 912.1 MiB)
21/02/17 01:34:14 INFO BlockManagerInfo: Removed broadcast_49_piece0 on localhost:35117 in memory (size: 2.5 KiB, free: 912.1 MiB)
21/02/17 01:34:14 INFO Executor: Finished task 0.0 in stage 58.0 (TID 60). 1709 bytes result sent to driver
21/02/17 01:34:14 INFO TaskSetManager: Finished task 0.0 in stage 58.0 (TID 60) in 9 ms on localhost (executor driver) (1/1)
21/02/17 01:34:14 INFO BlockManagerInfo: Removed broadcast_63_piece0 on localhost:35117 in memory (size: 27.2 KiB, free: 912.1 MiB)
21/02/17 01:34:14 INFO TaskSchedulerImpl: Removed TaskSet 58.0, whose tasks have all completed, from pool 
21/02/17 01:34:14 INFO DAGScheduler: ResultStage 58 (head at RFormula.scala:521) finished in 0.013 s
21/02/17 01:34:14 INFO DAGScheduler: Job 46 is finished. Cancelling potential speculative or zombie tasks for this job
21/02/17 01:34:14 INFO TaskSchedulerImpl: Killing all running tasks in stage 58: Stage finished
21/02/17 01:34:14 INFO DAGScheduler: Job 46 finished: head at RFormula.scala:521, took 0.014598 s
21/02/17 01:34:14 INFO BlockManagerInfo: Removed broadcast_62_piece0 on localhost:35117 in memory (size: 2.5 KiB, free: 912.1 MiB)
21/02/17 01:34:14 INFO BlockManagerInfo: Removed broadcast_52_piece0 on localhost:35117 in memory (size: 31.1 KiB, free: 912.1 MiB)
21/02/17 01:34:14 INFO BlockManagerInfo: Removed broadcast_67_piece0 on localhost:35117 in memory (size: 4.8 KiB, free: 912.1 MiB)
21/02/17 01:34:14 INFO BlockManagerInfo: Removed broadcast_58_piece0 on localhost:35117 in memory (size: 2.5 KiB, free: 912.1 MiB)
21/02/17 01:34:14 INFO BlockManagerInfo: Removed broadcast_68_piece0 on localhost:35117 in memory (size: 27.2 KiB, free: 912.2 MiB)
21/02/17 01:34:14 INFO BlockManagerInfo: Removed broadcast_69_piece0 on localhost:35117 in memory (size: 2.5 KiB, free: 912.2 MiB)
21/02/17 01:34:14 INFO BlockManagerInfo: Removed broadcast_53_piece0 on localhost:35117 in memory (size: 29.6 KiB, free: 912.2 MiB)
21/02/17 01:34:14 INFO CodeGenerator: Code generated in 13.57493 ms
21/02/17 01:34:14 INFO Instrumentation: [812fd430] training finished
21/02/17 01:34:14 INFO Instrumentation: [8156f980] training finished
21/02/17 01:34:14 INFO MemoryStore: Block broadcast_75 stored as values in memory (estimated size 294.6 KiB, free 911.4 MiB)
21/02/17 01:34:14 INFO MemoryStore: Block broadcast_75_piece0 stored as bytes in memory (estimated size 27.2 KiB, free 911.4 MiB)
21/02/17 01:34:14 INFO BlockManagerInfo: Added broadcast_75_piece0 in memory on localhost:35117 (size: 27.2 KiB, free: 912.2 MiB)
21/02/17 01:34:14 INFO SparkContext: Created broadcast 75 from textFile at ReadWrite.scala:587
21/02/17 01:34:14 INFO FileInputFormat: Total input files to process : 1
21/02/17 01:34:14 INFO SparkContext: Starting job: first at ReadWrite.scala:587
21/02/17 01:34:14 INFO DAGScheduler: Got job 47 (first at ReadWrite.scala:587) with 1 output partitions
21/02/17 01:34:14 INFO DAGScheduler: Final stage: ResultStage 59 (first at ReadWrite.scala:587)
21/02/17 01:34:14 INFO DAGScheduler: Parents of final stage: List()
21/02/17 01:34:14 INFO DAGScheduler: Missing parents: List()
21/02/17 01:34:14 INFO DAGScheduler: Submitting ResultStage 59 (/tmp/RtmpE1GwT4/file220626098807e/stages/1_xgboost_regressor__3f160205_3c69_46f1_9170_a41f0585fc45/metadata MapPartitionsRDD[180] at textFile at ReadWrite.scala:587), which has no missing parents
21/02/17 01:34:14 INFO MemoryStore: Block broadcast_76 stored as values in memory (estimated size 4.2 KiB, free 911.4 MiB)
21/02/17 01:34:14 INFO MemoryStore: Block broadcast_76_piece0 stored as bytes in memory (estimated size 2.5 KiB, free 911.4 MiB)
21/02/17 01:34:14 INFO BlockManagerInfo: Added broadcast_76_piece0 in memory on localhost:35117 (size: 2.5 KiB, free: 912.2 MiB)
21/02/17 01:34:14 INFO SparkContext: Created broadcast 76 from broadcast at DAGScheduler.scala:1200
21/02/17 01:34:14 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 59 (/tmp/RtmpE1GwT4/file220626098807e/stages/1_xgboost_regressor__3f160205_3c69_46f1_9170_a41f0585fc45/metadata MapPartitionsRDD[180] at textFile at ReadWrite.scala:587) (first 15 tasks are for partitions Vector(0))
21/02/17 01:34:14 INFO TaskSchedulerImpl: Adding task set 59.0 with 1 tasks
21/02/17 01:34:14 INFO TaskSetManager: Starting task 0.0 in stage 59.0 (TID 61, localhost, executor driver, partition 0, PROCESS_LOCAL, 7464 bytes)
21/02/17 01:34:14 INFO Executor: Running task 0.0 in stage 59.0 (TID 61)
21/02/17 01:34:14 INFO HadoopRDD: Input split: file:/tmp/RtmpE1GwT4/file220626098807e/stages/1_xgboost_regressor__3f160205_3c69_46f1_9170_a41f0585fc45/metadata/part-00000:0+1284
21/02/17 01:34:14 INFO Executor: Finished task 0.0 in stage 59.0 (TID 61). 2217 bytes result sent to driver
21/02/17 01:34:14 INFO TaskSetManager: Finished task 0.0 in stage 59.0 (TID 61) in 5 ms on localhost (executor driver) (1/1)
21/02/17 01:34:14 INFO TaskSchedulerImpl: Removed TaskSet 59.0, whose tasks have all completed, from pool 
21/02/17 01:34:14 INFO DAGScheduler: ResultStage 59 (first at ReadWrite.scala:587) finished in 0.008 s
21/02/17 01:34:14 INFO DAGScheduler: Job 47 is finished. Cancelling potential speculative or zombie tasks for this job
21/02/17 01:34:14 INFO TaskSchedulerImpl: Killing all running tasks in stage 59: Stage finished
21/02/17 01:34:14 INFO DAGScheduler: Job 47 finished: first at ReadWrite.scala:587, took 0.009698 s
21/02/17 01:34:14 INFO MemoryStore: Block broadcast_77 stored as values in memory (estimated size 294.6 KiB, free 911.1 MiB)
21/02/17 01:34:14 INFO MemoryStore: Block broadcast_77_piece0 stored as bytes in memory (estimated size 27.2 KiB, free 911.1 MiB)
21/02/17 01:34:14 INFO BlockManagerInfo: Added broadcast_77_piece0 in memory on localhost:35117 (size: 27.2 KiB, free: 912.1 MiB)
21/02/17 01:34:14 INFO SparkContext: Created broadcast 77 from textFile at DefaultXGBoostParamsReader.scala:82
21/02/17 01:34:14 INFO FileInputFormat: Total input files to process : 1
21/02/17 01:34:14 INFO SparkContext: Starting job: first at DefaultXGBoostParamsReader.scala:82
21/02/17 01:34:14 INFO DAGScheduler: Got job 48 (first at DefaultXGBoostParamsReader.scala:82) with 1 output partitions
21/02/17 01:34:14 INFO DAGScheduler: Final stage: ResultStage 60 (first at DefaultXGBoostParamsReader.scala:82)
21/02/17 01:34:14 INFO DAGScheduler: Parents of final stage: List()
21/02/17 01:34:14 INFO DAGScheduler: Missing parents: List()
21/02/17 01:34:14 INFO DAGScheduler: Submitting ResultStage 60 (/tmp/RtmpE1GwT4/file220626098807e/stages/1_xgboost_regressor__3f160205_3c69_46f1_9170_a41f0585fc45/metadata MapPartitionsRDD[182] at textFile at DefaultXGBoostParamsReader.scala:82), which has no missing parents
21/02/17 01:34:14 INFO MemoryStore: Block broadcast_78 stored as values in memory (estimated size 4.2 KiB, free 911.1 MiB)
21/02/17 01:34:14 INFO MemoryStore: Block broadcast_78_piece0 stored as bytes in memory (estimated size 2.5 KiB, free 911.1 MiB)
21/02/17 01:34:14 INFO BlockManagerInfo: Added broadcast_78_piece0 in memory on localhost:35117 (size: 2.5 KiB, free: 912.1 MiB)
21/02/17 01:34:14 INFO SparkContext: Created broadcast 78 from broadcast at DAGScheduler.scala:1200
21/02/17 01:34:14 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 60 (/tmp/RtmpE1GwT4/file220626098807e/stages/1_xgboost_regressor__3f160205_3c69_46f1_9170_a41f0585fc45/metadata MapPartitionsRDD[182] at textFile at DefaultXGBoostParamsReader.scala:82) (first 15 tasks are for partitions Vector(0))
21/02/17 01:34:14 INFO TaskSchedulerImpl: Adding task set 60.0 with 1 tasks
21/02/17 01:34:14 INFO TaskSetManager: Starting task 0.0 in stage 60.0 (TID 62, localhost, executor driver, partition 0, PROCESS_LOCAL, 7464 bytes)
21/02/17 01:34:14 INFO Executor: Running task 0.0 in stage 60.0 (TID 62)
21/02/17 01:34:14 INFO HadoopRDD: Input split: file:/tmp/RtmpE1GwT4/file220626098807e/stages/1_xgboost_regressor__3f160205_3c69_46f1_9170_a41f0585fc45/metadata/part-00000:0+1284
21/02/17 01:34:14 INFO Executor: Finished task 0.0 in stage 60.0 (TID 62). 2217 bytes result sent to driver
21/02/17 01:34:14 INFO TaskSetManager: Finished task 0.0 in stage 60.0 (TID 62) in 5 ms on localhost (executor driver) (1/1)
21/02/17 01:34:14 INFO TaskSchedulerImpl: Removed TaskSet 60.0, whose tasks have all completed, from pool 
21/02/17 01:34:14 INFO DAGScheduler: ResultStage 60 (first at DefaultXGBoostParamsReader.scala:82) finished in 0.008 s
21/02/17 01:34:14 INFO DAGScheduler: Job 48 is finished. Cancelling potential speculative or zombie tasks for this job
21/02/17 01:34:14 INFO TaskSchedulerImpl: Killing all running tasks in stage 60: Stage finished
21/02/17 01:34:14 INFO DAGScheduler: Job 48 finished: first at DefaultXGBoostParamsReader.scala:82, took 0.010188 s
21/02/17 01:34:14 INFO Instrumentation: [6ed15214] training finished
21/02/17 01:34:14 INFO Instrumentation: [137cd566] training finished
21/02/17 01:34:15 INFO Instrumentation: [0b961151] training finished
21/02/17 01:34:15 INFO MemoryStore: Block broadcast_79 stored as values in memory (estimated size 64.0 B, free 911.1 MiB)
21/02/17 01:34:15 INFO MemoryStore: Block broadcast_79_piece0 stored as bytes in memory (estimated size 515.0 B, free 911.1 MiB)
21/02/17 01:34:15 INFO BlockManagerInfo: Added broadcast_79_piece0 in memory on localhost:35117 (size: 515.0 B, free: 912.1 MiB)
21/02/17 01:34:15 INFO SparkContext: Created broadcast 79 from broadcast at XGBoostRegressor.scala:279
21/02/17 01:34:15 INFO Instrumentation: [b8d17801] training finished
21/02/17 01:34:15 INFO SparkContext: Starting job: collect at utils.scala:137
21/02/17 01:34:15 INFO DAGScheduler: Got job 49 (collect at utils.scala:137) with 1 output partitions
21/02/17 01:34:15 INFO DAGScheduler: Final stage: ResultStage 61 (collect at utils.scala:137)
21/02/17 01:34:15 INFO DAGScheduler: Parents of final stage: List()
21/02/17 01:34:15 INFO DAGScheduler: Missing parents: List()
21/02/17 01:34:15 INFO DAGScheduler: Submitting ResultStage 61 (MapPartitionsRDD[192] at collect at utils.scala:137), which has no missing parents
21/02/17 01:34:15 INFO MemoryStore: Block broadcast_80 stored as values in memory (estimated size 7.3 KiB, free 911.1 MiB)
21/02/17 01:34:15 INFO MemoryStore: Block broadcast_80_piece0 stored as bytes in memory (estimated size 3.7 KiB, free 911.1 MiB)
21/02/17 01:34:15 INFO BlockManagerInfo: Added broadcast_80_piece0 in memory on localhost:35117 (size: 3.7 KiB, free: 912.1 MiB)
21/02/17 01:34:15 INFO SparkContext: Created broadcast 80 from broadcast at DAGScheduler.scala:1200
21/02/17 01:34:15 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 61 (MapPartitionsRDD[192] at collect at utils.scala:137) (first 15 tasks are for partitions Vector(0))
21/02/17 01:34:15 INFO TaskSchedulerImpl: Adding task set 61.0 with 1 tasks
21/02/17 01:34:15 INFO TaskSetManager: Starting task 0.0 in stage 61.0 (TID 63, localhost, executor driver, partition 0, PROCESS_LOCAL, 7561 bytes)
21/02/17 01:34:15 INFO Executor: Running task 0.0 in stage 61.0 (TID 63)
21/02/17 01:34:15 INFO Executor: Finished task 0.0 in stage 61.0 (TID 63). 1354 bytes result sent to driver
21/02/17 01:34:15 INFO TaskSetManager: Finished task 0.0 in stage 61.0 (TID 63) in 3 ms on localhost (executor driver) (1/1)
21/02/17 01:34:15 INFO TaskSchedulerImpl: Removed TaskSet 61.0, whose tasks have all completed, from pool 
21/02/17 01:34:15 INFO DAGScheduler: ResultStage 61 (collect at utils.scala:137) finished in 0.008 s
21/02/17 01:34:15 INFO DAGScheduler: Job 49 is finished. Cancelling potential speculative or zombie tasks for this job
21/02/17 01:34:15 INFO TaskSchedulerImpl: Killing all running tasks in stage 61: Stage finished
21/02/17 01:34:15 INFO DAGScheduler: Job 49 finished: collect at utils.scala:137, took 0.008612 s
21/02/17 01:34:15 INFO SparkContext: Starting job: count at utils.scala:135
21/02/17 01:34:15 INFO DAGScheduler: Registering RDD 194 (count at utils.scala:135) as input to shuffle 13
21/02/17 01:34:15 INFO DAGScheduler: Got job 50 (count at utils.scala:135) with 1 output partitions
21/02/17 01:34:15 INFO DAGScheduler: Final stage: ResultStage 63 (count at utils.scala:135)
21/02/17 01:34:15 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 62)
21/02/17 01:34:15 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 62)
21/02/17 01:34:15 INFO DAGScheduler: Submitting ShuffleMapStage 62 (MapPartitionsRDD[194] at count at utils.scala:135), which has no missing parents
21/02/17 01:34:15 INFO MemoryStore: Block broadcast_81 stored as values in memory (estimated size 10.0 KiB, free 911.0 MiB)
21/02/17 01:34:15 INFO MemoryStore: Block broadcast_81_piece0 stored as bytes in memory (estimated size 5.2 KiB, free 911.0 MiB)
21/02/17 01:34:15 INFO BlockManagerInfo: Added broadcast_81_piece0 in memory on localhost:35117 (size: 5.2 KiB, free: 912.1 MiB)
21/02/17 01:34:15 INFO SparkContext: Created broadcast 81 from broadcast at DAGScheduler.scala:1200
21/02/17 01:34:15 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 62 (MapPartitionsRDD[194] at count at utils.scala:135) (first 15 tasks are for partitions Vector(0))
21/02/17 01:34:15 INFO TaskSchedulerImpl: Adding task set 62.0 with 1 tasks
21/02/17 01:34:15 INFO TaskSetManager: Starting task 0.0 in stage 62.0 (TID 64, localhost, executor driver, partition 0, PROCESS_LOCAL, 7550 bytes)
21/02/17 01:34:15 INFO Executor: Running task 0.0 in stage 62.0 (TID 64)
21/02/17 01:34:15 INFO Executor: Finished task 0.0 in stage 62.0 (TID 64). 1833 bytes result sent to driver
21/02/17 01:34:15 INFO TaskSetManager: Finished task 0.0 in stage 62.0 (TID 64) in 4 ms on localhost (executor driver) (1/1)
21/02/17 01:34:15 INFO TaskSchedulerImpl: Removed TaskSet 62.0, whose tasks have all completed, from pool 
21/02/17 01:34:15 INFO DAGScheduler: ShuffleMapStage 62 (count at utils.scala:135) finished in 0.008 s
21/02/17 01:34:15 INFO DAGScheduler: looking for newly runnable stages
21/02/17 01:34:15 INFO DAGScheduler: running: Set()
21/02/17 01:34:15 INFO DAGScheduler: waiting: Set(ResultStage 63)
21/02/17 01:34:15 INFO DAGScheduler: failed: Set()
21/02/17 01:34:15 INFO DAGScheduler: Submitting ResultStage 63 (MapPartitionsRDD[197] at count at utils.scala:135), which has no missing parents
21/02/17 01:34:15 INFO MemoryStore: Block broadcast_82 stored as values in memory (estimated size 10.1 KiB, free 911.0 MiB)
21/02/17 01:34:15 INFO MemoryStore: Block broadcast_82_piece0 stored as bytes in memory (estimated size 5.0 KiB, free 911.0 MiB)
21/02/17 01:34:15 INFO BlockManagerInfo: Added broadcast_82_piece0 in memory on localhost:35117 (size: 5.0 KiB, free: 912.1 MiB)
21/02/17 01:34:15 INFO SparkContext: Created broadcast 82 from broadcast at DAGScheduler.scala:1200
21/02/17 01:34:15 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 63 (MapPartitionsRDD[197] at count at utils.scala:135) (first 15 tasks are for partitions Vector(0))
21/02/17 01:34:15 INFO TaskSchedulerImpl: Adding task set 63.0 with 1 tasks
21/02/17 01:34:15 INFO TaskSetManager: Starting task 0.0 in stage 63.0 (TID 65, localhost, executor driver, partition 0, NODE_LOCAL, 7325 bytes)
21/02/17 01:34:15 INFO Executor: Running task 0.0 in stage 63.0 (TID 65)
21/02/17 01:34:15 INFO ShuffleBlockFetcherIterator: Getting 1 (60.0 B) non-empty blocks including 1 (60.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
21/02/17 01:34:15 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
21/02/17 01:34:15 INFO Executor: Finished task 0.0 in stage 63.0 (TID 65). 2648 bytes result sent to driver
21/02/17 01:34:15 INFO TaskSetManager: Finished task 0.0 in stage 63.0 (TID 65) in 3 ms on localhost (executor driver) (1/1)
21/02/17 01:34:15 INFO TaskSchedulerImpl: Removed TaskSet 63.0, whose tasks have all completed, from pool 
21/02/17 01:34:15 INFO DAGScheduler: ResultStage 63 (count at utils.scala:135) finished in 0.008 s
21/02/17 01:34:15 INFO DAGScheduler: Job 50 is finished. Cancelling potential speculative or zombie tasks for this job
21/02/17 01:34:15 INFO TaskSchedulerImpl: Killing all running tasks in stage 63: Stage finished
21/02/17 01:34:15 INFO DAGScheduler: Job 50 finished: count at utils.scala:135, took 0.018209 s
21/02/17 01:34:15 INFO SparkContext: Starting job: collect at utils.scala:137
21/02/17 01:34:15 INFO DAGScheduler: Got job 51 (collect at utils.scala:137) with 1 output partitions
21/02/17 01:34:15 INFO DAGScheduler: Final stage: ResultStage 64 (collect at utils.scala:137)
21/02/17 01:34:15 INFO DAGScheduler: Parents of final stage: List()
21/02/17 01:34:15 INFO DAGScheduler: Missing parents: List()
21/02/17 01:34:15 INFO DAGScheduler: Submitting ResultStage 64 (MapPartitionsRDD[199] at collect at utils.scala:137), which has no missing parents
21/02/17 01:34:15 INFO MemoryStore: Block broadcast_83 stored as values in memory (estimated size 72.4 KiB, free 911.0 MiB)
21/02/17 01:34:15 INFO MemoryStore: Block broadcast_83_piece0 stored as bytes in memory (estimated size 28.5 KiB, free 910.9 MiB)
21/02/17 01:34:15 INFO BlockManagerInfo: Added broadcast_83_piece0 in memory on localhost:35117 (size: 28.5 KiB, free: 912.1 MiB)
21/02/17 01:34:15 INFO SparkContext: Created broadcast 83 from broadcast at DAGScheduler.scala:1200
21/02/17 01:34:15 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 64 (MapPartitionsRDD[199] at collect at utils.scala:137) (first 15 tasks are for partitions Vector(0))
21/02/17 01:34:15 INFO TaskSchedulerImpl: Adding task set 64.0 with 1 tasks
21/02/17 01:34:15 INFO TaskSetManager: Starting task 0.0 in stage 64.0 (TID 66, localhost, executor driver, partition 0, PROCESS_LOCAL, 18492 bytes)
21/02/17 01:34:15 INFO Executor: Running task 0.0 in stage 64.0 (TID 66)
21/02/17 01:34:15 INFO BlockManager: Found block rdd_23_0 locally
21/02/17 01:34:15 INFO Executor: Finished task 0.0 in stage 64.0 (TID 66). 1955 bytes result sent to driver
21/02/17 01:34:15 INFO TaskSetManager: Finished task 0.0 in stage 64.0 (TID 66) in 37 ms on localhost (executor driver) (1/1)
21/02/17 01:34:15 INFO TaskSchedulerImpl: Removed TaskSet 64.0, whose tasks have all completed, from pool 
21/02/17 01:34:15 INFO DAGScheduler: ResultStage 64 (collect at utils.scala:137) finished in 0.041 s
21/02/17 01:34:15 INFO DAGScheduler: Job 51 is finished. Cancelling potential speculative or zombie tasks for this job
21/02/17 01:34:15 INFO TaskSchedulerImpl: Killing all running tasks in stage 64: Stage finished
21/02/17 01:34:15 INFO DAGScheduler: Job 51 finished: collect at utils.scala:137, took 0.043915 s
21/02/17 01:34:15 INFO SparkContext: Starting job: count at utils.scala:135
21/02/17 01:34:15 INFO DAGScheduler: Registering RDD 201 (count at utils.scala:135) as input to shuffle 14
21/02/17 01:34:15 INFO DAGScheduler: Got job 52 (count at utils.scala:135) with 1 output partitions
21/02/17 01:34:15 INFO DAGScheduler: Final stage: ResultStage 66 (count at utils.scala:135)
21/02/17 01:34:15 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 65)
21/02/17 01:34:15 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 65)
21/02/17 01:34:15 INFO DAGScheduler: Submitting ShuffleMapStage 65 (MapPartitionsRDD[201] at count at utils.scala:135), which has no missing parents
21/02/17 01:34:15 INFO MemoryStore: Block broadcast_84 stored as values in memory (estimated size 73.9 KiB, free 910.9 MiB)
21/02/17 01:34:15 INFO MemoryStore: Block broadcast_84_piece0 stored as bytes in memory (estimated size 29.2 KiB, free 910.8 MiB)
21/02/17 01:34:15 INFO BlockManagerInfo: Added broadcast_84_piece0 in memory on localhost:35117 (size: 29.2 KiB, free: 912.1 MiB)
21/02/17 01:34:15 INFO SparkContext: Created broadcast 84 from broadcast at DAGScheduler.scala:1200
21/02/17 01:34:15 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 65 (MapPartitionsRDD[201] at count at utils.scala:135) (first 15 tasks are for partitions Vector(0))
21/02/17 01:34:15 INFO TaskSchedulerImpl: Adding task set 65.0 with 1 tasks
21/02/17 01:34:15 INFO TaskSetManager: Starting task 0.0 in stage 65.0 (TID 67, localhost, executor driver, partition 0, PROCESS_LOCAL, 18481 bytes)
21/02/17 01:34:15 INFO Executor: Running task 0.0 in stage 65.0 (TID 67)
21/02/17 01:34:15 INFO BlockManager: Found block rdd_23_0 locally
21/02/17 01:34:15 INFO Executor: Finished task 0.0 in stage 65.0 (TID 67). 2253 bytes result sent to driver
21/02/17 01:34:15 INFO TaskSetManager: Finished task 0.0 in stage 65.0 (TID 67) in 54 ms on localhost (executor driver) (1/1)
21/02/17 01:34:15 INFO TaskSchedulerImpl: Removed TaskSet 65.0, whose tasks have all completed, from pool 
21/02/17 01:34:15 INFO DAGScheduler: ShuffleMapStage 65 (count at utils.scala:135) finished in 0.058 s
21/02/17 01:34:15 INFO DAGScheduler: looking for newly runnable stages
21/02/17 01:34:15 INFO DAGScheduler: running: Set()
21/02/17 01:34:15 INFO DAGScheduler: waiting: Set(ResultStage 66)
21/02/17 01:34:15 INFO DAGScheduler: failed: Set()
21/02/17 01:34:15 INFO DAGScheduler: Submitting ResultStage 66 (MapPartitionsRDD[204] at count at utils.scala:135), which has no missing parents
21/02/17 01:34:15 INFO MemoryStore: Block broadcast_85 stored as values in memory (estimated size 10.1 KiB, free 910.8 MiB)
21/02/17 01:34:15 INFO MemoryStore: Block broadcast_85_piece0 stored as bytes in memory (estimated size 5.0 KiB, free 910.8 MiB)
21/02/17 01:34:15 INFO BlockManagerInfo: Added broadcast_85_piece0 in memory on localhost:35117 (size: 5.0 KiB, free: 912.1 MiB)
21/02/17 01:34:15 INFO SparkContext: Created broadcast 85 from broadcast at DAGScheduler.scala:1200
21/02/17 01:34:15 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 66 (MapPartitionsRDD[204] at count at utils.scala:135) (first 15 tasks are for partitions Vector(0))
21/02/17 01:34:15 INFO TaskSchedulerImpl: Adding task set 66.0 with 1 tasks
21/02/17 01:34:15 INFO TaskSetManager: Starting task 0.0 in stage 66.0 (TID 68, localhost, executor driver, partition 0, NODE_LOCAL, 7325 bytes)
21/02/17 01:34:15 INFO Executor: Running task 0.0 in stage 66.0 (TID 68)
21/02/17 01:34:15 INFO ShuffleBlockFetcherIterator: Getting 1 (60.0 B) non-empty blocks including 1 (60.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
21/02/17 01:34:15 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
21/02/17 01:34:15 INFO Executor: Finished task 0.0 in stage 66.0 (TID 68). 2648 bytes result sent to driver
21/02/17 01:34:15 INFO TaskSetManager: Finished task 0.0 in stage 66.0 (TID 68) in 3 ms on localhost (executor driver) (1/1)
21/02/17 01:34:15 INFO TaskSchedulerImpl: Removed TaskSet 66.0, whose tasks have all completed, from pool 
21/02/17 01:34:15 INFO DAGScheduler: ResultStage 66 (count at utils.scala:135) finished in 0.006 s
21/02/17 01:34:15 INFO DAGScheduler: Job 52 is finished. Cancelling potential speculative or zombie tasks for this job
21/02/17 01:34:15 INFO TaskSchedulerImpl: Killing all running tasks in stage 66: Stage finished
21/02/17 01:34:15 INFO DAGScheduler: Job 52 finished: count at utils.scala:135, took 0.067399 s
21/02/17 01:34:17 INFO SparkContext: Invoking stop() from shutdown hook
21/02/17 01:34:17 INFO SparkUI: Stopped Spark web UI at http://localhost:4040
21/02/17 01:34:17 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!
21/02/17 01:34:17 INFO MemoryStore: MemoryStore cleared
21/02/17 01:34:17 INFO BlockManager: BlockManager stopped
21/02/17 01:34:17 INFO BlockManagerMaster: BlockManagerMaster stopped
21/02/17 01:34:17 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!
21/02/17 01:34:17 INFO SparkContext: Successfully stopped SparkContext
21/02/17 01:34:17 INFO ShutdownHookManager: Shutdown hook called
21/02/17 01:34:17 INFO ShutdownHookManager: Deleting directory /tmp/spark-ca615bc3-30f7-4593-8daa-291675d832ac
21/02/17 01:34:17 INFO ShutdownHookManager: Deleting directory /tmp/spark-12f582a0-84bc-44b5-a912-d296fadb2980
21/02/17 01:34:29 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
21/02/17 01:34:30 INFO SparkContext: Running Spark version 2.3.0
21/02/17 01:34:30 INFO SparkContext: Submitted application: sparklyr
21/02/17 01:34:30 INFO SecurityManager: Changing view acls to: yitaoli
21/02/17 01:34:30 INFO SecurityManager: Changing modify acls to: yitaoli
21/02/17 01:34:30 INFO SecurityManager: Changing view acls groups to: 
21/02/17 01:34:30 INFO SecurityManager: Changing modify acls groups to: 
21/02/17 01:34:30 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(yitaoli); groups with view permissions: Set(); users  with modify permissions: Set(yitaoli); groups with modify permissions: Set()
21/02/17 01:34:30 INFO Utils: Successfully started service 'sparkDriver' on port 36931.
21/02/17 01:34:30 INFO SparkEnv: Registering MapOutputTracker
21/02/17 01:34:30 INFO SparkEnv: Registering BlockManagerMaster
21/02/17 01:34:30 INFO BlockManagerMasterEndpoint: Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
21/02/17 01:34:30 INFO BlockManagerMasterEndpoint: BlockManagerMasterEndpoint up
21/02/17 01:34:30 INFO DiskBlockManager: Created local directory at /tmp/blockmgr-7057a8aa-5c6b-43f2-b473-742f8d4515bb
21/02/17 01:34:30 INFO MemoryStore: MemoryStore started with capacity 912.3 MB
21/02/17 01:34:30 INFO SparkEnv: Registering OutputCommitCoordinator
21/02/17 01:34:30 INFO Utils: Successfully started service 'SparkUI' on port 4040.
21/02/17 01:34:30 INFO SparkUI: Bound SparkUI to 127.0.0.1, and started at http://localhost:4040
21/02/17 01:34:30 INFO SparkContext: Added JAR file:///home/yitaoli/R/x86_64-pc-linux-gnu-library/4.0/sparkxgb/java/sparkxgb-2.3-2.11.jar at spark://localhost:36931/jars/sparkxgb-2.3-2.11.jar with timestamp 1613525670638
21/02/17 01:34:30 INFO SparkContext: Added JAR file:///home/yitaoli/.ivy2/jars/ml.dmlc_xgboost4j-spark_2.11-1.1.2.jar at spark://localhost:36931/jars/ml.dmlc_xgboost4j-spark_2.11-1.1.2.jar with timestamp 1613525670639
21/02/17 01:34:30 INFO SparkContext: Added JAR file:///home/yitaoli/.ivy2/jars/org.json4s_json4s-jackson_2.11-3.6.10.jar at spark://localhost:36931/jars/org.json4s_json4s-jackson_2.11-3.6.10.jar with timestamp 1613525670639
21/02/17 01:34:30 INFO SparkContext: Added JAR file:///home/yitaoli/.ivy2/jars/ml.dmlc_xgboost4j_2.11-1.1.2.jar at spark://localhost:36931/jars/ml.dmlc_xgboost4j_2.11-1.1.2.jar with timestamp 1613525670639
21/02/17 01:34:30 INFO SparkContext: Added JAR file:///home/yitaoli/.ivy2/jars/com.esotericsoftware.kryo_kryo-2.22.jar at spark://localhost:36931/jars/com.esotericsoftware.kryo_kryo-2.22.jar with timestamp 1613525670639
21/02/17 01:34:30 INFO SparkContext: Added JAR file:///home/yitaoli/.ivy2/jars/org.scala-lang_scala-compiler-2.11.12.jar at spark://localhost:36931/jars/org.scala-lang_scala-compiler-2.11.12.jar with timestamp 1613525670639
21/02/17 01:34:30 INFO SparkContext: Added JAR file:///home/yitaoli/.ivy2/jars/org.scala-lang_scala-reflect-2.11.12.jar at spark://localhost:36931/jars/org.scala-lang_scala-reflect-2.11.12.jar with timestamp 1613525670639
21/02/17 01:34:30 INFO SparkContext: Added JAR file:///home/yitaoli/.ivy2/jars/commons-logging_commons-logging-1.2.jar at spark://localhost:36931/jars/commons-logging_commons-logging-1.2.jar with timestamp 1613525670639
21/02/17 01:34:30 INFO SparkContext: Added JAR file:///home/yitaoli/.ivy2/jars/com.typesafe.akka_akka-actor_2.11-2.5.23.jar at spark://localhost:36931/jars/com.typesafe.akka_akka-actor_2.11-2.5.23.jar with timestamp 1613525670639
21/02/17 01:34:30 INFO SparkContext: Added JAR file:///home/yitaoli/.ivy2/jars/com.typesafe_config-1.3.3.jar at spark://localhost:36931/jars/com.typesafe_config-1.3.3.jar with timestamp 1613525670640
21/02/17 01:34:30 INFO SparkContext: Added JAR file:///home/yitaoli/.ivy2/jars/org.scala-lang.modules_scala-java8-compat_2.11-0.7.0.jar at spark://localhost:36931/jars/org.scala-lang.modules_scala-java8-compat_2.11-0.7.0.jar with timestamp 1613525670640
21/02/17 01:34:30 INFO SparkContext: Added JAR file:///home/yitaoli/.ivy2/jars/org.scala-lang.modules_scala-xml_2.11-1.0.5.jar at spark://localhost:36931/jars/org.scala-lang.modules_scala-xml_2.11-1.0.5.jar with timestamp 1613525670640
21/02/17 01:34:30 INFO SparkContext: Added JAR file:///home/yitaoli/.ivy2/jars/org.scala-lang.modules_scala-parser-combinators_2.11-1.0.4.jar at spark://localhost:36931/jars/org.scala-lang.modules_scala-parser-combinators_2.11-1.0.4.jar with timestamp 1613525670640
21/02/17 01:34:30 INFO SparkContext: Added JAR file:///home/yitaoli/.ivy2/jars/org.json4s_json4s-core_2.11-3.6.10.jar at spark://localhost:36931/jars/org.json4s_json4s-core_2.11-3.6.10.jar with timestamp 1613525670640
21/02/17 01:34:30 INFO SparkContext: Added JAR file:///home/yitaoli/.ivy2/jars/com.fasterxml.jackson.core_jackson-databind-2.9.10.6.jar at spark://localhost:36931/jars/com.fasterxml.jackson.core_jackson-databind-2.9.10.6.jar with timestamp 1613525670640
21/02/17 01:34:30 INFO SparkContext: Added JAR file:///home/yitaoli/.ivy2/jars/org.json4s_json4s-ast_2.11-3.6.10.jar at spark://localhost:36931/jars/org.json4s_json4s-ast_2.11-3.6.10.jar with timestamp 1613525670640
21/02/17 01:34:30 INFO SparkContext: Added JAR file:///home/yitaoli/.ivy2/jars/org.json4s_json4s-scalap_2.11-3.6.10.jar at spark://localhost:36931/jars/org.json4s_json4s-scalap_2.11-3.6.10.jar with timestamp 1613525670640
21/02/17 01:34:30 INFO SparkContext: Added JAR file:///home/yitaoli/.ivy2/jars/com.thoughtworks.paranamer_paranamer-2.8.jar at spark://localhost:36931/jars/com.thoughtworks.paranamer_paranamer-2.8.jar with timestamp 1613525670641
21/02/17 01:34:30 INFO SparkContext: Added JAR file:///home/yitaoli/.ivy2/jars/com.fasterxml.jackson.core_jackson-annotations-2.9.10.jar at spark://localhost:36931/jars/com.fasterxml.jackson.core_jackson-annotations-2.9.10.jar with timestamp 1613525670641
21/02/17 01:34:30 INFO SparkContext: Added JAR file:///home/yitaoli/.ivy2/jars/com.fasterxml.jackson.core_jackson-core-2.9.10.jar at spark://localhost:36931/jars/com.fasterxml.jackson.core_jackson-core-2.9.10.jar with timestamp 1613525670641
21/02/17 01:34:30 INFO SparkContext: Added JAR file:/home/yitaoli/R/x86_64-pc-linux-gnu-library/4.0/sparklyr/java/sparklyr-2.3-2.11.jar at spark://localhost:36931/jars/sparklyr-2.3-2.11.jar with timestamp 1613525670641
21/02/17 01:34:30 INFO Executor: Starting executor ID driver on host localhost
21/02/17 01:34:30 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 34997.
21/02/17 01:34:30 INFO NettyBlockTransferService: Server created on localhost:34997
21/02/17 01:34:30 INFO BlockManager: Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
21/02/17 01:34:30 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, localhost, 34997, None)
21/02/17 01:34:30 INFO BlockManagerMasterEndpoint: Registering block manager localhost:34997 with 912.3 MB RAM, BlockManagerId(driver, localhost, 34997, None)
21/02/17 01:34:30 INFO BlockManagerMaster: Registered BlockManager BlockManagerId(driver, localhost, 34997, None)
21/02/17 01:34:30 INFO BlockManager: Initialized BlockManager: BlockManagerId(driver, localhost, 34997, None)
21/02/17 01:34:30 INFO SharedState: loading hive config file: file:/home/yitaoli/spark/spark-2.3.0-bin-hadoop2.7/conf/hive-site.xml
21/02/17 01:34:30 INFO SharedState: Setting hive.metastore.warehouse.dir ('null') to the value of spark.sql.warehouse.dir ('file:/home/yitaoli/sparkxgb/tests/testthat/spark-warehouse').
21/02/17 01:34:30 INFO SharedState: Warehouse path is 'file:/home/yitaoli/sparkxgb/tests/testthat/spark-warehouse'.
21/02/17 01:34:31 INFO StateStoreCoordinatorRef: Registered StateStoreCoordinator endpoint
21/02/17 01:34:32 INFO HiveUtils: Initializing HiveMetastoreConnection version 1.2.1 using Spark classes.
21/02/17 01:34:32 INFO HiveMetaStore: 0: Opening raw store with implemenation class:org.apache.hadoop.hive.metastore.ObjectStore
21/02/17 01:34:32 INFO ObjectStore: ObjectStore, initialize called
21/02/17 01:34:32 INFO Persistence: Property hive.metastore.integral.jdo.pushdown unknown - will be ignored
21/02/17 01:34:32 INFO Persistence: Property datanucleus.cache.level2 unknown - will be ignored
21/02/17 01:34:33 INFO ObjectStore: Setting MetaStore object pin classes with hive.metastore.cache.pinobjtypes="Table,StorageDescriptor,SerDeInfo,Partition,Database,Type,FieldSchema,Order"
21/02/17 01:34:34 INFO Datastore: The class "org.apache.hadoop.hive.metastore.model.MFieldSchema" is tagged as "embedded-only" so does not have its own datastore table.
21/02/17 01:34:34 INFO Datastore: The class "org.apache.hadoop.hive.metastore.model.MOrder" is tagged as "embedded-only" so does not have its own datastore table.
21/02/17 01:34:34 INFO Datastore: The class "org.apache.hadoop.hive.metastore.model.MFieldSchema" is tagged as "embedded-only" so does not have its own datastore table.
21/02/17 01:34:34 INFO Datastore: The class "org.apache.hadoop.hive.metastore.model.MOrder" is tagged as "embedded-only" so does not have its own datastore table.
21/02/17 01:34:35 INFO MetaStoreDirectSql: Using direct SQL, underlying DB is DERBY
21/02/17 01:34:35 INFO ObjectStore: Initialized ObjectStore
21/02/17 01:34:35 WARN ObjectStore: Version information not found in metastore. hive.metastore.schema.verification is not enabled so recording the schema version 1.2.0
21/02/17 01:34:35 WARN ObjectStore: Failed to get database default, returning NoSuchObjectException
21/02/17 01:34:35 INFO HiveMetaStore: Added admin role in metastore
21/02/17 01:34:35 INFO HiveMetaStore: Added public role in metastore
21/02/17 01:34:35 INFO HiveMetaStore: No user is added in admin role, since config is empty
21/02/17 01:34:35 INFO HiveMetaStore: 0: get_all_databases
21/02/17 01:34:35 INFO audit: ugi=yitaoli	ip=unknown-ip-addr	cmd=get_all_databases	
21/02/17 01:34:35 INFO HiveMetaStore: 0: get_functions: db=default pat=*
21/02/17 01:34:35 INFO audit: ugi=yitaoli	ip=unknown-ip-addr	cmd=get_functions: db=default pat=*	
21/02/17 01:34:35 INFO Datastore: The class "org.apache.hadoop.hive.metastore.model.MResourceUri" is tagged as "embedded-only" so does not have its own datastore table.
21/02/17 01:34:35 INFO SessionState: Created local directory: /tmp/7ee170eb-36e4-40c2-b13a-498a76e8d362_resources
21/02/17 01:34:35 INFO SessionState: Created HDFS directory: /tmp/hive/yitaoli/7ee170eb-36e4-40c2-b13a-498a76e8d362
21/02/17 01:34:35 INFO SessionState: Created local directory: /tmp/yitaoli/7ee170eb-36e4-40c2-b13a-498a76e8d362
21/02/17 01:34:35 INFO SessionState: Created HDFS directory: /tmp/hive/yitaoli/7ee170eb-36e4-40c2-b13a-498a76e8d362/_tmp_space.db
21/02/17 01:34:35 INFO HiveClientImpl: Warehouse location for Hive client (version 1.2.2) is file:/home/yitaoli/sparkxgb/tests/testthat/spark-warehouse
21/02/17 01:34:35 INFO HiveMetaStore: 0: get_database: default
21/02/17 01:34:35 INFO audit: ugi=yitaoli	ip=unknown-ip-addr	cmd=get_database: default	
21/02/17 01:34:35 INFO HiveMetaStore: 0: get_database: global_temp
21/02/17 01:34:35 INFO audit: ugi=yitaoli	ip=unknown-ip-addr	cmd=get_database: global_temp	
21/02/17 01:34:35 WARN ObjectStore: Failed to get database global_temp, returning NoSuchObjectException
21/02/17 01:34:35 INFO HiveMetaStore: 0: get_table : db=default tbl=iris
21/02/17 01:34:35 INFO audit: ugi=yitaoli	ip=unknown-ip-addr	cmd=get_table : db=default tbl=iris	
21/02/17 01:34:35 INFO HiveMetaStore: 0: get_database: default
21/02/17 01:34:35 INFO audit: ugi=yitaoli	ip=unknown-ip-addr	cmd=get_database: default	
21/02/17 01:34:35 INFO HiveMetaStore: 0: get_database: default
21/02/17 01:34:35 INFO audit: ugi=yitaoli	ip=unknown-ip-addr	cmd=get_database: default	
21/02/17 01:34:35 INFO HiveMetaStore: 0: get_tables: db=default pat=*
21/02/17 01:34:35 INFO audit: ugi=yitaoli	ip=unknown-ip-addr	cmd=get_tables: db=default pat=*	
21/02/17 01:34:36 INFO SparkContext: Starting job: collect at utils.scala:61
21/02/17 01:34:36 INFO DAGScheduler: Got job 0 (collect at utils.scala:61) with 1 output partitions
21/02/17 01:34:36 INFO DAGScheduler: Final stage: ResultStage 0 (collect at utils.scala:61)
21/02/17 01:34:36 INFO DAGScheduler: Parents of final stage: List()
21/02/17 01:34:36 INFO DAGScheduler: Missing parents: List()
21/02/17 01:34:36 INFO DAGScheduler: Submitting ResultStage 0 (MapPartitionsRDD[4] at map at utils.scala:54), which has no missing parents
21/02/17 01:34:36 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 5.9 KB, free 912.3 MB)
21/02/17 01:34:36 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 3.3 KB, free 912.3 MB)
21/02/17 01:34:36 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on localhost:34997 (size: 3.3 KB, free: 912.3 MB)
21/02/17 01:34:36 INFO SparkContext: Created broadcast 0 from broadcast at DAGScheduler.scala:1039
21/02/17 01:34:36 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 0 (MapPartitionsRDD[4] at map at utils.scala:54) (first 15 tasks are for partitions Vector(0))
21/02/17 01:34:36 INFO TaskSchedulerImpl: Adding task set 0.0 with 1 tasks
21/02/17 01:34:36 INFO TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0, localhost, executor driver, partition 0, PROCESS_LOCAL, 7880 bytes)
21/02/17 01:34:36 INFO Executor: Running task 0.0 in stage 0.0 (TID 0)
21/02/17 01:34:36 INFO Executor: Fetching spark://localhost:36931/jars/ml.dmlc_xgboost4j-spark_2.11-1.1.2.jar with timestamp 1613525670639
21/02/17 01:34:36 INFO TransportClientFactory: Successfully created connection to localhost/127.0.0.1:36931 after 13 ms (0 ms spent in bootstraps)
21/02/17 01:34:36 INFO Utils: Fetching spark://localhost:36931/jars/ml.dmlc_xgboost4j-spark_2.11-1.1.2.jar to /tmp/spark-3a24ac5a-64a8-4146-96c3-4764374d3e73/userFiles-c103ab95-4bd4-462d-ad2b-69020afe17d6/fetchFileTemp3007183480841167086.tmp
21/02/17 01:34:36 INFO Executor: Adding file:/tmp/spark-3a24ac5a-64a8-4146-96c3-4764374d3e73/userFiles-c103ab95-4bd4-462d-ad2b-69020afe17d6/ml.dmlc_xgboost4j-spark_2.11-1.1.2.jar to class loader
21/02/17 01:34:36 INFO Executor: Fetching spark://localhost:36931/jars/com.typesafe.akka_akka-actor_2.11-2.5.23.jar with timestamp 1613525670639
21/02/17 01:34:36 INFO Utils: Fetching spark://localhost:36931/jars/com.typesafe.akka_akka-actor_2.11-2.5.23.jar to /tmp/spark-3a24ac5a-64a8-4146-96c3-4764374d3e73/userFiles-c103ab95-4bd4-462d-ad2b-69020afe17d6/fetchFileTemp5834884052516668128.tmp
21/02/17 01:34:36 INFO Executor: Adding file:/tmp/spark-3a24ac5a-64a8-4146-96c3-4764374d3e73/userFiles-c103ab95-4bd4-462d-ad2b-69020afe17d6/com.typesafe.akka_akka-actor_2.11-2.5.23.jar to class loader
21/02/17 01:34:36 INFO Executor: Fetching spark://localhost:36931/jars/com.fasterxml.jackson.core_jackson-core-2.9.10.jar with timestamp 1613525670641
21/02/17 01:34:36 INFO Utils: Fetching spark://localhost:36931/jars/com.fasterxml.jackson.core_jackson-core-2.9.10.jar to /tmp/spark-3a24ac5a-64a8-4146-96c3-4764374d3e73/userFiles-c103ab95-4bd4-462d-ad2b-69020afe17d6/fetchFileTemp5986963023280783625.tmp
21/02/17 01:34:36 INFO Executor: Adding file:/tmp/spark-3a24ac5a-64a8-4146-96c3-4764374d3e73/userFiles-c103ab95-4bd4-462d-ad2b-69020afe17d6/com.fasterxml.jackson.core_jackson-core-2.9.10.jar to class loader
21/02/17 01:34:36 INFO Executor: Fetching spark://localhost:36931/jars/ml.dmlc_xgboost4j_2.11-1.1.2.jar with timestamp 1613525670639
21/02/17 01:34:36 INFO Utils: Fetching spark://localhost:36931/jars/ml.dmlc_xgboost4j_2.11-1.1.2.jar to /tmp/spark-3a24ac5a-64a8-4146-96c3-4764374d3e73/userFiles-c103ab95-4bd4-462d-ad2b-69020afe17d6/fetchFileTemp7599966123618735689.tmp
21/02/17 01:34:36 INFO Executor: Adding file:/tmp/spark-3a24ac5a-64a8-4146-96c3-4764374d3e73/userFiles-c103ab95-4bd4-462d-ad2b-69020afe17d6/ml.dmlc_xgboost4j_2.11-1.1.2.jar to class loader
21/02/17 01:34:36 INFO Executor: Fetching spark://localhost:36931/jars/com.esotericsoftware.kryo_kryo-2.22.jar with timestamp 1613525670639
21/02/17 01:34:36 INFO Utils: Fetching spark://localhost:36931/jars/com.esotericsoftware.kryo_kryo-2.22.jar to /tmp/spark-3a24ac5a-64a8-4146-96c3-4764374d3e73/userFiles-c103ab95-4bd4-462d-ad2b-69020afe17d6/fetchFileTemp746901046388830674.tmp
21/02/17 01:34:36 INFO Executor: Adding file:/tmp/spark-3a24ac5a-64a8-4146-96c3-4764374d3e73/userFiles-c103ab95-4bd4-462d-ad2b-69020afe17d6/com.esotericsoftware.kryo_kryo-2.22.jar to class loader
21/02/17 01:34:36 INFO Executor: Fetching spark://localhost:36931/jars/com.fasterxml.jackson.core_jackson-annotations-2.9.10.jar with timestamp 1613525670641
21/02/17 01:34:36 INFO Utils: Fetching spark://localhost:36931/jars/com.fasterxml.jackson.core_jackson-annotations-2.9.10.jar to /tmp/spark-3a24ac5a-64a8-4146-96c3-4764374d3e73/userFiles-c103ab95-4bd4-462d-ad2b-69020afe17d6/fetchFileTemp7527799120284949912.tmp
21/02/17 01:34:36 INFO Executor: Adding file:/tmp/spark-3a24ac5a-64a8-4146-96c3-4764374d3e73/userFiles-c103ab95-4bd4-462d-ad2b-69020afe17d6/com.fasterxml.jackson.core_jackson-annotations-2.9.10.jar to class loader
21/02/17 01:34:36 INFO Executor: Fetching spark://localhost:36931/jars/sparkxgb-2.3-2.11.jar with timestamp 1613525670638
21/02/17 01:34:36 INFO Utils: Fetching spark://localhost:36931/jars/sparkxgb-2.3-2.11.jar to /tmp/spark-3a24ac5a-64a8-4146-96c3-4764374d3e73/userFiles-c103ab95-4bd4-462d-ad2b-69020afe17d6/fetchFileTemp2219476710415549247.tmp
21/02/17 01:34:36 INFO Executor: Adding file:/tmp/spark-3a24ac5a-64a8-4146-96c3-4764374d3e73/userFiles-c103ab95-4bd4-462d-ad2b-69020afe17d6/sparkxgb-2.3-2.11.jar to class loader
21/02/17 01:34:36 INFO Executor: Fetching spark://localhost:36931/jars/org.scala-lang_scala-reflect-2.11.12.jar with timestamp 1613525670639
21/02/17 01:34:36 INFO Utils: Fetching spark://localhost:36931/jars/org.scala-lang_scala-reflect-2.11.12.jar to /tmp/spark-3a24ac5a-64a8-4146-96c3-4764374d3e73/userFiles-c103ab95-4bd4-462d-ad2b-69020afe17d6/fetchFileTemp8681400653527561651.tmp
21/02/17 01:34:36 INFO Executor: Adding file:/tmp/spark-3a24ac5a-64a8-4146-96c3-4764374d3e73/userFiles-c103ab95-4bd4-462d-ad2b-69020afe17d6/org.scala-lang_scala-reflect-2.11.12.jar to class loader
21/02/17 01:34:36 INFO Executor: Fetching spark://localhost:36931/jars/org.json4s_json4s-core_2.11-3.6.10.jar with timestamp 1613525670640
21/02/17 01:34:36 INFO Utils: Fetching spark://localhost:36931/jars/org.json4s_json4s-core_2.11-3.6.10.jar to /tmp/spark-3a24ac5a-64a8-4146-96c3-4764374d3e73/userFiles-c103ab95-4bd4-462d-ad2b-69020afe17d6/fetchFileTemp931452626544723423.tmp
21/02/17 01:34:36 INFO Executor: Adding file:/tmp/spark-3a24ac5a-64a8-4146-96c3-4764374d3e73/userFiles-c103ab95-4bd4-462d-ad2b-69020afe17d6/org.json4s_json4s-core_2.11-3.6.10.jar to class loader
21/02/17 01:34:36 INFO Executor: Fetching spark://localhost:36931/jars/com.typesafe_config-1.3.3.jar with timestamp 1613525670640
21/02/17 01:34:36 INFO Utils: Fetching spark://localhost:36931/jars/com.typesafe_config-1.3.3.jar to /tmp/spark-3a24ac5a-64a8-4146-96c3-4764374d3e73/userFiles-c103ab95-4bd4-462d-ad2b-69020afe17d6/fetchFileTemp2446373585744419398.tmp
21/02/17 01:34:36 INFO Executor: Adding file:/tmp/spark-3a24ac5a-64a8-4146-96c3-4764374d3e73/userFiles-c103ab95-4bd4-462d-ad2b-69020afe17d6/com.typesafe_config-1.3.3.jar to class loader
21/02/17 01:34:36 INFO Executor: Fetching spark://localhost:36931/jars/sparklyr-2.3-2.11.jar with timestamp 1613525670641
21/02/17 01:34:36 INFO Utils: Fetching spark://localhost:36931/jars/sparklyr-2.3-2.11.jar to /tmp/spark-3a24ac5a-64a8-4146-96c3-4764374d3e73/userFiles-c103ab95-4bd4-462d-ad2b-69020afe17d6/fetchFileTemp5463646663625762381.tmp
21/02/17 01:34:36 INFO Executor: Adding file:/tmp/spark-3a24ac5a-64a8-4146-96c3-4764374d3e73/userFiles-c103ab95-4bd4-462d-ad2b-69020afe17d6/sparklyr-2.3-2.11.jar to class loader
21/02/17 01:34:36 INFO Executor: Fetching spark://localhost:36931/jars/org.json4s_json4s-ast_2.11-3.6.10.jar with timestamp 1613525670640
21/02/17 01:34:36 INFO Utils: Fetching spark://localhost:36931/jars/org.json4s_json4s-ast_2.11-3.6.10.jar to /tmp/spark-3a24ac5a-64a8-4146-96c3-4764374d3e73/userFiles-c103ab95-4bd4-462d-ad2b-69020afe17d6/fetchFileTemp5884814692610054139.tmp
21/02/17 01:34:36 INFO Executor: Adding file:/tmp/spark-3a24ac5a-64a8-4146-96c3-4764374d3e73/userFiles-c103ab95-4bd4-462d-ad2b-69020afe17d6/org.json4s_json4s-ast_2.11-3.6.10.jar to class loader
21/02/17 01:34:36 INFO Executor: Fetching spark://localhost:36931/jars/com.thoughtworks.paranamer_paranamer-2.8.jar with timestamp 1613525670641
21/02/17 01:34:36 INFO Utils: Fetching spark://localhost:36931/jars/com.thoughtworks.paranamer_paranamer-2.8.jar to /tmp/spark-3a24ac5a-64a8-4146-96c3-4764374d3e73/userFiles-c103ab95-4bd4-462d-ad2b-69020afe17d6/fetchFileTemp7176733569074720096.tmp
21/02/17 01:34:36 INFO Executor: Adding file:/tmp/spark-3a24ac5a-64a8-4146-96c3-4764374d3e73/userFiles-c103ab95-4bd4-462d-ad2b-69020afe17d6/com.thoughtworks.paranamer_paranamer-2.8.jar to class loader
21/02/17 01:34:36 INFO Executor: Fetching spark://localhost:36931/jars/org.scala-lang.modules_scala-parser-combinators_2.11-1.0.4.jar with timestamp 1613525670640
21/02/17 01:34:36 INFO Utils: Fetching spark://localhost:36931/jars/org.scala-lang.modules_scala-parser-combinators_2.11-1.0.4.jar to /tmp/spark-3a24ac5a-64a8-4146-96c3-4764374d3e73/userFiles-c103ab95-4bd4-462d-ad2b-69020afe17d6/fetchFileTemp2063850850697063368.tmp
21/02/17 01:34:36 INFO Executor: Adding file:/tmp/spark-3a24ac5a-64a8-4146-96c3-4764374d3e73/userFiles-c103ab95-4bd4-462d-ad2b-69020afe17d6/org.scala-lang.modules_scala-parser-combinators_2.11-1.0.4.jar to class loader
21/02/17 01:34:36 INFO Executor: Fetching spark://localhost:36931/jars/org.json4s_json4s-scalap_2.11-3.6.10.jar with timestamp 1613525670640
21/02/17 01:34:36 INFO Utils: Fetching spark://localhost:36931/jars/org.json4s_json4s-scalap_2.11-3.6.10.jar to /tmp/spark-3a24ac5a-64a8-4146-96c3-4764374d3e73/userFiles-c103ab95-4bd4-462d-ad2b-69020afe17d6/fetchFileTemp1616717786458314358.tmp
21/02/17 01:34:36 INFO Executor: Adding file:/tmp/spark-3a24ac5a-64a8-4146-96c3-4764374d3e73/userFiles-c103ab95-4bd4-462d-ad2b-69020afe17d6/org.json4s_json4s-scalap_2.11-3.6.10.jar to class loader
21/02/17 01:34:36 INFO Executor: Fetching spark://localhost:36931/jars/commons-logging_commons-logging-1.2.jar with timestamp 1613525670639
21/02/17 01:34:36 INFO Utils: Fetching spark://localhost:36931/jars/commons-logging_commons-logging-1.2.jar to /tmp/spark-3a24ac5a-64a8-4146-96c3-4764374d3e73/userFiles-c103ab95-4bd4-462d-ad2b-69020afe17d6/fetchFileTemp5959617946473260159.tmp
21/02/17 01:34:36 INFO Executor: Adding file:/tmp/spark-3a24ac5a-64a8-4146-96c3-4764374d3e73/userFiles-c103ab95-4bd4-462d-ad2b-69020afe17d6/commons-logging_commons-logging-1.2.jar to class loader
21/02/17 01:34:36 INFO Executor: Fetching spark://localhost:36931/jars/org.scala-lang.modules_scala-java8-compat_2.11-0.7.0.jar with timestamp 1613525670640
21/02/17 01:34:36 INFO Utils: Fetching spark://localhost:36931/jars/org.scala-lang.modules_scala-java8-compat_2.11-0.7.0.jar to /tmp/spark-3a24ac5a-64a8-4146-96c3-4764374d3e73/userFiles-c103ab95-4bd4-462d-ad2b-69020afe17d6/fetchFileTemp2065392453863572211.tmp
21/02/17 01:34:36 INFO Executor: Adding file:/tmp/spark-3a24ac5a-64a8-4146-96c3-4764374d3e73/userFiles-c103ab95-4bd4-462d-ad2b-69020afe17d6/org.scala-lang.modules_scala-java8-compat_2.11-0.7.0.jar to class loader
21/02/17 01:34:36 INFO Executor: Fetching spark://localhost:36931/jars/com.fasterxml.jackson.core_jackson-databind-2.9.10.6.jar with timestamp 1613525670640
21/02/17 01:34:36 INFO Utils: Fetching spark://localhost:36931/jars/com.fasterxml.jackson.core_jackson-databind-2.9.10.6.jar to /tmp/spark-3a24ac5a-64a8-4146-96c3-4764374d3e73/userFiles-c103ab95-4bd4-462d-ad2b-69020afe17d6/fetchFileTemp1887719253195581595.tmp
21/02/17 01:34:36 INFO Executor: Adding file:/tmp/spark-3a24ac5a-64a8-4146-96c3-4764374d3e73/userFiles-c103ab95-4bd4-462d-ad2b-69020afe17d6/com.fasterxml.jackson.core_jackson-databind-2.9.10.6.jar to class loader
21/02/17 01:34:36 INFO Executor: Fetching spark://localhost:36931/jars/org.scala-lang.modules_scala-xml_2.11-1.0.5.jar with timestamp 1613525670640
21/02/17 01:34:36 INFO Utils: Fetching spark://localhost:36931/jars/org.scala-lang.modules_scala-xml_2.11-1.0.5.jar to /tmp/spark-3a24ac5a-64a8-4146-96c3-4764374d3e73/userFiles-c103ab95-4bd4-462d-ad2b-69020afe17d6/fetchFileTemp2252035659973943843.tmp
21/02/17 01:34:36 INFO Executor: Adding file:/tmp/spark-3a24ac5a-64a8-4146-96c3-4764374d3e73/userFiles-c103ab95-4bd4-462d-ad2b-69020afe17d6/org.scala-lang.modules_scala-xml_2.11-1.0.5.jar to class loader
21/02/17 01:34:36 INFO Executor: Fetching spark://localhost:36931/jars/org.scala-lang_scala-compiler-2.11.12.jar with timestamp 1613525670639
21/02/17 01:34:36 INFO Utils: Fetching spark://localhost:36931/jars/org.scala-lang_scala-compiler-2.11.12.jar to /tmp/spark-3a24ac5a-64a8-4146-96c3-4764374d3e73/userFiles-c103ab95-4bd4-462d-ad2b-69020afe17d6/fetchFileTemp4457278653398351544.tmp
21/02/17 01:34:36 INFO Executor: Adding file:/tmp/spark-3a24ac5a-64a8-4146-96c3-4764374d3e73/userFiles-c103ab95-4bd4-462d-ad2b-69020afe17d6/org.scala-lang_scala-compiler-2.11.12.jar to class loader
21/02/17 01:34:36 INFO Executor: Fetching spark://localhost:36931/jars/org.json4s_json4s-jackson_2.11-3.6.10.jar with timestamp 1613525670639
21/02/17 01:34:36 INFO Utils: Fetching spark://localhost:36931/jars/org.json4s_json4s-jackson_2.11-3.6.10.jar to /tmp/spark-3a24ac5a-64a8-4146-96c3-4764374d3e73/userFiles-c103ab95-4bd4-462d-ad2b-69020afe17d6/fetchFileTemp8680459093387014916.tmp
21/02/17 01:34:36 INFO Executor: Adding file:/tmp/spark-3a24ac5a-64a8-4146-96c3-4764374d3e73/userFiles-c103ab95-4bd4-462d-ad2b-69020afe17d6/org.json4s_json4s-jackson_2.11-3.6.10.jar to class loader
21/02/17 01:34:36 INFO CodeGenerator: Code generated in 152.696089 ms
21/02/17 01:34:36 INFO Executor: Finished task 0.0 in stage 0.0 (TID 0). 970 bytes result sent to driver
21/02/17 01:34:36 INFO TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in 466 ms on localhost (executor driver) (1/1)
21/02/17 01:34:36 INFO TaskSchedulerImpl: Removed TaskSet 0.0, whose tasks have all completed, from pool 
21/02/17 01:34:36 INFO DAGScheduler: ResultStage 0 (collect at utils.scala:61) finished in 0.568 s
21/02/17 01:34:36 INFO DAGScheduler: Job 0 finished: collect at utils.scala:61, took 0.602564 s
21/02/17 01:34:37 INFO CodeGenerator: Code generated in 12.950767 ms
21/02/17 01:34:37 INFO CodeGenerator: Code generated in 12.787798 ms
21/02/17 01:34:37 INFO SparkContext: Starting job: collect at utils.scala:135
21/02/17 01:34:37 INFO DAGScheduler: Got job 1 (collect at utils.scala:135) with 1 output partitions
21/02/17 01:34:37 INFO DAGScheduler: Final stage: ResultStage 1 (collect at utils.scala:135)
21/02/17 01:34:37 INFO DAGScheduler: Parents of final stage: List()
21/02/17 01:34:37 INFO DAGScheduler: Missing parents: List()
21/02/17 01:34:37 INFO DAGScheduler: Submitting ResultStage 1 (MapPartitionsRDD[9] at collect at utils.scala:135), which has no missing parents
21/02/17 01:34:37 INFO MemoryStore: Block broadcast_1 stored as values in memory (estimated size 6.4 KB, free 912.3 MB)
21/02/17 01:34:37 INFO MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 3.2 KB, free 912.3 MB)
21/02/17 01:34:37 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on localhost:34997 (size: 3.2 KB, free: 912.3 MB)
21/02/17 01:34:37 INFO SparkContext: Created broadcast 1 from broadcast at DAGScheduler.scala:1039
21/02/17 01:34:37 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 1 (MapPartitionsRDD[9] at collect at utils.scala:135) (first 15 tasks are for partitions Vector(0))
21/02/17 01:34:37 INFO TaskSchedulerImpl: Adding task set 1.0 with 1 tasks
21/02/17 01:34:37 INFO TaskSetManager: Starting task 0.0 in stage 1.0 (TID 1, localhost, executor driver, partition 0, PROCESS_LOCAL, 8067 bytes)
21/02/17 01:34:37 INFO Executor: Running task 0.0 in stage 1.0 (TID 1)
21/02/17 01:34:37 INFO CodeGenerator: Code generated in 6.945829 ms
21/02/17 01:34:37 INFO Executor: Finished task 0.0 in stage 1.0 (TID 1). 1329 bytes result sent to driver
21/02/17 01:34:37 INFO TaskSetManager: Finished task 0.0 in stage 1.0 (TID 1) in 23 ms on localhost (executor driver) (1/1)
21/02/17 01:34:37 INFO TaskSchedulerImpl: Removed TaskSet 1.0, whose tasks have all completed, from pool 
21/02/17 01:34:37 INFO DAGScheduler: ResultStage 1 (collect at utils.scala:135) finished in 0.032 s
21/02/17 01:34:37 INFO DAGScheduler: Job 1 finished: collect at utils.scala:135, took 0.034510 s
21/02/17 01:34:37 INFO CodeGenerator: Code generated in 11.954721 ms
21/02/17 01:34:37 INFO CodeGenerator: Code generated in 13.367367 ms
21/02/17 01:34:37 INFO SparkContext: Starting job: count at utils.scala:135
21/02/17 01:34:37 INFO DAGScheduler: Registering RDD 12 (count at utils.scala:135)
21/02/17 01:34:37 INFO DAGScheduler: Got job 2 (count at utils.scala:135) with 1 output partitions
21/02/17 01:34:37 INFO DAGScheduler: Final stage: ResultStage 3 (count at utils.scala:135)
21/02/17 01:34:37 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 2)
21/02/17 01:34:37 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 2)
21/02/17 01:34:37 INFO DAGScheduler: Submitting ShuffleMapStage 2 (MapPartitionsRDD[12] at count at utils.scala:135), which has no missing parents
21/02/17 01:34:37 INFO MemoryStore: Block broadcast_2 stored as values in memory (estimated size 8.9 KB, free 912.3 MB)
21/02/17 01:34:37 INFO MemoryStore: Block broadcast_2_piece0 stored as bytes in memory (estimated size 4.5 KB, free 912.3 MB)
21/02/17 01:34:37 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on localhost:34997 (size: 4.5 KB, free: 912.3 MB)
21/02/17 01:34:37 INFO SparkContext: Created broadcast 2 from broadcast at DAGScheduler.scala:1039
21/02/17 01:34:37 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 2 (MapPartitionsRDD[12] at count at utils.scala:135) (first 15 tasks are for partitions Vector(0))
21/02/17 01:34:37 INFO TaskSchedulerImpl: Adding task set 2.0 with 1 tasks
21/02/17 01:34:37 INFO TaskSetManager: Starting task 0.0 in stage 2.0 (TID 2, localhost, executor driver, partition 0, PROCESS_LOCAL, 8056 bytes)
21/02/17 01:34:37 INFO Executor: Running task 0.0 in stage 2.0 (TID 2)
21/02/17 01:34:37 INFO Executor: Finished task 0.0 in stage 2.0 (TID 2). 1542 bytes result sent to driver
21/02/17 01:34:37 INFO TaskSetManager: Finished task 0.0 in stage 2.0 (TID 2) in 36 ms on localhost (executor driver) (1/1)
21/02/17 01:34:37 INFO TaskSchedulerImpl: Removed TaskSet 2.0, whose tasks have all completed, from pool 
21/02/17 01:34:37 INFO DAGScheduler: ShuffleMapStage 2 (count at utils.scala:135) finished in 0.048 s
21/02/17 01:34:37 INFO DAGScheduler: looking for newly runnable stages
21/02/17 01:34:37 INFO DAGScheduler: running: Set()
21/02/17 01:34:37 INFO DAGScheduler: waiting: Set(ResultStage 3)
21/02/17 01:34:37 INFO DAGScheduler: failed: Set()
21/02/17 01:34:37 INFO DAGScheduler: Submitting ResultStage 3 (MapPartitionsRDD[15] at count at utils.scala:135), which has no missing parents
21/02/17 01:34:37 INFO MemoryStore: Block broadcast_3 stored as values in memory (estimated size 7.3 KB, free 912.3 MB)
21/02/17 01:34:37 INFO MemoryStore: Block broadcast_3_piece0 stored as bytes in memory (estimated size 3.8 KB, free 912.3 MB)
21/02/17 01:34:37 INFO BlockManagerInfo: Added broadcast_3_piece0 in memory on localhost:34997 (size: 3.8 KB, free: 912.3 MB)
21/02/17 01:34:37 INFO SparkContext: Created broadcast 3 from broadcast at DAGScheduler.scala:1039
21/02/17 01:34:37 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 3 (MapPartitionsRDD[15] at count at utils.scala:135) (first 15 tasks are for partitions Vector(0))
21/02/17 01:34:37 INFO TaskSchedulerImpl: Adding task set 3.0 with 1 tasks
21/02/17 01:34:37 INFO TaskSetManager: Starting task 0.0 in stage 3.0 (TID 3, localhost, executor driver, partition 0, NODE_LOCAL, 7754 bytes)
21/02/17 01:34:37 INFO Executor: Running task 0.0 in stage 3.0 (TID 3)
21/02/17 01:34:37 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
21/02/17 01:34:37 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 4 ms
21/02/17 01:34:37 INFO Executor: Finished task 0.0 in stage 3.0 (TID 3). 1782 bytes result sent to driver
21/02/17 01:34:37 INFO TaskSetManager: Finished task 0.0 in stage 3.0 (TID 3) in 29 ms on localhost (executor driver) (1/1)
21/02/17 01:34:37 INFO TaskSchedulerImpl: Removed TaskSet 3.0, whose tasks have all completed, from pool 
21/02/17 01:34:37 INFO DAGScheduler: ResultStage 3 (count at utils.scala:135) finished in 0.039 s
21/02/17 01:34:37 INFO DAGScheduler: Job 2 finished: count at utils.scala:135, took 0.103722 s
21/02/17 01:34:37 INFO SparkContext: Starting job: collect at utils.scala:135
21/02/17 01:34:37 INFO DAGScheduler: Got job 3 (collect at utils.scala:135) with 1 output partitions
21/02/17 01:34:37 INFO DAGScheduler: Final stage: ResultStage 4 (collect at utils.scala:135)
21/02/17 01:34:37 INFO DAGScheduler: Parents of final stage: List()
21/02/17 01:34:37 INFO DAGScheduler: Missing parents: List()
21/02/17 01:34:37 INFO DAGScheduler: Submitting ResultStage 4 (MapPartitionsRDD[20] at collect at utils.scala:135), which has no missing parents
21/02/17 01:34:37 INFO MemoryStore: Block broadcast_4 stored as values in memory (estimated size 6.4 KB, free 912.3 MB)
21/02/17 01:34:37 INFO MemoryStore: Block broadcast_4_piece0 stored as bytes in memory (estimated size 3.2 KB, free 912.2 MB)
21/02/17 01:34:37 INFO BlockManagerInfo: Added broadcast_4_piece0 in memory on localhost:34997 (size: 3.2 KB, free: 912.3 MB)
21/02/17 01:34:37 INFO SparkContext: Created broadcast 4 from broadcast at DAGScheduler.scala:1039
21/02/17 01:34:37 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 4 (MapPartitionsRDD[20] at collect at utils.scala:135) (first 15 tasks are for partitions Vector(0))
21/02/17 01:34:37 INFO TaskSchedulerImpl: Adding task set 4.0 with 1 tasks
21/02/17 01:34:37 INFO TaskSetManager: Starting task 0.0 in stage 4.0 (TID 4, localhost, executor driver, partition 0, PROCESS_LOCAL, 8067 bytes)
21/02/17 01:34:37 INFO Executor: Running task 0.0 in stage 4.0 (TID 4)
21/02/17 01:34:37 INFO Executor: Finished task 0.0 in stage 4.0 (TID 4). 1286 bytes result sent to driver
21/02/17 01:34:37 INFO TaskSetManager: Finished task 0.0 in stage 4.0 (TID 4) in 4 ms on localhost (executor driver) (1/1)
21/02/17 01:34:37 INFO TaskSchedulerImpl: Removed TaskSet 4.0, whose tasks have all completed, from pool 
21/02/17 01:34:37 INFO DAGScheduler: ResultStage 4 (collect at utils.scala:135) finished in 0.010 s
21/02/17 01:34:37 INFO DAGScheduler: Job 3 finished: collect at utils.scala:135, took 0.012684 s
21/02/17 01:34:37 INFO SparkContext: Starting job: count at utils.scala:135
21/02/17 01:34:37 INFO DAGScheduler: Registering RDD 23 (count at utils.scala:135)
21/02/17 01:34:37 INFO DAGScheduler: Got job 4 (count at utils.scala:135) with 1 output partitions
21/02/17 01:34:37 INFO DAGScheduler: Final stage: ResultStage 6 (count at utils.scala:135)
21/02/17 01:34:37 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 5)
21/02/17 01:34:37 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 5)
21/02/17 01:34:37 INFO DAGScheduler: Submitting ShuffleMapStage 5 (MapPartitionsRDD[23] at count at utils.scala:135), which has no missing parents
21/02/17 01:34:37 INFO MemoryStore: Block broadcast_5 stored as values in memory (estimated size 8.9 KB, free 912.2 MB)
21/02/17 01:34:37 INFO MemoryStore: Block broadcast_5_piece0 stored as bytes in memory (estimated size 4.5 KB, free 912.2 MB)
21/02/17 01:34:37 INFO BlockManagerInfo: Added broadcast_5_piece0 in memory on localhost:34997 (size: 4.5 KB, free: 912.3 MB)
21/02/17 01:34:37 INFO SparkContext: Created broadcast 5 from broadcast at DAGScheduler.scala:1039
21/02/17 01:34:37 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 5 (MapPartitionsRDD[23] at count at utils.scala:135) (first 15 tasks are for partitions Vector(0))
21/02/17 01:34:37 INFO TaskSchedulerImpl: Adding task set 5.0 with 1 tasks
21/02/17 01:34:37 INFO TaskSetManager: Starting task 0.0 in stage 5.0 (TID 5, localhost, executor driver, partition 0, PROCESS_LOCAL, 8056 bytes)
21/02/17 01:34:37 INFO Executor: Running task 0.0 in stage 5.0 (TID 5)
21/02/17 01:34:37 INFO Executor: Finished task 0.0 in stage 5.0 (TID 5). 1499 bytes result sent to driver
21/02/17 01:34:37 INFO TaskSetManager: Finished task 0.0 in stage 5.0 (TID 5) in 6 ms on localhost (executor driver) (1/1)
21/02/17 01:34:37 INFO TaskSchedulerImpl: Removed TaskSet 5.0, whose tasks have all completed, from pool 
21/02/17 01:34:37 INFO DAGScheduler: ShuffleMapStage 5 (count at utils.scala:135) finished in 0.011 s
21/02/17 01:34:37 INFO DAGScheduler: looking for newly runnable stages
21/02/17 01:34:37 INFO DAGScheduler: running: Set()
21/02/17 01:34:37 INFO DAGScheduler: waiting: Set(ResultStage 6)
21/02/17 01:34:37 INFO DAGScheduler: failed: Set()
21/02/17 01:34:37 INFO DAGScheduler: Submitting ResultStage 6 (MapPartitionsRDD[26] at count at utils.scala:135), which has no missing parents
21/02/17 01:34:37 INFO MemoryStore: Block broadcast_6 stored as values in memory (estimated size 7.3 KB, free 912.2 MB)
21/02/17 01:34:37 INFO MemoryStore: Block broadcast_6_piece0 stored as bytes in memory (estimated size 3.8 KB, free 912.2 MB)
21/02/17 01:34:37 INFO BlockManagerInfo: Added broadcast_6_piece0 in memory on localhost:34997 (size: 3.8 KB, free: 912.3 MB)
21/02/17 01:34:37 INFO SparkContext: Created broadcast 6 from broadcast at DAGScheduler.scala:1039
21/02/17 01:34:37 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 6 (MapPartitionsRDD[26] at count at utils.scala:135) (first 15 tasks are for partitions Vector(0))
21/02/17 01:34:37 INFO TaskSchedulerImpl: Adding task set 6.0 with 1 tasks
21/02/17 01:34:37 INFO TaskSetManager: Starting task 0.0 in stage 6.0 (TID 6, localhost, executor driver, partition 0, NODE_LOCAL, 7754 bytes)
21/02/17 01:34:37 INFO Executor: Running task 0.0 in stage 6.0 (TID 6)
21/02/17 01:34:37 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
21/02/17 01:34:37 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
21/02/17 01:34:37 INFO Executor: Finished task 0.0 in stage 6.0 (TID 6). 1782 bytes result sent to driver
21/02/17 01:34:37 INFO TaskSetManager: Finished task 0.0 in stage 6.0 (TID 6) in 6 ms on localhost (executor driver) (1/1)
21/02/17 01:34:37 INFO TaskSchedulerImpl: Removed TaskSet 6.0, whose tasks have all completed, from pool 
21/02/17 01:34:37 INFO DAGScheduler: ResultStage 6 (count at utils.scala:135) finished in 0.012 s
21/02/17 01:34:37 INFO DAGScheduler: Job 4 finished: count at utils.scala:135, took 0.027219 s
21/02/17 01:34:38 INFO ContextCleaner: Cleaned accumulator 10
21/02/17 01:34:38 INFO ContextCleaner: Cleaned accumulator 181
21/02/17 01:34:38 INFO ContextCleaner: Cleaned accumulator 184
21/02/17 01:34:38 INFO ContextCleaner: Cleaned accumulator 202
21/02/17 01:34:38 INFO ContextCleaner: Cleaned accumulator 172
21/02/17 01:34:38 INFO ContextCleaner: Cleaned accumulator 17
21/02/17 01:34:38 INFO ContextCleaner: Cleaned accumulator 156
21/02/17 01:34:38 INFO ContextCleaner: Cleaned accumulator 81
21/02/17 01:34:38 INFO ContextCleaner: Cleaned accumulator 192
21/02/17 01:34:38 INFO ContextCleaner: Cleaned accumulator 165
21/02/17 01:34:38 INFO ContextCleaner: Cleaned accumulator 40
21/02/17 01:34:38 INFO ContextCleaner: Cleaned accumulator 133
21/02/17 01:34:38 INFO ContextCleaner: Cleaned accumulator 32
21/02/17 01:34:38 INFO ContextCleaner: Cleaned accumulator 6
21/02/17 01:34:38 INFO ContextCleaner: Cleaned accumulator 22
21/02/17 01:34:38 INFO ContextCleaner: Cleaned accumulator 191
21/02/17 01:34:38 INFO ContextCleaner: Cleaned shuffle 0
21/02/17 01:34:38 INFO ContextCleaner: Cleaned accumulator 35
21/02/17 01:34:38 INFO BlockManagerInfo: Removed broadcast_2_piece0 on localhost:34997 in memory (size: 4.5 KB, free: 912.3 MB)
21/02/17 01:34:38 INFO ContextCleaner: Cleaned accumulator 97
21/02/17 01:34:38 INFO ContextCleaner: Cleaned accumulator 155
21/02/17 01:34:38 INFO ContextCleaner: Cleaned accumulator 177
21/02/17 01:34:38 INFO ContextCleaner: Cleaned accumulator 151
21/02/17 01:34:38 INFO ContextCleaner: Cleaned accumulator 69
21/02/17 01:34:38 INFO ContextCleaner: Cleaned accumulator 154
21/02/17 01:34:38 INFO ContextCleaner: Cleaned accumulator 182
21/02/17 01:34:38 INFO ContextCleaner: Cleaned accumulator 33
21/02/17 01:34:38 INFO ContextCleaner: Cleaned accumulator 94
21/02/17 01:34:38 INFO ContextCleaner: Cleaned accumulator 82
21/02/17 01:34:38 INFO ContextCleaner: Cleaned accumulator 25
21/02/17 01:34:38 INFO ContextCleaner: Cleaned accumulator 66
21/02/17 01:34:38 INFO ContextCleaner: Cleaned accumulator 34
21/02/17 01:34:38 INFO ContextCleaner: Cleaned accumulator 158
21/02/17 01:34:38 INFO ContextCleaner: Cleaned accumulator 150
21/02/17 01:34:38 INFO ContextCleaner: Cleaned accumulator 37
21/02/17 01:34:38 INFO ContextCleaner: Cleaned accumulator 2
21/02/17 01:34:38 INFO ContextCleaner: Cleaned accumulator 68
21/02/17 01:34:38 INFO ContextCleaner: Cleaned accumulator 171
21/02/17 01:34:38 INFO ContextCleaner: Cleaned accumulator 203
21/02/17 01:34:38 INFO ContextCleaner: Cleaned accumulator 44
21/02/17 01:34:38 INFO ContextCleaner: Cleaned accumulator 137
21/02/17 01:34:38 INFO BlockManagerInfo: Removed broadcast_5_piece0 on localhost:34997 in memory (size: 4.5 KB, free: 912.3 MB)
21/02/17 01:34:38 INFO ContextCleaner: Cleaned accumulator 136
21/02/17 01:34:38 INFO ContextCleaner: Cleaned accumulator 144
21/02/17 01:34:38 INFO ContextCleaner: Cleaned accumulator 88
21/02/17 01:34:38 INFO ContextCleaner: Cleaned accumulator 122
21/02/17 01:34:38 INFO ContextCleaner: Cleaned accumulator 101
21/02/17 01:34:38 INFO ContextCleaner: Cleaned accumulator 114
21/02/17 01:34:38 INFO ContextCleaner: Cleaned accumulator 153
21/02/17 01:34:38 INFO ContextCleaner: Cleaned accumulator 109
21/02/17 01:34:38 INFO ContextCleaner: Cleaned accumulator 8
21/02/17 01:34:38 INFO ContextCleaner: Cleaned accumulator 12
21/02/17 01:34:38 INFO ContextCleaner: Cleaned accumulator 148
21/02/17 01:34:38 INFO ContextCleaner: Cleaned accumulator 186
21/02/17 01:34:38 INFO ContextCleaner: Cleaned accumulator 178
21/02/17 01:34:38 INFO ContextCleaner: Cleaned accumulator 38
21/02/17 01:34:38 INFO ContextCleaner: Cleaned accumulator 95
21/02/17 01:34:38 INFO ContextCleaner: Cleaned accumulator 30
21/02/17 01:34:38 INFO ContextCleaner: Cleaned accumulator 145
21/02/17 01:34:38 INFO ContextCleaner: Cleaned accumulator 124
21/02/17 01:34:38 INFO ContextCleaner: Cleaned accumulator 125
21/02/17 01:34:38 INFO ContextCleaner: Cleaned accumulator 157
21/02/17 01:34:38 INFO ContextCleaner: Cleaned accumulator 138
21/02/17 01:34:38 INFO ContextCleaner: Cleaned accumulator 175
21/02/17 01:34:38 INFO BlockManagerInfo: Removed broadcast_4_piece0 on localhost:34997 in memory (size: 3.2 KB, free: 912.3 MB)
21/02/17 01:34:38 INFO ContextCleaner: Cleaned accumulator 126
21/02/17 01:34:38 INFO ContextCleaner: Cleaned accumulator 161
21/02/17 01:34:38 INFO ContextCleaner: Cleaned accumulator 211
21/02/17 01:34:38 INFO ContextCleaner: Cleaned accumulator 42
21/02/17 01:34:38 INFO ContextCleaner: Cleaned accumulator 60
21/02/17 01:34:38 INFO ContextCleaner: Cleaned accumulator 7
21/02/17 01:34:38 INFO ContextCleaner: Cleaned accumulator 91
21/02/17 01:34:38 INFO ContextCleaner: Cleaned accumulator 116
21/02/17 01:34:38 INFO ContextCleaner: Cleaned accumulator 16
21/02/17 01:34:38 INFO ContextCleaner: Cleaned accumulator 61
21/02/17 01:34:38 INFO ContextCleaner: Cleaned accumulator 111
21/02/17 01:34:38 INFO ContextCleaner: Cleaned accumulator 108
21/02/17 01:34:38 INFO ContextCleaner: Cleaned accumulator 3
21/02/17 01:34:38 INFO ContextCleaner: Cleaned accumulator 41
21/02/17 01:34:38 INFO ContextCleaner: Cleaned accumulator 14
21/02/17 01:34:38 INFO ContextCleaner: Cleaned accumulator 173
21/02/17 01:34:38 INFO ContextCleaner: Cleaned accumulator 39
21/02/17 01:34:38 INFO ContextCleaner: Cleaned accumulator 5
21/02/17 01:34:38 INFO ContextCleaner: Cleaned accumulator 117
21/02/17 01:34:38 INFO ContextCleaner: Cleaned accumulator 24
21/02/17 01:34:38 INFO ContextCleaner: Cleaned accumulator 29
21/02/17 01:34:38 INFO ContextCleaner: Cleaned accumulator 102
21/02/17 01:34:38 INFO ContextCleaner: Cleaned shuffle 1
21/02/17 01:34:38 INFO ContextCleaner: Cleaned accumulator 73
21/02/17 01:34:38 INFO ContextCleaner: Cleaned accumulator 76
21/02/17 01:34:38 INFO ContextCleaner: Cleaned accumulator 143
21/02/17 01:34:38 INFO ContextCleaner: Cleaned accumulator 104
21/02/17 01:34:38 INFO ContextCleaner: Cleaned accumulator 140
21/02/17 01:34:38 INFO ContextCleaner: Cleaned accumulator 57
21/02/17 01:34:38 INFO ContextCleaner: Cleaned accumulator 26
21/02/17 01:34:38 INFO ContextCleaner: Cleaned accumulator 9
21/02/17 01:34:38 INFO ContextCleaner: Cleaned accumulator 146
21/02/17 01:34:38 INFO ContextCleaner: Cleaned accumulator 45
21/02/17 01:34:38 INFO ContextCleaner: Cleaned accumulator 54
21/02/17 01:34:38 INFO ContextCleaner: Cleaned accumulator 194
21/02/17 01:34:38 INFO ContextCleaner: Cleaned accumulator 93
21/02/17 01:34:38 INFO ContextCleaner: Cleaned accumulator 75
21/02/17 01:34:38 INFO ContextCleaner: Cleaned accumulator 78
21/02/17 01:34:38 INFO ContextCleaner: Cleaned accumulator 65
21/02/17 01:34:38 INFO ContextCleaner: Cleaned accumulator 201
21/02/17 01:34:38 INFO ContextCleaner: Cleaned accumulator 199
21/02/17 01:34:38 INFO ContextCleaner: Cleaned accumulator 123
21/02/17 01:34:38 INFO ContextCleaner: Cleaned accumulator 74
21/02/17 01:34:38 INFO ContextCleaner: Cleaned accumulator 63
21/02/17 01:34:38 INFO ContextCleaner: Cleaned accumulator 180
21/02/17 01:34:38 INFO ContextCleaner: Cleaned accumulator 72
21/02/17 01:34:38 INFO ContextCleaner: Cleaned accumulator 210
21/02/17 01:34:38 INFO ContextCleaner: Cleaned accumulator 135
21/02/17 01:34:38 INFO ContextCleaner: Cleaned accumulator 205
21/02/17 01:34:38 INFO ContextCleaner: Cleaned accumulator 176
21/02/17 01:34:38 INFO ContextCleaner: Cleaned accumulator 189
21/02/17 01:34:38 INFO ContextCleaner: Cleaned accumulator 80
21/02/17 01:34:38 INFO ContextCleaner: Cleaned accumulator 98
21/02/17 01:34:38 INFO ContextCleaner: Cleaned accumulator 185
21/02/17 01:34:38 INFO ContextCleaner: Cleaned accumulator 169
21/02/17 01:34:38 INFO ContextCleaner: Cleaned accumulator 139
21/02/17 01:34:38 INFO ContextCleaner: Cleaned accumulator 141
21/02/17 01:34:38 INFO ContextCleaner: Cleaned accumulator 129
21/02/17 01:34:38 INFO BlockManagerInfo: Removed broadcast_0_piece0 on localhost:34997 in memory (size: 3.3 KB, free: 912.3 MB)
21/02/17 01:34:38 INFO ContextCleaner: Cleaned accumulator 149
21/02/17 01:34:38 INFO ContextCleaner: Cleaned accumulator 206
21/02/17 01:34:38 INFO ContextCleaner: Cleaned accumulator 163
21/02/17 01:34:38 INFO ContextCleaner: Cleaned accumulator 50
21/02/17 01:34:38 INFO ContextCleaner: Cleaned accumulator 103
21/02/17 01:34:38 INFO ContextCleaner: Cleaned accumulator 152
21/02/17 01:34:38 INFO ContextCleaner: Cleaned accumulator 20
21/02/17 01:34:38 INFO ContextCleaner: Cleaned accumulator 96
21/02/17 01:34:38 INFO ContextCleaner: Cleaned accumulator 52
21/02/17 01:34:38 INFO ContextCleaner: Cleaned accumulator 85
21/02/17 01:34:38 INFO ContextCleaner: Cleaned accumulator 179
21/02/17 01:34:38 INFO ContextCleaner: Cleaned accumulator 100
21/02/17 01:34:38 INFO ContextCleaner: Cleaned accumulator 51
21/02/17 01:34:38 INFO ContextCleaner: Cleaned accumulator 147
21/02/17 01:34:38 INFO ContextCleaner: Cleaned accumulator 200
21/02/17 01:34:38 INFO ContextCleaner: Cleaned accumulator 53
21/02/17 01:34:38 INFO ContextCleaner: Cleaned accumulator 190
21/02/17 01:34:38 INFO ContextCleaner: Cleaned accumulator 193
21/02/17 01:34:38 INFO ContextCleaner: Cleaned accumulator 62
21/02/17 01:34:38 INFO ContextCleaner: Cleaned accumulator 196
21/02/17 01:34:38 INFO ContextCleaner: Cleaned accumulator 198
21/02/17 01:34:38 INFO ContextCleaner: Cleaned accumulator 159
21/02/17 01:34:38 INFO ContextCleaner: Cleaned accumulator 195
21/02/17 01:34:38 INFO ContextCleaner: Cleaned accumulator 48
21/02/17 01:34:38 INFO ContextCleaner: Cleaned accumulator 204
21/02/17 01:34:38 INFO ContextCleaner: Cleaned accumulator 79
21/02/17 01:34:38 INFO ContextCleaner: Cleaned accumulator 46
21/02/17 01:34:38 INFO ContextCleaner: Cleaned accumulator 58
21/02/17 01:34:38 INFO ContextCleaner: Cleaned accumulator 115
21/02/17 01:34:38 INFO ContextCleaner: Cleaned accumulator 106
21/02/17 01:34:38 INFO ContextCleaner: Cleaned accumulator 120
21/02/17 01:34:38 INFO ContextCleaner: Cleaned accumulator 164
21/02/17 01:34:38 INFO BlockManagerInfo: Removed broadcast_3_piece0 on localhost:34997 in memory (size: 3.8 KB, free: 912.3 MB)
21/02/17 01:34:38 INFO ContextCleaner: Cleaned accumulator 170
21/02/17 01:34:38 INFO ContextCleaner: Cleaned accumulator 19
21/02/17 01:34:38 INFO ContextCleaner: Cleaned accumulator 56
21/02/17 01:34:38 INFO ContextCleaner: Cleaned accumulator 21
21/02/17 01:34:38 INFO ContextCleaner: Cleaned accumulator 31
21/02/17 01:34:38 INFO ContextCleaner: Cleaned accumulator 70
21/02/17 01:34:38 INFO ContextCleaner: Cleaned accumulator 162
21/02/17 01:34:38 INFO ContextCleaner: Cleaned accumulator 11
21/02/17 01:34:38 INFO ContextCleaner: Cleaned accumulator 207
21/02/17 01:34:38 INFO ContextCleaner: Cleaned accumulator 18
21/02/17 01:34:38 INFO ContextCleaner: Cleaned accumulator 47
21/02/17 01:34:38 INFO ContextCleaner: Cleaned accumulator 174
21/02/17 01:34:38 INFO ContextCleaner: Cleaned accumulator 131
21/02/17 01:34:38 INFO ContextCleaner: Cleaned accumulator 99
21/02/17 01:34:38 INFO ContextCleaner: Cleaned accumulator 167
21/02/17 01:34:38 INFO ContextCleaner: Cleaned accumulator 166
21/02/17 01:34:38 INFO ContextCleaner: Cleaned accumulator 209
21/02/17 01:34:38 INFO ContextCleaner: Cleaned accumulator 77
21/02/17 01:34:38 INFO ContextCleaner: Cleaned accumulator 15
21/02/17 01:34:38 INFO ContextCleaner: Cleaned accumulator 83
21/02/17 01:34:38 INFO ContextCleaner: Cleaned accumulator 67
21/02/17 01:34:38 INFO ContextCleaner: Cleaned accumulator 112
21/02/17 01:34:38 INFO ContextCleaner: Cleaned accumulator 59
21/02/17 01:34:38 INFO ContextCleaner: Cleaned accumulator 55
21/02/17 01:34:38 INFO ContextCleaner: Cleaned accumulator 142
21/02/17 01:34:38 INFO ContextCleaner: Cleaned accumulator 49
21/02/17 01:34:38 INFO ContextCleaner: Cleaned accumulator 13
21/02/17 01:34:38 INFO ContextCleaner: Cleaned accumulator 127
21/02/17 01:34:38 INFO ContextCleaner: Cleaned accumulator 128
21/02/17 01:34:38 INFO ContextCleaner: Cleaned accumulator 197
21/02/17 01:34:38 INFO ContextCleaner: Cleaned accumulator 84
21/02/17 01:34:38 INFO ContextCleaner: Cleaned accumulator 36
21/02/17 01:34:38 INFO ContextCleaner: Cleaned accumulator 188
21/02/17 01:34:38 INFO ContextCleaner: Cleaned accumulator 28
21/02/17 01:34:38 INFO ContextCleaner: Cleaned accumulator 92
21/02/17 01:34:38 INFO BlockManagerInfo: Removed broadcast_1_piece0 on localhost:34997 in memory (size: 3.2 KB, free: 912.3 MB)
21/02/17 01:34:38 INFO ContextCleaner: Cleaned accumulator 87
21/02/17 01:34:38 INFO ContextCleaner: Cleaned accumulator 113
21/02/17 01:34:38 INFO ContextCleaner: Cleaned accumulator 23
21/02/17 01:34:38 INFO ContextCleaner: Cleaned accumulator 110
21/02/17 01:34:38 INFO BlockManagerInfo: Removed broadcast_6_piece0 on localhost:34997 in memory (size: 3.8 KB, free: 912.3 MB)
21/02/17 01:34:38 INFO ContextCleaner: Cleaned accumulator 160
21/02/17 01:34:38 INFO ContextCleaner: Cleaned accumulator 132
21/02/17 01:34:38 INFO ContextCleaner: Cleaned accumulator 134
21/02/17 01:34:38 INFO ContextCleaner: Cleaned accumulator 168
21/02/17 01:34:38 INFO ContextCleaner: Cleaned accumulator 130
21/02/17 01:34:38 INFO ContextCleaner: Cleaned accumulator 187
21/02/17 01:34:38 INFO ContextCleaner: Cleaned accumulator 64
21/02/17 01:34:38 INFO ContextCleaner: Cleaned accumulator 4
21/02/17 01:34:38 INFO ContextCleaner: Cleaned accumulator 27
21/02/17 01:34:38 INFO ContextCleaner: Cleaned accumulator 71
21/02/17 01:34:38 INFO ContextCleaner: Cleaned accumulator 89
21/02/17 01:34:38 INFO ContextCleaner: Cleaned accumulator 208
21/02/17 01:34:38 INFO ContextCleaner: Cleaned accumulator 105
21/02/17 01:34:38 INFO ContextCleaner: Cleaned accumulator 1
21/02/17 01:34:38 INFO ContextCleaner: Cleaned accumulator 43
21/02/17 01:34:38 INFO ContextCleaner: Cleaned accumulator 86
21/02/17 01:34:38 INFO ContextCleaner: Cleaned accumulator 107
21/02/17 01:34:38 INFO ContextCleaner: Cleaned accumulator 90
21/02/17 01:34:38 INFO ContextCleaner: Cleaned accumulator 183
21/02/17 01:34:38 INFO ContextCleaner: Cleaned accumulator 121
21/02/17 01:34:38 INFO CodeGenerator: Code generated in 39.279743 ms
21/02/17 01:34:38 INFO XGBoostSpark: Running XGBoost 1.1.2 with parameters:
alpha -> 0.0
min_child_weight -> 1.0
sample_type -> uniform
base_score -> 0.5
rabit_timeout -> -1
colsample_bylevel -> 1.0
grow_policy -> depthwise
skip_drop -> 0.0
lambda_bias -> 0.0
silent -> 0
scale_pos_weight -> 1.0
seed -> 0
cache_training_set -> false
features_col -> features
num_early_stopping_rounds -> 0
label_col -> label
num_workers -> 1
subsample -> 1.0
lambda -> 1.0
max_depth -> 6
tree_limit -> 0
custom_eval -> null
dmlc_worker_connect_retry -> 5
rate_drop -> 0.0
max_bin -> 16
train_test_ratio -> 1.0
use_external_memory -> false
objective -> reg:linear
eval_metric -> rmse
num_round -> 1
maximize_evaluation_metrics -> false
timeout_request_workers -> 1800000
missing -> NaN
rabit_ring_reduce_threshold -> 32768
checkpoint_path -> 
tracker_conf -> TrackerConf(0,python)
tree_method -> auto
max_delta_step -> 0.0
eta -> 0.3
verbosity -> 1
colsample_bytree -> 1.0
objective_type -> regression
normalize_type -> tree
allow_non_zero_for_missing -> false
custom_obj -> null
gamma -> 0.0
sketch_eps -> 0.03
nthread -> 1
prediction_col -> prediction
checkpoint_interval -> -1
21/02/17 01:34:38 WARN XGBoostSpark: train_test_ratio is deprecated since XGBoost 0.82, we recommend to explicitly pass a training and multiple evaluation datasets by passing 'eval_sets' and 'eval_set_names'
21/02/17 01:34:38 INFO RabitTracker$TrackerProcessLogger: 2021-02-17 01:34:38,711 INFO start listen on 192.168.2.12:9091
21/02/17 01:34:38 INFO XGBoostSpark: starting training with timeout set as 1800000 ms for waiting for resources
21/02/17 01:34:38 INFO SparkContext: Starting job: foreachPartition at XGBoost.scala:565
21/02/17 01:34:38 INFO DAGScheduler: Got job 5 (foreachPartition at XGBoost.scala:565) with 1 output partitions
21/02/17 01:34:38 INFO DAGScheduler: Final stage: ResultStage 7 (foreachPartition at XGBoost.scala:565)
21/02/17 01:34:38 INFO DAGScheduler: Parents of final stage: List()
21/02/17 01:34:38 INFO DAGScheduler: Missing parents: List()
21/02/17 01:34:38 INFO DAGScheduler: Submitting ResultStage 7 (MapPartitionsRDD[35] at mapPartitions at XGBoost.scala:450), which has no missing parents
21/02/17 01:34:38 INFO MemoryStore: Block broadcast_7 stored as values in memory (estimated size 33.9 KB, free 912.3 MB)
21/02/17 01:34:38 INFO MemoryStore: Block broadcast_7_piece0 stored as bytes in memory (estimated size 14.2 KB, free 912.3 MB)
21/02/17 01:34:38 INFO BlockManagerInfo: Added broadcast_7_piece0 in memory on localhost:34997 (size: 14.2 KB, free: 912.3 MB)
21/02/17 01:34:38 INFO SparkContext: Created broadcast 7 from broadcast at DAGScheduler.scala:1039
21/02/17 01:34:38 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 7 (MapPartitionsRDD[35] at mapPartitions at XGBoost.scala:450) (first 15 tasks are for partitions Vector(0))
21/02/17 01:34:38 INFO TaskSchedulerImpl: Adding task set 7.0 with 1 tasks
21/02/17 01:34:38 INFO TaskSetManager: Starting task 0.0 in stage 7.0 (TID 7, localhost, executor driver, partition 0, PROCESS_LOCAL, 18998 bytes)
21/02/17 01:34:38 INFO Executor: Running task 0.0 in stage 7.0 (TID 7)
21/02/17 01:34:38 INFO CodeGenerator: Code generated in 10.928567 ms
21/02/17 01:34:38 INFO MemoryStore: Block rdd_17_0 stored as values in memory (estimated size 5.6 KB, free 912.2 MB)
21/02/17 01:34:38 INFO BlockManagerInfo: Added rdd_17_0 in memory on localhost:34997 (size: 5.6 KB, free: 912.3 MB)
21/02/17 01:34:38 INFO CodeGenerator: Code generated in 3.769544 ms
21/02/17 01:34:38 INFO CodeGenerator: Code generated in 19.60012 ms
21/02/17 01:34:38 INFO CodeGenerator: Code generated in 11.768203 ms
21/02/17 01:34:38 INFO RabitTracker$TrackerProcessLogger: /tmp/tracker8197182258829259585.py:330: DeprecationWarning: isAlive() is deprecated, use is_alive() instead
21/02/17 01:34:38 INFO RabitTracker$TrackerProcessLogger:   while self.thread.isAlive():
21/02/17 01:34:38 INFO RabitTracker$TrackerProcessLogger: 2021-02-17 01:34:38,977 DEBUG Recieve start signal from 192.168.2.12; assign rank 0
21/02/17 01:34:38 INFO RabitTracker$TrackerProcessLogger: 2021-02-17 01:34:38,977 INFO @tracker All of 1 nodes getting started
21/02/17 01:34:38 INFO RabitTracker$TrackerProcessLogger: 2021-02-17 01:34:38,984 INFO [0]	train-rmse:2.633044
21/02/17 01:34:38 INFO RabitTracker$TrackerProcessLogger: 2021-02-17 01:34:38,985 DEBUG Recieve shutdown signal from 0
21/02/17 01:34:38 INFO RabitTracker$TrackerProcessLogger: 2021-02-17 01:34:38,985 INFO @tracker All nodes finishes job
21/02/17 01:34:38 INFO RabitTracker$TrackerProcessLogger: 2021-02-17 01:34:38,985 INFO @tracker 0.008443832397460938 secs between node start and job finish
21/02/17 01:34:38 INFO MemoryStore: Block rdd_35_0 stored as values in memory (estimated size 192.0 B, free 912.2 MB)
21/02/17 01:34:38 INFO BlockManagerInfo: Added rdd_35_0 in memory on localhost:34997 (size: 192.0 B, free: 912.3 MB)
21/02/17 01:34:38 INFO RabitTracker$TrackerProcessLogger: Tracker Process ends with exit code 0
21/02/17 01:34:38 INFO RabitTracker: Tracker Process ends with exit code 0
21/02/17 01:34:38 INFO XGBoostSpark: Rabit returns with exit code 0
21/02/17 01:34:38 INFO Executor: 1 block locks were not released by TID = 7:
[rdd_35_0]
21/02/17 01:34:38 INFO Executor: Finished task 0.0 in stage 7.0 (TID 7). 1303 bytes result sent to driver
21/02/17 01:34:38 INFO TaskSetManager: Finished task 0.0 in stage 7.0 (TID 7) in 212 ms on localhost (executor driver) (1/1)
21/02/17 01:34:38 INFO TaskSchedulerImpl: Removed TaskSet 7.0, whose tasks have all completed, from pool 
21/02/17 01:34:38 INFO DAGScheduler: ResultStage 7 (foreachPartition at XGBoost.scala:565) finished in 0.255 s
21/02/17 01:34:38 INFO DAGScheduler: Job 5 finished: foreachPartition at XGBoost.scala:565, took 0.261943 s
21/02/17 01:34:39 INFO SparkContext: Starting job: first at XGBoost.scala:685
21/02/17 01:34:39 INFO DAGScheduler: Got job 6 (first at XGBoost.scala:685) with 1 output partitions
21/02/17 01:34:39 INFO DAGScheduler: Final stage: ResultStage 8 (first at XGBoost.scala:685)
21/02/17 01:34:39 INFO DAGScheduler: Parents of final stage: List()
21/02/17 01:34:39 INFO DAGScheduler: Missing parents: List()
21/02/17 01:34:39 INFO DAGScheduler: Submitting ResultStage 8 (MapPartitionsRDD[35] at mapPartitions at XGBoost.scala:450), which has no missing parents
21/02/17 01:34:39 INFO MemoryStore: Block broadcast_8 stored as values in memory (estimated size 34.0 KB, free 912.2 MB)
21/02/17 01:34:39 INFO MemoryStore: Block broadcast_8_piece0 stored as bytes in memory (estimated size 14.3 KB, free 912.2 MB)
21/02/17 01:34:39 INFO BlockManagerInfo: Added broadcast_8_piece0 in memory on localhost:34997 (size: 14.3 KB, free: 912.3 MB)
21/02/17 01:34:39 INFO SparkContext: Created broadcast 8 from broadcast at DAGScheduler.scala:1039
21/02/17 01:34:39 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 8 (MapPartitionsRDD[35] at mapPartitions at XGBoost.scala:450) (first 15 tasks are for partitions Vector(0))
21/02/17 01:34:39 INFO TaskSchedulerImpl: Adding task set 8.0 with 1 tasks
21/02/17 01:34:39 INFO TaskSetManager: Starting task 0.0 in stage 8.0 (TID 8, localhost, executor driver, partition 0, PROCESS_LOCAL, 18998 bytes)
21/02/17 01:34:39 INFO Executor: Running task 0.0 in stage 8.0 (TID 8)
21/02/17 01:34:39 INFO BlockManager: Found block rdd_35_0 locally
21/02/17 01:34:39 INFO Executor: 1 block locks were not released by TID = 8:
[rdd_35_0]
21/02/17 01:34:39 INFO Executor: Finished task 0.0 in stage 8.0 (TID 8). 2551 bytes result sent to driver
21/02/17 01:34:39 INFO TaskSetManager: Finished task 0.0 in stage 8.0 (TID 8) in 12 ms on localhost (executor driver) (1/1)
21/02/17 01:34:39 INFO TaskSchedulerImpl: Removed TaskSet 8.0, whose tasks have all completed, from pool 
21/02/17 01:34:39 INFO DAGScheduler: ResultStage 8 (first at XGBoost.scala:685) finished in 0.021 s
21/02/17 01:34:39 INFO DAGScheduler: Job 6 finished: first at XGBoost.scala:685, took 0.023530 s
21/02/17 01:34:39 INFO MapPartitionsRDD: Removing RDD 35 from persistence list
21/02/17 01:34:39 INFO BlockManager: Removing RDD 35
21/02/17 01:34:39 INFO MemoryStore: Block broadcast_9 stored as values in memory (estimated size 64.0 B, free 912.2 MB)
21/02/17 01:34:39 INFO MemoryStore: Block broadcast_9_piece0 stored as bytes in memory (estimated size 510.0 B, free 912.2 MB)
21/02/17 01:34:39 INFO BlockManagerInfo: Added broadcast_9_piece0 in memory on localhost:34997 (size: 510.0 B, free: 912.3 MB)
21/02/17 01:34:39 INFO SparkContext: Created broadcast 9 from broadcast at XGBoostRegressor.scala:271
21/02/17 01:34:39 INFO CodeGenerator: Code generated in 21.859317 ms
21/02/17 01:34:39 INFO CodeGenerator: Code generated in 6.524179 ms
21/02/17 01:34:39 INFO CodeGenerator: Code generated in 7.957594 ms
21/02/17 01:34:39 INFO SparkContext: Starting job: collect at utils.scala:135
21/02/17 01:34:39 INFO DAGScheduler: Got job 7 (collect at utils.scala:135) with 1 output partitions
21/02/17 01:34:39 INFO DAGScheduler: Final stage: ResultStage 9 (collect at utils.scala:135)
21/02/17 01:34:39 INFO DAGScheduler: Parents of final stage: List()
21/02/17 01:34:39 INFO DAGScheduler: Missing parents: List()
21/02/17 01:34:39 INFO DAGScheduler: Submitting ResultStage 9 (MapPartitionsRDD[46] at collect at utils.scala:135), which has no missing parents
21/02/17 01:34:39 INFO MemoryStore: Block broadcast_10 stored as values in memory (estimated size 6.5 KB, free 912.2 MB)
21/02/17 01:34:39 INFO MemoryStore: Block broadcast_10_piece0 stored as bytes in memory (estimated size 3.2 KB, free 912.2 MB)
21/02/17 01:34:39 INFO BlockManagerInfo: Added broadcast_10_piece0 in memory on localhost:34997 (size: 3.2 KB, free: 912.3 MB)
21/02/17 01:34:39 INFO SparkContext: Created broadcast 10 from broadcast at DAGScheduler.scala:1039
21/02/17 01:34:39 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 9 (MapPartitionsRDD[46] at collect at utils.scala:135) (first 15 tasks are for partitions Vector(0))
21/02/17 01:34:39 INFO TaskSchedulerImpl: Adding task set 9.0 with 1 tasks
21/02/17 01:34:39 INFO TaskSetManager: Starting task 0.0 in stage 9.0 (TID 9, localhost, executor driver, partition 0, PROCESS_LOCAL, 8067 bytes)
21/02/17 01:34:39 INFO Executor: Running task 0.0 in stage 9.0 (TID 9)
21/02/17 01:34:39 INFO Executor: Finished task 0.0 in stage 9.0 (TID 9). 1243 bytes result sent to driver
21/02/17 01:34:39 INFO TaskSetManager: Finished task 0.0 in stage 9.0 (TID 9) in 5 ms on localhost (executor driver) (1/1)
21/02/17 01:34:39 INFO TaskSchedulerImpl: Removed TaskSet 9.0, whose tasks have all completed, from pool 
21/02/17 01:34:39 INFO DAGScheduler: ResultStage 9 (collect at utils.scala:135) finished in 0.011 s
21/02/17 01:34:39 INFO DAGScheduler: Job 7 finished: collect at utils.scala:135, took 0.012783 s
21/02/17 01:34:39 INFO SparkContext: Starting job: count at utils.scala:135
21/02/17 01:34:39 INFO DAGScheduler: Registering RDD 49 (count at utils.scala:135)
21/02/17 01:34:39 INFO DAGScheduler: Got job 8 (count at utils.scala:135) with 1 output partitions
21/02/17 01:34:39 INFO DAGScheduler: Final stage: ResultStage 11 (count at utils.scala:135)
21/02/17 01:34:39 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 10)
21/02/17 01:34:39 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 10)
21/02/17 01:34:39 INFO DAGScheduler: Submitting ShuffleMapStage 10 (MapPartitionsRDD[49] at count at utils.scala:135), which has no missing parents
21/02/17 01:34:39 INFO MemoryStore: Block broadcast_11 stored as values in memory (estimated size 8.9 KB, free 912.2 MB)
21/02/17 01:34:39 INFO MemoryStore: Block broadcast_11_piece0 stored as bytes in memory (estimated size 4.5 KB, free 912.2 MB)
21/02/17 01:34:39 INFO BlockManagerInfo: Added broadcast_11_piece0 in memory on localhost:34997 (size: 4.5 KB, free: 912.3 MB)
21/02/17 01:34:39 INFO SparkContext: Created broadcast 11 from broadcast at DAGScheduler.scala:1039
21/02/17 01:34:39 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 10 (MapPartitionsRDD[49] at count at utils.scala:135) (first 15 tasks are for partitions Vector(0))
21/02/17 01:34:39 INFO TaskSchedulerImpl: Adding task set 10.0 with 1 tasks
21/02/17 01:34:39 INFO TaskSetManager: Starting task 0.0 in stage 10.0 (TID 10, localhost, executor driver, partition 0, PROCESS_LOCAL, 8056 bytes)
21/02/17 01:34:39 INFO Executor: Running task 0.0 in stage 10.0 (TID 10)
21/02/17 01:34:39 INFO Executor: Finished task 0.0 in stage 10.0 (TID 10). 1499 bytes result sent to driver
21/02/17 01:34:39 INFO TaskSetManager: Finished task 0.0 in stage 10.0 (TID 10) in 6 ms on localhost (executor driver) (1/1)
21/02/17 01:34:39 INFO TaskSchedulerImpl: Removed TaskSet 10.0, whose tasks have all completed, from pool 
21/02/17 01:34:39 INFO DAGScheduler: ShuffleMapStage 10 (count at utils.scala:135) finished in 0.013 s
21/02/17 01:34:39 INFO DAGScheduler: looking for newly runnable stages
21/02/17 01:34:39 INFO DAGScheduler: running: Set()
21/02/17 01:34:39 INFO DAGScheduler: waiting: Set(ResultStage 11)
21/02/17 01:34:39 INFO DAGScheduler: failed: Set()
21/02/17 01:34:39 INFO DAGScheduler: Submitting ResultStage 11 (MapPartitionsRDD[52] at count at utils.scala:135), which has no missing parents
21/02/17 01:34:39 INFO MemoryStore: Block broadcast_12 stored as values in memory (estimated size 7.3 KB, free 912.2 MB)
21/02/17 01:34:39 INFO MemoryStore: Block broadcast_12_piece0 stored as bytes in memory (estimated size 3.8 KB, free 912.2 MB)
21/02/17 01:34:39 INFO BlockManagerInfo: Added broadcast_12_piece0 in memory on localhost:34997 (size: 3.8 KB, free: 912.3 MB)
21/02/17 01:34:39 INFO SparkContext: Created broadcast 12 from broadcast at DAGScheduler.scala:1039
21/02/17 01:34:39 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 11 (MapPartitionsRDD[52] at count at utils.scala:135) (first 15 tasks are for partitions Vector(0))
21/02/17 01:34:39 INFO TaskSchedulerImpl: Adding task set 11.0 with 1 tasks
21/02/17 01:34:39 INFO TaskSetManager: Starting task 0.0 in stage 11.0 (TID 11, localhost, executor driver, partition 0, NODE_LOCAL, 7754 bytes)
21/02/17 01:34:39 INFO Executor: Running task 0.0 in stage 11.0 (TID 11)
21/02/17 01:34:39 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
21/02/17 01:34:39 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
21/02/17 01:34:39 INFO Executor: Finished task 0.0 in stage 11.0 (TID 11). 1782 bytes result sent to driver
21/02/17 01:34:39 INFO TaskSetManager: Finished task 0.0 in stage 11.0 (TID 11) in 6 ms on localhost (executor driver) (1/1)
21/02/17 01:34:39 INFO TaskSchedulerImpl: Removed TaskSet 11.0, whose tasks have all completed, from pool 
21/02/17 01:34:39 INFO DAGScheduler: ResultStage 11 (count at utils.scala:135) finished in 0.012 s
21/02/17 01:34:39 INFO DAGScheduler: Job 8 finished: count at utils.scala:135, took 0.028375 s
21/02/17 01:34:39 INFO CodeGenerator: Code generated in 7.20613 ms
21/02/17 01:34:39 INFO CodeGenerator: Code generated in 10.218829 ms
21/02/17 01:34:39 INFO SparkContext: Starting job: collect at utils.scala:135
21/02/17 01:34:39 INFO DAGScheduler: Got job 9 (collect at utils.scala:135) with 1 output partitions
21/02/17 01:34:39 INFO DAGScheduler: Final stage: ResultStage 12 (collect at utils.scala:135)
21/02/17 01:34:39 INFO DAGScheduler: Parents of final stage: List()
21/02/17 01:34:39 INFO DAGScheduler: Missing parents: List()
21/02/17 01:34:39 INFO DAGScheduler: Submitting ResultStage 12 (MapPartitionsRDD[55] at collect at utils.scala:135), which has no missing parents
21/02/17 01:34:39 INFO MemoryStore: Block broadcast_13 stored as values in memory (estimated size 61.1 KB, free 912.1 MB)
21/02/17 01:34:39 INFO MemoryStore: Block broadcast_13_piece0 stored as bytes in memory (estimated size 25.3 KB, free 912.1 MB)
21/02/17 01:34:39 INFO BlockManagerInfo: Added broadcast_13_piece0 in memory on localhost:34997 (size: 25.3 KB, free: 912.2 MB)
21/02/17 01:34:39 INFO SparkContext: Created broadcast 13 from broadcast at DAGScheduler.scala:1039
21/02/17 01:34:39 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 12 (MapPartitionsRDD[55] at collect at utils.scala:135) (first 15 tasks are for partitions Vector(0))
21/02/17 01:34:39 INFO TaskSchedulerImpl: Adding task set 12.0 with 1 tasks
21/02/17 01:34:39 INFO TaskSetManager: Starting task 0.0 in stage 12.0 (TID 12, localhost, executor driver, partition 0, PROCESS_LOCAL, 18998 bytes)
21/02/17 01:34:39 INFO Executor: Running task 0.0 in stage 12.0 (TID 12)
21/02/17 01:34:39 INFO BlockManager: Found block rdd_17_0 locally
21/02/17 01:34:39 INFO CodeGenerator: Code generated in 11.211207 ms
21/02/17 01:34:39 INFO CodeGenerator: Code generated in 21.051069 ms
21/02/17 01:34:40 INFO CodeGenerator: Code generated in 37.999139 ms
21/02/17 01:34:40 INFO Executor: Finished task 0.0 in stage 12.0 (TID 12). 1815 bytes result sent to driver
21/02/17 01:34:40 INFO TaskSetManager: Finished task 0.0 in stage 12.0 (TID 12) in 137 ms on localhost (executor driver) (1/1)
21/02/17 01:34:40 INFO TaskSchedulerImpl: Removed TaskSet 12.0, whose tasks have all completed, from pool 
21/02/17 01:34:40 INFO DAGScheduler: ResultStage 12 (collect at utils.scala:135) finished in 0.145 s
21/02/17 01:34:40 INFO DAGScheduler: Job 9 finished: collect at utils.scala:135, took 0.148485 s
21/02/17 01:34:40 INFO CodeGenerator: Code generated in 9.953261 ms
21/02/17 01:34:40 INFO SparkContext: Starting job: count at utils.scala:135
21/02/17 01:34:40 INFO DAGScheduler: Registering RDD 58 (count at utils.scala:135)
21/02/17 01:34:40 INFO DAGScheduler: Got job 10 (count at utils.scala:135) with 1 output partitions
21/02/17 01:34:40 INFO DAGScheduler: Final stage: ResultStage 14 (count at utils.scala:135)
21/02/17 01:34:40 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 13)
21/02/17 01:34:40 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 13)
21/02/17 01:34:40 INFO DAGScheduler: Submitting ShuffleMapStage 13 (MapPartitionsRDD[58] at count at utils.scala:135), which has no missing parents
21/02/17 01:34:40 INFO MemoryStore: Block broadcast_14 stored as values in memory (estimated size 62.0 KB, free 912.0 MB)
21/02/17 01:34:40 INFO MemoryStore: Block broadcast_14_piece0 stored as bytes in memory (estimated size 25.8 KB, free 912.0 MB)
21/02/17 01:34:40 INFO BlockManagerInfo: Added broadcast_14_piece0 in memory on localhost:34997 (size: 25.8 KB, free: 912.2 MB)
21/02/17 01:34:40 INFO SparkContext: Created broadcast 14 from broadcast at DAGScheduler.scala:1039
21/02/17 01:34:40 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 13 (MapPartitionsRDD[58] at count at utils.scala:135) (first 15 tasks are for partitions Vector(0))
21/02/17 01:34:40 INFO TaskSchedulerImpl: Adding task set 13.0 with 1 tasks
21/02/17 01:34:40 INFO TaskSetManager: Starting task 0.0 in stage 13.0 (TID 13, localhost, executor driver, partition 0, PROCESS_LOCAL, 18987 bytes)
21/02/17 01:34:40 INFO Executor: Running task 0.0 in stage 13.0 (TID 13)
21/02/17 01:34:40 INFO BlockManager: Found block rdd_17_0 locally
21/02/17 01:34:40 INFO Executor: Finished task 0.0 in stage 13.0 (TID 13). 1976 bytes result sent to driver
21/02/17 01:34:40 INFO TaskSetManager: Finished task 0.0 in stage 13.0 (TID 13) in 39 ms on localhost (executor driver) (1/1)
21/02/17 01:34:40 INFO TaskSchedulerImpl: Removed TaskSet 13.0, whose tasks have all completed, from pool 
21/02/17 01:34:40 INFO DAGScheduler: ShuffleMapStage 13 (count at utils.scala:135) finished in 0.047 s
21/02/17 01:34:40 INFO DAGScheduler: looking for newly runnable stages
21/02/17 01:34:40 INFO DAGScheduler: running: Set()
21/02/17 01:34:40 INFO DAGScheduler: waiting: Set(ResultStage 14)
21/02/17 01:34:40 INFO DAGScheduler: failed: Set()
21/02/17 01:34:40 INFO DAGScheduler: Submitting ResultStage 14 (MapPartitionsRDD[61] at count at utils.scala:135), which has no missing parents
21/02/17 01:34:40 INFO MemoryStore: Block broadcast_15 stored as values in memory (estimated size 7.3 KB, free 912.0 MB)
21/02/17 01:34:40 INFO MemoryStore: Block broadcast_15_piece0 stored as bytes in memory (estimated size 3.8 KB, free 912.0 MB)
21/02/17 01:34:40 INFO BlockManagerInfo: Added broadcast_15_piece0 in memory on localhost:34997 (size: 3.8 KB, free: 912.2 MB)
21/02/17 01:34:40 INFO SparkContext: Created broadcast 15 from broadcast at DAGScheduler.scala:1039
21/02/17 01:34:40 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 14 (MapPartitionsRDD[61] at count at utils.scala:135) (first 15 tasks are for partitions Vector(0))
21/02/17 01:34:40 INFO TaskSchedulerImpl: Adding task set 14.0 with 1 tasks
21/02/17 01:34:40 INFO TaskSetManager: Starting task 0.0 in stage 14.0 (TID 14, localhost, executor driver, partition 0, NODE_LOCAL, 7754 bytes)
21/02/17 01:34:40 INFO Executor: Running task 0.0 in stage 14.0 (TID 14)
21/02/17 01:34:40 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
21/02/17 01:34:40 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
21/02/17 01:34:40 INFO Executor: Finished task 0.0 in stage 14.0 (TID 14). 1782 bytes result sent to driver
21/02/17 01:34:40 INFO TaskSetManager: Finished task 0.0 in stage 14.0 (TID 14) in 4 ms on localhost (executor driver) (1/1)
21/02/17 01:34:40 INFO TaskSchedulerImpl: Removed TaskSet 14.0, whose tasks have all completed, from pool 
21/02/17 01:34:40 INFO DAGScheduler: ResultStage 14 (count at utils.scala:135) finished in 0.008 s
21/02/17 01:34:40 INFO DAGScheduler: Job 10 finished: count at utils.scala:135, took 0.059444 s
21/02/17 01:34:40 INFO deprecation: mapred.output.dir is deprecated. Instead, use mapreduce.output.fileoutputformat.outputdir
21/02/17 01:34:40 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
21/02/17 01:34:40 INFO SparkContext: Starting job: runJob at SparkHadoopWriter.scala:78
21/02/17 01:34:40 INFO DAGScheduler: Got job 11 (runJob at SparkHadoopWriter.scala:78) with 1 output partitions
21/02/17 01:34:40 INFO DAGScheduler: Final stage: ResultStage 15 (runJob at SparkHadoopWriter.scala:78)
21/02/17 01:34:40 INFO DAGScheduler: Parents of final stage: List()
21/02/17 01:34:40 INFO DAGScheduler: Missing parents: List()
21/02/17 01:34:40 INFO DAGScheduler: Submitting ResultStage 15 (MapPartitionsRDD[63] at saveAsTextFile at ReadWrite.scala:283), which has no missing parents
21/02/17 01:34:40 INFO MemoryStore: Block broadcast_16 stored as values in memory (estimated size 71.0 KB, free 911.9 MB)
21/02/17 01:34:40 INFO MemoryStore: Block broadcast_16_piece0 stored as bytes in memory (estimated size 25.3 KB, free 911.9 MB)
21/02/17 01:34:40 INFO BlockManagerInfo: Added broadcast_16_piece0 in memory on localhost:34997 (size: 25.3 KB, free: 912.2 MB)
21/02/17 01:34:40 INFO SparkContext: Created broadcast 16 from broadcast at DAGScheduler.scala:1039
21/02/17 01:34:40 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 15 (MapPartitionsRDD[63] at saveAsTextFile at ReadWrite.scala:283) (first 15 tasks are for partitions Vector(0))
21/02/17 01:34:40 INFO TaskSchedulerImpl: Adding task set 15.0 with 1 tasks
21/02/17 01:34:40 INFO TaskSetManager: Starting task 0.0 in stage 15.0 (TID 15, localhost, executor driver, partition 0, PROCESS_LOCAL, 8142 bytes)
21/02/17 01:34:40 INFO Executor: Running task 0.0 in stage 15.0 (TID 15)
21/02/17 01:34:40 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
21/02/17 01:34:40 INFO FileOutputCommitter: Saved output of task 'attempt_20210217013440_0063_m_000000_0' to file:/tmp/RtmpqE8K95/file2236138cd1f15/metadata/_temporary/0/task_20210217013440_0063_m_000000
21/02/17 01:34:40 INFO SparkHadoopMapRedUtil: attempt_20210217013440_0063_m_000000_0: Committed
21/02/17 01:34:40 INFO Executor: Finished task 0.0 in stage 15.0 (TID 15). 1072 bytes result sent to driver
21/02/17 01:34:40 INFO TaskSetManager: Finished task 0.0 in stage 15.0 (TID 15) in 50 ms on localhost (executor driver) (1/1)
21/02/17 01:34:40 INFO TaskSchedulerImpl: Removed TaskSet 15.0, whose tasks have all completed, from pool 
21/02/17 01:34:40 INFO DAGScheduler: ResultStage 15 (runJob at SparkHadoopWriter.scala:78) finished in 0.069 s
21/02/17 01:34:40 INFO DAGScheduler: Job 11 finished: runJob at SparkHadoopWriter.scala:78, took 0.070358 s
21/02/17 01:34:40 INFO SparkHadoopWriter: Job job_20210217013440_0063 committed.
21/02/17 01:34:40 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
21/02/17 01:34:40 INFO SparkContext: Starting job: runJob at SparkHadoopWriter.scala:78
21/02/17 01:34:40 INFO DAGScheduler: Got job 12 (runJob at SparkHadoopWriter.scala:78) with 1 output partitions
21/02/17 01:34:40 INFO DAGScheduler: Final stage: ResultStage 16 (runJob at SparkHadoopWriter.scala:78)
21/02/17 01:34:40 INFO DAGScheduler: Parents of final stage: List()
21/02/17 01:34:40 INFO DAGScheduler: Missing parents: List()
21/02/17 01:34:40 INFO DAGScheduler: Submitting ResultStage 16 (MapPartitionsRDD[65] at saveAsTextFile at ReadWrite.scala:283), which has no missing parents
21/02/17 01:34:40 INFO MemoryStore: Block broadcast_17 stored as values in memory (estimated size 71.1 KB, free 911.8 MB)
21/02/17 01:34:40 INFO MemoryStore: Block broadcast_17_piece0 stored as bytes in memory (estimated size 25.4 KB, free 911.8 MB)
21/02/17 01:34:40 INFO BlockManagerInfo: Added broadcast_17_piece0 in memory on localhost:34997 (size: 25.4 KB, free: 912.2 MB)
21/02/17 01:34:40 INFO SparkContext: Created broadcast 17 from broadcast at DAGScheduler.scala:1039
21/02/17 01:34:40 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 16 (MapPartitionsRDD[65] at saveAsTextFile at ReadWrite.scala:283) (first 15 tasks are for partitions Vector(0))
21/02/17 01:34:40 INFO TaskSchedulerImpl: Adding task set 16.0 with 1 tasks
21/02/17 01:34:40 INFO TaskSetManager: Starting task 0.0 in stage 16.0 (TID 16, localhost, executor driver, partition 0, PROCESS_LOCAL, 8216 bytes)
21/02/17 01:34:40 INFO Executor: Running task 0.0 in stage 16.0 (TID 16)
21/02/17 01:34:40 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
21/02/17 01:34:40 INFO FileOutputCommitter: Saved output of task 'attempt_20210217013440_0065_m_000000_0' to file:/tmp/RtmpqE8K95/file2236138cd1f15/stages/0_r_formula__9b9b20bf_34e1_4305_9c6b_8f400f69191b/metadata/_temporary/0/task_20210217013440_0065_m_000000
21/02/17 01:34:40 INFO SparkHadoopMapRedUtil: attempt_20210217013440_0065_m_000000_0: Committed
21/02/17 01:34:40 INFO Executor: Finished task 0.0 in stage 16.0 (TID 16). 1029 bytes result sent to driver
21/02/17 01:34:40 INFO TaskSetManager: Finished task 0.0 in stage 16.0 (TID 16) in 17 ms on localhost (executor driver) (1/1)
21/02/17 01:34:40 INFO TaskSchedulerImpl: Removed TaskSet 16.0, whose tasks have all completed, from pool 
21/02/17 01:34:40 INFO DAGScheduler: ResultStage 16 (runJob at SparkHadoopWriter.scala:78) finished in 0.031 s
21/02/17 01:34:40 INFO DAGScheduler: Job 12 finished: runJob at SparkHadoopWriter.scala:78, took 0.033527 s
21/02/17 01:34:40 INFO SparkHadoopWriter: Job job_20210217013440_0065 committed.
21/02/17 01:34:40 INFO ParquetFileFormat: Using default output committer for Parquet: org.apache.parquet.hadoop.ParquetOutputCommitter
21/02/17 01:34:40 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
21/02/17 01:34:40 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
21/02/17 01:34:40 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
21/02/17 01:34:40 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
21/02/17 01:34:40 INFO CodeGenerator: Code generated in 12.27864 ms
21/02/17 01:34:40 INFO SparkContext: Starting job: parquet at RFormula.scala:421
21/02/17 01:34:40 INFO DAGScheduler: Registering RDD 68 (parquet at RFormula.scala:421)
21/02/17 01:34:40 INFO DAGScheduler: Got job 13 (parquet at RFormula.scala:421) with 1 output partitions
21/02/17 01:34:40 INFO DAGScheduler: Final stage: ResultStage 18 (parquet at RFormula.scala:421)
21/02/17 01:34:40 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 17)
21/02/17 01:34:40 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 17)
21/02/17 01:34:40 INFO DAGScheduler: Submitting ShuffleMapStage 17 (MapPartitionsRDD[68] at parquet at RFormula.scala:421), which has no missing parents
21/02/17 01:34:40 INFO MemoryStore: Block broadcast_18 stored as values in memory (estimated size 4.8 KB, free 911.8 MB)
21/02/17 01:34:40 INFO MemoryStore: Block broadcast_18_piece0 stored as bytes in memory (estimated size 2.9 KB, free 911.8 MB)
21/02/17 01:34:40 INFO BlockManagerInfo: Added broadcast_18_piece0 in memory on localhost:34997 (size: 2.9 KB, free: 912.1 MB)
21/02/17 01:34:40 INFO SparkContext: Created broadcast 18 from broadcast at DAGScheduler.scala:1039
21/02/17 01:34:40 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 17 (MapPartitionsRDD[68] at parquet at RFormula.scala:421) (first 15 tasks are for partitions Vector(0))
21/02/17 01:34:40 INFO TaskSchedulerImpl: Adding task set 17.0 with 1 tasks
21/02/17 01:34:40 INFO TaskSetManager: Starting task 0.0 in stage 17.0 (TID 17, localhost, executor driver, partition 0, PROCESS_LOCAL, 8164 bytes)
21/02/17 01:34:40 INFO Executor: Running task 0.0 in stage 17.0 (TID 17)
21/02/17 01:34:40 INFO Executor: Finished task 0.0 in stage 17.0 (TID 17). 1247 bytes result sent to driver
21/02/17 01:34:40 INFO TaskSetManager: Finished task 0.0 in stage 17.0 (TID 17) in 5 ms on localhost (executor driver) (1/1)
21/02/17 01:34:40 INFO TaskSchedulerImpl: Removed TaskSet 17.0, whose tasks have all completed, from pool 
21/02/17 01:34:40 INFO DAGScheduler: ShuffleMapStage 17 (parquet at RFormula.scala:421) finished in 0.011 s
21/02/17 01:34:40 INFO DAGScheduler: looking for newly runnable stages
21/02/17 01:34:40 INFO DAGScheduler: running: Set()
21/02/17 01:34:40 INFO DAGScheduler: waiting: Set(ResultStage 18)
21/02/17 01:34:40 INFO DAGScheduler: failed: Set()
21/02/17 01:34:40 INFO DAGScheduler: Submitting ResultStage 18 (ShuffledRowRDD[69] at parquet at RFormula.scala:421), which has no missing parents
21/02/17 01:34:40 INFO MemoryStore: Block broadcast_19 stored as values in memory (estimated size 151.0 KB, free 911.6 MB)
21/02/17 01:34:40 INFO MemoryStore: Block broadcast_19_piece0 stored as bytes in memory (estimated size 53.5 KB, free 911.6 MB)
21/02/17 01:34:40 INFO BlockManagerInfo: Added broadcast_19_piece0 in memory on localhost:34997 (size: 53.5 KB, free: 912.1 MB)
21/02/17 01:34:40 INFO SparkContext: Created broadcast 19 from broadcast at DAGScheduler.scala:1039
21/02/17 01:34:40 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 18 (ShuffledRowRDD[69] at parquet at RFormula.scala:421) (first 15 tasks are for partitions Vector(0))
21/02/17 01:34:40 INFO TaskSchedulerImpl: Adding task set 18.0 with 1 tasks
21/02/17 01:34:40 INFO TaskSetManager: Starting task 0.0 in stage 18.0 (TID 18, localhost, executor driver, partition 0, NODE_LOCAL, 7754 bytes)
21/02/17 01:34:40 INFO Executor: Running task 0.0 in stage 18.0 (TID 18)
21/02/17 01:34:40 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
21/02/17 01:34:40 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
21/02/17 01:34:40 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
21/02/17 01:34:40 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
21/02/17 01:34:40 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
21/02/17 01:34:40 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
21/02/17 01:34:40 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:
{
  "type" : "struct",
  "fields" : [ {
    "name" : "label",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "terms",
    "type" : {
      "type" : "array",
      "elementType" : {
        "type" : "array",
        "elementType" : "string",
        "containsNull" : true
      },
      "containsNull" : true
    },
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "hasIntercept",
    "type" : "boolean",
    "nullable" : false,
    "metadata" : { }
  } ]
}
and corresponding Parquet message type:
message spark_schema {
  optional binary label (UTF8);
  optional group terms (LIST) {
    repeated group list {
      optional group element (LIST) {
        repeated group list {
          optional binary element (UTF8);
        }
      }
    }
  }
  required boolean hasIntercept;
}

       
21/02/17 01:34:40 INFO CodecPool: Got brand-new compressor [.snappy]
21/02/17 01:34:40 INFO BlockManagerInfo: Removed broadcast_18_piece0 on localhost:34997 in memory (size: 2.9 KB, free: 912.1 MB)
21/02/17 01:34:40 INFO ContextCleaner: Cleaned accumulator 381
21/02/17 01:34:40 INFO ContextCleaner: Cleaned accumulator 387
21/02/17 01:34:40 INFO ContextCleaner: Cleaned accumulator 403
21/02/17 01:34:40 INFO ContextCleaner: Cleaned accumulator 446
21/02/17 01:34:40 INFO ContextCleaner: Cleaned accumulator 456
21/02/17 01:34:40 INFO ContextCleaner: Cleaned accumulator 343
21/02/17 01:34:40 INFO ContextCleaner: Cleaned accumulator 474
21/02/17 01:34:40 INFO ContextCleaner: Cleaned accumulator 259
21/02/17 01:34:40 INFO ContextCleaner: Cleaned accumulator 378
21/02/17 01:34:40 INFO ContextCleaner: Cleaned accumulator 294
21/02/17 01:34:40 INFO ContextCleaner: Cleaned accumulator 427
21/02/17 01:34:40 INFO ContextCleaner: Cleaned accumulator 454
21/02/17 01:34:40 INFO ContextCleaner: Cleaned accumulator 362
21/02/17 01:34:40 INFO ContextCleaner: Cleaned accumulator 253
21/02/17 01:34:40 INFO ContextCleaner: Cleaned accumulator 426
21/02/17 01:34:40 INFO ContextCleaner: Cleaned accumulator 261
21/02/17 01:34:40 INFO ContextCleaner: Cleaned accumulator 457
21/02/17 01:34:40 INFO ContextCleaner: Cleaned accumulator 476
21/02/17 01:34:40 INFO ContextCleaner: Cleaned accumulator 224
21/02/17 01:34:40 INFO ContextCleaner: Cleaned accumulator 296
21/02/17 01:34:40 INFO ContextCleaner: Cleaned accumulator 423
21/02/17 01:34:40 INFO ContextCleaner: Cleaned accumulator 270
21/02/17 01:34:40 INFO ContextCleaner: Cleaned accumulator 260
21/02/17 01:34:40 INFO ContextCleaner: Cleaned accumulator 289
21/02/17 01:34:40 INFO ContextCleaner: Cleaned accumulator 363
21/02/17 01:34:40 INFO ContextCleaner: Cleaned accumulator 360
21/02/17 01:34:40 INFO ContextCleaner: Cleaned accumulator 234
21/02/17 01:34:40 INFO ContextCleaner: Cleaned accumulator 443
21/02/17 01:34:40 INFO ContextCleaner: Cleaned accumulator 349
21/02/17 01:34:40 INFO ContextCleaner: Cleaned accumulator 458
21/02/17 01:34:40 INFO ContextCleaner: Cleaned shuffle 2
21/02/17 01:34:40 INFO ContextCleaner: Cleaned accumulator 220
21/02/17 01:34:40 INFO ContextCleaner: Cleaned accumulator 441
21/02/17 01:34:40 INFO ContextCleaner: Cleaned accumulator 449
21/02/17 01:34:40 INFO ContextCleaner: Cleaned accumulator 469
21/02/17 01:34:40 INFO ContextCleaner: Cleaned accumulator 264
21/02/17 01:34:40 INFO ContextCleaner: Cleaned accumulator 351
21/02/17 01:34:40 INFO ContextCleaner: Cleaned accumulator 218
21/02/17 01:34:40 INFO ContextCleaner: Cleaned accumulator 281
21/02/17 01:34:40 INFO ContextCleaner: Cleaned accumulator 263
21/02/17 01:34:40 INFO ContextCleaner: Cleaned accumulator 492
21/02/17 01:34:40 INFO ContextCleaner: Cleaned accumulator 305
21/02/17 01:34:40 INFO ContextCleaner: Cleaned accumulator 370
21/02/17 01:34:40 INFO ContextCleaner: Cleaned accumulator 335
21/02/17 01:34:40 INFO ContextCleaner: Cleaned accumulator 501
21/02/17 01:34:40 INFO ContextCleaner: Cleaned accumulator 493
21/02/17 01:34:40 INFO ContextCleaner: Cleaned accumulator 452
21/02/17 01:34:40 INFO ContextCleaner: Cleaned accumulator 273
21/02/17 01:34:40 INFO ContextCleaner: Cleaned accumulator 275
21/02/17 01:34:40 INFO BlockManagerInfo: Removed broadcast_16_piece0 on localhost:34997 in memory (size: 25.3 KB, free: 912.1 MB)
21/02/17 01:34:40 INFO ContextCleaner: Cleaned accumulator 280
21/02/17 01:34:40 INFO ContextCleaner: Cleaned accumulator 415
21/02/17 01:34:40 INFO BlockManagerInfo: Removed broadcast_7_piece0 on localhost:34997 in memory (size: 14.2 KB, free: 912.1 MB)
21/02/17 01:34:40 INFO ContextCleaner: Cleaned accumulator 350
21/02/17 01:34:40 INFO ContextCleaner: Cleaned accumulator 276
21/02/17 01:34:40 INFO ContextCleaner: Cleaned accumulator 322
21/02/17 01:34:40 INFO ContextCleaner: Cleaned accumulator 498
21/02/17 01:34:40 INFO ContextCleaner: Cleaned accumulator 271
21/02/17 01:34:40 INFO ContextCleaner: Cleaned accumulator 232
21/02/17 01:34:40 INFO ContextCleaner: Cleaned accumulator 384
21/02/17 01:34:40 INFO ContextCleaner: Cleaned accumulator 371
21/02/17 01:34:40 INFO ContextCleaner: Cleaned accumulator 499
21/02/17 01:34:40 INFO ContextCleaner: Cleaned accumulator 358
21/02/17 01:34:40 INFO ContextCleaner: Cleaned accumulator 243
21/02/17 01:34:40 INFO ContextCleaner: Cleaned accumulator 303
21/02/17 01:34:40 INFO ContextCleaner: Cleaned accumulator 331
21/02/17 01:34:40 INFO ContextCleaner: Cleaned accumulator 413
21/02/17 01:34:40 INFO BlockManagerInfo: Removed broadcast_10_piece0 on localhost:34997 in memory (size: 3.2 KB, free: 912.1 MB)
21/02/17 01:34:40 INFO BlockManagerInfo: Removed broadcast_14_piece0 on localhost:34997 in memory (size: 25.8 KB, free: 912.2 MB)
21/02/17 01:34:40 INFO ContextCleaner: Cleaned accumulator 241
21/02/17 01:34:40 INFO ContextCleaner: Cleaned accumulator 298
21/02/17 01:34:40 INFO ContextCleaner: Cleaned accumulator 477
21/02/17 01:34:40 INFO ContextCleaner: Cleaned accumulator 246
21/02/17 01:34:40 INFO ContextCleaner: Cleaned accumulator 428
21/02/17 01:34:40 INFO ContextCleaner: Cleaned accumulator 346
21/02/17 01:34:40 INFO ContextCleaner: Cleaned accumulator 245
21/02/17 01:34:40 INFO ContextCleaner: Cleaned accumulator 430
21/02/17 01:34:40 INFO ContextCleaner: Cleaned accumulator 269
21/02/17 01:34:40 INFO ContextCleaner: Cleaned accumulator 485
21/02/17 01:34:40 INFO ContextCleaner: Cleaned accumulator 286
21/02/17 01:34:40 INFO ContextCleaner: Cleaned accumulator 252
21/02/17 01:34:40 INFO ContextCleaner: Cleaned accumulator 468
21/02/17 01:34:40 INFO ContextCleaner: Cleaned accumulator 216
21/02/17 01:34:40 INFO ContextCleaner: Cleaned accumulator 268
21/02/17 01:34:40 INFO ContextCleaner: Cleaned accumulator 374
21/02/17 01:34:40 INFO ContextCleaner: Cleaned accumulator 488
21/02/17 01:34:40 INFO ContextCleaner: Cleaned accumulator 356
21/02/17 01:34:40 INFO ContextCleaner: Cleaned accumulator 399
21/02/17 01:34:40 INFO ContextCleaner: Cleaned accumulator 314
21/02/17 01:34:40 INFO ContextCleaner: Cleaned accumulator 437
21/02/17 01:34:40 INFO ContextCleaner: Cleaned accumulator 383
21/02/17 01:34:40 INFO ContextCleaner: Cleaned accumulator 433
21/02/17 01:34:40 INFO ContextCleaner: Cleaned accumulator 453
21/02/17 01:34:40 INFO ContextCleaner: Cleaned accumulator 393
21/02/17 01:34:40 INFO ContextCleaner: Cleaned accumulator 345
21/02/17 01:34:40 INFO ContextCleaner: Cleaned accumulator 354
21/02/17 01:34:40 INFO ContextCleaner: Cleaned accumulator 254
21/02/17 01:34:40 INFO ContextCleaner: Cleaned accumulator 490
21/02/17 01:34:40 INFO ContextCleaner: Cleaned accumulator 223
21/02/17 01:34:40 INFO ContextCleaner: Cleaned accumulator 340
21/02/17 01:34:40 INFO ContextCleaner: Cleaned accumulator 311
21/02/17 01:34:40 INFO ContextCleaner: Cleaned accumulator 424
21/02/17 01:34:40 INFO ContextCleaner: Cleaned accumulator 376
21/02/17 01:34:40 INFO ContextCleaner: Cleaned accumulator 231
21/02/17 01:34:40 INFO ContextCleaner: Cleaned accumulator 283
21/02/17 01:34:40 INFO ContextCleaner: Cleaned accumulator 338
21/02/17 01:34:40 INFO ContextCleaner: Cleaned accumulator 233
21/02/17 01:34:40 INFO ContextCleaner: Cleaned accumulator 248
21/02/17 01:34:40 INFO ContextCleaner: Cleaned accumulator 325
21/02/17 01:34:40 INFO ContextCleaner: Cleaned accumulator 461
21/02/17 01:34:40 INFO ContextCleaner: Cleaned accumulator 319
21/02/17 01:34:40 INFO ContextCleaner: Cleaned accumulator 255
21/02/17 01:34:40 INFO ContextCleaner: Cleaned accumulator 323
21/02/17 01:34:40 INFO BlockManager: Removing RDD 35
21/02/17 01:34:40 INFO ContextCleaner: Cleaned RDD 35
21/02/17 01:34:40 INFO ContextCleaner: Cleaned accumulator 418
21/02/17 01:34:40 INFO ContextCleaner: Cleaned accumulator 429
21/02/17 01:34:40 INFO ContextCleaner: Cleaned accumulator 444
21/02/17 01:34:40 INFO ContextCleaner: Cleaned accumulator 230
21/02/17 01:34:40 INFO ContextCleaner: Cleaned accumulator 321
21/02/17 01:34:40 INFO ContextCleaner: Cleaned accumulator 300
21/02/17 01:34:40 INFO ContextCleaner: Cleaned accumulator 215
21/02/17 01:34:40 INFO ContextCleaner: Cleaned accumulator 455
21/02/17 01:34:40 INFO ContextCleaner: Cleaned accumulator 304
21/02/17 01:34:40 INFO ContextCleaner: Cleaned accumulator 480
21/02/17 01:34:40 INFO ContextCleaner: Cleaned accumulator 290
21/02/17 01:34:40 INFO ContextCleaner: Cleaned accumulator 307
21/02/17 01:34:40 INFO ContextCleaner: Cleaned accumulator 372
21/02/17 01:34:40 INFO ContextCleaner: Cleaned accumulator 385
21/02/17 01:34:40 INFO ContextCleaner: Cleaned accumulator 308
21/02/17 01:34:40 INFO ContextCleaner: Cleaned accumulator 212
21/02/17 01:34:40 INFO ContextCleaner: Cleaned accumulator 411
21/02/17 01:34:40 INFO ContextCleaner: Cleaned accumulator 470
21/02/17 01:34:40 INFO BlockManagerInfo: Removed broadcast_11_piece0 on localhost:34997 in memory (size: 4.5 KB, free: 912.2 MB)
21/02/17 01:34:40 INFO ContextCleaner: Cleaned accumulator 434
21/02/17 01:34:40 INFO ContextCleaner: Cleaned accumulator 279
21/02/17 01:34:40 INFO ContextCleaner: Cleaned accumulator 414
21/02/17 01:34:40 INFO ContextCleaner: Cleaned accumulator 332
21/02/17 01:34:40 INFO BlockManagerInfo: Removed broadcast_15_piece0 on localhost:34997 in memory (size: 3.8 KB, free: 912.2 MB)
21/02/17 01:34:40 INFO ContextCleaner: Cleaned accumulator 213
21/02/17 01:34:40 INFO ContextCleaner: Cleaned accumulator 310
21/02/17 01:34:40 INFO ContextCleaner: Cleaned accumulator 422
21/02/17 01:34:40 INFO ContextCleaner: Cleaned accumulator 235
21/02/17 01:34:40 INFO BlockManagerInfo: Removed broadcast_8_piece0 on localhost:34997 in memory (size: 14.3 KB, free: 912.2 MB)
21/02/17 01:34:40 INFO ContextCleaner: Cleaned accumulator 244
21/02/17 01:34:40 INFO ContextCleaner: Cleaned accumulator 334
21/02/17 01:34:40 INFO ContextCleaner: Cleaned accumulator 397
21/02/17 01:34:40 INFO BlockManagerInfo: Removed broadcast_17_piece0 on localhost:34997 in memory (size: 25.4 KB, free: 912.2 MB)
21/02/17 01:34:40 INFO ContextCleaner: Cleaned accumulator 394
21/02/17 01:34:40 INFO ContextCleaner: Cleaned accumulator 479
21/02/17 01:34:40 INFO ContextCleaner: Cleaned accumulator 419
21/02/17 01:34:40 INFO ContextCleaner: Cleaned accumulator 282
21/02/17 01:34:40 INFO ContextCleaner: Cleaned accumulator 472
21/02/17 01:34:40 INFO ContextCleaner: Cleaned shuffle 3
21/02/17 01:34:40 INFO ContextCleaner: Cleaned accumulator 217
21/02/17 01:34:40 INFO BlockManagerInfo: Removed broadcast_13_piece0 on localhost:34997 in memory (size: 25.3 KB, free: 912.2 MB)
21/02/17 01:34:40 INFO ContextCleaner: Cleaned accumulator 438
21/02/17 01:34:40 INFO ContextCleaner: Cleaned accumulator 451
21/02/17 01:34:40 INFO ContextCleaner: Cleaned accumulator 482
21/02/17 01:34:40 INFO ContextCleaner: Cleaned accumulator 400
21/02/17 01:34:40 INFO ContextCleaner: Cleaned accumulator 339
21/02/17 01:34:40 INFO ContextCleaner: Cleaned accumulator 257
21/02/17 01:34:40 INFO ContextCleaner: Cleaned accumulator 357
21/02/17 01:34:40 INFO ContextCleaner: Cleaned accumulator 432
21/02/17 01:34:40 INFO ContextCleaner: Cleaned accumulator 439
21/02/17 01:34:40 INFO ContextCleaner: Cleaned accumulator 421
21/02/17 01:34:40 INFO ContextCleaner: Cleaned accumulator 326
21/02/17 01:34:40 INFO ContextCleaner: Cleaned accumulator 329
21/02/17 01:34:40 INFO ContextCleaner: Cleaned accumulator 344
21/02/17 01:34:40 INFO ContextCleaner: Cleaned accumulator 287
21/02/17 01:34:40 INFO ContextCleaner: Cleaned accumulator 386
21/02/17 01:34:40 INFO ContextCleaner: Cleaned accumulator 214
21/02/17 01:34:40 INFO ContextCleaner: Cleaned accumulator 406
21/02/17 01:34:40 INFO ContextCleaner: Cleaned accumulator 473
21/02/17 01:34:40 INFO ContextCleaner: Cleaned accumulator 342
21/02/17 01:34:40 INFO ContextCleaner: Cleaned accumulator 313
21/02/17 01:34:40 INFO ContextCleaner: Cleaned accumulator 301
21/02/17 01:34:40 INFO ContextCleaner: Cleaned accumulator 410
21/02/17 01:34:40 INFO ContextCleaner: Cleaned accumulator 312
21/02/17 01:34:40 INFO ContextCleaner: Cleaned accumulator 225
21/02/17 01:34:40 INFO ContextCleaner: Cleaned accumulator 239
21/02/17 01:34:40 INFO ContextCleaner: Cleaned accumulator 425
21/02/17 01:34:40 INFO ContextCleaner: Cleaned accumulator 316
21/02/17 01:34:40 INFO ContextCleaner: Cleaned accumulator 364
21/02/17 01:34:40 INFO ContextCleaner: Cleaned accumulator 436
21/02/17 01:34:40 INFO ContextCleaner: Cleaned accumulator 219
21/02/17 01:34:40 INFO ContextCleaner: Cleaned accumulator 299
21/02/17 01:34:40 INFO ContextCleaner: Cleaned accumulator 471
21/02/17 01:34:40 INFO ContextCleaner: Cleaned accumulator 440
21/02/17 01:34:40 INFO ContextCleaner: Cleaned accumulator 317
21/02/17 01:34:40 INFO ContextCleaner: Cleaned accumulator 320
21/02/17 01:34:40 INFO ContextCleaner: Cleaned accumulator 475
21/02/17 01:34:40 INFO ContextCleaner: Cleaned accumulator 395
21/02/17 01:34:40 INFO ContextCleaner: Cleaned accumulator 309
21/02/17 01:34:40 INFO ContextCleaner: Cleaned accumulator 481
21/02/17 01:34:40 INFO ContextCleaner: Cleaned accumulator 447
21/02/17 01:34:40 INFO ContextCleaner: Cleaned accumulator 404
21/02/17 01:34:40 INFO ContextCleaner: Cleaned accumulator 274
21/02/17 01:34:40 INFO ContextCleaner: Cleaned accumulator 448
21/02/17 01:34:40 INFO ContextCleaner: Cleaned accumulator 459
21/02/17 01:34:40 INFO ContextCleaner: Cleaned accumulator 494
21/02/17 01:34:40 INFO ContextCleaner: Cleaned accumulator 361
21/02/17 01:34:40 INFO ContextCleaner: Cleaned accumulator 398
21/02/17 01:34:40 INFO ContextCleaner: Cleaned accumulator 229
21/02/17 01:34:40 INFO ContextCleaner: Cleaned accumulator 377
21/02/17 01:34:40 INFO ContextCleaner: Cleaned accumulator 465
21/02/17 01:34:40 INFO ContextCleaner: Cleaned accumulator 497
21/02/17 01:34:40 INFO ContextCleaner: Cleaned accumulator 359
21/02/17 01:34:40 INFO ContextCleaner: Cleaned accumulator 487
21/02/17 01:34:40 INFO ContextCleaner: Cleaned accumulator 366
21/02/17 01:34:40 INFO ContextCleaner: Cleaned accumulator 402
21/02/17 01:34:40 INFO ContextCleaner: Cleaned accumulator 407
21/02/17 01:34:40 INFO ContextCleaner: Cleaned accumulator 496
21/02/17 01:34:40 INFO ContextCleaner: Cleaned accumulator 379
21/02/17 01:34:40 INFO ContextCleaner: Cleaned accumulator 391
21/02/17 01:34:40 INFO ContextCleaner: Cleaned accumulator 292
21/02/17 01:34:40 INFO ContextCleaner: Cleaned accumulator 466
21/02/17 01:34:40 INFO ContextCleaner: Cleaned accumulator 409
21/02/17 01:34:40 INFO ContextCleaner: Cleaned accumulator 278
21/02/17 01:34:40 INFO BlockManagerInfo: Removed broadcast_12_piece0 on localhost:34997 in memory (size: 3.8 KB, free: 912.2 MB)
21/02/17 01:34:40 INFO ContextCleaner: Cleaned accumulator 392
21/02/17 01:34:40 INFO ContextCleaner: Cleaned accumulator 291
21/02/17 01:34:40 INFO ContextCleaner: Cleaned accumulator 227
21/02/17 01:34:40 INFO ContextCleaner: Cleaned accumulator 341
21/02/17 01:34:40 INFO ContextCleaner: Cleaned accumulator 417
21/02/17 01:34:40 INFO ContextCleaner: Cleaned accumulator 262
21/02/17 01:34:40 INFO ContextCleaner: Cleaned accumulator 353
21/02/17 01:34:40 INFO ContextCleaner: Cleaned accumulator 489
21/02/17 01:34:40 INFO ContextCleaner: Cleaned accumulator 295
21/02/17 01:34:40 INFO ContextCleaner: Cleaned accumulator 495
21/02/17 01:34:40 INFO ContextCleaner: Cleaned accumulator 502
21/02/17 01:34:40 INFO ContextCleaner: Cleaned accumulator 483
21/02/17 01:34:40 INFO ContextCleaner: Cleaned accumulator 375
21/02/17 01:34:40 INFO ContextCleaner: Cleaned accumulator 388
21/02/17 01:34:40 INFO ContextCleaner: Cleaned accumulator 324
21/02/17 01:34:40 INFO ContextCleaner: Cleaned accumulator 367
21/02/17 01:34:40 INFO ContextCleaner: Cleaned accumulator 347
21/02/17 01:34:40 INFO ContextCleaner: Cleaned accumulator 352
21/02/17 01:34:40 INFO ContextCleaner: Cleaned accumulator 382
21/02/17 01:34:40 INFO ContextCleaner: Cleaned accumulator 297
21/02/17 01:34:40 INFO ContextCleaner: Cleaned accumulator 258
21/02/17 01:34:40 INFO ContextCleaner: Cleaned accumulator 380
21/02/17 01:34:40 INFO ContextCleaner: Cleaned accumulator 228
21/02/17 01:34:40 INFO ContextCleaner: Cleaned accumulator 250
21/02/17 01:34:40 INFO ContextCleaner: Cleaned accumulator 463
21/02/17 01:34:40 INFO ContextCleaner: Cleaned accumulator 369
21/02/17 01:34:40 INFO ContextCleaner: Cleaned accumulator 373
21/02/17 01:34:40 INFO ContextCleaner: Cleaned accumulator 249
21/02/17 01:34:40 INFO ContextCleaner: Cleaned accumulator 238
21/02/17 01:34:40 INFO ContextCleaner: Cleaned accumulator 236
21/02/17 01:34:40 INFO ContextCleaner: Cleaned accumulator 408
21/02/17 01:34:40 INFO ContextCleaner: Cleaned accumulator 284
21/02/17 01:34:40 INFO ContextCleaner: Cleaned accumulator 222
21/02/17 01:34:40 INFO ContextCleaner: Cleaned accumulator 500
21/02/17 01:34:40 INFO ContextCleaner: Cleaned accumulator 450
21/02/17 01:34:40 INFO ContextCleaner: Cleaned accumulator 242
21/02/17 01:34:40 INFO ContextCleaner: Cleaned accumulator 285
21/02/17 01:34:40 INFO ContextCleaner: Cleaned accumulator 293
21/02/17 01:34:40 INFO ContextCleaner: Cleaned accumulator 412
21/02/17 01:34:40 INFO ContextCleaner: Cleaned accumulator 435
21/02/17 01:34:40 INFO ContextCleaner: Cleaned accumulator 327
21/02/17 01:34:40 INFO ContextCleaner: Cleaned accumulator 396
21/02/17 01:34:40 INFO ContextCleaner: Cleaned accumulator 272
21/02/17 01:34:40 INFO ContextCleaner: Cleaned accumulator 416
21/02/17 01:34:40 INFO ContextCleaner: Cleaned accumulator 355
21/02/17 01:34:40 INFO ContextCleaner: Cleaned accumulator 491
21/02/17 01:34:40 INFO ContextCleaner: Cleaned accumulator 348
21/02/17 01:34:40 INFO ContextCleaner: Cleaned accumulator 240
21/02/17 01:34:40 INFO ContextCleaner: Cleaned accumulator 484
21/02/17 01:34:40 INFO ContextCleaner: Cleaned accumulator 221
21/02/17 01:34:40 INFO ContextCleaner: Cleaned accumulator 390
21/02/17 01:34:40 INFO ContextCleaner: Cleaned accumulator 306
21/02/17 01:34:40 INFO ContextCleaner: Cleaned accumulator 277
21/02/17 01:34:40 INFO ContextCleaner: Cleaned accumulator 330
21/02/17 01:34:40 INFO ContextCleaner: Cleaned accumulator 302
21/02/17 01:34:40 INFO ContextCleaner: Cleaned accumulator 389
21/02/17 01:34:40 INFO ContextCleaner: Cleaned accumulator 251
21/02/17 01:34:40 INFO ContextCleaner: Cleaned accumulator 467
21/02/17 01:34:40 INFO ContextCleaner: Cleaned accumulator 478
21/02/17 01:34:40 INFO ContextCleaner: Cleaned accumulator 247
21/02/17 01:34:40 INFO ContextCleaner: Cleaned accumulator 333
21/02/17 01:34:40 INFO ContextCleaner: Cleaned accumulator 315
21/02/17 01:34:40 INFO ContextCleaner: Cleaned accumulator 401
21/02/17 01:34:40 INFO ContextCleaner: Cleaned accumulator 337
21/02/17 01:34:40 INFO ContextCleaner: Cleaned accumulator 460
21/02/17 01:34:40 INFO ContextCleaner: Cleaned accumulator 486
21/02/17 01:34:40 INFO ContextCleaner: Cleaned accumulator 365
21/02/17 01:34:40 INFO ContextCleaner: Cleaned accumulator 445
21/02/17 01:34:40 INFO ContextCleaner: Cleaned accumulator 318
21/02/17 01:34:40 INFO ContextCleaner: Cleaned accumulator 420
21/02/17 01:34:40 INFO ContextCleaner: Cleaned accumulator 237
21/02/17 01:34:40 INFO ContextCleaner: Cleaned accumulator 442
21/02/17 01:34:40 INFO ContextCleaner: Cleaned accumulator 226
21/02/17 01:34:40 INFO ContextCleaner: Cleaned accumulator 328
21/02/17 01:34:40 INFO ContextCleaner: Cleaned accumulator 462
21/02/17 01:34:40 INFO ContextCleaner: Cleaned accumulator 464
21/02/17 01:34:40 INFO ContextCleaner: Cleaned accumulator 288
21/02/17 01:34:40 INFO ContextCleaner: Cleaned accumulator 368
21/02/17 01:34:40 INFO ContextCleaner: Cleaned accumulator 405
21/02/17 01:34:40 INFO ContextCleaner: Cleaned accumulator 431
21/02/17 01:34:40 INFO ContextCleaner: Cleaned accumulator 336
21/02/17 01:34:40 INFO ContextCleaner: Cleaned accumulator 256
21/02/17 01:34:40 INFO FileOutputCommitter: Saved output of task 'attempt_20210217013440_0018_m_000000_0' to file:/tmp/RtmpqE8K95/file2236138cd1f15/stages/0_r_formula__9b9b20bf_34e1_4305_9c6b_8f400f69191b/data/_temporary/0/task_20210217013440_0018_m_000000
21/02/17 01:34:40 INFO SparkHadoopMapRedUtil: attempt_20210217013440_0018_m_000000_0: Committed
21/02/17 01:34:40 INFO Executor: Finished task 0.0 in stage 18.0 (TID 18). 2394 bytes result sent to driver
21/02/17 01:34:40 INFO TaskSetManager: Finished task 0.0 in stage 18.0 (TID 18) in 264 ms on localhost (executor driver) (1/1)
21/02/17 01:34:40 INFO TaskSchedulerImpl: Removed TaskSet 18.0, whose tasks have all completed, from pool 
21/02/17 01:34:40 INFO DAGScheduler: ResultStage 18 (parquet at RFormula.scala:421) finished in 0.285 s
21/02/17 01:34:40 INFO DAGScheduler: Job 13 finished: parquet at RFormula.scala:421, took 0.299212 s
21/02/17 01:34:40 INFO FileFormatWriter: Job null committed.
21/02/17 01:34:40 INFO FileFormatWriter: Finished processing stats for job null.
21/02/17 01:34:40 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
21/02/17 01:34:40 INFO SparkContext: Starting job: runJob at SparkHadoopWriter.scala:78
21/02/17 01:34:40 INFO DAGScheduler: Got job 14 (runJob at SparkHadoopWriter.scala:78) with 1 output partitions
21/02/17 01:34:40 INFO DAGScheduler: Final stage: ResultStage 19 (runJob at SparkHadoopWriter.scala:78)
21/02/17 01:34:40 INFO DAGScheduler: Parents of final stage: List()
21/02/17 01:34:40 INFO DAGScheduler: Missing parents: List()
21/02/17 01:34:40 INFO DAGScheduler: Submitting ResultStage 19 (MapPartitionsRDD[72] at saveAsTextFile at ReadWrite.scala:283), which has no missing parents
21/02/17 01:34:40 INFO MemoryStore: Block broadcast_20 stored as values in memory (estimated size 71.1 KB, free 912.0 MB)
21/02/17 01:34:40 INFO MemoryStore: Block broadcast_20_piece0 stored as bytes in memory (estimated size 25.5 KB, free 912.0 MB)
21/02/17 01:34:40 INFO BlockManagerInfo: Added broadcast_20_piece0 in memory on localhost:34997 (size: 25.5 KB, free: 912.2 MB)
21/02/17 01:34:40 INFO SparkContext: Created broadcast 20 from broadcast at DAGScheduler.scala:1039
21/02/17 01:34:40 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 19 (MapPartitionsRDD[72] at saveAsTextFile at ReadWrite.scala:283) (first 15 tasks are for partitions Vector(0))
21/02/17 01:34:40 INFO TaskSchedulerImpl: Adding task set 19.0 with 1 tasks
21/02/17 01:34:40 INFO TaskSetManager: Starting task 0.0 in stage 19.0 (TID 19, localhost, executor driver, partition 0, PROCESS_LOCAL, 8147 bytes)
21/02/17 01:34:40 INFO Executor: Running task 0.0 in stage 19.0 (TID 19)
21/02/17 01:34:40 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
21/02/17 01:34:40 INFO FileOutputCommitter: Saved output of task 'attempt_20210217013440_0072_m_000000_0' to file:/tmp/RtmpqE8K95/file2236138cd1f15/stages/0_r_formula__9b9b20bf_34e1_4305_9c6b_8f400f69191b/pipelineModel/metadata/_temporary/0/task_20210217013440_0072_m_000000
21/02/17 01:34:40 INFO SparkHadoopMapRedUtil: attempt_20210217013440_0072_m_000000_0: Committed
21/02/17 01:34:40 INFO Executor: Finished task 0.0 in stage 19.0 (TID 19). 1029 bytes result sent to driver
21/02/17 01:34:40 INFO TaskSetManager: Finished task 0.0 in stage 19.0 (TID 19) in 16 ms on localhost (executor driver) (1/1)
21/02/17 01:34:40 INFO TaskSchedulerImpl: Removed TaskSet 19.0, whose tasks have all completed, from pool 
21/02/17 01:34:40 INFO DAGScheduler: ResultStage 19 (runJob at SparkHadoopWriter.scala:78) finished in 0.033 s
21/02/17 01:34:40 INFO DAGScheduler: Job 14 finished: runJob at SparkHadoopWriter.scala:78, took 0.035475 s
21/02/17 01:34:40 INFO SparkHadoopWriter: Job job_20210217013440_0072 committed.
21/02/17 01:34:40 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
21/02/17 01:34:40 INFO SparkContext: Starting job: runJob at SparkHadoopWriter.scala:78
21/02/17 01:34:40 INFO DAGScheduler: Got job 15 (runJob at SparkHadoopWriter.scala:78) with 1 output partitions
21/02/17 01:34:40 INFO DAGScheduler: Final stage: ResultStage 20 (runJob at SparkHadoopWriter.scala:78)
21/02/17 01:34:40 INFO DAGScheduler: Parents of final stage: List()
21/02/17 01:34:40 INFO DAGScheduler: Missing parents: List()
21/02/17 01:34:40 INFO DAGScheduler: Submitting ResultStage 20 (MapPartitionsRDD[74] at saveAsTextFile at ReadWrite.scala:283), which has no missing parents
21/02/17 01:34:40 INFO MemoryStore: Block broadcast_21 stored as values in memory (estimated size 71.3 KB, free 911.9 MB)
21/02/17 01:34:40 INFO MemoryStore: Block broadcast_21_piece0 stored as bytes in memory (estimated size 25.5 KB, free 911.9 MB)
21/02/17 01:34:40 INFO BlockManagerInfo: Added broadcast_21_piece0 in memory on localhost:34997 (size: 25.5 KB, free: 912.2 MB)
21/02/17 01:34:40 INFO SparkContext: Created broadcast 21 from broadcast at DAGScheduler.scala:1039
21/02/17 01:34:40 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 20 (MapPartitionsRDD[74] at saveAsTextFile at ReadWrite.scala:283) (first 15 tasks are for partitions Vector(0))
21/02/17 01:34:40 INFO TaskSchedulerImpl: Adding task set 20.0 with 1 tasks
21/02/17 01:34:40 INFO TaskSetManager: Starting task 0.0 in stage 20.0 (TID 20, localhost, executor driver, partition 0, PROCESS_LOCAL, 8097 bytes)
21/02/17 01:34:40 INFO Executor: Running task 0.0 in stage 20.0 (TID 20)
21/02/17 01:34:40 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
21/02/17 01:34:40 INFO FileOutputCommitter: Saved output of task 'attempt_20210217013440_0074_m_000000_0' to file:/tmp/RtmpqE8K95/file2236138cd1f15/stages/0_r_formula__9b9b20bf_34e1_4305_9c6b_8f400f69191b/pipelineModel/stages/0_r_formula__9b9b20bf_34e1_4305_9c6b_8f400f69191b/metadata/_temporary/0/task_20210217013440_0074_m_000000
21/02/17 01:34:40 INFO SparkHadoopMapRedUtil: attempt_20210217013440_0074_m_000000_0: Committed
21/02/17 01:34:40 INFO Executor: Finished task 0.0 in stage 20.0 (TID 20). 1029 bytes result sent to driver
21/02/17 01:34:40 INFO TaskSetManager: Finished task 0.0 in stage 20.0 (TID 20) in 13 ms on localhost (executor driver) (1/1)
21/02/17 01:34:40 INFO TaskSchedulerImpl: Removed TaskSet 20.0, whose tasks have all completed, from pool 
21/02/17 01:34:40 INFO DAGScheduler: ResultStage 20 (runJob at SparkHadoopWriter.scala:78) finished in 0.023 s
21/02/17 01:34:40 INFO DAGScheduler: Job 15 finished: runJob at SparkHadoopWriter.scala:78, took 0.023899 s
21/02/17 01:34:40 INFO SparkHadoopWriter: Job job_20210217013440_0074 committed.
21/02/17 01:34:40 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
21/02/17 01:34:40 INFO SparkContext: Starting job: runJob at SparkHadoopWriter.scala:78
21/02/17 01:34:40 INFO DAGScheduler: Got job 16 (runJob at SparkHadoopWriter.scala:78) with 1 output partitions
21/02/17 01:34:40 INFO DAGScheduler: Final stage: ResultStage 21 (runJob at SparkHadoopWriter.scala:78)
21/02/17 01:34:40 INFO DAGScheduler: Parents of final stage: List()
21/02/17 01:34:40 INFO DAGScheduler: Missing parents: List()
21/02/17 01:34:40 INFO DAGScheduler: Submitting ResultStage 21 (MapPartitionsRDD[76] at saveAsTextFile at ReadWrite.scala:283), which has no missing parents
21/02/17 01:34:40 INFO MemoryStore: Block broadcast_22 stored as values in memory (estimated size 71.2 KB, free 911.8 MB)
21/02/17 01:34:40 INFO MemoryStore: Block broadcast_22_piece0 stored as bytes in memory (estimated size 25.6 KB, free 911.8 MB)
21/02/17 01:34:40 INFO BlockManagerInfo: Added broadcast_22_piece0 in memory on localhost:34997 (size: 25.6 KB, free: 912.2 MB)
21/02/17 01:34:40 INFO SparkContext: Created broadcast 22 from broadcast at DAGScheduler.scala:1039
21/02/17 01:34:41 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 21 (MapPartitionsRDD[76] at saveAsTextFile at ReadWrite.scala:283) (first 15 tasks are for partitions Vector(0))
21/02/17 01:34:41 INFO TaskSchedulerImpl: Adding task set 21.0 with 1 tasks
21/02/17 01:34:41 INFO TaskSetManager: Starting task 0.0 in stage 21.0 (TID 21, localhost, executor driver, partition 0, PROCESS_LOCAL, 8024 bytes)
21/02/17 01:34:41 INFO Executor: Running task 0.0 in stage 21.0 (TID 21)
21/02/17 01:34:41 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
21/02/17 01:34:41 INFO FileOutputCommitter: Saved output of task 'attempt_20210217013440_0076_m_000000_0' to file:/tmp/RtmpqE8K95/file2236138cd1f15/stages/0_r_formula__9b9b20bf_34e1_4305_9c6b_8f400f69191b/pipelineModel/stages/1_vectorAttrRewriter_cbe2c7c677da/metadata/_temporary/0/task_20210217013440_0076_m_000000
21/02/17 01:34:41 INFO SparkHadoopMapRedUtil: attempt_20210217013440_0076_m_000000_0: Committed
21/02/17 01:34:41 INFO Executor: Finished task 0.0 in stage 21.0 (TID 21). 1029 bytes result sent to driver
21/02/17 01:34:41 INFO TaskSetManager: Finished task 0.0 in stage 21.0 (TID 21) in 12 ms on localhost (executor driver) (1/1)
21/02/17 01:34:41 INFO TaskSchedulerImpl: Removed TaskSet 21.0, whose tasks have all completed, from pool 
21/02/17 01:34:41 INFO DAGScheduler: ResultStage 21 (runJob at SparkHadoopWriter.scala:78) finished in 0.025 s
21/02/17 01:34:41 INFO DAGScheduler: Job 16 finished: runJob at SparkHadoopWriter.scala:78, took 0.026447 s
21/02/17 01:34:41 INFO SparkHadoopWriter: Job job_20210217013440_0076 committed.
21/02/17 01:34:41 INFO ParquetFileFormat: Using default output committer for Parquet: org.apache.parquet.hadoop.ParquetOutputCommitter
21/02/17 01:34:41 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
21/02/17 01:34:41 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
21/02/17 01:34:41 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
21/02/17 01:34:41 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
21/02/17 01:34:41 INFO CodeGenerator: Code generated in 8.287681 ms
21/02/17 01:34:41 INFO SparkContext: Starting job: parquet at RFormula.scala:586
21/02/17 01:34:41 INFO DAGScheduler: Registering RDD 79 (parquet at RFormula.scala:586)
21/02/17 01:34:41 INFO DAGScheduler: Got job 17 (parquet at RFormula.scala:586) with 1 output partitions
21/02/17 01:34:41 INFO DAGScheduler: Final stage: ResultStage 23 (parquet at RFormula.scala:586)
21/02/17 01:34:41 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 22)
21/02/17 01:34:41 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 22)
21/02/17 01:34:41 INFO DAGScheduler: Submitting ShuffleMapStage 22 (MapPartitionsRDD[79] at parquet at RFormula.scala:586), which has no missing parents
21/02/17 01:34:41 INFO MemoryStore: Block broadcast_23 stored as values in memory (estimated size 4.8 KB, free 911.8 MB)
21/02/17 01:34:41 INFO MemoryStore: Block broadcast_23_piece0 stored as bytes in memory (estimated size 2.8 KB, free 911.8 MB)
21/02/17 01:34:41 INFO BlockManagerInfo: Added broadcast_23_piece0 in memory on localhost:34997 (size: 2.8 KB, free: 912.2 MB)
21/02/17 01:34:41 INFO SparkContext: Created broadcast 23 from broadcast at DAGScheduler.scala:1039
21/02/17 01:34:41 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 22 (MapPartitionsRDD[79] at parquet at RFormula.scala:586) (first 15 tasks are for partitions Vector(0))
21/02/17 01:34:41 INFO TaskSchedulerImpl: Adding task set 22.0 with 1 tasks
21/02/17 01:34:41 INFO TaskSetManager: Starting task 0.0 in stage 22.0 (TID 22, localhost, executor driver, partition 0, PROCESS_LOCAL, 8060 bytes)
21/02/17 01:34:41 INFO Executor: Running task 0.0 in stage 22.0 (TID 22)
21/02/17 01:34:41 INFO Executor: Finished task 0.0 in stage 22.0 (TID 22). 1247 bytes result sent to driver
21/02/17 01:34:41 INFO TaskSetManager: Finished task 0.0 in stage 22.0 (TID 22) in 5 ms on localhost (executor driver) (1/1)
21/02/17 01:34:41 INFO TaskSchedulerImpl: Removed TaskSet 22.0, whose tasks have all completed, from pool 
21/02/17 01:34:41 INFO DAGScheduler: ShuffleMapStage 22 (parquet at RFormula.scala:586) finished in 0.010 s
21/02/17 01:34:41 INFO DAGScheduler: looking for newly runnable stages
21/02/17 01:34:41 INFO DAGScheduler: running: Set()
21/02/17 01:34:41 INFO DAGScheduler: waiting: Set(ResultStage 23)
21/02/17 01:34:41 INFO DAGScheduler: failed: Set()
21/02/17 01:34:41 INFO DAGScheduler: Submitting ResultStage 23 (ShuffledRowRDD[80] at parquet at RFormula.scala:586), which has no missing parents
21/02/17 01:34:41 INFO MemoryStore: Block broadcast_24 stored as values in memory (estimated size 151.0 KB, free 911.7 MB)
21/02/17 01:34:41 INFO MemoryStore: Block broadcast_24_piece0 stored as bytes in memory (estimated size 53.5 KB, free 911.6 MB)
21/02/17 01:34:41 INFO BlockManagerInfo: Added broadcast_24_piece0 in memory on localhost:34997 (size: 53.5 KB, free: 912.1 MB)
21/02/17 01:34:41 INFO SparkContext: Created broadcast 24 from broadcast at DAGScheduler.scala:1039
21/02/17 01:34:41 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 23 (ShuffledRowRDD[80] at parquet at RFormula.scala:586) (first 15 tasks are for partitions Vector(0))
21/02/17 01:34:41 INFO TaskSchedulerImpl: Adding task set 23.0 with 1 tasks
21/02/17 01:34:41 INFO TaskSetManager: Starting task 0.0 in stage 23.0 (TID 23, localhost, executor driver, partition 0, NODE_LOCAL, 7754 bytes)
21/02/17 01:34:41 INFO Executor: Running task 0.0 in stage 23.0 (TID 23)
21/02/17 01:34:41 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
21/02/17 01:34:41 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
21/02/17 01:34:41 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
21/02/17 01:34:41 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
21/02/17 01:34:41 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
21/02/17 01:34:41 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
21/02/17 01:34:41 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:
{
  "type" : "struct",
  "fields" : [ {
    "name" : "vectorCol",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "prefixesToRewrite",
    "type" : {
      "type" : "map",
      "keyType" : "string",
      "valueType" : "string",
      "valueContainsNull" : true
    },
    "nullable" : true,
    "metadata" : { }
  } ]
}
and corresponding Parquet message type:
message spark_schema {
  optional binary vectorCol (UTF8);
  optional group prefixesToRewrite (MAP) {
    repeated group key_value {
      required binary key (UTF8);
      optional binary value (UTF8);
    }
  }
}

       
21/02/17 01:34:41 INFO FileOutputCommitter: Saved output of task 'attempt_20210217013441_0023_m_000000_0' to file:/tmp/RtmpqE8K95/file2236138cd1f15/stages/0_r_formula__9b9b20bf_34e1_4305_9c6b_8f400f69191b/pipelineModel/stages/1_vectorAttrRewriter_cbe2c7c677da/data/_temporary/0/task_20210217013441_0023_m_000000
21/02/17 01:34:41 INFO SparkHadoopMapRedUtil: attempt_20210217013441_0023_m_000000_0: Committed
21/02/17 01:34:41 INFO Executor: Finished task 0.0 in stage 23.0 (TID 23). 2308 bytes result sent to driver
21/02/17 01:34:41 INFO TaskSetManager: Finished task 0.0 in stage 23.0 (TID 23) in 31 ms on localhost (executor driver) (1/1)
21/02/17 01:34:41 INFO TaskSchedulerImpl: Removed TaskSet 23.0, whose tasks have all completed, from pool 
21/02/17 01:34:41 INFO DAGScheduler: ResultStage 23 (parquet at RFormula.scala:586) finished in 0.052 s
21/02/17 01:34:41 INFO DAGScheduler: Job 17 finished: parquet at RFormula.scala:586, took 0.064703 s
21/02/17 01:34:41 INFO FileFormatWriter: Job null committed.
21/02/17 01:34:41 INFO FileFormatWriter: Finished processing stats for job null.
21/02/17 01:34:41 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
21/02/17 01:34:41 INFO SparkContext: Starting job: runJob at SparkHadoopWriter.scala:78
21/02/17 01:34:41 INFO DAGScheduler: Got job 18 (runJob at SparkHadoopWriter.scala:78) with 1 output partitions
21/02/17 01:34:41 INFO DAGScheduler: Final stage: ResultStage 24 (runJob at SparkHadoopWriter.scala:78)
21/02/17 01:34:41 INFO DAGScheduler: Parents of final stage: List()
21/02/17 01:34:41 INFO DAGScheduler: Missing parents: List()
21/02/17 01:34:41 INFO DAGScheduler: Submitting ResultStage 24 (MapPartitionsRDD[83] at saveAsTextFile at ReadWrite.scala:283), which has no missing parents
21/02/17 01:34:41 INFO MemoryStore: Block broadcast_25 stored as values in memory (estimated size 71.2 KB, free 911.5 MB)
21/02/17 01:34:41 INFO MemoryStore: Block broadcast_25_piece0 stored as bytes in memory (estimated size 25.6 KB, free 911.5 MB)
21/02/17 01:34:41 INFO BlockManagerInfo: Added broadcast_25_piece0 in memory on localhost:34997 (size: 25.6 KB, free: 912.1 MB)
21/02/17 01:34:41 INFO SparkContext: Created broadcast 25 from broadcast at DAGScheduler.scala:1039
21/02/17 01:34:41 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 24 (MapPartitionsRDD[83] at saveAsTextFile at ReadWrite.scala:283) (first 15 tasks are for partitions Vector(0))
21/02/17 01:34:41 INFO TaskSchedulerImpl: Adding task set 24.0 with 1 tasks
21/02/17 01:34:41 INFO TaskSetManager: Starting task 0.0 in stage 24.0 (TID 24, localhost, executor driver, partition 0, PROCESS_LOCAL, 8007 bytes)
21/02/17 01:34:41 INFO Executor: Running task 0.0 in stage 24.0 (TID 24)
21/02/17 01:34:41 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
21/02/17 01:34:41 INFO FileOutputCommitter: Saved output of task 'attempt_20210217013441_0083_m_000000_0' to file:/tmp/RtmpqE8K95/file2236138cd1f15/stages/0_r_formula__9b9b20bf_34e1_4305_9c6b_8f400f69191b/pipelineModel/stages/2_columnPruner_673a5842ee24/metadata/_temporary/0/task_20210217013441_0083_m_000000
21/02/17 01:34:41 INFO SparkHadoopMapRedUtil: attempt_20210217013441_0083_m_000000_0: Committed
21/02/17 01:34:41 INFO Executor: Finished task 0.0 in stage 24.0 (TID 24). 1029 bytes result sent to driver
21/02/17 01:34:41 INFO TaskSetManager: Finished task 0.0 in stage 24.0 (TID 24) in 10 ms on localhost (executor driver) (1/1)
21/02/17 01:34:41 INFO TaskSchedulerImpl: Removed TaskSet 24.0, whose tasks have all completed, from pool 
21/02/17 01:34:41 INFO DAGScheduler: ResultStage 24 (runJob at SparkHadoopWriter.scala:78) finished in 0.020 s
21/02/17 01:34:41 INFO DAGScheduler: Job 18 finished: runJob at SparkHadoopWriter.scala:78, took 0.021127 s
21/02/17 01:34:41 INFO SparkHadoopWriter: Job job_20210217013441_0083 committed.
21/02/17 01:34:41 INFO ParquetFileFormat: Using default output committer for Parquet: org.apache.parquet.hadoop.ParquetOutputCommitter
21/02/17 01:34:41 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
21/02/17 01:34:41 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
21/02/17 01:34:41 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
21/02/17 01:34:41 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
21/02/17 01:34:41 INFO CodeGenerator: Code generated in 8.779286 ms
21/02/17 01:34:41 INFO SparkContext: Starting job: parquet at RFormula.scala:495
21/02/17 01:34:41 INFO DAGScheduler: Registering RDD 86 (parquet at RFormula.scala:495)
21/02/17 01:34:41 INFO DAGScheduler: Got job 19 (parquet at RFormula.scala:495) with 1 output partitions
21/02/17 01:34:41 INFO DAGScheduler: Final stage: ResultStage 26 (parquet at RFormula.scala:495)
21/02/17 01:34:41 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 25)
21/02/17 01:34:41 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 25)
21/02/17 01:34:41 INFO DAGScheduler: Submitting ShuffleMapStage 25 (MapPartitionsRDD[86] at parquet at RFormula.scala:495), which has no missing parents
21/02/17 01:34:41 INFO MemoryStore: Block broadcast_26 stored as values in memory (estimated size 4.7 KB, free 911.5 MB)
21/02/17 01:34:41 INFO MemoryStore: Block broadcast_26_piece0 stored as bytes in memory (estimated size 2.8 KB, free 911.5 MB)
21/02/17 01:34:41 INFO BlockManagerInfo: Added broadcast_26_piece0 in memory on localhost:34997 (size: 2.8 KB, free: 912.1 MB)
21/02/17 01:34:41 INFO SparkContext: Created broadcast 26 from broadcast at DAGScheduler.scala:1039
21/02/17 01:34:41 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 25 (MapPartitionsRDD[86] at parquet at RFormula.scala:495) (first 15 tasks are for partitions Vector(0))
21/02/17 01:34:41 INFO TaskSchedulerImpl: Adding task set 25.0 with 1 tasks
21/02/17 01:34:41 INFO TaskSetManager: Starting task 0.0 in stage 25.0 (TID 25, localhost, executor driver, partition 0, PROCESS_LOCAL, 8028 bytes)
21/02/17 01:34:41 INFO Executor: Running task 0.0 in stage 25.0 (TID 25)
21/02/17 01:34:41 INFO Executor: Finished task 0.0 in stage 25.0 (TID 25). 1247 bytes result sent to driver
21/02/17 01:34:41 INFO TaskSetManager: Finished task 0.0 in stage 25.0 (TID 25) in 5 ms on localhost (executor driver) (1/1)
21/02/17 01:34:41 INFO TaskSchedulerImpl: Removed TaskSet 25.0, whose tasks have all completed, from pool 
21/02/17 01:34:41 INFO DAGScheduler: ShuffleMapStage 25 (parquet at RFormula.scala:495) finished in 0.010 s
21/02/17 01:34:41 INFO DAGScheduler: looking for newly runnable stages
21/02/17 01:34:41 INFO DAGScheduler: running: Set()
21/02/17 01:34:41 INFO DAGScheduler: waiting: Set(ResultStage 26)
21/02/17 01:34:41 INFO DAGScheduler: failed: Set()
21/02/17 01:34:41 INFO DAGScheduler: Submitting ResultStage 26 (ShuffledRowRDD[87] at parquet at RFormula.scala:495), which has no missing parents
21/02/17 01:34:41 INFO MemoryStore: Block broadcast_27 stored as values in memory (estimated size 150.8 KB, free 911.4 MB)
21/02/17 01:34:41 INFO MemoryStore: Block broadcast_27_piece0 stored as bytes in memory (estimated size 53.4 KB, free 911.3 MB)
21/02/17 01:34:41 INFO BlockManagerInfo: Added broadcast_27_piece0 in memory on localhost:34997 (size: 53.4 KB, free: 912.0 MB)
21/02/17 01:34:41 INFO SparkContext: Created broadcast 27 from broadcast at DAGScheduler.scala:1039
21/02/17 01:34:41 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 26 (ShuffledRowRDD[87] at parquet at RFormula.scala:495) (first 15 tasks are for partitions Vector(0))
21/02/17 01:34:41 INFO TaskSchedulerImpl: Adding task set 26.0 with 1 tasks
21/02/17 01:34:41 INFO TaskSetManager: Starting task 0.0 in stage 26.0 (TID 26, localhost, executor driver, partition 0, NODE_LOCAL, 7754 bytes)
21/02/17 01:34:41 INFO Executor: Running task 0.0 in stage 26.0 (TID 26)
21/02/17 01:34:41 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
21/02/17 01:34:41 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
21/02/17 01:34:41 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
21/02/17 01:34:41 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
21/02/17 01:34:41 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
21/02/17 01:34:41 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
21/02/17 01:34:41 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:
{
  "type" : "struct",
  "fields" : [ {
    "name" : "columnsToPrune",
    "type" : {
      "type" : "array",
      "elementType" : "string",
      "containsNull" : true
    },
    "nullable" : true,
    "metadata" : { }
  } ]
}
and corresponding Parquet message type:
message spark_schema {
  optional group columnsToPrune (LIST) {
    repeated group list {
      optional binary element (UTF8);
    }
  }
}

       
21/02/17 01:34:41 INFO FileOutputCommitter: Saved output of task 'attempt_20210217013441_0026_m_000000_0' to file:/tmp/RtmpqE8K95/file2236138cd1f15/stages/0_r_formula__9b9b20bf_34e1_4305_9c6b_8f400f69191b/pipelineModel/stages/2_columnPruner_673a5842ee24/data/_temporary/0/task_20210217013441_0026_m_000000
21/02/17 01:34:41 INFO SparkHadoopMapRedUtil: attempt_20210217013441_0026_m_000000_0: Committed
21/02/17 01:34:41 INFO Executor: Finished task 0.0 in stage 26.0 (TID 26). 2308 bytes result sent to driver
21/02/17 01:34:41 INFO TaskSetManager: Finished task 0.0 in stage 26.0 (TID 26) in 25 ms on localhost (executor driver) (1/1)
21/02/17 01:34:41 INFO TaskSchedulerImpl: Removed TaskSet 26.0, whose tasks have all completed, from pool 
21/02/17 01:34:41 INFO DAGScheduler: ResultStage 26 (parquet at RFormula.scala:495) finished in 0.046 s
21/02/17 01:34:41 INFO DAGScheduler: Job 19 finished: parquet at RFormula.scala:495, took 0.059606 s
21/02/17 01:34:41 INFO FileFormatWriter: Job null committed.
21/02/17 01:34:41 INFO FileFormatWriter: Finished processing stats for job null.
21/02/17 01:34:43 INFO SparkContext: Invoking stop() from shutdown hook
21/02/17 01:34:43 INFO SparkUI: Stopped Spark web UI at http://localhost:4040
21/02/17 01:34:43 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!
21/02/17 01:34:43 INFO MemoryStore: MemoryStore cleared
21/02/17 01:34:43 INFO BlockManager: BlockManager stopped
21/02/17 01:34:43 INFO BlockManagerMaster: BlockManagerMaster stopped
21/02/17 01:34:43 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!
21/02/17 01:34:43 INFO SparkContext: Successfully stopped SparkContext
21/02/17 01:34:43 INFO ShutdownHookManager: Shutdown hook called
21/02/17 01:34:43 INFO ShutdownHookManager: Deleting directory /tmp/spark-d03a7ac1-d107-4f6b-8354-67e3877558ca
21/02/17 01:34:43 INFO ShutdownHookManager: Deleting directory /tmp/spark-3a24ac5a-64a8-4146-96c3-4764374d3e73
21/02/17 01:37:19 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
21/02/17 01:37:20 INFO SparkContext: Running Spark version 2.3.0
21/02/17 01:37:20 INFO SparkContext: Submitted application: sparklyr
21/02/17 01:37:20 INFO SecurityManager: Changing view acls to: yitaoli
21/02/17 01:37:20 INFO SecurityManager: Changing modify acls to: yitaoli
21/02/17 01:37:20 INFO SecurityManager: Changing view acls groups to: 
21/02/17 01:37:20 INFO SecurityManager: Changing modify acls groups to: 
21/02/17 01:37:20 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(yitaoli); groups with view permissions: Set(); users  with modify permissions: Set(yitaoli); groups with modify permissions: Set()
21/02/17 01:37:20 INFO Utils: Successfully started service 'sparkDriver' on port 38575.
21/02/17 01:37:20 INFO SparkEnv: Registering MapOutputTracker
21/02/17 01:37:20 INFO SparkEnv: Registering BlockManagerMaster
21/02/17 01:37:20 INFO BlockManagerMasterEndpoint: Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
21/02/17 01:37:20 INFO BlockManagerMasterEndpoint: BlockManagerMasterEndpoint up
21/02/17 01:37:20 INFO DiskBlockManager: Created local directory at /tmp/blockmgr-1865d798-4357-4c50-aa28-73f9d3441c73
21/02/17 01:37:20 INFO MemoryStore: MemoryStore started with capacity 912.3 MB
21/02/17 01:37:20 INFO SparkEnv: Registering OutputCommitCoordinator
21/02/17 01:37:20 INFO Utils: Successfully started service 'SparkUI' on port 4040.
21/02/17 01:37:20 INFO SparkUI: Bound SparkUI to 127.0.0.1, and started at http://localhost:4040
21/02/17 01:37:20 INFO SparkContext: Added JAR file:///home/yitaoli/R/x86_64-pc-linux-gnu-library/4.0/sparkxgb/java/sparkxgb-2.3-2.11.jar at spark://localhost:38575/jars/sparkxgb-2.3-2.11.jar with timestamp 1613525840606
21/02/17 01:37:20 INFO SparkContext: Added JAR file:///home/yitaoli/.ivy2/jars/ml.dmlc_xgboost4j-spark_2.11-1.1.2.jar at spark://localhost:38575/jars/ml.dmlc_xgboost4j-spark_2.11-1.1.2.jar with timestamp 1613525840607
21/02/17 01:37:20 INFO SparkContext: Added JAR file:///home/yitaoli/.ivy2/jars/org.json4s_json4s-jackson_2.11-3.2.11.jar at spark://localhost:38575/jars/org.json4s_json4s-jackson_2.11-3.2.11.jar with timestamp 1613525840607
21/02/17 01:37:20 INFO SparkContext: Added JAR file:///home/yitaoli/.ivy2/jars/ml.dmlc_xgboost4j_2.11-1.1.2.jar at spark://localhost:38575/jars/ml.dmlc_xgboost4j_2.11-1.1.2.jar with timestamp 1613525840607
21/02/17 01:37:20 INFO SparkContext: Added JAR file:///home/yitaoli/.ivy2/jars/com.esotericsoftware.kryo_kryo-2.22.jar at spark://localhost:38575/jars/com.esotericsoftware.kryo_kryo-2.22.jar with timestamp 1613525840607
21/02/17 01:37:20 INFO SparkContext: Added JAR file:///home/yitaoli/.ivy2/jars/org.scala-lang_scala-compiler-2.11.12.jar at spark://localhost:38575/jars/org.scala-lang_scala-compiler-2.11.12.jar with timestamp 1613525840607
21/02/17 01:37:20 INFO SparkContext: Added JAR file:///home/yitaoli/.ivy2/jars/org.scala-lang_scala-reflect-2.11.12.jar at spark://localhost:38575/jars/org.scala-lang_scala-reflect-2.11.12.jar with timestamp 1613525840607
21/02/17 01:37:20 INFO SparkContext: Added JAR file:///home/yitaoli/.ivy2/jars/commons-logging_commons-logging-1.2.jar at spark://localhost:38575/jars/commons-logging_commons-logging-1.2.jar with timestamp 1613525840608
21/02/17 01:37:20 INFO SparkContext: Added JAR file:///home/yitaoli/.ivy2/jars/com.typesafe.akka_akka-actor_2.11-2.5.23.jar at spark://localhost:38575/jars/com.typesafe.akka_akka-actor_2.11-2.5.23.jar with timestamp 1613525840608
21/02/17 01:37:20 INFO SparkContext: Added JAR file:///home/yitaoli/.ivy2/jars/com.typesafe_config-1.3.3.jar at spark://localhost:38575/jars/com.typesafe_config-1.3.3.jar with timestamp 1613525840608
21/02/17 01:37:20 INFO SparkContext: Added JAR file:///home/yitaoli/.ivy2/jars/org.scala-lang.modules_scala-java8-compat_2.11-0.7.0.jar at spark://localhost:38575/jars/org.scala-lang.modules_scala-java8-compat_2.11-0.7.0.jar with timestamp 1613525840608
21/02/17 01:37:20 INFO SparkContext: Added JAR file:///home/yitaoli/.ivy2/jars/org.scala-lang.modules_scala-xml_2.11-1.0.5.jar at spark://localhost:38575/jars/org.scala-lang.modules_scala-xml_2.11-1.0.5.jar with timestamp 1613525840608
21/02/17 01:37:20 INFO SparkContext: Added JAR file:///home/yitaoli/.ivy2/jars/org.scala-lang.modules_scala-parser-combinators_2.11-1.0.4.jar at spark://localhost:38575/jars/org.scala-lang.modules_scala-parser-combinators_2.11-1.0.4.jar with timestamp 1613525840608
21/02/17 01:37:20 INFO SparkContext: Added JAR file:///home/yitaoli/.ivy2/jars/org.json4s_json4s-core_2.11-3.2.11.jar at spark://localhost:38575/jars/org.json4s_json4s-core_2.11-3.2.11.jar with timestamp 1613525840608
21/02/17 01:37:20 INFO SparkContext: Added JAR file:///home/yitaoli/.ivy2/jars/com.fasterxml.jackson.core_jackson-databind-2.3.1.jar at spark://localhost:38575/jars/com.fasterxml.jackson.core_jackson-databind-2.3.1.jar with timestamp 1613525840608
21/02/17 01:37:20 INFO SparkContext: Added JAR file:///home/yitaoli/.ivy2/jars/org.json4s_json4s-ast_2.11-3.2.11.jar at spark://localhost:38575/jars/org.json4s_json4s-ast_2.11-3.2.11.jar with timestamp 1613525840608
21/02/17 01:37:20 INFO SparkContext: Added JAR file:///home/yitaoli/.ivy2/jars/com.thoughtworks.paranamer_paranamer-2.6.jar at spark://localhost:38575/jars/com.thoughtworks.paranamer_paranamer-2.6.jar with timestamp 1613525840608
21/02/17 01:37:20 INFO SparkContext: Added JAR file:///home/yitaoli/.ivy2/jars/org.scala-lang_scalap-2.11.0.jar at spark://localhost:38575/jars/org.scala-lang_scalap-2.11.0.jar with timestamp 1613525840608
21/02/17 01:37:20 INFO SparkContext: Added JAR file:///home/yitaoli/.ivy2/jars/com.fasterxml.jackson.core_jackson-annotations-2.3.0.jar at spark://localhost:38575/jars/com.fasterxml.jackson.core_jackson-annotations-2.3.0.jar with timestamp 1613525840608
21/02/17 01:37:20 INFO SparkContext: Added JAR file:///home/yitaoli/.ivy2/jars/com.fasterxml.jackson.core_jackson-core-2.3.1.jar at spark://localhost:38575/jars/com.fasterxml.jackson.core_jackson-core-2.3.1.jar with timestamp 1613525840608
21/02/17 01:37:20 INFO SparkContext: Added JAR file:/home/yitaoli/R/x86_64-pc-linux-gnu-library/4.0/sparklyr/java/sparklyr-2.3-2.11.jar at spark://localhost:38575/jars/sparklyr-2.3-2.11.jar with timestamp 1613525840609
21/02/17 01:37:20 INFO Executor: Starting executor ID driver on host localhost
21/02/17 01:37:20 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 38285.
21/02/17 01:37:20 INFO NettyBlockTransferService: Server created on localhost:38285
21/02/17 01:37:20 INFO BlockManager: Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
21/02/17 01:37:20 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, localhost, 38285, None)
21/02/17 01:37:20 INFO BlockManagerMasterEndpoint: Registering block manager localhost:38285 with 912.3 MB RAM, BlockManagerId(driver, localhost, 38285, None)
21/02/17 01:37:20 INFO BlockManagerMaster: Registered BlockManager BlockManagerId(driver, localhost, 38285, None)
21/02/17 01:37:20 INFO BlockManager: Initialized BlockManager: BlockManagerId(driver, localhost, 38285, None)
21/02/17 01:37:20 INFO SharedState: loading hive config file: file:/home/yitaoli/spark/spark-2.3.0-bin-hadoop2.7/conf/hive-site.xml
21/02/17 01:37:20 INFO SharedState: Setting hive.metastore.warehouse.dir ('null') to the value of spark.sql.warehouse.dir ('file:/home/yitaoli/sparkxgb/tests/testthat/spark-warehouse').
21/02/17 01:37:20 INFO SharedState: Warehouse path is 'file:/home/yitaoli/sparkxgb/tests/testthat/spark-warehouse'.
21/02/17 01:37:21 INFO StateStoreCoordinatorRef: Registered StateStoreCoordinator endpoint
21/02/17 01:37:22 INFO HiveUtils: Initializing HiveMetastoreConnection version 1.2.1 using Spark classes.
21/02/17 01:37:22 INFO HiveMetaStore: 0: Opening raw store with implemenation class:org.apache.hadoop.hive.metastore.ObjectStore
21/02/17 01:37:22 INFO ObjectStore: ObjectStore, initialize called
21/02/17 01:37:22 INFO Persistence: Property hive.metastore.integral.jdo.pushdown unknown - will be ignored
21/02/17 01:37:22 INFO Persistence: Property datanucleus.cache.level2 unknown - will be ignored
21/02/17 01:37:23 INFO ObjectStore: Setting MetaStore object pin classes with hive.metastore.cache.pinobjtypes="Table,StorageDescriptor,SerDeInfo,Partition,Database,Type,FieldSchema,Order"
21/02/17 01:37:24 INFO Datastore: The class "org.apache.hadoop.hive.metastore.model.MFieldSchema" is tagged as "embedded-only" so does not have its own datastore table.
21/02/17 01:37:24 INFO Datastore: The class "org.apache.hadoop.hive.metastore.model.MOrder" is tagged as "embedded-only" so does not have its own datastore table.
21/02/17 01:37:24 INFO Datastore: The class "org.apache.hadoop.hive.metastore.model.MFieldSchema" is tagged as "embedded-only" so does not have its own datastore table.
21/02/17 01:37:24 INFO Datastore: The class "org.apache.hadoop.hive.metastore.model.MOrder" is tagged as "embedded-only" so does not have its own datastore table.
21/02/17 01:37:25 INFO MetaStoreDirectSql: Using direct SQL, underlying DB is DERBY
21/02/17 01:37:25 INFO ObjectStore: Initialized ObjectStore
21/02/17 01:37:25 WARN ObjectStore: Version information not found in metastore. hive.metastore.schema.verification is not enabled so recording the schema version 1.2.0
21/02/17 01:37:25 WARN ObjectStore: Failed to get database default, returning NoSuchObjectException
21/02/17 01:37:25 INFO HiveMetaStore: Added admin role in metastore
21/02/17 01:37:25 INFO HiveMetaStore: Added public role in metastore
21/02/17 01:37:25 INFO HiveMetaStore: No user is added in admin role, since config is empty
21/02/17 01:37:25 INFO HiveMetaStore: 0: get_all_databases
21/02/17 01:37:25 INFO audit: ugi=yitaoli	ip=unknown-ip-addr	cmd=get_all_databases	
21/02/17 01:37:25 INFO HiveMetaStore: 0: get_functions: db=default pat=*
21/02/17 01:37:25 INFO audit: ugi=yitaoli	ip=unknown-ip-addr	cmd=get_functions: db=default pat=*	
21/02/17 01:37:25 INFO Datastore: The class "org.apache.hadoop.hive.metastore.model.MResourceUri" is tagged as "embedded-only" so does not have its own datastore table.
21/02/17 01:37:25 INFO SessionState: Created local directory: /tmp/bf8fb987-28ac-4bb0-9d5e-ab9b6aca1e47_resources
21/02/17 01:37:25 INFO SessionState: Created HDFS directory: /tmp/hive/yitaoli/bf8fb987-28ac-4bb0-9d5e-ab9b6aca1e47
21/02/17 01:37:25 INFO SessionState: Created local directory: /tmp/yitaoli/bf8fb987-28ac-4bb0-9d5e-ab9b6aca1e47
21/02/17 01:37:25 INFO SessionState: Created HDFS directory: /tmp/hive/yitaoli/bf8fb987-28ac-4bb0-9d5e-ab9b6aca1e47/_tmp_space.db
21/02/17 01:37:25 INFO HiveClientImpl: Warehouse location for Hive client (version 1.2.2) is file:/home/yitaoli/sparkxgb/tests/testthat/spark-warehouse
21/02/17 01:37:25 INFO HiveMetaStore: 0: get_database: default
21/02/17 01:37:25 INFO audit: ugi=yitaoli	ip=unknown-ip-addr	cmd=get_database: default	
21/02/17 01:37:25 INFO HiveMetaStore: 0: get_database: global_temp
21/02/17 01:37:25 INFO audit: ugi=yitaoli	ip=unknown-ip-addr	cmd=get_database: global_temp	
21/02/17 01:37:25 WARN ObjectStore: Failed to get database global_temp, returning NoSuchObjectException
21/02/17 01:37:25 INFO HiveMetaStore: 0: get_table : db=default tbl=iris
21/02/17 01:37:25 INFO audit: ugi=yitaoli	ip=unknown-ip-addr	cmd=get_table : db=default tbl=iris	
21/02/17 01:37:25 INFO HiveMetaStore: 0: get_database: default
21/02/17 01:37:25 INFO audit: ugi=yitaoli	ip=unknown-ip-addr	cmd=get_database: default	
21/02/17 01:37:25 INFO HiveMetaStore: 0: get_database: default
21/02/17 01:37:25 INFO audit: ugi=yitaoli	ip=unknown-ip-addr	cmd=get_database: default	
21/02/17 01:37:25 INFO HiveMetaStore: 0: get_tables: db=default pat=*
21/02/17 01:37:25 INFO audit: ugi=yitaoli	ip=unknown-ip-addr	cmd=get_tables: db=default pat=*	
21/02/17 01:37:26 INFO SparkContext: Starting job: collect at utils.scala:61
21/02/17 01:37:26 INFO DAGScheduler: Got job 0 (collect at utils.scala:61) with 1 output partitions
21/02/17 01:37:26 INFO DAGScheduler: Final stage: ResultStage 0 (collect at utils.scala:61)
21/02/17 01:37:26 INFO DAGScheduler: Parents of final stage: List()
21/02/17 01:37:26 INFO DAGScheduler: Missing parents: List()
21/02/17 01:37:26 INFO DAGScheduler: Submitting ResultStage 0 (MapPartitionsRDD[4] at map at utils.scala:54), which has no missing parents
21/02/17 01:37:26 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 5.9 KB, free 912.3 MB)
21/02/17 01:37:26 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 3.3 KB, free 912.3 MB)
21/02/17 01:37:26 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on localhost:38285 (size: 3.3 KB, free: 912.3 MB)
21/02/17 01:37:26 INFO SparkContext: Created broadcast 0 from broadcast at DAGScheduler.scala:1039
21/02/17 01:37:26 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 0 (MapPartitionsRDD[4] at map at utils.scala:54) (first 15 tasks are for partitions Vector(0))
21/02/17 01:37:26 INFO TaskSchedulerImpl: Adding task set 0.0 with 1 tasks
21/02/17 01:37:26 INFO TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0, localhost, executor driver, partition 0, PROCESS_LOCAL, 7880 bytes)
21/02/17 01:37:26 INFO Executor: Running task 0.0 in stage 0.0 (TID 0)
21/02/17 01:37:26 INFO Executor: Fetching spark://localhost:38575/jars/com.typesafe.akka_akka-actor_2.11-2.5.23.jar with timestamp 1613525840608
21/02/17 01:37:26 INFO TransportClientFactory: Successfully created connection to localhost/127.0.0.1:38575 after 13 ms (0 ms spent in bootstraps)
21/02/17 01:37:26 INFO Utils: Fetching spark://localhost:38575/jars/com.typesafe.akka_akka-actor_2.11-2.5.23.jar to /tmp/spark-0cdef2b3-d9d2-4cd6-ab8c-8c9b4dde38cf/userFiles-1fb42b18-4c40-49e9-a7f5-51af68926a50/fetchFileTemp6304734397610435987.tmp
21/02/17 01:37:26 INFO Executor: Adding file:/tmp/spark-0cdef2b3-d9d2-4cd6-ab8c-8c9b4dde38cf/userFiles-1fb42b18-4c40-49e9-a7f5-51af68926a50/com.typesafe.akka_akka-actor_2.11-2.5.23.jar to class loader
21/02/17 01:37:26 INFO Executor: Fetching spark://localhost:38575/jars/com.fasterxml.jackson.core_jackson-databind-2.3.1.jar with timestamp 1613525840608
21/02/17 01:37:26 INFO Utils: Fetching spark://localhost:38575/jars/com.fasterxml.jackson.core_jackson-databind-2.3.1.jar to /tmp/spark-0cdef2b3-d9d2-4cd6-ab8c-8c9b4dde38cf/userFiles-1fb42b18-4c40-49e9-a7f5-51af68926a50/fetchFileTemp6846529291237275172.tmp
21/02/17 01:37:26 INFO Executor: Adding file:/tmp/spark-0cdef2b3-d9d2-4cd6-ab8c-8c9b4dde38cf/userFiles-1fb42b18-4c40-49e9-a7f5-51af68926a50/com.fasterxml.jackson.core_jackson-databind-2.3.1.jar to class loader
21/02/17 01:37:26 INFO Executor: Fetching spark://localhost:38575/jars/ml.dmlc_xgboost4j_2.11-1.1.2.jar with timestamp 1613525840607
21/02/17 01:37:26 INFO Utils: Fetching spark://localhost:38575/jars/ml.dmlc_xgboost4j_2.11-1.1.2.jar to /tmp/spark-0cdef2b3-d9d2-4cd6-ab8c-8c9b4dde38cf/userFiles-1fb42b18-4c40-49e9-a7f5-51af68926a50/fetchFileTemp5876224523746203098.tmp
21/02/17 01:37:26 INFO Executor: Adding file:/tmp/spark-0cdef2b3-d9d2-4cd6-ab8c-8c9b4dde38cf/userFiles-1fb42b18-4c40-49e9-a7f5-51af68926a50/ml.dmlc_xgboost4j_2.11-1.1.2.jar to class loader
21/02/17 01:37:26 INFO Executor: Fetching spark://localhost:38575/jars/org.json4s_json4s-core_2.11-3.2.11.jar with timestamp 1613525840608
21/02/17 01:37:26 INFO Utils: Fetching spark://localhost:38575/jars/org.json4s_json4s-core_2.11-3.2.11.jar to /tmp/spark-0cdef2b3-d9d2-4cd6-ab8c-8c9b4dde38cf/userFiles-1fb42b18-4c40-49e9-a7f5-51af68926a50/fetchFileTemp6408026919492192686.tmp
21/02/17 01:37:26 INFO Executor: Adding file:/tmp/spark-0cdef2b3-d9d2-4cd6-ab8c-8c9b4dde38cf/userFiles-1fb42b18-4c40-49e9-a7f5-51af68926a50/org.json4s_json4s-core_2.11-3.2.11.jar to class loader
21/02/17 01:37:26 INFO Executor: Fetching spark://localhost:38575/jars/com.esotericsoftware.kryo_kryo-2.22.jar with timestamp 1613525840607
21/02/17 01:37:26 INFO Utils: Fetching spark://localhost:38575/jars/com.esotericsoftware.kryo_kryo-2.22.jar to /tmp/spark-0cdef2b3-d9d2-4cd6-ab8c-8c9b4dde38cf/userFiles-1fb42b18-4c40-49e9-a7f5-51af68926a50/fetchFileTemp6985168026494642122.tmp
21/02/17 01:37:26 INFO Executor: Adding file:/tmp/spark-0cdef2b3-d9d2-4cd6-ab8c-8c9b4dde38cf/userFiles-1fb42b18-4c40-49e9-a7f5-51af68926a50/com.esotericsoftware.kryo_kryo-2.22.jar to class loader
21/02/17 01:37:26 INFO Executor: Fetching spark://localhost:38575/jars/sparkxgb-2.3-2.11.jar with timestamp 1613525840606
21/02/17 01:37:26 INFO Utils: Fetching spark://localhost:38575/jars/sparkxgb-2.3-2.11.jar to /tmp/spark-0cdef2b3-d9d2-4cd6-ab8c-8c9b4dde38cf/userFiles-1fb42b18-4c40-49e9-a7f5-51af68926a50/fetchFileTemp598396959865930553.tmp
21/02/17 01:37:26 INFO Executor: Adding file:/tmp/spark-0cdef2b3-d9d2-4cd6-ab8c-8c9b4dde38cf/userFiles-1fb42b18-4c40-49e9-a7f5-51af68926a50/sparkxgb-2.3-2.11.jar to class loader
21/02/17 01:37:26 INFO Executor: Fetching spark://localhost:38575/jars/org.scala-lang_scala-compiler-2.11.12.jar with timestamp 1613525840607
21/02/17 01:37:26 INFO Utils: Fetching spark://localhost:38575/jars/org.scala-lang_scala-compiler-2.11.12.jar to /tmp/spark-0cdef2b3-d9d2-4cd6-ab8c-8c9b4dde38cf/userFiles-1fb42b18-4c40-49e9-a7f5-51af68926a50/fetchFileTemp3494754177792409318.tmp
21/02/17 01:37:26 INFO Executor: Adding file:/tmp/spark-0cdef2b3-d9d2-4cd6-ab8c-8c9b4dde38cf/userFiles-1fb42b18-4c40-49e9-a7f5-51af68926a50/org.scala-lang_scala-compiler-2.11.12.jar to class loader
21/02/17 01:37:26 INFO Executor: Fetching spark://localhost:38575/jars/org.scala-lang_scalap-2.11.0.jar with timestamp 1613525840608
21/02/17 01:37:26 INFO Utils: Fetching spark://localhost:38575/jars/org.scala-lang_scalap-2.11.0.jar to /tmp/spark-0cdef2b3-d9d2-4cd6-ab8c-8c9b4dde38cf/userFiles-1fb42b18-4c40-49e9-a7f5-51af68926a50/fetchFileTemp7182563713634137030.tmp
21/02/17 01:37:26 INFO Executor: Adding file:/tmp/spark-0cdef2b3-d9d2-4cd6-ab8c-8c9b4dde38cf/userFiles-1fb42b18-4c40-49e9-a7f5-51af68926a50/org.scala-lang_scalap-2.11.0.jar to class loader
21/02/17 01:37:26 INFO Executor: Fetching spark://localhost:38575/jars/org.scala-lang.modules_scala-xml_2.11-1.0.5.jar with timestamp 1613525840608
21/02/17 01:37:26 INFO Utils: Fetching spark://localhost:38575/jars/org.scala-lang.modules_scala-xml_2.11-1.0.5.jar to /tmp/spark-0cdef2b3-d9d2-4cd6-ab8c-8c9b4dde38cf/userFiles-1fb42b18-4c40-49e9-a7f5-51af68926a50/fetchFileTemp7188590540588037789.tmp
21/02/17 01:37:26 INFO Executor: Adding file:/tmp/spark-0cdef2b3-d9d2-4cd6-ab8c-8c9b4dde38cf/userFiles-1fb42b18-4c40-49e9-a7f5-51af68926a50/org.scala-lang.modules_scala-xml_2.11-1.0.5.jar to class loader
21/02/17 01:37:26 INFO Executor: Fetching spark://localhost:38575/jars/sparklyr-2.3-2.11.jar with timestamp 1613525840609
21/02/17 01:37:26 INFO Utils: Fetching spark://localhost:38575/jars/sparklyr-2.3-2.11.jar to /tmp/spark-0cdef2b3-d9d2-4cd6-ab8c-8c9b4dde38cf/userFiles-1fb42b18-4c40-49e9-a7f5-51af68926a50/fetchFileTemp1129157902055083641.tmp
21/02/17 01:37:26 INFO Executor: Adding file:/tmp/spark-0cdef2b3-d9d2-4cd6-ab8c-8c9b4dde38cf/userFiles-1fb42b18-4c40-49e9-a7f5-51af68926a50/sparklyr-2.3-2.11.jar to class loader
21/02/17 01:37:26 INFO Executor: Fetching spark://localhost:38575/jars/org.scala-lang_scala-reflect-2.11.12.jar with timestamp 1613525840607
21/02/17 01:37:26 INFO Utils: Fetching spark://localhost:38575/jars/org.scala-lang_scala-reflect-2.11.12.jar to /tmp/spark-0cdef2b3-d9d2-4cd6-ab8c-8c9b4dde38cf/userFiles-1fb42b18-4c40-49e9-a7f5-51af68926a50/fetchFileTemp4640659715864179067.tmp
21/02/17 01:37:26 INFO Executor: Adding file:/tmp/spark-0cdef2b3-d9d2-4cd6-ab8c-8c9b4dde38cf/userFiles-1fb42b18-4c40-49e9-a7f5-51af68926a50/org.scala-lang_scala-reflect-2.11.12.jar to class loader
21/02/17 01:37:26 INFO Executor: Fetching spark://localhost:38575/jars/com.typesafe_config-1.3.3.jar with timestamp 1613525840608
21/02/17 01:37:26 INFO Utils: Fetching spark://localhost:38575/jars/com.typesafe_config-1.3.3.jar to /tmp/spark-0cdef2b3-d9d2-4cd6-ab8c-8c9b4dde38cf/userFiles-1fb42b18-4c40-49e9-a7f5-51af68926a50/fetchFileTemp4311881438163309676.tmp
21/02/17 01:37:26 INFO Executor: Adding file:/tmp/spark-0cdef2b3-d9d2-4cd6-ab8c-8c9b4dde38cf/userFiles-1fb42b18-4c40-49e9-a7f5-51af68926a50/com.typesafe_config-1.3.3.jar to class loader
21/02/17 01:37:26 INFO Executor: Fetching spark://localhost:38575/jars/org.scala-lang.modules_scala-parser-combinators_2.11-1.0.4.jar with timestamp 1613525840608
21/02/17 01:37:26 INFO Utils: Fetching spark://localhost:38575/jars/org.scala-lang.modules_scala-parser-combinators_2.11-1.0.4.jar to /tmp/spark-0cdef2b3-d9d2-4cd6-ab8c-8c9b4dde38cf/userFiles-1fb42b18-4c40-49e9-a7f5-51af68926a50/fetchFileTemp203433226294093113.tmp
21/02/17 01:37:26 INFO Executor: Adding file:/tmp/spark-0cdef2b3-d9d2-4cd6-ab8c-8c9b4dde38cf/userFiles-1fb42b18-4c40-49e9-a7f5-51af68926a50/org.scala-lang.modules_scala-parser-combinators_2.11-1.0.4.jar to class loader
21/02/17 01:37:26 INFO Executor: Fetching spark://localhost:38575/jars/org.scala-lang.modules_scala-java8-compat_2.11-0.7.0.jar with timestamp 1613525840608
21/02/17 01:37:26 INFO Utils: Fetching spark://localhost:38575/jars/org.scala-lang.modules_scala-java8-compat_2.11-0.7.0.jar to /tmp/spark-0cdef2b3-d9d2-4cd6-ab8c-8c9b4dde38cf/userFiles-1fb42b18-4c40-49e9-a7f5-51af68926a50/fetchFileTemp8810766385447277038.tmp
21/02/17 01:37:26 INFO Executor: Adding file:/tmp/spark-0cdef2b3-d9d2-4cd6-ab8c-8c9b4dde38cf/userFiles-1fb42b18-4c40-49e9-a7f5-51af68926a50/org.scala-lang.modules_scala-java8-compat_2.11-0.7.0.jar to class loader
21/02/17 01:37:26 INFO Executor: Fetching spark://localhost:38575/jars/ml.dmlc_xgboost4j-spark_2.11-1.1.2.jar with timestamp 1613525840607
21/02/17 01:37:26 INFO Utils: Fetching spark://localhost:38575/jars/ml.dmlc_xgboost4j-spark_2.11-1.1.2.jar to /tmp/spark-0cdef2b3-d9d2-4cd6-ab8c-8c9b4dde38cf/userFiles-1fb42b18-4c40-49e9-a7f5-51af68926a50/fetchFileTemp8136378959347579436.tmp
21/02/17 01:37:26 INFO Executor: Adding file:/tmp/spark-0cdef2b3-d9d2-4cd6-ab8c-8c9b4dde38cf/userFiles-1fb42b18-4c40-49e9-a7f5-51af68926a50/ml.dmlc_xgboost4j-spark_2.11-1.1.2.jar to class loader
21/02/17 01:37:26 INFO Executor: Fetching spark://localhost:38575/jars/commons-logging_commons-logging-1.2.jar with timestamp 1613525840608
21/02/17 01:37:26 INFO Utils: Fetching spark://localhost:38575/jars/commons-logging_commons-logging-1.2.jar to /tmp/spark-0cdef2b3-d9d2-4cd6-ab8c-8c9b4dde38cf/userFiles-1fb42b18-4c40-49e9-a7f5-51af68926a50/fetchFileTemp775746300380902206.tmp
21/02/17 01:37:26 INFO Executor: Adding file:/tmp/spark-0cdef2b3-d9d2-4cd6-ab8c-8c9b4dde38cf/userFiles-1fb42b18-4c40-49e9-a7f5-51af68926a50/commons-logging_commons-logging-1.2.jar to class loader
21/02/17 01:37:26 INFO Executor: Fetching spark://localhost:38575/jars/org.json4s_json4s-jackson_2.11-3.2.11.jar with timestamp 1613525840607
21/02/17 01:37:26 INFO Utils: Fetching spark://localhost:38575/jars/org.json4s_json4s-jackson_2.11-3.2.11.jar to /tmp/spark-0cdef2b3-d9d2-4cd6-ab8c-8c9b4dde38cf/userFiles-1fb42b18-4c40-49e9-a7f5-51af68926a50/fetchFileTemp3881994611992254804.tmp
21/02/17 01:37:26 INFO Executor: Adding file:/tmp/spark-0cdef2b3-d9d2-4cd6-ab8c-8c9b4dde38cf/userFiles-1fb42b18-4c40-49e9-a7f5-51af68926a50/org.json4s_json4s-jackson_2.11-3.2.11.jar to class loader
21/02/17 01:37:26 INFO Executor: Fetching spark://localhost:38575/jars/com.fasterxml.jackson.core_jackson-annotations-2.3.0.jar with timestamp 1613525840608
21/02/17 01:37:26 INFO Utils: Fetching spark://localhost:38575/jars/com.fasterxml.jackson.core_jackson-annotations-2.3.0.jar to /tmp/spark-0cdef2b3-d9d2-4cd6-ab8c-8c9b4dde38cf/userFiles-1fb42b18-4c40-49e9-a7f5-51af68926a50/fetchFileTemp5408667041335221251.tmp
21/02/17 01:37:26 INFO Executor: Adding file:/tmp/spark-0cdef2b3-d9d2-4cd6-ab8c-8c9b4dde38cf/userFiles-1fb42b18-4c40-49e9-a7f5-51af68926a50/com.fasterxml.jackson.core_jackson-annotations-2.3.0.jar to class loader
21/02/17 01:37:26 INFO Executor: Fetching spark://localhost:38575/jars/org.json4s_json4s-ast_2.11-3.2.11.jar with timestamp 1613525840608
21/02/17 01:37:26 INFO Utils: Fetching spark://localhost:38575/jars/org.json4s_json4s-ast_2.11-3.2.11.jar to /tmp/spark-0cdef2b3-d9d2-4cd6-ab8c-8c9b4dde38cf/userFiles-1fb42b18-4c40-49e9-a7f5-51af68926a50/fetchFileTemp3589239217213367585.tmp
21/02/17 01:37:26 INFO Executor: Adding file:/tmp/spark-0cdef2b3-d9d2-4cd6-ab8c-8c9b4dde38cf/userFiles-1fb42b18-4c40-49e9-a7f5-51af68926a50/org.json4s_json4s-ast_2.11-3.2.11.jar to class loader
21/02/17 01:37:26 INFO Executor: Fetching spark://localhost:38575/jars/com.fasterxml.jackson.core_jackson-core-2.3.1.jar with timestamp 1613525840608
21/02/17 01:37:26 INFO Utils: Fetching spark://localhost:38575/jars/com.fasterxml.jackson.core_jackson-core-2.3.1.jar to /tmp/spark-0cdef2b3-d9d2-4cd6-ab8c-8c9b4dde38cf/userFiles-1fb42b18-4c40-49e9-a7f5-51af68926a50/fetchFileTemp440142397361995584.tmp
21/02/17 01:37:26 INFO Executor: Adding file:/tmp/spark-0cdef2b3-d9d2-4cd6-ab8c-8c9b4dde38cf/userFiles-1fb42b18-4c40-49e9-a7f5-51af68926a50/com.fasterxml.jackson.core_jackson-core-2.3.1.jar to class loader
21/02/17 01:37:26 INFO Executor: Fetching spark://localhost:38575/jars/com.thoughtworks.paranamer_paranamer-2.6.jar with timestamp 1613525840608
21/02/17 01:37:26 INFO Utils: Fetching spark://localhost:38575/jars/com.thoughtworks.paranamer_paranamer-2.6.jar to /tmp/spark-0cdef2b3-d9d2-4cd6-ab8c-8c9b4dde38cf/userFiles-1fb42b18-4c40-49e9-a7f5-51af68926a50/fetchFileTemp8132281592301467432.tmp
21/02/17 01:37:26 INFO Executor: Adding file:/tmp/spark-0cdef2b3-d9d2-4cd6-ab8c-8c9b4dde38cf/userFiles-1fb42b18-4c40-49e9-a7f5-51af68926a50/com.thoughtworks.paranamer_paranamer-2.6.jar to class loader
21/02/17 01:37:26 INFO CodeGenerator: Code generated in 169.488432 ms
21/02/17 01:37:26 INFO Executor: Finished task 0.0 in stage 0.0 (TID 0). 970 bytes result sent to driver
21/02/17 01:37:26 INFO TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in 468 ms on localhost (executor driver) (1/1)
21/02/17 01:37:26 INFO TaskSchedulerImpl: Removed TaskSet 0.0, whose tasks have all completed, from pool 
21/02/17 01:37:26 INFO DAGScheduler: ResultStage 0 (collect at utils.scala:61) finished in 0.573 s
21/02/17 01:37:26 INFO DAGScheduler: Job 0 finished: collect at utils.scala:61, took 0.613036 s
21/02/17 01:37:27 INFO CodeGenerator: Code generated in 9.479106 ms
21/02/17 01:37:27 INFO CodeGenerator: Code generated in 11.62086 ms
21/02/17 01:37:27 INFO SparkContext: Starting job: collect at utils.scala:135
21/02/17 01:37:27 INFO DAGScheduler: Got job 1 (collect at utils.scala:135) with 1 output partitions
21/02/17 01:37:27 INFO DAGScheduler: Final stage: ResultStage 1 (collect at utils.scala:135)
21/02/17 01:37:27 INFO DAGScheduler: Parents of final stage: List()
21/02/17 01:37:27 INFO DAGScheduler: Missing parents: List()
21/02/17 01:37:27 INFO DAGScheduler: Submitting ResultStage 1 (MapPartitionsRDD[9] at collect at utils.scala:135), which has no missing parents
21/02/17 01:37:27 INFO MemoryStore: Block broadcast_1 stored as values in memory (estimated size 6.4 KB, free 912.3 MB)
21/02/17 01:37:27 INFO MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 3.2 KB, free 912.3 MB)
21/02/17 01:37:27 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on localhost:38285 (size: 3.2 KB, free: 912.3 MB)
21/02/17 01:37:27 INFO SparkContext: Created broadcast 1 from broadcast at DAGScheduler.scala:1039
21/02/17 01:37:27 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 1 (MapPartitionsRDD[9] at collect at utils.scala:135) (first 15 tasks are for partitions Vector(0))
21/02/17 01:37:27 INFO TaskSchedulerImpl: Adding task set 1.0 with 1 tasks
21/02/17 01:37:27 INFO TaskSetManager: Starting task 0.0 in stage 1.0 (TID 1, localhost, executor driver, partition 0, PROCESS_LOCAL, 8067 bytes)
21/02/17 01:37:27 INFO Executor: Running task 0.0 in stage 1.0 (TID 1)
21/02/17 01:37:27 INFO CodeGenerator: Code generated in 5.768403 ms
21/02/17 01:37:27 INFO Executor: Finished task 0.0 in stage 1.0 (TID 1). 1329 bytes result sent to driver
21/02/17 01:37:27 INFO TaskSetManager: Finished task 0.0 in stage 1.0 (TID 1) in 19 ms on localhost (executor driver) (1/1)
21/02/17 01:37:27 INFO TaskSchedulerImpl: Removed TaskSet 1.0, whose tasks have all completed, from pool 
21/02/17 01:37:27 INFO DAGScheduler: ResultStage 1 (collect at utils.scala:135) finished in 0.024 s
21/02/17 01:37:27 INFO DAGScheduler: Job 1 finished: collect at utils.scala:135, took 0.026936 s
21/02/17 01:37:27 INFO CodeGenerator: Code generated in 15.296485 ms
21/02/17 01:37:27 INFO CodeGenerator: Code generated in 12.451469 ms
21/02/17 01:37:27 INFO SparkContext: Starting job: count at utils.scala:135
21/02/17 01:37:27 INFO DAGScheduler: Registering RDD 12 (count at utils.scala:135)
21/02/17 01:37:27 INFO DAGScheduler: Got job 2 (count at utils.scala:135) with 1 output partitions
21/02/17 01:37:27 INFO DAGScheduler: Final stage: ResultStage 3 (count at utils.scala:135)
21/02/17 01:37:27 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 2)
21/02/17 01:37:27 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 2)
21/02/17 01:37:27 INFO DAGScheduler: Submitting ShuffleMapStage 2 (MapPartitionsRDD[12] at count at utils.scala:135), which has no missing parents
21/02/17 01:37:27 INFO MemoryStore: Block broadcast_2 stored as values in memory (estimated size 8.9 KB, free 912.3 MB)
21/02/17 01:37:27 INFO MemoryStore: Block broadcast_2_piece0 stored as bytes in memory (estimated size 4.5 KB, free 912.3 MB)
21/02/17 01:37:27 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on localhost:38285 (size: 4.5 KB, free: 912.3 MB)
21/02/17 01:37:27 INFO SparkContext: Created broadcast 2 from broadcast at DAGScheduler.scala:1039
21/02/17 01:37:27 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 2 (MapPartitionsRDD[12] at count at utils.scala:135) (first 15 tasks are for partitions Vector(0))
21/02/17 01:37:27 INFO TaskSchedulerImpl: Adding task set 2.0 with 1 tasks
21/02/17 01:37:27 INFO TaskSetManager: Starting task 0.0 in stage 2.0 (TID 2, localhost, executor driver, partition 0, PROCESS_LOCAL, 8056 bytes)
21/02/17 01:37:27 INFO Executor: Running task 0.0 in stage 2.0 (TID 2)
21/02/17 01:37:27 INFO Executor: Finished task 0.0 in stage 2.0 (TID 2). 1542 bytes result sent to driver
21/02/17 01:37:27 INFO TaskSetManager: Finished task 0.0 in stage 2.0 (TID 2) in 29 ms on localhost (executor driver) (1/1)
21/02/17 01:37:27 INFO TaskSchedulerImpl: Removed TaskSet 2.0, whose tasks have all completed, from pool 
21/02/17 01:37:27 INFO DAGScheduler: ShuffleMapStage 2 (count at utils.scala:135) finished in 0.038 s
21/02/17 01:37:27 INFO DAGScheduler: looking for newly runnable stages
21/02/17 01:37:27 INFO DAGScheduler: running: Set()
21/02/17 01:37:27 INFO DAGScheduler: waiting: Set(ResultStage 3)
21/02/17 01:37:27 INFO DAGScheduler: failed: Set()
21/02/17 01:37:27 INFO DAGScheduler: Submitting ResultStage 3 (MapPartitionsRDD[15] at count at utils.scala:135), which has no missing parents
21/02/17 01:37:27 INFO MemoryStore: Block broadcast_3 stored as values in memory (estimated size 7.3 KB, free 912.3 MB)
21/02/17 01:37:27 INFO MemoryStore: Block broadcast_3_piece0 stored as bytes in memory (estimated size 3.8 KB, free 912.3 MB)
21/02/17 01:37:27 INFO BlockManagerInfo: Added broadcast_3_piece0 in memory on localhost:38285 (size: 3.8 KB, free: 912.3 MB)
21/02/17 01:37:27 INFO SparkContext: Created broadcast 3 from broadcast at DAGScheduler.scala:1039
21/02/17 01:37:27 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 3 (MapPartitionsRDD[15] at count at utils.scala:135) (first 15 tasks are for partitions Vector(0))
21/02/17 01:37:27 INFO TaskSchedulerImpl: Adding task set 3.0 with 1 tasks
21/02/17 01:37:27 INFO TaskSetManager: Starting task 0.0 in stage 3.0 (TID 3, localhost, executor driver, partition 0, NODE_LOCAL, 7754 bytes)
21/02/17 01:37:27 INFO Executor: Running task 0.0 in stage 3.0 (TID 3)
21/02/17 01:37:27 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
21/02/17 01:37:27 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 3 ms
21/02/17 01:37:27 INFO Executor: Finished task 0.0 in stage 3.0 (TID 3). 1782 bytes result sent to driver
21/02/17 01:37:27 INFO TaskSetManager: Finished task 0.0 in stage 3.0 (TID 3) in 25 ms on localhost (executor driver) (1/1)
21/02/17 01:37:27 INFO TaskSchedulerImpl: Removed TaskSet 3.0, whose tasks have all completed, from pool 
21/02/17 01:37:27 INFO DAGScheduler: ResultStage 3 (count at utils.scala:135) finished in 0.032 s
21/02/17 01:37:27 INFO DAGScheduler: Job 2 finished: count at utils.scala:135, took 0.084686 s
21/02/17 01:37:27 INFO SparkContext: Starting job: collect at utils.scala:135
21/02/17 01:37:27 INFO DAGScheduler: Got job 3 (collect at utils.scala:135) with 1 output partitions
21/02/17 01:37:27 INFO DAGScheduler: Final stage: ResultStage 4 (collect at utils.scala:135)
21/02/17 01:37:27 INFO DAGScheduler: Parents of final stage: List()
21/02/17 01:37:27 INFO DAGScheduler: Missing parents: List()
21/02/17 01:37:27 INFO DAGScheduler: Submitting ResultStage 4 (MapPartitionsRDD[20] at collect at utils.scala:135), which has no missing parents
21/02/17 01:37:27 INFO MemoryStore: Block broadcast_4 stored as values in memory (estimated size 6.4 KB, free 912.3 MB)
21/02/17 01:37:27 INFO MemoryStore: Block broadcast_4_piece0 stored as bytes in memory (estimated size 3.2 KB, free 912.2 MB)
21/02/17 01:37:27 INFO BlockManagerInfo: Added broadcast_4_piece0 in memory on localhost:38285 (size: 3.2 KB, free: 912.3 MB)
21/02/17 01:37:27 INFO SparkContext: Created broadcast 4 from broadcast at DAGScheduler.scala:1039
21/02/17 01:37:27 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 4 (MapPartitionsRDD[20] at collect at utils.scala:135) (first 15 tasks are for partitions Vector(0))
21/02/17 01:37:27 INFO TaskSchedulerImpl: Adding task set 4.0 with 1 tasks
21/02/17 01:37:27 INFO TaskSetManager: Starting task 0.0 in stage 4.0 (TID 4, localhost, executor driver, partition 0, PROCESS_LOCAL, 8067 bytes)
21/02/17 01:37:27 INFO Executor: Running task 0.0 in stage 4.0 (TID 4)
21/02/17 01:37:27 INFO Executor: Finished task 0.0 in stage 4.0 (TID 4). 1286 bytes result sent to driver
21/02/17 01:37:27 INFO TaskSetManager: Finished task 0.0 in stage 4.0 (TID 4) in 5 ms on localhost (executor driver) (1/1)
21/02/17 01:37:27 INFO TaskSchedulerImpl: Removed TaskSet 4.0, whose tasks have all completed, from pool 
21/02/17 01:37:27 INFO DAGScheduler: ResultStage 4 (collect at utils.scala:135) finished in 0.010 s
21/02/17 01:37:27 INFO DAGScheduler: Job 3 finished: collect at utils.scala:135, took 0.012032 s
21/02/17 01:37:27 INFO SparkContext: Starting job: count at utils.scala:135
21/02/17 01:37:27 INFO DAGScheduler: Registering RDD 23 (count at utils.scala:135)
21/02/17 01:37:27 INFO DAGScheduler: Got job 4 (count at utils.scala:135) with 1 output partitions
21/02/17 01:37:27 INFO DAGScheduler: Final stage: ResultStage 6 (count at utils.scala:135)
21/02/17 01:37:27 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 5)
21/02/17 01:37:27 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 5)
21/02/17 01:37:27 INFO DAGScheduler: Submitting ShuffleMapStage 5 (MapPartitionsRDD[23] at count at utils.scala:135), which has no missing parents
21/02/17 01:37:27 INFO MemoryStore: Block broadcast_5 stored as values in memory (estimated size 8.9 KB, free 912.2 MB)
21/02/17 01:37:27 INFO MemoryStore: Block broadcast_5_piece0 stored as bytes in memory (estimated size 4.5 KB, free 912.2 MB)
21/02/17 01:37:27 INFO BlockManagerInfo: Added broadcast_5_piece0 in memory on localhost:38285 (size: 4.5 KB, free: 912.3 MB)
21/02/17 01:37:27 INFO SparkContext: Created broadcast 5 from broadcast at DAGScheduler.scala:1039
21/02/17 01:37:27 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 5 (MapPartitionsRDD[23] at count at utils.scala:135) (first 15 tasks are for partitions Vector(0))
21/02/17 01:37:27 INFO TaskSchedulerImpl: Adding task set 5.0 with 1 tasks
21/02/17 01:37:27 INFO TaskSetManager: Starting task 0.0 in stage 5.0 (TID 5, localhost, executor driver, partition 0, PROCESS_LOCAL, 8056 bytes)
21/02/17 01:37:27 INFO Executor: Running task 0.0 in stage 5.0 (TID 5)
21/02/17 01:37:27 INFO Executor: Finished task 0.0 in stage 5.0 (TID 5). 1499 bytes result sent to driver
21/02/17 01:37:27 INFO TaskSetManager: Finished task 0.0 in stage 5.0 (TID 5) in 7 ms on localhost (executor driver) (1/1)
21/02/17 01:37:27 INFO TaskSchedulerImpl: Removed TaskSet 5.0, whose tasks have all completed, from pool 
21/02/17 01:37:27 INFO DAGScheduler: ShuffleMapStage 5 (count at utils.scala:135) finished in 0.015 s
21/02/17 01:37:27 INFO DAGScheduler: looking for newly runnable stages
21/02/17 01:37:27 INFO DAGScheduler: running: Set()
21/02/17 01:37:27 INFO DAGScheduler: waiting: Set(ResultStage 6)
21/02/17 01:37:27 INFO DAGScheduler: failed: Set()
21/02/17 01:37:27 INFO DAGScheduler: Submitting ResultStage 6 (MapPartitionsRDD[26] at count at utils.scala:135), which has no missing parents
21/02/17 01:37:27 INFO MemoryStore: Block broadcast_6 stored as values in memory (estimated size 7.3 KB, free 912.2 MB)
21/02/17 01:37:27 INFO MemoryStore: Block broadcast_6_piece0 stored as bytes in memory (estimated size 3.8 KB, free 912.2 MB)
21/02/17 01:37:27 INFO BlockManagerInfo: Added broadcast_6_piece0 in memory on localhost:38285 (size: 3.8 KB, free: 912.3 MB)
21/02/17 01:37:27 INFO SparkContext: Created broadcast 6 from broadcast at DAGScheduler.scala:1039
21/02/17 01:37:27 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 6 (MapPartitionsRDD[26] at count at utils.scala:135) (first 15 tasks are for partitions Vector(0))
21/02/17 01:37:27 INFO TaskSchedulerImpl: Adding task set 6.0 with 1 tasks
21/02/17 01:37:27 INFO TaskSetManager: Starting task 0.0 in stage 6.0 (TID 6, localhost, executor driver, partition 0, NODE_LOCAL, 7754 bytes)
21/02/17 01:37:27 INFO Executor: Running task 0.0 in stage 6.0 (TID 6)
21/02/17 01:37:27 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
21/02/17 01:37:27 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
21/02/17 01:37:27 INFO Executor: Finished task 0.0 in stage 6.0 (TID 6). 1825 bytes result sent to driver
21/02/17 01:37:27 INFO TaskSetManager: Finished task 0.0 in stage 6.0 (TID 6) in 6 ms on localhost (executor driver) (1/1)
21/02/17 01:37:27 INFO TaskSchedulerImpl: Removed TaskSet 6.0, whose tasks have all completed, from pool 
21/02/17 01:37:27 INFO DAGScheduler: ResultStage 6 (count at utils.scala:135) finished in 0.014 s
21/02/17 01:37:27 INFO DAGScheduler: Job 4 finished: count at utils.scala:135, took 0.032135 s
21/02/17 01:37:27 INFO ContextCleaner: Cleaned accumulator 110
21/02/17 01:37:27 INFO ContextCleaner: Cleaned accumulator 45
21/02/17 01:37:27 INFO ContextCleaner: Cleaned accumulator 49
21/02/17 01:37:27 INFO ContextCleaner: Cleaned accumulator 69
21/02/17 01:37:27 INFO ContextCleaner: Cleaned accumulator 106
21/02/17 01:37:27 INFO ContextCleaner: Cleaned accumulator 203
21/02/17 01:37:27 INFO BlockManagerInfo: Removed broadcast_3_piece0 on localhost:38285 in memory (size: 3.8 KB, free: 912.3 MB)
21/02/17 01:37:27 INFO ContextCleaner: Cleaned accumulator 207
21/02/17 01:37:27 INFO ContextCleaner: Cleaned accumulator 70
21/02/17 01:37:27 INFO ContextCleaner: Cleaned accumulator 39
21/02/17 01:37:27 INFO ContextCleaner: Cleaned accumulator 141
21/02/17 01:37:27 INFO ContextCleaner: Cleaned accumulator 128
21/02/17 01:37:27 INFO ContextCleaner: Cleaned accumulator 43
21/02/17 01:37:27 INFO ContextCleaner: Cleaned accumulator 76
21/02/17 01:37:27 INFO ContextCleaner: Cleaned accumulator 26
21/02/17 01:37:27 INFO ContextCleaner: Cleaned accumulator 169
21/02/17 01:37:27 INFO ContextCleaner: Cleaned accumulator 168
21/02/17 01:37:27 INFO ContextCleaner: Cleaned accumulator 32
21/02/17 01:37:27 INFO ContextCleaner: Cleaned accumulator 61
21/02/17 01:37:27 INFO ContextCleaner: Cleaned accumulator 66
21/02/17 01:37:27 INFO ContextCleaner: Cleaned accumulator 52
21/02/17 01:37:27 INFO ContextCleaner: Cleaned accumulator 143
21/02/17 01:37:27 INFO ContextCleaner: Cleaned accumulator 161
21/02/17 01:37:27 INFO ContextCleaner: Cleaned accumulator 125
21/02/17 01:37:27 INFO ContextCleaner: Cleaned accumulator 131
21/02/17 01:37:27 INFO ContextCleaner: Cleaned accumulator 29
21/02/17 01:37:27 INFO ContextCleaner: Cleaned accumulator 38
21/02/17 01:37:27 INFO ContextCleaner: Cleaned accumulator 121
21/02/17 01:37:27 INFO ContextCleaner: Cleaned accumulator 183
21/02/17 01:37:27 INFO ContextCleaner: Cleaned accumulator 55
21/02/17 01:37:27 INFO ContextCleaner: Cleaned accumulator 123
21/02/17 01:37:27 INFO ContextCleaner: Cleaned accumulator 72
21/02/17 01:37:27 INFO ContextCleaner: Cleaned accumulator 94
21/02/17 01:37:27 INFO ContextCleaner: Cleaned accumulator 30
21/02/17 01:37:27 INFO ContextCleaner: Cleaned accumulator 193
21/02/17 01:37:27 INFO ContextCleaner: Cleaned accumulator 79
21/02/17 01:37:27 INFO ContextCleaner: Cleaned accumulator 24
21/02/17 01:37:27 INFO ContextCleaner: Cleaned accumulator 68
21/02/17 01:37:27 INFO ContextCleaner: Cleaned accumulator 135
21/02/17 01:37:27 INFO ContextCleaner: Cleaned accumulator 109
21/02/17 01:37:27 INFO ContextCleaner: Cleaned accumulator 112
21/02/17 01:37:27 INFO ContextCleaner: Cleaned accumulator 148
21/02/17 01:37:27 INFO ContextCleaner: Cleaned accumulator 105
21/02/17 01:37:27 INFO ContextCleaner: Cleaned accumulator 87
21/02/17 01:37:27 INFO ContextCleaner: Cleaned accumulator 114
21/02/17 01:37:27 INFO ContextCleaner: Cleaned accumulator 98
21/02/17 01:37:27 INFO ContextCleaner: Cleaned accumulator 84
21/02/17 01:37:27 INFO ContextCleaner: Cleaned accumulator 11
21/02/17 01:37:27 INFO ContextCleaner: Cleaned accumulator 25
21/02/17 01:37:27 INFO ContextCleaner: Cleaned accumulator 80
21/02/17 01:37:27 INFO ContextCleaner: Cleaned accumulator 139
21/02/17 01:37:27 INFO ContextCleaner: Cleaned accumulator 122
21/02/17 01:37:27 INFO ContextCleaner: Cleaned accumulator 180
21/02/17 01:37:27 INFO ContextCleaner: Cleaned accumulator 210
21/02/17 01:37:27 INFO ContextCleaner: Cleaned accumulator 51
21/02/17 01:37:27 INFO ContextCleaner: Cleaned accumulator 188
21/02/17 01:37:27 INFO ContextCleaner: Cleaned accumulator 132
21/02/17 01:37:27 INFO ContextCleaner: Cleaned accumulator 192
21/02/17 01:37:27 INFO ContextCleaner: Cleaned accumulator 200
21/02/17 01:37:27 INFO ContextCleaner: Cleaned accumulator 91
21/02/17 01:37:27 INFO BlockManagerInfo: Removed broadcast_5_piece0 on localhost:38285 in memory (size: 4.5 KB, free: 912.3 MB)
21/02/17 01:37:27 INFO ContextCleaner: Cleaned accumulator 211
21/02/17 01:37:27 INFO ContextCleaner: Cleaned accumulator 151
21/02/17 01:37:27 INFO ContextCleaner: Cleaned accumulator 186
21/02/17 01:37:27 INFO ContextCleaner: Cleaned accumulator 165
21/02/17 01:37:27 INFO ContextCleaner: Cleaned accumulator 58
21/02/17 01:37:27 INFO ContextCleaner: Cleaned accumulator 209
21/02/17 01:37:27 INFO ContextCleaner: Cleaned accumulator 77
21/02/17 01:37:27 INFO ContextCleaner: Cleaned accumulator 73
21/02/17 01:37:27 INFO ContextCleaner: Cleaned accumulator 47
21/02/17 01:37:27 INFO ContextCleaner: Cleaned accumulator 158
21/02/17 01:37:27 INFO ContextCleaner: Cleaned accumulator 195
21/02/17 01:37:27 INFO ContextCleaner: Cleaned accumulator 15
21/02/17 01:37:27 INFO ContextCleaner: Cleaned accumulator 21
21/02/17 01:37:27 INFO ContextCleaner: Cleaned accumulator 176
21/02/17 01:37:27 INFO ContextCleaner: Cleaned accumulator 184
21/02/17 01:37:27 INFO ContextCleaner: Cleaned accumulator 8
21/02/17 01:37:27 INFO ContextCleaner: Cleaned accumulator 75
21/02/17 01:37:27 INFO ContextCleaner: Cleaned accumulator 27
21/02/17 01:37:27 INFO ContextCleaner: Cleaned accumulator 1
21/02/17 01:37:27 INFO ContextCleaner: Cleaned accumulator 181
21/02/17 01:37:27 INFO ContextCleaner: Cleaned accumulator 166
21/02/17 01:37:27 INFO ContextCleaner: Cleaned shuffle 0
21/02/17 01:37:27 INFO ContextCleaner: Cleaned accumulator 34
21/02/17 01:37:27 INFO ContextCleaner: Cleaned accumulator 150
21/02/17 01:37:27 INFO ContextCleaner: Cleaned accumulator 185
21/02/17 01:37:27 INFO ContextCleaner: Cleaned accumulator 111
21/02/17 01:37:27 INFO ContextCleaner: Cleaned accumulator 156
21/02/17 01:37:27 INFO ContextCleaner: Cleaned accumulator 31
21/02/17 01:37:27 INFO ContextCleaner: Cleaned accumulator 40
21/02/17 01:37:27 INFO ContextCleaner: Cleaned accumulator 57
21/02/17 01:37:27 INFO ContextCleaner: Cleaned accumulator 144
21/02/17 01:37:27 INFO ContextCleaner: Cleaned accumulator 202
21/02/17 01:37:27 INFO ContextCleaner: Cleaned accumulator 204
21/02/17 01:37:27 INFO ContextCleaner: Cleaned accumulator 63
21/02/17 01:37:27 INFO ContextCleaner: Cleaned accumulator 64
21/02/17 01:37:27 INFO ContextCleaner: Cleaned accumulator 174
21/02/17 01:37:27 INFO ContextCleaner: Cleaned accumulator 23
21/02/17 01:37:27 INFO ContextCleaner: Cleaned accumulator 22
21/02/17 01:37:27 INFO ContextCleaner: Cleaned accumulator 54
21/02/17 01:37:27 INFO ContextCleaner: Cleaned accumulator 5
21/02/17 01:37:27 INFO ContextCleaner: Cleaned accumulator 154
21/02/17 01:37:27 INFO ContextCleaner: Cleaned accumulator 85
21/02/17 01:37:27 INFO ContextCleaner: Cleaned accumulator 81
21/02/17 01:37:27 INFO ContextCleaner: Cleaned accumulator 89
21/02/17 01:37:27 INFO ContextCleaner: Cleaned accumulator 86
21/02/17 01:37:27 INFO ContextCleaner: Cleaned accumulator 171
21/02/17 01:37:27 INFO ContextCleaner: Cleaned accumulator 137
21/02/17 01:37:27 INFO ContextCleaner: Cleaned accumulator 7
21/02/17 01:37:27 INFO ContextCleaner: Cleaned accumulator 78
21/02/17 01:37:27 INFO ContextCleaner: Cleaned accumulator 56
21/02/17 01:37:27 INFO ContextCleaner: Cleaned accumulator 163
21/02/17 01:37:27 INFO ContextCleaner: Cleaned accumulator 44
21/02/17 01:37:27 INFO ContextCleaner: Cleaned accumulator 103
21/02/17 01:37:27 INFO ContextCleaner: Cleaned accumulator 167
21/02/17 01:37:27 INFO ContextCleaner: Cleaned accumulator 93
21/02/17 01:37:27 INFO ContextCleaner: Cleaned accumulator 157
21/02/17 01:37:27 INFO ContextCleaner: Cleaned accumulator 153
21/02/17 01:37:27 INFO ContextCleaner: Cleaned accumulator 100
21/02/17 01:37:27 INFO ContextCleaner: Cleaned accumulator 107
21/02/17 01:37:27 INFO ContextCleaner: Cleaned accumulator 138
21/02/17 01:37:27 INFO ContextCleaner: Cleaned accumulator 53
21/02/17 01:37:27 INFO ContextCleaner: Cleaned accumulator 102
21/02/17 01:37:27 INFO ContextCleaner: Cleaned accumulator 115
21/02/17 01:37:27 INFO ContextCleaner: Cleaned accumulator 20
21/02/17 01:37:27 INFO ContextCleaner: Cleaned accumulator 117
21/02/17 01:37:27 INFO ContextCleaner: Cleaned accumulator 208
21/02/17 01:37:27 INFO ContextCleaner: Cleaned accumulator 108
21/02/17 01:37:27 INFO ContextCleaner: Cleaned accumulator 50
21/02/17 01:37:27 INFO ContextCleaner: Cleaned accumulator 129
21/02/17 01:37:27 INFO ContextCleaner: Cleaned accumulator 116
21/02/17 01:37:27 INFO BlockManagerInfo: Removed broadcast_4_piece0 on localhost:38285 in memory (size: 3.2 KB, free: 912.3 MB)
21/02/17 01:37:27 INFO ContextCleaner: Cleaned accumulator 127
21/02/17 01:37:27 INFO ContextCleaner: Cleaned accumulator 60
21/02/17 01:37:27 INFO ContextCleaner: Cleaned accumulator 206
21/02/17 01:37:27 INFO ContextCleaner: Cleaned accumulator 175
21/02/17 01:37:27 INFO BlockManagerInfo: Removed broadcast_0_piece0 on localhost:38285 in memory (size: 3.3 KB, free: 912.3 MB)
21/02/17 01:37:27 INFO ContextCleaner: Cleaned accumulator 178
21/02/17 01:37:27 INFO ContextCleaner: Cleaned accumulator 33
21/02/17 01:37:27 INFO BlockManagerInfo: Removed broadcast_2_piece0 on localhost:38285 in memory (size: 4.5 KB, free: 912.3 MB)
21/02/17 01:37:27 INFO ContextCleaner: Cleaned accumulator 130
21/02/17 01:37:27 INFO ContextCleaner: Cleaned accumulator 104
21/02/17 01:37:27 INFO ContextCleaner: Cleaned accumulator 182
21/02/17 01:37:27 INFO ContextCleaner: Cleaned accumulator 187
21/02/17 01:37:27 INFO ContextCleaner: Cleaned accumulator 16
21/02/17 01:37:27 INFO ContextCleaner: Cleaned accumulator 99
21/02/17 01:37:27 INFO ContextCleaner: Cleaned shuffle 1
21/02/17 01:37:27 INFO ContextCleaner: Cleaned accumulator 37
21/02/17 01:37:27 INFO ContextCleaner: Cleaned accumulator 146
21/02/17 01:37:27 INFO ContextCleaner: Cleaned accumulator 10
21/02/17 01:37:27 INFO ContextCleaner: Cleaned accumulator 17
21/02/17 01:37:27 INFO ContextCleaner: Cleaned accumulator 199
21/02/17 01:37:27 INFO ContextCleaner: Cleaned accumulator 172
21/02/17 01:37:27 INFO ContextCleaner: Cleaned accumulator 59
21/02/17 01:37:27 INFO ContextCleaner: Cleaned accumulator 97
21/02/17 01:37:27 INFO ContextCleaner: Cleaned accumulator 177
21/02/17 01:37:27 INFO ContextCleaner: Cleaned accumulator 160
21/02/17 01:37:27 INFO ContextCleaner: Cleaned accumulator 205
21/02/17 01:37:27 INFO ContextCleaner: Cleaned accumulator 162
21/02/17 01:37:27 INFO ContextCleaner: Cleaned accumulator 95
21/02/17 01:37:27 INFO ContextCleaner: Cleaned accumulator 147
21/02/17 01:37:27 INFO ContextCleaner: Cleaned accumulator 164
21/02/17 01:37:27 INFO ContextCleaner: Cleaned accumulator 189
21/02/17 01:37:27 INFO ContextCleaner: Cleaned accumulator 113
21/02/17 01:37:27 INFO ContextCleaner: Cleaned accumulator 96
21/02/17 01:37:27 INFO BlockManagerInfo: Removed broadcast_1_piece0 on localhost:38285 in memory (size: 3.2 KB, free: 912.3 MB)
21/02/17 01:37:27 INFO ContextCleaner: Cleaned accumulator 9
21/02/17 01:37:27 INFO ContextCleaner: Cleaned accumulator 71
21/02/17 01:37:27 INFO ContextCleaner: Cleaned accumulator 101
21/02/17 01:37:27 INFO ContextCleaner: Cleaned accumulator 149
21/02/17 01:37:27 INFO ContextCleaner: Cleaned accumulator 83
21/02/17 01:37:27 INFO ContextCleaner: Cleaned accumulator 133
21/02/17 01:37:27 INFO ContextCleaner: Cleaned accumulator 145
21/02/17 01:37:27 INFO ContextCleaner: Cleaned accumulator 14
21/02/17 01:37:27 INFO ContextCleaner: Cleaned accumulator 42
21/02/17 01:37:27 INFO ContextCleaner: Cleaned accumulator 179
21/02/17 01:37:27 INFO ContextCleaner: Cleaned accumulator 2
21/02/17 01:37:27 INFO ContextCleaner: Cleaned accumulator 124
21/02/17 01:37:27 INFO ContextCleaner: Cleaned accumulator 140
21/02/17 01:37:27 INFO ContextCleaner: Cleaned accumulator 18
21/02/17 01:37:27 INFO ContextCleaner: Cleaned accumulator 159
21/02/17 01:37:27 INFO ContextCleaner: Cleaned accumulator 65
21/02/17 01:37:27 INFO ContextCleaner: Cleaned accumulator 12
21/02/17 01:37:27 INFO ContextCleaner: Cleaned accumulator 48
21/02/17 01:37:27 INFO ContextCleaner: Cleaned accumulator 90
21/02/17 01:37:27 INFO ContextCleaner: Cleaned accumulator 19
21/02/17 01:37:27 INFO ContextCleaner: Cleaned accumulator 191
21/02/17 01:37:27 INFO ContextCleaner: Cleaned accumulator 196
21/02/17 01:37:27 INFO ContextCleaner: Cleaned accumulator 173
21/02/17 01:37:27 INFO ContextCleaner: Cleaned accumulator 74
21/02/17 01:37:27 INFO ContextCleaner: Cleaned accumulator 136
21/02/17 01:37:27 INFO ContextCleaner: Cleaned accumulator 67
21/02/17 01:37:27 INFO ContextCleaner: Cleaned accumulator 35
21/02/17 01:37:27 INFO ContextCleaner: Cleaned accumulator 13
21/02/17 01:37:27 INFO ContextCleaner: Cleaned accumulator 152
21/02/17 01:37:27 INFO ContextCleaner: Cleaned accumulator 82
21/02/17 01:37:27 INFO ContextCleaner: Cleaned accumulator 28
21/02/17 01:37:27 INFO ContextCleaner: Cleaned accumulator 190
21/02/17 01:37:27 INFO ContextCleaner: Cleaned accumulator 41
21/02/17 01:37:27 INFO ContextCleaner: Cleaned accumulator 120
21/02/17 01:37:27 INFO BlockManagerInfo: Removed broadcast_6_piece0 on localhost:38285 in memory (size: 3.8 KB, free: 912.3 MB)
21/02/17 01:37:27 INFO ContextCleaner: Cleaned accumulator 3
21/02/17 01:37:27 INFO ContextCleaner: Cleaned accumulator 4
21/02/17 01:37:27 INFO ContextCleaner: Cleaned accumulator 194
21/02/17 01:37:27 INFO ContextCleaner: Cleaned accumulator 62
21/02/17 01:37:27 INFO ContextCleaner: Cleaned accumulator 126
21/02/17 01:37:27 INFO ContextCleaner: Cleaned accumulator 88
21/02/17 01:37:27 INFO ContextCleaner: Cleaned accumulator 197
21/02/17 01:37:27 INFO ContextCleaner: Cleaned accumulator 201
21/02/17 01:37:27 INFO ContextCleaner: Cleaned accumulator 6
21/02/17 01:37:27 INFO ContextCleaner: Cleaned accumulator 155
21/02/17 01:37:27 INFO ContextCleaner: Cleaned accumulator 198
21/02/17 01:37:27 INFO ContextCleaner: Cleaned accumulator 142
21/02/17 01:37:27 INFO ContextCleaner: Cleaned accumulator 170
21/02/17 01:37:27 INFO ContextCleaner: Cleaned accumulator 46
21/02/17 01:37:27 INFO ContextCleaner: Cleaned accumulator 92
21/02/17 01:37:27 INFO ContextCleaner: Cleaned accumulator 134
21/02/17 01:37:27 INFO ContextCleaner: Cleaned accumulator 36
21/02/17 01:37:28 INFO CodeGenerator: Code generated in 46.466691 ms
21/02/17 01:37:28 INFO XGBoostSpark: Running XGBoost 1.1.2 with parameters:
alpha -> 0.0
min_child_weight -> 1.0
sample_type -> uniform
base_score -> 0.5
rabit_timeout -> -1
colsample_bylevel -> 1.0
grow_policy -> depthwise
skip_drop -> 0.0
lambda_bias -> 0.0
silent -> 0
scale_pos_weight -> 1.0
seed -> 0
cache_training_set -> false
features_col -> features
num_early_stopping_rounds -> 0
label_col -> label
num_workers -> 1
subsample -> 1.0
lambda -> 1.0
max_depth -> 6
tree_limit -> 0
custom_eval -> null
dmlc_worker_connect_retry -> 5
rate_drop -> 0.0
max_bin -> 16
train_test_ratio -> 1.0
use_external_memory -> false
objective -> reg:linear
eval_metric -> rmse
num_round -> 1
maximize_evaluation_metrics -> false
timeout_request_workers -> 1800000
missing -> NaN
rabit_ring_reduce_threshold -> 32768
checkpoint_path -> 
tracker_conf -> TrackerConf(0,python)
tree_method -> auto
max_delta_step -> 0.0
eta -> 0.3
verbosity -> 1
colsample_bytree -> 1.0
objective_type -> regression
normalize_type -> tree
allow_non_zero_for_missing -> false
custom_obj -> null
gamma -> 0.0
sketch_eps -> 0.03
nthread -> 1
prediction_col -> prediction
checkpoint_interval -> -1
21/02/17 01:37:28 WARN XGBoostSpark: train_test_ratio is deprecated since XGBoost 0.82, we recommend to explicitly pass a training and multiple evaluation datasets by passing 'eval_sets' and 'eval_set_names'
21/02/17 01:37:28 INFO RabitTracker$TrackerProcessLogger: 2021-02-17 01:37:28,629 INFO start listen on 192.168.2.12:9091
21/02/17 01:37:28 INFO XGBoostSpark: starting training with timeout set as 1800000 ms for waiting for resources
21/02/17 01:37:28 INFO SparkContext: Starting job: foreachPartition at XGBoost.scala:565
21/02/17 01:37:28 INFO DAGScheduler: Got job 5 (foreachPartition at XGBoost.scala:565) with 1 output partitions
21/02/17 01:37:28 INFO DAGScheduler: Final stage: ResultStage 7 (foreachPartition at XGBoost.scala:565)
21/02/17 01:37:28 INFO DAGScheduler: Parents of final stage: List()
21/02/17 01:37:28 INFO DAGScheduler: Missing parents: List()
21/02/17 01:37:28 INFO DAGScheduler: Submitting ResultStage 7 (MapPartitionsRDD[35] at mapPartitions at XGBoost.scala:450), which has no missing parents
21/02/17 01:37:28 INFO MemoryStore: Block broadcast_7 stored as values in memory (estimated size 33.9 KB, free 912.3 MB)
21/02/17 01:37:28 INFO MemoryStore: Block broadcast_7_piece0 stored as bytes in memory (estimated size 14.2 KB, free 912.3 MB)
21/02/17 01:37:28 INFO BlockManagerInfo: Added broadcast_7_piece0 in memory on localhost:38285 (size: 14.2 KB, free: 912.3 MB)
21/02/17 01:37:28 INFO SparkContext: Created broadcast 7 from broadcast at DAGScheduler.scala:1039
21/02/17 01:37:28 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 7 (MapPartitionsRDD[35] at mapPartitions at XGBoost.scala:450) (first 15 tasks are for partitions Vector(0))
21/02/17 01:37:28 INFO TaskSchedulerImpl: Adding task set 7.0 with 1 tasks
21/02/17 01:37:28 INFO TaskSetManager: Starting task 0.0 in stage 7.0 (TID 7, localhost, executor driver, partition 0, PROCESS_LOCAL, 18998 bytes)
21/02/17 01:37:28 INFO Executor: Running task 0.0 in stage 7.0 (TID 7)
21/02/17 01:37:28 INFO CodeGenerator: Code generated in 11.353614 ms
21/02/17 01:37:28 INFO MemoryStore: Block rdd_17_0 stored as values in memory (estimated size 5.6 KB, free 912.2 MB)
21/02/17 01:37:28 INFO BlockManagerInfo: Added rdd_17_0 in memory on localhost:38285 (size: 5.6 KB, free: 912.3 MB)
21/02/17 01:37:28 INFO CodeGenerator: Code generated in 3.786473 ms
21/02/17 01:37:28 INFO CodeGenerator: Code generated in 19.05726 ms
21/02/17 01:37:28 INFO CodeGenerator: Code generated in 6.931425 ms
21/02/17 01:37:28 INFO RabitTracker$TrackerProcessLogger: /tmp/tracker5019776109654939288.py:330: DeprecationWarning: isAlive() is deprecated, use is_alive() instead
21/02/17 01:37:28 INFO RabitTracker$TrackerProcessLogger:   while self.thread.isAlive():
21/02/17 01:37:28 INFO RabitTracker$TrackerProcessLogger: 2021-02-17 01:37:28,897 DEBUG Recieve start signal from 192.168.2.12; assign rank 0
21/02/17 01:37:28 INFO RabitTracker$TrackerProcessLogger: 2021-02-17 01:37:28,897 INFO @tracker All of 1 nodes getting started
21/02/17 01:37:28 INFO RabitTracker$TrackerProcessLogger: 2021-02-17 01:37:28,905 INFO [0]	train-rmse:2.633044
21/02/17 01:37:28 INFO RabitTracker$TrackerProcessLogger: 2021-02-17 01:37:28,906 DEBUG Recieve shutdown signal from 0
21/02/17 01:37:28 INFO RabitTracker$TrackerProcessLogger: 2021-02-17 01:37:28,906 INFO @tracker All nodes finishes job
21/02/17 01:37:28 INFO RabitTracker$TrackerProcessLogger: 2021-02-17 01:37:28,906 INFO @tracker 0.009276151657104492 secs between node start and job finish
21/02/17 01:37:28 INFO MemoryStore: Block rdd_35_0 stored as values in memory (estimated size 192.0 B, free 912.2 MB)
21/02/17 01:37:28 INFO BlockManagerInfo: Added rdd_35_0 in memory on localhost:38285 (size: 192.0 B, free: 912.3 MB)
21/02/17 01:37:28 INFO RabitTracker$TrackerProcessLogger: Tracker Process ends with exit code 0
21/02/17 01:37:28 INFO RabitTracker: Tracker Process ends with exit code 0
21/02/17 01:37:28 INFO XGBoostSpark: Rabit returns with exit code 0
21/02/17 01:37:28 INFO Executor: 1 block locks were not released by TID = 7:
[rdd_35_0]
21/02/17 01:37:28 INFO Executor: Finished task 0.0 in stage 7.0 (TID 7). 1303 bytes result sent to driver
21/02/17 01:37:28 INFO TaskSetManager: Finished task 0.0 in stage 7.0 (TID 7) in 215 ms on localhost (executor driver) (1/1)
21/02/17 01:37:28 INFO TaskSchedulerImpl: Removed TaskSet 7.0, whose tasks have all completed, from pool 
21/02/17 01:37:28 INFO DAGScheduler: ResultStage 7 (foreachPartition at XGBoost.scala:565) finished in 0.258 s
21/02/17 01:37:28 INFO DAGScheduler: Job 5 finished: foreachPartition at XGBoost.scala:565, took 0.263395 s
21/02/17 01:37:28 INFO SparkContext: Starting job: first at XGBoost.scala:685
21/02/17 01:37:28 INFO DAGScheduler: Got job 6 (first at XGBoost.scala:685) with 1 output partitions
21/02/17 01:37:28 INFO DAGScheduler: Final stage: ResultStage 8 (first at XGBoost.scala:685)
21/02/17 01:37:28 INFO DAGScheduler: Parents of final stage: List()
21/02/17 01:37:28 INFO DAGScheduler: Missing parents: List()
21/02/17 01:37:28 INFO DAGScheduler: Submitting ResultStage 8 (MapPartitionsRDD[35] at mapPartitions at XGBoost.scala:450), which has no missing parents
21/02/17 01:37:28 INFO MemoryStore: Block broadcast_8 stored as values in memory (estimated size 34.0 KB, free 912.2 MB)
21/02/17 01:37:28 INFO MemoryStore: Block broadcast_8_piece0 stored as bytes in memory (estimated size 14.3 KB, free 912.2 MB)
21/02/17 01:37:28 INFO BlockManagerInfo: Added broadcast_8_piece0 in memory on localhost:38285 (size: 14.3 KB, free: 912.3 MB)
21/02/17 01:37:28 INFO SparkContext: Created broadcast 8 from broadcast at DAGScheduler.scala:1039
21/02/17 01:37:28 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 8 (MapPartitionsRDD[35] at mapPartitions at XGBoost.scala:450) (first 15 tasks are for partitions Vector(0))
21/02/17 01:37:28 INFO TaskSchedulerImpl: Adding task set 8.0 with 1 tasks
21/02/17 01:37:28 INFO TaskSetManager: Starting task 0.0 in stage 8.0 (TID 8, localhost, executor driver, partition 0, PROCESS_LOCAL, 18998 bytes)
21/02/17 01:37:28 INFO Executor: Running task 0.0 in stage 8.0 (TID 8)
21/02/17 01:37:28 INFO BlockManager: Found block rdd_35_0 locally
21/02/17 01:37:28 INFO Executor: 1 block locks were not released by TID = 8:
[rdd_35_0]
21/02/17 01:37:28 INFO Executor: Finished task 0.0 in stage 8.0 (TID 8). 2551 bytes result sent to driver
21/02/17 01:37:28 INFO TaskSetManager: Finished task 0.0 in stage 8.0 (TID 8) in 13 ms on localhost (executor driver) (1/1)
21/02/17 01:37:28 INFO TaskSchedulerImpl: Removed TaskSet 8.0, whose tasks have all completed, from pool 
21/02/17 01:37:28 INFO DAGScheduler: ResultStage 8 (first at XGBoost.scala:685) finished in 0.022 s
21/02/17 01:37:28 INFO DAGScheduler: Job 6 finished: first at XGBoost.scala:685, took 0.025435 s
21/02/17 01:37:28 INFO MapPartitionsRDD: Removing RDD 35 from persistence list
21/02/17 01:37:28 INFO BlockManager: Removing RDD 35
21/02/17 01:37:29 INFO MemoryStore: Block broadcast_9 stored as values in memory (estimated size 64.0 B, free 912.2 MB)
21/02/17 01:37:29 INFO MemoryStore: Block broadcast_9_piece0 stored as bytes in memory (estimated size 510.0 B, free 912.2 MB)
21/02/17 01:37:29 INFO BlockManagerInfo: Added broadcast_9_piece0 in memory on localhost:38285 (size: 510.0 B, free: 912.3 MB)
21/02/17 01:37:29 INFO SparkContext: Created broadcast 9 from broadcast at XGBoostRegressor.scala:271
21/02/17 01:37:29 INFO CodeGenerator: Code generated in 30.380241 ms
21/02/17 01:37:29 INFO CodeGenerator: Code generated in 6.345775 ms
21/02/17 01:37:29 INFO CodeGenerator: Code generated in 5.631477 ms
21/02/17 01:37:29 INFO SparkContext: Starting job: collect at utils.scala:135
21/02/17 01:37:29 INFO DAGScheduler: Got job 7 (collect at utils.scala:135) with 1 output partitions
21/02/17 01:37:29 INFO DAGScheduler: Final stage: ResultStage 9 (collect at utils.scala:135)
21/02/17 01:37:29 INFO DAGScheduler: Parents of final stage: List()
21/02/17 01:37:29 INFO DAGScheduler: Missing parents: List()
21/02/17 01:37:29 INFO DAGScheduler: Submitting ResultStage 9 (MapPartitionsRDD[46] at collect at utils.scala:135), which has no missing parents
21/02/17 01:37:29 INFO MemoryStore: Block broadcast_10 stored as values in memory (estimated size 6.5 KB, free 912.2 MB)
21/02/17 01:37:29 INFO MemoryStore: Block broadcast_10_piece0 stored as bytes in memory (estimated size 3.2 KB, free 912.2 MB)
21/02/17 01:37:29 INFO BlockManagerInfo: Added broadcast_10_piece0 in memory on localhost:38285 (size: 3.2 KB, free: 912.3 MB)
21/02/17 01:37:29 INFO SparkContext: Created broadcast 10 from broadcast at DAGScheduler.scala:1039
21/02/17 01:37:29 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 9 (MapPartitionsRDD[46] at collect at utils.scala:135) (first 15 tasks are for partitions Vector(0))
21/02/17 01:37:29 INFO TaskSchedulerImpl: Adding task set 9.0 with 1 tasks
21/02/17 01:37:29 INFO TaskSetManager: Starting task 0.0 in stage 9.0 (TID 9, localhost, executor driver, partition 0, PROCESS_LOCAL, 8067 bytes)
21/02/17 01:37:29 INFO Executor: Running task 0.0 in stage 9.0 (TID 9)
21/02/17 01:37:29 INFO Executor: Finished task 0.0 in stage 9.0 (TID 9). 1243 bytes result sent to driver
21/02/17 01:37:29 INFO TaskSetManager: Finished task 0.0 in stage 9.0 (TID 9) in 5 ms on localhost (executor driver) (1/1)
21/02/17 01:37:29 INFO TaskSchedulerImpl: Removed TaskSet 9.0, whose tasks have all completed, from pool 
21/02/17 01:37:29 INFO DAGScheduler: ResultStage 9 (collect at utils.scala:135) finished in 0.010 s
21/02/17 01:37:29 INFO DAGScheduler: Job 7 finished: collect at utils.scala:135, took 0.011452 s
21/02/17 01:37:29 INFO SparkContext: Starting job: count at utils.scala:135
21/02/17 01:37:29 INFO DAGScheduler: Registering RDD 49 (count at utils.scala:135)
21/02/17 01:37:29 INFO DAGScheduler: Got job 8 (count at utils.scala:135) with 1 output partitions
21/02/17 01:37:29 INFO DAGScheduler: Final stage: ResultStage 11 (count at utils.scala:135)
21/02/17 01:37:29 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 10)
21/02/17 01:37:29 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 10)
21/02/17 01:37:29 INFO DAGScheduler: Submitting ShuffleMapStage 10 (MapPartitionsRDD[49] at count at utils.scala:135), which has no missing parents
21/02/17 01:37:29 INFO MemoryStore: Block broadcast_11 stored as values in memory (estimated size 8.9 KB, free 912.2 MB)
21/02/17 01:37:29 INFO MemoryStore: Block broadcast_11_piece0 stored as bytes in memory (estimated size 4.5 KB, free 912.2 MB)
21/02/17 01:37:29 INFO BlockManagerInfo: Added broadcast_11_piece0 in memory on localhost:38285 (size: 4.5 KB, free: 912.3 MB)
21/02/17 01:37:29 INFO SparkContext: Created broadcast 11 from broadcast at DAGScheduler.scala:1039
21/02/17 01:37:29 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 10 (MapPartitionsRDD[49] at count at utils.scala:135) (first 15 tasks are for partitions Vector(0))
21/02/17 01:37:29 INFO TaskSchedulerImpl: Adding task set 10.0 with 1 tasks
21/02/17 01:37:29 INFO TaskSetManager: Starting task 0.0 in stage 10.0 (TID 10, localhost, executor driver, partition 0, PROCESS_LOCAL, 8056 bytes)
21/02/17 01:37:29 INFO Executor: Running task 0.0 in stage 10.0 (TID 10)
21/02/17 01:37:29 INFO Executor: Finished task 0.0 in stage 10.0 (TID 10). 1499 bytes result sent to driver
21/02/17 01:37:29 INFO TaskSetManager: Finished task 0.0 in stage 10.0 (TID 10) in 6 ms on localhost (executor driver) (1/1)
21/02/17 01:37:29 INFO TaskSchedulerImpl: Removed TaskSet 10.0, whose tasks have all completed, from pool 
21/02/17 01:37:29 INFO DAGScheduler: ShuffleMapStage 10 (count at utils.scala:135) finished in 0.013 s
21/02/17 01:37:29 INFO DAGScheduler: looking for newly runnable stages
21/02/17 01:37:29 INFO DAGScheduler: running: Set()
21/02/17 01:37:29 INFO DAGScheduler: waiting: Set(ResultStage 11)
21/02/17 01:37:29 INFO DAGScheduler: failed: Set()
21/02/17 01:37:29 INFO DAGScheduler: Submitting ResultStage 11 (MapPartitionsRDD[52] at count at utils.scala:135), which has no missing parents
21/02/17 01:37:29 INFO MemoryStore: Block broadcast_12 stored as values in memory (estimated size 7.3 KB, free 912.2 MB)
21/02/17 01:37:29 INFO MemoryStore: Block broadcast_12_piece0 stored as bytes in memory (estimated size 3.8 KB, free 912.2 MB)
21/02/17 01:37:29 INFO BlockManagerInfo: Added broadcast_12_piece0 in memory on localhost:38285 (size: 3.8 KB, free: 912.3 MB)
21/02/17 01:37:29 INFO SparkContext: Created broadcast 12 from broadcast at DAGScheduler.scala:1039
21/02/17 01:37:29 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 11 (MapPartitionsRDD[52] at count at utils.scala:135) (first 15 tasks are for partitions Vector(0))
21/02/17 01:37:29 INFO TaskSchedulerImpl: Adding task set 11.0 with 1 tasks
21/02/17 01:37:29 INFO TaskSetManager: Starting task 0.0 in stage 11.0 (TID 11, localhost, executor driver, partition 0, NODE_LOCAL, 7754 bytes)
21/02/17 01:37:29 INFO Executor: Running task 0.0 in stage 11.0 (TID 11)
21/02/17 01:37:29 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
21/02/17 01:37:29 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
21/02/17 01:37:29 INFO Executor: Finished task 0.0 in stage 11.0 (TID 11). 1782 bytes result sent to driver
21/02/17 01:37:29 INFO TaskSetManager: Finished task 0.0 in stage 11.0 (TID 11) in 5 ms on localhost (executor driver) (1/1)
21/02/17 01:37:29 INFO TaskSchedulerImpl: Removed TaskSet 11.0, whose tasks have all completed, from pool 
21/02/17 01:37:29 INFO DAGScheduler: ResultStage 11 (count at utils.scala:135) finished in 0.011 s
21/02/17 01:37:29 INFO DAGScheduler: Job 8 finished: count at utils.scala:135, took 0.027015 s
21/02/17 01:37:29 INFO CodeGenerator: Code generated in 7.311467 ms
21/02/17 01:37:29 INFO CodeGenerator: Code generated in 9.704685 ms
21/02/17 01:37:29 INFO SparkContext: Starting job: collect at utils.scala:135
21/02/17 01:37:29 INFO DAGScheduler: Got job 9 (collect at utils.scala:135) with 1 output partitions
21/02/17 01:37:29 INFO DAGScheduler: Final stage: ResultStage 12 (collect at utils.scala:135)
21/02/17 01:37:29 INFO DAGScheduler: Parents of final stage: List()
21/02/17 01:37:29 INFO DAGScheduler: Missing parents: List()
21/02/17 01:37:29 INFO DAGScheduler: Submitting ResultStage 12 (MapPartitionsRDD[55] at collect at utils.scala:135), which has no missing parents
21/02/17 01:37:29 INFO MemoryStore: Block broadcast_13 stored as values in memory (estimated size 61.1 KB, free 912.1 MB)
21/02/17 01:37:29 INFO MemoryStore: Block broadcast_13_piece0 stored as bytes in memory (estimated size 25.4 KB, free 912.1 MB)
21/02/17 01:37:29 INFO BlockManagerInfo: Added broadcast_13_piece0 in memory on localhost:38285 (size: 25.4 KB, free: 912.2 MB)
21/02/17 01:37:29 INFO SparkContext: Created broadcast 13 from broadcast at DAGScheduler.scala:1039
21/02/17 01:37:29 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 12 (MapPartitionsRDD[55] at collect at utils.scala:135) (first 15 tasks are for partitions Vector(0))
21/02/17 01:37:29 INFO TaskSchedulerImpl: Adding task set 12.0 with 1 tasks
21/02/17 01:37:29 INFO TaskSetManager: Starting task 0.0 in stage 12.0 (TID 12, localhost, executor driver, partition 0, PROCESS_LOCAL, 18998 bytes)
21/02/17 01:37:29 INFO Executor: Running task 0.0 in stage 12.0 (TID 12)
21/02/17 01:37:29 INFO BlockManager: Found block rdd_17_0 locally
21/02/17 01:37:29 INFO CodeGenerator: Code generated in 11.384911 ms
21/02/17 01:37:29 INFO CodeGenerator: Code generated in 19.273336 ms
21/02/17 01:37:30 INFO CodeGenerator: Code generated in 46.514349 ms
21/02/17 01:37:30 INFO Executor: Finished task 0.0 in stage 12.0 (TID 12). 1815 bytes result sent to driver
21/02/17 01:37:30 INFO TaskSetManager: Finished task 0.0 in stage 12.0 (TID 12) in 143 ms on localhost (executor driver) (1/1)
21/02/17 01:37:30 INFO TaskSchedulerImpl: Removed TaskSet 12.0, whose tasks have all completed, from pool 
21/02/17 01:37:30 INFO DAGScheduler: ResultStage 12 (collect at utils.scala:135) finished in 0.152 s
21/02/17 01:37:30 INFO DAGScheduler: Job 9 finished: collect at utils.scala:135, took 0.154521 s
21/02/17 01:37:30 INFO CodeGenerator: Code generated in 8.802105 ms
21/02/17 01:37:30 INFO SparkContext: Starting job: count at utils.scala:135
21/02/17 01:37:30 INFO DAGScheduler: Registering RDD 58 (count at utils.scala:135)
21/02/17 01:37:30 INFO DAGScheduler: Got job 10 (count at utils.scala:135) with 1 output partitions
21/02/17 01:37:30 INFO DAGScheduler: Final stage: ResultStage 14 (count at utils.scala:135)
21/02/17 01:37:30 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 13)
21/02/17 01:37:30 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 13)
21/02/17 01:37:30 INFO DAGScheduler: Submitting ShuffleMapStage 13 (MapPartitionsRDD[58] at count at utils.scala:135), which has no missing parents
21/02/17 01:37:30 INFO MemoryStore: Block broadcast_14 stored as values in memory (estimated size 62.0 KB, free 912.0 MB)
21/02/17 01:37:30 INFO MemoryStore: Block broadcast_14_piece0 stored as bytes in memory (estimated size 25.9 KB, free 912.0 MB)
21/02/17 01:37:30 INFO BlockManagerInfo: Added broadcast_14_piece0 in memory on localhost:38285 (size: 25.9 KB, free: 912.2 MB)
21/02/17 01:37:30 INFO SparkContext: Created broadcast 14 from broadcast at DAGScheduler.scala:1039
21/02/17 01:37:30 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 13 (MapPartitionsRDD[58] at count at utils.scala:135) (first 15 tasks are for partitions Vector(0))
21/02/17 01:37:30 INFO TaskSchedulerImpl: Adding task set 13.0 with 1 tasks
21/02/17 01:37:30 INFO TaskSetManager: Starting task 0.0 in stage 13.0 (TID 13, localhost, executor driver, partition 0, PROCESS_LOCAL, 18987 bytes)
21/02/17 01:37:30 INFO Executor: Running task 0.0 in stage 13.0 (TID 13)
21/02/17 01:37:30 INFO BlockManager: Found block rdd_17_0 locally
21/02/17 01:37:30 INFO Executor: Finished task 0.0 in stage 13.0 (TID 13). 1933 bytes result sent to driver
21/02/17 01:37:30 INFO TaskSetManager: Finished task 0.0 in stage 13.0 (TID 13) in 33 ms on localhost (executor driver) (1/1)
21/02/17 01:37:30 INFO TaskSchedulerImpl: Removed TaskSet 13.0, whose tasks have all completed, from pool 
21/02/17 01:37:30 INFO DAGScheduler: ShuffleMapStage 13 (count at utils.scala:135) finished in 0.041 s
21/02/17 01:37:30 INFO DAGScheduler: looking for newly runnable stages
21/02/17 01:37:30 INFO DAGScheduler: running: Set()
21/02/17 01:37:30 INFO DAGScheduler: waiting: Set(ResultStage 14)
21/02/17 01:37:30 INFO DAGScheduler: failed: Set()
21/02/17 01:37:30 INFO DAGScheduler: Submitting ResultStage 14 (MapPartitionsRDD[61] at count at utils.scala:135), which has no missing parents
21/02/17 01:37:30 INFO MemoryStore: Block broadcast_15 stored as values in memory (estimated size 7.3 KB, free 912.0 MB)
21/02/17 01:37:30 INFO MemoryStore: Block broadcast_15_piece0 stored as bytes in memory (estimated size 3.8 KB, free 912.0 MB)
21/02/17 01:37:30 INFO BlockManagerInfo: Added broadcast_15_piece0 in memory on localhost:38285 (size: 3.8 KB, free: 912.2 MB)
21/02/17 01:37:30 INFO SparkContext: Created broadcast 15 from broadcast at DAGScheduler.scala:1039
21/02/17 01:37:30 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 14 (MapPartitionsRDD[61] at count at utils.scala:135) (first 15 tasks are for partitions Vector(0))
21/02/17 01:37:30 INFO TaskSchedulerImpl: Adding task set 14.0 with 1 tasks
21/02/17 01:37:30 INFO TaskSetManager: Starting task 0.0 in stage 14.0 (TID 14, localhost, executor driver, partition 0, NODE_LOCAL, 7754 bytes)
21/02/17 01:37:30 INFO Executor: Running task 0.0 in stage 14.0 (TID 14)
21/02/17 01:37:30 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
21/02/17 01:37:30 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
21/02/17 01:37:30 INFO Executor: Finished task 0.0 in stage 14.0 (TID 14). 1782 bytes result sent to driver
21/02/17 01:37:30 INFO TaskSetManager: Finished task 0.0 in stage 14.0 (TID 14) in 4 ms on localhost (executor driver) (1/1)
21/02/17 01:37:30 INFO TaskSchedulerImpl: Removed TaskSet 14.0, whose tasks have all completed, from pool 
21/02/17 01:37:30 INFO DAGScheduler: ResultStage 14 (count at utils.scala:135) finished in 0.009 s
21/02/17 01:37:30 INFO DAGScheduler: Job 10 finished: count at utils.scala:135, took 0.053857 s
21/02/17 01:37:30 INFO deprecation: mapred.output.dir is deprecated. Instead, use mapreduce.output.fileoutputformat.outputdir
21/02/17 01:37:30 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
21/02/17 01:37:30 INFO SparkContext: Starting job: runJob at SparkHadoopWriter.scala:78
21/02/17 01:37:30 INFO DAGScheduler: Got job 11 (runJob at SparkHadoopWriter.scala:78) with 1 output partitions
21/02/17 01:37:30 INFO DAGScheduler: Final stage: ResultStage 15 (runJob at SparkHadoopWriter.scala:78)
21/02/17 01:37:30 INFO DAGScheduler: Parents of final stage: List()
21/02/17 01:37:30 INFO DAGScheduler: Missing parents: List()
21/02/17 01:37:30 INFO DAGScheduler: Submitting ResultStage 15 (MapPartitionsRDD[63] at saveAsTextFile at ReadWrite.scala:283), which has no missing parents
21/02/17 01:37:30 INFO MemoryStore: Block broadcast_16 stored as values in memory (estimated size 71.0 KB, free 911.9 MB)
21/02/17 01:37:30 INFO MemoryStore: Block broadcast_16_piece0 stored as bytes in memory (estimated size 25.3 KB, free 911.9 MB)
21/02/17 01:37:30 INFO BlockManagerInfo: Added broadcast_16_piece0 in memory on localhost:38285 (size: 25.3 KB, free: 912.2 MB)
21/02/17 01:37:30 INFO SparkContext: Created broadcast 16 from broadcast at DAGScheduler.scala:1039
21/02/17 01:37:30 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 15 (MapPartitionsRDD[63] at saveAsTextFile at ReadWrite.scala:283) (first 15 tasks are for partitions Vector(0))
21/02/17 01:37:30 INFO TaskSchedulerImpl: Adding task set 15.0 with 1 tasks
21/02/17 01:37:30 INFO TaskSetManager: Starting task 0.0 in stage 15.0 (TID 15, localhost, executor driver, partition 0, PROCESS_LOCAL, 8142 bytes)
21/02/17 01:37:30 INFO Executor: Running task 0.0 in stage 15.0 (TID 15)
21/02/17 01:37:30 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
21/02/17 01:37:30 INFO FileOutputCommitter: Saved output of task 'attempt_20210217013730_0063_m_000000_0' to file:/tmp/RtmpAwg72U/file2273e1dcb2db/metadata/_temporary/0/task_20210217013730_0063_m_000000
21/02/17 01:37:30 INFO SparkHadoopMapRedUtil: attempt_20210217013730_0063_m_000000_0: Committed
21/02/17 01:37:30 INFO Executor: Finished task 0.0 in stage 15.0 (TID 15). 1072 bytes result sent to driver
21/02/17 01:37:30 INFO TaskSetManager: Finished task 0.0 in stage 15.0 (TID 15) in 42 ms on localhost (executor driver) (1/1)
21/02/17 01:37:30 INFO TaskSchedulerImpl: Removed TaskSet 15.0, whose tasks have all completed, from pool 
21/02/17 01:37:30 INFO DAGScheduler: ResultStage 15 (runJob at SparkHadoopWriter.scala:78) finished in 0.052 s
21/02/17 01:37:30 INFO DAGScheduler: Job 11 finished: runJob at SparkHadoopWriter.scala:78, took 0.054330 s
21/02/17 01:37:30 INFO SparkHadoopWriter: Job job_20210217013730_0063 committed.
21/02/17 01:37:30 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
21/02/17 01:37:30 INFO SparkContext: Starting job: runJob at SparkHadoopWriter.scala:78
21/02/17 01:37:30 INFO DAGScheduler: Got job 12 (runJob at SparkHadoopWriter.scala:78) with 1 output partitions
21/02/17 01:37:30 INFO DAGScheduler: Final stage: ResultStage 16 (runJob at SparkHadoopWriter.scala:78)
21/02/17 01:37:30 INFO DAGScheduler: Parents of final stage: List()
21/02/17 01:37:30 INFO DAGScheduler: Missing parents: List()
21/02/17 01:37:30 INFO DAGScheduler: Submitting ResultStage 16 (MapPartitionsRDD[65] at saveAsTextFile at ReadWrite.scala:283), which has no missing parents
21/02/17 01:37:30 INFO MemoryStore: Block broadcast_17 stored as values in memory (estimated size 71.1 KB, free 911.8 MB)
21/02/17 01:37:30 INFO MemoryStore: Block broadcast_17_piece0 stored as bytes in memory (estimated size 25.4 KB, free 911.8 MB)
21/02/17 01:37:30 INFO BlockManagerInfo: Added broadcast_17_piece0 in memory on localhost:38285 (size: 25.4 KB, free: 912.2 MB)
21/02/17 01:37:30 INFO SparkContext: Created broadcast 17 from broadcast at DAGScheduler.scala:1039
21/02/17 01:37:30 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 16 (MapPartitionsRDD[65] at saveAsTextFile at ReadWrite.scala:283) (first 15 tasks are for partitions Vector(0))
21/02/17 01:37:30 INFO TaskSchedulerImpl: Adding task set 16.0 with 1 tasks
21/02/17 01:37:30 INFO TaskSetManager: Starting task 0.0 in stage 16.0 (TID 16, localhost, executor driver, partition 0, PROCESS_LOCAL, 8216 bytes)
21/02/17 01:37:30 INFO Executor: Running task 0.0 in stage 16.0 (TID 16)
21/02/17 01:37:30 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
21/02/17 01:37:30 INFO FileOutputCommitter: Saved output of task 'attempt_20210217013730_0065_m_000000_0' to file:/tmp/RtmpAwg72U/file2273e1dcb2db/stages/0_r_formula__d1af6ac8_fb81_4178_b8f7_d931e3812fd8/metadata/_temporary/0/task_20210217013730_0065_m_000000
21/02/17 01:37:30 INFO SparkHadoopMapRedUtil: attempt_20210217013730_0065_m_000000_0: Committed
21/02/17 01:37:30 INFO Executor: Finished task 0.0 in stage 16.0 (TID 16). 1029 bytes result sent to driver
21/02/17 01:37:30 INFO TaskSetManager: Finished task 0.0 in stage 16.0 (TID 16) in 19 ms on localhost (executor driver) (1/1)
21/02/17 01:37:30 INFO TaskSchedulerImpl: Removed TaskSet 16.0, whose tasks have all completed, from pool 
21/02/17 01:37:30 INFO DAGScheduler: ResultStage 16 (runJob at SparkHadoopWriter.scala:78) finished in 0.032 s
21/02/17 01:37:30 INFO DAGScheduler: Job 12 finished: runJob at SparkHadoopWriter.scala:78, took 0.033873 s
21/02/17 01:37:30 INFO SparkHadoopWriter: Job job_20210217013730_0065 committed.
21/02/17 01:37:30 INFO ContextCleaner: Cleaned accumulator 482
21/02/17 01:37:30 INFO BlockManagerInfo: Removed broadcast_16_piece0 on localhost:38285 in memory (size: 25.3 KB, free: 912.2 MB)
21/02/17 01:37:30 INFO ContextCleaner: Cleaned accumulator 490
21/02/17 01:37:30 INFO ContextCleaner: Cleaned accumulator 499
21/02/17 01:37:30 INFO ContextCleaner: Cleaned accumulator 300
21/02/17 01:37:30 INFO ContextCleaner: Cleaned accumulator 346
21/02/17 01:37:30 INFO ContextCleaner: Cleaned accumulator 431
21/02/17 01:37:30 INFO ContextCleaner: Cleaned accumulator 322
21/02/17 01:37:30 INFO ContextCleaner: Cleaned accumulator 273
21/02/17 01:37:30 INFO ContextCleaner: Cleaned accumulator 469
21/02/17 01:37:30 INFO ContextCleaner: Cleaned accumulator 501
21/02/17 01:37:30 INFO ContextCleaner: Cleaned accumulator 287
21/02/17 01:37:30 INFO ContextCleaner: Cleaned accumulator 434
21/02/17 01:37:30 INFO ContextCleaner: Cleaned accumulator 280
21/02/17 01:37:30 INFO ContextCleaner: Cleaned accumulator 471
21/02/17 01:37:30 INFO ContextCleaner: Cleaned accumulator 382
21/02/17 01:37:30 INFO ContextCleaner: Cleaned accumulator 332
21/02/17 01:37:30 INFO ContextCleaner: Cleaned accumulator 333
21/02/17 01:37:30 INFO ContextCleaner: Cleaned accumulator 269
21/02/17 01:37:30 INFO ContextCleaner: Cleaned accumulator 369
21/02/17 01:37:30 INFO ContextCleaner: Cleaned accumulator 386
21/02/17 01:37:30 INFO ContextCleaner: Cleaned accumulator 219
21/02/17 01:37:30 INFO ContextCleaner: Cleaned accumulator 212
21/02/17 01:37:30 INFO ContextCleaner: Cleaned accumulator 460
21/02/17 01:37:30 INFO ContextCleaner: Cleaned accumulator 420
21/02/17 01:37:30 INFO ContextCleaner: Cleaned accumulator 235
21/02/17 01:37:30 INFO ContextCleaner: Cleaned accumulator 496
21/02/17 01:37:30 INFO ContextCleaner: Cleaned accumulator 418
21/02/17 01:37:30 INFO ContextCleaner: Cleaned accumulator 233
21/02/17 01:37:30 INFO ContextCleaner: Cleaned accumulator 256
21/02/17 01:37:30 INFO ContextCleaner: Cleaned accumulator 488
21/02/17 01:37:30 INFO ContextCleaner: Cleaned accumulator 224
21/02/17 01:37:30 INFO ContextCleaner: Cleaned accumulator 473
21/02/17 01:37:30 INFO ContextCleaner: Cleaned accumulator 363
21/02/17 01:37:30 INFO ContextCleaner: Cleaned accumulator 381
21/02/17 01:37:30 INFO ContextCleaner: Cleaned accumulator 255
21/02/17 01:37:30 INFO ContextCleaner: Cleaned accumulator 295
21/02/17 01:37:30 INFO ContextCleaner: Cleaned accumulator 291
21/02/17 01:37:30 INFO ContextCleaner: Cleaned accumulator 236
21/02/17 01:37:30 INFO ContextCleaner: Cleaned accumulator 260
21/02/17 01:37:30 INFO ContextCleaner: Cleaned accumulator 270
21/02/17 01:37:30 INFO ContextCleaner: Cleaned accumulator 416
21/02/17 01:37:30 INFO ContextCleaner: Cleaned accumulator 303
21/02/17 01:37:30 INFO ContextCleaner: Cleaned accumulator 436
21/02/17 01:37:30 INFO ContextCleaner: Cleaned accumulator 347
21/02/17 01:37:30 INFO ContextCleaner: Cleaned accumulator 435
21/02/17 01:37:30 INFO ContextCleaner: Cleaned accumulator 423
21/02/17 01:37:30 INFO BlockManagerInfo: Removed broadcast_7_piece0 on localhost:38285 in memory (size: 14.2 KB, free: 912.2 MB)
21/02/17 01:37:30 INFO ContextCleaner: Cleaned accumulator 343
21/02/17 01:37:30 INFO ContextCleaner: Cleaned accumulator 443
21/02/17 01:37:30 INFO ContextCleaner: Cleaned accumulator 315
21/02/17 01:37:30 INFO ContextCleaner: Cleaned accumulator 406
21/02/17 01:37:30 INFO ContextCleaner: Cleaned accumulator 301
21/02/17 01:37:30 INFO ContextCleaner: Cleaned accumulator 408
21/02/17 01:37:30 INFO ContextCleaner: Cleaned shuffle 2
21/02/17 01:37:30 INFO ContextCleaner: Cleaned accumulator 338
21/02/17 01:37:30 INFO ContextCleaner: Cleaned accumulator 388
21/02/17 01:37:30 INFO ContextCleaner: Cleaned accumulator 470
21/02/17 01:37:30 INFO ContextCleaner: Cleaned accumulator 454
21/02/17 01:37:30 INFO ContextCleaner: Cleaned accumulator 312
21/02/17 01:37:30 INFO ContextCleaner: Cleaned accumulator 377
21/02/17 01:37:30 INFO ContextCleaner: Cleaned accumulator 218
21/02/17 01:37:30 INFO ContextCleaner: Cleaned accumulator 230
21/02/17 01:37:30 INFO ContextCleaner: Cleaned accumulator 302
21/02/17 01:37:30 INFO ContextCleaner: Cleaned accumulator 453
21/02/17 01:37:30 INFO ContextCleaner: Cleaned accumulator 395
21/02/17 01:37:30 INFO ContextCleaner: Cleaned accumulator 379
21/02/17 01:37:30 INFO ContextCleaner: Cleaned accumulator 445
21/02/17 01:37:30 INFO ContextCleaner: Cleaned accumulator 427
21/02/17 01:37:30 INFO ContextCleaner: Cleaned accumulator 457
21/02/17 01:37:30 INFO ContextCleaner: Cleaned accumulator 297
21/02/17 01:37:30 INFO ContextCleaner: Cleaned accumulator 278
21/02/17 01:37:30 INFO ContextCleaner: Cleaned accumulator 356
21/02/17 01:37:30 INFO ContextCleaner: Cleaned accumulator 421
21/02/17 01:37:30 INFO ContextCleaner: Cleaned accumulator 290
21/02/17 01:37:30 INFO ContextCleaner: Cleaned accumulator 304
21/02/17 01:37:30 INFO ContextCleaner: Cleaned accumulator 374
21/02/17 01:37:30 INFO ContextCleaner: Cleaned accumulator 414
21/02/17 01:37:30 INFO ContextCleaner: Cleaned accumulator 350
21/02/17 01:37:30 INFO ContextCleaner: Cleaned accumulator 289
21/02/17 01:37:30 INFO ContextCleaner: Cleaned accumulator 227
21/02/17 01:37:30 INFO ContextCleaner: Cleaned accumulator 250
21/02/17 01:37:30 INFO ContextCleaner: Cleaned accumulator 226
21/02/17 01:37:30 INFO ContextCleaner: Cleaned accumulator 292
21/02/17 01:37:30 INFO ContextCleaner: Cleaned accumulator 393
21/02/17 01:37:30 INFO ContextCleaner: Cleaned accumulator 245
21/02/17 01:37:30 INFO ContextCleaner: Cleaned accumulator 411
21/02/17 01:37:30 INFO ContextCleaner: Cleaned accumulator 483
21/02/17 01:37:30 INFO ContextCleaner: Cleaned accumulator 240
21/02/17 01:37:30 INFO ContextCleaner: Cleaned accumulator 442
21/02/17 01:37:30 INFO ContextCleaner: Cleaned accumulator 494
21/02/17 01:37:30 INFO ContextCleaner: Cleaned accumulator 307
21/02/17 01:37:30 INFO ContextCleaner: Cleaned accumulator 330
21/02/17 01:37:30 INFO ContextCleaner: Cleaned accumulator 314
21/02/17 01:37:30 INFO ContextCleaner: Cleaned accumulator 400
21/02/17 01:37:30 INFO ContextCleaner: Cleaned accumulator 232
21/02/17 01:37:30 INFO ContextCleaner: Cleaned accumulator 380
21/02/17 01:37:30 INFO ContextCleaner: Cleaned accumulator 437
21/02/17 01:37:30 INFO ContextCleaner: Cleaned accumulator 464
21/02/17 01:37:30 INFO ContextCleaner: Cleaned accumulator 390
21/02/17 01:37:30 INFO ContextCleaner: Cleaned accumulator 253
21/02/17 01:37:30 INFO ContextCleaner: Cleaned accumulator 479
21/02/17 01:37:30 INFO ContextCleaner: Cleaned accumulator 220
21/02/17 01:37:30 INFO ContextCleaner: Cleaned accumulator 375
21/02/17 01:37:30 INFO ContextCleaner: Cleaned accumulator 444
21/02/17 01:37:30 INFO ContextCleaner: Cleaned accumulator 248
21/02/17 01:37:30 INFO ContextCleaner: Cleaned accumulator 391
21/02/17 01:37:30 INFO ContextCleaner: Cleaned accumulator 320
21/02/17 01:37:30 INFO ContextCleaner: Cleaned accumulator 392
21/02/17 01:37:30 INFO ContextCleaner: Cleaned accumulator 404
21/02/17 01:37:30 INFO ContextCleaner: Cleaned accumulator 339
21/02/17 01:37:30 INFO ContextCleaner: Cleaned accumulator 311
21/02/17 01:37:30 INFO ContextCleaner: Cleaned accumulator 215
21/02/17 01:37:30 INFO ContextCleaner: Cleaned accumulator 252
21/02/17 01:37:30 INFO ContextCleaner: Cleaned accumulator 337
21/02/17 01:37:30 INFO ContextCleaner: Cleaned accumulator 465
21/02/17 01:37:30 INFO ContextCleaner: Cleaned accumulator 396
21/02/17 01:37:30 INFO ContextCleaner: Cleaned accumulator 448
21/02/17 01:37:30 INFO BlockManagerInfo: Removed broadcast_14_piece0 on localhost:38285 in memory (size: 25.9 KB, free: 912.2 MB)
21/02/17 01:37:30 INFO ContextCleaner: Cleaned accumulator 430
21/02/17 01:37:30 INFO ContextCleaner: Cleaned accumulator 247
21/02/17 01:37:30 INFO ContextCleaner: Cleaned accumulator 476
21/02/17 01:37:30 INFO ContextCleaner: Cleaned accumulator 229
21/02/17 01:37:30 INFO ContextCleaner: Cleaned accumulator 282
21/02/17 01:37:30 INFO ContextCleaner: Cleaned accumulator 500
21/02/17 01:37:30 INFO ContextCleaner: Cleaned accumulator 262
21/02/17 01:37:30 INFO ContextCleaner: Cleaned accumulator 360
21/02/17 01:37:30 INFO ContextCleaner: Cleaned accumulator 475
21/02/17 01:37:30 INFO ContextCleaner: Cleaned accumulator 456
21/02/17 01:37:30 INFO ContextCleaner: Cleaned accumulator 293
21/02/17 01:37:30 INFO ContextCleaner: Cleaned accumulator 299
21/02/17 01:37:30 INFO ContextCleaner: Cleaned accumulator 367
21/02/17 01:37:30 INFO BlockManagerInfo: Removed broadcast_12_piece0 on localhost:38285 in memory (size: 3.8 KB, free: 912.2 MB)
21/02/17 01:37:30 INFO ContextCleaner: Cleaned accumulator 478
21/02/17 01:37:30 INFO ContextCleaner: Cleaned accumulator 258
21/02/17 01:37:30 INFO ContextCleaner: Cleaned accumulator 451
21/02/17 01:37:30 INFO ContextCleaner: Cleaned accumulator 294
21/02/17 01:37:30 INFO ContextCleaner: Cleaned accumulator 348
21/02/17 01:37:30 INFO ContextCleaner: Cleaned accumulator 432
21/02/17 01:37:30 INFO ContextCleaner: Cleaned accumulator 284
21/02/17 01:37:30 INFO ContextCleaner: Cleaned accumulator 264
21/02/17 01:37:30 INFO ContextCleaner: Cleaned accumulator 279
21/02/17 01:37:30 INFO ContextCleaner: Cleaned accumulator 239
21/02/17 01:37:30 INFO ContextCleaner: Cleaned accumulator 446
21/02/17 01:37:30 INFO ContextCleaner: Cleaned accumulator 402
21/02/17 01:37:30 INFO ContextCleaner: Cleaned accumulator 449
21/02/17 01:37:30 INFO ContextCleaner: Cleaned accumulator 331
21/02/17 01:37:30 INFO ContextCleaner: Cleaned accumulator 317
21/02/17 01:37:30 INFO ContextCleaner: Cleaned accumulator 359
21/02/17 01:37:30 INFO ContextCleaner: Cleaned accumulator 413
21/02/17 01:37:30 INFO ContextCleaner: Cleaned accumulator 485
21/02/17 01:37:30 INFO ContextCleaner: Cleaned accumulator 355
21/02/17 01:37:30 INFO ContextCleaner: Cleaned accumulator 372
21/02/17 01:37:30 INFO ContextCleaner: Cleaned shuffle 3
21/02/17 01:37:30 INFO ContextCleaner: Cleaned accumulator 213
21/02/17 01:37:30 INFO ContextCleaner: Cleaned accumulator 439
21/02/17 01:37:30 INFO ContextCleaner: Cleaned accumulator 357
21/02/17 01:37:30 INFO ContextCleaner: Cleaned accumulator 316
21/02/17 01:37:30 INFO ContextCleaner: Cleaned accumulator 308
21/02/17 01:37:30 INFO ContextCleaner: Cleaned accumulator 441
21/02/17 01:37:30 INFO ContextCleaner: Cleaned accumulator 361
21/02/17 01:37:30 INFO ContextCleaner: Cleaned accumulator 492
21/02/17 01:37:30 INFO ContextCleaner: Cleaned accumulator 422
21/02/17 01:37:30 INFO ContextCleaner: Cleaned accumulator 362
21/02/17 01:37:30 INFO ContextCleaner: Cleaned accumulator 214
21/02/17 01:37:30 INFO ContextCleaner: Cleaned accumulator 481
21/02/17 01:37:30 INFO ContextCleaner: Cleaned accumulator 341
21/02/17 01:37:30 INFO ContextCleaner: Cleaned accumulator 318
21/02/17 01:37:30 INFO ContextCleaner: Cleaned accumulator 426
21/02/17 01:37:30 INFO BlockManagerInfo: Removed broadcast_15_piece0 on localhost:38285 in memory (size: 3.8 KB, free: 912.2 MB)
21/02/17 01:37:30 INFO ContextCleaner: Cleaned accumulator 467
21/02/17 01:37:30 INFO ContextCleaner: Cleaned accumulator 405
21/02/17 01:37:30 INFO ContextCleaner: Cleaned accumulator 242
21/02/17 01:37:30 INFO ContextCleaner: Cleaned accumulator 313
21/02/17 01:37:30 INFO ContextCleaner: Cleaned accumulator 486
21/02/17 01:37:30 INFO ContextCleaner: Cleaned accumulator 223
21/02/17 01:37:30 INFO ContextCleaner: Cleaned accumulator 410
21/02/17 01:37:30 INFO BlockManagerInfo: Removed broadcast_13_piece0 on localhost:38285 in memory (size: 25.4 KB, free: 912.2 MB)
21/02/17 01:37:30 INFO ContextCleaner: Cleaned accumulator 376
21/02/17 01:37:30 INFO ContextCleaner: Cleaned accumulator 246
21/02/17 01:37:30 INFO ContextCleaner: Cleaned accumulator 340
21/02/17 01:37:30 INFO BlockManagerInfo: Removed broadcast_17_piece0 on localhost:38285 in memory (size: 25.4 KB, free: 912.3 MB)
21/02/17 01:37:30 INFO ContextCleaner: Cleaned accumulator 378
21/02/17 01:37:30 INFO ContextCleaner: Cleaned accumulator 429
21/02/17 01:37:30 INFO ContextCleaner: Cleaned accumulator 285
21/02/17 01:37:30 INFO ContextCleaner: Cleaned accumulator 237
21/02/17 01:37:30 INFO ContextCleaner: Cleaned accumulator 383
21/02/17 01:37:30 INFO ContextCleaner: Cleaned accumulator 306
21/02/17 01:37:30 INFO ContextCleaner: Cleaned accumulator 480
21/02/17 01:37:30 INFO ContextCleaner: Cleaned accumulator 251
21/02/17 01:37:30 INFO BlockManagerInfo: Removed broadcast_8_piece0 on localhost:38285 in memory (size: 14.3 KB, free: 912.3 MB)
21/02/17 01:37:30 INFO ContextCleaner: Cleaned accumulator 472
21/02/17 01:37:30 INFO ContextCleaner: Cleaned accumulator 327
21/02/17 01:37:30 INFO ContextCleaner: Cleaned accumulator 468
21/02/17 01:37:30 INFO ContextCleaner: Cleaned accumulator 412
21/02/17 01:37:30 INFO ContextCleaner: Cleaned accumulator 497
21/02/17 01:37:30 INFO ContextCleaner: Cleaned accumulator 281
21/02/17 01:37:30 INFO ContextCleaner: Cleaned accumulator 228
21/02/17 01:37:30 INFO ContextCleaner: Cleaned accumulator 344
21/02/17 01:37:30 INFO ContextCleaner: Cleaned accumulator 323
21/02/17 01:37:30 INFO ContextCleaner: Cleaned accumulator 461
21/02/17 01:37:30 INFO ContextCleaner: Cleaned accumulator 498
21/02/17 01:37:30 INFO ContextCleaner: Cleaned accumulator 222
21/02/17 01:37:30 INFO ContextCleaner: Cleaned accumulator 438
21/02/17 01:37:30 INFO ContextCleaner: Cleaned accumulator 349
21/02/17 01:37:30 INFO ContextCleaner: Cleaned accumulator 351
21/02/17 01:37:30 INFO ContextCleaner: Cleaned accumulator 277
21/02/17 01:37:30 INFO ContextCleaner: Cleaned accumulator 221
21/02/17 01:37:30 INFO ContextCleaner: Cleaned accumulator 364
21/02/17 01:37:30 INFO ContextCleaner: Cleaned accumulator 399
21/02/17 01:37:30 INFO ContextCleaner: Cleaned accumulator 276
21/02/17 01:37:30 INFO ContextCleaner: Cleaned accumulator 217
21/02/17 01:37:30 INFO ContextCleaner: Cleaned accumulator 491
21/02/17 01:37:30 INFO ContextCleaner: Cleaned accumulator 433
21/02/17 01:37:30 INFO ContextCleaner: Cleaned accumulator 271
21/02/17 01:37:30 INFO ContextCleaner: Cleaned accumulator 352
21/02/17 01:37:30 INFO ContextCleaner: Cleaned accumulator 257
21/02/17 01:37:30 INFO ContextCleaner: Cleaned accumulator 358
21/02/17 01:37:30 INFO ContextCleaner: Cleaned accumulator 415
21/02/17 01:37:30 INFO ContextCleaner: Cleaned accumulator 334
21/02/17 01:37:30 INFO ContextCleaner: Cleaned accumulator 366
21/02/17 01:37:30 INFO BlockManagerInfo: Removed broadcast_11_piece0 on localhost:38285 in memory (size: 4.5 KB, free: 912.3 MB)
21/02/17 01:37:30 INFO ContextCleaner: Cleaned accumulator 417
21/02/17 01:37:30 INFO ContextCleaner: Cleaned accumulator 455
21/02/17 01:37:30 INFO ContextCleaner: Cleaned accumulator 458
21/02/17 01:37:30 INFO ContextCleaner: Cleaned accumulator 241
21/02/17 01:37:30 INFO ContextCleaner: Cleaned accumulator 495
21/02/17 01:37:30 INFO ContextCleaner: Cleaned accumulator 354
21/02/17 01:37:30 INFO ContextCleaner: Cleaned accumulator 305
21/02/17 01:37:30 INFO ContextCleaner: Cleaned accumulator 394
21/02/17 01:37:30 INFO ContextCleaner: Cleaned accumulator 319
21/02/17 01:37:30 INFO ContextCleaner: Cleaned accumulator 275
21/02/17 01:37:30 INFO ContextCleaner: Cleaned accumulator 329
21/02/17 01:37:30 INFO ContextCleaner: Cleaned accumulator 254
21/02/17 01:37:30 INFO ContextCleaner: Cleaned accumulator 373
21/02/17 01:37:30 INFO ContextCleaner: Cleaned accumulator 387
21/02/17 01:37:30 INFO ContextCleaner: Cleaned accumulator 274
21/02/17 01:37:30 INFO ContextCleaner: Cleaned accumulator 310
21/02/17 01:37:30 INFO ContextCleaner: Cleaned accumulator 493
21/02/17 01:37:30 INFO ContextCleaner: Cleaned accumulator 328
21/02/17 01:37:30 INFO ContextCleaner: Cleaned accumulator 403
21/02/17 01:37:30 INFO ContextCleaner: Cleaned accumulator 272
21/02/17 01:37:30 INFO ContextCleaner: Cleaned accumulator 309
21/02/17 01:37:30 INFO ContextCleaner: Cleaned accumulator 428
21/02/17 01:37:30 INFO ContextCleaner: Cleaned accumulator 263
21/02/17 01:37:30 INFO ContextCleaner: Cleaned accumulator 286
21/02/17 01:37:30 INFO ContextCleaner: Cleaned accumulator 397
21/02/17 01:37:30 INFO ContextCleaner: Cleaned accumulator 243
21/02/17 01:37:30 INFO ContextCleaner: Cleaned accumulator 489
21/02/17 01:37:30 INFO BlockManagerInfo: Removed broadcast_10_piece0 on localhost:38285 in memory (size: 3.2 KB, free: 912.3 MB)
21/02/17 01:37:30 INFO ContextCleaner: Cleaned accumulator 484
21/02/17 01:37:30 INFO ContextCleaner: Cleaned accumulator 288
21/02/17 01:37:30 INFO ContextCleaner: Cleaned accumulator 342
21/02/17 01:37:30 INFO ContextCleaner: Cleaned accumulator 336
21/02/17 01:37:30 INFO ContextCleaner: Cleaned accumulator 324
21/02/17 01:37:30 INFO ContextCleaner: Cleaned accumulator 425
21/02/17 01:37:30 INFO ContextCleaner: Cleaned accumulator 440
21/02/17 01:37:30 INFO ContextCleaner: Cleaned accumulator 477
21/02/17 01:37:30 INFO ContextCleaner: Cleaned accumulator 238
21/02/17 01:37:30 INFO ContextCleaner: Cleaned accumulator 261
21/02/17 01:37:30 INFO ContextCleaner: Cleaned accumulator 370
21/02/17 01:37:30 INFO ContextCleaner: Cleaned accumulator 268
21/02/17 01:37:30 INFO ContextCleaner: Cleaned accumulator 389
21/02/17 01:37:30 INFO ContextCleaner: Cleaned accumulator 259
21/02/17 01:37:30 INFO ContextCleaner: Cleaned accumulator 409
21/02/17 01:37:30 INFO BlockManager: Removing RDD 35
21/02/17 01:37:30 INFO ContextCleaner: Cleaned RDD 35
21/02/17 01:37:30 INFO ContextCleaner: Cleaned accumulator 296
21/02/17 01:37:30 INFO ContextCleaner: Cleaned accumulator 283
21/02/17 01:37:30 INFO ContextCleaner: Cleaned accumulator 474
21/02/17 01:37:30 INFO ContextCleaner: Cleaned accumulator 216
21/02/17 01:37:30 INFO ContextCleaner: Cleaned accumulator 225
21/02/17 01:37:30 INFO ContextCleaner: Cleaned accumulator 487
21/02/17 01:37:30 INFO ContextCleaner: Cleaned accumulator 321
21/02/17 01:37:30 INFO ContextCleaner: Cleaned accumulator 353
21/02/17 01:37:30 INFO ContextCleaner: Cleaned accumulator 371
21/02/17 01:37:30 INFO ContextCleaner: Cleaned accumulator 365
21/02/17 01:37:30 INFO ContextCleaner: Cleaned accumulator 244
21/02/17 01:37:30 INFO ContextCleaner: Cleaned accumulator 401
21/02/17 01:37:30 INFO ContextCleaner: Cleaned accumulator 384
21/02/17 01:37:30 INFO ContextCleaner: Cleaned accumulator 398
21/02/17 01:37:30 INFO ContextCleaner: Cleaned accumulator 231
21/02/17 01:37:30 INFO ContextCleaner: Cleaned accumulator 249
21/02/17 01:37:30 INFO ContextCleaner: Cleaned accumulator 462
21/02/17 01:37:30 INFO ContextCleaner: Cleaned accumulator 424
21/02/17 01:37:30 INFO ContextCleaner: Cleaned accumulator 385
21/02/17 01:37:30 INFO ContextCleaner: Cleaned accumulator 419
21/02/17 01:37:30 INFO ContextCleaner: Cleaned accumulator 452
21/02/17 01:37:30 INFO ContextCleaner: Cleaned accumulator 450
21/02/17 01:37:30 INFO ContextCleaner: Cleaned accumulator 345
21/02/17 01:37:30 INFO ContextCleaner: Cleaned accumulator 466
21/02/17 01:37:30 INFO ContextCleaner: Cleaned accumulator 447
21/02/17 01:37:30 INFO ContextCleaner: Cleaned accumulator 407
21/02/17 01:37:30 INFO ContextCleaner: Cleaned accumulator 298
21/02/17 01:37:30 INFO ContextCleaner: Cleaned accumulator 234
21/02/17 01:37:30 INFO ContextCleaner: Cleaned accumulator 325
21/02/17 01:37:30 INFO ContextCleaner: Cleaned accumulator 326
21/02/17 01:37:30 INFO ContextCleaner: Cleaned accumulator 335
21/02/17 01:37:30 INFO ContextCleaner: Cleaned accumulator 368
21/02/17 01:37:30 INFO ContextCleaner: Cleaned accumulator 459
21/02/17 01:37:30 INFO ContextCleaner: Cleaned accumulator 463
21/02/17 01:37:30 INFO ParquetFileFormat: Using default output committer for Parquet: org.apache.parquet.hadoop.ParquetOutputCommitter
21/02/17 01:37:30 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
21/02/17 01:37:30 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
21/02/17 01:37:30 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
21/02/17 01:37:30 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
21/02/17 01:37:30 INFO CodeGenerator: Code generated in 7.567984 ms
21/02/17 01:37:30 INFO SparkContext: Starting job: parquet at RFormula.scala:421
21/02/17 01:37:30 INFO DAGScheduler: Registering RDD 68 (parquet at RFormula.scala:421)
21/02/17 01:37:30 INFO DAGScheduler: Got job 13 (parquet at RFormula.scala:421) with 1 output partitions
21/02/17 01:37:30 INFO DAGScheduler: Final stage: ResultStage 18 (parquet at RFormula.scala:421)
21/02/17 01:37:30 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 17)
21/02/17 01:37:30 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 17)
21/02/17 01:37:30 INFO DAGScheduler: Submitting ShuffleMapStage 17 (MapPartitionsRDD[68] at parquet at RFormula.scala:421), which has no missing parents
21/02/17 01:37:30 INFO MemoryStore: Block broadcast_18 stored as values in memory (estimated size 4.8 KB, free 912.3 MB)
21/02/17 01:37:30 INFO MemoryStore: Block broadcast_18_piece0 stored as bytes in memory (estimated size 2.9 KB, free 912.3 MB)
21/02/17 01:37:30 INFO BlockManagerInfo: Added broadcast_18_piece0 in memory on localhost:38285 (size: 2.9 KB, free: 912.3 MB)
21/02/17 01:37:30 INFO SparkContext: Created broadcast 18 from broadcast at DAGScheduler.scala:1039
21/02/17 01:37:30 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 17 (MapPartitionsRDD[68] at parquet at RFormula.scala:421) (first 15 tasks are for partitions Vector(0))
21/02/17 01:37:30 INFO TaskSchedulerImpl: Adding task set 17.0 with 1 tasks
21/02/17 01:37:30 INFO TaskSetManager: Starting task 0.0 in stage 17.0 (TID 17, localhost, executor driver, partition 0, PROCESS_LOCAL, 8164 bytes)
21/02/17 01:37:30 INFO Executor: Running task 0.0 in stage 17.0 (TID 17)
21/02/17 01:37:30 INFO Executor: Finished task 0.0 in stage 17.0 (TID 17). 1247 bytes result sent to driver
21/02/17 01:37:30 INFO TaskSetManager: Finished task 0.0 in stage 17.0 (TID 17) in 5 ms on localhost (executor driver) (1/1)
21/02/17 01:37:30 INFO TaskSchedulerImpl: Removed TaskSet 17.0, whose tasks have all completed, from pool 
21/02/17 01:37:30 INFO DAGScheduler: ShuffleMapStage 17 (parquet at RFormula.scala:421) finished in 0.012 s
21/02/17 01:37:30 INFO DAGScheduler: looking for newly runnable stages
21/02/17 01:37:30 INFO DAGScheduler: running: Set()
21/02/17 01:37:30 INFO DAGScheduler: waiting: Set(ResultStage 18)
21/02/17 01:37:30 INFO DAGScheduler: failed: Set()
21/02/17 01:37:30 INFO DAGScheduler: Submitting ResultStage 18 (ShuffledRowRDD[69] at parquet at RFormula.scala:421), which has no missing parents
21/02/17 01:37:30 INFO MemoryStore: Block broadcast_19 stored as values in memory (estimated size 150.9 KB, free 912.1 MB)
21/02/17 01:37:30 INFO MemoryStore: Block broadcast_19_piece0 stored as bytes in memory (estimated size 53.4 KB, free 912.1 MB)
21/02/17 01:37:30 INFO BlockManagerInfo: Added broadcast_19_piece0 in memory on localhost:38285 (size: 53.4 KB, free: 912.2 MB)
21/02/17 01:37:30 INFO SparkContext: Created broadcast 19 from broadcast at DAGScheduler.scala:1039
21/02/17 01:37:30 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 18 (ShuffledRowRDD[69] at parquet at RFormula.scala:421) (first 15 tasks are for partitions Vector(0))
21/02/17 01:37:30 INFO TaskSchedulerImpl: Adding task set 18.0 with 1 tasks
21/02/17 01:37:30 INFO TaskSetManager: Starting task 0.0 in stage 18.0 (TID 18, localhost, executor driver, partition 0, NODE_LOCAL, 7754 bytes)
21/02/17 01:37:30 INFO Executor: Running task 0.0 in stage 18.0 (TID 18)
21/02/17 01:37:30 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
21/02/17 01:37:30 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
21/02/17 01:37:30 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
21/02/17 01:37:30 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
21/02/17 01:37:30 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
21/02/17 01:37:30 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
21/02/17 01:37:30 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:
{
  "type" : "struct",
  "fields" : [ {
    "name" : "label",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "terms",
    "type" : {
      "type" : "array",
      "elementType" : {
        "type" : "array",
        "elementType" : "string",
        "containsNull" : true
      },
      "containsNull" : true
    },
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "hasIntercept",
    "type" : "boolean",
    "nullable" : false,
    "metadata" : { }
  } ]
}
and corresponding Parquet message type:
message spark_schema {
  optional binary label (UTF8);
  optional group terms (LIST) {
    repeated group list {
      optional group element (LIST) {
        repeated group list {
          optional binary element (UTF8);
        }
      }
    }
  }
  required boolean hasIntercept;
}

       
21/02/17 01:37:30 INFO CodecPool: Got brand-new compressor [.snappy]
21/02/17 01:37:30 INFO FileOutputCommitter: Saved output of task 'attempt_20210217013730_0018_m_000000_0' to file:/tmp/RtmpAwg72U/file2273e1dcb2db/stages/0_r_formula__d1af6ac8_fb81_4178_b8f7_d931e3812fd8/data/_temporary/0/task_20210217013730_0018_m_000000
21/02/17 01:37:30 INFO SparkHadoopMapRedUtil: attempt_20210217013730_0018_m_000000_0: Committed
21/02/17 01:37:30 INFO Executor: Finished task 0.0 in stage 18.0 (TID 18). 2351 bytes result sent to driver
21/02/17 01:37:30 INFO TaskSetManager: Finished task 0.0 in stage 18.0 (TID 18) in 224 ms on localhost (executor driver) (1/1)
21/02/17 01:37:30 INFO TaskSchedulerImpl: Removed TaskSet 18.0, whose tasks have all completed, from pool 
21/02/17 01:37:30 INFO DAGScheduler: ResultStage 18 (parquet at RFormula.scala:421) finished in 0.246 s
21/02/17 01:37:30 INFO DAGScheduler: Job 13 finished: parquet at RFormula.scala:421, took 0.261375 s
21/02/17 01:37:30 INFO FileFormatWriter: Job null committed.
21/02/17 01:37:30 INFO FileFormatWriter: Finished processing stats for job null.
21/02/17 01:37:30 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
21/02/17 01:37:30 INFO SparkContext: Starting job: runJob at SparkHadoopWriter.scala:78
21/02/17 01:37:30 INFO DAGScheduler: Got job 14 (runJob at SparkHadoopWriter.scala:78) with 1 output partitions
21/02/17 01:37:30 INFO DAGScheduler: Final stage: ResultStage 19 (runJob at SparkHadoopWriter.scala:78)
21/02/17 01:37:30 INFO DAGScheduler: Parents of final stage: List()
21/02/17 01:37:30 INFO DAGScheduler: Missing parents: List()
21/02/17 01:37:30 INFO DAGScheduler: Submitting ResultStage 19 (MapPartitionsRDD[72] at saveAsTextFile at ReadWrite.scala:283), which has no missing parents
21/02/17 01:37:30 INFO MemoryStore: Block broadcast_20 stored as values in memory (estimated size 71.1 KB, free 912.0 MB)
21/02/17 01:37:30 INFO MemoryStore: Block broadcast_20_piece0 stored as bytes in memory (estimated size 25.5 KB, free 912.0 MB)
21/02/17 01:37:30 INFO BlockManagerInfo: Added broadcast_20_piece0 in memory on localhost:38285 (size: 25.5 KB, free: 912.2 MB)
21/02/17 01:37:30 INFO SparkContext: Created broadcast 20 from broadcast at DAGScheduler.scala:1039
21/02/17 01:37:30 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 19 (MapPartitionsRDD[72] at saveAsTextFile at ReadWrite.scala:283) (first 15 tasks are for partitions Vector(0))
21/02/17 01:37:30 INFO TaskSchedulerImpl: Adding task set 19.0 with 1 tasks
21/02/17 01:37:30 INFO TaskSetManager: Starting task 0.0 in stage 19.0 (TID 19, localhost, executor driver, partition 0, PROCESS_LOCAL, 8147 bytes)
21/02/17 01:37:30 INFO Executor: Running task 0.0 in stage 19.0 (TID 19)
21/02/17 01:37:30 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
21/02/17 01:37:30 INFO FileOutputCommitter: Saved output of task 'attempt_20210217013730_0072_m_000000_0' to file:/tmp/RtmpAwg72U/file2273e1dcb2db/stages/0_r_formula__d1af6ac8_fb81_4178_b8f7_d931e3812fd8/pipelineModel/metadata/_temporary/0/task_20210217013730_0072_m_000000
21/02/17 01:37:30 INFO SparkHadoopMapRedUtil: attempt_20210217013730_0072_m_000000_0: Committed
21/02/17 01:37:30 INFO Executor: Finished task 0.0 in stage 19.0 (TID 19). 1029 bytes result sent to driver
21/02/17 01:37:30 INFO TaskSetManager: Finished task 0.0 in stage 19.0 (TID 19) in 13 ms on localhost (executor driver) (1/1)
21/02/17 01:37:30 INFO TaskSchedulerImpl: Removed TaskSet 19.0, whose tasks have all completed, from pool 
21/02/17 01:37:30 INFO DAGScheduler: ResultStage 19 (runJob at SparkHadoopWriter.scala:78) finished in 0.030 s
21/02/17 01:37:30 INFO DAGScheduler: Job 14 finished: runJob at SparkHadoopWriter.scala:78, took 0.031404 s
21/02/17 01:37:30 INFO SparkHadoopWriter: Job job_20210217013730_0072 committed.
21/02/17 01:37:30 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
21/02/17 01:37:30 INFO SparkContext: Starting job: runJob at SparkHadoopWriter.scala:78
21/02/17 01:37:30 INFO DAGScheduler: Got job 15 (runJob at SparkHadoopWriter.scala:78) with 1 output partitions
21/02/17 01:37:30 INFO DAGScheduler: Final stage: ResultStage 20 (runJob at SparkHadoopWriter.scala:78)
21/02/17 01:37:30 INFO DAGScheduler: Parents of final stage: List()
21/02/17 01:37:30 INFO DAGScheduler: Missing parents: List()
21/02/17 01:37:30 INFO DAGScheduler: Submitting ResultStage 20 (MapPartitionsRDD[74] at saveAsTextFile at ReadWrite.scala:283), which has no missing parents
21/02/17 01:37:30 INFO MemoryStore: Block broadcast_21 stored as values in memory (estimated size 71.3 KB, free 911.9 MB)
21/02/17 01:37:30 INFO MemoryStore: Block broadcast_21_piece0 stored as bytes in memory (estimated size 25.5 KB, free 911.9 MB)
21/02/17 01:37:30 INFO BlockManagerInfo: Added broadcast_21_piece0 in memory on localhost:38285 (size: 25.5 KB, free: 912.2 MB)
21/02/17 01:37:30 INFO SparkContext: Created broadcast 21 from broadcast at DAGScheduler.scala:1039
21/02/17 01:37:30 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 20 (MapPartitionsRDD[74] at saveAsTextFile at ReadWrite.scala:283) (first 15 tasks are for partitions Vector(0))
21/02/17 01:37:30 INFO TaskSchedulerImpl: Adding task set 20.0 with 1 tasks
21/02/17 01:37:30 INFO TaskSetManager: Starting task 0.0 in stage 20.0 (TID 20, localhost, executor driver, partition 0, PROCESS_LOCAL, 8097 bytes)
21/02/17 01:37:30 INFO Executor: Running task 0.0 in stage 20.0 (TID 20)
21/02/17 01:37:30 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
21/02/17 01:37:30 INFO FileOutputCommitter: Saved output of task 'attempt_20210217013730_0074_m_000000_0' to file:/tmp/RtmpAwg72U/file2273e1dcb2db/stages/0_r_formula__d1af6ac8_fb81_4178_b8f7_d931e3812fd8/pipelineModel/stages/0_r_formula__d1af6ac8_fb81_4178_b8f7_d931e3812fd8/metadata/_temporary/0/task_20210217013730_0074_m_000000
21/02/17 01:37:30 INFO SparkHadoopMapRedUtil: attempt_20210217013730_0074_m_000000_0: Committed
21/02/17 01:37:30 INFO Executor: Finished task 0.0 in stage 20.0 (TID 20). 1029 bytes result sent to driver
21/02/17 01:37:30 INFO TaskSetManager: Finished task 0.0 in stage 20.0 (TID 20) in 14 ms on localhost (executor driver) (1/1)
21/02/17 01:37:30 INFO TaskSchedulerImpl: Removed TaskSet 20.0, whose tasks have all completed, from pool 
21/02/17 01:37:30 INFO DAGScheduler: ResultStage 20 (runJob at SparkHadoopWriter.scala:78) finished in 0.027 s
21/02/17 01:37:30 INFO DAGScheduler: Job 15 finished: runJob at SparkHadoopWriter.scala:78, took 0.029197 s
21/02/17 01:37:30 INFO SparkHadoopWriter: Job job_20210217013730_0074 committed.
21/02/17 01:37:31 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
21/02/17 01:37:31 INFO SparkContext: Starting job: runJob at SparkHadoopWriter.scala:78
21/02/17 01:37:31 INFO DAGScheduler: Got job 16 (runJob at SparkHadoopWriter.scala:78) with 1 output partitions
21/02/17 01:37:31 INFO DAGScheduler: Final stage: ResultStage 21 (runJob at SparkHadoopWriter.scala:78)
21/02/17 01:37:31 INFO DAGScheduler: Parents of final stage: List()
21/02/17 01:37:31 INFO DAGScheduler: Missing parents: List()
21/02/17 01:37:31 INFO DAGScheduler: Submitting ResultStage 21 (MapPartitionsRDD[76] at saveAsTextFile at ReadWrite.scala:283), which has no missing parents
21/02/17 01:37:31 INFO MemoryStore: Block broadcast_22 stored as values in memory (estimated size 71.2 KB, free 911.8 MB)
21/02/17 01:37:31 INFO MemoryStore: Block broadcast_22_piece0 stored as bytes in memory (estimated size 25.5 KB, free 911.8 MB)
21/02/17 01:37:31 INFO BlockManagerInfo: Added broadcast_22_piece0 in memory on localhost:38285 (size: 25.5 KB, free: 912.2 MB)
21/02/17 01:37:31 INFO SparkContext: Created broadcast 22 from broadcast at DAGScheduler.scala:1039
21/02/17 01:37:31 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 21 (MapPartitionsRDD[76] at saveAsTextFile at ReadWrite.scala:283) (first 15 tasks are for partitions Vector(0))
21/02/17 01:37:31 INFO TaskSchedulerImpl: Adding task set 21.0 with 1 tasks
21/02/17 01:37:31 INFO TaskSetManager: Starting task 0.0 in stage 21.0 (TID 21, localhost, executor driver, partition 0, PROCESS_LOCAL, 8024 bytes)
21/02/17 01:37:31 INFO Executor: Running task 0.0 in stage 21.0 (TID 21)
21/02/17 01:37:31 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
21/02/17 01:37:31 INFO FileOutputCommitter: Saved output of task 'attempt_20210217013731_0076_m_000000_0' to file:/tmp/RtmpAwg72U/file2273e1dcb2db/stages/0_r_formula__d1af6ac8_fb81_4178_b8f7_d931e3812fd8/pipelineModel/stages/1_vectorAttrRewriter_778f1a83d132/metadata/_temporary/0/task_20210217013731_0076_m_000000
21/02/17 01:37:31 INFO SparkHadoopMapRedUtil: attempt_20210217013731_0076_m_000000_0: Committed
21/02/17 01:37:31 INFO Executor: Finished task 0.0 in stage 21.0 (TID 21). 1029 bytes result sent to driver
21/02/17 01:37:31 INFO TaskSetManager: Finished task 0.0 in stage 21.0 (TID 21) in 12 ms on localhost (executor driver) (1/1)
21/02/17 01:37:31 INFO TaskSchedulerImpl: Removed TaskSet 21.0, whose tasks have all completed, from pool 
21/02/17 01:37:31 INFO DAGScheduler: ResultStage 21 (runJob at SparkHadoopWriter.scala:78) finished in 0.026 s
21/02/17 01:37:31 INFO DAGScheduler: Job 16 finished: runJob at SparkHadoopWriter.scala:78, took 0.027741 s
21/02/17 01:37:31 INFO SparkHadoopWriter: Job job_20210217013731_0076 committed.
21/02/17 01:37:31 INFO ParquetFileFormat: Using default output committer for Parquet: org.apache.parquet.hadoop.ParquetOutputCommitter
21/02/17 01:37:31 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
21/02/17 01:37:31 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
21/02/17 01:37:31 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
21/02/17 01:37:31 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
21/02/17 01:37:31 INFO CodeGenerator: Code generated in 8.263502 ms
21/02/17 01:37:31 INFO SparkContext: Starting job: parquet at RFormula.scala:586
21/02/17 01:37:31 INFO DAGScheduler: Registering RDD 79 (parquet at RFormula.scala:586)
21/02/17 01:37:31 INFO DAGScheduler: Got job 17 (parquet at RFormula.scala:586) with 1 output partitions
21/02/17 01:37:31 INFO DAGScheduler: Final stage: ResultStage 23 (parquet at RFormula.scala:586)
21/02/17 01:37:31 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 22)
21/02/17 01:37:31 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 22)
21/02/17 01:37:31 INFO DAGScheduler: Submitting ShuffleMapStage 22 (MapPartitionsRDD[79] at parquet at RFormula.scala:586), which has no missing parents
21/02/17 01:37:31 INFO MemoryStore: Block broadcast_23 stored as values in memory (estimated size 4.8 KB, free 911.8 MB)
21/02/17 01:37:31 INFO MemoryStore: Block broadcast_23_piece0 stored as bytes in memory (estimated size 2.8 KB, free 911.8 MB)
21/02/17 01:37:31 INFO BlockManagerInfo: Added broadcast_23_piece0 in memory on localhost:38285 (size: 2.8 KB, free: 912.2 MB)
21/02/17 01:37:31 INFO SparkContext: Created broadcast 23 from broadcast at DAGScheduler.scala:1039
21/02/17 01:37:31 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 22 (MapPartitionsRDD[79] at parquet at RFormula.scala:586) (first 15 tasks are for partitions Vector(0))
21/02/17 01:37:31 INFO TaskSchedulerImpl: Adding task set 22.0 with 1 tasks
21/02/17 01:37:31 INFO TaskSetManager: Starting task 0.0 in stage 22.0 (TID 22, localhost, executor driver, partition 0, PROCESS_LOCAL, 8060 bytes)
21/02/17 01:37:31 INFO Executor: Running task 0.0 in stage 22.0 (TID 22)
21/02/17 01:37:31 INFO Executor: Finished task 0.0 in stage 22.0 (TID 22). 1247 bytes result sent to driver
21/02/17 01:37:31 INFO TaskSetManager: Finished task 0.0 in stage 22.0 (TID 22) in 5 ms on localhost (executor driver) (1/1)
21/02/17 01:37:31 INFO TaskSchedulerImpl: Removed TaskSet 22.0, whose tasks have all completed, from pool 
21/02/17 01:37:31 INFO DAGScheduler: ShuffleMapStage 22 (parquet at RFormula.scala:586) finished in 0.010 s
21/02/17 01:37:31 INFO DAGScheduler: looking for newly runnable stages
21/02/17 01:37:31 INFO DAGScheduler: running: Set()
21/02/17 01:37:31 INFO DAGScheduler: waiting: Set(ResultStage 23)
21/02/17 01:37:31 INFO DAGScheduler: failed: Set()
21/02/17 01:37:31 INFO DAGScheduler: Submitting ResultStage 23 (ShuffledRowRDD[80] at parquet at RFormula.scala:586), which has no missing parents
21/02/17 01:37:31 INFO MemoryStore: Block broadcast_24 stored as values in memory (estimated size 150.9 KB, free 911.6 MB)
21/02/17 01:37:31 INFO MemoryStore: Block broadcast_24_piece0 stored as bytes in memory (estimated size 53.4 KB, free 911.6 MB)
21/02/17 01:37:31 INFO BlockManagerInfo: Added broadcast_24_piece0 in memory on localhost:38285 (size: 53.4 KB, free: 912.1 MB)
21/02/17 01:37:31 INFO SparkContext: Created broadcast 24 from broadcast at DAGScheduler.scala:1039
21/02/17 01:37:31 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 23 (ShuffledRowRDD[80] at parquet at RFormula.scala:586) (first 15 tasks are for partitions Vector(0))
21/02/17 01:37:31 INFO TaskSchedulerImpl: Adding task set 23.0 with 1 tasks
21/02/17 01:37:31 INFO TaskSetManager: Starting task 0.0 in stage 23.0 (TID 23, localhost, executor driver, partition 0, NODE_LOCAL, 7754 bytes)
21/02/17 01:37:31 INFO Executor: Running task 0.0 in stage 23.0 (TID 23)
21/02/17 01:37:31 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
21/02/17 01:37:31 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
21/02/17 01:37:31 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
21/02/17 01:37:31 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
21/02/17 01:37:31 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
21/02/17 01:37:31 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
21/02/17 01:37:31 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:
{
  "type" : "struct",
  "fields" : [ {
    "name" : "vectorCol",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "prefixesToRewrite",
    "type" : {
      "type" : "map",
      "keyType" : "string",
      "valueType" : "string",
      "valueContainsNull" : true
    },
    "nullable" : true,
    "metadata" : { }
  } ]
}
and corresponding Parquet message type:
message spark_schema {
  optional binary vectorCol (UTF8);
  optional group prefixesToRewrite (MAP) {
    repeated group key_value {
      required binary key (UTF8);
      optional binary value (UTF8);
    }
  }
}

       
21/02/17 01:37:31 INFO FileOutputCommitter: Saved output of task 'attempt_20210217013731_0023_m_000000_0' to file:/tmp/RtmpAwg72U/file2273e1dcb2db/stages/0_r_formula__d1af6ac8_fb81_4178_b8f7_d931e3812fd8/pipelineModel/stages/1_vectorAttrRewriter_778f1a83d132/data/_temporary/0/task_20210217013731_0023_m_000000
21/02/17 01:37:31 INFO SparkHadoopMapRedUtil: attempt_20210217013731_0023_m_000000_0: Committed
21/02/17 01:37:31 INFO Executor: Finished task 0.0 in stage 23.0 (TID 23). 2308 bytes result sent to driver
21/02/17 01:37:31 INFO TaskSetManager: Finished task 0.0 in stage 23.0 (TID 23) in 29 ms on localhost (executor driver) (1/1)
21/02/17 01:37:31 INFO TaskSchedulerImpl: Removed TaskSet 23.0, whose tasks have all completed, from pool 
21/02/17 01:37:31 INFO DAGScheduler: ResultStage 23 (parquet at RFormula.scala:586) finished in 0.050 s
21/02/17 01:37:31 INFO DAGScheduler: Job 17 finished: parquet at RFormula.scala:586, took 0.063232 s
21/02/17 01:37:31 INFO FileFormatWriter: Job null committed.
21/02/17 01:37:31 INFO FileFormatWriter: Finished processing stats for job null.
21/02/17 01:37:31 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
21/02/17 01:37:31 INFO SparkContext: Starting job: runJob at SparkHadoopWriter.scala:78
21/02/17 01:37:31 INFO DAGScheduler: Got job 18 (runJob at SparkHadoopWriter.scala:78) with 1 output partitions
21/02/17 01:37:31 INFO DAGScheduler: Final stage: ResultStage 24 (runJob at SparkHadoopWriter.scala:78)
21/02/17 01:37:31 INFO DAGScheduler: Parents of final stage: List()
21/02/17 01:37:31 INFO DAGScheduler: Missing parents: List()
21/02/17 01:37:31 INFO DAGScheduler: Submitting ResultStage 24 (MapPartitionsRDD[83] at saveAsTextFile at ReadWrite.scala:283), which has no missing parents
21/02/17 01:37:31 INFO MemoryStore: Block broadcast_25 stored as values in memory (estimated size 71.2 KB, free 911.5 MB)
21/02/17 01:37:31 INFO MemoryStore: Block broadcast_25_piece0 stored as bytes in memory (estimated size 25.6 KB, free 911.5 MB)
21/02/17 01:37:31 INFO BlockManagerInfo: Added broadcast_25_piece0 in memory on localhost:38285 (size: 25.6 KB, free: 912.1 MB)
21/02/17 01:37:31 INFO SparkContext: Created broadcast 25 from broadcast at DAGScheduler.scala:1039
21/02/17 01:37:31 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 24 (MapPartitionsRDD[83] at saveAsTextFile at ReadWrite.scala:283) (first 15 tasks are for partitions Vector(0))
21/02/17 01:37:31 INFO TaskSchedulerImpl: Adding task set 24.0 with 1 tasks
21/02/17 01:37:31 INFO TaskSetManager: Starting task 0.0 in stage 24.0 (TID 24, localhost, executor driver, partition 0, PROCESS_LOCAL, 8007 bytes)
21/02/17 01:37:31 INFO Executor: Running task 0.0 in stage 24.0 (TID 24)
21/02/17 01:37:31 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
21/02/17 01:37:31 INFO FileOutputCommitter: Saved output of task 'attempt_20210217013731_0083_m_000000_0' to file:/tmp/RtmpAwg72U/file2273e1dcb2db/stages/0_r_formula__d1af6ac8_fb81_4178_b8f7_d931e3812fd8/pipelineModel/stages/2_columnPruner_c7b3ccab6193/metadata/_temporary/0/task_20210217013731_0083_m_000000
21/02/17 01:37:31 INFO SparkHadoopMapRedUtil: attempt_20210217013731_0083_m_000000_0: Committed
21/02/17 01:37:31 INFO Executor: Finished task 0.0 in stage 24.0 (TID 24). 1029 bytes result sent to driver
21/02/17 01:37:31 INFO TaskSetManager: Finished task 0.0 in stage 24.0 (TID 24) in 12 ms on localhost (executor driver) (1/1)
21/02/17 01:37:31 INFO TaskSchedulerImpl: Removed TaskSet 24.0, whose tasks have all completed, from pool 
21/02/17 01:37:31 INFO DAGScheduler: ResultStage 24 (runJob at SparkHadoopWriter.scala:78) finished in 0.021 s
21/02/17 01:37:31 INFO DAGScheduler: Job 18 finished: runJob at SparkHadoopWriter.scala:78, took 0.022236 s
21/02/17 01:37:31 INFO SparkHadoopWriter: Job job_20210217013731_0083 committed.
21/02/17 01:37:31 INFO ParquetFileFormat: Using default output committer for Parquet: org.apache.parquet.hadoop.ParquetOutputCommitter
21/02/17 01:37:31 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
21/02/17 01:37:31 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
21/02/17 01:37:31 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
21/02/17 01:37:31 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
21/02/17 01:37:31 INFO CodeGenerator: Code generated in 5.596496 ms
21/02/17 01:37:31 INFO SparkContext: Starting job: parquet at RFormula.scala:495
21/02/17 01:37:31 INFO DAGScheduler: Registering RDD 86 (parquet at RFormula.scala:495)
21/02/17 01:37:31 INFO DAGScheduler: Got job 19 (parquet at RFormula.scala:495) with 1 output partitions
21/02/17 01:37:31 INFO DAGScheduler: Final stage: ResultStage 26 (parquet at RFormula.scala:495)
21/02/17 01:37:31 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 25)
21/02/17 01:37:31 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 25)
21/02/17 01:37:31 INFO DAGScheduler: Submitting ShuffleMapStage 25 (MapPartitionsRDD[86] at parquet at RFormula.scala:495), which has no missing parents
21/02/17 01:37:31 INFO MemoryStore: Block broadcast_26 stored as values in memory (estimated size 4.7 KB, free 911.5 MB)
21/02/17 01:37:31 INFO MemoryStore: Block broadcast_26_piece0 stored as bytes in memory (estimated size 2.8 KB, free 911.5 MB)
21/02/17 01:37:31 INFO BlockManagerInfo: Added broadcast_26_piece0 in memory on localhost:38285 (size: 2.8 KB, free: 912.1 MB)
21/02/17 01:37:31 INFO SparkContext: Created broadcast 26 from broadcast at DAGScheduler.scala:1039
21/02/17 01:37:31 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 25 (MapPartitionsRDD[86] at parquet at RFormula.scala:495) (first 15 tasks are for partitions Vector(0))
21/02/17 01:37:31 INFO TaskSchedulerImpl: Adding task set 25.0 with 1 tasks
21/02/17 01:37:31 INFO TaskSetManager: Starting task 0.0 in stage 25.0 (TID 25, localhost, executor driver, partition 0, PROCESS_LOCAL, 8028 bytes)
21/02/17 01:37:31 INFO Executor: Running task 0.0 in stage 25.0 (TID 25)
21/02/17 01:37:31 INFO Executor: Finished task 0.0 in stage 25.0 (TID 25). 1247 bytes result sent to driver
21/02/17 01:37:31 INFO TaskSetManager: Finished task 0.0 in stage 25.0 (TID 25) in 3 ms on localhost (executor driver) (1/1)
21/02/17 01:37:31 INFO TaskSchedulerImpl: Removed TaskSet 25.0, whose tasks have all completed, from pool 
21/02/17 01:37:31 INFO DAGScheduler: ShuffleMapStage 25 (parquet at RFormula.scala:495) finished in 0.008 s
21/02/17 01:37:31 INFO DAGScheduler: looking for newly runnable stages
21/02/17 01:37:31 INFO DAGScheduler: running: Set()
21/02/17 01:37:31 INFO DAGScheduler: waiting: Set(ResultStage 26)
21/02/17 01:37:31 INFO DAGScheduler: failed: Set()
21/02/17 01:37:31 INFO DAGScheduler: Submitting ResultStage 26 (ShuffledRowRDD[87] at parquet at RFormula.scala:495), which has no missing parents
21/02/17 01:37:31 INFO MemoryStore: Block broadcast_27 stored as values in memory (estimated size 150.7 KB, free 911.3 MB)
21/02/17 01:37:31 INFO MemoryStore: Block broadcast_27_piece0 stored as bytes in memory (estimated size 53.4 KB, free 911.3 MB)
21/02/17 01:37:31 INFO BlockManagerInfo: Added broadcast_27_piece0 in memory on localhost:38285 (size: 53.4 KB, free: 912.0 MB)
21/02/17 01:37:31 INFO SparkContext: Created broadcast 27 from broadcast at DAGScheduler.scala:1039
21/02/17 01:37:31 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 26 (ShuffledRowRDD[87] at parquet at RFormula.scala:495) (first 15 tasks are for partitions Vector(0))
21/02/17 01:37:31 INFO TaskSchedulerImpl: Adding task set 26.0 with 1 tasks
21/02/17 01:37:31 INFO TaskSetManager: Starting task 0.0 in stage 26.0 (TID 26, localhost, executor driver, partition 0, NODE_LOCAL, 7754 bytes)
21/02/17 01:37:31 INFO Executor: Running task 0.0 in stage 26.0 (TID 26)
21/02/17 01:37:31 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
21/02/17 01:37:31 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
21/02/17 01:37:31 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
21/02/17 01:37:31 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
21/02/17 01:37:31 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
21/02/17 01:37:31 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
21/02/17 01:37:31 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:
{
  "type" : "struct",
  "fields" : [ {
    "name" : "columnsToPrune",
    "type" : {
      "type" : "array",
      "elementType" : "string",
      "containsNull" : true
    },
    "nullable" : true,
    "metadata" : { }
  } ]
}
and corresponding Parquet message type:
message spark_schema {
  optional group columnsToPrune (LIST) {
    repeated group list {
      optional binary element (UTF8);
    }
  }
}

       
21/02/17 01:37:31 INFO FileOutputCommitter: Saved output of task 'attempt_20210217013731_0026_m_000000_0' to file:/tmp/RtmpAwg72U/file2273e1dcb2db/stages/0_r_formula__d1af6ac8_fb81_4178_b8f7_d931e3812fd8/pipelineModel/stages/2_columnPruner_c7b3ccab6193/data/_temporary/0/task_20210217013731_0026_m_000000
21/02/17 01:37:31 INFO SparkHadoopMapRedUtil: attempt_20210217013731_0026_m_000000_0: Committed
21/02/17 01:37:31 INFO Executor: Finished task 0.0 in stage 26.0 (TID 26). 2308 bytes result sent to driver
21/02/17 01:37:31 INFO TaskSetManager: Finished task 0.0 in stage 26.0 (TID 26) in 22 ms on localhost (executor driver) (1/1)
21/02/17 01:37:31 INFO TaskSchedulerImpl: Removed TaskSet 26.0, whose tasks have all completed, from pool 
21/02/17 01:37:31 INFO DAGScheduler: ResultStage 26 (parquet at RFormula.scala:495) finished in 0.035 s
21/02/17 01:37:31 INFO DAGScheduler: Job 19 finished: parquet at RFormula.scala:495, took 0.046097 s
21/02/17 01:37:31 INFO FileFormatWriter: Job null committed.
21/02/17 01:37:31 INFO FileFormatWriter: Finished processing stats for job null.
21/02/17 01:37:33 INFO SparkContext: Invoking stop() from shutdown hook
21/02/17 01:37:33 INFO SparkUI: Stopped Spark web UI at http://localhost:4040
21/02/17 01:37:33 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!
21/02/17 01:37:33 INFO MemoryStore: MemoryStore cleared
21/02/17 01:37:33 INFO BlockManager: BlockManager stopped
21/02/17 01:37:33 INFO BlockManagerMaster: BlockManagerMaster stopped
21/02/17 01:37:33 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!
21/02/17 01:37:33 INFO SparkContext: Successfully stopped SparkContext
21/02/17 01:37:33 INFO ShutdownHookManager: Shutdown hook called
21/02/17 01:37:33 INFO ShutdownHookManager: Deleting directory /tmp/spark-703c7049-d6a9-4dca-a191-8fbad4dd3de4
21/02/17 01:37:33 INFO ShutdownHookManager: Deleting directory /tmp/spark-0cdef2b3-d9d2-4cd6-ab8c-8c9b4dde38cf
21/02/17 01:38:26 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
21/02/17 01:38:27 INFO SparkContext: Running Spark version 2.3.0
21/02/17 01:38:27 INFO SparkContext: Submitted application: sparklyr
21/02/17 01:38:27 INFO SecurityManager: Changing view acls to: yitaoli
21/02/17 01:38:27 INFO SecurityManager: Changing modify acls to: yitaoli
21/02/17 01:38:27 INFO SecurityManager: Changing view acls groups to: 
21/02/17 01:38:27 INFO SecurityManager: Changing modify acls groups to: 
21/02/17 01:38:27 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(yitaoli); groups with view permissions: Set(); users  with modify permissions: Set(yitaoli); groups with modify permissions: Set()
21/02/17 01:38:27 INFO Utils: Successfully started service 'sparkDriver' on port 44413.
21/02/17 01:38:27 INFO SparkEnv: Registering MapOutputTracker
21/02/17 01:38:27 INFO SparkEnv: Registering BlockManagerMaster
21/02/17 01:38:27 INFO BlockManagerMasterEndpoint: Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
21/02/17 01:38:27 INFO BlockManagerMasterEndpoint: BlockManagerMasterEndpoint up
21/02/17 01:38:27 INFO DiskBlockManager: Created local directory at /tmp/blockmgr-0b98b774-6826-4e8e-9e2c-77fc1bd33bfb
21/02/17 01:38:27 INFO MemoryStore: MemoryStore started with capacity 912.3 MB
21/02/17 01:38:27 INFO SparkEnv: Registering OutputCommitCoordinator
21/02/17 01:38:27 INFO Utils: Successfully started service 'SparkUI' on port 4040.
21/02/17 01:38:27 INFO SparkUI: Bound SparkUI to 127.0.0.1, and started at http://localhost:4040
21/02/17 01:38:27 INFO SparkContext: Added JAR file:///home/yitaoli/R/x86_64-pc-linux-gnu-library/4.0/sparkxgb/java/sparkxgb-2.3-2.11.jar at spark://localhost:44413/jars/sparkxgb-2.3-2.11.jar with timestamp 1613525907760
21/02/17 01:38:27 INFO SparkContext: Added JAR file:///home/yitaoli/.ivy2/jars/ml.dmlc_xgboost4j-spark_2.11-1.1.2.jar at spark://localhost:44413/jars/ml.dmlc_xgboost4j-spark_2.11-1.1.2.jar with timestamp 1613525907760
21/02/17 01:38:27 INFO SparkContext: Added JAR file:///home/yitaoli/.ivy2/jars/org.json4s_json4s-jackson_2.11-3.2.11.jar at spark://localhost:44413/jars/org.json4s_json4s-jackson_2.11-3.2.11.jar with timestamp 1613525907760
21/02/17 01:38:27 INFO SparkContext: Added JAR file:///home/yitaoli/.ivy2/jars/ml.dmlc_xgboost4j_2.11-1.1.2.jar at spark://localhost:44413/jars/ml.dmlc_xgboost4j_2.11-1.1.2.jar with timestamp 1613525907761
21/02/17 01:38:27 INFO SparkContext: Added JAR file:///home/yitaoli/.ivy2/jars/com.esotericsoftware.kryo_kryo-2.22.jar at spark://localhost:44413/jars/com.esotericsoftware.kryo_kryo-2.22.jar with timestamp 1613525907761
21/02/17 01:38:27 INFO SparkContext: Added JAR file:///home/yitaoli/.ivy2/jars/org.scala-lang_scala-compiler-2.11.12.jar at spark://localhost:44413/jars/org.scala-lang_scala-compiler-2.11.12.jar with timestamp 1613525907761
21/02/17 01:38:27 INFO SparkContext: Added JAR file:///home/yitaoli/.ivy2/jars/org.scala-lang_scala-reflect-2.11.12.jar at spark://localhost:44413/jars/org.scala-lang_scala-reflect-2.11.12.jar with timestamp 1613525907761
21/02/17 01:38:27 INFO SparkContext: Added JAR file:///home/yitaoli/.ivy2/jars/commons-logging_commons-logging-1.2.jar at spark://localhost:44413/jars/commons-logging_commons-logging-1.2.jar with timestamp 1613525907761
21/02/17 01:38:27 INFO SparkContext: Added JAR file:///home/yitaoli/.ivy2/jars/com.typesafe.akka_akka-actor_2.11-2.5.23.jar at spark://localhost:44413/jars/com.typesafe.akka_akka-actor_2.11-2.5.23.jar with timestamp 1613525907761
21/02/17 01:38:27 INFO SparkContext: Added JAR file:///home/yitaoli/.ivy2/jars/com.typesafe_config-1.3.3.jar at spark://localhost:44413/jars/com.typesafe_config-1.3.3.jar with timestamp 1613525907761
21/02/17 01:38:27 INFO SparkContext: Added JAR file:///home/yitaoli/.ivy2/jars/org.scala-lang.modules_scala-java8-compat_2.11-0.7.0.jar at spark://localhost:44413/jars/org.scala-lang.modules_scala-java8-compat_2.11-0.7.0.jar with timestamp 1613525907761
21/02/17 01:38:27 INFO SparkContext: Added JAR file:///home/yitaoli/.ivy2/jars/org.scala-lang.modules_scala-xml_2.11-1.0.5.jar at spark://localhost:44413/jars/org.scala-lang.modules_scala-xml_2.11-1.0.5.jar with timestamp 1613525907761
21/02/17 01:38:27 INFO SparkContext: Added JAR file:///home/yitaoli/.ivy2/jars/org.scala-lang.modules_scala-parser-combinators_2.11-1.0.4.jar at spark://localhost:44413/jars/org.scala-lang.modules_scala-parser-combinators_2.11-1.0.4.jar with timestamp 1613525907762
21/02/17 01:38:27 INFO SparkContext: Added JAR file:///home/yitaoli/.ivy2/jars/org.json4s_json4s-core_2.11-3.2.11.jar at spark://localhost:44413/jars/org.json4s_json4s-core_2.11-3.2.11.jar with timestamp 1613525907762
21/02/17 01:38:27 INFO SparkContext: Added JAR file:///home/yitaoli/.ivy2/jars/com.fasterxml.jackson.core_jackson-databind-2.3.1.jar at spark://localhost:44413/jars/com.fasterxml.jackson.core_jackson-databind-2.3.1.jar with timestamp 1613525907762
21/02/17 01:38:27 INFO SparkContext: Added JAR file:///home/yitaoli/.ivy2/jars/org.json4s_json4s-ast_2.11-3.2.11.jar at spark://localhost:44413/jars/org.json4s_json4s-ast_2.11-3.2.11.jar with timestamp 1613525907762
21/02/17 01:38:27 INFO SparkContext: Added JAR file:///home/yitaoli/.ivy2/jars/com.thoughtworks.paranamer_paranamer-2.6.jar at spark://localhost:44413/jars/com.thoughtworks.paranamer_paranamer-2.6.jar with timestamp 1613525907762
21/02/17 01:38:27 INFO SparkContext: Added JAR file:///home/yitaoli/.ivy2/jars/org.scala-lang_scalap-2.11.0.jar at spark://localhost:44413/jars/org.scala-lang_scalap-2.11.0.jar with timestamp 1613525907762
21/02/17 01:38:27 INFO SparkContext: Added JAR file:///home/yitaoli/.ivy2/jars/com.fasterxml.jackson.core_jackson-annotations-2.3.0.jar at spark://localhost:44413/jars/com.fasterxml.jackson.core_jackson-annotations-2.3.0.jar with timestamp 1613525907762
21/02/17 01:38:27 INFO SparkContext: Added JAR file:///home/yitaoli/.ivy2/jars/com.fasterxml.jackson.core_jackson-core-2.3.1.jar at spark://localhost:44413/jars/com.fasterxml.jackson.core_jackson-core-2.3.1.jar with timestamp 1613525907762
21/02/17 01:38:27 INFO SparkContext: Added JAR file:/home/yitaoli/R/x86_64-pc-linux-gnu-library/4.0/sparklyr/java/sparklyr-2.3-2.11.jar at spark://localhost:44413/jars/sparklyr-2.3-2.11.jar with timestamp 1613525907762
21/02/17 01:38:27 INFO Executor: Starting executor ID driver on host localhost
21/02/17 01:38:27 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 34941.
21/02/17 01:38:27 INFO NettyBlockTransferService: Server created on localhost:34941
21/02/17 01:38:27 INFO BlockManager: Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
21/02/17 01:38:27 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, localhost, 34941, None)
21/02/17 01:38:27 INFO BlockManagerMasterEndpoint: Registering block manager localhost:34941 with 912.3 MB RAM, BlockManagerId(driver, localhost, 34941, None)
21/02/17 01:38:27 INFO BlockManagerMaster: Registered BlockManager BlockManagerId(driver, localhost, 34941, None)
21/02/17 01:38:27 INFO BlockManager: Initialized BlockManager: BlockManagerId(driver, localhost, 34941, None)
21/02/17 01:38:27 INFO SharedState: loading hive config file: file:/home/yitaoli/spark/spark-2.3.0-bin-hadoop2.7/conf/hive-site.xml
21/02/17 01:38:27 INFO SharedState: Setting hive.metastore.warehouse.dir ('null') to the value of spark.sql.warehouse.dir ('file:/home/yitaoli/sparkxgb/tests/testthat/spark-warehouse').
21/02/17 01:38:27 INFO SharedState: Warehouse path is 'file:/home/yitaoli/sparkxgb/tests/testthat/spark-warehouse'.
21/02/17 01:38:28 INFO StateStoreCoordinatorRef: Registered StateStoreCoordinator endpoint
21/02/17 01:38:29 INFO HiveUtils: Initializing HiveMetastoreConnection version 1.2.1 using Spark classes.
21/02/17 01:38:30 INFO HiveMetaStore: 0: Opening raw store with implemenation class:org.apache.hadoop.hive.metastore.ObjectStore
21/02/17 01:38:30 INFO ObjectStore: ObjectStore, initialize called
21/02/17 01:38:30 INFO Persistence: Property hive.metastore.integral.jdo.pushdown unknown - will be ignored
21/02/17 01:38:30 INFO Persistence: Property datanucleus.cache.level2 unknown - will be ignored
21/02/17 01:38:31 INFO ObjectStore: Setting MetaStore object pin classes with hive.metastore.cache.pinobjtypes="Table,StorageDescriptor,SerDeInfo,Partition,Database,Type,FieldSchema,Order"
21/02/17 01:38:31 INFO Datastore: The class "org.apache.hadoop.hive.metastore.model.MFieldSchema" is tagged as "embedded-only" so does not have its own datastore table.
21/02/17 01:38:31 INFO Datastore: The class "org.apache.hadoop.hive.metastore.model.MOrder" is tagged as "embedded-only" so does not have its own datastore table.
21/02/17 01:38:32 INFO Datastore: The class "org.apache.hadoop.hive.metastore.model.MFieldSchema" is tagged as "embedded-only" so does not have its own datastore table.
21/02/17 01:38:32 INFO Datastore: The class "org.apache.hadoop.hive.metastore.model.MOrder" is tagged as "embedded-only" so does not have its own datastore table.
21/02/17 01:38:32 INFO MetaStoreDirectSql: Using direct SQL, underlying DB is DERBY
21/02/17 01:38:32 INFO ObjectStore: Initialized ObjectStore
21/02/17 01:38:32 WARN ObjectStore: Version information not found in metastore. hive.metastore.schema.verification is not enabled so recording the schema version 1.2.0
21/02/17 01:38:32 WARN ObjectStore: Failed to get database default, returning NoSuchObjectException
21/02/17 01:38:32 INFO HiveMetaStore: Added admin role in metastore
21/02/17 01:38:32 INFO HiveMetaStore: Added public role in metastore
21/02/17 01:38:32 INFO HiveMetaStore: No user is added in admin role, since config is empty
21/02/17 01:38:32 INFO HiveMetaStore: 0: get_all_databases
21/02/17 01:38:32 INFO audit: ugi=yitaoli	ip=unknown-ip-addr	cmd=get_all_databases	
21/02/17 01:38:32 INFO HiveMetaStore: 0: get_functions: db=default pat=*
21/02/17 01:38:32 INFO audit: ugi=yitaoli	ip=unknown-ip-addr	cmd=get_functions: db=default pat=*	
21/02/17 01:38:32 INFO Datastore: The class "org.apache.hadoop.hive.metastore.model.MResourceUri" is tagged as "embedded-only" so does not have its own datastore table.
21/02/17 01:38:32 INFO SessionState: Created local directory: /tmp/a7519315-0164-46b8-bb81-2b3264fefa3d_resources
21/02/17 01:38:32 INFO SessionState: Created HDFS directory: /tmp/hive/yitaoli/a7519315-0164-46b8-bb81-2b3264fefa3d
21/02/17 01:38:32 INFO SessionState: Created local directory: /tmp/yitaoli/a7519315-0164-46b8-bb81-2b3264fefa3d
21/02/17 01:38:32 INFO SessionState: Created HDFS directory: /tmp/hive/yitaoli/a7519315-0164-46b8-bb81-2b3264fefa3d/_tmp_space.db
21/02/17 01:38:32 INFO HiveClientImpl: Warehouse location for Hive client (version 1.2.2) is file:/home/yitaoli/sparkxgb/tests/testthat/spark-warehouse
21/02/17 01:38:32 INFO HiveMetaStore: 0: get_database: default
21/02/17 01:38:32 INFO audit: ugi=yitaoli	ip=unknown-ip-addr	cmd=get_database: default	
21/02/17 01:38:32 INFO HiveMetaStore: 0: get_database: global_temp
21/02/17 01:38:32 INFO audit: ugi=yitaoli	ip=unknown-ip-addr	cmd=get_database: global_temp	
21/02/17 01:38:32 WARN ObjectStore: Failed to get database global_temp, returning NoSuchObjectException
21/02/17 01:38:32 INFO HiveMetaStore: 0: get_table : db=default tbl=iris
21/02/17 01:38:32 INFO audit: ugi=yitaoli	ip=unknown-ip-addr	cmd=get_table : db=default tbl=iris	
21/02/17 01:38:33 INFO HiveMetaStore: 0: get_database: default
21/02/17 01:38:33 INFO audit: ugi=yitaoli	ip=unknown-ip-addr	cmd=get_database: default	
21/02/17 01:38:33 INFO HiveMetaStore: 0: get_database: default
21/02/17 01:38:33 INFO audit: ugi=yitaoli	ip=unknown-ip-addr	cmd=get_database: default	
21/02/17 01:38:33 INFO HiveMetaStore: 0: get_tables: db=default pat=*
21/02/17 01:38:33 INFO audit: ugi=yitaoli	ip=unknown-ip-addr	cmd=get_tables: db=default pat=*	
21/02/17 01:38:33 INFO SparkContext: Starting job: collect at utils.scala:61
21/02/17 01:38:33 INFO DAGScheduler: Got job 0 (collect at utils.scala:61) with 1 output partitions
21/02/17 01:38:33 INFO DAGScheduler: Final stage: ResultStage 0 (collect at utils.scala:61)
21/02/17 01:38:33 INFO DAGScheduler: Parents of final stage: List()
21/02/17 01:38:33 INFO DAGScheduler: Missing parents: List()
21/02/17 01:38:33 INFO DAGScheduler: Submitting ResultStage 0 (MapPartitionsRDD[4] at map at utils.scala:54), which has no missing parents
21/02/17 01:38:33 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 5.9 KB, free 912.3 MB)
21/02/17 01:38:33 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 3.3 KB, free 912.3 MB)
21/02/17 01:38:33 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on localhost:34941 (size: 3.3 KB, free: 912.3 MB)
21/02/17 01:38:33 INFO SparkContext: Created broadcast 0 from broadcast at DAGScheduler.scala:1039
21/02/17 01:38:33 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 0 (MapPartitionsRDD[4] at map at utils.scala:54) (first 15 tasks are for partitions Vector(0))
21/02/17 01:38:33 INFO TaskSchedulerImpl: Adding task set 0.0 with 1 tasks
21/02/17 01:38:33 INFO TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0, localhost, executor driver, partition 0, PROCESS_LOCAL, 7880 bytes)
21/02/17 01:38:33 INFO Executor: Running task 0.0 in stage 0.0 (TID 0)
21/02/17 01:38:33 INFO Executor: Fetching spark://localhost:44413/jars/com.fasterxml.jackson.core_jackson-databind-2.3.1.jar with timestamp 1613525907762
21/02/17 01:38:33 INFO TransportClientFactory: Successfully created connection to localhost/127.0.0.1:44413 after 11 ms (0 ms spent in bootstraps)
21/02/17 01:38:33 INFO Utils: Fetching spark://localhost:44413/jars/com.fasterxml.jackson.core_jackson-databind-2.3.1.jar to /tmp/spark-9437c1c4-850b-4802-ba59-5f700fa4fd01/userFiles-8342364e-5889-4ee1-b7c0-3d2f66adc9a9/fetchFileTemp6859957721925055096.tmp
21/02/17 01:38:33 INFO Executor: Adding file:/tmp/spark-9437c1c4-850b-4802-ba59-5f700fa4fd01/userFiles-8342364e-5889-4ee1-b7c0-3d2f66adc9a9/com.fasterxml.jackson.core_jackson-databind-2.3.1.jar to class loader
21/02/17 01:38:33 INFO Executor: Fetching spark://localhost:44413/jars/com.thoughtworks.paranamer_paranamer-2.6.jar with timestamp 1613525907762
21/02/17 01:38:33 INFO Utils: Fetching spark://localhost:44413/jars/com.thoughtworks.paranamer_paranamer-2.6.jar to /tmp/spark-9437c1c4-850b-4802-ba59-5f700fa4fd01/userFiles-8342364e-5889-4ee1-b7c0-3d2f66adc9a9/fetchFileTemp5260566414648992127.tmp
21/02/17 01:38:33 INFO Executor: Adding file:/tmp/spark-9437c1c4-850b-4802-ba59-5f700fa4fd01/userFiles-8342364e-5889-4ee1-b7c0-3d2f66adc9a9/com.thoughtworks.paranamer_paranamer-2.6.jar to class loader
21/02/17 01:38:33 INFO Executor: Fetching spark://localhost:44413/jars/ml.dmlc_xgboost4j-spark_2.11-1.1.2.jar with timestamp 1613525907760
21/02/17 01:38:33 INFO Utils: Fetching spark://localhost:44413/jars/ml.dmlc_xgboost4j-spark_2.11-1.1.2.jar to /tmp/spark-9437c1c4-850b-4802-ba59-5f700fa4fd01/userFiles-8342364e-5889-4ee1-b7c0-3d2f66adc9a9/fetchFileTemp8988295263590885247.tmp
21/02/17 01:38:33 INFO Executor: Adding file:/tmp/spark-9437c1c4-850b-4802-ba59-5f700fa4fd01/userFiles-8342364e-5889-4ee1-b7c0-3d2f66adc9a9/ml.dmlc_xgboost4j-spark_2.11-1.1.2.jar to class loader
21/02/17 01:38:33 INFO Executor: Fetching spark://localhost:44413/jars/com.fasterxml.jackson.core_jackson-core-2.3.1.jar with timestamp 1613525907762
21/02/17 01:38:33 INFO Utils: Fetching spark://localhost:44413/jars/com.fasterxml.jackson.core_jackson-core-2.3.1.jar to /tmp/spark-9437c1c4-850b-4802-ba59-5f700fa4fd01/userFiles-8342364e-5889-4ee1-b7c0-3d2f66adc9a9/fetchFileTemp4169888482945274813.tmp
21/02/17 01:38:33 INFO Executor: Adding file:/tmp/spark-9437c1c4-850b-4802-ba59-5f700fa4fd01/userFiles-8342364e-5889-4ee1-b7c0-3d2f66adc9a9/com.fasterxml.jackson.core_jackson-core-2.3.1.jar to class loader
21/02/17 01:38:33 INFO Executor: Fetching spark://localhost:44413/jars/commons-logging_commons-logging-1.2.jar with timestamp 1613525907761
21/02/17 01:38:33 INFO Utils: Fetching spark://localhost:44413/jars/commons-logging_commons-logging-1.2.jar to /tmp/spark-9437c1c4-850b-4802-ba59-5f700fa4fd01/userFiles-8342364e-5889-4ee1-b7c0-3d2f66adc9a9/fetchFileTemp432715868407432511.tmp
21/02/17 01:38:33 INFO Executor: Adding file:/tmp/spark-9437c1c4-850b-4802-ba59-5f700fa4fd01/userFiles-8342364e-5889-4ee1-b7c0-3d2f66adc9a9/commons-logging_commons-logging-1.2.jar to class loader
21/02/17 01:38:33 INFO Executor: Fetching spark://localhost:44413/jars/org.json4s_json4s-jackson_2.11-3.2.11.jar with timestamp 1613525907760
21/02/17 01:38:33 INFO Utils: Fetching spark://localhost:44413/jars/org.json4s_json4s-jackson_2.11-3.2.11.jar to /tmp/spark-9437c1c4-850b-4802-ba59-5f700fa4fd01/userFiles-8342364e-5889-4ee1-b7c0-3d2f66adc9a9/fetchFileTemp5794910916612629335.tmp
21/02/17 01:38:33 INFO Executor: Adding file:/tmp/spark-9437c1c4-850b-4802-ba59-5f700fa4fd01/userFiles-8342364e-5889-4ee1-b7c0-3d2f66adc9a9/org.json4s_json4s-jackson_2.11-3.2.11.jar to class loader
21/02/17 01:38:33 INFO Executor: Fetching spark://localhost:44413/jars/com.typesafe_config-1.3.3.jar with timestamp 1613525907761
21/02/17 01:38:33 INFO Utils: Fetching spark://localhost:44413/jars/com.typesafe_config-1.3.3.jar to /tmp/spark-9437c1c4-850b-4802-ba59-5f700fa4fd01/userFiles-8342364e-5889-4ee1-b7c0-3d2f66adc9a9/fetchFileTemp5720584909697797001.tmp
21/02/17 01:38:33 INFO Executor: Adding file:/tmp/spark-9437c1c4-850b-4802-ba59-5f700fa4fd01/userFiles-8342364e-5889-4ee1-b7c0-3d2f66adc9a9/com.typesafe_config-1.3.3.jar to class loader
21/02/17 01:38:33 INFO Executor: Fetching spark://localhost:44413/jars/org.json4s_json4s-ast_2.11-3.2.11.jar with timestamp 1613525907762
21/02/17 01:38:33 INFO Utils: Fetching spark://localhost:44413/jars/org.json4s_json4s-ast_2.11-3.2.11.jar to /tmp/spark-9437c1c4-850b-4802-ba59-5f700fa4fd01/userFiles-8342364e-5889-4ee1-b7c0-3d2f66adc9a9/fetchFileTemp7266417800797278380.tmp
21/02/17 01:38:33 INFO Executor: Adding file:/tmp/spark-9437c1c4-850b-4802-ba59-5f700fa4fd01/userFiles-8342364e-5889-4ee1-b7c0-3d2f66adc9a9/org.json4s_json4s-ast_2.11-3.2.11.jar to class loader
21/02/17 01:38:33 INFO Executor: Fetching spark://localhost:44413/jars/com.typesafe.akka_akka-actor_2.11-2.5.23.jar with timestamp 1613525907761
21/02/17 01:38:33 INFO Utils: Fetching spark://localhost:44413/jars/com.typesafe.akka_akka-actor_2.11-2.5.23.jar to /tmp/spark-9437c1c4-850b-4802-ba59-5f700fa4fd01/userFiles-8342364e-5889-4ee1-b7c0-3d2f66adc9a9/fetchFileTemp1850349429125012663.tmp
21/02/17 01:38:33 INFO Executor: Adding file:/tmp/spark-9437c1c4-850b-4802-ba59-5f700fa4fd01/userFiles-8342364e-5889-4ee1-b7c0-3d2f66adc9a9/com.typesafe.akka_akka-actor_2.11-2.5.23.jar to class loader
21/02/17 01:38:33 INFO Executor: Fetching spark://localhost:44413/jars/sparkxgb-2.3-2.11.jar with timestamp 1613525907760
21/02/17 01:38:33 INFO Utils: Fetching spark://localhost:44413/jars/sparkxgb-2.3-2.11.jar to /tmp/spark-9437c1c4-850b-4802-ba59-5f700fa4fd01/userFiles-8342364e-5889-4ee1-b7c0-3d2f66adc9a9/fetchFileTemp3934557496340581970.tmp
21/02/17 01:38:33 INFO Executor: Adding file:/tmp/spark-9437c1c4-850b-4802-ba59-5f700fa4fd01/userFiles-8342364e-5889-4ee1-b7c0-3d2f66adc9a9/sparkxgb-2.3-2.11.jar to class loader
21/02/17 01:38:33 INFO Executor: Fetching spark://localhost:44413/jars/org.scala-lang.modules_scala-java8-compat_2.11-0.7.0.jar with timestamp 1613525907761
21/02/17 01:38:33 INFO Utils: Fetching spark://localhost:44413/jars/org.scala-lang.modules_scala-java8-compat_2.11-0.7.0.jar to /tmp/spark-9437c1c4-850b-4802-ba59-5f700fa4fd01/userFiles-8342364e-5889-4ee1-b7c0-3d2f66adc9a9/fetchFileTemp4708092900828276174.tmp
21/02/17 01:38:33 INFO Executor: Adding file:/tmp/spark-9437c1c4-850b-4802-ba59-5f700fa4fd01/userFiles-8342364e-5889-4ee1-b7c0-3d2f66adc9a9/org.scala-lang.modules_scala-java8-compat_2.11-0.7.0.jar to class loader
21/02/17 01:38:33 INFO Executor: Fetching spark://localhost:44413/jars/com.fasterxml.jackson.core_jackson-annotations-2.3.0.jar with timestamp 1613525907762
21/02/17 01:38:33 INFO Utils: Fetching spark://localhost:44413/jars/com.fasterxml.jackson.core_jackson-annotations-2.3.0.jar to /tmp/spark-9437c1c4-850b-4802-ba59-5f700fa4fd01/userFiles-8342364e-5889-4ee1-b7c0-3d2f66adc9a9/fetchFileTemp5105487950429200579.tmp
21/02/17 01:38:33 INFO Executor: Adding file:/tmp/spark-9437c1c4-850b-4802-ba59-5f700fa4fd01/userFiles-8342364e-5889-4ee1-b7c0-3d2f66adc9a9/com.fasterxml.jackson.core_jackson-annotations-2.3.0.jar to class loader
21/02/17 01:38:33 INFO Executor: Fetching spark://localhost:44413/jars/sparklyr-2.3-2.11.jar with timestamp 1613525907762
21/02/17 01:38:33 INFO Utils: Fetching spark://localhost:44413/jars/sparklyr-2.3-2.11.jar to /tmp/spark-9437c1c4-850b-4802-ba59-5f700fa4fd01/userFiles-8342364e-5889-4ee1-b7c0-3d2f66adc9a9/fetchFileTemp3007177218295134027.tmp
21/02/17 01:38:33 INFO Executor: Adding file:/tmp/spark-9437c1c4-850b-4802-ba59-5f700fa4fd01/userFiles-8342364e-5889-4ee1-b7c0-3d2f66adc9a9/sparklyr-2.3-2.11.jar to class loader
21/02/17 01:38:33 INFO Executor: Fetching spark://localhost:44413/jars/org.scala-lang_scala-reflect-2.11.12.jar with timestamp 1613525907761
21/02/17 01:38:33 INFO Utils: Fetching spark://localhost:44413/jars/org.scala-lang_scala-reflect-2.11.12.jar to /tmp/spark-9437c1c4-850b-4802-ba59-5f700fa4fd01/userFiles-8342364e-5889-4ee1-b7c0-3d2f66adc9a9/fetchFileTemp7133459980940684062.tmp
21/02/17 01:38:33 INFO Executor: Adding file:/tmp/spark-9437c1c4-850b-4802-ba59-5f700fa4fd01/userFiles-8342364e-5889-4ee1-b7c0-3d2f66adc9a9/org.scala-lang_scala-reflect-2.11.12.jar to class loader
21/02/17 01:38:33 INFO Executor: Fetching spark://localhost:44413/jars/ml.dmlc_xgboost4j_2.11-1.1.2.jar with timestamp 1613525907761
21/02/17 01:38:33 INFO Utils: Fetching spark://localhost:44413/jars/ml.dmlc_xgboost4j_2.11-1.1.2.jar to /tmp/spark-9437c1c4-850b-4802-ba59-5f700fa4fd01/userFiles-8342364e-5889-4ee1-b7c0-3d2f66adc9a9/fetchFileTemp8007130224373201749.tmp
21/02/17 01:38:33 INFO Executor: Adding file:/tmp/spark-9437c1c4-850b-4802-ba59-5f700fa4fd01/userFiles-8342364e-5889-4ee1-b7c0-3d2f66adc9a9/ml.dmlc_xgboost4j_2.11-1.1.2.jar to class loader
21/02/17 01:38:33 INFO Executor: Fetching spark://localhost:44413/jars/org.json4s_json4s-core_2.11-3.2.11.jar with timestamp 1613525907762
21/02/17 01:38:33 INFO Utils: Fetching spark://localhost:44413/jars/org.json4s_json4s-core_2.11-3.2.11.jar to /tmp/spark-9437c1c4-850b-4802-ba59-5f700fa4fd01/userFiles-8342364e-5889-4ee1-b7c0-3d2f66adc9a9/fetchFileTemp6902179736058051459.tmp
21/02/17 01:38:33 INFO Executor: Adding file:/tmp/spark-9437c1c4-850b-4802-ba59-5f700fa4fd01/userFiles-8342364e-5889-4ee1-b7c0-3d2f66adc9a9/org.json4s_json4s-core_2.11-3.2.11.jar to class loader
21/02/17 01:38:33 INFO Executor: Fetching spark://localhost:44413/jars/org.scala-lang_scala-compiler-2.11.12.jar with timestamp 1613525907761
21/02/17 01:38:33 INFO Utils: Fetching spark://localhost:44413/jars/org.scala-lang_scala-compiler-2.11.12.jar to /tmp/spark-9437c1c4-850b-4802-ba59-5f700fa4fd01/userFiles-8342364e-5889-4ee1-b7c0-3d2f66adc9a9/fetchFileTemp1557985295946724534.tmp
21/02/17 01:38:33 INFO Executor: Adding file:/tmp/spark-9437c1c4-850b-4802-ba59-5f700fa4fd01/userFiles-8342364e-5889-4ee1-b7c0-3d2f66adc9a9/org.scala-lang_scala-compiler-2.11.12.jar to class loader
21/02/17 01:38:33 INFO Executor: Fetching spark://localhost:44413/jars/org.scala-lang_scalap-2.11.0.jar with timestamp 1613525907762
21/02/17 01:38:33 INFO Utils: Fetching spark://localhost:44413/jars/org.scala-lang_scalap-2.11.0.jar to /tmp/spark-9437c1c4-850b-4802-ba59-5f700fa4fd01/userFiles-8342364e-5889-4ee1-b7c0-3d2f66adc9a9/fetchFileTemp4469572879681922143.tmp
21/02/17 01:38:33 INFO Executor: Adding file:/tmp/spark-9437c1c4-850b-4802-ba59-5f700fa4fd01/userFiles-8342364e-5889-4ee1-b7c0-3d2f66adc9a9/org.scala-lang_scalap-2.11.0.jar to class loader
21/02/17 01:38:33 INFO Executor: Fetching spark://localhost:44413/jars/org.scala-lang.modules_scala-parser-combinators_2.11-1.0.4.jar with timestamp 1613525907762
21/02/17 01:38:33 INFO Utils: Fetching spark://localhost:44413/jars/org.scala-lang.modules_scala-parser-combinators_2.11-1.0.4.jar to /tmp/spark-9437c1c4-850b-4802-ba59-5f700fa4fd01/userFiles-8342364e-5889-4ee1-b7c0-3d2f66adc9a9/fetchFileTemp4284539032742668450.tmp
21/02/17 01:38:33 INFO Executor: Adding file:/tmp/spark-9437c1c4-850b-4802-ba59-5f700fa4fd01/userFiles-8342364e-5889-4ee1-b7c0-3d2f66adc9a9/org.scala-lang.modules_scala-parser-combinators_2.11-1.0.4.jar to class loader
21/02/17 01:38:33 INFO Executor: Fetching spark://localhost:44413/jars/org.scala-lang.modules_scala-xml_2.11-1.0.5.jar with timestamp 1613525907761
21/02/17 01:38:33 INFO Utils: Fetching spark://localhost:44413/jars/org.scala-lang.modules_scala-xml_2.11-1.0.5.jar to /tmp/spark-9437c1c4-850b-4802-ba59-5f700fa4fd01/userFiles-8342364e-5889-4ee1-b7c0-3d2f66adc9a9/fetchFileTemp6007670124731121145.tmp
21/02/17 01:38:33 INFO Executor: Adding file:/tmp/spark-9437c1c4-850b-4802-ba59-5f700fa4fd01/userFiles-8342364e-5889-4ee1-b7c0-3d2f66adc9a9/org.scala-lang.modules_scala-xml_2.11-1.0.5.jar to class loader
21/02/17 01:38:33 INFO Executor: Fetching spark://localhost:44413/jars/com.esotericsoftware.kryo_kryo-2.22.jar with timestamp 1613525907761
21/02/17 01:38:33 INFO Utils: Fetching spark://localhost:44413/jars/com.esotericsoftware.kryo_kryo-2.22.jar to /tmp/spark-9437c1c4-850b-4802-ba59-5f700fa4fd01/userFiles-8342364e-5889-4ee1-b7c0-3d2f66adc9a9/fetchFileTemp413858536821748661.tmp
21/02/17 01:38:33 INFO Executor: Adding file:/tmp/spark-9437c1c4-850b-4802-ba59-5f700fa4fd01/userFiles-8342364e-5889-4ee1-b7c0-3d2f66adc9a9/com.esotericsoftware.kryo_kryo-2.22.jar to class loader
21/02/17 01:38:34 INFO CodeGenerator: Code generated in 243.609182 ms
21/02/17 01:38:34 INFO Executor: Finished task 0.0 in stage 0.0 (TID 0). 1013 bytes result sent to driver
21/02/17 01:38:34 INFO TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in 560 ms on localhost (executor driver) (1/1)
21/02/17 01:38:34 INFO TaskSchedulerImpl: Removed TaskSet 0.0, whose tasks have all completed, from pool 
21/02/17 01:38:34 INFO DAGScheduler: ResultStage 0 (collect at utils.scala:61) finished in 0.654 s
21/02/17 01:38:34 INFO DAGScheduler: Job 0 finished: collect at utils.scala:61, took 0.689218 s
21/02/17 01:38:34 INFO CodeGenerator: Code generated in 9.498241 ms
21/02/17 01:38:34 INFO CodeGenerator: Code generated in 13.436723 ms
21/02/17 01:38:34 INFO SparkContext: Starting job: collect at utils.scala:135
21/02/17 01:38:34 INFO DAGScheduler: Got job 1 (collect at utils.scala:135) with 1 output partitions
21/02/17 01:38:34 INFO DAGScheduler: Final stage: ResultStage 1 (collect at utils.scala:135)
21/02/17 01:38:34 INFO DAGScheduler: Parents of final stage: List()
21/02/17 01:38:34 INFO DAGScheduler: Missing parents: List()
21/02/17 01:38:34 INFO DAGScheduler: Submitting ResultStage 1 (MapPartitionsRDD[9] at collect at utils.scala:135), which has no missing parents
21/02/17 01:38:34 INFO MemoryStore: Block broadcast_1 stored as values in memory (estimated size 6.4 KB, free 912.3 MB)
21/02/17 01:38:34 INFO MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 3.2 KB, free 912.3 MB)
21/02/17 01:38:34 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on localhost:34941 (size: 3.2 KB, free: 912.3 MB)
21/02/17 01:38:34 INFO SparkContext: Created broadcast 1 from broadcast at DAGScheduler.scala:1039
21/02/17 01:38:34 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 1 (MapPartitionsRDD[9] at collect at utils.scala:135) (first 15 tasks are for partitions Vector(0))
21/02/17 01:38:34 INFO TaskSchedulerImpl: Adding task set 1.0 with 1 tasks
21/02/17 01:38:34 INFO TaskSetManager: Starting task 0.0 in stage 1.0 (TID 1, localhost, executor driver, partition 0, PROCESS_LOCAL, 8067 bytes)
21/02/17 01:38:34 INFO Executor: Running task 0.0 in stage 1.0 (TID 1)
21/02/17 01:38:34 INFO CodeGenerator: Code generated in 8.556369 ms
21/02/17 01:38:34 INFO Executor: Finished task 0.0 in stage 1.0 (TID 1). 1286 bytes result sent to driver
21/02/17 01:38:34 INFO TaskSetManager: Finished task 0.0 in stage 1.0 (TID 1) in 26 ms on localhost (executor driver) (1/1)
21/02/17 01:38:34 INFO TaskSchedulerImpl: Removed TaskSet 1.0, whose tasks have all completed, from pool 
21/02/17 01:38:34 INFO DAGScheduler: ResultStage 1 (collect at utils.scala:135) finished in 0.033 s
21/02/17 01:38:34 INFO DAGScheduler: Job 1 finished: collect at utils.scala:135, took 0.035368 s
21/02/17 01:38:34 INFO CodeGenerator: Code generated in 16.325494 ms
21/02/17 01:38:34 INFO CodeGenerator: Code generated in 14.654681 ms
21/02/17 01:38:34 INFO SparkContext: Starting job: count at utils.scala:135
21/02/17 01:38:34 INFO DAGScheduler: Registering RDD 12 (count at utils.scala:135)
21/02/17 01:38:34 INFO DAGScheduler: Got job 2 (count at utils.scala:135) with 1 output partitions
21/02/17 01:38:34 INFO DAGScheduler: Final stage: ResultStage 3 (count at utils.scala:135)
21/02/17 01:38:34 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 2)
21/02/17 01:38:34 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 2)
21/02/17 01:38:34 INFO DAGScheduler: Submitting ShuffleMapStage 2 (MapPartitionsRDD[12] at count at utils.scala:135), which has no missing parents
21/02/17 01:38:34 INFO MemoryStore: Block broadcast_2 stored as values in memory (estimated size 8.9 KB, free 912.3 MB)
21/02/17 01:38:34 INFO MemoryStore: Block broadcast_2_piece0 stored as bytes in memory (estimated size 4.5 KB, free 912.3 MB)
21/02/17 01:38:34 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on localhost:34941 (size: 4.5 KB, free: 912.3 MB)
21/02/17 01:38:34 INFO SparkContext: Created broadcast 2 from broadcast at DAGScheduler.scala:1039
21/02/17 01:38:34 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 2 (MapPartitionsRDD[12] at count at utils.scala:135) (first 15 tasks are for partitions Vector(0))
21/02/17 01:38:34 INFO TaskSchedulerImpl: Adding task set 2.0 with 1 tasks
21/02/17 01:38:34 INFO TaskSetManager: Starting task 0.0 in stage 2.0 (TID 2, localhost, executor driver, partition 0, PROCESS_LOCAL, 8056 bytes)
21/02/17 01:38:34 INFO Executor: Running task 0.0 in stage 2.0 (TID 2)
21/02/17 01:38:34 INFO Executor: Finished task 0.0 in stage 2.0 (TID 2). 1542 bytes result sent to driver
21/02/17 01:38:34 INFO TaskSetManager: Finished task 0.0 in stage 2.0 (TID 2) in 37 ms on localhost (executor driver) (1/1)
21/02/17 01:38:34 INFO TaskSchedulerImpl: Removed TaskSet 2.0, whose tasks have all completed, from pool 
21/02/17 01:38:34 INFO DAGScheduler: ShuffleMapStage 2 (count at utils.scala:135) finished in 0.048 s
21/02/17 01:38:34 INFO DAGScheduler: looking for newly runnable stages
21/02/17 01:38:34 INFO DAGScheduler: running: Set()
21/02/17 01:38:34 INFO DAGScheduler: waiting: Set(ResultStage 3)
21/02/17 01:38:34 INFO DAGScheduler: failed: Set()
21/02/17 01:38:34 INFO DAGScheduler: Submitting ResultStage 3 (MapPartitionsRDD[15] at count at utils.scala:135), which has no missing parents
21/02/17 01:38:34 INFO MemoryStore: Block broadcast_3 stored as values in memory (estimated size 7.3 KB, free 912.3 MB)
21/02/17 01:38:34 INFO MemoryStore: Block broadcast_3_piece0 stored as bytes in memory (estimated size 3.8 KB, free 912.3 MB)
21/02/17 01:38:34 INFO BlockManagerInfo: Added broadcast_3_piece0 in memory on localhost:34941 (size: 3.8 KB, free: 912.3 MB)
21/02/17 01:38:34 INFO SparkContext: Created broadcast 3 from broadcast at DAGScheduler.scala:1039
21/02/17 01:38:34 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 3 (MapPartitionsRDD[15] at count at utils.scala:135) (first 15 tasks are for partitions Vector(0))
21/02/17 01:38:34 INFO TaskSchedulerImpl: Adding task set 3.0 with 1 tasks
21/02/17 01:38:34 INFO TaskSetManager: Starting task 0.0 in stage 3.0 (TID 3, localhost, executor driver, partition 0, NODE_LOCAL, 7754 bytes)
21/02/17 01:38:34 INFO Executor: Running task 0.0 in stage 3.0 (TID 3)
21/02/17 01:38:34 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
21/02/17 01:38:34 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 5 ms
21/02/17 01:38:34 INFO Executor: Finished task 0.0 in stage 3.0 (TID 3). 1782 bytes result sent to driver
21/02/17 01:38:34 INFO TaskSetManager: Finished task 0.0 in stage 3.0 (TID 3) in 29 ms on localhost (executor driver) (1/1)
21/02/17 01:38:34 INFO TaskSchedulerImpl: Removed TaskSet 3.0, whose tasks have all completed, from pool 
21/02/17 01:38:34 INFO DAGScheduler: ResultStage 3 (count at utils.scala:135) finished in 0.039 s
21/02/17 01:38:34 INFO DAGScheduler: Job 2 finished: count at utils.scala:135, took 0.103873 s
21/02/17 01:38:34 INFO SparkContext: Starting job: collect at utils.scala:135
21/02/17 01:38:34 INFO DAGScheduler: Got job 3 (collect at utils.scala:135) with 1 output partitions
21/02/17 01:38:34 INFO DAGScheduler: Final stage: ResultStage 4 (collect at utils.scala:135)
21/02/17 01:38:34 INFO DAGScheduler: Parents of final stage: List()
21/02/17 01:38:34 INFO DAGScheduler: Missing parents: List()
21/02/17 01:38:34 INFO DAGScheduler: Submitting ResultStage 4 (MapPartitionsRDD[20] at collect at utils.scala:135), which has no missing parents
21/02/17 01:38:34 INFO MemoryStore: Block broadcast_4 stored as values in memory (estimated size 6.4 KB, free 912.3 MB)
21/02/17 01:38:34 INFO MemoryStore: Block broadcast_4_piece0 stored as bytes in memory (estimated size 3.2 KB, free 912.2 MB)
21/02/17 01:38:34 INFO BlockManagerInfo: Added broadcast_4_piece0 in memory on localhost:34941 (size: 3.2 KB, free: 912.3 MB)
21/02/17 01:38:34 INFO SparkContext: Created broadcast 4 from broadcast at DAGScheduler.scala:1039
21/02/17 01:38:34 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 4 (MapPartitionsRDD[20] at collect at utils.scala:135) (first 15 tasks are for partitions Vector(0))
21/02/17 01:38:34 INFO TaskSchedulerImpl: Adding task set 4.0 with 1 tasks
21/02/17 01:38:34 INFO TaskSetManager: Starting task 0.0 in stage 4.0 (TID 4, localhost, executor driver, partition 0, PROCESS_LOCAL, 8067 bytes)
21/02/17 01:38:34 INFO Executor: Running task 0.0 in stage 4.0 (TID 4)
21/02/17 01:38:34 INFO Executor: Finished task 0.0 in stage 4.0 (TID 4). 1286 bytes result sent to driver
21/02/17 01:38:34 INFO TaskSetManager: Finished task 0.0 in stage 4.0 (TID 4) in 6 ms on localhost (executor driver) (1/1)
21/02/17 01:38:34 INFO TaskSchedulerImpl: Removed TaskSet 4.0, whose tasks have all completed, from pool 
21/02/17 01:38:34 INFO DAGScheduler: ResultStage 4 (collect at utils.scala:135) finished in 0.011 s
21/02/17 01:38:34 INFO DAGScheduler: Job 3 finished: collect at utils.scala:135, took 0.014729 s
21/02/17 01:38:35 INFO SparkContext: Starting job: count at utils.scala:135
21/02/17 01:38:35 INFO DAGScheduler: Registering RDD 23 (count at utils.scala:135)
21/02/17 01:38:35 INFO DAGScheduler: Got job 4 (count at utils.scala:135) with 1 output partitions
21/02/17 01:38:35 INFO DAGScheduler: Final stage: ResultStage 6 (count at utils.scala:135)
21/02/17 01:38:35 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 5)
21/02/17 01:38:35 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 5)
21/02/17 01:38:35 INFO DAGScheduler: Submitting ShuffleMapStage 5 (MapPartitionsRDD[23] at count at utils.scala:135), which has no missing parents
21/02/17 01:38:35 INFO MemoryStore: Block broadcast_5 stored as values in memory (estimated size 8.9 KB, free 912.2 MB)
21/02/17 01:38:35 INFO MemoryStore: Block broadcast_5_piece0 stored as bytes in memory (estimated size 4.5 KB, free 912.2 MB)
21/02/17 01:38:35 INFO BlockManagerInfo: Added broadcast_5_piece0 in memory on localhost:34941 (size: 4.5 KB, free: 912.3 MB)
21/02/17 01:38:35 INFO SparkContext: Created broadcast 5 from broadcast at DAGScheduler.scala:1039
21/02/17 01:38:35 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 5 (MapPartitionsRDD[23] at count at utils.scala:135) (first 15 tasks are for partitions Vector(0))
21/02/17 01:38:35 INFO TaskSchedulerImpl: Adding task set 5.0 with 1 tasks
21/02/17 01:38:35 INFO TaskSetManager: Starting task 0.0 in stage 5.0 (TID 5, localhost, executor driver, partition 0, PROCESS_LOCAL, 8056 bytes)
21/02/17 01:38:35 INFO Executor: Running task 0.0 in stage 5.0 (TID 5)
21/02/17 01:38:35 INFO Executor: Finished task 0.0 in stage 5.0 (TID 5). 1499 bytes result sent to driver
21/02/17 01:38:35 INFO TaskSetManager: Finished task 0.0 in stage 5.0 (TID 5) in 5 ms on localhost (executor driver) (1/1)
21/02/17 01:38:35 INFO TaskSchedulerImpl: Removed TaskSet 5.0, whose tasks have all completed, from pool 
21/02/17 01:38:35 INFO DAGScheduler: ShuffleMapStage 5 (count at utils.scala:135) finished in 0.011 s
21/02/17 01:38:35 INFO DAGScheduler: looking for newly runnable stages
21/02/17 01:38:35 INFO DAGScheduler: running: Set()
21/02/17 01:38:35 INFO DAGScheduler: waiting: Set(ResultStage 6)
21/02/17 01:38:35 INFO DAGScheduler: failed: Set()
21/02/17 01:38:35 INFO DAGScheduler: Submitting ResultStage 6 (MapPartitionsRDD[26] at count at utils.scala:135), which has no missing parents
21/02/17 01:38:35 INFO MemoryStore: Block broadcast_6 stored as values in memory (estimated size 7.3 KB, free 912.2 MB)
21/02/17 01:38:35 INFO MemoryStore: Block broadcast_6_piece0 stored as bytes in memory (estimated size 3.8 KB, free 912.2 MB)
21/02/17 01:38:35 INFO BlockManagerInfo: Added broadcast_6_piece0 in memory on localhost:34941 (size: 3.8 KB, free: 912.3 MB)
21/02/17 01:38:35 INFO SparkContext: Created broadcast 6 from broadcast at DAGScheduler.scala:1039
21/02/17 01:38:35 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 6 (MapPartitionsRDD[26] at count at utils.scala:135) (first 15 tasks are for partitions Vector(0))
21/02/17 01:38:35 INFO TaskSchedulerImpl: Adding task set 6.0 with 1 tasks
21/02/17 01:38:35 INFO TaskSetManager: Starting task 0.0 in stage 6.0 (TID 6, localhost, executor driver, partition 0, NODE_LOCAL, 7754 bytes)
21/02/17 01:38:35 INFO Executor: Running task 0.0 in stage 6.0 (TID 6)
21/02/17 01:38:35 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
21/02/17 01:38:35 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
21/02/17 01:38:35 INFO Executor: Finished task 0.0 in stage 6.0 (TID 6). 1782 bytes result sent to driver
21/02/17 01:38:35 INFO TaskSetManager: Finished task 0.0 in stage 6.0 (TID 6) in 4 ms on localhost (executor driver) (1/1)
21/02/17 01:38:35 INFO TaskSchedulerImpl: Removed TaskSet 6.0, whose tasks have all completed, from pool 
21/02/17 01:38:35 INFO DAGScheduler: ResultStage 6 (count at utils.scala:135) finished in 0.009 s
21/02/17 01:38:35 INFO DAGScheduler: Job 4 finished: count at utils.scala:135, took 0.023313 s
21/02/17 01:38:35 INFO CodeGenerator: Code generated in 45.338721 ms
21/02/17 01:38:35 INFO XGBoostSpark: Running XGBoost 1.1.2 with parameters:
alpha -> 0.0
min_child_weight -> 1.0
sample_type -> uniform
base_score -> 0.5
rabit_timeout -> -1
colsample_bylevel -> 1.0
grow_policy -> depthwise
skip_drop -> 0.0
lambda_bias -> 0.0
silent -> 0
scale_pos_weight -> 1.0
seed -> 0
cache_training_set -> false
features_col -> features
num_early_stopping_rounds -> 0
label_col -> label
num_workers -> 1
subsample -> 1.0
lambda -> 1.0
max_depth -> 6
tree_limit -> 0
custom_eval -> null
dmlc_worker_connect_retry -> 5
rate_drop -> 0.0
max_bin -> 16
train_test_ratio -> 1.0
use_external_memory -> false
objective -> reg:linear
eval_metric -> rmse
num_round -> 1
maximize_evaluation_metrics -> false
timeout_request_workers -> 1800000
missing -> NaN
rabit_ring_reduce_threshold -> 32768
checkpoint_path -> 
tracker_conf -> TrackerConf(0,python)
tree_method -> auto
max_delta_step -> 0.0
eta -> 0.3
verbosity -> 1
colsample_bytree -> 1.0
objective_type -> regression
normalize_type -> tree
allow_non_zero_for_missing -> false
custom_obj -> null
gamma -> 0.0
sketch_eps -> 0.03
nthread -> 1
prediction_col -> prediction
checkpoint_interval -> -1
21/02/17 01:38:35 WARN XGBoostSpark: train_test_ratio is deprecated since XGBoost 0.82, we recommend to explicitly pass a training and multiple evaluation datasets by passing 'eval_sets' and 'eval_set_names'
21/02/17 01:38:35 INFO RabitTracker$TrackerProcessLogger: 2021-02-17 01:38:35,919 INFO start listen on 192.168.2.12:9091
21/02/17 01:38:35 INFO XGBoostSpark: starting training with timeout set as 1800000 ms for waiting for resources
21/02/17 01:38:35 INFO SparkContext: Starting job: foreachPartition at XGBoost.scala:565
21/02/17 01:38:35 INFO DAGScheduler: Got job 5 (foreachPartition at XGBoost.scala:565) with 1 output partitions
21/02/17 01:38:35 INFO DAGScheduler: Final stage: ResultStage 7 (foreachPartition at XGBoost.scala:565)
21/02/17 01:38:35 INFO DAGScheduler: Parents of final stage: List()
21/02/17 01:38:35 INFO DAGScheduler: Missing parents: List()
21/02/17 01:38:35 INFO DAGScheduler: Submitting ResultStage 7 (MapPartitionsRDD[35] at mapPartitions at XGBoost.scala:450), which has no missing parents
21/02/17 01:38:35 INFO MemoryStore: Block broadcast_7 stored as values in memory (estimated size 33.9 KB, free 912.2 MB)
21/02/17 01:38:35 INFO MemoryStore: Block broadcast_7_piece0 stored as bytes in memory (estimated size 14.2 KB, free 912.2 MB)
21/02/17 01:38:35 INFO BlockManagerInfo: Added broadcast_7_piece0 in memory on localhost:34941 (size: 14.2 KB, free: 912.3 MB)
21/02/17 01:38:35 INFO SparkContext: Created broadcast 7 from broadcast at DAGScheduler.scala:1039
21/02/17 01:38:35 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 7 (MapPartitionsRDD[35] at mapPartitions at XGBoost.scala:450) (first 15 tasks are for partitions Vector(0))
21/02/17 01:38:35 INFO TaskSchedulerImpl: Adding task set 7.0 with 1 tasks
21/02/17 01:38:35 INFO TaskSetManager: Starting task 0.0 in stage 7.0 (TID 7, localhost, executor driver, partition 0, PROCESS_LOCAL, 18998 bytes)
21/02/17 01:38:35 INFO Executor: Running task 0.0 in stage 7.0 (TID 7)
21/02/17 01:38:36 INFO CodeGenerator: Code generated in 9.19662 ms
21/02/17 01:38:36 INFO MemoryStore: Block rdd_17_0 stored as values in memory (estimated size 5.6 KB, free 912.2 MB)
21/02/17 01:38:36 INFO BlockManagerInfo: Added rdd_17_0 in memory on localhost:34941 (size: 5.6 KB, free: 912.3 MB)
21/02/17 01:38:36 INFO CodeGenerator: Code generated in 4.376945 ms
21/02/17 01:38:36 INFO CodeGenerator: Code generated in 19.706329 ms
21/02/17 01:38:36 INFO CodeGenerator: Code generated in 9.660365 ms
21/02/17 01:38:36 INFO RabitTracker$TrackerProcessLogger: /tmp/tracker1790174546856936330.py:330: DeprecationWarning: isAlive() is deprecated, use is_alive() instead
21/02/17 01:38:36 INFO RabitTracker$TrackerProcessLogger:   while self.thread.isAlive():
21/02/17 01:38:36 INFO RabitTracker$TrackerProcessLogger: 2021-02-17 01:38:36,190 DEBUG Recieve start signal from 192.168.2.12; assign rank 0
21/02/17 01:38:36 INFO RabitTracker$TrackerProcessLogger: 2021-02-17 01:38:36,190 INFO @tracker All of 1 nodes getting started
21/02/17 01:38:36 INFO RabitTracker$TrackerProcessLogger: 2021-02-17 01:38:36,199 INFO [0]	train-rmse:2.633044
21/02/17 01:38:36 INFO RabitTracker$TrackerProcessLogger: 2021-02-17 01:38:36,200 DEBUG Recieve shutdown signal from 0
21/02/17 01:38:36 INFO RabitTracker$TrackerProcessLogger: 2021-02-17 01:38:36,200 INFO @tracker All nodes finishes job
21/02/17 01:38:36 INFO RabitTracker$TrackerProcessLogger: 2021-02-17 01:38:36,200 INFO @tracker 0.009870290756225586 secs between node start and job finish
21/02/17 01:38:36 INFO MemoryStore: Block rdd_35_0 stored as values in memory (estimated size 192.0 B, free 912.2 MB)
21/02/17 01:38:36 INFO BlockManagerInfo: Added rdd_35_0 in memory on localhost:34941 (size: 192.0 B, free: 912.3 MB)
21/02/17 01:38:36 INFO RabitTracker: Tracker Process ends with exit code 0
21/02/17 01:38:36 INFO RabitTracker$TrackerProcessLogger: Tracker Process ends with exit code 0
21/02/17 01:38:36 INFO XGBoostSpark: Rabit returns with exit code 0
21/02/17 01:38:36 INFO Executor: 1 block locks were not released by TID = 7:
[rdd_35_0]
21/02/17 01:38:36 INFO Executor: Finished task 0.0 in stage 7.0 (TID 7). 1303 bytes result sent to driver
21/02/17 01:38:36 INFO TaskSetManager: Finished task 0.0 in stage 7.0 (TID 7) in 223 ms on localhost (executor driver) (1/1)
21/02/17 01:38:36 INFO TaskSchedulerImpl: Removed TaskSet 7.0, whose tasks have all completed, from pool 
21/02/17 01:38:36 INFO DAGScheduler: ResultStage 7 (foreachPartition at XGBoost.scala:565) finished in 0.264 s
21/02/17 01:38:36 INFO DAGScheduler: Job 5 finished: foreachPartition at XGBoost.scala:565, took 0.270980 s
21/02/17 01:38:36 INFO SparkContext: Starting job: first at XGBoost.scala:685
21/02/17 01:38:36 INFO DAGScheduler: Got job 6 (first at XGBoost.scala:685) with 1 output partitions
21/02/17 01:38:36 INFO DAGScheduler: Final stage: ResultStage 8 (first at XGBoost.scala:685)
21/02/17 01:38:36 INFO DAGScheduler: Parents of final stage: List()
21/02/17 01:38:36 INFO DAGScheduler: Missing parents: List()
21/02/17 01:38:36 INFO DAGScheduler: Submitting ResultStage 8 (MapPartitionsRDD[35] at mapPartitions at XGBoost.scala:450), which has no missing parents
21/02/17 01:38:36 INFO MemoryStore: Block broadcast_8 stored as values in memory (estimated size 34.0 KB, free 912.1 MB)
21/02/17 01:38:36 INFO MemoryStore: Block broadcast_8_piece0 stored as bytes in memory (estimated size 14.3 KB, free 912.1 MB)
21/02/17 01:38:36 INFO BlockManagerInfo: Added broadcast_8_piece0 in memory on localhost:34941 (size: 14.3 KB, free: 912.2 MB)
21/02/17 01:38:36 INFO SparkContext: Created broadcast 8 from broadcast at DAGScheduler.scala:1039
21/02/17 01:38:36 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 8 (MapPartitionsRDD[35] at mapPartitions at XGBoost.scala:450) (first 15 tasks are for partitions Vector(0))
21/02/17 01:38:36 INFO TaskSchedulerImpl: Adding task set 8.0 with 1 tasks
21/02/17 01:38:36 INFO TaskSetManager: Starting task 0.0 in stage 8.0 (TID 8, localhost, executor driver, partition 0, PROCESS_LOCAL, 18998 bytes)
21/02/17 01:38:36 INFO Executor: Running task 0.0 in stage 8.0 (TID 8)
21/02/17 01:38:36 INFO BlockManager: Found block rdd_35_0 locally
21/02/17 01:38:36 INFO Executor: 1 block locks were not released by TID = 8:
[rdd_35_0]
21/02/17 01:38:36 INFO Executor: Finished task 0.0 in stage 8.0 (TID 8). 2551 bytes result sent to driver
21/02/17 01:38:36 INFO TaskSetManager: Finished task 0.0 in stage 8.0 (TID 8) in 10 ms on localhost (executor driver) (1/1)
21/02/17 01:38:36 INFO TaskSchedulerImpl: Removed TaskSet 8.0, whose tasks have all completed, from pool 
21/02/17 01:38:36 INFO DAGScheduler: ResultStage 8 (first at XGBoost.scala:685) finished in 0.017 s
21/02/17 01:38:36 INFO DAGScheduler: Job 6 finished: first at XGBoost.scala:685, took 0.019030 s
21/02/17 01:38:36 INFO MapPartitionsRDD: Removing RDD 35 from persistence list
21/02/17 01:38:36 INFO BlockManager: Removing RDD 35
21/02/17 01:38:36 INFO MemoryStore: Block broadcast_9 stored as values in memory (estimated size 64.0 B, free 912.1 MB)
21/02/17 01:38:36 INFO MemoryStore: Block broadcast_9_piece0 stored as bytes in memory (estimated size 510.0 B, free 912.1 MB)
21/02/17 01:38:36 INFO BlockManagerInfo: Added broadcast_9_piece0 in memory on localhost:34941 (size: 510.0 B, free: 912.2 MB)
21/02/17 01:38:36 INFO SparkContext: Created broadcast 9 from broadcast at XGBoostRegressor.scala:271
21/02/17 01:38:36 INFO ContextCleaner: Cleaned accumulator 53
21/02/17 01:38:36 INFO ContextCleaner: Cleaned accumulator 150
21/02/17 01:38:36 INFO ContextCleaner: Cleaned accumulator 184
21/02/17 01:38:36 INFO BlockManagerInfo: Removed broadcast_4_piece0 on localhost:34941 in memory (size: 3.2 KB, free: 912.2 MB)
21/02/17 01:38:36 INFO ContextCleaner: Cleaned accumulator 97
21/02/17 01:38:36 INFO ContextCleaner: Cleaned accumulator 46
21/02/17 01:38:36 INFO ContextCleaner: Cleaned accumulator 36
21/02/17 01:38:36 INFO ContextCleaner: Cleaned accumulator 171
21/02/17 01:38:36 INFO ContextCleaner: Cleaned accumulator 206
21/02/17 01:38:36 INFO ContextCleaner: Cleaned accumulator 75
21/02/17 01:38:36 INFO ContextCleaner: Cleaned accumulator 194
21/02/17 01:38:36 INFO ContextCleaner: Cleaned accumulator 71
21/02/17 01:38:36 INFO ContextCleaner: Cleaned accumulator 131
21/02/17 01:38:36 INFO ContextCleaner: Cleaned accumulator 77
21/02/17 01:38:36 INFO ContextCleaner: Cleaned accumulator 263
21/02/17 01:38:36 INFO ContextCleaner: Cleaned accumulator 28
21/02/17 01:38:36 INFO ContextCleaner: Cleaned accumulator 185
21/02/17 01:38:36 INFO ContextCleaner: Cleaned accumulator 235
21/02/17 01:38:36 INFO BlockManagerInfo: Removed broadcast_5_piece0 on localhost:34941 in memory (size: 4.5 KB, free: 912.2 MB)
21/02/17 01:38:36 INFO ContextCleaner: Cleaned accumulator 26
21/02/17 01:38:36 INFO ContextCleaner: Cleaned accumulator 44
21/02/17 01:38:36 INFO ContextCleaner: Cleaned accumulator 140
21/02/17 01:38:36 INFO ContextCleaner: Cleaned accumulator 243
21/02/17 01:38:36 INFO ContextCleaner: Cleaned accumulator 107
21/02/17 01:38:36 INFO ContextCleaner: Cleaned accumulator 127
21/02/17 01:38:36 INFO ContextCleaner: Cleaned accumulator 142
21/02/17 01:38:36 INFO ContextCleaner: Cleaned accumulator 37
21/02/17 01:38:36 INFO ContextCleaner: Cleaned accumulator 248
21/02/17 01:38:36 INFO ContextCleaner: Cleaned accumulator 203
21/02/17 01:38:36 INFO ContextCleaner: Cleaned accumulator 218
21/02/17 01:38:36 INFO ContextCleaner: Cleaned accumulator 230
21/02/17 01:38:36 INFO ContextCleaner: Cleaned accumulator 241
21/02/17 01:38:36 INFO ContextCleaner: Cleaned accumulator 147
21/02/17 01:38:36 INFO ContextCleaner: Cleaned accumulator 199
21/02/17 01:38:36 INFO ContextCleaner: Cleaned accumulator 90
21/02/17 01:38:36 INFO ContextCleaner: Cleaned accumulator 123
21/02/17 01:38:36 INFO ContextCleaner: Cleaned accumulator 29
21/02/17 01:38:36 INFO ContextCleaner: Cleaned accumulator 104
21/02/17 01:38:36 INFO ContextCleaner: Cleaned accumulator 72
21/02/17 01:38:36 INFO ContextCleaner: Cleaned accumulator 257
21/02/17 01:38:36 INFO ContextCleaner: Cleaned accumulator 52
21/02/17 01:38:36 INFO ContextCleaner: Cleaned accumulator 227
21/02/17 01:38:36 INFO ContextCleaner: Cleaned accumulator 81
21/02/17 01:38:36 INFO ContextCleaner: Cleaned accumulator 220
21/02/17 01:38:36 INFO ContextCleaner: Cleaned accumulator 91
21/02/17 01:38:36 INFO ContextCleaner: Cleaned accumulator 260
21/02/17 01:38:36 INFO ContextCleaner: Cleaned accumulator 125
21/02/17 01:38:36 INFO ContextCleaner: Cleaned accumulator 247
21/02/17 01:38:36 INFO ContextCleaner: Cleaned accumulator 224
21/02/17 01:38:36 INFO ContextCleaner: Cleaned accumulator 49
21/02/17 01:38:36 INFO ContextCleaner: Cleaned shuffle 1
21/02/17 01:38:36 INFO ContextCleaner: Cleaned accumulator 122
21/02/17 01:38:36 INFO ContextCleaner: Cleaned accumulator 236
21/02/17 01:38:36 INFO ContextCleaner: Cleaned accumulator 178
21/02/17 01:38:36 INFO ContextCleaner: Cleaned accumulator 132
21/02/17 01:38:36 INFO ContextCleaner: Cleaned accumulator 106
21/02/17 01:38:36 INFO ContextCleaner: Cleaned accumulator 31
21/02/17 01:38:36 INFO ContextCleaner: Cleaned accumulator 143
21/02/17 01:38:36 INFO ContextCleaner: Cleaned accumulator 67
21/02/17 01:38:36 INFO ContextCleaner: Cleaned accumulator 124
21/02/17 01:38:36 INFO ContextCleaner: Cleaned accumulator 215
21/02/17 01:38:36 INFO ContextCleaner: Cleaned accumulator 114
21/02/17 01:38:36 INFO ContextCleaner: Cleaned accumulator 229
21/02/17 01:38:36 INFO ContextCleaner: Cleaned accumulator 137
21/02/17 01:38:36 INFO ContextCleaner: Cleaned accumulator 211
21/02/17 01:38:36 INFO ContextCleaner: Cleaned accumulator 112
21/02/17 01:38:36 INFO ContextCleaner: Cleaned accumulator 234
21/02/17 01:38:36 INFO ContextCleaner: Cleaned accumulator 182
21/02/17 01:38:36 INFO ContextCleaner: Cleaned accumulator 48
21/02/17 01:38:36 INFO ContextCleaner: Cleaned accumulator 196
21/02/17 01:38:36 INFO ContextCleaner: Cleaned accumulator 204
21/02/17 01:38:36 INFO ContextCleaner: Cleaned accumulator 149
21/02/17 01:38:36 INFO ContextCleaner: Cleaned accumulator 50
21/02/17 01:38:36 INFO ContextCleaner: Cleaned accumulator 154
21/02/17 01:38:36 INFO ContextCleaner: Cleaned accumulator 177
21/02/17 01:38:36 INFO ContextCleaner: Cleaned accumulator 145
21/02/17 01:38:36 INFO ContextCleaner: Cleaned accumulator 189
21/02/17 01:38:36 INFO ContextCleaner: Cleaned accumulator 115
21/02/17 01:38:36 INFO ContextCleaner: Cleaned accumulator 120
21/02/17 01:38:36 INFO ContextCleaner: Cleaned accumulator 134
21/02/17 01:38:36 INFO ContextCleaner: Cleaned accumulator 239
21/02/17 01:38:36 INFO ContextCleaner: Cleaned accumulator 141
21/02/17 01:38:36 INFO ContextCleaner: Cleaned accumulator 121
21/02/17 01:38:36 INFO ContextCleaner: Cleaned accumulator 264
21/02/17 01:38:36 INFO ContextCleaner: Cleaned accumulator 201
21/02/17 01:38:36 INFO ContextCleaner: Cleaned accumulator 249
21/02/17 01:38:36 INFO ContextCleaner: Cleaned accumulator 216
21/02/17 01:38:36 INFO ContextCleaner: Cleaned accumulator 200
21/02/17 01:38:36 INFO BlockManagerInfo: Removed broadcast_2_piece0 on localhost:34941 in memory (size: 4.5 KB, free: 912.3 MB)
21/02/17 01:38:36 INFO ContextCleaner: Cleaned accumulator 168
21/02/17 01:38:36 INFO ContextCleaner: Cleaned accumulator 226
21/02/17 01:38:36 INFO ContextCleaner: Cleaned accumulator 245
21/02/17 01:38:36 INFO ContextCleaner: Cleaned accumulator 102
21/02/17 01:38:36 INFO ContextCleaner: Cleaned accumulator 111
21/02/17 01:38:36 INFO BlockManagerInfo: Removed broadcast_3_piece0 on localhost:34941 in memory (size: 3.8 KB, free: 912.3 MB)
21/02/17 01:38:36 INFO ContextCleaner: Cleaned accumulator 163
21/02/17 01:38:36 INFO ContextCleaner: Cleaned accumulator 89
21/02/17 01:38:36 INFO ContextCleaner: Cleaned accumulator 219
21/02/17 01:38:36 INFO ContextCleaner: Cleaned accumulator 33
21/02/17 01:38:36 INFO ContextCleaner: Cleaned accumulator 233
21/02/17 01:38:36 INFO ContextCleaner: Cleaned accumulator 192
21/02/17 01:38:36 INFO ContextCleaner: Cleaned accumulator 179
21/02/17 01:38:36 INFO ContextCleaner: Cleaned accumulator 162
21/02/17 01:38:36 INFO ContextCleaner: Cleaned accumulator 128
21/02/17 01:38:36 INFO ContextCleaner: Cleaned accumulator 166
21/02/17 01:38:36 INFO ContextCleaner: Cleaned accumulator 253
21/02/17 01:38:36 INFO ContextCleaner: Cleaned accumulator 250
21/02/17 01:38:36 INFO ContextCleaner: Cleaned accumulator 86
21/02/17 01:38:36 INFO ContextCleaner: Cleaned accumulator 133
21/02/17 01:38:36 INFO ContextCleaner: Cleaned accumulator 148
21/02/17 01:38:36 INFO ContextCleaner: Cleaned accumulator 62
21/02/17 01:38:36 INFO ContextCleaner: Cleaned accumulator 30
21/02/17 01:38:36 INFO ContextCleaner: Cleaned accumulator 255
21/02/17 01:38:36 INFO ContextCleaner: Cleaned accumulator 135
21/02/17 01:38:36 INFO ContextCleaner: Cleaned accumulator 95
21/02/17 01:38:36 INFO ContextCleaner: Cleaned accumulator 160
21/02/17 01:38:36 INFO ContextCleaner: Cleaned accumulator 93
21/02/17 01:38:36 INFO ContextCleaner: Cleaned accumulator 195
21/02/17 01:38:36 INFO ContextCleaner: Cleaned accumulator 116
21/02/17 01:38:36 INFO ContextCleaner: Cleaned accumulator 197
21/02/17 01:38:36 INFO BlockManagerInfo: Removed broadcast_8_piece0 on localhost:34941 in memory (size: 14.3 KB, free: 912.3 MB)
21/02/17 01:38:36 INFO ContextCleaner: Cleaned accumulator 183
21/02/17 01:38:36 INFO ContextCleaner: Cleaned accumulator 225
21/02/17 01:38:36 INFO ContextCleaner: Cleaned accumulator 231
21/02/17 01:38:36 INFO ContextCleaner: Cleaned accumulator 130
21/02/17 01:38:36 INFO ContextCleaner: Cleaned accumulator 47
21/02/17 01:38:36 INFO ContextCleaner: Cleaned accumulator 54
21/02/17 01:38:36 INFO ContextCleaner: Cleaned accumulator 117
21/02/17 01:38:36 INFO ContextCleaner: Cleaned accumulator 41
21/02/17 01:38:36 INFO ContextCleaner: Cleaned accumulator 59
21/02/17 01:38:36 INFO ContextCleaner: Cleaned accumulator 66
21/02/17 01:38:36 INFO ContextCleaner: Cleaned accumulator 207
21/02/17 01:38:36 INFO ContextCleaner: Cleaned accumulator 232
21/02/17 01:38:36 INFO BlockManagerInfo: Removed broadcast_1_piece0 on localhost:34941 in memory (size: 3.2 KB, free: 912.3 MB)
21/02/17 01:38:36 INFO ContextCleaner: Cleaned accumulator 138
21/02/17 01:38:36 INFO ContextCleaner: Cleaned accumulator 209
21/02/17 01:38:36 INFO ContextCleaner: Cleaned accumulator 56
21/02/17 01:38:36 INFO ContextCleaner: Cleaned shuffle 0
21/02/17 01:38:36 INFO ContextCleaner: Cleaned accumulator 39
21/02/17 01:38:36 INFO ContextCleaner: Cleaned accumulator 157
21/02/17 01:38:36 INFO ContextCleaner: Cleaned accumulator 51
21/02/17 01:38:36 INFO ContextCleaner: Cleaned accumulator 113
21/02/17 01:38:36 INFO ContextCleaner: Cleaned accumulator 32
21/02/17 01:38:36 INFO ContextCleaner: Cleaned accumulator 35
21/02/17 01:38:36 INFO ContextCleaner: Cleaned accumulator 38
21/02/17 01:38:36 INFO ContextCleaner: Cleaned accumulator 181
21/02/17 01:38:36 INFO ContextCleaner: Cleaned accumulator 78
21/02/17 01:38:36 INFO ContextCleaner: Cleaned accumulator 84
21/02/17 01:38:36 INFO ContextCleaner: Cleaned accumulator 92
21/02/17 01:38:36 INFO ContextCleaner: Cleaned accumulator 96
21/02/17 01:38:36 INFO BlockManagerInfo: Removed broadcast_6_piece0 on localhost:34941 in memory (size: 3.8 KB, free: 912.3 MB)
21/02/17 01:38:36 INFO ContextCleaner: Cleaned accumulator 68
21/02/17 01:38:36 INFO ContextCleaner: Cleaned accumulator 256
21/02/17 01:38:36 INFO ContextCleaner: Cleaned accumulator 221
21/02/17 01:38:36 INFO ContextCleaner: Cleaned accumulator 223
21/02/17 01:38:36 INFO ContextCleaner: Cleaned accumulator 251
21/02/17 01:38:36 INFO ContextCleaner: Cleaned accumulator 174
21/02/17 01:38:36 INFO ContextCleaner: Cleaned accumulator 42
21/02/17 01:38:36 INFO ContextCleaner: Cleaned accumulator 180
21/02/17 01:38:36 INFO ContextCleaner: Cleaned accumulator 80
21/02/17 01:38:36 INFO ContextCleaner: Cleaned accumulator 146
21/02/17 01:38:36 INFO ContextCleaner: Cleaned accumulator 55
21/02/17 01:38:36 INFO ContextCleaner: Cleaned accumulator 58
21/02/17 01:38:36 INFO ContextCleaner: Cleaned accumulator 155
21/02/17 01:38:36 INFO ContextCleaner: Cleaned accumulator 34
21/02/17 01:38:36 INFO ContextCleaner: Cleaned accumulator 108
21/02/17 01:38:36 INFO ContextCleaner: Cleaned accumulator 158
21/02/17 01:38:36 INFO ContextCleaner: Cleaned accumulator 94
21/02/17 01:38:36 INFO ContextCleaner: Cleaned accumulator 244
21/02/17 01:38:36 INFO ContextCleaner: Cleaned accumulator 202
21/02/17 01:38:36 INFO ContextCleaner: Cleaned accumulator 83
21/02/17 01:38:36 INFO ContextCleaner: Cleaned accumulator 254
21/02/17 01:38:36 INFO ContextCleaner: Cleaned accumulator 167
21/02/17 01:38:36 INFO ContextCleaner: Cleaned accumulator 259
21/02/17 01:38:36 INFO ContextCleaner: Cleaned accumulator 45
21/02/17 01:38:36 INFO ContextCleaner: Cleaned accumulator 193
21/02/17 01:38:36 INFO ContextCleaner: Cleaned accumulator 69
21/02/17 01:38:36 INFO ContextCleaner: Cleaned accumulator 261
21/02/17 01:38:36 INFO ContextCleaner: Cleaned accumulator 126
21/02/17 01:38:36 INFO ContextCleaner: Cleaned accumulator 238
21/02/17 01:38:36 INFO ContextCleaner: Cleaned accumulator 88
21/02/17 01:38:36 INFO ContextCleaner: Cleaned accumulator 190
21/02/17 01:38:36 INFO ContextCleaner: Cleaned accumulator 109
21/02/17 01:38:36 INFO ContextCleaner: Cleaned accumulator 74
21/02/17 01:38:36 INFO ContextCleaner: Cleaned accumulator 103
21/02/17 01:38:36 INFO ContextCleaner: Cleaned accumulator 43
21/02/17 01:38:36 INFO ContextCleaner: Cleaned accumulator 258
21/02/17 01:38:36 INFO ContextCleaner: Cleaned accumulator 172
21/02/17 01:38:36 INFO ContextCleaner: Cleaned accumulator 27
21/02/17 01:38:36 INFO ContextCleaner: Cleaned accumulator 63
21/02/17 01:38:36 INFO ContextCleaner: Cleaned accumulator 105
21/02/17 01:38:36 INFO ContextCleaner: Cleaned accumulator 222
21/02/17 01:38:36 INFO ContextCleaner: Cleaned accumulator 237
21/02/17 01:38:36 INFO ContextCleaner: Cleaned accumulator 242
21/02/17 01:38:36 INFO ContextCleaner: Cleaned accumulator 87
21/02/17 01:38:36 INFO ContextCleaner: Cleaned accumulator 151
21/02/17 01:38:36 INFO ContextCleaner: Cleaned accumulator 175
21/02/17 01:38:36 INFO ContextCleaner: Cleaned accumulator 57
21/02/17 01:38:36 INFO ContextCleaner: Cleaned accumulator 153
21/02/17 01:38:36 INFO ContextCleaner: Cleaned accumulator 186
21/02/17 01:38:36 INFO ContextCleaner: Cleaned accumulator 136
21/02/17 01:38:36 INFO ContextCleaner: Cleaned accumulator 173
21/02/17 01:38:36 INFO ContextCleaner: Cleaned accumulator 101
21/02/17 01:38:36 INFO BlockManager: Removing RDD 35
21/02/17 01:38:36 INFO ContextCleaner: Cleaned RDD 35
21/02/17 01:38:36 INFO ContextCleaner: Cleaned accumulator 169
21/02/17 01:38:36 INFO ContextCleaner: Cleaned accumulator 187
21/02/17 01:38:36 INFO ContextCleaner: Cleaned accumulator 208
21/02/17 01:38:36 INFO ContextCleaner: Cleaned accumulator 73
21/02/17 01:38:36 INFO ContextCleaner: Cleaned accumulator 64
21/02/17 01:38:36 INFO ContextCleaner: Cleaned accumulator 246
21/02/17 01:38:36 INFO ContextCleaner: Cleaned accumulator 70
21/02/17 01:38:36 INFO ContextCleaner: Cleaned accumulator 170
21/02/17 01:38:36 INFO ContextCleaner: Cleaned accumulator 161
21/02/17 01:38:36 INFO ContextCleaner: Cleaned accumulator 61
21/02/17 01:38:36 INFO ContextCleaner: Cleaned accumulator 110
21/02/17 01:38:36 INFO ContextCleaner: Cleaned accumulator 188
21/02/17 01:38:36 INFO ContextCleaner: Cleaned accumulator 212
21/02/17 01:38:36 INFO ContextCleaner: Cleaned accumulator 176
21/02/17 01:38:36 INFO ContextCleaner: Cleaned accumulator 252
21/02/17 01:38:36 INFO ContextCleaner: Cleaned accumulator 198
21/02/17 01:38:36 INFO ContextCleaner: Cleaned accumulator 65
21/02/17 01:38:36 INFO ContextCleaner: Cleaned accumulator 144
21/02/17 01:38:36 INFO ContextCleaner: Cleaned accumulator 98
21/02/17 01:38:36 INFO BlockManagerInfo: Removed broadcast_7_piece0 on localhost:34941 in memory (size: 14.2 KB, free: 912.3 MB)
21/02/17 01:38:36 INFO ContextCleaner: Cleaned accumulator 79
21/02/17 01:38:36 INFO ContextCleaner: Cleaned accumulator 165
21/02/17 01:38:36 INFO ContextCleaner: Cleaned accumulator 152
21/02/17 01:38:36 INFO ContextCleaner: Cleaned accumulator 139
21/02/17 01:38:36 INFO ContextCleaner: Cleaned accumulator 262
21/02/17 01:38:36 INFO ContextCleaner: Cleaned accumulator 164
21/02/17 01:38:36 INFO ContextCleaner: Cleaned accumulator 217
21/02/17 01:38:36 INFO ContextCleaner: Cleaned accumulator 85
21/02/17 01:38:36 INFO ContextCleaner: Cleaned accumulator 191
21/02/17 01:38:36 INFO ContextCleaner: Cleaned accumulator 205
21/02/17 01:38:36 INFO ContextCleaner: Cleaned accumulator 76
21/02/17 01:38:36 INFO ContextCleaner: Cleaned accumulator 100
21/02/17 01:38:36 INFO ContextCleaner: Cleaned accumulator 213
21/02/17 01:38:36 INFO ContextCleaner: Cleaned accumulator 228
21/02/17 01:38:36 INFO ContextCleaner: Cleaned accumulator 156
21/02/17 01:38:36 INFO ContextCleaner: Cleaned accumulator 129
21/02/17 01:38:36 INFO ContextCleaner: Cleaned accumulator 214
21/02/17 01:38:36 INFO ContextCleaner: Cleaned accumulator 159
21/02/17 01:38:36 INFO ContextCleaner: Cleaned accumulator 40
21/02/17 01:38:36 INFO ContextCleaner: Cleaned accumulator 60
21/02/17 01:38:36 INFO ContextCleaner: Cleaned accumulator 210
21/02/17 01:38:36 INFO ContextCleaner: Cleaned accumulator 240
21/02/17 01:38:36 INFO ContextCleaner: Cleaned accumulator 82
21/02/17 01:38:36 INFO ContextCleaner: Cleaned accumulator 99
21/02/17 01:38:36 INFO CodeGenerator: Code generated in 32.134143 ms
21/02/17 01:38:36 INFO CodeGenerator: Code generated in 8.826504 ms
21/02/17 01:38:36 INFO CodeGenerator: Code generated in 8.516006 ms
21/02/17 01:38:36 INFO SparkContext: Starting job: collect at utils.scala:135
21/02/17 01:38:36 INFO DAGScheduler: Got job 7 (collect at utils.scala:135) with 1 output partitions
21/02/17 01:38:36 INFO DAGScheduler: Final stage: ResultStage 9 (collect at utils.scala:135)
21/02/17 01:38:36 INFO DAGScheduler: Parents of final stage: List()
21/02/17 01:38:36 INFO DAGScheduler: Missing parents: List()
21/02/17 01:38:36 INFO DAGScheduler: Submitting ResultStage 9 (MapPartitionsRDD[46] at collect at utils.scala:135), which has no missing parents
21/02/17 01:38:36 INFO MemoryStore: Block broadcast_10 stored as values in memory (estimated size 6.5 KB, free 912.3 MB)
21/02/17 01:38:36 INFO MemoryStore: Block broadcast_10_piece0 stored as bytes in memory (estimated size 3.2 KB, free 912.3 MB)
21/02/17 01:38:36 INFO BlockManagerInfo: Added broadcast_10_piece0 in memory on localhost:34941 (size: 3.2 KB, free: 912.3 MB)
21/02/17 01:38:36 INFO SparkContext: Created broadcast 10 from broadcast at DAGScheduler.scala:1039
21/02/17 01:38:36 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 9 (MapPartitionsRDD[46] at collect at utils.scala:135) (first 15 tasks are for partitions Vector(0))
21/02/17 01:38:36 INFO TaskSchedulerImpl: Adding task set 9.0 with 1 tasks
21/02/17 01:38:36 INFO TaskSetManager: Starting task 0.0 in stage 9.0 (TID 9, localhost, executor driver, partition 0, PROCESS_LOCAL, 8067 bytes)
21/02/17 01:38:36 INFO Executor: Running task 0.0 in stage 9.0 (TID 9)
21/02/17 01:38:36 INFO Executor: Finished task 0.0 in stage 9.0 (TID 9). 1286 bytes result sent to driver
21/02/17 01:38:36 INFO TaskSetManager: Finished task 0.0 in stage 9.0 (TID 9) in 6 ms on localhost (executor driver) (1/1)
21/02/17 01:38:36 INFO TaskSchedulerImpl: Removed TaskSet 9.0, whose tasks have all completed, from pool 
21/02/17 01:38:36 INFO DAGScheduler: ResultStage 9 (collect at utils.scala:135) finished in 0.011 s
21/02/17 01:38:36 INFO DAGScheduler: Job 7 finished: collect at utils.scala:135, took 0.013788 s
21/02/17 01:38:36 INFO SparkContext: Starting job: count at utils.scala:135
21/02/17 01:38:36 INFO DAGScheduler: Registering RDD 49 (count at utils.scala:135)
21/02/17 01:38:36 INFO DAGScheduler: Got job 8 (count at utils.scala:135) with 1 output partitions
21/02/17 01:38:36 INFO DAGScheduler: Final stage: ResultStage 11 (count at utils.scala:135)
21/02/17 01:38:36 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 10)
21/02/17 01:38:36 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 10)
21/02/17 01:38:36 INFO DAGScheduler: Submitting ShuffleMapStage 10 (MapPartitionsRDD[49] at count at utils.scala:135), which has no missing parents
21/02/17 01:38:36 INFO MemoryStore: Block broadcast_11 stored as values in memory (estimated size 8.9 KB, free 912.3 MB)
21/02/17 01:38:36 INFO MemoryStore: Block broadcast_11_piece0 stored as bytes in memory (estimated size 4.5 KB, free 912.3 MB)
21/02/17 01:38:36 INFO BlockManagerInfo: Added broadcast_11_piece0 in memory on localhost:34941 (size: 4.5 KB, free: 912.3 MB)
21/02/17 01:38:36 INFO SparkContext: Created broadcast 11 from broadcast at DAGScheduler.scala:1039
21/02/17 01:38:36 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 10 (MapPartitionsRDD[49] at count at utils.scala:135) (first 15 tasks are for partitions Vector(0))
21/02/17 01:38:36 INFO TaskSchedulerImpl: Adding task set 10.0 with 1 tasks
21/02/17 01:38:36 INFO TaskSetManager: Starting task 0.0 in stage 10.0 (TID 10, localhost, executor driver, partition 0, PROCESS_LOCAL, 8056 bytes)
21/02/17 01:38:36 INFO Executor: Running task 0.0 in stage 10.0 (TID 10)
21/02/17 01:38:36 INFO Executor: Finished task 0.0 in stage 10.0 (TID 10). 1499 bytes result sent to driver
21/02/17 01:38:36 INFO TaskSetManager: Finished task 0.0 in stage 10.0 (TID 10) in 4 ms on localhost (executor driver) (1/1)
21/02/17 01:38:36 INFO TaskSchedulerImpl: Removed TaskSet 10.0, whose tasks have all completed, from pool 
21/02/17 01:38:36 INFO DAGScheduler: ShuffleMapStage 10 (count at utils.scala:135) finished in 0.011 s
21/02/17 01:38:36 INFO DAGScheduler: looking for newly runnable stages
21/02/17 01:38:36 INFO DAGScheduler: running: Set()
21/02/17 01:38:36 INFO DAGScheduler: waiting: Set(ResultStage 11)
21/02/17 01:38:36 INFO DAGScheduler: failed: Set()
21/02/17 01:38:36 INFO DAGScheduler: Submitting ResultStage 11 (MapPartitionsRDD[52] at count at utils.scala:135), which has no missing parents
21/02/17 01:38:36 INFO MemoryStore: Block broadcast_12 stored as values in memory (estimated size 7.3 KB, free 912.3 MB)
21/02/17 01:38:36 INFO MemoryStore: Block broadcast_12_piece0 stored as bytes in memory (estimated size 3.8 KB, free 912.3 MB)
21/02/17 01:38:36 INFO BlockManagerInfo: Added broadcast_12_piece0 in memory on localhost:34941 (size: 3.8 KB, free: 912.3 MB)
21/02/17 01:38:36 INFO SparkContext: Created broadcast 12 from broadcast at DAGScheduler.scala:1039
21/02/17 01:38:36 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 11 (MapPartitionsRDD[52] at count at utils.scala:135) (first 15 tasks are for partitions Vector(0))
21/02/17 01:38:36 INFO TaskSchedulerImpl: Adding task set 11.0 with 1 tasks
21/02/17 01:38:36 INFO TaskSetManager: Starting task 0.0 in stage 11.0 (TID 11, localhost, executor driver, partition 0, NODE_LOCAL, 7754 bytes)
21/02/17 01:38:36 INFO Executor: Running task 0.0 in stage 11.0 (TID 11)
21/02/17 01:38:36 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
21/02/17 01:38:36 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
21/02/17 01:38:36 INFO Executor: Finished task 0.0 in stage 11.0 (TID 11). 1782 bytes result sent to driver
21/02/17 01:38:36 INFO TaskSetManager: Finished task 0.0 in stage 11.0 (TID 11) in 5 ms on localhost (executor driver) (1/1)
21/02/17 01:38:36 INFO TaskSchedulerImpl: Removed TaskSet 11.0, whose tasks have all completed, from pool 
21/02/17 01:38:36 INFO DAGScheduler: ResultStage 11 (count at utils.scala:135) finished in 0.008 s
21/02/17 01:38:36 INFO DAGScheduler: Job 8 finished: count at utils.scala:135, took 0.022881 s
21/02/17 01:38:37 INFO CodeGenerator: Code generated in 6.31443 ms
21/02/17 01:38:37 INFO CodeGenerator: Code generated in 9.048635 ms
21/02/17 01:38:37 INFO SparkContext: Starting job: collect at utils.scala:135
21/02/17 01:38:37 INFO DAGScheduler: Got job 9 (collect at utils.scala:135) with 1 output partitions
21/02/17 01:38:37 INFO DAGScheduler: Final stage: ResultStage 12 (collect at utils.scala:135)
21/02/17 01:38:37 INFO DAGScheduler: Parents of final stage: List()
21/02/17 01:38:37 INFO DAGScheduler: Missing parents: List()
21/02/17 01:38:37 INFO DAGScheduler: Submitting ResultStage 12 (MapPartitionsRDD[55] at collect at utils.scala:135), which has no missing parents
21/02/17 01:38:37 INFO MemoryStore: Block broadcast_13 stored as values in memory (estimated size 61.1 KB, free 912.2 MB)
21/02/17 01:38:37 INFO MemoryStore: Block broadcast_13_piece0 stored as bytes in memory (estimated size 25.3 KB, free 912.2 MB)
21/02/17 01:38:37 INFO BlockManagerInfo: Added broadcast_13_piece0 in memory on localhost:34941 (size: 25.3 KB, free: 912.3 MB)
21/02/17 01:38:37 INFO SparkContext: Created broadcast 13 from broadcast at DAGScheduler.scala:1039
21/02/17 01:38:37 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 12 (MapPartitionsRDD[55] at collect at utils.scala:135) (first 15 tasks are for partitions Vector(0))
21/02/17 01:38:37 INFO TaskSchedulerImpl: Adding task set 12.0 with 1 tasks
21/02/17 01:38:37 INFO TaskSetManager: Starting task 0.0 in stage 12.0 (TID 12, localhost, executor driver, partition 0, PROCESS_LOCAL, 18998 bytes)
21/02/17 01:38:37 INFO Executor: Running task 0.0 in stage 12.0 (TID 12)
21/02/17 01:38:37 INFO BlockManager: Found block rdd_17_0 locally
21/02/17 01:38:37 INFO CodeGenerator: Code generated in 10.960128 ms
21/02/17 01:38:37 INFO CodeGenerator: Code generated in 18.669757 ms
21/02/17 01:38:37 INFO CodeGenerator: Code generated in 34.49614 ms
21/02/17 01:38:37 INFO Executor: Finished task 0.0 in stage 12.0 (TID 12). 1815 bytes result sent to driver
21/02/17 01:38:37 INFO TaskSetManager: Finished task 0.0 in stage 12.0 (TID 12) in 122 ms on localhost (executor driver) (1/1)
21/02/17 01:38:37 INFO TaskSchedulerImpl: Removed TaskSet 12.0, whose tasks have all completed, from pool 
21/02/17 01:38:37 INFO DAGScheduler: ResultStage 12 (collect at utils.scala:135) finished in 0.131 s
21/02/17 01:38:37 INFO DAGScheduler: Job 9 finished: collect at utils.scala:135, took 0.133701 s
21/02/17 01:38:37 INFO CodeGenerator: Code generated in 9.181217 ms
21/02/17 01:38:37 INFO SparkContext: Starting job: count at utils.scala:135
21/02/17 01:38:37 INFO DAGScheduler: Registering RDD 58 (count at utils.scala:135)
21/02/17 01:38:37 INFO DAGScheduler: Got job 10 (count at utils.scala:135) with 1 output partitions
21/02/17 01:38:37 INFO DAGScheduler: Final stage: ResultStage 14 (count at utils.scala:135)
21/02/17 01:38:37 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 13)
21/02/17 01:38:37 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 13)
21/02/17 01:38:37 INFO DAGScheduler: Submitting ShuffleMapStage 13 (MapPartitionsRDD[58] at count at utils.scala:135), which has no missing parents
21/02/17 01:38:37 INFO MemoryStore: Block broadcast_14 stored as values in memory (estimated size 62.0 KB, free 912.1 MB)
21/02/17 01:38:37 INFO MemoryStore: Block broadcast_14_piece0 stored as bytes in memory (estimated size 25.8 KB, free 912.1 MB)
21/02/17 01:38:37 INFO BlockManagerInfo: Added broadcast_14_piece0 in memory on localhost:34941 (size: 25.8 KB, free: 912.2 MB)
21/02/17 01:38:37 INFO SparkContext: Created broadcast 14 from broadcast at DAGScheduler.scala:1039
21/02/17 01:38:37 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 13 (MapPartitionsRDD[58] at count at utils.scala:135) (first 15 tasks are for partitions Vector(0))
21/02/17 01:38:37 INFO TaskSchedulerImpl: Adding task set 13.0 with 1 tasks
21/02/17 01:38:37 INFO TaskSetManager: Starting task 0.0 in stage 13.0 (TID 13, localhost, executor driver, partition 0, PROCESS_LOCAL, 18987 bytes)
21/02/17 01:38:37 INFO Executor: Running task 0.0 in stage 13.0 (TID 13)
21/02/17 01:38:37 INFO BlockManager: Found block rdd_17_0 locally
21/02/17 01:38:37 INFO Executor: Finished task 0.0 in stage 13.0 (TID 13). 1933 bytes result sent to driver
21/02/17 01:38:37 INFO TaskSetManager: Finished task 0.0 in stage 13.0 (TID 13) in 31 ms on localhost (executor driver) (1/1)
21/02/17 01:38:37 INFO TaskSchedulerImpl: Removed TaskSet 13.0, whose tasks have all completed, from pool 
21/02/17 01:38:37 INFO DAGScheduler: ShuffleMapStage 13 (count at utils.scala:135) finished in 0.036 s
21/02/17 01:38:37 INFO DAGScheduler: looking for newly runnable stages
21/02/17 01:38:37 INFO DAGScheduler: running: Set()
21/02/17 01:38:37 INFO DAGScheduler: waiting: Set(ResultStage 14)
21/02/17 01:38:37 INFO DAGScheduler: failed: Set()
21/02/17 01:38:37 INFO DAGScheduler: Submitting ResultStage 14 (MapPartitionsRDD[61] at count at utils.scala:135), which has no missing parents
21/02/17 01:38:37 INFO MemoryStore: Block broadcast_15 stored as values in memory (estimated size 7.3 KB, free 912.1 MB)
21/02/17 01:38:37 INFO MemoryStore: Block broadcast_15_piece0 stored as bytes in memory (estimated size 3.8 KB, free 912.1 MB)
21/02/17 01:38:37 INFO BlockManagerInfo: Added broadcast_15_piece0 in memory on localhost:34941 (size: 3.8 KB, free: 912.2 MB)
21/02/17 01:38:37 INFO SparkContext: Created broadcast 15 from broadcast at DAGScheduler.scala:1039
21/02/17 01:38:37 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 14 (MapPartitionsRDD[61] at count at utils.scala:135) (first 15 tasks are for partitions Vector(0))
21/02/17 01:38:37 INFO TaskSchedulerImpl: Adding task set 14.0 with 1 tasks
21/02/17 01:38:37 INFO TaskSetManager: Starting task 0.0 in stage 14.0 (TID 14, localhost, executor driver, partition 0, NODE_LOCAL, 7754 bytes)
21/02/17 01:38:37 INFO Executor: Running task 0.0 in stage 14.0 (TID 14)
21/02/17 01:38:37 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
21/02/17 01:38:37 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
21/02/17 01:38:37 INFO Executor: Finished task 0.0 in stage 14.0 (TID 14). 1782 bytes result sent to driver
21/02/17 01:38:37 INFO TaskSetManager: Finished task 0.0 in stage 14.0 (TID 14) in 4 ms on localhost (executor driver) (1/1)
21/02/17 01:38:37 INFO TaskSchedulerImpl: Removed TaskSet 14.0, whose tasks have all completed, from pool 
21/02/17 01:38:37 INFO DAGScheduler: ResultStage 14 (count at utils.scala:135) finished in 0.008 s
21/02/17 01:38:37 INFO DAGScheduler: Job 10 finished: count at utils.scala:135, took 0.048573 s
21/02/17 01:38:37 INFO deprecation: mapred.output.dir is deprecated. Instead, use mapreduce.output.fileoutputformat.outputdir
21/02/17 01:38:37 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
21/02/17 01:38:37 INFO SparkContext: Starting job: runJob at SparkHadoopWriter.scala:78
21/02/17 01:38:37 INFO DAGScheduler: Got job 11 (runJob at SparkHadoopWriter.scala:78) with 1 output partitions
21/02/17 01:38:37 INFO DAGScheduler: Final stage: ResultStage 15 (runJob at SparkHadoopWriter.scala:78)
21/02/17 01:38:37 INFO DAGScheduler: Parents of final stage: List()
21/02/17 01:38:37 INFO DAGScheduler: Missing parents: List()
21/02/17 01:38:37 INFO DAGScheduler: Submitting ResultStage 15 (MapPartitionsRDD[63] at saveAsTextFile at ReadWrite.scala:283), which has no missing parents
21/02/17 01:38:37 INFO MemoryStore: Block broadcast_16 stored as values in memory (estimated size 71.0 KB, free 912.0 MB)
21/02/17 01:38:37 INFO MemoryStore: Block broadcast_16_piece0 stored as bytes in memory (estimated size 25.3 KB, free 912.0 MB)
21/02/17 01:38:37 INFO BlockManagerInfo: Added broadcast_16_piece0 in memory on localhost:34941 (size: 25.3 KB, free: 912.2 MB)
21/02/17 01:38:37 INFO SparkContext: Created broadcast 16 from broadcast at DAGScheduler.scala:1039
21/02/17 01:38:37 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 15 (MapPartitionsRDD[63] at saveAsTextFile at ReadWrite.scala:283) (first 15 tasks are for partitions Vector(0))
21/02/17 01:38:37 INFO TaskSchedulerImpl: Adding task set 15.0 with 1 tasks
21/02/17 01:38:37 INFO TaskSetManager: Starting task 0.0 in stage 15.0 (TID 15, localhost, executor driver, partition 0, PROCESS_LOCAL, 8142 bytes)
21/02/17 01:38:37 INFO Executor: Running task 0.0 in stage 15.0 (TID 15)
21/02/17 01:38:37 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
21/02/17 01:38:37 INFO FileOutputCommitter: Saved output of task 'attempt_20210217013837_0063_m_000000_0' to file:/tmp/RtmpS1B6G2/file229295a853f48/metadata/_temporary/0/task_20210217013837_0063_m_000000
21/02/17 01:38:37 INFO SparkHadoopMapRedUtil: attempt_20210217013837_0063_m_000000_0: Committed
21/02/17 01:38:37 INFO Executor: Finished task 0.0 in stage 15.0 (TID 15). 1072 bytes result sent to driver
21/02/17 01:38:37 INFO TaskSetManager: Finished task 0.0 in stage 15.0 (TID 15) in 36 ms on localhost (executor driver) (1/1)
21/02/17 01:38:37 INFO TaskSchedulerImpl: Removed TaskSet 15.0, whose tasks have all completed, from pool 
21/02/17 01:38:37 INFO DAGScheduler: ResultStage 15 (runJob at SparkHadoopWriter.scala:78) finished in 0.049 s
21/02/17 01:38:37 INFO DAGScheduler: Job 11 finished: runJob at SparkHadoopWriter.scala:78, took 0.050312 s
21/02/17 01:38:37 INFO SparkHadoopWriter: Job job_20210217013837_0063 committed.
21/02/17 01:38:37 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
21/02/17 01:38:37 INFO SparkContext: Starting job: runJob at SparkHadoopWriter.scala:78
21/02/17 01:38:37 INFO DAGScheduler: Got job 12 (runJob at SparkHadoopWriter.scala:78) with 1 output partitions
21/02/17 01:38:37 INFO DAGScheduler: Final stage: ResultStage 16 (runJob at SparkHadoopWriter.scala:78)
21/02/17 01:38:37 INFO DAGScheduler: Parents of final stage: List()
21/02/17 01:38:37 INFO DAGScheduler: Missing parents: List()
21/02/17 01:38:37 INFO DAGScheduler: Submitting ResultStage 16 (MapPartitionsRDD[65] at saveAsTextFile at ReadWrite.scala:283), which has no missing parents
21/02/17 01:38:37 INFO MemoryStore: Block broadcast_17 stored as values in memory (estimated size 71.1 KB, free 911.9 MB)
21/02/17 01:38:37 INFO MemoryStore: Block broadcast_17_piece0 stored as bytes in memory (estimated size 25.4 KB, free 911.9 MB)
21/02/17 01:38:37 INFO BlockManagerInfo: Added broadcast_17_piece0 in memory on localhost:34941 (size: 25.4 KB, free: 912.2 MB)
21/02/17 01:38:37 INFO SparkContext: Created broadcast 17 from broadcast at DAGScheduler.scala:1039
21/02/17 01:38:37 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 16 (MapPartitionsRDD[65] at saveAsTextFile at ReadWrite.scala:283) (first 15 tasks are for partitions Vector(0))
21/02/17 01:38:37 INFO TaskSchedulerImpl: Adding task set 16.0 with 1 tasks
21/02/17 01:38:37 INFO TaskSetManager: Starting task 0.0 in stage 16.0 (TID 16, localhost, executor driver, partition 0, PROCESS_LOCAL, 8216 bytes)
21/02/17 01:38:37 INFO Executor: Running task 0.0 in stage 16.0 (TID 16)
21/02/17 01:38:37 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
21/02/17 01:38:37 INFO FileOutputCommitter: Saved output of task 'attempt_20210217013837_0065_m_000000_0' to file:/tmp/RtmpS1B6G2/file229295a853f48/stages/0_r_formula__1f0c17e2_5e1f_4747_b5f7_cf8564b20278/metadata/_temporary/0/task_20210217013837_0065_m_000000
21/02/17 01:38:37 INFO SparkHadoopMapRedUtil: attempt_20210217013837_0065_m_000000_0: Committed
21/02/17 01:38:37 INFO Executor: Finished task 0.0 in stage 16.0 (TID 16). 1029 bytes result sent to driver
21/02/17 01:38:37 INFO TaskSetManager: Finished task 0.0 in stage 16.0 (TID 16) in 15 ms on localhost (executor driver) (1/1)
21/02/17 01:38:37 INFO TaskSchedulerImpl: Removed TaskSet 16.0, whose tasks have all completed, from pool 
21/02/17 01:38:37 INFO DAGScheduler: ResultStage 16 (runJob at SparkHadoopWriter.scala:78) finished in 0.025 s
21/02/17 01:38:37 INFO DAGScheduler: Job 12 finished: runJob at SparkHadoopWriter.scala:78, took 0.026182 s
21/02/17 01:38:37 INFO SparkHadoopWriter: Job job_20210217013837_0065 committed.
21/02/17 01:38:37 INFO ParquetFileFormat: Using default output committer for Parquet: org.apache.parquet.hadoop.ParquetOutputCommitter
21/02/17 01:38:37 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
21/02/17 01:38:37 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
21/02/17 01:38:37 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
21/02/17 01:38:37 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
21/02/17 01:38:37 INFO CodeGenerator: Code generated in 8.128856 ms
21/02/17 01:38:37 INFO SparkContext: Starting job: parquet at RFormula.scala:421
21/02/17 01:38:37 INFO DAGScheduler: Registering RDD 68 (parquet at RFormula.scala:421)
21/02/17 01:38:37 INFO DAGScheduler: Got job 13 (parquet at RFormula.scala:421) with 1 output partitions
21/02/17 01:38:37 INFO DAGScheduler: Final stage: ResultStage 18 (parquet at RFormula.scala:421)
21/02/17 01:38:37 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 17)
21/02/17 01:38:37 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 17)
21/02/17 01:38:37 INFO DAGScheduler: Submitting ShuffleMapStage 17 (MapPartitionsRDD[68] at parquet at RFormula.scala:421), which has no missing parents
21/02/17 01:38:37 INFO MemoryStore: Block broadcast_18 stored as values in memory (estimated size 4.8 KB, free 911.9 MB)
21/02/17 01:38:37 INFO MemoryStore: Block broadcast_18_piece0 stored as bytes in memory (estimated size 2.9 KB, free 911.9 MB)
21/02/17 01:38:37 INFO BlockManagerInfo: Added broadcast_18_piece0 in memory on localhost:34941 (size: 2.9 KB, free: 912.2 MB)
21/02/17 01:38:37 INFO SparkContext: Created broadcast 18 from broadcast at DAGScheduler.scala:1039
21/02/17 01:38:37 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 17 (MapPartitionsRDD[68] at parquet at RFormula.scala:421) (first 15 tasks are for partitions Vector(0))
21/02/17 01:38:37 INFO TaskSchedulerImpl: Adding task set 17.0 with 1 tasks
21/02/17 01:38:37 INFO TaskSetManager: Starting task 0.0 in stage 17.0 (TID 17, localhost, executor driver, partition 0, PROCESS_LOCAL, 8164 bytes)
21/02/17 01:38:37 INFO Executor: Running task 0.0 in stage 17.0 (TID 17)
21/02/17 01:38:37 INFO Executor: Finished task 0.0 in stage 17.0 (TID 17). 1247 bytes result sent to driver
21/02/17 01:38:37 INFO TaskSetManager: Finished task 0.0 in stage 17.0 (TID 17) in 4 ms on localhost (executor driver) (1/1)
21/02/17 01:38:37 INFO TaskSchedulerImpl: Removed TaskSet 17.0, whose tasks have all completed, from pool 
21/02/17 01:38:37 INFO DAGScheduler: ShuffleMapStage 17 (parquet at RFormula.scala:421) finished in 0.008 s
21/02/17 01:38:37 INFO DAGScheduler: looking for newly runnable stages
21/02/17 01:38:37 INFO DAGScheduler: running: Set()
21/02/17 01:38:37 INFO DAGScheduler: waiting: Set(ResultStage 18)
21/02/17 01:38:37 INFO DAGScheduler: failed: Set()
21/02/17 01:38:37 INFO DAGScheduler: Submitting ResultStage 18 (ShuffledRowRDD[69] at parquet at RFormula.scala:421), which has no missing parents
21/02/17 01:38:37 INFO MemoryStore: Block broadcast_19 stored as values in memory (estimated size 150.9 KB, free 911.7 MB)
21/02/17 01:38:37 INFO MemoryStore: Block broadcast_19_piece0 stored as bytes in memory (estimated size 53.4 KB, free 911.7 MB)
21/02/17 01:38:37 INFO BlockManagerInfo: Added broadcast_19_piece0 in memory on localhost:34941 (size: 53.4 KB, free: 912.1 MB)
21/02/17 01:38:37 INFO SparkContext: Created broadcast 19 from broadcast at DAGScheduler.scala:1039
21/02/17 01:38:37 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 18 (ShuffledRowRDD[69] at parquet at RFormula.scala:421) (first 15 tasks are for partitions Vector(0))
21/02/17 01:38:37 INFO TaskSchedulerImpl: Adding task set 18.0 with 1 tasks
21/02/17 01:38:37 INFO TaskSetManager: Starting task 0.0 in stage 18.0 (TID 18, localhost, executor driver, partition 0, NODE_LOCAL, 7754 bytes)
21/02/17 01:38:37 INFO Executor: Running task 0.0 in stage 18.0 (TID 18)
21/02/17 01:38:37 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
21/02/17 01:38:37 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
21/02/17 01:38:37 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
21/02/17 01:38:37 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
21/02/17 01:38:37 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
21/02/17 01:38:37 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
21/02/17 01:38:37 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:
{
  "type" : "struct",
  "fields" : [ {
    "name" : "label",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "terms",
    "type" : {
      "type" : "array",
      "elementType" : {
        "type" : "array",
        "elementType" : "string",
        "containsNull" : true
      },
      "containsNull" : true
    },
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "hasIntercept",
    "type" : "boolean",
    "nullable" : false,
    "metadata" : { }
  } ]
}
and corresponding Parquet message type:
message spark_schema {
  optional binary label (UTF8);
  optional group terms (LIST) {
    repeated group list {
      optional group element (LIST) {
        repeated group list {
          optional binary element (UTF8);
        }
      }
    }
  }
  required boolean hasIntercept;
}

       
21/02/17 01:38:37 INFO CodecPool: Got brand-new compressor [.snappy]
21/02/17 01:38:37 INFO FileOutputCommitter: Saved output of task 'attempt_20210217013837_0018_m_000000_0' to file:/tmp/RtmpS1B6G2/file229295a853f48/stages/0_r_formula__1f0c17e2_5e1f_4747_b5f7_cf8564b20278/data/_temporary/0/task_20210217013837_0018_m_000000
21/02/17 01:38:37 INFO SparkHadoopMapRedUtil: attempt_20210217013837_0018_m_000000_0: Committed
21/02/17 01:38:37 INFO Executor: Finished task 0.0 in stage 18.0 (TID 18). 2351 bytes result sent to driver
21/02/17 01:38:37 INFO TaskSetManager: Finished task 0.0 in stage 18.0 (TID 18) in 185 ms on localhost (executor driver) (1/1)
21/02/17 01:38:37 INFO TaskSchedulerImpl: Removed TaskSet 18.0, whose tasks have all completed, from pool 
21/02/17 01:38:37 INFO DAGScheduler: ResultStage 18 (parquet at RFormula.scala:421) finished in 0.203 s
21/02/17 01:38:37 INFO DAGScheduler: Job 13 finished: parquet at RFormula.scala:421, took 0.214217 s
21/02/17 01:38:37 INFO FileFormatWriter: Job null committed.
21/02/17 01:38:37 INFO FileFormatWriter: Finished processing stats for job null.
21/02/17 01:38:37 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
21/02/17 01:38:37 INFO SparkContext: Starting job: runJob at SparkHadoopWriter.scala:78
21/02/17 01:38:37 INFO DAGScheduler: Got job 14 (runJob at SparkHadoopWriter.scala:78) with 1 output partitions
21/02/17 01:38:37 INFO DAGScheduler: Final stage: ResultStage 19 (runJob at SparkHadoopWriter.scala:78)
21/02/17 01:38:37 INFO DAGScheduler: Parents of final stage: List()
21/02/17 01:38:37 INFO DAGScheduler: Missing parents: List()
21/02/17 01:38:37 INFO DAGScheduler: Submitting ResultStage 19 (MapPartitionsRDD[72] at saveAsTextFile at ReadWrite.scala:283), which has no missing parents
21/02/17 01:38:37 INFO MemoryStore: Block broadcast_20 stored as values in memory (estimated size 71.1 KB, free 911.6 MB)
21/02/17 01:38:37 INFO MemoryStore: Block broadcast_20_piece0 stored as bytes in memory (estimated size 25.5 KB, free 911.6 MB)
21/02/17 01:38:37 INFO BlockManagerInfo: Added broadcast_20_piece0 in memory on localhost:34941 (size: 25.5 KB, free: 912.1 MB)
21/02/17 01:38:37 INFO SparkContext: Created broadcast 20 from broadcast at DAGScheduler.scala:1039
21/02/17 01:38:37 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 19 (MapPartitionsRDD[72] at saveAsTextFile at ReadWrite.scala:283) (first 15 tasks are for partitions Vector(0))
21/02/17 01:38:37 INFO TaskSchedulerImpl: Adding task set 19.0 with 1 tasks
21/02/17 01:38:37 INFO TaskSetManager: Starting task 0.0 in stage 19.0 (TID 19, localhost, executor driver, partition 0, PROCESS_LOCAL, 8147 bytes)
21/02/17 01:38:37 INFO Executor: Running task 0.0 in stage 19.0 (TID 19)
21/02/17 01:38:38 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
21/02/17 01:38:38 INFO FileOutputCommitter: Saved output of task 'attempt_20210217013837_0072_m_000000_0' to file:/tmp/RtmpS1B6G2/file229295a853f48/stages/0_r_formula__1f0c17e2_5e1f_4747_b5f7_cf8564b20278/pipelineModel/metadata/_temporary/0/task_20210217013837_0072_m_000000
21/02/17 01:38:38 INFO SparkHadoopMapRedUtil: attempt_20210217013837_0072_m_000000_0: Committed
21/02/17 01:38:38 INFO Executor: Finished task 0.0 in stage 19.0 (TID 19). 1029 bytes result sent to driver
21/02/17 01:38:38 INFO TaskSetManager: Finished task 0.0 in stage 19.0 (TID 19) in 14 ms on localhost (executor driver) (1/1)
21/02/17 01:38:38 INFO TaskSchedulerImpl: Removed TaskSet 19.0, whose tasks have all completed, from pool 
21/02/17 01:38:38 INFO DAGScheduler: ResultStage 19 (runJob at SparkHadoopWriter.scala:78) finished in 0.024 s
21/02/17 01:38:38 INFO DAGScheduler: Job 14 finished: runJob at SparkHadoopWriter.scala:78, took 0.025536 s
21/02/17 01:38:38 INFO SparkHadoopWriter: Job job_20210217013837_0072 committed.
21/02/17 01:38:38 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
21/02/17 01:38:38 INFO SparkContext: Starting job: runJob at SparkHadoopWriter.scala:78
21/02/17 01:38:38 INFO DAGScheduler: Got job 15 (runJob at SparkHadoopWriter.scala:78) with 1 output partitions
21/02/17 01:38:38 INFO DAGScheduler: Final stage: ResultStage 20 (runJob at SparkHadoopWriter.scala:78)
21/02/17 01:38:38 INFO DAGScheduler: Parents of final stage: List()
21/02/17 01:38:38 INFO DAGScheduler: Missing parents: List()
21/02/17 01:38:38 INFO DAGScheduler: Submitting ResultStage 20 (MapPartitionsRDD[74] at saveAsTextFile at ReadWrite.scala:283), which has no missing parents
21/02/17 01:38:38 INFO MemoryStore: Block broadcast_21 stored as values in memory (estimated size 71.3 KB, free 911.5 MB)
21/02/17 01:38:38 INFO MemoryStore: Block broadcast_21_piece0 stored as bytes in memory (estimated size 25.5 KB, free 911.5 MB)
21/02/17 01:38:38 INFO BlockManagerInfo: Added broadcast_21_piece0 in memory on localhost:34941 (size: 25.5 KB, free: 912.1 MB)
21/02/17 01:38:38 INFO SparkContext: Created broadcast 21 from broadcast at DAGScheduler.scala:1039
21/02/17 01:38:38 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 20 (MapPartitionsRDD[74] at saveAsTextFile at ReadWrite.scala:283) (first 15 tasks are for partitions Vector(0))
21/02/17 01:38:38 INFO TaskSchedulerImpl: Adding task set 20.0 with 1 tasks
21/02/17 01:38:38 INFO TaskSetManager: Starting task 0.0 in stage 20.0 (TID 20, localhost, executor driver, partition 0, PROCESS_LOCAL, 8097 bytes)
21/02/17 01:38:38 INFO Executor: Running task 0.0 in stage 20.0 (TID 20)
21/02/17 01:38:38 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
21/02/17 01:38:38 INFO FileOutputCommitter: Saved output of task 'attempt_20210217013838_0074_m_000000_0' to file:/tmp/RtmpS1B6G2/file229295a853f48/stages/0_r_formula__1f0c17e2_5e1f_4747_b5f7_cf8564b20278/pipelineModel/stages/0_r_formula__1f0c17e2_5e1f_4747_b5f7_cf8564b20278/metadata/_temporary/0/task_20210217013838_0074_m_000000
21/02/17 01:38:38 INFO SparkHadoopMapRedUtil: attempt_20210217013838_0074_m_000000_0: Committed
21/02/17 01:38:38 INFO Executor: Finished task 0.0 in stage 20.0 (TID 20). 1029 bytes result sent to driver
21/02/17 01:38:38 INFO TaskSetManager: Finished task 0.0 in stage 20.0 (TID 20) in 16 ms on localhost (executor driver) (1/1)
21/02/17 01:38:38 INFO TaskSchedulerImpl: Removed TaskSet 20.0, whose tasks have all completed, from pool 
21/02/17 01:38:38 INFO DAGScheduler: ResultStage 20 (runJob at SparkHadoopWriter.scala:78) finished in 0.030 s
21/02/17 01:38:38 INFO DAGScheduler: Job 15 finished: runJob at SparkHadoopWriter.scala:78, took 0.031802 s
21/02/17 01:38:38 INFO SparkHadoopWriter: Job job_20210217013838_0074 committed.
21/02/17 01:38:38 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
21/02/17 01:38:38 INFO SparkContext: Starting job: runJob at SparkHadoopWriter.scala:78
21/02/17 01:38:38 INFO DAGScheduler: Got job 16 (runJob at SparkHadoopWriter.scala:78) with 1 output partitions
21/02/17 01:38:38 INFO DAGScheduler: Final stage: ResultStage 21 (runJob at SparkHadoopWriter.scala:78)
21/02/17 01:38:38 INFO DAGScheduler: Parents of final stage: List()
21/02/17 01:38:38 INFO DAGScheduler: Missing parents: List()
21/02/17 01:38:38 INFO DAGScheduler: Submitting ResultStage 21 (MapPartitionsRDD[76] at saveAsTextFile at ReadWrite.scala:283), which has no missing parents
21/02/17 01:38:38 INFO MemoryStore: Block broadcast_22 stored as values in memory (estimated size 71.2 KB, free 911.4 MB)
21/02/17 01:38:38 INFO MemoryStore: Block broadcast_22_piece0 stored as bytes in memory (estimated size 25.6 KB, free 911.4 MB)
21/02/17 01:38:38 INFO BlockManagerInfo: Added broadcast_22_piece0 in memory on localhost:34941 (size: 25.6 KB, free: 912.0 MB)
21/02/17 01:38:38 INFO SparkContext: Created broadcast 22 from broadcast at DAGScheduler.scala:1039
21/02/17 01:38:38 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 21 (MapPartitionsRDD[76] at saveAsTextFile at ReadWrite.scala:283) (first 15 tasks are for partitions Vector(0))
21/02/17 01:38:38 INFO TaskSchedulerImpl: Adding task set 21.0 with 1 tasks
21/02/17 01:38:38 INFO TaskSetManager: Starting task 0.0 in stage 21.0 (TID 21, localhost, executor driver, partition 0, PROCESS_LOCAL, 8024 bytes)
21/02/17 01:38:38 INFO Executor: Running task 0.0 in stage 21.0 (TID 21)
21/02/17 01:38:38 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
21/02/17 01:38:38 INFO FileOutputCommitter: Saved output of task 'attempt_20210217013838_0076_m_000000_0' to file:/tmp/RtmpS1B6G2/file229295a853f48/stages/0_r_formula__1f0c17e2_5e1f_4747_b5f7_cf8564b20278/pipelineModel/stages/1_vectorAttrRewriter_830bb07adc02/metadata/_temporary/0/task_20210217013838_0076_m_000000
21/02/17 01:38:38 INFO SparkHadoopMapRedUtil: attempt_20210217013838_0076_m_000000_0: Committed
21/02/17 01:38:38 INFO Executor: Finished task 0.0 in stage 21.0 (TID 21). 1029 bytes result sent to driver
21/02/17 01:38:38 INFO TaskSetManager: Finished task 0.0 in stage 21.0 (TID 21) in 13 ms on localhost (executor driver) (1/1)
21/02/17 01:38:38 INFO TaskSchedulerImpl: Removed TaskSet 21.0, whose tasks have all completed, from pool 
21/02/17 01:38:38 INFO DAGScheduler: ResultStage 21 (runJob at SparkHadoopWriter.scala:78) finished in 0.023 s
21/02/17 01:38:38 INFO DAGScheduler: Job 16 finished: runJob at SparkHadoopWriter.scala:78, took 0.024358 s
21/02/17 01:38:38 INFO SparkHadoopWriter: Job job_20210217013838_0076 committed.
21/02/17 01:38:38 INFO ParquetFileFormat: Using default output committer for Parquet: org.apache.parquet.hadoop.ParquetOutputCommitter
21/02/17 01:38:38 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
21/02/17 01:38:38 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
21/02/17 01:38:38 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
21/02/17 01:38:38 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
21/02/17 01:38:38 INFO CodeGenerator: Code generated in 8.52505 ms
21/02/17 01:38:38 INFO SparkContext: Starting job: parquet at RFormula.scala:586
21/02/17 01:38:38 INFO DAGScheduler: Registering RDD 79 (parquet at RFormula.scala:586)
21/02/17 01:38:38 INFO DAGScheduler: Got job 17 (parquet at RFormula.scala:586) with 1 output partitions
21/02/17 01:38:38 INFO DAGScheduler: Final stage: ResultStage 23 (parquet at RFormula.scala:586)
21/02/17 01:38:38 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 22)
21/02/17 01:38:38 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 22)
21/02/17 01:38:38 INFO DAGScheduler: Submitting ShuffleMapStage 22 (MapPartitionsRDD[79] at parquet at RFormula.scala:586), which has no missing parents
21/02/17 01:38:38 INFO MemoryStore: Block broadcast_23 stored as values in memory (estimated size 4.8 KB, free 911.4 MB)
21/02/17 01:38:38 INFO MemoryStore: Block broadcast_23_piece0 stored as bytes in memory (estimated size 2.8 KB, free 911.4 MB)
21/02/17 01:38:38 INFO BlockManagerInfo: Added broadcast_23_piece0 in memory on localhost:34941 (size: 2.8 KB, free: 912.0 MB)
21/02/17 01:38:38 INFO SparkContext: Created broadcast 23 from broadcast at DAGScheduler.scala:1039
21/02/17 01:38:38 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 22 (MapPartitionsRDD[79] at parquet at RFormula.scala:586) (first 15 tasks are for partitions Vector(0))
21/02/17 01:38:38 INFO TaskSchedulerImpl: Adding task set 22.0 with 1 tasks
21/02/17 01:38:38 INFO TaskSetManager: Starting task 0.0 in stage 22.0 (TID 22, localhost, executor driver, partition 0, PROCESS_LOCAL, 8060 bytes)
21/02/17 01:38:38 INFO Executor: Running task 0.0 in stage 22.0 (TID 22)
21/02/17 01:38:38 INFO Executor: Finished task 0.0 in stage 22.0 (TID 22). 1204 bytes result sent to driver
21/02/17 01:38:38 INFO TaskSetManager: Finished task 0.0 in stage 22.0 (TID 22) in 3 ms on localhost (executor driver) (1/1)
21/02/17 01:38:38 INFO TaskSchedulerImpl: Removed TaskSet 22.0, whose tasks have all completed, from pool 
21/02/17 01:38:38 INFO DAGScheduler: ShuffleMapStage 22 (parquet at RFormula.scala:586) finished in 0.007 s
21/02/17 01:38:38 INFO DAGScheduler: looking for newly runnable stages
21/02/17 01:38:38 INFO DAGScheduler: running: Set()
21/02/17 01:38:38 INFO DAGScheduler: waiting: Set(ResultStage 23)
21/02/17 01:38:38 INFO DAGScheduler: failed: Set()
21/02/17 01:38:38 INFO DAGScheduler: Submitting ResultStage 23 (ShuffledRowRDD[80] at parquet at RFormula.scala:586), which has no missing parents
21/02/17 01:38:38 INFO MemoryStore: Block broadcast_24 stored as values in memory (estimated size 150.9 KB, free 911.2 MB)
21/02/17 01:38:38 INFO MemoryStore: Block broadcast_24_piece0 stored as bytes in memory (estimated size 53.5 KB, free 911.2 MB)
21/02/17 01:38:38 INFO BlockManagerInfo: Added broadcast_24_piece0 in memory on localhost:34941 (size: 53.5 KB, free: 912.0 MB)
21/02/17 01:38:38 INFO SparkContext: Created broadcast 24 from broadcast at DAGScheduler.scala:1039
21/02/17 01:38:38 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 23 (ShuffledRowRDD[80] at parquet at RFormula.scala:586) (first 15 tasks are for partitions Vector(0))
21/02/17 01:38:38 INFO TaskSchedulerImpl: Adding task set 23.0 with 1 tasks
21/02/17 01:38:38 INFO TaskSetManager: Starting task 0.0 in stage 23.0 (TID 23, localhost, executor driver, partition 0, NODE_LOCAL, 7754 bytes)
21/02/17 01:38:38 INFO Executor: Running task 0.0 in stage 23.0 (TID 23)
21/02/17 01:38:38 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
21/02/17 01:38:38 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
21/02/17 01:38:38 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
21/02/17 01:38:38 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
21/02/17 01:38:38 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
21/02/17 01:38:38 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
21/02/17 01:38:38 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:
{
  "type" : "struct",
  "fields" : [ {
    "name" : "vectorCol",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "prefixesToRewrite",
    "type" : {
      "type" : "map",
      "keyType" : "string",
      "valueType" : "string",
      "valueContainsNull" : true
    },
    "nullable" : true,
    "metadata" : { }
  } ]
}
and corresponding Parquet message type:
message spark_schema {
  optional binary vectorCol (UTF8);
  optional group prefixesToRewrite (MAP) {
    repeated group key_value {
      required binary key (UTF8);
      optional binary value (UTF8);
    }
  }
}

       
21/02/17 01:38:38 INFO FileOutputCommitter: Saved output of task 'attempt_20210217013838_0023_m_000000_0' to file:/tmp/RtmpS1B6G2/file229295a853f48/stages/0_r_formula__1f0c17e2_5e1f_4747_b5f7_cf8564b20278/pipelineModel/stages/1_vectorAttrRewriter_830bb07adc02/data/_temporary/0/task_20210217013838_0023_m_000000
21/02/17 01:38:38 INFO SparkHadoopMapRedUtil: attempt_20210217013838_0023_m_000000_0: Committed
21/02/17 01:38:38 INFO Executor: Finished task 0.0 in stage 23.0 (TID 23). 2308 bytes result sent to driver
21/02/17 01:38:38 INFO TaskSetManager: Finished task 0.0 in stage 23.0 (TID 23) in 26 ms on localhost (executor driver) (1/1)
21/02/17 01:38:38 INFO TaskSchedulerImpl: Removed TaskSet 23.0, whose tasks have all completed, from pool 
21/02/17 01:38:38 INFO DAGScheduler: ResultStage 23 (parquet at RFormula.scala:586) finished in 0.043 s
21/02/17 01:38:38 INFO DAGScheduler: Job 17 finished: parquet at RFormula.scala:586, took 0.052935 s
21/02/17 01:38:38 INFO FileFormatWriter: Job null committed.
21/02/17 01:38:38 INFO FileFormatWriter: Finished processing stats for job null.
21/02/17 01:38:38 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
21/02/17 01:38:38 INFO SparkContext: Starting job: runJob at SparkHadoopWriter.scala:78
21/02/17 01:38:38 INFO DAGScheduler: Got job 18 (runJob at SparkHadoopWriter.scala:78) with 1 output partitions
21/02/17 01:38:38 INFO DAGScheduler: Final stage: ResultStage 24 (runJob at SparkHadoopWriter.scala:78)
21/02/17 01:38:38 INFO DAGScheduler: Parents of final stage: List()
21/02/17 01:38:38 INFO DAGScheduler: Missing parents: List()
21/02/17 01:38:38 INFO DAGScheduler: Submitting ResultStage 24 (MapPartitionsRDD[83] at saveAsTextFile at ReadWrite.scala:283), which has no missing parents
21/02/17 01:38:38 INFO MemoryStore: Block broadcast_25 stored as values in memory (estimated size 71.2 KB, free 911.1 MB)
21/02/17 01:38:38 INFO MemoryStore: Block broadcast_25_piece0 stored as bytes in memory (estimated size 25.6 KB, free 911.1 MB)
21/02/17 01:38:38 INFO BlockManagerInfo: Added broadcast_25_piece0 in memory on localhost:34941 (size: 25.6 KB, free: 912.0 MB)
21/02/17 01:38:38 INFO SparkContext: Created broadcast 25 from broadcast at DAGScheduler.scala:1039
21/02/17 01:38:38 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 24 (MapPartitionsRDD[83] at saveAsTextFile at ReadWrite.scala:283) (first 15 tasks are for partitions Vector(0))
21/02/17 01:38:38 INFO TaskSchedulerImpl: Adding task set 24.0 with 1 tasks
21/02/17 01:38:38 INFO TaskSetManager: Starting task 0.0 in stage 24.0 (TID 24, localhost, executor driver, partition 0, PROCESS_LOCAL, 8007 bytes)
21/02/17 01:38:38 INFO Executor: Running task 0.0 in stage 24.0 (TID 24)
21/02/17 01:38:38 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
21/02/17 01:38:38 INFO FileOutputCommitter: Saved output of task 'attempt_20210217013838_0083_m_000000_0' to file:/tmp/RtmpS1B6G2/file229295a853f48/stages/0_r_formula__1f0c17e2_5e1f_4747_b5f7_cf8564b20278/pipelineModel/stages/2_columnPruner_d6a8a49ad94b/metadata/_temporary/0/task_20210217013838_0083_m_000000
21/02/17 01:38:38 INFO SparkHadoopMapRedUtil: attempt_20210217013838_0083_m_000000_0: Committed
21/02/17 01:38:38 INFO Executor: Finished task 0.0 in stage 24.0 (TID 24). 1029 bytes result sent to driver
21/02/17 01:38:38 INFO TaskSetManager: Finished task 0.0 in stage 24.0 (TID 24) in 12 ms on localhost (executor driver) (1/1)
21/02/17 01:38:38 INFO TaskSchedulerImpl: Removed TaskSet 24.0, whose tasks have all completed, from pool 
21/02/17 01:38:38 INFO DAGScheduler: ResultStage 24 (runJob at SparkHadoopWriter.scala:78) finished in 0.025 s
21/02/17 01:38:38 INFO DAGScheduler: Job 18 finished: runJob at SparkHadoopWriter.scala:78, took 0.025546 s
21/02/17 01:38:38 INFO SparkHadoopWriter: Job job_20210217013838_0083 committed.
21/02/17 01:38:38 INFO ParquetFileFormat: Using default output committer for Parquet: org.apache.parquet.hadoop.ParquetOutputCommitter
21/02/17 01:38:38 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
21/02/17 01:38:38 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
21/02/17 01:38:38 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
21/02/17 01:38:38 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
21/02/17 01:38:38 INFO CodeGenerator: Code generated in 6.220647 ms
21/02/17 01:38:38 INFO ContextCleaner: Cleaned accumulator 573
21/02/17 01:38:38 INFO ContextCleaner: Cleaned accumulator 389
21/02/17 01:38:38 INFO ContextCleaner: Cleaned accumulator 677
21/02/17 01:38:38 INFO ContextCleaner: Cleaned accumulator 561
21/02/17 01:38:38 INFO BlockManagerInfo: Removed broadcast_18_piece0 on localhost:34941 in memory (size: 2.9 KB, free: 912.0 MB)
21/02/17 01:38:38 INFO ContextCleaner: Cleaned accumulator 516
21/02/17 01:38:38 INFO ContextCleaner: Cleaned accumulator 392
21/02/17 01:38:38 INFO ContextCleaner: Cleaned accumulator 597
21/02/17 01:38:38 INFO ContextCleaner: Cleaned accumulator 351
21/02/17 01:38:38 INFO ContextCleaner: Cleaned accumulator 519
21/02/17 01:38:38 INFO ContextCleaner: Cleaned accumulator 287
21/02/17 01:38:38 INFO ContextCleaner: Cleaned accumulator 272
21/02/17 01:38:38 INFO ContextCleaner: Cleaned accumulator 649
21/02/17 01:38:38 INFO BlockManagerInfo: Removed broadcast_23_piece0 on localhost:34941 in memory (size: 2.8 KB, free: 912.0 MB)
21/02/17 01:38:38 INFO ContextCleaner: Cleaned accumulator 704
21/02/17 01:38:38 INFO BlockManagerInfo: Removed broadcast_15_piece0 on localhost:34941 in memory (size: 3.8 KB, free: 912.0 MB)
21/02/17 01:38:38 INFO ContextCleaner: Cleaned accumulator 551
21/02/17 01:38:38 INFO ContextCleaner: Cleaned accumulator 498
21/02/17 01:38:38 INFO ContextCleaner: Cleaned accumulator 575
21/02/17 01:38:38 INFO ContextCleaner: Cleaned accumulator 565
21/02/17 01:38:38 INFO ContextCleaner: Cleaned accumulator 415
21/02/17 01:38:38 INFO ContextCleaner: Cleaned accumulator 329
21/02/17 01:38:38 INFO ContextCleaner: Cleaned accumulator 332
21/02/17 01:38:38 INFO ContextCleaner: Cleaned accumulator 345
21/02/17 01:38:38 INFO ContextCleaner: Cleaned accumulator 446
21/02/17 01:38:38 INFO ContextCleaner: Cleaned accumulator 693
21/02/17 01:38:38 INFO BlockManagerInfo: Removed broadcast_16_piece0 on localhost:34941 in memory (size: 25.3 KB, free: 912.0 MB)
21/02/17 01:38:38 INFO ContextCleaner: Cleaned accumulator 592
21/02/17 01:38:38 INFO ContextCleaner: Cleaned accumulator 642
21/02/17 01:38:38 INFO ContextCleaner: Cleaned accumulator 673
21/02/17 01:38:38 INFO ContextCleaner: Cleaned accumulator 655
21/02/17 01:38:38 INFO ContextCleaner: Cleaned accumulator 433
21/02/17 01:38:38 INFO ContextCleaner: Cleaned accumulator 490
21/02/17 01:38:38 INFO ContextCleaner: Cleaned accumulator 398
21/02/17 01:38:38 INFO ContextCleaner: Cleaned accumulator 569
21/02/17 01:38:38 INFO ContextCleaner: Cleaned accumulator 570
21/02/17 01:38:38 INFO ContextCleaner: Cleaned accumulator 333
21/02/17 01:38:38 INFO ContextCleaner: Cleaned accumulator 504
21/02/17 01:38:38 INFO ContextCleaner: Cleaned accumulator 557
21/02/17 01:38:38 INFO ContextCleaner: Cleaned accumulator 517
21/02/17 01:38:38 INFO ContextCleaner: Cleaned accumulator 715
21/02/17 01:38:38 INFO ContextCleaner: Cleaned accumulator 396
21/02/17 01:38:38 INFO ContextCleaner: Cleaned accumulator 342
21/02/17 01:38:38 INFO ContextCleaner: Cleaned accumulator 405
21/02/17 01:38:38 INFO ContextCleaner: Cleaned accumulator 707
21/02/17 01:38:38 INFO ContextCleaner: Cleaned accumulator 313
21/02/17 01:38:38 INFO ContextCleaner: Cleaned shuffle 3
21/02/17 01:38:38 INFO ContextCleaner: Cleaned accumulator 502
21/02/17 01:38:38 INFO ContextCleaner: Cleaned accumulator 663
21/02/17 01:38:38 INFO ContextCleaner: Cleaned accumulator 656
21/02/17 01:38:38 INFO ContextCleaner: Cleaned accumulator 670
21/02/17 01:38:38 INFO ContextCleaner: Cleaned accumulator 381
21/02/17 01:38:38 INFO ContextCleaner: Cleaned accumulator 591
21/02/17 01:38:38 INFO ContextCleaner: Cleaned accumulator 646
21/02/17 01:38:38 INFO ContextCleaner: Cleaned accumulator 617
21/02/17 01:38:38 INFO ContextCleaner: Cleaned accumulator 648
21/02/17 01:38:38 INFO ContextCleaner: Cleaned accumulator 622
21/02/17 01:38:38 INFO ContextCleaner: Cleaned accumulator 387
21/02/17 01:38:38 INFO ContextCleaner: Cleaned accumulator 434
21/02/17 01:38:38 INFO ContextCleaner: Cleaned accumulator 429
21/02/17 01:38:38 INFO ContextCleaner: Cleaned accumulator 322
21/02/17 01:38:38 INFO ContextCleaner: Cleaned accumulator 474
21/02/17 01:38:38 INFO ContextCleaner: Cleaned accumulator 635
21/02/17 01:38:38 INFO ContextCleaner: Cleaned accumulator 705
21/02/17 01:38:38 INFO ContextCleaner: Cleaned accumulator 497
21/02/17 01:38:38 INFO ContextCleaner: Cleaned accumulator 323
21/02/17 01:38:38 INFO ContextCleaner: Cleaned accumulator 507
21/02/17 01:38:38 INFO ContextCleaner: Cleaned accumulator 483
21/02/17 01:38:38 INFO ContextCleaner: Cleaned accumulator 488
21/02/17 01:38:38 INFO ContextCleaner: Cleaned accumulator 416
21/02/17 01:38:38 INFO ContextCleaner: Cleaned accumulator 540
21/02/17 01:38:38 INFO ContextCleaner: Cleaned accumulator 486
21/02/17 01:38:38 INFO ContextCleaner: Cleaned accumulator 614
21/02/17 01:38:38 INFO ContextCleaner: Cleaned accumulator 564
21/02/17 01:38:38 INFO ContextCleaner: Cleaned accumulator 411
21/02/17 01:38:38 INFO ContextCleaner: Cleaned accumulator 586
21/02/17 01:38:38 INFO ContextCleaner: Cleaned accumulator 668
21/02/17 01:38:38 INFO ContextCleaner: Cleaned accumulator 296
21/02/17 01:38:38 INFO ContextCleaner: Cleaned accumulator 611
21/02/17 01:38:38 INFO ContextCleaner: Cleaned accumulator 449
21/02/17 01:38:38 INFO ContextCleaner: Cleaned accumulator 534
21/02/17 01:38:38 INFO ContextCleaner: Cleaned accumulator 309
21/02/17 01:38:38 INFO ContextCleaner: Cleaned accumulator 495
21/02/17 01:38:38 INFO ContextCleaner: Cleaned accumulator 680
21/02/17 01:38:38 INFO ContextCleaner: Cleaned accumulator 637
21/02/17 01:38:38 INFO ContextCleaner: Cleaned accumulator 493
21/02/17 01:38:38 INFO ContextCleaner: Cleaned accumulator 364
21/02/17 01:38:38 INFO ContextCleaner: Cleaned accumulator 536
21/02/17 01:38:38 INFO ContextCleaner: Cleaned accumulator 589
21/02/17 01:38:38 INFO ContextCleaner: Cleaned accumulator 679
21/02/17 01:38:38 INFO ContextCleaner: Cleaned accumulator 374
21/02/17 01:38:38 INFO ContextCleaner: Cleaned accumulator 456
21/02/17 01:38:38 INFO ContextCleaner: Cleaned accumulator 458
21/02/17 01:38:38 INFO ContextCleaner: Cleaned accumulator 645
21/02/17 01:38:38 INFO ContextCleaner: Cleaned accumulator 512
21/02/17 01:38:38 INFO ContextCleaner: Cleaned accumulator 464
21/02/17 01:38:38 INFO ContextCleaner: Cleaned accumulator 703
21/02/17 01:38:38 INFO ContextCleaner: Cleaned accumulator 320
21/02/17 01:38:38 INFO BlockManagerInfo: Removed broadcast_25_piece0 on localhost:34941 in memory (size: 25.6 KB, free: 912.0 MB)
21/02/17 01:38:38 INFO ContextCleaner: Cleaned accumulator 397
21/02/17 01:38:38 INFO ContextCleaner: Cleaned accumulator 700
21/02/17 01:38:38 INFO ContextCleaner: Cleaned accumulator 326
21/02/17 01:38:38 INFO ContextCleaner: Cleaned accumulator 420
21/02/17 01:38:38 INFO ContextCleaner: Cleaned accumulator 445
21/02/17 01:38:38 INFO BlockManagerInfo: Removed broadcast_10_piece0 on localhost:34941 in memory (size: 3.2 KB, free: 912.0 MB)
21/02/17 01:38:38 INFO ContextCleaner: Cleaned accumulator 509
21/02/17 01:38:38 INFO ContextCleaner: Cleaned accumulator 276
21/02/17 01:38:38 INFO ContextCleaner: Cleaned accumulator 348
21/02/17 01:38:38 INFO ContextCleaner: Cleaned accumulator 520
21/02/17 01:38:38 INFO ContextCleaner: Cleaned accumulator 281
21/02/17 01:38:38 INFO ContextCleaner: Cleaned accumulator 467
21/02/17 01:38:38 INFO ContextCleaner: Cleaned accumulator 440
21/02/17 01:38:38 INFO ContextCleaner: Cleaned accumulator 393
21/02/17 01:38:38 INFO ContextCleaner: Cleaned accumulator 413
21/02/17 01:38:38 INFO ContextCleaner: Cleaned accumulator 521
21/02/17 01:38:38 INFO ContextCleaner: Cleaned accumulator 577
21/02/17 01:38:38 INFO ContextCleaner: Cleaned accumulator 460
21/02/17 01:38:38 INFO ContextCleaner: Cleaned accumulator 417
21/02/17 01:38:38 INFO ContextCleaner: Cleaned accumulator 606
21/02/17 01:38:38 INFO ContextCleaner: Cleaned accumulator 410
21/02/17 01:38:38 INFO ContextCleaner: Cleaned accumulator 581
21/02/17 01:38:38 INFO ContextCleaner: Cleaned accumulator 666
21/02/17 01:38:38 INFO ContextCleaner: Cleaned accumulator 558
21/02/17 01:38:38 INFO ContextCleaner: Cleaned accumulator 689
21/02/17 01:38:38 INFO ContextCleaner: Cleaned accumulator 523
21/02/17 01:38:38 INFO ContextCleaner: Cleaned accumulator 563
21/02/17 01:38:38 INFO ContextCleaner: Cleaned accumulator 698
21/02/17 01:38:38 INFO ContextCleaner: Cleaned accumulator 714
21/02/17 01:38:38 INFO ContextCleaner: Cleaned accumulator 428
21/02/17 01:38:38 INFO ContextCleaner: Cleaned accumulator 667
21/02/17 01:38:38 INFO ContextCleaner: Cleaned accumulator 687
21/02/17 01:38:38 INFO ContextCleaner: Cleaned accumulator 580
21/02/17 01:38:38 INFO ContextCleaner: Cleaned accumulator 612
21/02/17 01:38:38 INFO ContextCleaner: Cleaned accumulator 375
21/02/17 01:38:38 INFO ContextCleaner: Cleaned accumulator 553
21/02/17 01:38:38 INFO ContextCleaner: Cleaned accumulator 532
21/02/17 01:38:38 INFO ContextCleaner: Cleaned accumulator 477
21/02/17 01:38:38 INFO ContextCleaner: Cleaned accumulator 452
21/02/17 01:38:38 INFO ContextCleaner: Cleaned accumulator 366
21/02/17 01:38:38 INFO ContextCleaner: Cleaned accumulator 269
21/02/17 01:38:38 INFO ContextCleaner: Cleaned accumulator 291
21/02/17 01:38:38 INFO ContextCleaner: Cleaned accumulator 510
21/02/17 01:38:38 INFO BlockManagerInfo: Removed broadcast_19_piece0 on localhost:34941 in memory (size: 53.4 KB, free: 912.1 MB)
21/02/17 01:38:38 INFO ContextCleaner: Cleaned accumulator 473
21/02/17 01:38:38 INFO ContextCleaner: Cleaned accumulator 325
21/02/17 01:38:38 INFO ContextCleaner: Cleaned accumulator 451
21/02/17 01:38:38 INFO ContextCleaner: Cleaned accumulator 432
21/02/17 01:38:38 INFO ContextCleaner: Cleaned accumulator 503
21/02/17 01:38:38 INFO ContextCleaner: Cleaned accumulator 400
21/02/17 01:38:38 INFO ContextCleaner: Cleaned accumulator 403
21/02/17 01:38:38 INFO ContextCleaner: Cleaned accumulator 688
21/02/17 01:38:38 INFO ContextCleaner: Cleaned accumulator 556
21/02/17 01:38:38 INFO ContextCleaner: Cleaned accumulator 341
21/02/17 01:38:38 INFO ContextCleaner: Cleaned accumulator 533
21/02/17 01:38:38 INFO ContextCleaner: Cleaned accumulator 696
21/02/17 01:38:38 INFO ContextCleaner: Cleaned accumulator 442
21/02/17 01:38:38 INFO ContextCleaner: Cleaned accumulator 494
21/02/17 01:38:38 INFO ContextCleaner: Cleaned accumulator 338
21/02/17 01:38:38 INFO ContextCleaner: Cleaned accumulator 367
21/02/17 01:38:38 INFO ContextCleaner: Cleaned accumulator 489
21/02/17 01:38:38 INFO ContextCleaner: Cleaned accumulator 316
21/02/17 01:38:38 INFO ContextCleaner: Cleaned accumulator 567
21/02/17 01:38:38 INFO ContextCleaner: Cleaned accumulator 343
21/02/17 01:38:38 INFO ContextCleaner: Cleaned accumulator 357
21/02/17 01:38:38 INFO ContextCleaner: Cleaned accumulator 535
21/02/17 01:38:38 INFO ContextCleaner: Cleaned accumulator 283
21/02/17 01:38:38 INFO ContextCleaner: Cleaned accumulator 499
21/02/17 01:38:38 INFO ContextCleaner: Cleaned accumulator 353
21/02/17 01:38:38 INFO ContextCleaner: Cleaned accumulator 709
21/02/17 01:38:38 INFO ContextCleaner: Cleaned accumulator 388
21/02/17 01:38:38 INFO ContextCleaner: Cleaned accumulator 695
21/02/17 01:38:38 INFO ContextCleaner: Cleaned accumulator 692
21/02/17 01:38:38 INFO ContextCleaner: Cleaned accumulator 438
21/02/17 01:38:38 INFO ContextCleaner: Cleaned accumulator 640
21/02/17 01:38:38 INFO ContextCleaner: Cleaned accumulator 706
21/02/17 01:38:38 INFO ContextCleaner: Cleaned accumulator 468
21/02/17 01:38:38 INFO ContextCleaner: Cleaned accumulator 465
21/02/17 01:38:38 INFO ContextCleaner: Cleaned accumulator 298
21/02/17 01:38:38 INFO ContextCleaner: Cleaned accumulator 576
21/02/17 01:38:38 INFO ContextCleaner: Cleaned accumulator 654
21/02/17 01:38:38 INFO ContextCleaner: Cleaned accumulator 607
21/02/17 01:38:38 INFO ContextCleaner: Cleaned accumulator 270
21/02/17 01:38:38 INFO ContextCleaner: Cleaned accumulator 363
21/02/17 01:38:38 INFO ContextCleaner: Cleaned accumulator 659
21/02/17 01:38:38 INFO ContextCleaner: Cleaned shuffle 5
21/02/17 01:38:38 INFO ContextCleaner: Cleaned accumulator 615
21/02/17 01:38:38 INFO ContextCleaner: Cleaned accumulator 469
21/02/17 01:38:38 INFO ContextCleaner: Cleaned accumulator 518
21/02/17 01:38:38 INFO ContextCleaner: Cleaned accumulator 643
21/02/17 01:38:38 INFO ContextCleaner: Cleaned accumulator 414
21/02/17 01:38:38 INFO ContextCleaner: Cleaned accumulator 545
21/02/17 01:38:38 INFO ContextCleaner: Cleaned accumulator 317
21/02/17 01:38:38 INFO ContextCleaner: Cleaned accumulator 308
21/02/17 01:38:38 INFO ContextCleaner: Cleaned accumulator 303
21/02/17 01:38:38 INFO ContextCleaner: Cleaned accumulator 286
21/02/17 01:38:38 INFO ContextCleaner: Cleaned accumulator 590
21/02/17 01:38:38 INFO ContextCleaner: Cleaned accumulator 462
21/02/17 01:38:38 INFO ContextCleaner: Cleaned accumulator 638
21/02/17 01:38:38 INFO ContextCleaner: Cleaned accumulator 324
21/02/17 01:38:38 INFO ContextCleaner: Cleaned accumulator 472
21/02/17 01:38:38 INFO ContextCleaner: Cleaned accumulator 424
21/02/17 01:38:38 INFO ContextCleaner: Cleaned accumulator 394
21/02/17 01:38:38 INFO BlockManagerInfo: Removed broadcast_13_piece0 on localhost:34941 in memory (size: 25.3 KB, free: 912.1 MB)
21/02/17 01:38:38 INFO ContextCleaner: Cleaned accumulator 457
21/02/17 01:38:38 INFO ContextCleaner: Cleaned accumulator 568
21/02/17 01:38:38 INFO ContextCleaner: Cleaned accumulator 487
21/02/17 01:38:38 INFO ContextCleaner: Cleaned accumulator 402
21/02/17 01:38:38 INFO ContextCleaner: Cleaned accumulator 651
21/02/17 01:38:38 INFO ContextCleaner: Cleaned accumulator 271
21/02/17 01:38:38 INFO ContextCleaner: Cleaned accumulator 294
21/02/17 01:38:38 INFO ContextCleaner: Cleaned accumulator 596
21/02/17 01:38:38 INFO ContextCleaner: Cleaned accumulator 297
21/02/17 01:38:38 INFO BlockManagerInfo: Removed broadcast_11_piece0 on localhost:34941 in memory (size: 4.5 KB, free: 912.1 MB)
21/02/17 01:38:38 INFO ContextCleaner: Cleaned accumulator 674
21/02/17 01:38:38 INFO ContextCleaner: Cleaned accumulator 616
21/02/17 01:38:38 INFO ContextCleaner: Cleaned accumulator 448
21/02/17 01:38:38 INFO ContextCleaner: Cleaned accumulator 293
21/02/17 01:38:38 INFO ContextCleaner: Cleaned accumulator 337
21/02/17 01:38:38 INFO ContextCleaner: Cleaned accumulator 547
21/02/17 01:38:38 INFO ContextCleaner: Cleaned accumulator 459
21/02/17 01:38:38 INFO ContextCleaner: Cleaned accumulator 571
21/02/17 01:38:38 INFO ContextCleaner: Cleaned accumulator 390
21/02/17 01:38:38 INFO ContextCleaner: Cleaned accumulator 684
21/02/17 01:38:38 INFO ContextCleaner: Cleaned accumulator 531
21/02/17 01:38:38 INFO ContextCleaner: Cleaned accumulator 484
21/02/17 01:38:38 INFO ContextCleaner: Cleaned accumulator 311
21/02/17 01:38:38 INFO ContextCleaner: Cleaned accumulator 578
21/02/17 01:38:38 INFO ContextCleaner: Cleaned accumulator 669
21/02/17 01:38:38 INFO ContextCleaner: Cleaned accumulator 385
21/02/17 01:38:38 INFO ContextCleaner: Cleaned accumulator 691
21/02/17 01:38:38 INFO ContextCleaner: Cleaned accumulator 600
21/02/17 01:38:38 INFO ContextCleaner: Cleaned accumulator 349
21/02/17 01:38:38 INFO ContextCleaner: Cleaned accumulator 661
21/02/17 01:38:38 INFO ContextCleaner: Cleaned accumulator 426
21/02/17 01:38:38 INFO ContextCleaner: Cleaned accumulator 491
21/02/17 01:38:38 INFO ContextCleaner: Cleaned accumulator 511
21/02/17 01:38:38 INFO ContextCleaner: Cleaned accumulator 627
21/02/17 01:38:38 INFO ContextCleaner: Cleaned accumulator 587
21/02/17 01:38:38 INFO ContextCleaner: Cleaned accumulator 647
21/02/17 01:38:38 INFO ContextCleaner: Cleaned accumulator 676
21/02/17 01:38:38 INFO ContextCleaner: Cleaned accumulator 678
21/02/17 01:38:38 INFO ContextCleaner: Cleaned accumulator 307
21/02/17 01:38:38 INFO ContextCleaner: Cleaned accumulator 624
21/02/17 01:38:38 INFO ContextCleaner: Cleaned accumulator 603
21/02/17 01:38:38 INFO ContextCleaner: Cleaned accumulator 419
21/02/17 01:38:38 INFO ContextCleaner: Cleaned accumulator 463
21/02/17 01:38:38 INFO ContextCleaner: Cleaned accumulator 584
21/02/17 01:38:38 INFO ContextCleaner: Cleaned accumulator 376
21/02/17 01:38:38 INFO ContextCleaner: Cleaned accumulator 595
21/02/17 01:38:38 INFO ContextCleaner: Cleaned accumulator 335
21/02/17 01:38:38 INFO ContextCleaner: Cleaned accumulator 513
21/02/17 01:38:38 INFO ContextCleaner: Cleaned accumulator 441
21/02/17 01:38:38 INFO ContextCleaner: Cleaned shuffle 4
21/02/17 01:38:38 INFO ContextCleaner: Cleaned accumulator 455
21/02/17 01:38:38 INFO ContextCleaner: Cleaned accumulator 361
21/02/17 01:38:38 INFO ContextCleaner: Cleaned accumulator 527
21/02/17 01:38:38 INFO ContextCleaner: Cleaned accumulator 352
21/02/17 01:38:38 INFO ContextCleaner: Cleaned accumulator 470
21/02/17 01:38:38 INFO ContextCleaner: Cleaned accumulator 658
21/02/17 01:38:38 INFO ContextCleaner: Cleaned accumulator 625
21/02/17 01:38:38 INFO ContextCleaner: Cleaned accumulator 694
21/02/17 01:38:38 INFO ContextCleaner: Cleaned accumulator 530
21/02/17 01:38:38 INFO ContextCleaner: Cleaned accumulator 552
21/02/17 01:38:38 INFO ContextCleaner: Cleaned accumulator 501
21/02/17 01:38:38 INFO ContextCleaner: Cleaned accumulator 340
21/02/17 01:38:38 INFO SparkContext: Starting job: parquet at RFormula.scala:495
21/02/17 01:38:38 INFO ContextCleaner: Cleaned accumulator 524
21/02/17 01:38:38 INFO ContextCleaner: Cleaned accumulator 702
21/02/17 01:38:38 INFO ContextCleaner: Cleaned accumulator 318
21/02/17 01:38:38 INFO ContextCleaner: Cleaned accumulator 285
21/02/17 01:38:38 INFO ContextCleaner: Cleaned accumulator 275
21/02/17 01:38:38 INFO ContextCleaner: Cleaned accumulator 585
21/02/17 01:38:38 INFO ContextCleaner: Cleaned accumulator 708
21/02/17 01:38:38 INFO DAGScheduler: Registering RDD 86 (parquet at RFormula.scala:495)
21/02/17 01:38:38 INFO DAGScheduler: Got job 19 (parquet at RFormula.scala:495) with 1 output partitions
21/02/17 01:38:38 INFO DAGScheduler: Final stage: ResultStage 26 (parquet at RFormula.scala:495)
21/02/17 01:38:38 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 25)
21/02/17 01:38:38 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 25)
21/02/17 01:38:38 INFO BlockManagerInfo: Removed broadcast_22_piece0 on localhost:34941 in memory (size: 25.6 KB, free: 912.1 MB)
21/02/17 01:38:38 INFO DAGScheduler: Submitting ShuffleMapStage 25 (MapPartitionsRDD[86] at parquet at RFormula.scala:495), which has no missing parents
21/02/17 01:38:38 INFO ContextCleaner: Cleaned accumulator 277
21/02/17 01:38:38 INFO ContextCleaner: Cleaned accumulator 515
21/02/17 01:38:38 INFO ContextCleaner: Cleaned accumulator 282
21/02/17 01:38:38 INFO ContextCleaner: Cleaned accumulator 383
21/02/17 01:38:38 INFO ContextCleaner: Cleaned accumulator 378
21/02/17 01:38:38 INFO ContextCleaner: Cleaned accumulator 675
21/02/17 01:38:38 INFO ContextCleaner: Cleaned accumulator 598
21/02/17 01:38:38 INFO ContextCleaner: Cleaned accumulator 279
21/02/17 01:38:38 INFO ContextCleaner: Cleaned accumulator 406
21/02/17 01:38:38 INFO ContextCleaner: Cleaned accumulator 412
21/02/17 01:38:38 INFO ContextCleaner: Cleaned accumulator 305
21/02/17 01:38:38 INFO ContextCleaner: Cleaned accumulator 365
21/02/17 01:38:38 INFO ContextCleaner: Cleaned accumulator 450
21/02/17 01:38:38 INFO ContextCleaner: Cleaned accumulator 529
21/02/17 01:38:38 INFO ContextCleaner: Cleaned accumulator 362
21/02/17 01:38:38 INFO ContextCleaner: Cleaned accumulator 550
21/02/17 01:38:38 INFO ContextCleaner: Cleaned accumulator 583
21/02/17 01:38:38 INFO ContextCleaner: Cleaned accumulator 690
21/02/17 01:38:38 INFO ContextCleaner: Cleaned accumulator 588
21/02/17 01:38:38 INFO ContextCleaner: Cleaned accumulator 344
21/02/17 01:38:38 INFO ContextCleaner: Cleaned accumulator 610
21/02/17 01:38:38 INFO ContextCleaner: Cleaned accumulator 289
21/02/17 01:38:38 INFO ContextCleaner: Cleaned accumulator 377
21/02/17 01:38:38 INFO ContextCleaner: Cleaned accumulator 299
21/02/17 01:38:38 INFO ContextCleaner: Cleaned accumulator 273
21/02/17 01:38:38 INFO ContextCleaner: Cleaned accumulator 544
21/02/17 01:38:38 INFO ContextCleaner: Cleaned accumulator 475
21/02/17 01:38:38 INFO ContextCleaner: Cleaned accumulator 444
21/02/17 01:38:38 INFO ContextCleaner: Cleaned accumulator 346
21/02/17 01:38:38 INFO ContextCleaner: Cleaned accumulator 652
21/02/17 01:38:38 INFO ContextCleaner: Cleaned accumulator 671
21/02/17 01:38:38 INFO ContextCleaner: Cleaned accumulator 427
21/02/17 01:38:38 INFO ContextCleaner: Cleaned accumulator 701
21/02/17 01:38:38 INFO MemoryStore: Block broadcast_26 stored as values in memory (estimated size 4.7 KB, free 911.7 MB)
21/02/17 01:38:38 INFO ContextCleaner: Cleaned accumulator 613
21/02/17 01:38:38 INFO ContextCleaner: Cleaned accumulator 539
21/02/17 01:38:38 INFO ContextCleaner: Cleaned accumulator 500
21/02/17 01:38:38 INFO ContextCleaner: Cleaned accumulator 300
21/02/17 01:38:38 INFO ContextCleaner: Cleaned accumulator 408
21/02/17 01:38:38 INFO ContextCleaner: Cleaned accumulator 268
21/02/17 01:38:38 INFO ContextCleaner: Cleaned accumulator 559
21/02/17 01:38:38 INFO ContextCleaner: Cleaned accumulator 623
21/02/17 01:38:38 INFO ContextCleaner: Cleaned accumulator 554
21/02/17 01:38:38 INFO ContextCleaner: Cleaned accumulator 302
21/02/17 01:38:38 INFO ContextCleaner: Cleaned accumulator 641
21/02/17 01:38:38 INFO ContextCleaner: Cleaned accumulator 508
21/02/17 01:38:38 INFO ContextCleaner: Cleaned accumulator 672
21/02/17 01:38:38 INFO ContextCleaner: Cleaned accumulator 560
21/02/17 01:38:38 INFO MemoryStore: Block broadcast_26_piece0 stored as bytes in memory (estimated size 2.8 KB, free 911.9 MB)
21/02/17 01:38:38 INFO BlockManagerInfo: Removed broadcast_24_piece0 on localhost:34941 in memory (size: 53.5 KB, free: 912.2 MB)
21/02/17 01:38:38 INFO BlockManagerInfo: Added broadcast_26_piece0 in memory on localhost:34941 (size: 2.8 KB, free: 912.2 MB)
21/02/17 01:38:38 INFO SparkContext: Created broadcast 26 from broadcast at DAGScheduler.scala:1039
21/02/17 01:38:38 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 25 (MapPartitionsRDD[86] at parquet at RFormula.scala:495) (first 15 tasks are for partitions Vector(0))
21/02/17 01:38:38 INFO BlockManagerInfo: Removed broadcast_20_piece0 on localhost:34941 in memory (size: 25.5 KB, free: 912.2 MB)
21/02/17 01:38:38 INFO TaskSchedulerImpl: Adding task set 25.0 with 1 tasks
21/02/17 01:38:38 INFO ContextCleaner: Cleaned accumulator 660
21/02/17 01:38:38 INFO ContextCleaner: Cleaned accumulator 418
21/02/17 01:38:38 INFO ContextCleaner: Cleaned accumulator 650
21/02/17 01:38:38 INFO ContextCleaner: Cleaned accumulator 594
21/02/17 01:38:38 INFO ContextCleaner: Cleaned accumulator 644
21/02/17 01:38:38 INFO ContextCleaner: Cleaned accumulator 306
21/02/17 01:38:38 INFO ContextCleaner: Cleaned accumulator 453
21/02/17 01:38:38 INFO ContextCleaner: Cleaned accumulator 354
21/02/17 01:38:38 INFO ContextCleaner: Cleaned accumulator 505
21/02/17 01:38:38 INFO ContextCleaner: Cleaned accumulator 549
21/02/17 01:38:38 INFO ContextCleaner: Cleaned accumulator 369
21/02/17 01:38:38 INFO ContextCleaner: Cleaned accumulator 395
21/02/17 01:38:38 INFO ContextCleaner: Cleaned accumulator 542
21/02/17 01:38:38 INFO ContextCleaner: Cleaned accumulator 328
21/02/17 01:38:38 INFO ContextCleaner: Cleaned accumulator 599
21/02/17 01:38:38 INFO ContextCleaner: Cleaned accumulator 548
21/02/17 01:38:38 INFO ContextCleaner: Cleaned accumulator 425
21/02/17 01:38:38 INFO ContextCleaner: Cleaned accumulator 355
21/02/17 01:38:38 INFO ContextCleaner: Cleaned accumulator 601
21/02/17 01:38:38 INFO ContextCleaner: Cleaned accumulator 528
21/02/17 01:38:38 INFO ContextCleaner: Cleaned accumulator 619
21/02/17 01:38:38 INFO ContextCleaner: Cleaned accumulator 476
21/02/17 01:38:38 INFO ContextCleaner: Cleaned accumulator 574
21/02/17 01:38:38 INFO ContextCleaner: Cleaned accumulator 334
21/02/17 01:38:38 INFO ContextCleaner: Cleaned accumulator 537
21/02/17 01:38:38 INFO ContextCleaner: Cleaned accumulator 506
21/02/17 01:38:38 INFO ContextCleaner: Cleaned accumulator 639
21/02/17 01:38:38 INFO ContextCleaner: Cleaned accumulator 546
21/02/17 01:38:38 INFO TaskSetManager: Starting task 0.0 in stage 25.0 (TID 25, localhost, executor driver, partition 0, PROCESS_LOCAL, 8028 bytes)
21/02/17 01:38:38 INFO ContextCleaner: Cleaned accumulator 310
21/02/17 01:38:38 INFO ContextCleaner: Cleaned accumulator 439
21/02/17 01:38:38 INFO ContextCleaner: Cleaned accumulator 409
21/02/17 01:38:38 INFO ContextCleaner: Cleaned accumulator 356
21/02/17 01:38:38 INFO ContextCleaner: Cleaned accumulator 633
21/02/17 01:38:38 INFO ContextCleaner: Cleaned accumulator 685
21/02/17 01:38:38 INFO ContextCleaner: Cleaned accumulator 280
21/02/17 01:38:38 INFO ContextCleaner: Cleaned accumulator 681
21/02/17 01:38:38 INFO ContextCleaner: Cleaned accumulator 686
21/02/17 01:38:38 INFO ContextCleaner: Cleaned accumulator 481
21/02/17 01:38:38 INFO ContextCleaner: Cleaned accumulator 384
21/02/17 01:38:38 INFO ContextCleaner: Cleaned accumulator 336
21/02/17 01:38:38 INFO ContextCleaner: Cleaned accumulator 358
21/02/17 01:38:38 INFO Executor: Running task 0.0 in stage 25.0 (TID 25)
21/02/17 01:38:38 INFO ContextCleaner: Cleaned shuffle 2
21/02/17 01:38:38 INFO ContextCleaner: Cleaned accumulator 629
21/02/17 01:38:38 INFO ContextCleaner: Cleaned accumulator 301
21/02/17 01:38:38 INFO ContextCleaner: Cleaned accumulator 421
21/02/17 01:38:38 INFO ContextCleaner: Cleaned accumulator 407
21/02/17 01:38:38 INFO ContextCleaner: Cleaned accumulator 284
21/02/17 01:38:38 INFO ContextCleaner: Cleaned accumulator 682
21/02/17 01:38:38 INFO BlockManagerInfo: Removed broadcast_12_piece0 on localhost:34941 in memory (size: 3.8 KB, free: 912.2 MB)
21/02/17 01:38:38 INFO ContextCleaner: Cleaned accumulator 319
21/02/17 01:38:38 INFO ContextCleaner: Cleaned accumulator 632
21/02/17 01:38:38 INFO ContextCleaner: Cleaned accumulator 331
21/02/17 01:38:38 INFO ContextCleaner: Cleaned accumulator 526
21/02/17 01:38:38 INFO ContextCleaner: Cleaned accumulator 350
21/02/17 01:38:38 INFO ContextCleaner: Cleaned accumulator 579
21/02/17 01:38:38 INFO ContextCleaner: Cleaned accumulator 288
21/02/17 01:38:38 INFO ContextCleaner: Cleaned accumulator 321
21/02/17 01:38:38 INFO ContextCleaner: Cleaned accumulator 608
21/02/17 01:38:38 INFO ContextCleaner: Cleaned accumulator 621
21/02/17 01:38:38 INFO ContextCleaner: Cleaned accumulator 604
21/02/17 01:38:38 INFO ContextCleaner: Cleaned accumulator 712
21/02/17 01:38:38 INFO ContextCleaner: Cleaned accumulator 480
21/02/17 01:38:38 INFO ContextCleaner: Cleaned accumulator 555
21/02/17 01:38:38 INFO ContextCleaner: Cleaned accumulator 636
21/02/17 01:38:38 INFO ContextCleaner: Cleaned accumulator 543
21/02/17 01:38:38 INFO ContextCleaner: Cleaned accumulator 379
21/02/17 01:38:38 INFO ContextCleaner: Cleaned accumulator 593
21/02/17 01:38:38 INFO ContextCleaner: Cleaned accumulator 525
21/02/17 01:38:38 INFO ContextCleaner: Cleaned accumulator 562
21/02/17 01:38:38 INFO ContextCleaner: Cleaned accumulator 330
21/02/17 01:38:38 INFO ContextCleaner: Cleaned accumulator 653
21/02/17 01:38:38 INFO ContextCleaner: Cleaned accumulator 609
21/02/17 01:38:38 INFO ContextCleaner: Cleaned accumulator 401
21/02/17 01:38:38 INFO ContextCleaner: Cleaned accumulator 454
21/02/17 01:38:38 INFO ContextCleaner: Cleaned accumulator 399
21/02/17 01:38:38 INFO ContextCleaner: Cleaned accumulator 699
21/02/17 01:38:38 INFO ContextCleaner: Cleaned accumulator 339
21/02/17 01:38:38 INFO ContextCleaner: Cleaned accumulator 482
21/02/17 01:38:38 INFO ContextCleaner: Cleaned accumulator 572
21/02/17 01:38:38 INFO ContextCleaner: Cleaned accumulator 423
21/02/17 01:38:38 INFO ContextCleaner: Cleaned accumulator 538
21/02/17 01:38:38 INFO ContextCleaner: Cleaned accumulator 386
21/02/17 01:38:38 INFO ContextCleaner: Cleaned accumulator 479
21/02/17 01:38:38 INFO ContextCleaner: Cleaned accumulator 368
21/02/17 01:38:38 INFO ContextCleaner: Cleaned accumulator 602
21/02/17 01:38:38 INFO ContextCleaner: Cleaned accumulator 665
21/02/17 01:38:38 INFO ContextCleaner: Cleaned accumulator 496
21/02/17 01:38:38 INFO ContextCleaner: Cleaned accumulator 292
21/02/17 01:38:38 INFO ContextCleaner: Cleaned accumulator 697
21/02/17 01:38:38 INFO ContextCleaner: Cleaned accumulator 431
21/02/17 01:38:38 INFO ContextCleaner: Cleaned accumulator 710
21/02/17 01:38:38 INFO ContextCleaner: Cleaned accumulator 466
21/02/17 01:38:38 INFO Executor: Finished task 0.0 in stage 25.0 (TID 25). 1247 bytes result sent to driver
21/02/17 01:38:38 INFO BlockManagerInfo: Removed broadcast_17_piece0 on localhost:34941 in memory (size: 25.4 KB, free: 912.2 MB)
21/02/17 01:38:38 INFO ContextCleaner: Cleaned accumulator 380
21/02/17 01:38:38 INFO ContextCleaner: Cleaned accumulator 582
21/02/17 01:38:38 INFO ContextCleaner: Cleaned accumulator 315
21/02/17 01:38:38 INFO TaskSetManager: Finished task 0.0 in stage 25.0 (TID 25) in 4 ms on localhost (executor driver) (1/1)
21/02/17 01:38:38 INFO ContextCleaner: Cleaned accumulator 371
21/02/17 01:38:38 INFO ContextCleaner: Cleaned accumulator 422
21/02/17 01:38:38 INFO TaskSchedulerImpl: Removed TaskSet 25.0, whose tasks have all completed, from pool 
21/02/17 01:38:38 INFO ContextCleaner: Cleaned accumulator 711
21/02/17 01:38:38 INFO ContextCleaner: Cleaned accumulator 314
21/02/17 01:38:38 INFO ContextCleaner: Cleaned accumulator 443
21/02/17 01:38:38 INFO ContextCleaner: Cleaned accumulator 304
21/02/17 01:38:38 INFO ContextCleaner: Cleaned accumulator 391
21/02/17 01:38:38 INFO ContextCleaner: Cleaned accumulator 274
21/02/17 01:38:38 INFO ContextCleaner: Cleaned accumulator 327
21/02/17 01:38:38 INFO ContextCleaner: Cleaned accumulator 566
21/02/17 01:38:38 INFO DAGScheduler: ShuffleMapStage 25 (parquet at RFormula.scala:495) finished in 0.008 s
21/02/17 01:38:38 INFO DAGScheduler: looking for newly runnable stages
21/02/17 01:38:38 INFO DAGScheduler: running: Set()
21/02/17 01:38:38 INFO DAGScheduler: waiting: Set(ResultStage 26)
21/02/17 01:38:38 INFO DAGScheduler: failed: Set()
21/02/17 01:38:38 INFO BlockManagerInfo: Removed broadcast_21_piece0 on localhost:34941 in memory (size: 25.5 KB, free: 912.3 MB)
21/02/17 01:38:38 INFO DAGScheduler: Submitting ResultStage 26 (ShuffledRowRDD[87] at parquet at RFormula.scala:495), which has no missing parents
21/02/17 01:38:38 INFO ContextCleaner: Cleaned accumulator 541
21/02/17 01:38:38 INFO ContextCleaner: Cleaned accumulator 662
21/02/17 01:38:38 INFO ContextCleaner: Cleaned accumulator 370
21/02/17 01:38:38 INFO ContextCleaner: Cleaned accumulator 492
21/02/17 01:38:38 INFO ContextCleaner: Cleaned accumulator 514
21/02/17 01:38:38 INFO ContextCleaner: Cleaned accumulator 478
21/02/17 01:38:38 INFO ContextCleaner: Cleaned accumulator 628
21/02/17 01:38:38 INFO ContextCleaner: Cleaned accumulator 485
21/02/17 01:38:38 INFO ContextCleaner: Cleaned accumulator 713
21/02/17 01:38:38 INFO ContextCleaner: Cleaned accumulator 359
21/02/17 01:38:38 INFO BlockManagerInfo: Removed broadcast_14_piece0 on localhost:34941 in memory (size: 25.8 KB, free: 912.3 MB)
21/02/17 01:38:38 INFO ContextCleaner: Cleaned accumulator 618
21/02/17 01:38:38 INFO ContextCleaner: Cleaned accumulator 435
21/02/17 01:38:38 INFO ContextCleaner: Cleaned accumulator 447
21/02/17 01:38:38 INFO ContextCleaner: Cleaned accumulator 461
21/02/17 01:38:38 INFO ContextCleaner: Cleaned accumulator 620
21/02/17 01:38:38 INFO ContextCleaner: Cleaned accumulator 347
21/02/17 01:38:38 INFO ContextCleaner: Cleaned accumulator 430
21/02/17 01:38:38 INFO ContextCleaner: Cleaned accumulator 312
21/02/17 01:38:38 INFO ContextCleaner: Cleaned accumulator 373
21/02/17 01:38:38 INFO ContextCleaner: Cleaned accumulator 382
21/02/17 01:38:38 INFO ContextCleaner: Cleaned accumulator 657
21/02/17 01:38:38 INFO ContextCleaner: Cleaned accumulator 436
21/02/17 01:38:38 INFO ContextCleaner: Cleaned accumulator 626
21/02/17 01:38:38 INFO ContextCleaner: Cleaned accumulator 295
21/02/17 01:38:38 INFO ContextCleaner: Cleaned accumulator 372
21/02/17 01:38:38 INFO ContextCleaner: Cleaned accumulator 437
21/02/17 01:38:38 INFO ContextCleaner: Cleaned accumulator 522
21/02/17 01:38:38 INFO ContextCleaner: Cleaned accumulator 630
21/02/17 01:38:38 INFO ContextCleaner: Cleaned accumulator 683
21/02/17 01:38:38 INFO ContextCleaner: Cleaned accumulator 404
21/02/17 01:38:38 INFO ContextCleaner: Cleaned accumulator 664
21/02/17 01:38:38 INFO ContextCleaner: Cleaned accumulator 360
21/02/17 01:38:38 INFO ContextCleaner: Cleaned accumulator 605
21/02/17 01:38:38 INFO ContextCleaner: Cleaned accumulator 471
21/02/17 01:38:38 INFO ContextCleaner: Cleaned accumulator 631
21/02/17 01:38:38 INFO ContextCleaner: Cleaned accumulator 278
21/02/17 01:38:38 INFO ContextCleaner: Cleaned accumulator 290
21/02/17 01:38:38 INFO ContextCleaner: Cleaned accumulator 634
21/02/17 01:38:38 INFO MemoryStore: Block broadcast_27 stored as values in memory (estimated size 150.7 KB, free 912.1 MB)
21/02/17 01:38:38 INFO MemoryStore: Block broadcast_27_piece0 stored as bytes in memory (estimated size 53.4 KB, free 912.1 MB)
21/02/17 01:38:38 INFO BlockManagerInfo: Added broadcast_27_piece0 in memory on localhost:34941 (size: 53.4 KB, free: 912.2 MB)
21/02/17 01:38:38 INFO SparkContext: Created broadcast 27 from broadcast at DAGScheduler.scala:1039
21/02/17 01:38:38 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 26 (ShuffledRowRDD[87] at parquet at RFormula.scala:495) (first 15 tasks are for partitions Vector(0))
21/02/17 01:38:38 INFO TaskSchedulerImpl: Adding task set 26.0 with 1 tasks
21/02/17 01:38:38 INFO TaskSetManager: Starting task 0.0 in stage 26.0 (TID 26, localhost, executor driver, partition 0, NODE_LOCAL, 7754 bytes)
21/02/17 01:38:38 INFO Executor: Running task 0.0 in stage 26.0 (TID 26)
21/02/17 01:38:38 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
21/02/17 01:38:38 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
21/02/17 01:38:38 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
21/02/17 01:38:38 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
21/02/17 01:38:38 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
21/02/17 01:38:38 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
21/02/17 01:38:38 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:
{
  "type" : "struct",
  "fields" : [ {
    "name" : "columnsToPrune",
    "type" : {
      "type" : "array",
      "elementType" : "string",
      "containsNull" : true
    },
    "nullable" : true,
    "metadata" : { }
  } ]
}
and corresponding Parquet message type:
message spark_schema {
  optional group columnsToPrune (LIST) {
    repeated group list {
      optional binary element (UTF8);
    }
  }
}

       
21/02/17 01:38:38 INFO FileOutputCommitter: Saved output of task 'attempt_20210217013838_0026_m_000000_0' to file:/tmp/RtmpS1B6G2/file229295a853f48/stages/0_r_formula__1f0c17e2_5e1f_4747_b5f7_cf8564b20278/pipelineModel/stages/2_columnPruner_d6a8a49ad94b/data/_temporary/0/task_20210217013838_0026_m_000000
21/02/17 01:38:38 INFO SparkHadoopMapRedUtil: attempt_20210217013838_0026_m_000000_0: Committed
21/02/17 01:38:38 INFO Executor: Finished task 0.0 in stage 26.0 (TID 26). 2308 bytes result sent to driver
21/02/17 01:38:38 INFO TaskSetManager: Finished task 0.0 in stage 26.0 (TID 26) in 19 ms on localhost (executor driver) (1/1)
21/02/17 01:38:38 INFO TaskSchedulerImpl: Removed TaskSet 26.0, whose tasks have all completed, from pool 
21/02/17 01:38:38 INFO DAGScheduler: ResultStage 26 (parquet at RFormula.scala:495) finished in 0.035 s
21/02/17 01:38:38 INFO DAGScheduler: Job 19 finished: parquet at RFormula.scala:495, took 0.045487 s
21/02/17 01:38:38 INFO FileFormatWriter: Job null committed.
21/02/17 01:38:38 INFO FileFormatWriter: Finished processing stats for job null.
21/02/17 01:38:40 INFO SparkContext: Invoking stop() from shutdown hook
21/02/17 01:38:40 INFO SparkUI: Stopped Spark web UI at http://localhost:4040
21/02/17 01:38:40 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!
21/02/17 01:38:40 INFO MemoryStore: MemoryStore cleared
21/02/17 01:38:40 INFO BlockManager: BlockManager stopped
21/02/17 01:38:40 INFO BlockManagerMaster: BlockManagerMaster stopped
21/02/17 01:38:40 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!
21/02/17 01:38:40 INFO SparkContext: Successfully stopped SparkContext
21/02/17 01:38:40 INFO ShutdownHookManager: Shutdown hook called
21/02/17 01:38:40 INFO ShutdownHookManager: Deleting directory /tmp/spark-9a6ef888-e297-46da-82e5-aa4d88317b66
21/02/17 01:38:40 INFO ShutdownHookManager: Deleting directory /tmp/spark-9437c1c4-850b-4802-ba59-5f700fa4fd01
21/02/17 01:39:30 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
21/02/17 01:39:31 INFO SparkContext: Running Spark version 2.4.4
21/02/17 01:39:31 INFO SparkContext: Submitted application: sparklyr
21/02/17 01:39:31 INFO SecurityManager: Changing view acls to: yitaoli
21/02/17 01:39:31 INFO SecurityManager: Changing modify acls to: yitaoli
21/02/17 01:39:31 INFO SecurityManager: Changing view acls groups to: 
21/02/17 01:39:31 INFO SecurityManager: Changing modify acls groups to: 
21/02/17 01:39:31 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(yitaoli); groups with view permissions: Set(); users  with modify permissions: Set(yitaoli); groups with modify permissions: Set()
21/02/17 01:39:31 INFO Utils: Successfully started service 'sparkDriver' on port 39031.
21/02/17 01:39:31 INFO SparkEnv: Registering MapOutputTracker
21/02/17 01:39:31 INFO SparkEnv: Registering BlockManagerMaster
21/02/17 01:39:31 INFO BlockManagerMasterEndpoint: Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
21/02/17 01:39:31 INFO BlockManagerMasterEndpoint: BlockManagerMasterEndpoint up
21/02/17 01:39:31 INFO DiskBlockManager: Created local directory at /tmp/blockmgr-b3782bd9-fe7d-4188-abd6-0b7b2018e7c4
21/02/17 01:39:31 INFO MemoryStore: MemoryStore started with capacity 912.3 MB
21/02/17 01:39:31 INFO SparkEnv: Registering OutputCommitCoordinator
21/02/17 01:39:31 INFO Utils: Successfully started service 'SparkUI' on port 4040.
21/02/17 01:39:31 INFO SparkUI: Bound SparkUI to 127.0.0.1, and started at http://localhost:4040
21/02/17 01:39:31 INFO SparkContext: Added JAR file:///home/yitaoli/R/x86_64-pc-linux-gnu-library/4.0/sparkxgb/java/sparkxgb-2.3-2.11.jar at spark://localhost:39031/jars/sparkxgb-2.3-2.11.jar with timestamp 1613525971778
21/02/17 01:39:31 INFO SparkContext: Added JAR file:///home/yitaoli/.ivy2/jars/ml.dmlc_xgboost4j-spark_2.11-1.1.2.jar at spark://localhost:39031/jars/ml.dmlc_xgboost4j-spark_2.11-1.1.2.jar with timestamp 1613525971779
21/02/17 01:39:31 INFO SparkContext: Added JAR file:///home/yitaoli/.ivy2/jars/org.json4s_json4s-jackson_2.11-3.2.11.jar at spark://localhost:39031/jars/org.json4s_json4s-jackson_2.11-3.2.11.jar with timestamp 1613525971779
21/02/17 01:39:31 INFO SparkContext: Added JAR file:///home/yitaoli/.ivy2/jars/ml.dmlc_xgboost4j_2.11-1.1.2.jar at spark://localhost:39031/jars/ml.dmlc_xgboost4j_2.11-1.1.2.jar with timestamp 1613525971780
21/02/17 01:39:31 INFO SparkContext: Added JAR file:///home/yitaoli/.ivy2/jars/com.esotericsoftware.kryo_kryo-2.22.jar at spark://localhost:39031/jars/com.esotericsoftware.kryo_kryo-2.22.jar with timestamp 1613525971780
21/02/17 01:39:31 INFO SparkContext: Added JAR file:///home/yitaoli/.ivy2/jars/org.scala-lang_scala-compiler-2.11.12.jar at spark://localhost:39031/jars/org.scala-lang_scala-compiler-2.11.12.jar with timestamp 1613525971780
21/02/17 01:39:31 INFO SparkContext: Added JAR file:///home/yitaoli/.ivy2/jars/org.scala-lang_scala-reflect-2.11.12.jar at spark://localhost:39031/jars/org.scala-lang_scala-reflect-2.11.12.jar with timestamp 1613525971780
21/02/17 01:39:31 INFO SparkContext: Added JAR file:///home/yitaoli/.ivy2/jars/commons-logging_commons-logging-1.2.jar at spark://localhost:39031/jars/commons-logging_commons-logging-1.2.jar with timestamp 1613525971780
21/02/17 01:39:31 INFO SparkContext: Added JAR file:///home/yitaoli/.ivy2/jars/com.typesafe.akka_akka-actor_2.11-2.5.23.jar at spark://localhost:39031/jars/com.typesafe.akka_akka-actor_2.11-2.5.23.jar with timestamp 1613525971780
21/02/17 01:39:31 INFO SparkContext: Added JAR file:///home/yitaoli/.ivy2/jars/com.typesafe_config-1.3.3.jar at spark://localhost:39031/jars/com.typesafe_config-1.3.3.jar with timestamp 1613525971780
21/02/17 01:39:31 INFO SparkContext: Added JAR file:///home/yitaoli/.ivy2/jars/org.scala-lang.modules_scala-java8-compat_2.11-0.7.0.jar at spark://localhost:39031/jars/org.scala-lang.modules_scala-java8-compat_2.11-0.7.0.jar with timestamp 1613525971780
21/02/17 01:39:31 INFO SparkContext: Added JAR file:///home/yitaoli/.ivy2/jars/org.scala-lang.modules_scala-xml_2.11-1.0.5.jar at spark://localhost:39031/jars/org.scala-lang.modules_scala-xml_2.11-1.0.5.jar with timestamp 1613525971781
21/02/17 01:39:31 INFO SparkContext: Added JAR file:///home/yitaoli/.ivy2/jars/org.scala-lang.modules_scala-parser-combinators_2.11-1.0.4.jar at spark://localhost:39031/jars/org.scala-lang.modules_scala-parser-combinators_2.11-1.0.4.jar with timestamp 1613525971781
21/02/17 01:39:31 INFO SparkContext: Added JAR file:///home/yitaoli/.ivy2/jars/org.json4s_json4s-core_2.11-3.2.11.jar at spark://localhost:39031/jars/org.json4s_json4s-core_2.11-3.2.11.jar with timestamp 1613525971781
21/02/17 01:39:31 INFO SparkContext: Added JAR file:///home/yitaoli/.ivy2/jars/com.fasterxml.jackson.core_jackson-databind-2.3.1.jar at spark://localhost:39031/jars/com.fasterxml.jackson.core_jackson-databind-2.3.1.jar with timestamp 1613525971781
21/02/17 01:39:31 INFO SparkContext: Added JAR file:///home/yitaoli/.ivy2/jars/org.json4s_json4s-ast_2.11-3.2.11.jar at spark://localhost:39031/jars/org.json4s_json4s-ast_2.11-3.2.11.jar with timestamp 1613525971781
21/02/17 01:39:31 INFO SparkContext: Added JAR file:///home/yitaoli/.ivy2/jars/com.thoughtworks.paranamer_paranamer-2.6.jar at spark://localhost:39031/jars/com.thoughtworks.paranamer_paranamer-2.6.jar with timestamp 1613525971781
21/02/17 01:39:31 INFO SparkContext: Added JAR file:///home/yitaoli/.ivy2/jars/org.scala-lang_scalap-2.11.0.jar at spark://localhost:39031/jars/org.scala-lang_scalap-2.11.0.jar with timestamp 1613525971781
21/02/17 01:39:31 INFO SparkContext: Added JAR file:///home/yitaoli/.ivy2/jars/com.fasterxml.jackson.core_jackson-annotations-2.3.0.jar at spark://localhost:39031/jars/com.fasterxml.jackson.core_jackson-annotations-2.3.0.jar with timestamp 1613525971781
21/02/17 01:39:31 INFO SparkContext: Added JAR file:///home/yitaoli/.ivy2/jars/com.fasterxml.jackson.core_jackson-core-2.3.1.jar at spark://localhost:39031/jars/com.fasterxml.jackson.core_jackson-core-2.3.1.jar with timestamp 1613525971781
21/02/17 01:39:31 INFO SparkContext: Added JAR file:/home/yitaoli/R/x86_64-pc-linux-gnu-library/4.0/sparklyr/java/sparklyr-2.4-2.11.jar at spark://localhost:39031/jars/sparklyr-2.4-2.11.jar with timestamp 1613525971781
21/02/17 01:39:31 INFO Executor: Starting executor ID driver on host localhost
21/02/17 01:39:31 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 37301.
21/02/17 01:39:31 INFO NettyBlockTransferService: Server created on localhost:37301
21/02/17 01:39:31 INFO BlockManager: Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
21/02/17 01:39:31 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, localhost, 37301, None)
21/02/17 01:39:31 INFO BlockManagerMasterEndpoint: Registering block manager localhost:37301 with 912.3 MB RAM, BlockManagerId(driver, localhost, 37301, None)
21/02/17 01:39:31 INFO BlockManagerMaster: Registered BlockManager BlockManagerId(driver, localhost, 37301, None)
21/02/17 01:39:31 INFO BlockManager: Initialized BlockManager: BlockManagerId(driver, localhost, 37301, None)
21/02/17 01:39:32 INFO SharedState: loading hive config file: file:/home/yitaoli/spark/spark-2.4.4-bin-hadoop2.7/conf/hive-site.xml
21/02/17 01:39:32 INFO SharedState: Setting hive.metastore.warehouse.dir ('null') to the value of spark.sql.warehouse.dir ('file:/home/yitaoli/sparkxgb/tests/testthat/spark-warehouse').
21/02/17 01:39:32 INFO SharedState: Warehouse path is 'file:/home/yitaoli/sparkxgb/tests/testthat/spark-warehouse'.
21/02/17 01:39:32 INFO StateStoreCoordinatorRef: Registered StateStoreCoordinator endpoint
21/02/17 01:39:34 INFO HiveUtils: Initializing HiveMetastoreConnection version 1.2.1 using Spark classes.
21/02/17 01:39:34 INFO HiveMetaStore: 0: Opening raw store with implemenation class:org.apache.hadoop.hive.metastore.ObjectStore
21/02/17 01:39:34 INFO ObjectStore: ObjectStore, initialize called
21/02/17 01:39:34 INFO Persistence: Property hive.metastore.integral.jdo.pushdown unknown - will be ignored
21/02/17 01:39:34 INFO Persistence: Property datanucleus.cache.level2 unknown - will be ignored
21/02/17 01:39:35 INFO ObjectStore: Setting MetaStore object pin classes with hive.metastore.cache.pinobjtypes="Table,StorageDescriptor,SerDeInfo,Partition,Database,Type,FieldSchema,Order"
21/02/17 01:39:36 INFO Datastore: The class "org.apache.hadoop.hive.metastore.model.MFieldSchema" is tagged as "embedded-only" so does not have its own datastore table.
21/02/17 01:39:36 INFO Datastore: The class "org.apache.hadoop.hive.metastore.model.MOrder" is tagged as "embedded-only" so does not have its own datastore table.
21/02/17 01:39:36 INFO Datastore: The class "org.apache.hadoop.hive.metastore.model.MFieldSchema" is tagged as "embedded-only" so does not have its own datastore table.
21/02/17 01:39:36 INFO Datastore: The class "org.apache.hadoop.hive.metastore.model.MOrder" is tagged as "embedded-only" so does not have its own datastore table.
21/02/17 01:39:36 INFO MetaStoreDirectSql: Using direct SQL, underlying DB is DERBY
21/02/17 01:39:36 INFO ObjectStore: Initialized ObjectStore
21/02/17 01:39:37 WARN ObjectStore: Version information not found in metastore. hive.metastore.schema.verification is not enabled so recording the schema version 1.2.0
21/02/17 01:39:37 WARN ObjectStore: Failed to get database default, returning NoSuchObjectException
21/02/17 01:39:37 INFO HiveMetaStore: Added admin role in metastore
21/02/17 01:39:37 INFO HiveMetaStore: Added public role in metastore
21/02/17 01:39:37 INFO HiveMetaStore: No user is added in admin role, since config is empty
21/02/17 01:39:37 INFO HiveMetaStore: 0: get_all_databases
21/02/17 01:39:37 INFO audit: ugi=yitaoli	ip=unknown-ip-addr	cmd=get_all_databases	
21/02/17 01:39:37 INFO HiveMetaStore: 0: get_functions: db=default pat=*
21/02/17 01:39:37 INFO audit: ugi=yitaoli	ip=unknown-ip-addr	cmd=get_functions: db=default pat=*	
21/02/17 01:39:37 INFO Datastore: The class "org.apache.hadoop.hive.metastore.model.MResourceUri" is tagged as "embedded-only" so does not have its own datastore table.
21/02/17 01:39:37 INFO SessionState: Created local directory: /tmp/169027bc-6c8a-4897-b0e4-61bdb78dccb0_resources
21/02/17 01:39:37 INFO SessionState: Created HDFS directory: /tmp/hive/yitaoli/169027bc-6c8a-4897-b0e4-61bdb78dccb0
21/02/17 01:39:37 INFO SessionState: Created local directory: /tmp/yitaoli/169027bc-6c8a-4897-b0e4-61bdb78dccb0
21/02/17 01:39:37 INFO SessionState: Created HDFS directory: /tmp/hive/yitaoli/169027bc-6c8a-4897-b0e4-61bdb78dccb0/_tmp_space.db
21/02/17 01:39:37 INFO HiveClientImpl: Warehouse location for Hive client (version 1.2.2) is file:/home/yitaoli/sparkxgb/tests/testthat/spark-warehouse
21/02/17 01:39:37 INFO HiveMetaStore: 0: get_database: default
21/02/17 01:39:37 INFO audit: ugi=yitaoli	ip=unknown-ip-addr	cmd=get_database: default	
21/02/17 01:39:37 INFO HiveMetaStore: 0: get_database: global_temp
21/02/17 01:39:37 INFO audit: ugi=yitaoli	ip=unknown-ip-addr	cmd=get_database: global_temp	
21/02/17 01:39:37 WARN ObjectStore: Failed to get database global_temp, returning NoSuchObjectException
21/02/17 01:39:37 INFO HiveMetaStore: 0: get_table : db=default tbl=iris
21/02/17 01:39:37 INFO audit: ugi=yitaoli	ip=unknown-ip-addr	cmd=get_table : db=default tbl=iris	
21/02/17 01:39:37 INFO HiveMetaStore: 0: get_database: default
21/02/17 01:39:37 INFO audit: ugi=yitaoli	ip=unknown-ip-addr	cmd=get_database: default	
21/02/17 01:39:37 INFO HiveMetaStore: 0: get_database: default
21/02/17 01:39:37 INFO audit: ugi=yitaoli	ip=unknown-ip-addr	cmd=get_database: default	
21/02/17 01:39:37 INFO HiveMetaStore: 0: get_tables: db=default pat=*
21/02/17 01:39:37 INFO audit: ugi=yitaoli	ip=unknown-ip-addr	cmd=get_tables: db=default pat=*	
21/02/17 01:39:38 INFO SparkContext: Starting job: collect at utils.scala:61
21/02/17 01:39:38 INFO DAGScheduler: Got job 0 (collect at utils.scala:61) with 1 output partitions
21/02/17 01:39:38 INFO DAGScheduler: Final stage: ResultStage 0 (collect at utils.scala:61)
21/02/17 01:39:38 INFO DAGScheduler: Parents of final stage: List()
21/02/17 01:39:38 INFO DAGScheduler: Missing parents: List()
21/02/17 01:39:38 INFO DAGScheduler: Submitting ResultStage 0 (MapPartitionsRDD[4] at map at utils.scala:54), which has no missing parents
21/02/17 01:39:38 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 6.0 KB, free 912.3 MB)
21/02/17 01:39:38 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 3.4 KB, free 912.3 MB)
21/02/17 01:39:38 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on localhost:37301 (size: 3.4 KB, free: 912.3 MB)
21/02/17 01:39:38 INFO SparkContext: Created broadcast 0 from broadcast at DAGScheduler.scala:1161
21/02/17 01:39:38 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 0 (MapPartitionsRDD[4] at map at utils.scala:54) (first 15 tasks are for partitions Vector(0))
21/02/17 01:39:38 INFO TaskSchedulerImpl: Adding task set 0.0 with 1 tasks
21/02/17 01:39:38 INFO TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0, localhost, executor driver, partition 0, PROCESS_LOCAL, 7893 bytes)
21/02/17 01:39:38 INFO Executor: Running task 0.0 in stage 0.0 (TID 0)
21/02/17 01:39:38 INFO Executor: Fetching spark://localhost:39031/jars/commons-logging_commons-logging-1.2.jar with timestamp 1613525971780
21/02/17 01:39:38 INFO TransportClientFactory: Successfully created connection to localhost/127.0.0.1:39031 after 14 ms (0 ms spent in bootstraps)
21/02/17 01:39:38 INFO Utils: Fetching spark://localhost:39031/jars/commons-logging_commons-logging-1.2.jar to /tmp/spark-8bf7e157-a23d-4374-ba4f-5e728582deb6/userFiles-e41e0857-d346-4267-9b2a-25c1bf9df1c1/fetchFileTemp2202388702452611195.tmp
21/02/17 01:39:38 INFO Executor: Adding file:/tmp/spark-8bf7e157-a23d-4374-ba4f-5e728582deb6/userFiles-e41e0857-d346-4267-9b2a-25c1bf9df1c1/commons-logging_commons-logging-1.2.jar to class loader
21/02/17 01:39:38 INFO Executor: Fetching spark://localhost:39031/jars/org.json4s_json4s-jackson_2.11-3.2.11.jar with timestamp 1613525971779
21/02/17 01:39:38 INFO Utils: Fetching spark://localhost:39031/jars/org.json4s_json4s-jackson_2.11-3.2.11.jar to /tmp/spark-8bf7e157-a23d-4374-ba4f-5e728582deb6/userFiles-e41e0857-d346-4267-9b2a-25c1bf9df1c1/fetchFileTemp8973409328248653817.tmp
21/02/17 01:39:38 INFO Executor: Adding file:/tmp/spark-8bf7e157-a23d-4374-ba4f-5e728582deb6/userFiles-e41e0857-d346-4267-9b2a-25c1bf9df1c1/org.json4s_json4s-jackson_2.11-3.2.11.jar to class loader
21/02/17 01:39:38 INFO Executor: Fetching spark://localhost:39031/jars/org.scala-lang.modules_scala-java8-compat_2.11-0.7.0.jar with timestamp 1613525971780
21/02/17 01:39:38 INFO Utils: Fetching spark://localhost:39031/jars/org.scala-lang.modules_scala-java8-compat_2.11-0.7.0.jar to /tmp/spark-8bf7e157-a23d-4374-ba4f-5e728582deb6/userFiles-e41e0857-d346-4267-9b2a-25c1bf9df1c1/fetchFileTemp7283178817738826231.tmp
21/02/17 01:39:38 INFO Executor: Adding file:/tmp/spark-8bf7e157-a23d-4374-ba4f-5e728582deb6/userFiles-e41e0857-d346-4267-9b2a-25c1bf9df1c1/org.scala-lang.modules_scala-java8-compat_2.11-0.7.0.jar to class loader
21/02/17 01:39:38 INFO Executor: Fetching spark://localhost:39031/jars/org.scala-lang.modules_scala-xml_2.11-1.0.5.jar with timestamp 1613525971781
21/02/17 01:39:38 INFO Utils: Fetching spark://localhost:39031/jars/org.scala-lang.modules_scala-xml_2.11-1.0.5.jar to /tmp/spark-8bf7e157-a23d-4374-ba4f-5e728582deb6/userFiles-e41e0857-d346-4267-9b2a-25c1bf9df1c1/fetchFileTemp5274299761556297043.tmp
21/02/17 01:39:38 INFO Executor: Adding file:/tmp/spark-8bf7e157-a23d-4374-ba4f-5e728582deb6/userFiles-e41e0857-d346-4267-9b2a-25c1bf9df1c1/org.scala-lang.modules_scala-xml_2.11-1.0.5.jar to class loader
21/02/17 01:39:38 INFO Executor: Fetching spark://localhost:39031/jars/ml.dmlc_xgboost4j-spark_2.11-1.1.2.jar with timestamp 1613525971779
21/02/17 01:39:38 INFO Utils: Fetching spark://localhost:39031/jars/ml.dmlc_xgboost4j-spark_2.11-1.1.2.jar to /tmp/spark-8bf7e157-a23d-4374-ba4f-5e728582deb6/userFiles-e41e0857-d346-4267-9b2a-25c1bf9df1c1/fetchFileTemp6204462119677359677.tmp
21/02/17 01:39:38 INFO Executor: Adding file:/tmp/spark-8bf7e157-a23d-4374-ba4f-5e728582deb6/userFiles-e41e0857-d346-4267-9b2a-25c1bf9df1c1/ml.dmlc_xgboost4j-spark_2.11-1.1.2.jar to class loader
21/02/17 01:39:38 INFO Executor: Fetching spark://localhost:39031/jars/com.fasterxml.jackson.core_jackson-annotations-2.3.0.jar with timestamp 1613525971781
21/02/17 01:39:38 INFO Utils: Fetching spark://localhost:39031/jars/com.fasterxml.jackson.core_jackson-annotations-2.3.0.jar to /tmp/spark-8bf7e157-a23d-4374-ba4f-5e728582deb6/userFiles-e41e0857-d346-4267-9b2a-25c1bf9df1c1/fetchFileTemp6302770634838530894.tmp
21/02/17 01:39:38 INFO Executor: Adding file:/tmp/spark-8bf7e157-a23d-4374-ba4f-5e728582deb6/userFiles-e41e0857-d346-4267-9b2a-25c1bf9df1c1/com.fasterxml.jackson.core_jackson-annotations-2.3.0.jar to class loader
21/02/17 01:39:38 INFO Executor: Fetching spark://localhost:39031/jars/com.fasterxml.jackson.core_jackson-core-2.3.1.jar with timestamp 1613525971781
21/02/17 01:39:38 INFO Utils: Fetching spark://localhost:39031/jars/com.fasterxml.jackson.core_jackson-core-2.3.1.jar to /tmp/spark-8bf7e157-a23d-4374-ba4f-5e728582deb6/userFiles-e41e0857-d346-4267-9b2a-25c1bf9df1c1/fetchFileTemp8846845385176689777.tmp
21/02/17 01:39:38 INFO Executor: Adding file:/tmp/spark-8bf7e157-a23d-4374-ba4f-5e728582deb6/userFiles-e41e0857-d346-4267-9b2a-25c1bf9df1c1/com.fasterxml.jackson.core_jackson-core-2.3.1.jar to class loader
21/02/17 01:39:38 INFO Executor: Fetching spark://localhost:39031/jars/com.thoughtworks.paranamer_paranamer-2.6.jar with timestamp 1613525971781
21/02/17 01:39:38 INFO Utils: Fetching spark://localhost:39031/jars/com.thoughtworks.paranamer_paranamer-2.6.jar to /tmp/spark-8bf7e157-a23d-4374-ba4f-5e728582deb6/userFiles-e41e0857-d346-4267-9b2a-25c1bf9df1c1/fetchFileTemp2514217765172840632.tmp
21/02/17 01:39:38 INFO Executor: Adding file:/tmp/spark-8bf7e157-a23d-4374-ba4f-5e728582deb6/userFiles-e41e0857-d346-4267-9b2a-25c1bf9df1c1/com.thoughtworks.paranamer_paranamer-2.6.jar to class loader
21/02/17 01:39:38 INFO Executor: Fetching spark://localhost:39031/jars/com.typesafe.akka_akka-actor_2.11-2.5.23.jar with timestamp 1613525971780
21/02/17 01:39:38 INFO Utils: Fetching spark://localhost:39031/jars/com.typesafe.akka_akka-actor_2.11-2.5.23.jar to /tmp/spark-8bf7e157-a23d-4374-ba4f-5e728582deb6/userFiles-e41e0857-d346-4267-9b2a-25c1bf9df1c1/fetchFileTemp8982510864147251464.tmp
21/02/17 01:39:38 INFO Executor: Adding file:/tmp/spark-8bf7e157-a23d-4374-ba4f-5e728582deb6/userFiles-e41e0857-d346-4267-9b2a-25c1bf9df1c1/com.typesafe.akka_akka-actor_2.11-2.5.23.jar to class loader
21/02/17 01:39:38 INFO Executor: Fetching spark://localhost:39031/jars/ml.dmlc_xgboost4j_2.11-1.1.2.jar with timestamp 1613525971780
21/02/17 01:39:38 INFO Utils: Fetching spark://localhost:39031/jars/ml.dmlc_xgboost4j_2.11-1.1.2.jar to /tmp/spark-8bf7e157-a23d-4374-ba4f-5e728582deb6/userFiles-e41e0857-d346-4267-9b2a-25c1bf9df1c1/fetchFileTemp8901160606738998803.tmp
21/02/17 01:39:38 INFO Executor: Adding file:/tmp/spark-8bf7e157-a23d-4374-ba4f-5e728582deb6/userFiles-e41e0857-d346-4267-9b2a-25c1bf9df1c1/ml.dmlc_xgboost4j_2.11-1.1.2.jar to class loader
21/02/17 01:39:38 INFO Executor: Fetching spark://localhost:39031/jars/org.scala-lang_scala-compiler-2.11.12.jar with timestamp 1613525971780
21/02/17 01:39:38 INFO Utils: Fetching spark://localhost:39031/jars/org.scala-lang_scala-compiler-2.11.12.jar to /tmp/spark-8bf7e157-a23d-4374-ba4f-5e728582deb6/userFiles-e41e0857-d346-4267-9b2a-25c1bf9df1c1/fetchFileTemp2769770758258683911.tmp
21/02/17 01:39:38 INFO Executor: Adding file:/tmp/spark-8bf7e157-a23d-4374-ba4f-5e728582deb6/userFiles-e41e0857-d346-4267-9b2a-25c1bf9df1c1/org.scala-lang_scala-compiler-2.11.12.jar to class loader
21/02/17 01:39:38 INFO Executor: Fetching spark://localhost:39031/jars/com.typesafe_config-1.3.3.jar with timestamp 1613525971780
21/02/17 01:39:38 INFO Utils: Fetching spark://localhost:39031/jars/com.typesafe_config-1.3.3.jar to /tmp/spark-8bf7e157-a23d-4374-ba4f-5e728582deb6/userFiles-e41e0857-d346-4267-9b2a-25c1bf9df1c1/fetchFileTemp4758726588270828533.tmp
21/02/17 01:39:38 INFO Executor: Adding file:/tmp/spark-8bf7e157-a23d-4374-ba4f-5e728582deb6/userFiles-e41e0857-d346-4267-9b2a-25c1bf9df1c1/com.typesafe_config-1.3.3.jar to class loader
21/02/17 01:39:38 INFO Executor: Fetching spark://localhost:39031/jars/com.esotericsoftware.kryo_kryo-2.22.jar with timestamp 1613525971780
21/02/17 01:39:38 INFO Utils: Fetching spark://localhost:39031/jars/com.esotericsoftware.kryo_kryo-2.22.jar to /tmp/spark-8bf7e157-a23d-4374-ba4f-5e728582deb6/userFiles-e41e0857-d346-4267-9b2a-25c1bf9df1c1/fetchFileTemp1289193347304317849.tmp
21/02/17 01:39:38 INFO Executor: Adding file:/tmp/spark-8bf7e157-a23d-4374-ba4f-5e728582deb6/userFiles-e41e0857-d346-4267-9b2a-25c1bf9df1c1/com.esotericsoftware.kryo_kryo-2.22.jar to class loader
21/02/17 01:39:38 INFO Executor: Fetching spark://localhost:39031/jars/org.scala-lang.modules_scala-parser-combinators_2.11-1.0.4.jar with timestamp 1613525971781
21/02/17 01:39:38 INFO Utils: Fetching spark://localhost:39031/jars/org.scala-lang.modules_scala-parser-combinators_2.11-1.0.4.jar to /tmp/spark-8bf7e157-a23d-4374-ba4f-5e728582deb6/userFiles-e41e0857-d346-4267-9b2a-25c1bf9df1c1/fetchFileTemp2747622528518190971.tmp
21/02/17 01:39:38 INFO Executor: Adding file:/tmp/spark-8bf7e157-a23d-4374-ba4f-5e728582deb6/userFiles-e41e0857-d346-4267-9b2a-25c1bf9df1c1/org.scala-lang.modules_scala-parser-combinators_2.11-1.0.4.jar to class loader
21/02/17 01:39:38 INFO Executor: Fetching spark://localhost:39031/jars/sparkxgb-2.3-2.11.jar with timestamp 1613525971778
21/02/17 01:39:38 INFO Utils: Fetching spark://localhost:39031/jars/sparkxgb-2.3-2.11.jar to /tmp/spark-8bf7e157-a23d-4374-ba4f-5e728582deb6/userFiles-e41e0857-d346-4267-9b2a-25c1bf9df1c1/fetchFileTemp6943396513009742362.tmp
21/02/17 01:39:38 INFO Executor: Adding file:/tmp/spark-8bf7e157-a23d-4374-ba4f-5e728582deb6/userFiles-e41e0857-d346-4267-9b2a-25c1bf9df1c1/sparkxgb-2.3-2.11.jar to class loader
21/02/17 01:39:38 INFO Executor: Fetching spark://localhost:39031/jars/sparklyr-2.4-2.11.jar with timestamp 1613525971781
21/02/17 01:39:38 INFO Utils: Fetching spark://localhost:39031/jars/sparklyr-2.4-2.11.jar to /tmp/spark-8bf7e157-a23d-4374-ba4f-5e728582deb6/userFiles-e41e0857-d346-4267-9b2a-25c1bf9df1c1/fetchFileTemp1775344543968317578.tmp
21/02/17 01:39:38 INFO Executor: Adding file:/tmp/spark-8bf7e157-a23d-4374-ba4f-5e728582deb6/userFiles-e41e0857-d346-4267-9b2a-25c1bf9df1c1/sparklyr-2.4-2.11.jar to class loader
21/02/17 01:39:38 INFO Executor: Fetching spark://localhost:39031/jars/org.json4s_json4s-core_2.11-3.2.11.jar with timestamp 1613525971781
21/02/17 01:39:38 INFO Utils: Fetching spark://localhost:39031/jars/org.json4s_json4s-core_2.11-3.2.11.jar to /tmp/spark-8bf7e157-a23d-4374-ba4f-5e728582deb6/userFiles-e41e0857-d346-4267-9b2a-25c1bf9df1c1/fetchFileTemp7760019171304206485.tmp
21/02/17 01:39:38 INFO Executor: Adding file:/tmp/spark-8bf7e157-a23d-4374-ba4f-5e728582deb6/userFiles-e41e0857-d346-4267-9b2a-25c1bf9df1c1/org.json4s_json4s-core_2.11-3.2.11.jar to class loader
21/02/17 01:39:38 INFO Executor: Fetching spark://localhost:39031/jars/org.json4s_json4s-ast_2.11-3.2.11.jar with timestamp 1613525971781
21/02/17 01:39:38 INFO Utils: Fetching spark://localhost:39031/jars/org.json4s_json4s-ast_2.11-3.2.11.jar to /tmp/spark-8bf7e157-a23d-4374-ba4f-5e728582deb6/userFiles-e41e0857-d346-4267-9b2a-25c1bf9df1c1/fetchFileTemp8242873445223748051.tmp
21/02/17 01:39:38 INFO Executor: Adding file:/tmp/spark-8bf7e157-a23d-4374-ba4f-5e728582deb6/userFiles-e41e0857-d346-4267-9b2a-25c1bf9df1c1/org.json4s_json4s-ast_2.11-3.2.11.jar to class loader
21/02/17 01:39:38 INFO Executor: Fetching spark://localhost:39031/jars/org.scala-lang_scalap-2.11.0.jar with timestamp 1613525971781
21/02/17 01:39:38 INFO Utils: Fetching spark://localhost:39031/jars/org.scala-lang_scalap-2.11.0.jar to /tmp/spark-8bf7e157-a23d-4374-ba4f-5e728582deb6/userFiles-e41e0857-d346-4267-9b2a-25c1bf9df1c1/fetchFileTemp2735168828741696844.tmp
21/02/17 01:39:38 INFO Executor: Adding file:/tmp/spark-8bf7e157-a23d-4374-ba4f-5e728582deb6/userFiles-e41e0857-d346-4267-9b2a-25c1bf9df1c1/org.scala-lang_scalap-2.11.0.jar to class loader
21/02/17 01:39:38 INFO Executor: Fetching spark://localhost:39031/jars/org.scala-lang_scala-reflect-2.11.12.jar with timestamp 1613525971780
21/02/17 01:39:38 INFO Utils: Fetching spark://localhost:39031/jars/org.scala-lang_scala-reflect-2.11.12.jar to /tmp/spark-8bf7e157-a23d-4374-ba4f-5e728582deb6/userFiles-e41e0857-d346-4267-9b2a-25c1bf9df1c1/fetchFileTemp5480140995288639033.tmp
21/02/17 01:39:38 INFO Executor: Adding file:/tmp/spark-8bf7e157-a23d-4374-ba4f-5e728582deb6/userFiles-e41e0857-d346-4267-9b2a-25c1bf9df1c1/org.scala-lang_scala-reflect-2.11.12.jar to class loader
21/02/17 01:39:38 INFO Executor: Fetching spark://localhost:39031/jars/com.fasterxml.jackson.core_jackson-databind-2.3.1.jar with timestamp 1613525971781
21/02/17 01:39:38 INFO Utils: Fetching spark://localhost:39031/jars/com.fasterxml.jackson.core_jackson-databind-2.3.1.jar to /tmp/spark-8bf7e157-a23d-4374-ba4f-5e728582deb6/userFiles-e41e0857-d346-4267-9b2a-25c1bf9df1c1/fetchFileTemp1139013983302833690.tmp
21/02/17 01:39:38 INFO Executor: Adding file:/tmp/spark-8bf7e157-a23d-4374-ba4f-5e728582deb6/userFiles-e41e0857-d346-4267-9b2a-25c1bf9df1c1/com.fasterxml.jackson.core_jackson-databind-2.3.1.jar to class loader
21/02/17 01:39:38 INFO CodeGenerator: Code generated in 140.97277 ms
21/02/17 01:39:38 INFO Executor: Finished task 0.0 in stage 0.0 (TID 0). 1013 bytes result sent to driver
21/02/17 01:39:38 INFO TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in 565 ms on localhost (executor driver) (1/1)
21/02/17 01:39:38 INFO TaskSchedulerImpl: Removed TaskSet 0.0, whose tasks have all completed, from pool 
21/02/17 01:39:38 INFO DAGScheduler: ResultStage 0 (collect at utils.scala:61) finished in 0.675 s
21/02/17 01:39:38 INFO DAGScheduler: Job 0 finished: collect at utils.scala:61, took 0.716795 s
21/02/17 01:39:39 INFO CodeGenerator: Code generated in 12.615146 ms
21/02/17 01:39:39 INFO CodeGenerator: Code generated in 12.30171 ms
21/02/17 01:39:39 INFO SparkContext: Starting job: collect at utils.scala:135
21/02/17 01:39:39 INFO DAGScheduler: Got job 1 (collect at utils.scala:135) with 1 output partitions
21/02/17 01:39:39 INFO DAGScheduler: Final stage: ResultStage 1 (collect at utils.scala:135)
21/02/17 01:39:39 INFO DAGScheduler: Parents of final stage: List()
21/02/17 01:39:39 INFO DAGScheduler: Missing parents: List()
21/02/17 01:39:39 INFO DAGScheduler: Submitting ResultStage 1 (MapPartitionsRDD[9] at collect at utils.scala:135), which has no missing parents
21/02/17 01:39:39 INFO MemoryStore: Block broadcast_1 stored as values in memory (estimated size 6.2 KB, free 912.3 MB)
21/02/17 01:39:39 INFO MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 3.3 KB, free 912.3 MB)
21/02/17 01:39:39 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on localhost:37301 (size: 3.3 KB, free: 912.3 MB)
21/02/17 01:39:39 INFO SparkContext: Created broadcast 1 from broadcast at DAGScheduler.scala:1161
21/02/17 01:39:39 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 1 (MapPartitionsRDD[9] at collect at utils.scala:135) (first 15 tasks are for partitions Vector(0))
21/02/17 01:39:39 INFO TaskSchedulerImpl: Adding task set 1.0 with 1 tasks
21/02/17 01:39:39 INFO TaskSetManager: Starting task 0.0 in stage 1.0 (TID 1, localhost, executor driver, partition 0, PROCESS_LOCAL, 8080 bytes)
21/02/17 01:39:39 INFO Executor: Running task 0.0 in stage 1.0 (TID 1)
21/02/17 01:39:39 INFO CodeGenerator: Code generated in 8.194006 ms
21/02/17 01:39:39 INFO Executor: Finished task 0.0 in stage 1.0 (TID 1). 1329 bytes result sent to driver
21/02/17 01:39:39 INFO TaskSetManager: Finished task 0.0 in stage 1.0 (TID 1) in 29 ms on localhost (executor driver) (1/1)
21/02/17 01:39:39 INFO TaskSchedulerImpl: Removed TaskSet 1.0, whose tasks have all completed, from pool 
21/02/17 01:39:39 INFO DAGScheduler: ResultStage 1 (collect at utils.scala:135) finished in 0.036 s
21/02/17 01:39:39 INFO DAGScheduler: Job 1 finished: collect at utils.scala:135, took 0.039702 s
21/02/17 01:39:39 INFO CodeGenerator: Code generated in 9.741156 ms
21/02/17 01:39:39 INFO CodeGenerator: Code generated in 7.483726 ms
21/02/17 01:39:39 INFO SparkContext: Starting job: count at utils.scala:135
21/02/17 01:39:39 INFO DAGScheduler: Registering RDD 12 (count at utils.scala:135)
21/02/17 01:39:39 INFO DAGScheduler: Got job 2 (count at utils.scala:135) with 1 output partitions
21/02/17 01:39:39 INFO DAGScheduler: Final stage: ResultStage 3 (count at utils.scala:135)
21/02/17 01:39:39 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 2)
21/02/17 01:39:39 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 2)
21/02/17 01:39:39 INFO DAGScheduler: Submitting ShuffleMapStage 2 (MapPartitionsRDD[12] at count at utils.scala:135), which has no missing parents
21/02/17 01:39:39 INFO MemoryStore: Block broadcast_2 stored as values in memory (estimated size 8.4 KB, free 912.3 MB)
21/02/17 01:39:39 INFO MemoryStore: Block broadcast_2_piece0 stored as bytes in memory (estimated size 4.5 KB, free 912.3 MB)
21/02/17 01:39:39 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on localhost:37301 (size: 4.5 KB, free: 912.3 MB)
21/02/17 01:39:39 INFO SparkContext: Created broadcast 2 from broadcast at DAGScheduler.scala:1161
21/02/17 01:39:39 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 2 (MapPartitionsRDD[12] at count at utils.scala:135) (first 15 tasks are for partitions Vector(0))
21/02/17 01:39:39 INFO TaskSchedulerImpl: Adding task set 2.0 with 1 tasks
21/02/17 01:39:39 INFO TaskSetManager: Starting task 0.0 in stage 2.0 (TID 2, localhost, executor driver, partition 0, PROCESS_LOCAL, 8069 bytes)
21/02/17 01:39:39 INFO Executor: Running task 0.0 in stage 2.0 (TID 2)
21/02/17 01:39:39 INFO Executor: Finished task 0.0 in stage 2.0 (TID 2). 1542 bytes result sent to driver
21/02/17 01:39:39 INFO TaskSetManager: Finished task 0.0 in stage 2.0 (TID 2) in 36 ms on localhost (executor driver) (1/1)
21/02/17 01:39:39 INFO TaskSchedulerImpl: Removed TaskSet 2.0, whose tasks have all completed, from pool 
21/02/17 01:39:39 INFO DAGScheduler: ShuffleMapStage 2 (count at utils.scala:135) finished in 0.046 s
21/02/17 01:39:39 INFO DAGScheduler: looking for newly runnable stages
21/02/17 01:39:39 INFO DAGScheduler: running: Set()
21/02/17 01:39:39 INFO DAGScheduler: waiting: Set(ResultStage 3)
21/02/17 01:39:39 INFO DAGScheduler: failed: Set()
21/02/17 01:39:39 INFO DAGScheduler: Submitting ResultStage 3 (MapPartitionsRDD[15] at count at utils.scala:135), which has no missing parents
21/02/17 01:39:39 INFO MemoryStore: Block broadcast_3 stored as values in memory (estimated size 7.1 KB, free 912.3 MB)
21/02/17 01:39:39 INFO MemoryStore: Block broadcast_3_piece0 stored as bytes in memory (estimated size 3.8 KB, free 912.3 MB)
21/02/17 01:39:39 INFO BlockManagerInfo: Added broadcast_3_piece0 in memory on localhost:37301 (size: 3.8 KB, free: 912.3 MB)
21/02/17 01:39:39 INFO SparkContext: Created broadcast 3 from broadcast at DAGScheduler.scala:1161
21/02/17 01:39:39 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 3 (MapPartitionsRDD[15] at count at utils.scala:135) (first 15 tasks are for partitions Vector(0))
21/02/17 01:39:39 INFO TaskSchedulerImpl: Adding task set 3.0 with 1 tasks
21/02/17 01:39:39 INFO TaskSetManager: Starting task 0.0 in stage 3.0 (TID 3, localhost, executor driver, partition 0, NODE_LOCAL, 7767 bytes)
21/02/17 01:39:39 INFO Executor: Running task 0.0 in stage 3.0 (TID 3)
21/02/17 01:39:39 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks including 1 local blocks and 0 remote blocks
21/02/17 01:39:39 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 5 ms
21/02/17 01:39:39 INFO Executor: Finished task 0.0 in stage 3.0 (TID 3). 1782 bytes result sent to driver
21/02/17 01:39:39 INFO TaskSetManager: Finished task 0.0 in stage 3.0 (TID 3) in 33 ms on localhost (executor driver) (1/1)
21/02/17 01:39:39 INFO TaskSchedulerImpl: Removed TaskSet 3.0, whose tasks have all completed, from pool 
21/02/17 01:39:39 INFO DAGScheduler: ResultStage 3 (count at utils.scala:135) finished in 0.041 s
21/02/17 01:39:39 INFO DAGScheduler: Job 2 finished: count at utils.scala:135, took 0.105732 s
21/02/17 01:39:39 INFO SparkContext: Starting job: collect at utils.scala:135
21/02/17 01:39:39 INFO DAGScheduler: Got job 3 (collect at utils.scala:135) with 1 output partitions
21/02/17 01:39:39 INFO DAGScheduler: Final stage: ResultStage 4 (collect at utils.scala:135)
21/02/17 01:39:39 INFO DAGScheduler: Parents of final stage: List()
21/02/17 01:39:39 INFO DAGScheduler: Missing parents: List()
21/02/17 01:39:39 INFO DAGScheduler: Submitting ResultStage 4 (MapPartitionsRDD[18] at collect at utils.scala:135), which has no missing parents
21/02/17 01:39:39 INFO MemoryStore: Block broadcast_4 stored as values in memory (estimated size 6.2 KB, free 912.3 MB)
21/02/17 01:39:39 INFO MemoryStore: Block broadcast_4_piece0 stored as bytes in memory (estimated size 3.3 KB, free 912.2 MB)
21/02/17 01:39:39 INFO BlockManagerInfo: Added broadcast_4_piece0 in memory on localhost:37301 (size: 3.3 KB, free: 912.3 MB)
21/02/17 01:39:39 INFO SparkContext: Created broadcast 4 from broadcast at DAGScheduler.scala:1161
21/02/17 01:39:39 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 4 (MapPartitionsRDD[18] at collect at utils.scala:135) (first 15 tasks are for partitions Vector(0))
21/02/17 01:39:39 INFO TaskSchedulerImpl: Adding task set 4.0 with 1 tasks
21/02/17 01:39:39 INFO TaskSetManager: Starting task 0.0 in stage 4.0 (TID 4, localhost, executor driver, partition 0, PROCESS_LOCAL, 8080 bytes)
21/02/17 01:39:39 INFO Executor: Running task 0.0 in stage 4.0 (TID 4)
21/02/17 01:39:39 INFO Executor: Finished task 0.0 in stage 4.0 (TID 4). 1286 bytes result sent to driver
21/02/17 01:39:39 INFO TaskSetManager: Finished task 0.0 in stage 4.0 (TID 4) in 6 ms on localhost (executor driver) (1/1)
21/02/17 01:39:39 INFO TaskSchedulerImpl: Removed TaskSet 4.0, whose tasks have all completed, from pool 
21/02/17 01:39:39 INFO DAGScheduler: ResultStage 4 (collect at utils.scala:135) finished in 0.011 s
21/02/17 01:39:39 INFO DAGScheduler: Job 3 finished: collect at utils.scala:135, took 0.013083 s
21/02/17 01:39:39 INFO SparkContext: Starting job: count at utils.scala:135
21/02/17 01:39:39 INFO DAGScheduler: Registering RDD 21 (count at utils.scala:135)
21/02/17 01:39:39 INFO DAGScheduler: Got job 4 (count at utils.scala:135) with 1 output partitions
21/02/17 01:39:39 INFO DAGScheduler: Final stage: ResultStage 6 (count at utils.scala:135)
21/02/17 01:39:39 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 5)
21/02/17 01:39:39 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 5)
21/02/17 01:39:39 INFO DAGScheduler: Submitting ShuffleMapStage 5 (MapPartitionsRDD[21] at count at utils.scala:135), which has no missing parents
21/02/17 01:39:39 INFO MemoryStore: Block broadcast_5 stored as values in memory (estimated size 8.4 KB, free 912.2 MB)
21/02/17 01:39:39 INFO MemoryStore: Block broadcast_5_piece0 stored as bytes in memory (estimated size 4.5 KB, free 912.2 MB)
21/02/17 01:39:39 INFO BlockManagerInfo: Added broadcast_5_piece0 in memory on localhost:37301 (size: 4.5 KB, free: 912.3 MB)
21/02/17 01:39:39 INFO SparkContext: Created broadcast 5 from broadcast at DAGScheduler.scala:1161
21/02/17 01:39:39 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 5 (MapPartitionsRDD[21] at count at utils.scala:135) (first 15 tasks are for partitions Vector(0))
21/02/17 01:39:39 INFO TaskSchedulerImpl: Adding task set 5.0 with 1 tasks
21/02/17 01:39:39 INFO TaskSetManager: Starting task 0.0 in stage 5.0 (TID 5, localhost, executor driver, partition 0, PROCESS_LOCAL, 8069 bytes)
21/02/17 01:39:39 INFO Executor: Running task 0.0 in stage 5.0 (TID 5)
21/02/17 01:39:39 INFO Executor: Finished task 0.0 in stage 5.0 (TID 5). 1499 bytes result sent to driver
21/02/17 01:39:39 INFO TaskSetManager: Finished task 0.0 in stage 5.0 (TID 5) in 6 ms on localhost (executor driver) (1/1)
21/02/17 01:39:39 INFO TaskSchedulerImpl: Removed TaskSet 5.0, whose tasks have all completed, from pool 
21/02/17 01:39:39 INFO DAGScheduler: ShuffleMapStage 5 (count at utils.scala:135) finished in 0.011 s
21/02/17 01:39:39 INFO DAGScheduler: looking for newly runnable stages
21/02/17 01:39:39 INFO DAGScheduler: running: Set()
21/02/17 01:39:39 INFO DAGScheduler: waiting: Set(ResultStage 6)
21/02/17 01:39:39 INFO DAGScheduler: failed: Set()
21/02/17 01:39:39 INFO DAGScheduler: Submitting ResultStage 6 (MapPartitionsRDD[24] at count at utils.scala:135), which has no missing parents
21/02/17 01:39:39 INFO MemoryStore: Block broadcast_6 stored as values in memory (estimated size 7.1 KB, free 912.2 MB)
21/02/17 01:39:39 INFO MemoryStore: Block broadcast_6_piece0 stored as bytes in memory (estimated size 3.8 KB, free 912.2 MB)
21/02/17 01:39:39 INFO BlockManagerInfo: Added broadcast_6_piece0 in memory on localhost:37301 (size: 3.8 KB, free: 912.3 MB)
21/02/17 01:39:39 INFO SparkContext: Created broadcast 6 from broadcast at DAGScheduler.scala:1161
21/02/17 01:39:39 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 6 (MapPartitionsRDD[24] at count at utils.scala:135) (first 15 tasks are for partitions Vector(0))
21/02/17 01:39:39 INFO TaskSchedulerImpl: Adding task set 6.0 with 1 tasks
21/02/17 01:39:39 INFO TaskSetManager: Starting task 0.0 in stage 6.0 (TID 6, localhost, executor driver, partition 0, NODE_LOCAL, 7767 bytes)
21/02/17 01:39:39 INFO Executor: Running task 0.0 in stage 6.0 (TID 6)
21/02/17 01:39:39 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks including 1 local blocks and 0 remote blocks
21/02/17 01:39:39 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
21/02/17 01:39:39 INFO Executor: Finished task 0.0 in stage 6.0 (TID 6). 1782 bytes result sent to driver
21/02/17 01:39:39 INFO TaskSetManager: Finished task 0.0 in stage 6.0 (TID 6) in 5 ms on localhost (executor driver) (1/1)
21/02/17 01:39:39 INFO TaskSchedulerImpl: Removed TaskSet 6.0, whose tasks have all completed, from pool 
21/02/17 01:39:39 INFO DAGScheduler: ResultStage 6 (count at utils.scala:135) finished in 0.010 s
21/02/17 01:39:39 INFO DAGScheduler: Job 4 finished: count at utils.scala:135, took 0.025300 s
21/02/17 01:39:40 INFO ContextCleaner: Cleaned accumulator 156
21/02/17 01:39:40 INFO ContextCleaner: Cleaned accumulator 207
21/02/17 01:39:40 INFO ContextCleaner: Cleaned accumulator 148
21/02/17 01:39:40 INFO ContextCleaner: Cleaned accumulator 80
21/02/17 01:39:40 INFO ContextCleaner: Cleaned accumulator 185
21/02/17 01:39:40 INFO ContextCleaner: Cleaned accumulator 210
21/02/17 01:39:40 INFO ContextCleaner: Cleaned accumulator 61
21/02/17 01:39:40 INFO ContextCleaner: Cleaned accumulator 149
21/02/17 01:39:40 INFO ContextCleaner: Cleaned accumulator 154
21/02/17 01:39:40 INFO ContextCleaner: Cleaned accumulator 93
21/02/17 01:39:40 INFO ContextCleaner: Cleaned accumulator 170
21/02/17 01:39:40 INFO ContextCleaner: Cleaned accumulator 130
21/02/17 01:39:40 INFO ContextCleaner: Cleaned accumulator 173
21/02/17 01:39:40 INFO ContextCleaner: Cleaned accumulator 35
21/02/17 01:39:40 INFO ContextCleaner: Cleaned accumulator 180
21/02/17 01:39:40 INFO ContextCleaner: Cleaned accumulator 126
21/02/17 01:39:40 INFO ContextCleaner: Cleaned accumulator 69
21/02/17 01:39:40 INFO ContextCleaner: Cleaned accumulator 166
21/02/17 01:39:40 INFO ContextCleaner: Cleaned accumulator 85
21/02/17 01:39:40 INFO ContextCleaner: Cleaned accumulator 114
21/02/17 01:39:40 INFO ContextCleaner: Cleaned accumulator 203
21/02/17 01:39:40 INFO ContextCleaner: Cleaned accumulator 158
21/02/17 01:39:40 INFO BlockManagerInfo: Removed broadcast_4_piece0 on localhost:37301 in memory (size: 3.3 KB, free: 912.3 MB)
21/02/17 01:39:40 INFO ContextCleaner: Cleaned accumulator 84
21/02/17 01:39:40 INFO ContextCleaner: Cleaned accumulator 192
21/02/17 01:39:40 INFO ContextCleaner: Cleaned accumulator 100
21/02/17 01:39:40 INFO ContextCleaner: Cleaned accumulator 41
21/02/17 01:39:40 INFO ContextCleaner: Cleaned accumulator 198
21/02/17 01:39:40 INFO ContextCleaner: Cleaned accumulator 31
21/02/17 01:39:40 INFO ContextCleaner: Cleaned accumulator 142
21/02/17 01:39:40 INFO ContextCleaner: Cleaned accumulator 206
21/02/17 01:39:40 INFO ContextCleaner: Cleaned accumulator 119
21/02/17 01:39:40 INFO ContextCleaner: Cleaned accumulator 195
21/02/17 01:39:40 INFO ContextCleaner: Cleaned accumulator 112
21/02/17 01:39:40 INFO ContextCleaner: Cleaned accumulator 29
21/02/17 01:39:40 INFO ContextCleaner: Cleaned accumulator 57
21/02/17 01:39:40 INFO ContextCleaner: Cleaned accumulator 66
21/02/17 01:39:40 INFO ContextCleaner: Cleaned accumulator 42
21/02/17 01:39:40 INFO ContextCleaner: Cleaned accumulator 209
21/02/17 01:39:40 INFO ContextCleaner: Cleaned accumulator 160
21/02/17 01:39:40 INFO ContextCleaner: Cleaned accumulator 202
21/02/17 01:39:40 INFO ContextCleaner: Cleaned accumulator 117
21/02/17 01:39:40 INFO ContextCleaner: Cleaned accumulator 27
21/02/17 01:39:40 INFO ContextCleaner: Cleaned accumulator 104
21/02/17 01:39:40 INFO ContextCleaner: Cleaned accumulator 68
21/02/17 01:39:40 INFO ContextCleaner: Cleaned accumulator 46
21/02/17 01:39:40 INFO ContextCleaner: Cleaned accumulator 99
21/02/17 01:39:40 INFO ContextCleaner: Cleaned accumulator 199
21/02/17 01:39:40 INFO ContextCleaner: Cleaned accumulator 157
21/02/17 01:39:40 INFO ContextCleaner: Cleaned accumulator 165
21/02/17 01:39:40 INFO ContextCleaner: Cleaned accumulator 97
21/02/17 01:39:40 INFO ContextCleaner: Cleaned accumulator 169
21/02/17 01:39:40 INFO ContextCleaner: Cleaned accumulator 86
21/02/17 01:39:40 INFO ContextCleaner: Cleaned accumulator 184
21/02/17 01:39:40 INFO ContextCleaner: Cleaned accumulator 147
21/02/17 01:39:40 INFO ContextCleaner: Cleaned accumulator 113
21/02/17 01:39:40 INFO ContextCleaner: Cleaned accumulator 177
21/02/17 01:39:40 INFO ContextCleaner: Cleaned accumulator 44
21/02/17 01:39:40 INFO ContextCleaner: Cleaned accumulator 65
21/02/17 01:39:40 INFO ContextCleaner: Cleaned accumulator 79
21/02/17 01:39:40 INFO ContextCleaner: Cleaned accumulator 132
21/02/17 01:39:40 INFO ContextCleaner: Cleaned accumulator 141
21/02/17 01:39:40 INFO ContextCleaner: Cleaned accumulator 103
21/02/17 01:39:40 INFO ContextCleaner: Cleaned accumulator 72
21/02/17 01:39:40 INFO ContextCleaner: Cleaned accumulator 92
21/02/17 01:39:40 INFO ContextCleaner: Cleaned accumulator 146
21/02/17 01:39:40 INFO ContextCleaner: Cleaned accumulator 115
21/02/17 01:39:40 INFO ContextCleaner: Cleaned accumulator 91
21/02/17 01:39:40 INFO ContextCleaner: Cleaned accumulator 53
21/02/17 01:39:40 INFO ContextCleaner: Cleaned accumulator 107
21/02/17 01:39:40 INFO ContextCleaner: Cleaned accumulator 134
21/02/17 01:39:40 INFO ContextCleaner: Cleaned accumulator 191
21/02/17 01:39:40 INFO ContextCleaner: Cleaned accumulator 38
21/02/17 01:39:40 INFO ContextCleaner: Cleaned accumulator 110
21/02/17 01:39:40 INFO ContextCleaner: Cleaned accumulator 49
21/02/17 01:39:40 INFO ContextCleaner: Cleaned accumulator 133
21/02/17 01:39:40 INFO ContextCleaner: Cleaned shuffle 0
21/02/17 01:39:40 INFO ContextCleaner: Cleaned accumulator 74
21/02/17 01:39:40 INFO ContextCleaner: Cleaned accumulator 124
21/02/17 01:39:40 INFO ContextCleaner: Cleaned accumulator 175
21/02/17 01:39:40 INFO ContextCleaner: Cleaned accumulator 50
21/02/17 01:39:40 INFO ContextCleaner: Cleaned accumulator 190
21/02/17 01:39:40 INFO ContextCleaner: Cleaned accumulator 37
21/02/17 01:39:40 INFO ContextCleaner: Cleaned accumulator 94
21/02/17 01:39:40 INFO ContextCleaner: Cleaned accumulator 121
21/02/17 01:39:40 INFO ContextCleaner: Cleaned accumulator 176
21/02/17 01:39:40 INFO ContextCleaner: Cleaned accumulator 204
21/02/17 01:39:40 INFO ContextCleaner: Cleaned accumulator 196
21/02/17 01:39:40 INFO ContextCleaner: Cleaned accumulator 64
21/02/17 01:39:40 INFO ContextCleaner: Cleaned accumulator 181
21/02/17 01:39:40 INFO ContextCleaner: Cleaned accumulator 201
21/02/17 01:39:40 INFO ContextCleaner: Cleaned shuffle 1
21/02/17 01:39:40 INFO ContextCleaner: Cleaned accumulator 71
21/02/17 01:39:40 INFO ContextCleaner: Cleaned accumulator 88
21/02/17 01:39:40 INFO ContextCleaner: Cleaned accumulator 128
21/02/17 01:39:40 INFO ContextCleaner: Cleaned accumulator 55
21/02/17 01:39:40 INFO ContextCleaner: Cleaned accumulator 125
21/02/17 01:39:40 INFO ContextCleaner: Cleaned accumulator 102
21/02/17 01:39:40 INFO ContextCleaner: Cleaned accumulator 120
21/02/17 01:39:40 INFO ContextCleaner: Cleaned accumulator 171
21/02/17 01:39:40 INFO ContextCleaner: Cleaned accumulator 172
21/02/17 01:39:40 INFO ContextCleaner: Cleaned accumulator 182
21/02/17 01:39:40 INFO ContextCleaner: Cleaned accumulator 208
21/02/17 01:39:40 INFO ContextCleaner: Cleaned accumulator 34
21/02/17 01:39:40 INFO ContextCleaner: Cleaned accumulator 197
21/02/17 01:39:40 INFO ContextCleaner: Cleaned accumulator 183
21/02/17 01:39:40 INFO ContextCleaner: Cleaned accumulator 136
21/02/17 01:39:40 INFO ContextCleaner: Cleaned accumulator 129
21/02/17 01:39:40 INFO BlockManagerInfo: Removed broadcast_1_piece0 on localhost:37301 in memory (size: 3.3 KB, free: 912.3 MB)
21/02/17 01:39:40 INFO ContextCleaner: Cleaned accumulator 127
21/02/17 01:39:40 INFO ContextCleaner: Cleaned accumulator 159
21/02/17 01:39:40 INFO ContextCleaner: Cleaned accumulator 135
21/02/17 01:39:40 INFO ContextCleaner: Cleaned accumulator 143
21/02/17 01:39:40 INFO ContextCleaner: Cleaned accumulator 28
21/02/17 01:39:40 INFO ContextCleaner: Cleaned accumulator 123
21/02/17 01:39:40 INFO ContextCleaner: Cleaned accumulator 83
21/02/17 01:39:40 INFO ContextCleaner: Cleaned accumulator 193
21/02/17 01:39:40 INFO ContextCleaner: Cleaned accumulator 40
21/02/17 01:39:40 INFO ContextCleaner: Cleaned accumulator 43
21/02/17 01:39:40 INFO ContextCleaner: Cleaned accumulator 73
21/02/17 01:39:40 INFO ContextCleaner: Cleaned accumulator 82
21/02/17 01:39:40 INFO ContextCleaner: Cleaned accumulator 32
21/02/17 01:39:40 INFO ContextCleaner: Cleaned accumulator 153
21/02/17 01:39:40 INFO ContextCleaner: Cleaned accumulator 98
21/02/17 01:39:40 INFO ContextCleaner: Cleaned accumulator 33
21/02/17 01:39:40 INFO ContextCleaner: Cleaned accumulator 89
21/02/17 01:39:40 INFO ContextCleaner: Cleaned accumulator 188
21/02/17 01:39:40 INFO ContextCleaner: Cleaned accumulator 101
21/02/17 01:39:40 INFO ContextCleaner: Cleaned accumulator 155
21/02/17 01:39:40 INFO ContextCleaner: Cleaned accumulator 54
21/02/17 01:39:40 INFO ContextCleaner: Cleaned accumulator 45
21/02/17 01:39:40 INFO ContextCleaner: Cleaned accumulator 77
21/02/17 01:39:40 INFO ContextCleaner: Cleaned accumulator 51
21/02/17 01:39:40 INFO ContextCleaner: Cleaned accumulator 167
21/02/17 01:39:40 INFO ContextCleaner: Cleaned accumulator 205
21/02/17 01:39:40 INFO ContextCleaner: Cleaned accumulator 200
21/02/17 01:39:40 INFO ContextCleaner: Cleaned accumulator 60
21/02/17 01:39:40 INFO ContextCleaner: Cleaned accumulator 75
21/02/17 01:39:40 INFO BlockManagerInfo: Removed broadcast_3_piece0 on localhost:37301 in memory (size: 3.8 KB, free: 912.3 MB)
21/02/17 01:39:40 INFO ContextCleaner: Cleaned accumulator 137
21/02/17 01:39:40 INFO ContextCleaner: Cleaned accumulator 56
21/02/17 01:39:40 INFO ContextCleaner: Cleaned accumulator 174
21/02/17 01:39:40 INFO ContextCleaner: Cleaned accumulator 106
21/02/17 01:39:40 INFO ContextCleaner: Cleaned accumulator 122
21/02/17 01:39:40 INFO ContextCleaner: Cleaned accumulator 164
21/02/17 01:39:40 INFO ContextCleaner: Cleaned accumulator 152
21/02/17 01:39:40 INFO ContextCleaner: Cleaned accumulator 81
21/02/17 01:39:40 INFO ContextCleaner: Cleaned accumulator 48
21/02/17 01:39:40 INFO ContextCleaner: Cleaned accumulator 105
21/02/17 01:39:40 INFO ContextCleaner: Cleaned accumulator 109
21/02/17 01:39:40 INFO ContextCleaner: Cleaned accumulator 144
21/02/17 01:39:40 INFO BlockManagerInfo: Removed broadcast_5_piece0 on localhost:37301 in memory (size: 4.5 KB, free: 912.3 MB)
21/02/17 01:39:40 INFO ContextCleaner: Cleaned accumulator 67
21/02/17 01:39:40 INFO ContextCleaner: Cleaned accumulator 145
21/02/17 01:39:40 INFO BlockManagerInfo: Removed broadcast_6_piece0 on localhost:37301 in memory (size: 3.8 KB, free: 912.3 MB)
21/02/17 01:39:40 INFO ContextCleaner: Cleaned accumulator 63
21/02/17 01:39:40 INFO ContextCleaner: Cleaned accumulator 111
21/02/17 01:39:40 INFO ContextCleaner: Cleaned accumulator 90
21/02/17 01:39:40 INFO ContextCleaner: Cleaned accumulator 39
21/02/17 01:39:40 INFO ContextCleaner: Cleaned accumulator 78
21/02/17 01:39:40 INFO ContextCleaner: Cleaned accumulator 186
21/02/17 01:39:40 INFO ContextCleaner: Cleaned accumulator 179
21/02/17 01:39:40 INFO ContextCleaner: Cleaned accumulator 187
21/02/17 01:39:40 INFO ContextCleaner: Cleaned accumulator 62
21/02/17 01:39:40 INFO ContextCleaner: Cleaned accumulator 168
21/02/17 01:39:40 INFO ContextCleaner: Cleaned accumulator 162
21/02/17 01:39:40 INFO ContextCleaner: Cleaned accumulator 95
21/02/17 01:39:40 INFO ContextCleaner: Cleaned accumulator 76
21/02/17 01:39:40 INFO ContextCleaner: Cleaned accumulator 87
21/02/17 01:39:40 INFO ContextCleaner: Cleaned accumulator 30
21/02/17 01:39:40 INFO ContextCleaner: Cleaned accumulator 139
21/02/17 01:39:40 INFO ContextCleaner: Cleaned accumulator 140
21/02/17 01:39:40 INFO ContextCleaner: Cleaned accumulator 178
21/02/17 01:39:40 INFO ContextCleaner: Cleaned accumulator 138
21/02/17 01:39:40 INFO ContextCleaner: Cleaned accumulator 96
21/02/17 01:39:40 INFO ContextCleaner: Cleaned accumulator 151
21/02/17 01:39:40 INFO ContextCleaner: Cleaned accumulator 131
21/02/17 01:39:40 INFO ContextCleaner: Cleaned accumulator 116
21/02/17 01:39:40 INFO ContextCleaner: Cleaned accumulator 59
21/02/17 01:39:40 INFO ContextCleaner: Cleaned accumulator 108
21/02/17 01:39:40 INFO ContextCleaner: Cleaned accumulator 150
21/02/17 01:39:40 INFO ContextCleaner: Cleaned accumulator 26
21/02/17 01:39:40 INFO ContextCleaner: Cleaned accumulator 189
21/02/17 01:39:40 INFO ContextCleaner: Cleaned accumulator 58
21/02/17 01:39:40 INFO ContextCleaner: Cleaned accumulator 47
21/02/17 01:39:40 INFO ContextCleaner: Cleaned accumulator 163
21/02/17 01:39:40 INFO ContextCleaner: Cleaned accumulator 52
21/02/17 01:39:40 INFO ContextCleaner: Cleaned accumulator 161
21/02/17 01:39:40 INFO ContextCleaner: Cleaned accumulator 70
21/02/17 01:39:40 INFO BlockManagerInfo: Removed broadcast_2_piece0 on localhost:37301 in memory (size: 4.5 KB, free: 912.3 MB)
21/02/17 01:39:40 INFO ContextCleaner: Cleaned accumulator 36
21/02/17 01:39:40 INFO ContextCleaner: Cleaned accumulator 194
21/02/17 01:39:40 INFO CodeGenerator: Code generated in 34.381503 ms
21/02/17 01:39:40 INFO XGBoostSpark: Running XGBoost 1.1.2 with parameters:
alpha -> 0.0
min_child_weight -> 1.0
sample_type -> uniform
base_score -> 0.5
rabit_timeout -> -1
colsample_bylevel -> 1.0
grow_policy -> depthwise
skip_drop -> 0.0
lambda_bias -> 0.0
silent -> 0
scale_pos_weight -> 1.0
seed -> 0
cache_training_set -> false
features_col -> features
num_early_stopping_rounds -> 0
label_col -> label
num_workers -> 1
subsample -> 1.0
lambda -> 1.0
max_depth -> 6
tree_limit -> 0
custom_eval -> null
dmlc_worker_connect_retry -> 5
rate_drop -> 0.0
max_bin -> 16
train_test_ratio -> 1.0
use_external_memory -> false
objective -> reg:linear
eval_metric -> rmse
num_round -> 1
maximize_evaluation_metrics -> false
timeout_request_workers -> 1800000
missing -> NaN
rabit_ring_reduce_threshold -> 32768
checkpoint_path -> 
tracker_conf -> TrackerConf(0,python)
tree_method -> auto
max_delta_step -> 0.0
eta -> 0.3
verbosity -> 1
colsample_bytree -> 1.0
objective_type -> regression
normalize_type -> tree
allow_non_zero_for_missing -> false
custom_obj -> null
gamma -> 0.0
sketch_eps -> 0.03
nthread -> 1
prediction_col -> prediction
checkpoint_interval -> -1
21/02/17 01:39:40 WARN XGBoostSpark: train_test_ratio is deprecated since XGBoost 0.82, we recommend to explicitly pass a training and multiple evaluation datasets by passing 'eval_sets' and 'eval_set_names'
21/02/17 01:39:40 INFO RabitTracker$TrackerProcessLogger: 2021-02-17 01:39:40,768 INFO start listen on 192.168.2.12:9091
21/02/17 01:39:40 INFO XGBoostSpark: starting training with timeout set as 1800000 ms for waiting for resources
21/02/17 01:39:40 INFO SparkContext: Starting job: foreachPartition at XGBoost.scala:565
21/02/17 01:39:40 INFO DAGScheduler: Got job 5 (foreachPartition at XGBoost.scala:565) with 1 output partitions
21/02/17 01:39:40 INFO DAGScheduler: Final stage: ResultStage 7 (foreachPartition at XGBoost.scala:565)
21/02/17 01:39:40 INFO DAGScheduler: Parents of final stage: List()
21/02/17 01:39:40 INFO DAGScheduler: Missing parents: List()
21/02/17 01:39:40 INFO DAGScheduler: Submitting ResultStage 7 (MapPartitionsRDD[35] at mapPartitions at XGBoost.scala:450), which has no missing parents
21/02/17 01:39:40 INFO MemoryStore: Block broadcast_7 stored as values in memory (estimated size 31.7 KB, free 912.3 MB)
21/02/17 01:39:40 INFO MemoryStore: Block broadcast_7_piece0 stored as bytes in memory (estimated size 13.6 KB, free 912.2 MB)
21/02/17 01:39:40 INFO BlockManagerInfo: Added broadcast_7_piece0 in memory on localhost:37301 (size: 13.6 KB, free: 912.3 MB)
21/02/17 01:39:40 INFO SparkContext: Created broadcast 7 from broadcast at DAGScheduler.scala:1161
21/02/17 01:39:40 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 7 (MapPartitionsRDD[35] at mapPartitions at XGBoost.scala:450) (first 15 tasks are for partitions Vector(0))
21/02/17 01:39:40 INFO TaskSchedulerImpl: Adding task set 7.0 with 1 tasks
21/02/17 01:39:40 INFO TaskSetManager: Starting task 0.0 in stage 7.0 (TID 7, localhost, executor driver, partition 0, PROCESS_LOCAL, 19011 bytes)
21/02/17 01:39:40 INFO Executor: Running task 0.0 in stage 7.0 (TID 7)
21/02/17 01:39:40 INFO CodeGenerator: Code generated in 14.040026 ms
21/02/17 01:39:40 INFO MemoryStore: Block rdd_26_0 stored as values in memory (estimated size 5.6 KB, free 912.2 MB)
21/02/17 01:39:40 INFO BlockManagerInfo: Added rdd_26_0 in memory on localhost:37301 (size: 5.6 KB, free: 912.3 MB)
21/02/17 01:39:40 INFO CodeGenerator: Code generated in 3.670136 ms
21/02/17 01:39:40 INFO CodeGenerator: Code generated in 24.590204 ms
21/02/17 01:39:40 INFO CodeGenerator: Code generated in 10.648247 ms
21/02/17 01:39:41 INFO RabitTracker$TrackerProcessLogger: /tmp/tracker2559639731027832271.py:330: DeprecationWarning: isAlive() is deprecated, use is_alive() instead
21/02/17 01:39:41 INFO RabitTracker$TrackerProcessLogger:   while self.thread.isAlive():
21/02/17 01:39:41 INFO RabitTracker$TrackerProcessLogger: 2021-02-17 01:39:41,080 DEBUG Recieve start signal from 192.168.2.12; assign rank 0
21/02/17 01:39:41 INFO RabitTracker$TrackerProcessLogger: 2021-02-17 01:39:41,080 INFO @tracker All of 1 nodes getting started
21/02/17 01:39:41 INFO RabitTracker$TrackerProcessLogger: 2021-02-17 01:39:41,089 INFO [0]	train-rmse:2.633044
21/02/17 01:39:41 INFO RabitTracker$TrackerProcessLogger: 2021-02-17 01:39:41,090 DEBUG Recieve shutdown signal from 0
21/02/17 01:39:41 INFO RabitTracker$TrackerProcessLogger: 2021-02-17 01:39:41,090 INFO @tracker All nodes finishes job
21/02/17 01:39:41 INFO RabitTracker$TrackerProcessLogger: 2021-02-17 01:39:41,090 INFO @tracker 0.009598255157470703 secs between node start and job finish
21/02/17 01:39:41 INFO MemoryStore: Block rdd_35_0 stored as values in memory (estimated size 192.0 B, free 912.2 MB)
21/02/17 01:39:41 INFO BlockManagerInfo: Added rdd_35_0 in memory on localhost:37301 (size: 192.0 B, free: 912.3 MB)
21/02/17 01:39:41 INFO RabitTracker$TrackerProcessLogger: Tracker Process ends with exit code 0
21/02/17 01:39:41 INFO RabitTracker: Tracker Process ends with exit code 0
21/02/17 01:39:41 INFO XGBoostSpark: Rabit returns with exit code 0
21/02/17 01:39:41 INFO Executor: 1 block locks were not released by TID = 7:
[rdd_35_0]
21/02/17 01:39:41 INFO Executor: Finished task 0.0 in stage 7.0 (TID 7). 1303 bytes result sent to driver
21/02/17 01:39:41 INFO TaskSetManager: Finished task 0.0 in stage 7.0 (TID 7) in 267 ms on localhost (executor driver) (1/1)
21/02/17 01:39:41 INFO TaskSchedulerImpl: Removed TaskSet 7.0, whose tasks have all completed, from pool 
21/02/17 01:39:41 INFO DAGScheduler: ResultStage 7 (foreachPartition at XGBoost.scala:565) finished in 0.309 s
21/02/17 01:39:41 INFO DAGScheduler: Job 5 finished: foreachPartition at XGBoost.scala:565, took 0.314797 s
21/02/17 01:39:41 INFO SparkContext: Starting job: first at XGBoost.scala:685
21/02/17 01:39:41 INFO DAGScheduler: Got job 6 (first at XGBoost.scala:685) with 1 output partitions
21/02/17 01:39:41 INFO DAGScheduler: Final stage: ResultStage 8 (first at XGBoost.scala:685)
21/02/17 01:39:41 INFO DAGScheduler: Parents of final stage: List()
21/02/17 01:39:41 INFO DAGScheduler: Missing parents: List()
21/02/17 01:39:41 INFO DAGScheduler: Submitting ResultStage 8 (MapPartitionsRDD[35] at mapPartitions at XGBoost.scala:450), which has no missing parents
21/02/17 01:39:41 INFO MemoryStore: Block broadcast_8 stored as values in memory (estimated size 31.7 KB, free 912.2 MB)
21/02/17 01:39:41 INFO MemoryStore: Block broadcast_8_piece0 stored as bytes in memory (estimated size 13.7 KB, free 912.2 MB)
21/02/17 01:39:41 INFO BlockManagerInfo: Added broadcast_8_piece0 in memory on localhost:37301 (size: 13.7 KB, free: 912.3 MB)
21/02/17 01:39:41 INFO SparkContext: Created broadcast 8 from broadcast at DAGScheduler.scala:1161
21/02/17 01:39:41 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 8 (MapPartitionsRDD[35] at mapPartitions at XGBoost.scala:450) (first 15 tasks are for partitions Vector(0))
21/02/17 01:39:41 INFO TaskSchedulerImpl: Adding task set 8.0 with 1 tasks
21/02/17 01:39:41 INFO TaskSetManager: Starting task 0.0 in stage 8.0 (TID 8, localhost, executor driver, partition 0, PROCESS_LOCAL, 19011 bytes)
21/02/17 01:39:41 INFO Executor: Running task 0.0 in stage 8.0 (TID 8)
21/02/17 01:39:41 INFO BlockManager: Found block rdd_35_0 locally
21/02/17 01:39:41 INFO Executor: 1 block locks were not released by TID = 8:
[rdd_35_0]
21/02/17 01:39:41 INFO Executor: Finished task 0.0 in stage 8.0 (TID 8). 2551 bytes result sent to driver
21/02/17 01:39:41 INFO TaskSetManager: Finished task 0.0 in stage 8.0 (TID 8) in 13 ms on localhost (executor driver) (1/1)
21/02/17 01:39:41 INFO TaskSchedulerImpl: Removed TaskSet 8.0, whose tasks have all completed, from pool 
21/02/17 01:39:41 INFO DAGScheduler: ResultStage 8 (first at XGBoost.scala:685) finished in 0.019 s
21/02/17 01:39:41 INFO DAGScheduler: Job 6 finished: first at XGBoost.scala:685, took 0.022773 s
21/02/17 01:39:41 INFO MapPartitionsRDD: Removing RDD 35 from persistence list
21/02/17 01:39:41 INFO BlockManager: Removing RDD 35
21/02/17 01:39:41 INFO MemoryStore: Block broadcast_9 stored as values in memory (estimated size 64.0 B, free 912.2 MB)
21/02/17 01:39:41 INFO MemoryStore: Block broadcast_9_piece0 stored as bytes in memory (estimated size 510.0 B, free 912.2 MB)
21/02/17 01:39:41 INFO BlockManagerInfo: Added broadcast_9_piece0 in memory on localhost:37301 (size: 510.0 B, free: 912.3 MB)
21/02/17 01:39:41 INFO SparkContext: Created broadcast 9 from broadcast at XGBoostRegressor.scala:271
21/02/17 01:39:41 INFO CodeGenerator: Code generated in 22.2383 ms
21/02/17 01:39:41 INFO CodeGenerator: Code generated in 6.555867 ms
21/02/17 01:39:41 INFO CodeGenerator: Code generated in 5.510084 ms
21/02/17 01:39:41 INFO SparkContext: Starting job: collect at utils.scala:135
21/02/17 01:39:41 INFO DAGScheduler: Got job 7 (collect at utils.scala:135) with 1 output partitions
21/02/17 01:39:41 INFO DAGScheduler: Final stage: ResultStage 9 (collect at utils.scala:135)
21/02/17 01:39:41 INFO DAGScheduler: Parents of final stage: List()
21/02/17 01:39:41 INFO DAGScheduler: Missing parents: List()
21/02/17 01:39:41 INFO DAGScheduler: Submitting ResultStage 9 (MapPartitionsRDD[46] at collect at utils.scala:135), which has no missing parents
21/02/17 01:39:41 INFO MemoryStore: Block broadcast_10 stored as values in memory (estimated size 6.4 KB, free 912.2 MB)
21/02/17 01:39:41 INFO MemoryStore: Block broadcast_10_piece0 stored as bytes in memory (estimated size 3.3 KB, free 912.2 MB)
21/02/17 01:39:41 INFO BlockManagerInfo: Added broadcast_10_piece0 in memory on localhost:37301 (size: 3.3 KB, free: 912.3 MB)
21/02/17 01:39:41 INFO SparkContext: Created broadcast 10 from broadcast at DAGScheduler.scala:1161
21/02/17 01:39:41 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 9 (MapPartitionsRDD[46] at collect at utils.scala:135) (first 15 tasks are for partitions Vector(0))
21/02/17 01:39:41 INFO TaskSchedulerImpl: Adding task set 9.0 with 1 tasks
21/02/17 01:39:41 INFO TaskSetManager: Starting task 0.0 in stage 9.0 (TID 9, localhost, executor driver, partition 0, PROCESS_LOCAL, 8080 bytes)
21/02/17 01:39:41 INFO Executor: Running task 0.0 in stage 9.0 (TID 9)
21/02/17 01:39:41 INFO Executor: Finished task 0.0 in stage 9.0 (TID 9). 1286 bytes result sent to driver
21/02/17 01:39:41 INFO TaskSetManager: Finished task 0.0 in stage 9.0 (TID 9) in 6 ms on localhost (executor driver) (1/1)
21/02/17 01:39:41 INFO TaskSchedulerImpl: Removed TaskSet 9.0, whose tasks have all completed, from pool 
21/02/17 01:39:41 INFO DAGScheduler: ResultStage 9 (collect at utils.scala:135) finished in 0.012 s
21/02/17 01:39:41 INFO DAGScheduler: Job 7 finished: collect at utils.scala:135, took 0.013975 s
21/02/17 01:39:41 INFO SparkContext: Starting job: count at utils.scala:135
21/02/17 01:39:41 INFO DAGScheduler: Registering RDD 49 (count at utils.scala:135)
21/02/17 01:39:41 INFO DAGScheduler: Got job 8 (count at utils.scala:135) with 1 output partitions
21/02/17 01:39:41 INFO DAGScheduler: Final stage: ResultStage 11 (count at utils.scala:135)
21/02/17 01:39:41 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 10)
21/02/17 01:39:41 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 10)
21/02/17 01:39:41 INFO DAGScheduler: Submitting ShuffleMapStage 10 (MapPartitionsRDD[49] at count at utils.scala:135), which has no missing parents
21/02/17 01:39:41 INFO MemoryStore: Block broadcast_11 stored as values in memory (estimated size 8.4 KB, free 912.2 MB)
21/02/17 01:39:41 INFO MemoryStore: Block broadcast_11_piece0 stored as bytes in memory (estimated size 4.5 KB, free 912.2 MB)
21/02/17 01:39:41 INFO BlockManagerInfo: Added broadcast_11_piece0 in memory on localhost:37301 (size: 4.5 KB, free: 912.3 MB)
21/02/17 01:39:41 INFO SparkContext: Created broadcast 11 from broadcast at DAGScheduler.scala:1161
21/02/17 01:39:41 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 10 (MapPartitionsRDD[49] at count at utils.scala:135) (first 15 tasks are for partitions Vector(0))
21/02/17 01:39:41 INFO TaskSchedulerImpl: Adding task set 10.0 with 1 tasks
21/02/17 01:39:41 INFO TaskSetManager: Starting task 0.0 in stage 10.0 (TID 10, localhost, executor driver, partition 0, PROCESS_LOCAL, 8069 bytes)
21/02/17 01:39:41 INFO Executor: Running task 0.0 in stage 10.0 (TID 10)
21/02/17 01:39:41 INFO Executor: Finished task 0.0 in stage 10.0 (TID 10). 1499 bytes result sent to driver
21/02/17 01:39:41 INFO TaskSetManager: Finished task 0.0 in stage 10.0 (TID 10) in 6 ms on localhost (executor driver) (1/1)
21/02/17 01:39:41 INFO TaskSchedulerImpl: Removed TaskSet 10.0, whose tasks have all completed, from pool 
21/02/17 01:39:41 INFO DAGScheduler: ShuffleMapStage 10 (count at utils.scala:135) finished in 0.013 s
21/02/17 01:39:41 INFO DAGScheduler: looking for newly runnable stages
21/02/17 01:39:41 INFO DAGScheduler: running: Set()
21/02/17 01:39:41 INFO DAGScheduler: waiting: Set(ResultStage 11)
21/02/17 01:39:41 INFO DAGScheduler: failed: Set()
21/02/17 01:39:41 INFO DAGScheduler: Submitting ResultStage 11 (MapPartitionsRDD[52] at count at utils.scala:135), which has no missing parents
21/02/17 01:39:41 INFO MemoryStore: Block broadcast_12 stored as values in memory (estimated size 7.1 KB, free 912.2 MB)
21/02/17 01:39:41 INFO MemoryStore: Block broadcast_12_piece0 stored as bytes in memory (estimated size 3.8 KB, free 912.2 MB)
21/02/17 01:39:41 INFO BlockManagerInfo: Added broadcast_12_piece0 in memory on localhost:37301 (size: 3.8 KB, free: 912.3 MB)
21/02/17 01:39:41 INFO SparkContext: Created broadcast 12 from broadcast at DAGScheduler.scala:1161
21/02/17 01:39:41 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 11 (MapPartitionsRDD[52] at count at utils.scala:135) (first 15 tasks are for partitions Vector(0))
21/02/17 01:39:41 INFO TaskSchedulerImpl: Adding task set 11.0 with 1 tasks
21/02/17 01:39:41 INFO TaskSetManager: Starting task 0.0 in stage 11.0 (TID 11, localhost, executor driver, partition 0, NODE_LOCAL, 7767 bytes)
21/02/17 01:39:41 INFO Executor: Running task 0.0 in stage 11.0 (TID 11)
21/02/17 01:39:41 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks including 1 local blocks and 0 remote blocks
21/02/17 01:39:41 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
21/02/17 01:39:41 INFO Executor: Finished task 0.0 in stage 11.0 (TID 11). 1782 bytes result sent to driver
21/02/17 01:39:41 INFO TaskSetManager: Finished task 0.0 in stage 11.0 (TID 11) in 5 ms on localhost (executor driver) (1/1)
21/02/17 01:39:41 INFO TaskSchedulerImpl: Removed TaskSet 11.0, whose tasks have all completed, from pool 
21/02/17 01:39:41 INFO DAGScheduler: ResultStage 11 (count at utils.scala:135) finished in 0.009 s
21/02/17 01:39:41 INFO DAGScheduler: Job 8 finished: count at utils.scala:135, took 0.025783 s
21/02/17 01:39:42 INFO CodeGenerator: Code generated in 4.99891 ms
21/02/17 01:39:42 INFO CodeGenerator: Code generated in 6.43342 ms
21/02/17 01:39:42 INFO SparkContext: Starting job: collect at utils.scala:135
21/02/17 01:39:42 INFO DAGScheduler: Got job 9 (collect at utils.scala:135) with 1 output partitions
21/02/17 01:39:42 INFO DAGScheduler: Final stage: ResultStage 12 (collect at utils.scala:135)
21/02/17 01:39:42 INFO DAGScheduler: Parents of final stage: List()
21/02/17 01:39:42 INFO DAGScheduler: Missing parents: List()
21/02/17 01:39:42 INFO DAGScheduler: Submitting ResultStage 12 (MapPartitionsRDD[55] at collect at utils.scala:135), which has no missing parents
21/02/17 01:39:42 INFO MemoryStore: Block broadcast_13 stored as values in memory (estimated size 59.1 KB, free 912.1 MB)
21/02/17 01:39:42 INFO MemoryStore: Block broadcast_13_piece0 stored as bytes in memory (estimated size 25.5 KB, free 912.1 MB)
21/02/17 01:39:42 INFO BlockManagerInfo: Added broadcast_13_piece0 in memory on localhost:37301 (size: 25.5 KB, free: 912.2 MB)
21/02/17 01:39:42 INFO SparkContext: Created broadcast 13 from broadcast at DAGScheduler.scala:1161
21/02/17 01:39:42 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 12 (MapPartitionsRDD[55] at collect at utils.scala:135) (first 15 tasks are for partitions Vector(0))
21/02/17 01:39:42 INFO TaskSchedulerImpl: Adding task set 12.0 with 1 tasks
21/02/17 01:39:42 INFO TaskSetManager: Starting task 0.0 in stage 12.0 (TID 12, localhost, executor driver, partition 0, PROCESS_LOCAL, 19011 bytes)
21/02/17 01:39:42 INFO Executor: Running task 0.0 in stage 12.0 (TID 12)
21/02/17 01:39:42 INFO BlockManager: Found block rdd_26_0 locally
21/02/17 01:39:42 INFO CodeGenerator: Code generated in 8.059328 ms
21/02/17 01:39:42 INFO CodeGenerator: Code generated in 11.305591 ms
21/02/17 01:39:42 INFO CodeGenerator: Code generated in 31.750393 ms
21/02/17 01:39:42 INFO Executor: Finished task 0.0 in stage 12.0 (TID 12). 1815 bytes result sent to driver
21/02/17 01:39:42 INFO TaskSetManager: Finished task 0.0 in stage 12.0 (TID 12) in 108 ms on localhost (executor driver) (1/1)
21/02/17 01:39:42 INFO TaskSchedulerImpl: Removed TaskSet 12.0, whose tasks have all completed, from pool 
21/02/17 01:39:42 INFO DAGScheduler: ResultStage 12 (collect at utils.scala:135) finished in 0.117 s
21/02/17 01:39:42 INFO DAGScheduler: Job 9 finished: collect at utils.scala:135, took 0.119337 s
21/02/17 01:39:42 INFO CodeGenerator: Code generated in 7.109768 ms
21/02/17 01:39:42 INFO SparkContext: Starting job: count at utils.scala:135
21/02/17 01:39:42 INFO DAGScheduler: Registering RDD 58 (count at utils.scala:135)
21/02/17 01:39:42 INFO DAGScheduler: Got job 10 (count at utils.scala:135) with 1 output partitions
21/02/17 01:39:42 INFO DAGScheduler: Final stage: ResultStage 14 (count at utils.scala:135)
21/02/17 01:39:42 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 13)
21/02/17 01:39:42 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 13)
21/02/17 01:39:42 INFO DAGScheduler: Submitting ShuffleMapStage 13 (MapPartitionsRDD[58] at count at utils.scala:135), which has no missing parents
21/02/17 01:39:42 INFO MemoryStore: Block broadcast_14 stored as values in memory (estimated size 60.0 KB, free 912.0 MB)
21/02/17 01:39:42 INFO MemoryStore: Block broadcast_14_piece0 stored as bytes in memory (estimated size 26.0 KB, free 912.0 MB)
21/02/17 01:39:42 INFO BlockManagerInfo: Added broadcast_14_piece0 in memory on localhost:37301 (size: 26.0 KB, free: 912.2 MB)
21/02/17 01:39:42 INFO SparkContext: Created broadcast 14 from broadcast at DAGScheduler.scala:1161
21/02/17 01:39:42 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 13 (MapPartitionsRDD[58] at count at utils.scala:135) (first 15 tasks are for partitions Vector(0))
21/02/17 01:39:42 INFO TaskSchedulerImpl: Adding task set 13.0 with 1 tasks
21/02/17 01:39:42 INFO TaskSetManager: Starting task 0.0 in stage 13.0 (TID 13, localhost, executor driver, partition 0, PROCESS_LOCAL, 19000 bytes)
21/02/17 01:39:42 INFO Executor: Running task 0.0 in stage 13.0 (TID 13)
21/02/17 01:39:42 INFO BlockManager: Found block rdd_26_0 locally
21/02/17 01:39:42 INFO Executor: Finished task 0.0 in stage 13.0 (TID 13). 1933 bytes result sent to driver
21/02/17 01:39:42 INFO TaskSetManager: Finished task 0.0 in stage 13.0 (TID 13) in 48 ms on localhost (executor driver) (1/1)
21/02/17 01:39:42 INFO TaskSchedulerImpl: Removed TaskSet 13.0, whose tasks have all completed, from pool 
21/02/17 01:39:42 INFO DAGScheduler: ShuffleMapStage 13 (count at utils.scala:135) finished in 0.054 s
21/02/17 01:39:42 INFO DAGScheduler: looking for newly runnable stages
21/02/17 01:39:42 INFO DAGScheduler: running: Set()
21/02/17 01:39:42 INFO DAGScheduler: waiting: Set(ResultStage 14)
21/02/17 01:39:42 INFO DAGScheduler: failed: Set()
21/02/17 01:39:42 INFO DAGScheduler: Submitting ResultStage 14 (MapPartitionsRDD[61] at count at utils.scala:135), which has no missing parents
21/02/17 01:39:42 INFO MemoryStore: Block broadcast_15 stored as values in memory (estimated size 7.1 KB, free 912.0 MB)
21/02/17 01:39:42 INFO MemoryStore: Block broadcast_15_piece0 stored as bytes in memory (estimated size 3.8 KB, free 912.0 MB)
21/02/17 01:39:42 INFO BlockManagerInfo: Added broadcast_15_piece0 in memory on localhost:37301 (size: 3.8 KB, free: 912.2 MB)
21/02/17 01:39:42 INFO SparkContext: Created broadcast 15 from broadcast at DAGScheduler.scala:1161
21/02/17 01:39:42 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 14 (MapPartitionsRDD[61] at count at utils.scala:135) (first 15 tasks are for partitions Vector(0))
21/02/17 01:39:42 INFO TaskSchedulerImpl: Adding task set 14.0 with 1 tasks
21/02/17 01:39:42 INFO TaskSetManager: Starting task 0.0 in stage 14.0 (TID 14, localhost, executor driver, partition 0, NODE_LOCAL, 7767 bytes)
21/02/17 01:39:42 INFO Executor: Running task 0.0 in stage 14.0 (TID 14)
21/02/17 01:39:42 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks including 1 local blocks and 0 remote blocks
21/02/17 01:39:42 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
21/02/17 01:39:42 INFO Executor: Finished task 0.0 in stage 14.0 (TID 14). 1782 bytes result sent to driver
21/02/17 01:39:42 INFO TaskSetManager: Finished task 0.0 in stage 14.0 (TID 14) in 5 ms on localhost (executor driver) (1/1)
21/02/17 01:39:42 INFO TaskSchedulerImpl: Removed TaskSet 14.0, whose tasks have all completed, from pool 
21/02/17 01:39:42 INFO DAGScheduler: ResultStage 14 (count at utils.scala:135) finished in 0.010 s
21/02/17 01:39:42 INFO DAGScheduler: Job 10 finished: count at utils.scala:135, took 0.067547 s
21/02/17 01:39:42 INFO deprecation: mapred.output.dir is deprecated. Instead, use mapreduce.output.fileoutputformat.outputdir
21/02/17 01:39:42 INFO HadoopMapRedCommitProtocol: Using output committer class org.apache.hadoop.mapred.FileOutputCommitter
21/02/17 01:39:42 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
21/02/17 01:39:42 INFO ContextCleaner: Cleaned accumulator 275
21/02/17 01:39:42 INFO ContextCleaner: Cleaned accumulator 323
21/02/17 01:39:42 INFO ContextCleaner: Cleaned accumulator 271
21/02/17 01:39:42 INFO ContextCleaner: Cleaned accumulator 378
21/02/17 01:39:42 INFO ContextCleaner: Cleaned accumulator 228
21/02/17 01:39:42 INFO ContextCleaner: Cleaned accumulator 343
21/02/17 01:39:42 INFO ContextCleaner: Cleaned accumulator 246
21/02/17 01:39:42 INFO ContextCleaner: Cleaned accumulator 390
21/02/17 01:39:42 INFO ContextCleaner: Cleaned accumulator 311
21/02/17 01:39:42 INFO ContextCleaner: Cleaned accumulator 381
21/02/17 01:39:42 INFO ContextCleaner: Cleaned accumulator 329
21/02/17 01:39:42 INFO ContextCleaner: Cleaned accumulator 233
21/02/17 01:39:42 INFO ContextCleaner: Cleaned accumulator 309
21/02/17 01:39:42 INFO ContextCleaner: Cleaned accumulator 413
21/02/17 01:39:42 INFO ContextCleaner: Cleaned accumulator 447
21/02/17 01:39:42 INFO ContextCleaner: Cleaned accumulator 443
21/02/17 01:39:42 INFO ContextCleaner: Cleaned accumulator 291
21/02/17 01:39:42 INFO ContextCleaner: Cleaned accumulator 307
21/02/17 01:39:42 INFO ContextCleaner: Cleaned accumulator 312
21/02/17 01:39:42 INFO ContextCleaner: Cleaned accumulator 315
21/02/17 01:39:42 INFO ContextCleaner: Cleaned accumulator 240
21/02/17 01:39:42 INFO ContextCleaner: Cleaned accumulator 216
21/02/17 01:39:42 INFO ContextCleaner: Cleaned shuffle 2
21/02/17 01:39:42 INFO ContextCleaner: Cleaned accumulator 331
21/02/17 01:39:42 INFO ContextCleaner: Cleaned accumulator 421
21/02/17 01:39:42 INFO ContextCleaner: Cleaned accumulator 352
21/02/17 01:39:42 INFO ContextCleaner: Cleaned accumulator 408
21/02/17 01:39:42 INFO ContextCleaner: Cleaned accumulator 298
21/02/17 01:39:42 INFO ContextCleaner: Cleaned accumulator 336
21/02/17 01:39:42 INFO ContextCleaner: Cleaned accumulator 340
21/02/17 01:39:42 INFO ContextCleaner: Cleaned accumulator 274
21/02/17 01:39:42 INFO ContextCleaner: Cleaned accumulator 258
21/02/17 01:39:42 INFO ContextCleaner: Cleaned accumulator 279
21/02/17 01:39:42 INFO ContextCleaner: Cleaned accumulator 440
21/02/17 01:39:42 INFO ContextCleaner: Cleaned accumulator 355
21/02/17 01:39:42 INFO ContextCleaner: Cleaned accumulator 229
21/02/17 01:39:42 INFO ContextCleaner: Cleaned accumulator 285
21/02/17 01:39:42 INFO ContextCleaner: Cleaned accumulator 305
21/02/17 01:39:42 INFO ContextCleaner: Cleaned accumulator 430
21/02/17 01:39:42 INFO ContextCleaner: Cleaned accumulator 437
21/02/17 01:39:42 INFO ContextCleaner: Cleaned accumulator 374
21/02/17 01:39:42 INFO ContextCleaner: Cleaned accumulator 369
21/02/17 01:39:42 INFO ContextCleaner: Cleaned accumulator 342
21/02/17 01:39:42 INFO ContextCleaner: Cleaned accumulator 364
21/02/17 01:39:42 INFO ContextCleaner: Cleaned accumulator 341
21/02/17 01:39:42 INFO ContextCleaner: Cleaned accumulator 372
21/02/17 01:39:42 INFO ContextCleaner: Cleaned accumulator 353
21/02/17 01:39:42 INFO ContextCleaner: Cleaned accumulator 435
21/02/17 01:39:42 INFO ContextCleaner: Cleaned accumulator 380
21/02/17 01:39:42 INFO ContextCleaner: Cleaned accumulator 245
21/02/17 01:39:42 INFO ContextCleaner: Cleaned accumulator 360
21/02/17 01:39:42 INFO ContextCleaner: Cleaned accumulator 214
21/02/17 01:39:42 INFO ContextCleaner: Cleaned accumulator 268
21/02/17 01:39:42 INFO ContextCleaner: Cleaned accumulator 448
21/02/17 01:39:42 INFO ContextCleaner: Cleaned accumulator 418
21/02/17 01:39:42 INFO BlockManagerInfo: Removed broadcast_8_piece0 on localhost:37301 in memory (size: 13.7 KB, free: 912.2 MB)
21/02/17 01:39:42 INFO ContextCleaner: Cleaned accumulator 335
21/02/17 01:39:42 INFO ContextCleaner: Cleaned accumulator 220
21/02/17 01:39:42 INFO ContextCleaner: Cleaned accumulator 375
21/02/17 01:39:42 INFO BlockManagerInfo: Removed broadcast_10_piece0 on localhost:37301 in memory (size: 3.3 KB, free: 912.2 MB)
21/02/17 01:39:42 INFO ContextCleaner: Cleaned accumulator 259
21/02/17 01:39:42 INFO ContextCleaner: Cleaned accumulator 411
21/02/17 01:39:42 INFO ContextCleaner: Cleaned accumulator 427
21/02/17 01:39:42 INFO BlockManagerInfo: Removed broadcast_7_piece0 on localhost:37301 in memory (size: 13.6 KB, free: 912.2 MB)
21/02/17 01:39:42 INFO ContextCleaner: Cleaned accumulator 264
21/02/17 01:39:42 INFO ContextCleaner: Cleaned accumulator 405
21/02/17 01:39:42 INFO ContextCleaner: Cleaned accumulator 398
21/02/17 01:39:42 INFO ContextCleaner: Cleaned accumulator 346
21/02/17 01:39:42 INFO ContextCleaner: Cleaned accumulator 235
21/02/17 01:39:42 INFO ContextCleaner: Cleaned accumulator 350
21/02/17 01:39:42 INFO ContextCleaner: Cleaned accumulator 292
21/02/17 01:39:42 INFO ContextCleaner: Cleaned accumulator 303
21/02/17 01:39:42 INFO ContextCleaner: Cleaned accumulator 384
21/02/17 01:39:42 INFO ContextCleaner: Cleaned accumulator 449
21/02/17 01:39:42 INFO ContextCleaner: Cleaned accumulator 223
21/02/17 01:39:42 INFO ContextCleaner: Cleaned accumulator 339
21/02/17 01:39:42 INFO ContextCleaner: Cleaned accumulator 334
21/02/17 01:39:42 INFO ContextCleaner: Cleaned accumulator 426
21/02/17 01:39:42 INFO ContextCleaner: Cleaned accumulator 358
21/02/17 01:39:42 INFO ContextCleaner: Cleaned accumulator 361
21/02/17 01:39:42 INFO ContextCleaner: Cleaned accumulator 238
21/02/17 01:39:42 INFO ContextCleaner: Cleaned accumulator 308
21/02/17 01:39:42 INFO ContextCleaner: Cleaned accumulator 276
21/02/17 01:39:42 INFO ContextCleaner: Cleaned accumulator 317
21/02/17 01:39:42 INFO ContextCleaner: Cleaned accumulator 221
21/02/17 01:39:42 INFO ContextCleaner: Cleaned accumulator 283
21/02/17 01:39:42 INFO ContextCleaner: Cleaned accumulator 403
21/02/17 01:39:42 INFO ContextCleaner: Cleaned accumulator 371
21/02/17 01:39:42 INFO ContextCleaner: Cleaned accumulator 316
21/02/17 01:39:42 INFO ContextCleaner: Cleaned accumulator 282
21/02/17 01:39:42 INFO ContextCleaner: Cleaned accumulator 415
21/02/17 01:39:42 INFO BlockManagerInfo: Removed broadcast_14_piece0 on localhost:37301 in memory (size: 26.0 KB, free: 912.3 MB)
21/02/17 01:39:42 INFO ContextCleaner: Cleaned accumulator 407
21/02/17 01:39:42 INFO BlockManagerInfo: Removed broadcast_13_piece0 on localhost:37301 in memory (size: 25.5 KB, free: 912.3 MB)
21/02/17 01:39:42 INFO BlockManagerInfo: Removed broadcast_15_piece0 on localhost:37301 in memory (size: 3.8 KB, free: 912.3 MB)
21/02/17 01:39:42 INFO ContextCleaner: Cleaned accumulator 332
21/02/17 01:39:42 INFO BlockManagerInfo: Removed broadcast_12_piece0 on localhost:37301 in memory (size: 3.8 KB, free: 912.3 MB)
21/02/17 01:39:42 INFO ContextCleaner: Cleaned accumulator 310
21/02/17 01:39:42 INFO ContextCleaner: Cleaned accumulator 263
21/02/17 01:39:42 INFO ContextCleaner: Cleaned accumulator 414
21/02/17 01:39:42 INFO ContextCleaner: Cleaned accumulator 239
21/02/17 01:39:42 INFO ContextCleaner: Cleaned accumulator 377
21/02/17 01:39:42 INFO ContextCleaner: Cleaned accumulator 256
21/02/17 01:39:42 INFO ContextCleaner: Cleaned accumulator 231
21/02/17 01:39:42 INFO ContextCleaner: Cleaned accumulator 376
21/02/17 01:39:42 INFO ContextCleaner: Cleaned accumulator 255
21/02/17 01:39:42 INFO ContextCleaner: Cleaned accumulator 270
21/02/17 01:39:42 INFO ContextCleaner: Cleaned accumulator 293
21/02/17 01:39:42 INFO ContextCleaner: Cleaned accumulator 399
21/02/17 01:39:42 INFO ContextCleaner: Cleaned accumulator 357
21/02/17 01:39:42 INFO ContextCleaner: Cleaned accumulator 261
21/02/17 01:39:42 INFO ContextCleaner: Cleaned accumulator 412
21/02/17 01:39:42 INFO ContextCleaner: Cleaned accumulator 236
21/02/17 01:39:42 INFO ContextCleaner: Cleaned accumulator 290
21/02/17 01:39:42 INFO ContextCleaner: Cleaned accumulator 253
21/02/17 01:39:42 INFO ContextCleaner: Cleaned accumulator 269
21/02/17 01:39:42 INFO ContextCleaner: Cleaned accumulator 277
21/02/17 01:39:42 INFO ContextCleaner: Cleaned accumulator 287
21/02/17 01:39:42 INFO ContextCleaner: Cleaned accumulator 286
21/02/17 01:39:42 INFO ContextCleaner: Cleaned accumulator 296
21/02/17 01:39:42 INFO ContextCleaner: Cleaned accumulator 431
21/02/17 01:39:42 INFO ContextCleaner: Cleaned accumulator 248
21/02/17 01:39:42 INFO ContextCleaner: Cleaned accumulator 224
21/02/17 01:39:42 INFO ContextCleaner: Cleaned accumulator 304
21/02/17 01:39:42 INFO ContextCleaner: Cleaned accumulator 401
21/02/17 01:39:42 INFO ContextCleaner: Cleaned accumulator 445
21/02/17 01:39:42 INFO ContextCleaner: Cleaned accumulator 363
21/02/17 01:39:42 INFO ContextCleaner: Cleaned accumulator 394
21/02/17 01:39:42 INFO ContextCleaner: Cleaned accumulator 218
21/02/17 01:39:42 INFO ContextCleaner: Cleaned accumulator 288
21/02/17 01:39:42 INFO ContextCleaner: Cleaned accumulator 299
21/02/17 01:39:42 INFO ContextCleaner: Cleaned accumulator 436
21/02/17 01:39:42 INFO ContextCleaner: Cleaned accumulator 382
21/02/17 01:39:42 INFO ContextCleaner: Cleaned accumulator 314
21/02/17 01:39:42 INFO ContextCleaner: Cleaned accumulator 354
21/02/17 01:39:42 INFO ContextCleaner: Cleaned accumulator 373
21/02/17 01:39:42 INFO ContextCleaner: Cleaned accumulator 438
21/02/17 01:39:42 INFO ContextCleaner: Cleaned accumulator 272
21/02/17 01:39:42 INFO ContextCleaner: Cleaned accumulator 446
21/02/17 01:39:42 INFO ContextCleaner: Cleaned accumulator 420
21/02/17 01:39:42 INFO ContextCleaner: Cleaned accumulator 273
21/02/17 01:39:42 INFO ContextCleaner: Cleaned accumulator 385
21/02/17 01:39:42 INFO ContextCleaner: Cleaned accumulator 367
21/02/17 01:39:42 INFO ContextCleaner: Cleaned accumulator 416
21/02/17 01:39:42 INFO ContextCleaner: Cleaned accumulator 217
21/02/17 01:39:42 INFO ContextCleaner: Cleaned accumulator 442
21/02/17 01:39:42 INFO ContextCleaner: Cleaned accumulator 322
21/02/17 01:39:42 INFO ContextCleaner: Cleaned accumulator 396
21/02/17 01:39:42 INFO ContextCleaner: Cleaned accumulator 393
21/02/17 01:39:42 INFO ContextCleaner: Cleaned accumulator 227
21/02/17 01:39:42 INFO ContextCleaner: Cleaned accumulator 215
21/02/17 01:39:42 INFO ContextCleaner: Cleaned accumulator 383
21/02/17 01:39:42 INFO ContextCleaner: Cleaned accumulator 301
21/02/17 01:39:42 INFO SparkContext: Starting job: runJob at SparkHadoopWriter.scala:78
21/02/17 01:39:42 INFO BlockManager: Removing RDD 35
21/02/17 01:39:42 INFO DAGScheduler: Got job 11 (runJob at SparkHadoopWriter.scala:78) with 1 output partitions
21/02/17 01:39:42 INFO DAGScheduler: Final stage: ResultStage 15 (runJob at SparkHadoopWriter.scala:78)
21/02/17 01:39:42 INFO DAGScheduler: Parents of final stage: List()
21/02/17 01:39:42 INFO DAGScheduler: Missing parents: List()
21/02/17 01:39:42 INFO DAGScheduler: Submitting ResultStage 15 (MapPartitionsRDD[63] at saveAsTextFile at ReadWrite.scala:441), which has no missing parents
21/02/17 01:39:42 INFO ContextCleaner: Cleaned RDD 35
21/02/17 01:39:42 INFO ContextCleaner: Cleaned accumulator 387
21/02/17 01:39:42 INFO ContextCleaner: Cleaned accumulator 280
21/02/17 01:39:42 INFO ContextCleaner: Cleaned accumulator 344
21/02/17 01:39:42 INFO ContextCleaner: Cleaned accumulator 252
21/02/17 01:39:42 INFO ContextCleaner: Cleaned accumulator 402
21/02/17 01:39:42 INFO ContextCleaner: Cleaned accumulator 319
21/02/17 01:39:42 INFO ContextCleaner: Cleaned accumulator 320
21/02/17 01:39:42 INFO ContextCleaner: Cleaned accumulator 327
21/02/17 01:39:42 INFO ContextCleaner: Cleaned accumulator 379
21/02/17 01:39:42 INFO ContextCleaner: Cleaned accumulator 226
21/02/17 01:39:42 INFO ContextCleaner: Cleaned accumulator 247
21/02/17 01:39:42 INFO ContextCleaner: Cleaned accumulator 262
21/02/17 01:39:42 INFO ContextCleaner: Cleaned accumulator 318
21/02/17 01:39:42 INFO ContextCleaner: Cleaned accumulator 397
21/02/17 01:39:42 INFO ContextCleaner: Cleaned accumulator 348
21/02/17 01:39:42 INFO ContextCleaner: Cleaned accumulator 424
21/02/17 01:39:42 INFO ContextCleaner: Cleaned accumulator 289
21/02/17 01:39:42 INFO ContextCleaner: Cleaned accumulator 439
21/02/17 01:39:42 INFO ContextCleaner: Cleaned accumulator 330
21/02/17 01:39:42 INFO ContextCleaner: Cleaned accumulator 386
21/02/17 01:39:42 INFO ContextCleaner: Cleaned accumulator 250
21/02/17 01:39:42 INFO ContextCleaner: Cleaned accumulator 404
21/02/17 01:39:42 INFO ContextCleaner: Cleaned accumulator 409
21/02/17 01:39:42 INFO ContextCleaner: Cleaned accumulator 389
21/02/17 01:39:42 INFO ContextCleaner: Cleaned accumulator 241
21/02/17 01:39:42 INFO ContextCleaner: Cleaned accumulator 254
21/02/17 01:39:42 INFO ContextCleaner: Cleaned accumulator 278
21/02/17 01:39:42 INFO ContextCleaner: Cleaned accumulator 351
21/02/17 01:39:42 INFO ContextCleaner: Cleaned accumulator 451
21/02/17 01:39:42 INFO ContextCleaner: Cleaned accumulator 232
21/02/17 01:39:42 INFO ContextCleaner: Cleaned accumulator 347
21/02/17 01:39:42 INFO ContextCleaner: Cleaned accumulator 434
21/02/17 01:39:42 INFO ContextCleaner: Cleaned accumulator 244
21/02/17 01:39:42 INFO ContextCleaner: Cleaned accumulator 428
21/02/17 01:39:42 INFO ContextCleaner: Cleaned accumulator 237
21/02/17 01:39:42 INFO ContextCleaner: Cleaned accumulator 417
21/02/17 01:39:42 INFO ContextCleaner: Cleaned accumulator 400
21/02/17 01:39:42 INFO ContextCleaner: Cleaned accumulator 242
21/02/17 01:39:42 INFO ContextCleaner: Cleaned accumulator 251
21/02/17 01:39:42 INFO ContextCleaner: Cleaned accumulator 300
21/02/17 01:39:42 INFO ContextCleaner: Cleaned accumulator 260
21/02/17 01:39:42 INFO ContextCleaner: Cleaned accumulator 349
21/02/17 01:39:42 INFO ContextCleaner: Cleaned accumulator 395
21/02/17 01:39:42 INFO ContextCleaner: Cleaned accumulator 333
21/02/17 01:39:42 INFO ContextCleaner: Cleaned accumulator 234
21/02/17 01:39:42 INFO ContextCleaner: Cleaned accumulator 345
21/02/17 01:39:42 INFO ContextCleaner: Cleaned shuffle 3
21/02/17 01:39:42 INFO ContextCleaner: Cleaned accumulator 356
21/02/17 01:39:42 INFO ContextCleaner: Cleaned accumulator 368
21/02/17 01:39:42 INFO ContextCleaner: Cleaned accumulator 406
21/02/17 01:39:42 INFO ContextCleaner: Cleaned accumulator 366
21/02/17 01:39:42 INFO ContextCleaner: Cleaned accumulator 324
21/02/17 01:39:42 INFO ContextCleaner: Cleaned accumulator 444
21/02/17 01:39:42 INFO ContextCleaner: Cleaned accumulator 321
21/02/17 01:39:42 INFO ContextCleaner: Cleaned accumulator 423
21/02/17 01:39:42 INFO ContextCleaner: Cleaned accumulator 425
21/02/17 01:39:42 INFO ContextCleaner: Cleaned accumulator 284
21/02/17 01:39:42 INFO ContextCleaner: Cleaned accumulator 432
21/02/17 01:39:42 INFO ContextCleaner: Cleaned accumulator 392
21/02/17 01:39:42 INFO ContextCleaner: Cleaned accumulator 441
21/02/17 01:39:42 INFO ContextCleaner: Cleaned accumulator 391
21/02/17 01:39:42 INFO ContextCleaner: Cleaned accumulator 281
21/02/17 01:39:42 INFO ContextCleaner: Cleaned accumulator 230
21/02/17 01:39:42 INFO ContextCleaner: Cleaned accumulator 429
21/02/17 01:39:42 INFO ContextCleaner: Cleaned accumulator 294
21/02/17 01:39:42 INFO ContextCleaner: Cleaned accumulator 225
21/02/17 01:39:42 INFO ContextCleaner: Cleaned accumulator 297
21/02/17 01:39:42 INFO ContextCleaner: Cleaned accumulator 365
21/02/17 01:39:42 INFO ContextCleaner: Cleaned accumulator 313
21/02/17 01:39:42 INFO ContextCleaner: Cleaned accumulator 410
21/02/17 01:39:42 INFO ContextCleaner: Cleaned accumulator 370
21/02/17 01:39:42 INFO ContextCleaner: Cleaned accumulator 213
21/02/17 01:39:42 INFO ContextCleaner: Cleaned accumulator 243
21/02/17 01:39:42 INFO ContextCleaner: Cleaned accumulator 328
21/02/17 01:39:42 INFO ContextCleaner: Cleaned accumulator 257
21/02/17 01:39:42 INFO ContextCleaner: Cleaned accumulator 295
21/02/17 01:39:42 INFO ContextCleaner: Cleaned accumulator 326
21/02/17 01:39:42 INFO ContextCleaner: Cleaned accumulator 302
21/02/17 01:39:42 INFO ContextCleaner: Cleaned accumulator 337
21/02/17 01:39:42 INFO ContextCleaner: Cleaned accumulator 338
21/02/17 01:39:42 INFO ContextCleaner: Cleaned accumulator 388
21/02/17 01:39:42 INFO ContextCleaner: Cleaned accumulator 211
21/02/17 01:39:42 INFO BlockManagerInfo: Removed broadcast_11_piece0 on localhost:37301 in memory (size: 4.5 KB, free: 912.3 MB)
21/02/17 01:39:42 INFO ContextCleaner: Cleaned accumulator 222
21/02/17 01:39:42 INFO ContextCleaner: Cleaned accumulator 362
21/02/17 01:39:42 INFO ContextCleaner: Cleaned accumulator 219
21/02/17 01:39:42 INFO ContextCleaner: Cleaned accumulator 419
21/02/17 01:39:42 INFO ContextCleaner: Cleaned accumulator 249
21/02/17 01:39:42 INFO ContextCleaner: Cleaned accumulator 433
21/02/17 01:39:42 INFO ContextCleaner: Cleaned accumulator 422
21/02/17 01:39:42 INFO ContextCleaner: Cleaned accumulator 450
21/02/17 01:39:42 INFO ContextCleaner: Cleaned accumulator 325
21/02/17 01:39:42 INFO ContextCleaner: Cleaned accumulator 359
21/02/17 01:39:42 INFO ContextCleaner: Cleaned accumulator 306
21/02/17 01:39:42 INFO MemoryStore: Block broadcast_16 stored as values in memory (estimated size 71.1 KB, free 912.2 MB)
21/02/17 01:39:42 INFO MemoryStore: Block broadcast_16_piece0 stored as bytes in memory (estimated size 25.4 KB, free 912.2 MB)
21/02/17 01:39:42 INFO BlockManagerInfo: Added broadcast_16_piece0 in memory on localhost:37301 (size: 25.4 KB, free: 912.3 MB)
21/02/17 01:39:42 INFO SparkContext: Created broadcast 16 from broadcast at DAGScheduler.scala:1161
21/02/17 01:39:42 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 15 (MapPartitionsRDD[63] at saveAsTextFile at ReadWrite.scala:441) (first 15 tasks are for partitions Vector(0))
21/02/17 01:39:42 INFO TaskSchedulerImpl: Adding task set 15.0 with 1 tasks
21/02/17 01:39:42 INFO TaskSetManager: Starting task 0.0 in stage 15.0 (TID 15, localhost, executor driver, partition 0, PROCESS_LOCAL, 8176 bytes)
21/02/17 01:39:42 INFO Executor: Running task 0.0 in stage 15.0 (TID 15)
21/02/17 01:39:42 INFO HadoopMapRedCommitProtocol: Using output committer class org.apache.hadoop.mapred.FileOutputCommitter
21/02/17 01:39:42 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
21/02/17 01:39:42 INFO FileOutputCommitter: Saved output of task 'attempt_20210217013942_0063_m_000000_0' to file:/tmp/RtmpaHGCHH/file22ad95b56a718/metadata/_temporary/0/task_20210217013942_0063_m_000000
21/02/17 01:39:42 INFO SparkHadoopMapRedUtil: attempt_20210217013942_0063_m_000000_0: Committed
21/02/17 01:39:42 INFO Executor: Finished task 0.0 in stage 15.0 (TID 15). 1072 bytes result sent to driver
21/02/17 01:39:42 INFO TaskSetManager: Finished task 0.0 in stage 15.0 (TID 15) in 40 ms on localhost (executor driver) (1/1)
21/02/17 01:39:42 INFO TaskSchedulerImpl: Removed TaskSet 15.0, whose tasks have all completed, from pool 
21/02/17 01:39:42 INFO DAGScheduler: ResultStage 15 (runJob at SparkHadoopWriter.scala:78) finished in 0.056 s
21/02/17 01:39:42 INFO DAGScheduler: Job 11 finished: runJob at SparkHadoopWriter.scala:78, took 0.057652 s
21/02/17 01:39:42 INFO SparkHadoopWriter: Job job_20210217013942_0063 committed.
21/02/17 01:39:42 INFO HadoopMapRedCommitProtocol: Using output committer class org.apache.hadoop.mapred.FileOutputCommitter
21/02/17 01:39:42 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
21/02/17 01:39:42 INFO SparkContext: Starting job: runJob at SparkHadoopWriter.scala:78
21/02/17 01:39:42 INFO DAGScheduler: Got job 12 (runJob at SparkHadoopWriter.scala:78) with 1 output partitions
21/02/17 01:39:42 INFO DAGScheduler: Final stage: ResultStage 16 (runJob at SparkHadoopWriter.scala:78)
21/02/17 01:39:42 INFO DAGScheduler: Parents of final stage: List()
21/02/17 01:39:42 INFO DAGScheduler: Missing parents: List()
21/02/17 01:39:42 INFO DAGScheduler: Submitting ResultStage 16 (MapPartitionsRDD[65] at saveAsTextFile at ReadWrite.scala:441), which has no missing parents
21/02/17 01:39:42 INFO MemoryStore: Block broadcast_17 stored as values in memory (estimated size 71.2 KB, free 912.1 MB)
21/02/17 01:39:42 INFO MemoryStore: Block broadcast_17_piece0 stored as bytes in memory (estimated size 25.5 KB, free 912.1 MB)
21/02/17 01:39:42 INFO BlockManagerInfo: Added broadcast_17_piece0 in memory on localhost:37301 (size: 25.5 KB, free: 912.2 MB)
21/02/17 01:39:42 INFO SparkContext: Created broadcast 17 from broadcast at DAGScheduler.scala:1161
21/02/17 01:39:42 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 16 (MapPartitionsRDD[65] at saveAsTextFile at ReadWrite.scala:441) (first 15 tasks are for partitions Vector(0))
21/02/17 01:39:42 INFO TaskSchedulerImpl: Adding task set 16.0 with 1 tasks
21/02/17 01:39:42 INFO TaskSetManager: Starting task 0.0 in stage 16.0 (TID 16, localhost, executor driver, partition 0, PROCESS_LOCAL, 8317 bytes)
21/02/17 01:39:42 INFO Executor: Running task 0.0 in stage 16.0 (TID 16)
21/02/17 01:39:42 INFO HadoopMapRedCommitProtocol: Using output committer class org.apache.hadoop.mapred.FileOutputCommitter
21/02/17 01:39:42 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
21/02/17 01:39:42 INFO FileOutputCommitter: Saved output of task 'attempt_20210217013942_0065_m_000000_0' to file:/tmp/RtmpaHGCHH/file22ad95b56a718/stages/0_r_formula__8eae6edf_b16e_4036_a8d6_baf58826f8d0/metadata/_temporary/0/task_20210217013942_0065_m_000000
21/02/17 01:39:42 INFO SparkHadoopMapRedUtil: attempt_20210217013942_0065_m_000000_0: Committed
21/02/17 01:39:42 INFO Executor: Finished task 0.0 in stage 16.0 (TID 16). 1029 bytes result sent to driver
21/02/17 01:39:42 INFO TaskSetManager: Finished task 0.0 in stage 16.0 (TID 16) in 14 ms on localhost (executor driver) (1/1)
21/02/17 01:39:42 INFO TaskSchedulerImpl: Removed TaskSet 16.0, whose tasks have all completed, from pool 
21/02/17 01:39:42 INFO DAGScheduler: ResultStage 16 (runJob at SparkHadoopWriter.scala:78) finished in 0.025 s
21/02/17 01:39:42 INFO DAGScheduler: Job 12 finished: runJob at SparkHadoopWriter.scala:78, took 0.026535 s
21/02/17 01:39:42 INFO SparkHadoopWriter: Job job_20210217013942_0065 committed.
21/02/17 01:39:42 INFO ParquetFileFormat: Using default output committer for Parquet: org.apache.parquet.hadoop.ParquetOutputCommitter
21/02/17 01:39:42 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
21/02/17 01:39:42 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
21/02/17 01:39:42 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
21/02/17 01:39:42 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
21/02/17 01:39:42 INFO CodeGenerator: Code generated in 8.222305 ms
21/02/17 01:39:42 INFO SparkContext: Starting job: parquet at RFormula.scala:422
21/02/17 01:39:42 INFO DAGScheduler: Registering RDD 68 (parquet at RFormula.scala:422)
21/02/17 01:39:42 INFO DAGScheduler: Got job 13 (parquet at RFormula.scala:422) with 1 output partitions
21/02/17 01:39:42 INFO DAGScheduler: Final stage: ResultStage 18 (parquet at RFormula.scala:422)
21/02/17 01:39:42 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 17)
21/02/17 01:39:42 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 17)
21/02/17 01:39:42 INFO DAGScheduler: Submitting ShuffleMapStage 17 (MapPartitionsRDD[68] at parquet at RFormula.scala:422), which has no missing parents
21/02/17 01:39:42 INFO MemoryStore: Block broadcast_18 stored as values in memory (estimated size 5.0 KB, free 912.1 MB)
21/02/17 01:39:42 INFO MemoryStore: Block broadcast_18_piece0 stored as bytes in memory (estimated size 3.0 KB, free 912.1 MB)
21/02/17 01:39:42 INFO BlockManagerInfo: Added broadcast_18_piece0 in memory on localhost:37301 (size: 3.0 KB, free: 912.2 MB)
21/02/17 01:39:42 INFO SparkContext: Created broadcast 18 from broadcast at DAGScheduler.scala:1161
21/02/17 01:39:42 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 17 (MapPartitionsRDD[68] at parquet at RFormula.scala:422) (first 15 tasks are for partitions Vector(0))
21/02/17 01:39:42 INFO TaskSchedulerImpl: Adding task set 17.0 with 1 tasks
21/02/17 01:39:42 INFO TaskSetManager: Starting task 0.0 in stage 17.0 (TID 17, localhost, executor driver, partition 0, PROCESS_LOCAL, 8177 bytes)
21/02/17 01:39:42 INFO Executor: Running task 0.0 in stage 17.0 (TID 17)
21/02/17 01:39:42 INFO Executor: Finished task 0.0 in stage 17.0 (TID 17). 1247 bytes result sent to driver
21/02/17 01:39:42 INFO TaskSetManager: Finished task 0.0 in stage 17.0 (TID 17) in 5 ms on localhost (executor driver) (1/1)
21/02/17 01:39:42 INFO TaskSchedulerImpl: Removed TaskSet 17.0, whose tasks have all completed, from pool 
21/02/17 01:39:42 INFO DAGScheduler: ShuffleMapStage 17 (parquet at RFormula.scala:422) finished in 0.011 s
21/02/17 01:39:42 INFO DAGScheduler: looking for newly runnable stages
21/02/17 01:39:42 INFO DAGScheduler: running: Set()
21/02/17 01:39:42 INFO DAGScheduler: waiting: Set(ResultStage 18)
21/02/17 01:39:42 INFO DAGScheduler: failed: Set()
21/02/17 01:39:42 INFO DAGScheduler: Submitting ResultStage 18 (ShuffledRowRDD[69] at parquet at RFormula.scala:422), which has no missing parents
21/02/17 01:39:42 INFO MemoryStore: Block broadcast_19 stored as values in memory (estimated size 151.0 KB, free 911.9 MB)
21/02/17 01:39:42 INFO MemoryStore: Block broadcast_19_piece0 stored as bytes in memory (estimated size 53.6 KB, free 911.9 MB)
21/02/17 01:39:42 INFO BlockManagerInfo: Added broadcast_19_piece0 in memory on localhost:37301 (size: 53.6 KB, free: 912.2 MB)
21/02/17 01:39:42 INFO SparkContext: Created broadcast 19 from broadcast at DAGScheduler.scala:1161
21/02/17 01:39:42 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 18 (ShuffledRowRDD[69] at parquet at RFormula.scala:422) (first 15 tasks are for partitions Vector(0))
21/02/17 01:39:42 INFO TaskSchedulerImpl: Adding task set 18.0 with 1 tasks
21/02/17 01:39:42 INFO TaskSetManager: Starting task 0.0 in stage 18.0 (TID 18, localhost, executor driver, partition 0, NODE_LOCAL, 7767 bytes)
21/02/17 01:39:42 INFO Executor: Running task 0.0 in stage 18.0 (TID 18)
21/02/17 01:39:42 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks including 1 local blocks and 0 remote blocks
21/02/17 01:39:42 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
21/02/17 01:39:42 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
21/02/17 01:39:42 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
21/02/17 01:39:42 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
21/02/17 01:39:42 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
21/02/17 01:39:42 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:
{
  "type" : "struct",
  "fields" : [ {
    "name" : "label",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "terms",
    "type" : {
      "type" : "array",
      "elementType" : {
        "type" : "array",
        "elementType" : "string",
        "containsNull" : true
      },
      "containsNull" : true
    },
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "hasIntercept",
    "type" : "boolean",
    "nullable" : false,
    "metadata" : { }
  } ]
}
and corresponding Parquet message type:
message spark_schema {
  optional binary label (UTF8);
  optional group terms (LIST) {
    repeated group list {
      optional group element (LIST) {
        repeated group list {
          optional binary element (UTF8);
        }
      }
    }
  }
  required boolean hasIntercept;
}

       
21/02/17 01:39:42 INFO CodecPool: Got brand-new compressor [.snappy]
21/02/17 01:39:43 INFO FileOutputCommitter: Saved output of task 'attempt_20210217013942_0018_m_000000_18' to file:/tmp/RtmpaHGCHH/file22ad95b56a718/stages/0_r_formula__8eae6edf_b16e_4036_a8d6_baf58826f8d0/data/_temporary/0/task_20210217013942_0018_m_000000
21/02/17 01:39:43 INFO SparkHadoopMapRedUtil: attempt_20210217013942_0018_m_000000_18: Committed
21/02/17 01:39:43 INFO Executor: Finished task 0.0 in stage 18.0 (TID 18). 2334 bytes result sent to driver
21/02/17 01:39:43 INFO TaskSetManager: Finished task 0.0 in stage 18.0 (TID 18) in 354 ms on localhost (executor driver) (1/1)
21/02/17 01:39:43 INFO TaskSchedulerImpl: Removed TaskSet 18.0, whose tasks have all completed, from pool 
21/02/17 01:39:43 INFO DAGScheduler: ResultStage 18 (parquet at RFormula.scala:422) finished in 0.374 s
21/02/17 01:39:43 INFO DAGScheduler: Job 13 finished: parquet at RFormula.scala:422, took 0.388869 s
21/02/17 01:39:43 INFO FileFormatWriter: Write Job bcd7c6e4-067e-44ca-8503-b007f9c5b7ba committed.
21/02/17 01:39:43 INFO FileFormatWriter: Finished processing stats for write job bcd7c6e4-067e-44ca-8503-b007f9c5b7ba.
21/02/17 01:39:43 INFO HadoopMapRedCommitProtocol: Using output committer class org.apache.hadoop.mapred.FileOutputCommitter
21/02/17 01:39:43 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
21/02/17 01:39:43 INFO SparkContext: Starting job: runJob at SparkHadoopWriter.scala:78
21/02/17 01:39:43 INFO DAGScheduler: Got job 14 (runJob at SparkHadoopWriter.scala:78) with 1 output partitions
21/02/17 01:39:43 INFO DAGScheduler: Final stage: ResultStage 19 (runJob at SparkHadoopWriter.scala:78)
21/02/17 01:39:43 INFO DAGScheduler: Parents of final stage: List()
21/02/17 01:39:43 INFO DAGScheduler: Missing parents: List()
21/02/17 01:39:43 INFO DAGScheduler: Submitting ResultStage 19 (MapPartitionsRDD[72] at saveAsTextFile at ReadWrite.scala:441), which has no missing parents
21/02/17 01:39:43 INFO MemoryStore: Block broadcast_20 stored as values in memory (estimated size 71.3 KB, free 911.8 MB)
21/02/17 01:39:43 INFO MemoryStore: Block broadcast_20_piece0 stored as bytes in memory (estimated size 25.6 KB, free 911.8 MB)
21/02/17 01:39:43 INFO BlockManagerInfo: Added broadcast_20_piece0 in memory on localhost:37301 (size: 25.6 KB, free: 912.2 MB)
21/02/17 01:39:43 INFO SparkContext: Created broadcast 20 from broadcast at DAGScheduler.scala:1161
21/02/17 01:39:43 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 19 (MapPartitionsRDD[72] at saveAsTextFile at ReadWrite.scala:441) (first 15 tasks are for partitions Vector(0))
21/02/17 01:39:43 INFO TaskSchedulerImpl: Adding task set 19.0 with 1 tasks
21/02/17 01:39:43 INFO TaskSetManager: Starting task 0.0 in stage 19.0 (TID 19, localhost, executor driver, partition 0, PROCESS_LOCAL, 8181 bytes)
21/02/17 01:39:43 INFO Executor: Running task 0.0 in stage 19.0 (TID 19)
21/02/17 01:39:43 INFO HadoopMapRedCommitProtocol: Using output committer class org.apache.hadoop.mapred.FileOutputCommitter
21/02/17 01:39:43 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
21/02/17 01:39:43 INFO FileOutputCommitter: Saved output of task 'attempt_20210217013943_0072_m_000000_0' to file:/tmp/RtmpaHGCHH/file22ad95b56a718/stages/0_r_formula__8eae6edf_b16e_4036_a8d6_baf58826f8d0/pipelineModel/metadata/_temporary/0/task_20210217013943_0072_m_000000
21/02/17 01:39:43 INFO SparkHadoopMapRedUtil: attempt_20210217013943_0072_m_000000_0: Committed
21/02/17 01:39:43 INFO Executor: Finished task 0.0 in stage 19.0 (TID 19). 1029 bytes result sent to driver
21/02/17 01:39:43 INFO TaskSetManager: Finished task 0.0 in stage 19.0 (TID 19) in 17 ms on localhost (executor driver) (1/1)
21/02/17 01:39:43 INFO TaskSchedulerImpl: Removed TaskSet 19.0, whose tasks have all completed, from pool 
21/02/17 01:39:43 INFO DAGScheduler: ResultStage 19 (runJob at SparkHadoopWriter.scala:78) finished in 0.032 s
21/02/17 01:39:43 INFO DAGScheduler: Job 14 finished: runJob at SparkHadoopWriter.scala:78, took 0.034314 s
21/02/17 01:39:43 INFO SparkHadoopWriter: Job job_20210217013943_0072 committed.
21/02/17 01:39:43 INFO HadoopMapRedCommitProtocol: Using output committer class org.apache.hadoop.mapred.FileOutputCommitter
21/02/17 01:39:43 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
21/02/17 01:39:43 INFO SparkContext: Starting job: runJob at SparkHadoopWriter.scala:78
21/02/17 01:39:43 INFO DAGScheduler: Got job 15 (runJob at SparkHadoopWriter.scala:78) with 1 output partitions
21/02/17 01:39:43 INFO DAGScheduler: Final stage: ResultStage 20 (runJob at SparkHadoopWriter.scala:78)
21/02/17 01:39:43 INFO DAGScheduler: Parents of final stage: List()
21/02/17 01:39:43 INFO DAGScheduler: Missing parents: List()
21/02/17 01:39:43 INFO DAGScheduler: Submitting ResultStage 20 (MapPartitionsRDD[74] at saveAsTextFile at ReadWrite.scala:441), which has no missing parents
21/02/17 01:39:43 INFO MemoryStore: Block broadcast_21 stored as values in memory (estimated size 71.4 KB, free 911.7 MB)
21/02/17 01:39:43 INFO MemoryStore: Block broadcast_21_piece0 stored as bytes in memory (estimated size 25.5 KB, free 911.7 MB)
21/02/17 01:39:43 INFO BlockManagerInfo: Added broadcast_21_piece0 in memory on localhost:37301 (size: 25.5 KB, free: 912.1 MB)
21/02/17 01:39:43 INFO SparkContext: Created broadcast 21 from broadcast at DAGScheduler.scala:1161
21/02/17 01:39:43 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 20 (MapPartitionsRDD[74] at saveAsTextFile at ReadWrite.scala:441) (first 15 tasks are for partitions Vector(0))
21/02/17 01:39:43 INFO TaskSchedulerImpl: Adding task set 20.0 with 1 tasks
21/02/17 01:39:43 INFO TaskSetManager: Starting task 0.0 in stage 20.0 (TID 20, localhost, executor driver, partition 0, PROCESS_LOCAL, 8248 bytes)
21/02/17 01:39:43 INFO Executor: Running task 0.0 in stage 20.0 (TID 20)
21/02/17 01:39:43 INFO HadoopMapRedCommitProtocol: Using output committer class org.apache.hadoop.mapred.FileOutputCommitter
21/02/17 01:39:43 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
21/02/17 01:39:43 INFO FileOutputCommitter: Saved output of task 'attempt_20210217013943_0074_m_000000_0' to file:/tmp/RtmpaHGCHH/file22ad95b56a718/stages/0_r_formula__8eae6edf_b16e_4036_a8d6_baf58826f8d0/pipelineModel/stages/0_r_formula__8eae6edf_b16e_4036_a8d6_baf58826f8d0/metadata/_temporary/0/task_20210217013943_0074_m_000000
21/02/17 01:39:43 INFO SparkHadoopMapRedUtil: attempt_20210217013943_0074_m_000000_0: Committed
21/02/17 01:39:43 INFO Executor: Finished task 0.0 in stage 20.0 (TID 20). 1029 bytes result sent to driver
21/02/17 01:39:43 INFO TaskSetManager: Finished task 0.0 in stage 20.0 (TID 20) in 15 ms on localhost (executor driver) (1/1)
21/02/17 01:39:43 INFO TaskSchedulerImpl: Removed TaskSet 20.0, whose tasks have all completed, from pool 
21/02/17 01:39:43 INFO DAGScheduler: ResultStage 20 (runJob at SparkHadoopWriter.scala:78) finished in 0.026 s
21/02/17 01:39:43 INFO DAGScheduler: Job 15 finished: runJob at SparkHadoopWriter.scala:78, took 0.027785 s
21/02/17 01:39:43 INFO SparkHadoopWriter: Job job_20210217013943_0074 committed.
21/02/17 01:39:43 INFO HadoopMapRedCommitProtocol: Using output committer class org.apache.hadoop.mapred.FileOutputCommitter
21/02/17 01:39:43 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
21/02/17 01:39:43 INFO SparkContext: Starting job: runJob at SparkHadoopWriter.scala:78
21/02/17 01:39:43 INFO DAGScheduler: Got job 16 (runJob at SparkHadoopWriter.scala:78) with 1 output partitions
21/02/17 01:39:43 INFO DAGScheduler: Final stage: ResultStage 21 (runJob at SparkHadoopWriter.scala:78)
21/02/17 01:39:43 INFO DAGScheduler: Parents of final stage: List()
21/02/17 01:39:43 INFO DAGScheduler: Missing parents: List()
21/02/17 01:39:43 INFO DAGScheduler: Submitting ResultStage 21 (MapPartitionsRDD[76] at saveAsTextFile at ReadWrite.scala:441), which has no missing parents
21/02/17 01:39:43 INFO MemoryStore: Block broadcast_22 stored as values in memory (estimated size 71.3 KB, free 911.6 MB)
21/02/17 01:39:43 INFO MemoryStore: Block broadcast_22_piece0 stored as bytes in memory (estimated size 25.6 KB, free 911.6 MB)
21/02/17 01:39:43 INFO BlockManagerInfo: Added broadcast_22_piece0 in memory on localhost:37301 (size: 25.6 KB, free: 912.1 MB)
21/02/17 01:39:43 INFO SparkContext: Created broadcast 22 from broadcast at DAGScheduler.scala:1161
21/02/17 01:39:43 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 21 (MapPartitionsRDD[76] at saveAsTextFile at ReadWrite.scala:441) (first 15 tasks are for partitions Vector(0))
21/02/17 01:39:43 INFO TaskSchedulerImpl: Adding task set 21.0 with 1 tasks
21/02/17 01:39:43 INFO TaskSetManager: Starting task 0.0 in stage 21.0 (TID 21, localhost, executor driver, partition 0, PROCESS_LOCAL, 8058 bytes)
21/02/17 01:39:43 INFO Executor: Running task 0.0 in stage 21.0 (TID 21)
21/02/17 01:39:43 INFO HadoopMapRedCommitProtocol: Using output committer class org.apache.hadoop.mapred.FileOutputCommitter
21/02/17 01:39:43 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
21/02/17 01:39:43 INFO FileOutputCommitter: Saved output of task 'attempt_20210217013943_0076_m_000000_0' to file:/tmp/RtmpaHGCHH/file22ad95b56a718/stages/0_r_formula__8eae6edf_b16e_4036_a8d6_baf58826f8d0/pipelineModel/stages/1_vectorAttrRewriter_82617fd1f646/metadata/_temporary/0/task_20210217013943_0076_m_000000
21/02/17 01:39:43 INFO SparkHadoopMapRedUtil: attempt_20210217013943_0076_m_000000_0: Committed
21/02/17 01:39:43 INFO Executor: Finished task 0.0 in stage 21.0 (TID 21). 1029 bytes result sent to driver
21/02/17 01:39:43 INFO TaskSetManager: Finished task 0.0 in stage 21.0 (TID 21) in 13 ms on localhost (executor driver) (1/1)
21/02/17 01:39:43 INFO TaskSchedulerImpl: Removed TaskSet 21.0, whose tasks have all completed, from pool 
21/02/17 01:39:43 INFO DAGScheduler: ResultStage 21 (runJob at SparkHadoopWriter.scala:78) finished in 0.027 s
21/02/17 01:39:43 INFO DAGScheduler: Job 16 finished: runJob at SparkHadoopWriter.scala:78, took 0.028327 s
21/02/17 01:39:43 INFO SparkHadoopWriter: Job job_20210217013943_0076 committed.
21/02/17 01:39:43 INFO ParquetFileFormat: Using default output committer for Parquet: org.apache.parquet.hadoop.ParquetOutputCommitter
21/02/17 01:39:43 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
21/02/17 01:39:43 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
21/02/17 01:39:43 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
21/02/17 01:39:43 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
21/02/17 01:39:43 INFO CodeGenerator: Code generated in 11.058767 ms
21/02/17 01:39:43 INFO SparkContext: Starting job: parquet at RFormula.scala:587
21/02/17 01:39:43 INFO DAGScheduler: Registering RDD 79 (parquet at RFormula.scala:587)
21/02/17 01:39:43 INFO DAGScheduler: Got job 17 (parquet at RFormula.scala:587) with 1 output partitions
21/02/17 01:39:43 INFO DAGScheduler: Final stage: ResultStage 23 (parquet at RFormula.scala:587)
21/02/17 01:39:43 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 22)
21/02/17 01:39:43 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 22)
21/02/17 01:39:43 INFO DAGScheduler: Submitting ShuffleMapStage 22 (MapPartitionsRDD[79] at parquet at RFormula.scala:587), which has no missing parents
21/02/17 01:39:43 INFO MemoryStore: Block broadcast_23 stored as values in memory (estimated size 4.9 KB, free 911.6 MB)
21/02/17 01:39:43 INFO MemoryStore: Block broadcast_23_piece0 stored as bytes in memory (estimated size 3.0 KB, free 911.6 MB)
21/02/17 01:39:43 INFO BlockManagerInfo: Added broadcast_23_piece0 in memory on localhost:37301 (size: 3.0 KB, free: 912.1 MB)
21/02/17 01:39:43 INFO SparkContext: Created broadcast 23 from broadcast at DAGScheduler.scala:1161
21/02/17 01:39:43 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 22 (MapPartitionsRDD[79] at parquet at RFormula.scala:587) (first 15 tasks are for partitions Vector(0))
21/02/17 01:39:43 INFO TaskSchedulerImpl: Adding task set 22.0 with 1 tasks
21/02/17 01:39:43 INFO TaskSetManager: Starting task 0.0 in stage 22.0 (TID 22, localhost, executor driver, partition 0, PROCESS_LOCAL, 8073 bytes)
21/02/17 01:39:43 INFO Executor: Running task 0.0 in stage 22.0 (TID 22)
21/02/17 01:39:43 INFO Executor: Finished task 0.0 in stage 22.0 (TID 22). 1247 bytes result sent to driver
21/02/17 01:39:43 INFO TaskSetManager: Finished task 0.0 in stage 22.0 (TID 22) in 5 ms on localhost (executor driver) (1/1)
21/02/17 01:39:43 INFO TaskSchedulerImpl: Removed TaskSet 22.0, whose tasks have all completed, from pool 
21/02/17 01:39:43 INFO DAGScheduler: ShuffleMapStage 22 (parquet at RFormula.scala:587) finished in 0.010 s
21/02/17 01:39:43 INFO DAGScheduler: looking for newly runnable stages
21/02/17 01:39:43 INFO DAGScheduler: running: Set()
21/02/17 01:39:43 INFO DAGScheduler: waiting: Set(ResultStage 23)
21/02/17 01:39:43 INFO DAGScheduler: failed: Set()
21/02/17 01:39:43 INFO DAGScheduler: Submitting ResultStage 23 (ShuffledRowRDD[80] at parquet at RFormula.scala:587), which has no missing parents
21/02/17 01:39:43 INFO MemoryStore: Block broadcast_24 stored as values in memory (estimated size 151.0 KB, free 911.4 MB)
21/02/17 01:39:43 INFO MemoryStore: Block broadcast_24_piece0 stored as bytes in memory (estimated size 53.6 KB, free 911.4 MB)
21/02/17 01:39:43 INFO BlockManagerInfo: Added broadcast_24_piece0 in memory on localhost:37301 (size: 53.6 KB, free: 912.1 MB)
21/02/17 01:39:43 INFO SparkContext: Created broadcast 24 from broadcast at DAGScheduler.scala:1161
21/02/17 01:39:43 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 23 (ShuffledRowRDD[80] at parquet at RFormula.scala:587) (first 15 tasks are for partitions Vector(0))
21/02/17 01:39:43 INFO TaskSchedulerImpl: Adding task set 23.0 with 1 tasks
21/02/17 01:39:43 INFO TaskSetManager: Starting task 0.0 in stage 23.0 (TID 23, localhost, executor driver, partition 0, NODE_LOCAL, 7767 bytes)
21/02/17 01:39:43 INFO Executor: Running task 0.0 in stage 23.0 (TID 23)
21/02/17 01:39:43 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks including 1 local blocks and 0 remote blocks
21/02/17 01:39:43 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
21/02/17 01:39:43 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
21/02/17 01:39:43 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
21/02/17 01:39:43 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
21/02/17 01:39:43 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
21/02/17 01:39:43 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:
{
  "type" : "struct",
  "fields" : [ {
    "name" : "vectorCol",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "prefixesToRewrite",
    "type" : {
      "type" : "map",
      "keyType" : "string",
      "valueType" : "string",
      "valueContainsNull" : true
    },
    "nullable" : true,
    "metadata" : { }
  } ]
}
and corresponding Parquet message type:
message spark_schema {
  optional binary vectorCol (UTF8);
  optional group prefixesToRewrite (MAP) {
    repeated group key_value {
      required binary key (UTF8);
      optional binary value (UTF8);
    }
  }
}

       
21/02/17 01:39:43 INFO FileOutputCommitter: Saved output of task 'attempt_20210217013943_0023_m_000000_23' to file:/tmp/RtmpaHGCHH/file22ad95b56a718/stages/0_r_formula__8eae6edf_b16e_4036_a8d6_baf58826f8d0/pipelineModel/stages/1_vectorAttrRewriter_82617fd1f646/data/_temporary/0/task_20210217013943_0023_m_000000
21/02/17 01:39:43 INFO SparkHadoopMapRedUtil: attempt_20210217013943_0023_m_000000_23: Committed
21/02/17 01:39:43 INFO Executor: Finished task 0.0 in stage 23.0 (TID 23). 2291 bytes result sent to driver
21/02/17 01:39:43 INFO TaskSetManager: Finished task 0.0 in stage 23.0 (TID 23) in 41 ms on localhost (executor driver) (1/1)
21/02/17 01:39:43 INFO TaskSchedulerImpl: Removed TaskSet 23.0, whose tasks have all completed, from pool 
21/02/17 01:39:43 INFO DAGScheduler: ResultStage 23 (parquet at RFormula.scala:587) finished in 0.064 s
21/02/17 01:39:43 INFO DAGScheduler: Job 17 finished: parquet at RFormula.scala:587, took 0.077053 s
21/02/17 01:39:43 INFO FileFormatWriter: Write Job e08ce49c-58df-4214-b342-aeaf70f7ec68 committed.
21/02/17 01:39:43 INFO FileFormatWriter: Finished processing stats for write job e08ce49c-58df-4214-b342-aeaf70f7ec68.
21/02/17 01:39:43 INFO HadoopMapRedCommitProtocol: Using output committer class org.apache.hadoop.mapred.FileOutputCommitter
21/02/17 01:39:43 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
21/02/17 01:39:43 INFO SparkContext: Starting job: runJob at SparkHadoopWriter.scala:78
21/02/17 01:39:43 INFO DAGScheduler: Got job 18 (runJob at SparkHadoopWriter.scala:78) with 1 output partitions
21/02/17 01:39:43 INFO DAGScheduler: Final stage: ResultStage 24 (runJob at SparkHadoopWriter.scala:78)
21/02/17 01:39:43 INFO DAGScheduler: Parents of final stage: List()
21/02/17 01:39:43 INFO DAGScheduler: Missing parents: List()
21/02/17 01:39:43 INFO DAGScheduler: Submitting ResultStage 24 (MapPartitionsRDD[83] at saveAsTextFile at ReadWrite.scala:441), which has no missing parents
21/02/17 01:39:43 INFO MemoryStore: Block broadcast_25 stored as values in memory (estimated size 71.3 KB, free 911.3 MB)
21/02/17 01:39:43 INFO MemoryStore: Block broadcast_25_piece0 stored as bytes in memory (estimated size 25.6 KB, free 911.3 MB)
21/02/17 01:39:43 INFO BlockManagerInfo: Added broadcast_25_piece0 in memory on localhost:37301 (size: 25.6 KB, free: 912.0 MB)
21/02/17 01:39:43 INFO SparkContext: Created broadcast 25 from broadcast at DAGScheduler.scala:1161
21/02/17 01:39:43 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 24 (MapPartitionsRDD[83] at saveAsTextFile at ReadWrite.scala:441) (first 15 tasks are for partitions Vector(0))
21/02/17 01:39:43 INFO TaskSchedulerImpl: Adding task set 24.0 with 1 tasks
21/02/17 01:39:43 INFO TaskSetManager: Starting task 0.0 in stage 24.0 (TID 24, localhost, executor driver, partition 0, PROCESS_LOCAL, 8041 bytes)
21/02/17 01:39:43 INFO Executor: Running task 0.0 in stage 24.0 (TID 24)
21/02/17 01:39:43 INFO HadoopMapRedCommitProtocol: Using output committer class org.apache.hadoop.mapred.FileOutputCommitter
21/02/17 01:39:43 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
21/02/17 01:39:43 INFO FileOutputCommitter: Saved output of task 'attempt_20210217013943_0083_m_000000_0' to file:/tmp/RtmpaHGCHH/file22ad95b56a718/stages/0_r_formula__8eae6edf_b16e_4036_a8d6_baf58826f8d0/pipelineModel/stages/2_columnPruner_61c178682e95/metadata/_temporary/0/task_20210217013943_0083_m_000000
21/02/17 01:39:43 INFO SparkHadoopMapRedUtil: attempt_20210217013943_0083_m_000000_0: Committed
21/02/17 01:39:43 INFO Executor: Finished task 0.0 in stage 24.0 (TID 24). 1029 bytes result sent to driver
21/02/17 01:39:43 INFO TaskSetManager: Finished task 0.0 in stage 24.0 (TID 24) in 13 ms on localhost (executor driver) (1/1)
21/02/17 01:39:43 INFO TaskSchedulerImpl: Removed TaskSet 24.0, whose tasks have all completed, from pool 
21/02/17 01:39:43 INFO DAGScheduler: ResultStage 24 (runJob at SparkHadoopWriter.scala:78) finished in 0.026 s
21/02/17 01:39:43 INFO DAGScheduler: Job 18 finished: runJob at SparkHadoopWriter.scala:78, took 0.028170 s
21/02/17 01:39:43 INFO SparkHadoopWriter: Job job_20210217013943_0083 committed.
21/02/17 01:39:43 INFO ParquetFileFormat: Using default output committer for Parquet: org.apache.parquet.hadoop.ParquetOutputCommitter
21/02/17 01:39:43 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
21/02/17 01:39:43 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
21/02/17 01:39:43 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
21/02/17 01:39:43 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
21/02/17 01:39:43 INFO CodeGenerator: Code generated in 6.731811 ms
21/02/17 01:39:43 INFO SparkContext: Starting job: parquet at RFormula.scala:496
21/02/17 01:39:43 INFO DAGScheduler: Registering RDD 86 (parquet at RFormula.scala:496)
21/02/17 01:39:43 INFO DAGScheduler: Got job 19 (parquet at RFormula.scala:496) with 1 output partitions
21/02/17 01:39:43 INFO DAGScheduler: Final stage: ResultStage 26 (parquet at RFormula.scala:496)
21/02/17 01:39:43 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 25)
21/02/17 01:39:43 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 25)
21/02/17 01:39:43 INFO DAGScheduler: Submitting ShuffleMapStage 25 (MapPartitionsRDD[86] at parquet at RFormula.scala:496), which has no missing parents
21/02/17 01:39:43 INFO MemoryStore: Block broadcast_26 stored as values in memory (estimated size 4.9 KB, free 911.3 MB)
21/02/17 01:39:43 INFO MemoryStore: Block broadcast_26_piece0 stored as bytes in memory (estimated size 2.9 KB, free 911.3 MB)
21/02/17 01:39:43 INFO BlockManagerInfo: Added broadcast_26_piece0 in memory on localhost:37301 (size: 2.9 KB, free: 912.0 MB)
21/02/17 01:39:43 INFO SparkContext: Created broadcast 26 from broadcast at DAGScheduler.scala:1161
21/02/17 01:39:43 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 25 (MapPartitionsRDD[86] at parquet at RFormula.scala:496) (first 15 tasks are for partitions Vector(0))
21/02/17 01:39:43 INFO TaskSchedulerImpl: Adding task set 25.0 with 1 tasks
21/02/17 01:39:43 INFO TaskSetManager: Starting task 0.0 in stage 25.0 (TID 25, localhost, executor driver, partition 0, PROCESS_LOCAL, 8041 bytes)
21/02/17 01:39:43 INFO Executor: Running task 0.0 in stage 25.0 (TID 25)
21/02/17 01:39:43 INFO Executor: Finished task 0.0 in stage 25.0 (TID 25). 1247 bytes result sent to driver
21/02/17 01:39:43 INFO TaskSetManager: Finished task 0.0 in stage 25.0 (TID 25) in 5 ms on localhost (executor driver) (1/1)
21/02/17 01:39:43 INFO TaskSchedulerImpl: Removed TaskSet 25.0, whose tasks have all completed, from pool 
21/02/17 01:39:43 INFO DAGScheduler: ShuffleMapStage 25 (parquet at RFormula.scala:496) finished in 0.009 s
21/02/17 01:39:43 INFO DAGScheduler: looking for newly runnable stages
21/02/17 01:39:43 INFO DAGScheduler: running: Set()
21/02/17 01:39:43 INFO DAGScheduler: waiting: Set(ResultStage 26)
21/02/17 01:39:43 INFO DAGScheduler: failed: Set()
21/02/17 01:39:43 INFO DAGScheduler: Submitting ResultStage 26 (ShuffledRowRDD[87] at parquet at RFormula.scala:496), which has no missing parents
21/02/17 01:39:43 INFO MemoryStore: Block broadcast_27 stored as values in memory (estimated size 150.8 KB, free 911.1 MB)
21/02/17 01:39:43 INFO MemoryStore: Block broadcast_27_piece0 stored as bytes in memory (estimated size 53.4 KB, free 911.1 MB)
21/02/17 01:39:43 INFO BlockManagerInfo: Added broadcast_27_piece0 in memory on localhost:37301 (size: 53.4 KB, free: 912.0 MB)
21/02/17 01:39:43 INFO SparkContext: Created broadcast 27 from broadcast at DAGScheduler.scala:1161
21/02/17 01:39:43 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 26 (ShuffledRowRDD[87] at parquet at RFormula.scala:496) (first 15 tasks are for partitions Vector(0))
21/02/17 01:39:43 INFO TaskSchedulerImpl: Adding task set 26.0 with 1 tasks
21/02/17 01:39:43 INFO TaskSetManager: Starting task 0.0 in stage 26.0 (TID 26, localhost, executor driver, partition 0, NODE_LOCAL, 7767 bytes)
21/02/17 01:39:43 INFO Executor: Running task 0.0 in stage 26.0 (TID 26)
21/02/17 01:39:43 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks including 1 local blocks and 0 remote blocks
21/02/17 01:39:43 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
21/02/17 01:39:43 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
21/02/17 01:39:43 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
21/02/17 01:39:43 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
21/02/17 01:39:43 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
21/02/17 01:39:43 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:
{
  "type" : "struct",
  "fields" : [ {
    "name" : "columnsToPrune",
    "type" : {
      "type" : "array",
      "elementType" : "string",
      "containsNull" : true
    },
    "nullable" : true,
    "metadata" : { }
  } ]
}
and corresponding Parquet message type:
message spark_schema {
  optional group columnsToPrune (LIST) {
    repeated group list {
      optional binary element (UTF8);
    }
  }
}

       
21/02/17 01:39:43 INFO FileOutputCommitter: Saved output of task 'attempt_20210217013943_0026_m_000000_26' to file:/tmp/RtmpaHGCHH/file22ad95b56a718/stages/0_r_formula__8eae6edf_b16e_4036_a8d6_baf58826f8d0/pipelineModel/stages/2_columnPruner_61c178682e95/data/_temporary/0/task_20210217013943_0026_m_000000
21/02/17 01:39:43 INFO SparkHadoopMapRedUtil: attempt_20210217013943_0026_m_000000_26: Committed
21/02/17 01:39:43 INFO Executor: Finished task 0.0 in stage 26.0 (TID 26). 2291 bytes result sent to driver
21/02/17 01:39:43 INFO TaskSetManager: Finished task 0.0 in stage 26.0 (TID 26) in 24 ms on localhost (executor driver) (1/1)
21/02/17 01:39:43 INFO TaskSchedulerImpl: Removed TaskSet 26.0, whose tasks have all completed, from pool 
21/02/17 01:39:43 INFO DAGScheduler: ResultStage 26 (parquet at RFormula.scala:496) finished in 0.046 s
21/02/17 01:39:43 INFO DAGScheduler: Job 19 finished: parquet at RFormula.scala:496, took 0.057900 s
21/02/17 01:39:43 INFO FileFormatWriter: Write Job b7bf4541-ddb7-4c38-b9ad-fe87242ff522 committed.
21/02/17 01:39:43 INFO FileFormatWriter: Finished processing stats for write job b7bf4541-ddb7-4c38-b9ad-fe87242ff522.
21/02/17 01:39:43 INFO HadoopMapRedCommitProtocol: Using output committer class org.apache.hadoop.mapred.FileOutputCommitter
21/02/17 01:39:43 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
21/02/17 01:39:43 INFO SparkContext: Starting job: runJob at SparkHadoopWriter.scala:78
21/02/17 01:39:43 INFO DAGScheduler: Got job 20 (runJob at SparkHadoopWriter.scala:78) with 1 output partitions
21/02/17 01:39:43 INFO DAGScheduler: Final stage: ResultStage 27 (runJob at SparkHadoopWriter.scala:78)
21/02/17 01:39:43 INFO DAGScheduler: Parents of final stage: List()
21/02/17 01:39:43 INFO DAGScheduler: Missing parents: List()
21/02/17 01:39:43 INFO DAGScheduler: Submitting ResultStage 27 (MapPartitionsRDD[90] at saveAsTextFile at DefaultXGBoostParamsWriter.scala:52), which has no missing parents
21/02/17 01:39:43 INFO MemoryStore: Block broadcast_28 stored as values in memory (estimated size 71.2 KB, free 911.0 MB)
21/02/17 01:39:43 INFO MemoryStore: Block broadcast_28_piece0 stored as bytes in memory (estimated size 25.5 KB, free 911.0 MB)
21/02/17 01:39:43 INFO BlockManagerInfo: Added broadcast_28_piece0 in memory on localhost:37301 (size: 25.5 KB, free: 912.0 MB)
21/02/17 01:39:43 INFO SparkContext: Created broadcast 28 from broadcast at DAGScheduler.scala:1161
21/02/17 01:39:43 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 27 (MapPartitionsRDD[90] at saveAsTextFile at DefaultXGBoostParamsWriter.scala:52) (first 15 tasks are for partitions Vector(0))
21/02/17 01:39:43 INFO TaskSchedulerImpl: Adding task set 27.0 with 1 tasks
21/02/17 01:39:43 INFO TaskSetManager: Starting task 0.0 in stage 27.0 (TID 27, localhost, executor driver, partition 0, PROCESS_LOCAL, 9115 bytes)
21/02/17 01:39:43 INFO Executor: Running task 0.0 in stage 27.0 (TID 27)
21/02/17 01:39:43 INFO HadoopMapRedCommitProtocol: Using output committer class org.apache.hadoop.mapred.FileOutputCommitter
21/02/17 01:39:43 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
21/02/17 01:39:43 INFO FileOutputCommitter: Saved output of task 'attempt_20210217013943_0090_m_000000_0' to file:/tmp/RtmpaHGCHH/file22ad95b56a718/stages/1_xgboost_regressor__ad18f29f_192b_48d7_935a_86a6e9bc9187/metadata/_temporary/0/task_20210217013943_0090_m_000000
21/02/17 01:39:43 INFO SparkHadoopMapRedUtil: attempt_20210217013943_0090_m_000000_0: Committed
21/02/17 01:39:43 INFO Executor: Finished task 0.0 in stage 27.0 (TID 27). 1029 bytes result sent to driver
21/02/17 01:39:43 INFO TaskSetManager: Finished task 0.0 in stage 27.0 (TID 27) in 13 ms on localhost (executor driver) (1/1)
21/02/17 01:39:43 INFO TaskSchedulerImpl: Removed TaskSet 27.0, whose tasks have all completed, from pool 
21/02/17 01:39:43 INFO DAGScheduler: ResultStage 27 (runJob at SparkHadoopWriter.scala:78) finished in 0.023 s
21/02/17 01:39:43 INFO DAGScheduler: Job 20 finished: runJob at SparkHadoopWriter.scala:78, took 0.024856 s
21/02/17 01:39:43 INFO SparkHadoopWriter: Job job_20210217013943_0090 committed.
21/02/17 01:39:43 INFO HiveMetaStore: 0: get_database: default
21/02/17 01:39:43 INFO audit: ugi=yitaoli	ip=unknown-ip-addr	cmd=get_database: default	
21/02/17 01:39:43 INFO HiveMetaStore: 0: get_database: default
21/02/17 01:39:43 INFO audit: ugi=yitaoli	ip=unknown-ip-addr	cmd=get_database: default	
21/02/17 01:39:43 INFO HiveMetaStore: 0: get_tables: db=default pat=*
21/02/17 01:39:43 INFO audit: ugi=yitaoli	ip=unknown-ip-addr	cmd=get_tables: db=default pat=*	
21/02/17 01:39:43 INFO CodeGenerator: Code generated in 4.947974 ms
21/02/17 01:39:43 INFO SparkContext: Starting job: collect at utils.scala:61
21/02/17 01:39:43 INFO DAGScheduler: Got job 21 (collect at utils.scala:61) with 2 output partitions
21/02/17 01:39:43 INFO DAGScheduler: Final stage: ResultStage 28 (collect at utils.scala:61)
21/02/17 01:39:43 INFO DAGScheduler: Parents of final stage: List()
21/02/17 01:39:43 INFO DAGScheduler: Missing parents: List()
21/02/17 01:39:43 INFO DAGScheduler: Submitting ResultStage 28 (MapPartitionsRDD[95] at map at utils.scala:54), which has no missing parents
21/02/17 01:39:43 INFO MemoryStore: Block broadcast_29 stored as values in memory (estimated size 6.0 KB, free 911.0 MB)
21/02/17 01:39:43 INFO MemoryStore: Block broadcast_29_piece0 stored as bytes in memory (estimated size 3.4 KB, free 911.0 MB)
21/02/17 01:39:43 INFO BlockManagerInfo: Added broadcast_29_piece0 in memory on localhost:37301 (size: 3.4 KB, free: 911.9 MB)
21/02/17 01:39:43 INFO SparkContext: Created broadcast 29 from broadcast at DAGScheduler.scala:1161
21/02/17 01:39:43 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 28 (MapPartitionsRDD[95] at map at utils.scala:54) (first 15 tasks are for partitions Vector(0, 1))
21/02/17 01:39:43 INFO TaskSchedulerImpl: Adding task set 28.0 with 2 tasks
21/02/17 01:39:43 INFO TaskSetManager: Starting task 0.0 in stage 28.0 (TID 28, localhost, executor driver, partition 0, PROCESS_LOCAL, 8052 bytes)
21/02/17 01:39:43 INFO TaskSetManager: Starting task 1.0 in stage 28.0 (TID 29, localhost, executor driver, partition 1, PROCESS_LOCAL, 8100 bytes)
21/02/17 01:39:43 INFO Executor: Running task 0.0 in stage 28.0 (TID 28)
21/02/17 01:39:43 INFO Executor: Running task 1.0 in stage 28.0 (TID 29)
21/02/17 01:39:43 INFO Executor: Finished task 1.0 in stage 28.0 (TID 29). 1022 bytes result sent to driver
21/02/17 01:39:43 INFO Executor: Finished task 0.0 in stage 28.0 (TID 28). 977 bytes result sent to driver
21/02/17 01:39:43 INFO TaskSetManager: Finished task 1.0 in stage 28.0 (TID 29) in 5 ms on localhost (executor driver) (1/2)
21/02/17 01:39:43 INFO TaskSetManager: Finished task 0.0 in stage 28.0 (TID 28) in 5 ms on localhost (executor driver) (2/2)
21/02/17 01:39:43 INFO TaskSchedulerImpl: Removed TaskSet 28.0, whose tasks have all completed, from pool 
21/02/17 01:39:43 INFO DAGScheduler: ResultStage 28 (collect at utils.scala:61) finished in 0.011 s
21/02/17 01:39:43 INFO DAGScheduler: Job 21 finished: collect at utils.scala:61, took 0.012032 s
21/02/17 01:39:43 INFO FileSourceStrategy: Pruning directories with: 
21/02/17 01:39:44 INFO FileSourceStrategy: Post-Scan Filters: 
21/02/17 01:39:44 INFO FileSourceStrategy: Output Data Schema: struct<value: string>
21/02/17 01:39:44 INFO FileSourceScanExec: Pushed Filters: 
21/02/17 01:39:44 INFO CodeGenerator: Code generated in 3.940274 ms
21/02/17 01:39:44 INFO MemoryStore: Block broadcast_30 stored as values in memory (estimated size 290.3 KB, free 910.7 MB)
21/02/17 01:39:44 INFO MemoryStore: Block broadcast_30_piece0 stored as bytes in memory (estimated size 24.5 KB, free 910.7 MB)
21/02/17 01:39:44 INFO BlockManagerInfo: Added broadcast_30_piece0 in memory on localhost:37301 (size: 24.5 KB, free: 911.9 MB)
21/02/17 01:39:44 INFO SparkContext: Created broadcast 30 from json at NativeMethodAccessorImpl.java:0
21/02/17 01:39:44 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
21/02/17 01:39:44 INFO SparkContext: Starting job: json at NativeMethodAccessorImpl.java:0
21/02/17 01:39:44 INFO DAGScheduler: Got job 22 (json at NativeMethodAccessorImpl.java:0) with 1 output partitions
21/02/17 01:39:44 INFO DAGScheduler: Final stage: ResultStage 29 (json at NativeMethodAccessorImpl.java:0)
21/02/17 01:39:44 INFO DAGScheduler: Parents of final stage: List()
21/02/17 01:39:44 INFO DAGScheduler: Missing parents: List()
21/02/17 01:39:44 INFO DAGScheduler: Submitting ResultStage 29 (MapPartitionsRDD[98] at json at NativeMethodAccessorImpl.java:0), which has no missing parents
21/02/17 01:39:44 INFO MemoryStore: Block broadcast_31 stored as values in memory (estimated size 9.6 KB, free 910.7 MB)
21/02/17 01:39:44 INFO MemoryStore: Block broadcast_31_piece0 stored as bytes in memory (estimated size 5.2 KB, free 910.7 MB)
21/02/17 01:39:44 INFO BlockManagerInfo: Added broadcast_31_piece0 in memory on localhost:37301 (size: 5.2 KB, free: 911.9 MB)
21/02/17 01:39:44 INFO SparkContext: Created broadcast 31 from broadcast at DAGScheduler.scala:1161
21/02/17 01:39:44 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 29 (MapPartitionsRDD[98] at json at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
21/02/17 01:39:44 INFO TaskSchedulerImpl: Adding task set 29.0 with 1 tasks
21/02/17 01:39:44 INFO TaskSetManager: Starting task 0.0 in stage 29.0 (TID 30, localhost, executor driver, partition 0, PROCESS_LOCAL, 8276 bytes)
21/02/17 01:39:44 INFO Executor: Running task 0.0 in stage 29.0 (TID 30)
21/02/17 01:39:44 INFO ContextCleaner: Cleaned accumulator 472
21/02/17 01:39:44 INFO BlockManagerInfo: Removed broadcast_27_piece0 on localhost:37301 in memory (size: 53.4 KB, free: 912.0 MB)
21/02/17 01:39:44 INFO ContextCleaner: Cleaned accumulator 499
21/02/17 01:39:44 INFO ContextCleaner: Cleaned accumulator 524
21/02/17 01:39:44 INFO ContextCleaner: Cleaned accumulator 785
21/02/17 01:39:44 INFO ContextCleaner: Cleaned accumulator 462
21/02/17 01:39:44 INFO ContextCleaner: Cleaned accumulator 761
21/02/17 01:39:44 INFO ContextCleaner: Cleaned accumulator 467
21/02/17 01:39:44 INFO ContextCleaner: Cleaned accumulator 658
21/02/17 01:39:44 INFO ContextCleaner: Cleaned accumulator 768
21/02/17 01:39:44 INFO BlockManagerInfo: Removed broadcast_20_piece0 on localhost:37301 in memory (size: 25.6 KB, free: 912.0 MB)
21/02/17 01:39:44 INFO ContextCleaner: Cleaned accumulator 491
21/02/17 01:39:44 INFO ContextCleaner: Cleaned accumulator 585
21/02/17 01:39:44 INFO ContextCleaner: Cleaned accumulator 751
21/02/17 01:39:44 INFO ContextCleaner: Cleaned accumulator 736
21/02/17 01:39:44 INFO ContextCleaner: Cleaned accumulator 681
21/02/17 01:39:44 INFO ContextCleaner: Cleaned accumulator 724
21/02/17 01:39:44 INFO ContextCleaner: Cleaned accumulator 527
21/02/17 01:39:44 INFO ContextCleaner: Cleaned accumulator 453
21/02/17 01:39:44 INFO ContextCleaner: Cleaned accumulator 600
21/02/17 01:39:44 INFO ContextCleaner: Cleaned accumulator 521
21/02/17 01:39:44 INFO ContextCleaner: Cleaned accumulator 564
21/02/17 01:39:44 INFO ContextCleaner: Cleaned accumulator 555
21/02/17 01:39:44 INFO ContextCleaner: Cleaned accumulator 529
21/02/17 01:39:44 INFO ContextCleaner: Cleaned accumulator 513
21/02/17 01:39:44 INFO FileScanRDD: Reading File path: file:///tmp/RtmpaHGCHH/file22ad95b56a718/metadata/part-00000, range: 0-306, partition values: [empty row]
21/02/17 01:39:44 INFO BlockManagerInfo: Removed broadcast_25_piece0 on localhost:37301 in memory (size: 25.6 KB, free: 912.0 MB)
21/02/17 01:39:44 INFO ContextCleaner: Cleaned accumulator 722
21/02/17 01:39:44 INFO ContextCleaner: Cleaned accumulator 591
21/02/17 01:39:44 INFO ContextCleaner: Cleaned accumulator 639
21/02/17 01:39:44 INFO ContextCleaner: Cleaned accumulator 540
21/02/17 01:39:44 INFO ContextCleaner: Cleaned accumulator 571
21/02/17 01:39:44 INFO ContextCleaner: Cleaned accumulator 791
21/02/17 01:39:44 INFO ContextCleaner: Cleaned accumulator 504
21/02/17 01:39:44 INFO ContextCleaner: Cleaned accumulator 565
21/02/17 01:39:44 INFO ContextCleaner: Cleaned accumulator 468
21/02/17 01:39:44 INFO ContextCleaner: Cleaned accumulator 688
21/02/17 01:39:44 INFO ContextCleaner: Cleaned accumulator 575
21/02/17 01:39:44 INFO ContextCleaner: Cleaned accumulator 646
21/02/17 01:39:44 INFO ContextCleaner: Cleaned accumulator 663
21/02/17 01:39:44 INFO ContextCleaner: Cleaned accumulator 707
21/02/17 01:39:44 INFO ContextCleaner: Cleaned accumulator 518
21/02/17 01:39:44 INFO ContextCleaner: Cleaned accumulator 514
21/02/17 01:39:44 INFO ContextCleaner: Cleaned accumulator 525
21/02/17 01:39:44 INFO ContextCleaner: Cleaned accumulator 519
21/02/17 01:39:44 INFO ContextCleaner: Cleaned accumulator 813
21/02/17 01:39:44 INFO ContextCleaner: Cleaned accumulator 779
21/02/17 01:39:44 INFO ContextCleaner: Cleaned accumulator 589
21/02/17 01:39:44 INFO ContextCleaner: Cleaned accumulator 492
21/02/17 01:39:44 INFO ContextCleaner: Cleaned accumulator 773
21/02/17 01:39:44 INFO ContextCleaner: Cleaned accumulator 668
21/02/17 01:39:44 INFO ContextCleaner: Cleaned accumulator 723
21/02/17 01:39:44 INFO ContextCleaner: Cleaned accumulator 482
21/02/17 01:39:44 INFO ContextCleaner: Cleaned accumulator 596
21/02/17 01:39:44 INFO ContextCleaner: Cleaned accumulator 807
21/02/17 01:39:44 INFO ContextCleaner: Cleaned accumulator 651
21/02/17 01:39:44 INFO ContextCleaner: Cleaned accumulator 721
21/02/17 01:39:44 INFO ContextCleaner: Cleaned accumulator 583
21/02/17 01:39:44 INFO ContextCleaner: Cleaned accumulator 687
21/02/17 01:39:44 INFO ContextCleaner: Cleaned accumulator 754
21/02/17 01:39:44 INFO ContextCleaner: Cleaned accumulator 478
21/02/17 01:39:44 INFO BlockManagerInfo: Removed broadcast_22_piece0 on localhost:37301 in memory (size: 25.6 KB, free: 912.0 MB)
21/02/17 01:39:44 INFO ContextCleaner: Cleaned accumulator 753
21/02/17 01:39:44 INFO ContextCleaner: Cleaned accumulator 669
21/02/17 01:39:44 INFO ContextCleaner: Cleaned shuffle 5
21/02/17 01:39:44 INFO ContextCleaner: Cleaned accumulator 567
21/02/17 01:39:44 INFO ContextCleaner: Cleaned accumulator 705
21/02/17 01:39:44 INFO ContextCleaner: Cleaned accumulator 708
21/02/17 01:39:44 INFO ContextCleaner: Cleaned accumulator 810
21/02/17 01:39:44 INFO ContextCleaner: Cleaned accumulator 644
21/02/17 01:39:44 INFO ContextCleaner: Cleaned accumulator 790
21/02/17 01:39:44 INFO ContextCleaner: Cleaned accumulator 487
21/02/17 01:39:44 INFO ContextCleaner: Cleaned accumulator 765
21/02/17 01:39:44 INFO ContextCleaner: Cleaned accumulator 730
21/02/17 01:39:44 INFO ContextCleaner: Cleaned accumulator 578
21/02/17 01:39:44 INFO ContextCleaner: Cleaned accumulator 642
21/02/17 01:39:44 INFO ContextCleaner: Cleaned accumulator 503
21/02/17 01:39:44 INFO ContextCleaner: Cleaned accumulator 742
21/02/17 01:39:44 INFO ContextCleaner: Cleaned accumulator 502
21/02/17 01:39:44 INFO ContextCleaner: Cleaned accumulator 696
21/02/17 01:39:44 INFO ContextCleaner: Cleaned accumulator 626
21/02/17 01:39:44 INFO CodeGenerator: Code generated in 4.939685 ms
21/02/17 01:39:44 INFO BlockManagerInfo: Removed broadcast_17_piece0 on localhost:37301 in memory (size: 25.5 KB, free: 912.1 MB)
21/02/17 01:39:44 INFO ContextCleaner: Cleaned accumulator 517
21/02/17 01:39:44 INFO ContextCleaner: Cleaned accumulator 613
21/02/17 01:39:44 INFO ContextCleaner: Cleaned accumulator 802
21/02/17 01:39:44 INFO BlockManagerInfo: Removed broadcast_29_piece0 on localhost:37301 in memory (size: 3.4 KB, free: 912.1 MB)
21/02/17 01:39:44 INFO ContextCleaner: Cleaned accumulator 788
21/02/17 01:39:44 INFO ContextCleaner: Cleaned accumulator 702
21/02/17 01:39:44 INFO ContextCleaner: Cleaned accumulator 602
21/02/17 01:39:44 INFO ContextCleaner: Cleaned accumulator 617
21/02/17 01:39:44 INFO ContextCleaner: Cleaned accumulator 800
21/02/17 01:39:44 INFO BlockManagerInfo: Removed broadcast_23_piece0 on localhost:37301 in memory (size: 3.0 KB, free: 912.1 MB)
21/02/17 01:39:44 INFO ContextCleaner: Cleaned accumulator 614
21/02/17 01:39:44 INFO ContextCleaner: Cleaned accumulator 638
21/02/17 01:39:44 INFO ContextCleaner: Cleaned accumulator 804
21/02/17 01:39:44 INFO ContextCleaner: Cleaned accumulator 576
21/02/17 01:39:44 INFO ContextCleaner: Cleaned accumulator 632
21/02/17 01:39:44 INFO ContextCleaner: Cleaned accumulator 699
21/02/17 01:39:44 INFO ContextCleaner: Cleaned accumulator 511
21/02/17 01:39:44 INFO ContextCleaner: Cleaned accumulator 666
21/02/17 01:39:44 INFO ContextCleaner: Cleaned accumulator 579
21/02/17 01:39:44 INFO ContextCleaner: Cleaned accumulator 775
21/02/17 01:39:44 INFO ContextCleaner: Cleaned accumulator 812
21/02/17 01:39:44 INFO ContextCleaner: Cleaned accumulator 776
21/02/17 01:39:44 INFO ContextCleaner: Cleaned accumulator 818
21/02/17 01:39:44 INFO ContextCleaner: Cleaned accumulator 798
21/02/17 01:39:44 INFO ContextCleaner: Cleaned accumulator 611
21/02/17 01:39:44 INFO ContextCleaner: Cleaned accumulator 680
21/02/17 01:39:44 INFO ContextCleaner: Cleaned accumulator 475
21/02/17 01:39:44 INFO ContextCleaner: Cleaned accumulator 769
21/02/17 01:39:44 INFO ContextCleaner: Cleaned accumulator 771
21/02/17 01:39:44 INFO ContextCleaner: Cleaned accumulator 822
21/02/17 01:39:44 INFO ContextCleaner: Cleaned accumulator 528
21/02/17 01:39:44 INFO ContextCleaner: Cleaned accumulator 732
21/02/17 01:39:44 INFO ContextCleaner: Cleaned accumulator 738
21/02/17 01:39:44 INFO ContextCleaner: Cleaned accumulator 689
21/02/17 01:39:44 INFO ContextCleaner: Cleaned accumulator 541
21/02/17 01:39:44 INFO ContextCleaner: Cleaned accumulator 677
21/02/17 01:39:44 INFO ContextCleaner: Cleaned accumulator 636
21/02/17 01:39:44 INFO ContextCleaner: Cleaned accumulator 758
21/02/17 01:39:44 INFO ContextCleaner: Cleaned accumulator 560
21/02/17 01:39:44 INFO ContextCleaner: Cleaned accumulator 573
21/02/17 01:39:44 INFO ContextCleaner: Cleaned accumulator 612
21/02/17 01:39:44 INFO ContextCleaner: Cleaned accumulator 660
21/02/17 01:39:44 INFO ContextCleaner: Cleaned accumulator 697
21/02/17 01:39:44 INFO ContextCleaner: Cleaned accumulator 711
21/02/17 01:39:44 INFO ContextCleaner: Cleaned accumulator 516
21/02/17 01:39:44 INFO ContextCleaner: Cleaned accumulator 662
21/02/17 01:39:44 INFO ContextCleaner: Cleaned accumulator 685
21/02/17 01:39:44 INFO BlockManagerInfo: Removed broadcast_24_piece0 on localhost:37301 in memory (size: 53.6 KB, free: 912.1 MB)
21/02/17 01:39:44 INFO ContextCleaner: Cleaned accumulator 691
21/02/17 01:39:44 INFO ContextCleaner: Cleaned accumulator 570
21/02/17 01:39:44 INFO ContextCleaner: Cleaned accumulator 814
21/02/17 01:39:44 INFO ContextCleaner: Cleaned accumulator 657
21/02/17 01:39:44 INFO ContextCleaner: Cleaned accumulator 665
21/02/17 01:39:44 INFO ContextCleaner: Cleaned accumulator 595
21/02/17 01:39:44 INFO ContextCleaner: Cleaned accumulator 494
21/02/17 01:39:44 INFO ContextCleaner: Cleaned accumulator 507
21/02/17 01:39:44 INFO ContextCleaner: Cleaned accumulator 701
21/02/17 01:39:44 INFO ContextCleaner: Cleaned accumulator 733
21/02/17 01:39:44 INFO ContextCleaner: Cleaned accumulator 460
21/02/17 01:39:44 INFO ContextCleaner: Cleaned accumulator 605
21/02/17 01:39:44 INFO ContextCleaner: Cleaned accumulator 470
21/02/17 01:39:44 INFO ContextCleaner: Cleaned accumulator 673
21/02/17 01:39:44 INFO ContextCleaner: Cleaned accumulator 764
21/02/17 01:39:44 INFO ContextCleaner: Cleaned accumulator 655
21/02/17 01:39:44 INFO ContextCleaner: Cleaned accumulator 640
21/02/17 01:39:44 INFO ContextCleaner: Cleaned accumulator 557
21/02/17 01:39:44 INFO ContextCleaner: Cleaned accumulator 625
21/02/17 01:39:44 INFO ContextCleaner: Cleaned accumulator 750
21/02/17 01:39:44 INFO ContextCleaner: Cleaned accumulator 606
21/02/17 01:39:44 INFO ContextCleaner: Cleaned accumulator 770
21/02/17 01:39:44 INFO ContextCleaner: Cleaned shuffle 4
21/02/17 01:39:44 INFO BlockManagerInfo: Removed broadcast_19_piece0 on localhost:37301 in memory (size: 53.6 KB, free: 912.2 MB)
21/02/17 01:39:44 INFO ContextCleaner: Cleaned accumulator 538
21/02/17 01:39:44 INFO ContextCleaner: Cleaned accumulator 604
21/02/17 01:39:44 INFO ContextCleaner: Cleaned accumulator 671
21/02/17 01:39:44 INFO ContextCleaner: Cleaned accumulator 820
21/02/17 01:39:44 INFO ContextCleaner: Cleaned accumulator 650
21/02/17 01:39:44 INFO ContextCleaner: Cleaned accumulator 558
21/02/17 01:39:44 INFO ContextCleaner: Cleaned accumulator 574
21/02/17 01:39:44 INFO ContextCleaner: Cleaned accumulator 500
21/02/17 01:39:44 INFO ContextCleaner: Cleaned accumulator 474
21/02/17 01:39:44 INFO ContextCleaner: Cleaned accumulator 569
21/02/17 01:39:44 INFO ContextCleaner: Cleaned accumulator 815
21/02/17 01:39:44 INFO ContextCleaner: Cleaned accumulator 629
21/02/17 01:39:44 INFO ContextCleaner: Cleaned accumulator 623
21/02/17 01:39:44 INFO ContextCleaner: Cleaned accumulator 725
21/02/17 01:39:44 INFO ContextCleaner: Cleaned accumulator 550
21/02/17 01:39:44 INFO ContextCleaner: Cleaned accumulator 609
21/02/17 01:39:44 INFO ContextCleaner: Cleaned accumulator 645
21/02/17 01:39:44 INFO ContextCleaner: Cleaned accumulator 728
21/02/17 01:39:44 INFO ContextCleaner: Cleaned accumulator 794
21/02/17 01:39:44 INFO ContextCleaner: Cleaned accumulator 667
21/02/17 01:39:44 INFO ContextCleaner: Cleaned accumulator 535
21/02/17 01:39:44 INFO ContextCleaner: Cleaned accumulator 797
21/02/17 01:39:44 INFO ContextCleaner: Cleaned accumulator 457
21/02/17 01:39:44 INFO BlockManagerInfo: Removed broadcast_16_piece0 on localhost:37301 in memory (size: 25.4 KB, free: 912.2 MB)
21/02/17 01:39:44 INFO ContextCleaner: Cleaned accumulator 713
21/02/17 01:39:44 INFO ContextCleaner: Cleaned accumulator 714
21/02/17 01:39:44 INFO ContextCleaner: Cleaned accumulator 717
21/02/17 01:39:44 INFO ContextCleaner: Cleaned accumulator 757
21/02/17 01:39:44 INFO ContextCleaner: Cleaned accumulator 746
21/02/17 01:39:44 INFO ContextCleaner: Cleaned accumulator 686
21/02/17 01:39:44 INFO ContextCleaner: Cleaned accumulator 652
21/02/17 01:39:44 INFO ContextCleaner: Cleaned accumulator 749
21/02/17 01:39:44 INFO ContextCleaner: Cleaned accumulator 459
21/02/17 01:39:44 INFO ContextCleaner: Cleaned accumulator 744
21/02/17 01:39:44 INFO ContextCleaner: Cleaned accumulator 778
21/02/17 01:39:44 INFO ContextCleaner: Cleaned accumulator 709
21/02/17 01:39:44 INFO ContextCleaner: Cleaned accumulator 471
21/02/17 01:39:44 INFO ContextCleaner: Cleaned accumulator 556
21/02/17 01:39:44 INFO ContextCleaner: Cleaned accumulator 715
21/02/17 01:39:44 INFO BlockManagerInfo: Removed broadcast_26_piece0 on localhost:37301 in memory (size: 2.9 KB, free: 912.2 MB)
21/02/17 01:39:44 INFO ContextCleaner: Cleaned accumulator 706
21/02/17 01:39:44 INFO ContextCleaner: Cleaned accumulator 601
21/02/17 01:39:44 INFO ContextCleaner: Cleaned accumulator 608
21/02/17 01:39:44 INFO ContextCleaner: Cleaned accumulator 458
21/02/17 01:39:44 INFO ContextCleaner: Cleaned accumulator 718
21/02/17 01:39:44 INFO ContextCleaner: Cleaned accumulator 659
21/02/17 01:39:44 INFO ContextCleaner: Cleaned accumulator 562
21/02/17 01:39:44 INFO ContextCleaner: Cleaned accumulator 542
21/02/17 01:39:44 INFO ContextCleaner: Cleaned accumulator 461
21/02/17 01:39:44 INFO ContextCleaner: Cleaned accumulator 634
21/02/17 01:39:44 INFO ContextCleaner: Cleaned accumulator 532
21/02/17 01:39:44 INFO ContextCleaner: Cleaned accumulator 734
21/02/17 01:39:44 INFO ContextCleaner: Cleaned accumulator 787
21/02/17 01:39:44 INFO ContextCleaner: Cleaned accumulator 649
21/02/17 01:39:44 INFO ContextCleaner: Cleaned accumulator 580
21/02/17 01:39:44 INFO ContextCleaner: Cleaned accumulator 712
21/02/17 01:39:44 INFO ContextCleaner: Cleaned accumulator 759
21/02/17 01:39:44 INFO ContextCleaner: Cleaned accumulator 512
21/02/17 01:39:44 INFO ContextCleaner: Cleaned accumulator 610
21/02/17 01:39:44 INFO BlockManagerInfo: Removed broadcast_18_piece0 on localhost:37301 in memory (size: 3.0 KB, free: 912.2 MB)
21/02/17 01:39:44 INFO ContextCleaner: Cleaned shuffle 6
21/02/17 01:39:44 INFO ContextCleaner: Cleaned accumulator 756
21/02/17 01:39:44 INFO ContextCleaner: Cleaned accumulator 473
21/02/17 01:39:44 INFO ContextCleaner: Cleaned accumulator 637
21/02/17 01:39:44 INFO ContextCleaner: Cleaned accumulator 783
21/02/17 01:39:44 INFO ContextCleaner: Cleaned accumulator 496
21/02/17 01:39:44 INFO ContextCleaner: Cleaned accumulator 515
21/02/17 01:39:44 INFO ContextCleaner: Cleaned accumulator 456
21/02/17 01:39:44 INFO ContextCleaner: Cleaned accumulator 782
21/02/17 01:39:44 INFO ContextCleaner: Cleaned accumulator 635
21/02/17 01:39:44 INFO ContextCleaner: Cleaned accumulator 710
21/02/17 01:39:44 INFO ContextCleaner: Cleaned accumulator 630
21/02/17 01:39:44 INFO ContextCleaner: Cleaned accumulator 690
21/02/17 01:39:44 INFO ContextCleaner: Cleaned accumulator 796
21/02/17 01:39:44 INFO ContextCleaner: Cleaned accumulator 531
21/02/17 01:39:44 INFO ContextCleaner: Cleaned accumulator 809
21/02/17 01:39:44 INFO ContextCleaner: Cleaned accumulator 695
21/02/17 01:39:44 INFO ContextCleaner: Cleaned accumulator 647
21/02/17 01:39:44 INFO ContextCleaner: Cleaned accumulator 684
21/02/17 01:39:44 INFO ContextCleaner: Cleaned accumulator 692
21/02/17 01:39:44 INFO ContextCleaner: Cleaned accumulator 615
21/02/17 01:39:44 INFO ContextCleaner: Cleaned accumulator 551
21/02/17 01:39:44 INFO ContextCleaner: Cleaned accumulator 653
21/02/17 01:39:44 INFO ContextCleaner: Cleaned accumulator 489
21/02/17 01:39:44 INFO ContextCleaner: Cleaned accumulator 463
21/02/17 01:39:44 INFO ContextCleaner: Cleaned accumulator 505
21/02/17 01:39:44 INFO ContextCleaner: Cleaned accumulator 780
21/02/17 01:39:44 INFO ContextCleaner: Cleaned accumulator 784
21/02/17 01:39:44 INFO ContextCleaner: Cleaned accumulator 703
21/02/17 01:39:44 INFO ContextCleaner: Cleaned accumulator 719
21/02/17 01:39:44 INFO ContextCleaner: Cleaned accumulator 523
21/02/17 01:39:44 INFO ContextCleaner: Cleaned accumulator 747
21/02/17 01:39:44 INFO ContextCleaner: Cleaned accumulator 534
21/02/17 01:39:44 INFO ContextCleaner: Cleaned accumulator 536
21/02/17 01:39:44 INFO ContextCleaner: Cleaned accumulator 805
21/02/17 01:39:44 INFO ContextCleaner: Cleaned accumulator 748
21/02/17 01:39:44 INFO ContextCleaner: Cleaned accumulator 577
21/02/17 01:39:44 INFO ContextCleaner: Cleaned accumulator 760
21/02/17 01:39:44 INFO ContextCleaner: Cleaned accumulator 530
21/02/17 01:39:44 INFO ContextCleaner: Cleaned accumulator 726
21/02/17 01:39:44 INFO ContextCleaner: Cleaned accumulator 477
21/02/17 01:39:44 INFO ContextCleaner: Cleaned accumulator 817
21/02/17 01:39:44 INFO ContextCleaner: Cleaned accumulator 727
21/02/17 01:39:44 INFO ContextCleaner: Cleaned accumulator 466
21/02/17 01:39:44 INFO ContextCleaner: Cleaned accumulator 620
21/02/17 01:39:44 INFO ContextCleaner: Cleaned accumulator 549
21/02/17 01:39:44 INFO ContextCleaner: Cleaned accumulator 533
21/02/17 01:39:44 INFO ContextCleaner: Cleaned accumulator 587
21/02/17 01:39:44 INFO ContextCleaner: Cleaned accumulator 816
21/02/17 01:39:44 INFO ContextCleaner: Cleaned accumulator 720
21/02/17 01:39:44 INFO ContextCleaner: Cleaned accumulator 593
21/02/17 01:39:44 INFO ContextCleaner: Cleaned accumulator 485
21/02/17 01:39:44 INFO ContextCleaner: Cleaned accumulator 752
21/02/17 01:39:44 INFO ContextCleaner: Cleaned accumulator 603
21/02/17 01:39:44 INFO ContextCleaner: Cleaned accumulator 594
21/02/17 01:39:44 INFO ContextCleaner: Cleaned accumulator 607
21/02/17 01:39:44 INFO ContextCleaner: Cleaned accumulator 731
21/02/17 01:39:44 INFO ContextCleaner: Cleaned accumulator 803
21/02/17 01:39:44 INFO ContextCleaner: Cleaned accumulator 510
21/02/17 01:39:44 INFO ContextCleaner: Cleaned accumulator 545
21/02/17 01:39:44 INFO ContextCleaner: Cleaned accumulator 588
21/02/17 01:39:44 INFO ContextCleaner: Cleaned accumulator 801
21/02/17 01:39:44 INFO ContextCleaner: Cleaned accumulator 479
21/02/17 01:39:44 INFO ContextCleaner: Cleaned accumulator 700
21/02/17 01:39:44 INFO ContextCleaner: Cleaned accumulator 543
21/02/17 01:39:44 INFO ContextCleaner: Cleaned accumulator 767
21/02/17 01:39:44 INFO ContextCleaner: Cleaned accumulator 493
21/02/17 01:39:44 INFO ContextCleaner: Cleaned accumulator 631
21/02/17 01:39:44 INFO ContextCleaner: Cleaned accumulator 454
21/02/17 01:39:44 INFO ContextCleaner: Cleaned accumulator 568
21/02/17 01:39:44 INFO ContextCleaner: Cleaned accumulator 621
21/02/17 01:39:44 INFO ContextCleaner: Cleaned accumulator 737
21/02/17 01:39:44 INFO ContextCleaner: Cleaned accumulator 806
21/02/17 01:39:44 INFO ContextCleaner: Cleaned accumulator 739
21/02/17 01:39:44 INFO ContextCleaner: Cleaned accumulator 584
21/02/17 01:39:44 INFO ContextCleaner: Cleaned accumulator 506
21/02/17 01:39:44 INFO ContextCleaner: Cleaned accumulator 676
21/02/17 01:39:44 INFO ContextCleaner: Cleaned accumulator 490
21/02/17 01:39:44 INFO ContextCleaner: Cleaned accumulator 664
21/02/17 01:39:44 INFO ContextCleaner: Cleaned accumulator 781
21/02/17 01:39:44 INFO ContextCleaner: Cleaned accumulator 508
21/02/17 01:39:44 INFO ContextCleaner: Cleaned accumulator 509
21/02/17 01:39:44 INFO ContextCleaner: Cleaned accumulator 563
21/02/17 01:39:44 INFO ContextCleaner: Cleaned accumulator 704
21/02/17 01:39:44 INFO ContextCleaner: Cleaned accumulator 672
21/02/17 01:39:44 INFO ContextCleaner: Cleaned accumulator 811
21/02/17 01:39:44 INFO ContextCleaner: Cleaned accumulator 675
21/02/17 01:39:44 INFO ContextCleaner: Cleaned accumulator 762
21/02/17 01:39:44 INFO ContextCleaner: Cleaned accumulator 766
21/02/17 01:39:44 INFO ContextCleaner: Cleaned accumulator 823
21/02/17 01:39:44 INFO ContextCleaner: Cleaned accumulator 599
21/02/17 01:39:44 INFO ContextCleaner: Cleaned accumulator 755
21/02/17 01:39:44 INFO ContextCleaner: Cleaned accumulator 624
21/02/17 01:39:44 INFO ContextCleaner: Cleaned accumulator 745
21/02/17 01:39:44 INFO ContextCleaner: Cleaned accumulator 572
21/02/17 01:39:44 INFO ContextCleaner: Cleaned accumulator 476
21/02/17 01:39:44 INFO ContextCleaner: Cleaned accumulator 819
21/02/17 01:39:44 INFO ContextCleaner: Cleaned accumulator 469
21/02/17 01:39:44 INFO ContextCleaner: Cleaned accumulator 648
21/02/17 01:39:44 INFO ContextCleaner: Cleaned accumulator 694
21/02/17 01:39:44 INFO ContextCleaner: Cleaned accumulator 566
21/02/17 01:39:44 INFO ContextCleaner: Cleaned accumulator 741
21/02/17 01:39:44 INFO ContextCleaner: Cleaned accumulator 495
21/02/17 01:39:44 INFO ContextCleaner: Cleaned accumulator 544
21/02/17 01:39:44 INFO ContextCleaner: Cleaned accumulator 618
21/02/17 01:39:44 INFO ContextCleaner: Cleaned accumulator 670
21/02/17 01:39:44 INFO ContextCleaner: Cleaned accumulator 674
21/02/17 01:39:44 INFO ContextCleaner: Cleaned accumulator 716
21/02/17 01:39:44 INFO ContextCleaner: Cleaned accumulator 522
21/02/17 01:39:44 INFO ContextCleaner: Cleaned accumulator 619
21/02/17 01:39:44 INFO ContextCleaner: Cleaned accumulator 552
21/02/17 01:39:44 INFO ContextCleaner: Cleaned accumulator 683
21/02/17 01:39:44 INFO ContextCleaner: Cleaned accumulator 581
21/02/17 01:39:44 INFO ContextCleaner: Cleaned accumulator 693
21/02/17 01:39:44 INFO ContextCleaner: Cleaned accumulator 592
21/02/17 01:39:44 INFO ContextCleaner: Cleaned accumulator 729
21/02/17 01:39:44 INFO BlockManagerInfo: Removed broadcast_21_piece0 on localhost:37301 in memory (size: 25.5 KB, free: 912.2 MB)
21/02/17 01:39:44 INFO ContextCleaner: Cleaned accumulator 488
21/02/17 01:39:44 INFO ContextCleaner: Cleaned accumulator 656
21/02/17 01:39:44 INFO ContextCleaner: Cleaned accumulator 582
21/02/17 01:39:44 INFO ContextCleaner: Cleaned accumulator 483
21/02/17 01:39:44 INFO ContextCleaner: Cleaned accumulator 795
21/02/17 01:39:44 INFO ContextCleaner: Cleaned accumulator 774
21/02/17 01:39:44 INFO ContextCleaner: Cleaned accumulator 481
21/02/17 01:39:44 INFO ContextCleaner: Cleaned accumulator 520
21/02/17 01:39:44 INFO ContextCleaner: Cleaned accumulator 597
21/02/17 01:39:44 INFO ContextCleaner: Cleaned accumulator 537
21/02/17 01:39:44 INFO ContextCleaner: Cleaned accumulator 678
21/02/17 01:39:44 INFO ContextCleaner: Cleaned accumulator 465
21/02/17 01:39:44 INFO ContextCleaner: Cleaned accumulator 452
21/02/17 01:39:44 INFO ContextCleaner: Cleaned accumulator 526
21/02/17 01:39:44 INFO ContextCleaner: Cleaned accumulator 539
21/02/17 01:39:44 INFO ContextCleaner: Cleaned accumulator 598
21/02/17 01:39:44 INFO ContextCleaner: Cleaned accumulator 682
21/02/17 01:39:44 INFO ContextCleaner: Cleaned accumulator 792
21/02/17 01:39:44 INFO ContextCleaner: Cleaned accumulator 821
21/02/17 01:39:44 INFO ContextCleaner: Cleaned accumulator 654
21/02/17 01:39:44 INFO ContextCleaner: Cleaned accumulator 561
21/02/17 01:39:44 INFO ContextCleaner: Cleaned accumulator 586
21/02/17 01:39:44 INFO ContextCleaner: Cleaned accumulator 743
21/02/17 01:39:44 INFO ContextCleaner: Cleaned accumulator 777
21/02/17 01:39:44 INFO ContextCleaner: Cleaned accumulator 548
21/02/17 01:39:44 INFO ContextCleaner: Cleaned accumulator 480
21/02/17 01:39:44 INFO ContextCleaner: Cleaned accumulator 786
21/02/17 01:39:44 INFO ContextCleaner: Cleaned accumulator 464
21/02/17 01:39:44 INFO ContextCleaner: Cleaned accumulator 546
21/02/17 01:39:44 INFO ContextCleaner: Cleaned accumulator 547
21/02/17 01:39:44 INFO ContextCleaner: Cleaned accumulator 772
21/02/17 01:39:44 INFO ContextCleaner: Cleaned accumulator 661
21/02/17 01:39:44 INFO ContextCleaner: Cleaned accumulator 740
21/02/17 01:39:44 INFO ContextCleaner: Cleaned accumulator 633
21/02/17 01:39:44 INFO ContextCleaner: Cleaned accumulator 497
21/02/17 01:39:44 INFO ContextCleaner: Cleaned accumulator 554
21/02/17 01:39:44 INFO ContextCleaner: Cleaned accumulator 616
21/02/17 01:39:44 INFO ContextCleaner: Cleaned accumulator 698
21/02/17 01:39:44 INFO ContextCleaner: Cleaned accumulator 622
21/02/17 01:39:44 INFO ContextCleaner: Cleaned accumulator 735
21/02/17 01:39:44 INFO ContextCleaner: Cleaned accumulator 486
21/02/17 01:39:44 INFO BlockManagerInfo: Removed broadcast_28_piece0 on localhost:37301 in memory (size: 25.5 KB, free: 912.3 MB)
21/02/17 01:39:44 INFO ContextCleaner: Cleaned accumulator 799
21/02/17 01:39:44 INFO ContextCleaner: Cleaned accumulator 643
21/02/17 01:39:44 INFO ContextCleaner: Cleaned accumulator 679
21/02/17 01:39:44 INFO ContextCleaner: Cleaned accumulator 763
21/02/17 01:39:44 INFO ContextCleaner: Cleaned accumulator 501
21/02/17 01:39:44 INFO ContextCleaner: Cleaned accumulator 627
21/02/17 01:39:44 INFO ContextCleaner: Cleaned accumulator 641
21/02/17 01:39:44 INFO ContextCleaner: Cleaned accumulator 498
21/02/17 01:39:44 INFO ContextCleaner: Cleaned accumulator 455
21/02/17 01:39:44 INFO ContextCleaner: Cleaned accumulator 590
21/02/17 01:39:44 INFO ContextCleaner: Cleaned accumulator 559
21/02/17 01:39:44 INFO ContextCleaner: Cleaned accumulator 793
21/02/17 01:39:44 INFO ContextCleaner: Cleaned accumulator 789
21/02/17 01:39:44 INFO ContextCleaner: Cleaned accumulator 484
21/02/17 01:39:44 INFO ContextCleaner: Cleaned accumulator 628
21/02/17 01:39:44 INFO ContextCleaner: Cleaned accumulator 553
21/02/17 01:39:44 INFO ContextCleaner: Cleaned accumulator 808
21/02/17 01:39:44 INFO Executor: Finished task 0.0 in stage 29.0 (TID 30). 2192 bytes result sent to driver
21/02/17 01:39:44 INFO TaskSetManager: Finished task 0.0 in stage 29.0 (TID 30) in 57 ms on localhost (executor driver) (1/1)
21/02/17 01:39:44 INFO TaskSchedulerImpl: Removed TaskSet 29.0, whose tasks have all completed, from pool 
21/02/17 01:39:44 INFO DAGScheduler: ResultStage 29 (json at NativeMethodAccessorImpl.java:0) finished in 0.064 s
21/02/17 01:39:44 INFO DAGScheduler: Job 22 finished: json at NativeMethodAccessorImpl.java:0, took 0.094060 s
21/02/17 01:39:44 INFO HiveMetaStore: 0: get_database: default
21/02/17 01:39:44 INFO audit: ugi=yitaoli	ip=unknown-ip-addr	cmd=get_database: default	
21/02/17 01:39:44 INFO HiveMetaStore: 0: get_database: default
21/02/17 01:39:44 INFO audit: ugi=yitaoli	ip=unknown-ip-addr	cmd=get_database: default	
21/02/17 01:39:44 INFO HiveMetaStore: 0: get_tables: db=default pat=*
21/02/17 01:39:44 INFO audit: ugi=yitaoli	ip=unknown-ip-addr	cmd=get_tables: db=default pat=*	
21/02/17 01:39:44 INFO CodeGenerator: Code generated in 7.134263 ms
21/02/17 01:39:44 INFO CodeGenerator: Code generated in 6.126072 ms
21/02/17 01:39:44 INFO SparkContext: Starting job: count at utils.scala:135
21/02/17 01:39:44 INFO DAGScheduler: Registering RDD 102 (count at utils.scala:135)
21/02/17 01:39:44 INFO DAGScheduler: Got job 23 (count at utils.scala:135) with 1 output partitions
21/02/17 01:39:44 INFO DAGScheduler: Final stage: ResultStage 31 (count at utils.scala:135)
21/02/17 01:39:44 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 30)
21/02/17 01:39:44 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 30)
21/02/17 01:39:44 INFO DAGScheduler: Submitting ShuffleMapStage 30 (MapPartitionsRDD[102] at count at utils.scala:135), which has no missing parents
21/02/17 01:39:44 INFO MemoryStore: Block broadcast_32 stored as values in memory (estimated size 7.9 KB, free 912.0 MB)
21/02/17 01:39:44 INFO MemoryStore: Block broadcast_32_piece0 stored as bytes in memory (estimated size 4.2 KB, free 912.0 MB)
21/02/17 01:39:44 INFO BlockManagerInfo: Added broadcast_32_piece0 in memory on localhost:37301 (size: 4.2 KB, free: 912.3 MB)
21/02/17 01:39:44 INFO SparkContext: Created broadcast 32 from broadcast at DAGScheduler.scala:1161
21/02/17 01:39:44 INFO DAGScheduler: Submitting 2 missing tasks from ShuffleMapStage 30 (MapPartitionsRDD[102] at count at utils.scala:135) (first 15 tasks are for partitions Vector(0, 1))
21/02/17 01:39:44 INFO TaskSchedulerImpl: Adding task set 30.0 with 2 tasks
21/02/17 01:39:44 INFO TaskSetManager: Starting task 0.0 in stage 30.0 (TID 31, localhost, executor driver, partition 0, PROCESS_LOCAL, 8017 bytes)
21/02/17 01:39:44 INFO TaskSetManager: Starting task 1.0 in stage 30.0 (TID 32, localhost, executor driver, partition 1, PROCESS_LOCAL, 8017 bytes)
21/02/17 01:39:44 INFO Executor: Running task 0.0 in stage 30.0 (TID 31)
21/02/17 01:39:44 INFO Executor: Running task 1.0 in stage 30.0 (TID 32)
21/02/17 01:39:44 INFO Executor: Finished task 0.0 in stage 30.0 (TID 31). 1499 bytes result sent to driver
21/02/17 01:39:44 INFO Executor: Finished task 1.0 in stage 30.0 (TID 32). 1499 bytes result sent to driver
21/02/17 01:39:44 INFO TaskSetManager: Finished task 0.0 in stage 30.0 (TID 31) in 4 ms on localhost (executor driver) (1/2)
21/02/17 01:39:44 INFO TaskSetManager: Finished task 1.0 in stage 30.0 (TID 32) in 4 ms on localhost (executor driver) (2/2)
21/02/17 01:39:44 INFO TaskSchedulerImpl: Removed TaskSet 30.0, whose tasks have all completed, from pool 
21/02/17 01:39:44 INFO DAGScheduler: ShuffleMapStage 30 (count at utils.scala:135) finished in 0.009 s
21/02/17 01:39:44 INFO DAGScheduler: looking for newly runnable stages
21/02/17 01:39:44 INFO DAGScheduler: running: Set()
21/02/17 01:39:44 INFO DAGScheduler: waiting: Set(ResultStage 31)
21/02/17 01:39:44 INFO DAGScheduler: failed: Set()
21/02/17 01:39:44 INFO DAGScheduler: Submitting ResultStage 31 (MapPartitionsRDD[105] at count at utils.scala:135), which has no missing parents
21/02/17 01:39:44 INFO MemoryStore: Block broadcast_33 stored as values in memory (estimated size 7.1 KB, free 911.9 MB)
21/02/17 01:39:44 INFO MemoryStore: Block broadcast_33_piece0 stored as bytes in memory (estimated size 3.8 KB, free 911.9 MB)
21/02/17 01:39:44 INFO BlockManagerInfo: Added broadcast_33_piece0 in memory on localhost:37301 (size: 3.8 KB, free: 912.3 MB)
21/02/17 01:39:44 INFO SparkContext: Created broadcast 33 from broadcast at DAGScheduler.scala:1161
21/02/17 01:39:44 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 31 (MapPartitionsRDD[105] at count at utils.scala:135) (first 15 tasks are for partitions Vector(0))
21/02/17 01:39:44 INFO TaskSchedulerImpl: Adding task set 31.0 with 1 tasks
21/02/17 01:39:44 INFO TaskSetManager: Starting task 0.0 in stage 31.0 (TID 33, localhost, executor driver, partition 0, NODE_LOCAL, 7767 bytes)
21/02/17 01:39:44 INFO Executor: Running task 0.0 in stage 31.0 (TID 33)
21/02/17 01:39:44 INFO ShuffleBlockFetcherIterator: Getting 2 non-empty blocks including 2 local blocks and 0 remote blocks
21/02/17 01:39:44 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
21/02/17 01:39:44 INFO Executor: Finished task 0.0 in stage 31.0 (TID 33). 1782 bytes result sent to driver
21/02/17 01:39:44 INFO TaskSetManager: Finished task 0.0 in stage 31.0 (TID 33) in 4 ms on localhost (executor driver) (1/1)
21/02/17 01:39:44 INFO TaskSchedulerImpl: Removed TaskSet 31.0, whose tasks have all completed, from pool 
21/02/17 01:39:44 INFO DAGScheduler: ResultStage 31 (count at utils.scala:135) finished in 0.008 s
21/02/17 01:39:44 INFO DAGScheduler: Job 23 finished: count at utils.scala:135, took 0.020010 s
21/02/17 01:39:44 INFO FileSourceStrategy: Pruning directories with: 
21/02/17 01:39:44 INFO FileSourceStrategy: Post-Scan Filters: 
21/02/17 01:39:44 INFO FileSourceStrategy: Output Data Schema: struct<class: string, paramMap: struct<stageUids: array<string>>, sparkVersion: string, timestamp: bigint, uid: string ... 3 more fields>
21/02/17 01:39:44 INFO FileSourceScanExec: Pushed Filters: 
21/02/17 01:39:44 INFO MemoryStore: Block broadcast_34 stored as values in memory (estimated size 290.3 KB, free 911.7 MB)
21/02/17 01:39:44 INFO MemoryStore: Block broadcast_34_piece0 stored as bytes in memory (estimated size 24.5 KB, free 911.6 MB)
21/02/17 01:39:44 INFO BlockManagerInfo: Added broadcast_34_piece0 in memory on localhost:37301 (size: 24.5 KB, free: 912.2 MB)
21/02/17 01:39:44 INFO SparkContext: Created broadcast 34 from sql at <unknown>:0
21/02/17 01:39:44 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
21/02/17 01:39:44 INFO SparkContext: Starting job: sql at <unknown>:0
21/02/17 01:39:44 INFO DAGScheduler: Registering RDD 113 (sql at <unknown>:0)
21/02/17 01:39:44 INFO DAGScheduler: Got job 24 (sql at <unknown>:0) with 1 output partitions
21/02/17 01:39:44 INFO DAGScheduler: Final stage: ResultStage 33 (sql at <unknown>:0)
21/02/17 01:39:44 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 32)
21/02/17 01:39:44 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 32)
21/02/17 01:39:44 INFO DAGScheduler: Submitting ShuffleMapStage 32 (MapPartitionsRDD[113] at sql at <unknown>:0), which has no missing parents
21/02/17 01:39:44 INFO MemoryStore: Block broadcast_35 stored as values in memory (estimated size 20.2 KB, free 911.6 MB)
21/02/17 01:39:44 INFO MemoryStore: Block broadcast_35_piece0 stored as bytes in memory (estimated size 9.6 KB, free 911.6 MB)
21/02/17 01:39:44 INFO BlockManagerInfo: Added broadcast_35_piece0 in memory on localhost:37301 (size: 9.6 KB, free: 912.2 MB)
21/02/17 01:39:44 INFO SparkContext: Created broadcast 35 from broadcast at DAGScheduler.scala:1161
21/02/17 01:39:44 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 32 (MapPartitionsRDD[113] at sql at <unknown>:0) (first 15 tasks are for partitions Vector(0))
21/02/17 01:39:44 INFO TaskSchedulerImpl: Adding task set 32.0 with 1 tasks
21/02/17 01:39:44 INFO TaskSetManager: Starting task 0.0 in stage 32.0 (TID 34, localhost, executor driver, partition 0, PROCESS_LOCAL, 8265 bytes)
21/02/17 01:39:44 INFO Executor: Running task 0.0 in stage 32.0 (TID 34)
21/02/17 01:39:44 INFO FileScanRDD: Reading File path: file:///tmp/RtmpaHGCHH/file22ad95b56a718/metadata/part-00000, range: 0-306, partition values: [empty row]
21/02/17 01:39:44 INFO CodeGenerator: Code generated in 6.715865 ms
21/02/17 01:39:44 INFO MemoryStore: Block rdd_108_0 stored as values in memory (estimated size 1296.0 B, free 911.6 MB)
21/02/17 01:39:44 INFO BlockManagerInfo: Added rdd_108_0 in memory on localhost:37301 (size: 1296.0 B, free: 912.2 MB)
21/02/17 01:39:44 INFO CodeGenerator: Code generated in 7.582038 ms
21/02/17 01:39:44 INFO Executor: Finished task 0.0 in stage 32.0 (TID 34). 1871 bytes result sent to driver
21/02/17 01:39:44 INFO TaskSetManager: Finished task 0.0 in stage 32.0 (TID 34) in 48 ms on localhost (executor driver) (1/1)
21/02/17 01:39:44 INFO TaskSchedulerImpl: Removed TaskSet 32.0, whose tasks have all completed, from pool 
21/02/17 01:39:44 INFO DAGScheduler: ShuffleMapStage 32 (sql at <unknown>:0) finished in 0.055 s
21/02/17 01:39:44 INFO DAGScheduler: looking for newly runnable stages
21/02/17 01:39:44 INFO DAGScheduler: running: Set()
21/02/17 01:39:44 INFO DAGScheduler: waiting: Set(ResultStage 33)
21/02/17 01:39:44 INFO DAGScheduler: failed: Set()
21/02/17 01:39:44 INFO DAGScheduler: Submitting ResultStage 33 (MapPartitionsRDD[116] at sql at <unknown>:0), which has no missing parents
21/02/17 01:39:44 INFO MemoryStore: Block broadcast_36 stored as values in memory (estimated size 7.1 KB, free 911.6 MB)
21/02/17 01:39:44 INFO MemoryStore: Block broadcast_36_piece0 stored as bytes in memory (estimated size 3.8 KB, free 911.6 MB)
21/02/17 01:39:44 INFO BlockManagerInfo: Added broadcast_36_piece0 in memory on localhost:37301 (size: 3.8 KB, free: 912.2 MB)
21/02/17 01:39:44 INFO SparkContext: Created broadcast 36 from broadcast at DAGScheduler.scala:1161
21/02/17 01:39:44 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 33 (MapPartitionsRDD[116] at sql at <unknown>:0) (first 15 tasks are for partitions Vector(0))
21/02/17 01:39:44 INFO TaskSchedulerImpl: Adding task set 33.0 with 1 tasks
21/02/17 01:39:44 INFO TaskSetManager: Starting task 0.0 in stage 33.0 (TID 35, localhost, executor driver, partition 0, NODE_LOCAL, 7767 bytes)
21/02/17 01:39:44 INFO Executor: Running task 0.0 in stage 33.0 (TID 35)
21/02/17 01:39:44 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks including 1 local blocks and 0 remote blocks
21/02/17 01:39:44 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
21/02/17 01:39:44 INFO Executor: Finished task 0.0 in stage 33.0 (TID 35). 1739 bytes result sent to driver
21/02/17 01:39:44 INFO TaskSetManager: Finished task 0.0 in stage 33.0 (TID 35) in 3 ms on localhost (executor driver) (1/1)
21/02/17 01:39:44 INFO TaskSchedulerImpl: Removed TaskSet 33.0, whose tasks have all completed, from pool 
21/02/17 01:39:44 INFO DAGScheduler: ResultStage 33 (sql at <unknown>:0) finished in 0.006 s
21/02/17 01:39:44 INFO DAGScheduler: Job 24 finished: sql at <unknown>:0, took 0.064462 s
21/02/17 01:39:44 INFO CodeGenerator: Code generated in 4.41298 ms
21/02/17 01:39:44 INFO SparkContext: Starting job: collect at utils.scala:135
21/02/17 01:39:44 INFO DAGScheduler: Registering RDD 121 (collect at utils.scala:135)
21/02/17 01:39:44 INFO DAGScheduler: Got job 25 (collect at utils.scala:135) with 1 output partitions
21/02/17 01:39:44 INFO DAGScheduler: Final stage: ResultStage 35 (collect at utils.scala:135)
21/02/17 01:39:44 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 34)
21/02/17 01:39:44 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 34)
21/02/17 01:39:44 INFO DAGScheduler: Submitting ShuffleMapStage 34 (MapPartitionsRDD[121] at collect at utils.scala:135), which has no missing parents
21/02/17 01:39:44 INFO MemoryStore: Block broadcast_37 stored as values in memory (estimated size 20.2 KB, free 911.6 MB)
21/02/17 01:39:44 INFO MemoryStore: Block broadcast_37_piece0 stored as bytes in memory (estimated size 9.6 KB, free 911.6 MB)
21/02/17 01:39:44 INFO BlockManagerInfo: Added broadcast_37_piece0 in memory on localhost:37301 (size: 9.6 KB, free: 912.2 MB)
21/02/17 01:39:44 INFO SparkContext: Created broadcast 37 from broadcast at DAGScheduler.scala:1161
21/02/17 01:39:44 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 34 (MapPartitionsRDD[121] at collect at utils.scala:135) (first 15 tasks are for partitions Vector(0))
21/02/17 01:39:44 INFO TaskSchedulerImpl: Adding task set 34.0 with 1 tasks
21/02/17 01:39:44 INFO TaskSetManager: Starting task 0.0 in stage 34.0 (TID 36, localhost, executor driver, partition 0, PROCESS_LOCAL, 8265 bytes)
21/02/17 01:39:44 INFO Executor: Running task 0.0 in stage 34.0 (TID 36)
21/02/17 01:39:44 INFO BlockManager: Found block rdd_108_0 locally
21/02/17 01:39:44 INFO Executor: Finished task 0.0 in stage 34.0 (TID 36). 1871 bytes result sent to driver
21/02/17 01:39:44 INFO TaskSetManager: Finished task 0.0 in stage 34.0 (TID 36) in 4 ms on localhost (executor driver) (1/1)
21/02/17 01:39:44 INFO TaskSchedulerImpl: Removed TaskSet 34.0, whose tasks have all completed, from pool 
21/02/17 01:39:44 INFO DAGScheduler: ShuffleMapStage 34 (collect at utils.scala:135) finished in 0.010 s
21/02/17 01:39:44 INFO DAGScheduler: looking for newly runnable stages
21/02/17 01:39:44 INFO DAGScheduler: running: Set()
21/02/17 01:39:44 INFO DAGScheduler: waiting: Set(ResultStage 35)
21/02/17 01:39:44 INFO DAGScheduler: failed: Set()
21/02/17 01:39:44 INFO DAGScheduler: Submitting ResultStage 35 (MapPartitionsRDD[124] at collect at utils.scala:135), which has no missing parents
21/02/17 01:39:44 INFO MemoryStore: Block broadcast_38 stored as values in memory (estimated size 7.1 KB, free 911.6 MB)
21/02/17 01:39:44 INFO MemoryStore: Block broadcast_38_piece0 stored as bytes in memory (estimated size 3.8 KB, free 911.6 MB)
21/02/17 01:39:44 INFO BlockManagerInfo: Added broadcast_38_piece0 in memory on localhost:37301 (size: 3.8 KB, free: 912.2 MB)
21/02/17 01:39:44 INFO SparkContext: Created broadcast 38 from broadcast at DAGScheduler.scala:1161
21/02/17 01:39:44 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 35 (MapPartitionsRDD[124] at collect at utils.scala:135) (first 15 tasks are for partitions Vector(0))
21/02/17 01:39:44 INFO TaskSchedulerImpl: Adding task set 35.0 with 1 tasks
21/02/17 01:39:44 INFO TaskSetManager: Starting task 0.0 in stage 35.0 (TID 37, localhost, executor driver, partition 0, NODE_LOCAL, 7767 bytes)
21/02/17 01:39:44 INFO Executor: Running task 0.0 in stage 35.0 (TID 37)
21/02/17 01:39:44 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks including 1 local blocks and 0 remote blocks
21/02/17 01:39:44 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
21/02/17 01:39:44 INFO Executor: Finished task 0.0 in stage 35.0 (TID 37). 1739 bytes result sent to driver
21/02/17 01:39:44 INFO TaskSetManager: Finished task 0.0 in stage 35.0 (TID 37) in 4 ms on localhost (executor driver) (1/1)
21/02/17 01:39:44 INFO TaskSchedulerImpl: Removed TaskSet 35.0, whose tasks have all completed, from pool 
21/02/17 01:39:44 INFO DAGScheduler: ResultStage 35 (collect at utils.scala:135) finished in 0.007 s
21/02/17 01:39:44 INFO DAGScheduler: Job 25 finished: collect at utils.scala:135, took 0.020268 s
21/02/17 01:39:44 INFO CodeGenerator: Code generated in 6.868396 ms
21/02/17 01:39:44 INFO CodeGenerator: Code generated in 4.715424 ms
21/02/17 01:39:44 INFO SparkContext: Starting job: count at utils.scala:135
21/02/17 01:39:44 INFO DAGScheduler: Registering RDD 129 (count at utils.scala:135)
21/02/17 01:39:44 INFO DAGScheduler: Got job 26 (count at utils.scala:135) with 1 output partitions
21/02/17 01:39:44 INFO DAGScheduler: Final stage: ResultStage 37 (count at utils.scala:135)
21/02/17 01:39:44 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 36)
21/02/17 01:39:44 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 36)
21/02/17 01:39:44 INFO DAGScheduler: Submitting ShuffleMapStage 36 (MapPartitionsRDD[129] at count at utils.scala:135), which has no missing parents
21/02/17 01:39:44 INFO MemoryStore: Block broadcast_39 stored as values in memory (estimated size 19.6 KB, free 911.5 MB)
21/02/17 01:39:44 INFO MemoryStore: Block broadcast_39_piece0 stored as bytes in memory (estimated size 9.4 KB, free 911.5 MB)
21/02/17 01:39:44 INFO BlockManagerInfo: Added broadcast_39_piece0 in memory on localhost:37301 (size: 9.4 KB, free: 912.2 MB)
21/02/17 01:39:44 INFO SparkContext: Created broadcast 39 from broadcast at DAGScheduler.scala:1161
21/02/17 01:39:44 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 36 (MapPartitionsRDD[129] at count at utils.scala:135) (first 15 tasks are for partitions Vector(0))
21/02/17 01:39:44 INFO TaskSchedulerImpl: Adding task set 36.0 with 1 tasks
21/02/17 01:39:44 INFO TaskSetManager: Starting task 0.0 in stage 36.0 (TID 38, localhost, executor driver, partition 0, PROCESS_LOCAL, 8265 bytes)
21/02/17 01:39:44 INFO Executor: Running task 0.0 in stage 36.0 (TID 38)
21/02/17 01:39:44 INFO BlockManager: Found block rdd_108_0 locally
21/02/17 01:39:44 INFO Executor: Finished task 0.0 in stage 36.0 (TID 38). 1871 bytes result sent to driver
21/02/17 01:39:44 INFO TaskSetManager: Finished task 0.0 in stage 36.0 (TID 38) in 6 ms on localhost (executor driver) (1/1)
21/02/17 01:39:44 INFO TaskSchedulerImpl: Removed TaskSet 36.0, whose tasks have all completed, from pool 
21/02/17 01:39:44 INFO DAGScheduler: ShuffleMapStage 36 (count at utils.scala:135) finished in 0.011 s
21/02/17 01:39:44 INFO DAGScheduler: looking for newly runnable stages
21/02/17 01:39:44 INFO DAGScheduler: running: Set()
21/02/17 01:39:44 INFO DAGScheduler: waiting: Set(ResultStage 37)
21/02/17 01:39:44 INFO DAGScheduler: failed: Set()
21/02/17 01:39:44 INFO DAGScheduler: Submitting ResultStage 37 (MapPartitionsRDD[132] at count at utils.scala:135), which has no missing parents
21/02/17 01:39:44 INFO MemoryStore: Block broadcast_40 stored as values in memory (estimated size 9.1 KB, free 911.5 MB)
21/02/17 01:39:44 INFO MemoryStore: Block broadcast_40_piece0 stored as bytes in memory (estimated size 4.1 KB, free 911.5 MB)
21/02/17 01:39:44 INFO BlockManagerInfo: Added broadcast_40_piece0 in memory on localhost:37301 (size: 4.1 KB, free: 912.2 MB)
21/02/17 01:39:44 INFO SparkContext: Created broadcast 40 from broadcast at DAGScheduler.scala:1161
21/02/17 01:39:44 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 37 (MapPartitionsRDD[132] at count at utils.scala:135) (first 15 tasks are for partitions Vector(0))
21/02/17 01:39:44 INFO TaskSchedulerImpl: Adding task set 37.0 with 1 tasks
21/02/17 01:39:44 INFO TaskSetManager: Starting task 0.0 in stage 37.0 (TID 39, localhost, executor driver, partition 0, NODE_LOCAL, 7767 bytes)
21/02/17 01:39:44 INFO Executor: Running task 0.0 in stage 37.0 (TID 39)
21/02/17 01:39:44 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks including 1 local blocks and 0 remote blocks
21/02/17 01:39:44 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
21/02/17 01:39:44 INFO Executor: Finished task 0.0 in stage 37.0 (TID 39). 2098 bytes result sent to driver
21/02/17 01:39:44 INFO TaskSetManager: Finished task 0.0 in stage 37.0 (TID 39) in 9 ms on localhost (executor driver) (1/1)
21/02/17 01:39:44 INFO TaskSchedulerImpl: Removed TaskSet 37.0, whose tasks have all completed, from pool 
21/02/17 01:39:44 INFO DAGScheduler: ResultStage 37 (count at utils.scala:135) finished in 0.015 s
21/02/17 01:39:44 INFO DAGScheduler: Job 26 finished: count at utils.scala:135, took 0.028957 s
21/02/17 01:39:44 INFO SparkContext: Starting job: collect at utils.scala:135
21/02/17 01:39:44 INFO DAGScheduler: Got job 27 (collect at utils.scala:135) with 1 output partitions
21/02/17 01:39:44 INFO DAGScheduler: Final stage: ResultStage 38 (collect at utils.scala:135)
21/02/17 01:39:44 INFO DAGScheduler: Parents of final stage: List()
21/02/17 01:39:44 INFO DAGScheduler: Missing parents: List()
21/02/17 01:39:44 INFO DAGScheduler: Submitting ResultStage 38 (MapPartitionsRDD[135] at collect at utils.scala:135), which has no missing parents
21/02/17 01:39:44 INFO MemoryStore: Block broadcast_41 stored as values in memory (estimated size 6.2 KB, free 911.5 MB)
21/02/17 01:39:44 INFO MemoryStore: Block broadcast_41_piece0 stored as bytes in memory (estimated size 3.3 KB, free 911.5 MB)
21/02/17 01:39:44 INFO BlockManagerInfo: Added broadcast_41_piece0 in memory on localhost:37301 (size: 3.3 KB, free: 912.2 MB)
21/02/17 01:39:44 INFO SparkContext: Created broadcast 41 from broadcast at DAGScheduler.scala:1161
21/02/17 01:39:44 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 38 (MapPartitionsRDD[135] at collect at utils.scala:135) (first 15 tasks are for partitions Vector(0))
21/02/17 01:39:44 INFO TaskSchedulerImpl: Adding task set 38.0 with 1 tasks
21/02/17 01:39:44 INFO TaskSetManager: Starting task 0.0 in stage 38.0 (TID 40, localhost, executor driver, partition 0, PROCESS_LOCAL, 8080 bytes)
21/02/17 01:39:44 INFO Executor: Running task 0.0 in stage 38.0 (TID 40)
21/02/17 01:39:44 INFO Executor: Finished task 0.0 in stage 38.0 (TID 40). 1286 bytes result sent to driver
21/02/17 01:39:44 INFO TaskSetManager: Finished task 0.0 in stage 38.0 (TID 40) in 4 ms on localhost (executor driver) (1/1)
21/02/17 01:39:44 INFO TaskSchedulerImpl: Removed TaskSet 38.0, whose tasks have all completed, from pool 
21/02/17 01:39:44 INFO DAGScheduler: ResultStage 38 (collect at utils.scala:135) finished in 0.006 s
21/02/17 01:39:44 INFO DAGScheduler: Job 27 finished: collect at utils.scala:135, took 0.008164 s
21/02/17 01:39:44 INFO SparkContext: Starting job: count at utils.scala:135
21/02/17 01:39:44 INFO DAGScheduler: Registering RDD 138 (count at utils.scala:135)
21/02/17 01:39:44 INFO DAGScheduler: Got job 28 (count at utils.scala:135) with 1 output partitions
21/02/17 01:39:44 INFO DAGScheduler: Final stage: ResultStage 40 (count at utils.scala:135)
21/02/17 01:39:44 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 39)
21/02/17 01:39:44 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 39)
21/02/17 01:39:44 INFO DAGScheduler: Submitting ShuffleMapStage 39 (MapPartitionsRDD[138] at count at utils.scala:135), which has no missing parents
21/02/17 01:39:44 INFO MemoryStore: Block broadcast_42 stored as values in memory (estimated size 8.4 KB, free 911.5 MB)
21/02/17 01:39:44 INFO MemoryStore: Block broadcast_42_piece0 stored as bytes in memory (estimated size 4.5 KB, free 911.5 MB)
21/02/17 01:39:44 INFO BlockManagerInfo: Added broadcast_42_piece0 in memory on localhost:37301 (size: 4.5 KB, free: 912.2 MB)
21/02/17 01:39:44 INFO SparkContext: Created broadcast 42 from broadcast at DAGScheduler.scala:1161
21/02/17 01:39:44 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 39 (MapPartitionsRDD[138] at count at utils.scala:135) (first 15 tasks are for partitions Vector(0))
21/02/17 01:39:44 INFO TaskSchedulerImpl: Adding task set 39.0 with 1 tasks
21/02/17 01:39:44 INFO TaskSetManager: Starting task 0.0 in stage 39.0 (TID 41, localhost, executor driver, partition 0, PROCESS_LOCAL, 8069 bytes)
21/02/17 01:39:44 INFO Executor: Running task 0.0 in stage 39.0 (TID 41)
21/02/17 01:39:44 INFO Executor: Finished task 0.0 in stage 39.0 (TID 41). 1499 bytes result sent to driver
21/02/17 01:39:44 INFO TaskSetManager: Finished task 0.0 in stage 39.0 (TID 41) in 4 ms on localhost (executor driver) (1/1)
21/02/17 01:39:44 INFO TaskSchedulerImpl: Removed TaskSet 39.0, whose tasks have all completed, from pool 
21/02/17 01:39:44 INFO DAGScheduler: ShuffleMapStage 39 (count at utils.scala:135) finished in 0.010 s
21/02/17 01:39:44 INFO DAGScheduler: looking for newly runnable stages
21/02/17 01:39:44 INFO DAGScheduler: running: Set()
21/02/17 01:39:44 INFO DAGScheduler: waiting: Set(ResultStage 40)
21/02/17 01:39:44 INFO DAGScheduler: failed: Set()
21/02/17 01:39:44 INFO DAGScheduler: Submitting ResultStage 40 (MapPartitionsRDD[141] at count at utils.scala:135), which has no missing parents
21/02/17 01:39:44 INFO MemoryStore: Block broadcast_43 stored as values in memory (estimated size 7.1 KB, free 911.5 MB)
21/02/17 01:39:44 INFO MemoryStore: Block broadcast_43_piece0 stored as bytes in memory (estimated size 3.8 KB, free 911.5 MB)
21/02/17 01:39:44 INFO BlockManagerInfo: Added broadcast_43_piece0 in memory on localhost:37301 (size: 3.8 KB, free: 912.2 MB)
21/02/17 01:39:44 INFO SparkContext: Created broadcast 43 from broadcast at DAGScheduler.scala:1161
21/02/17 01:39:44 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 40 (MapPartitionsRDD[141] at count at utils.scala:135) (first 15 tasks are for partitions Vector(0))
21/02/17 01:39:44 INFO TaskSchedulerImpl: Adding task set 40.0 with 1 tasks
21/02/17 01:39:44 INFO TaskSetManager: Starting task 0.0 in stage 40.0 (TID 42, localhost, executor driver, partition 0, NODE_LOCAL, 7767 bytes)
21/02/17 01:39:44 INFO Executor: Running task 0.0 in stage 40.0 (TID 42)
21/02/17 01:39:44 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks including 1 local blocks and 0 remote blocks
21/02/17 01:39:44 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
21/02/17 01:39:44 INFO Executor: Finished task 0.0 in stage 40.0 (TID 42). 1782 bytes result sent to driver
21/02/17 01:39:44 INFO TaskSetManager: Finished task 0.0 in stage 40.0 (TID 42) in 4 ms on localhost (executor driver) (1/1)
21/02/17 01:39:44 INFO TaskSchedulerImpl: Removed TaskSet 40.0, whose tasks have all completed, from pool 
21/02/17 01:39:44 INFO DAGScheduler: ResultStage 40 (count at utils.scala:135) finished in 0.007 s
21/02/17 01:39:44 INFO DAGScheduler: Job 28 finished: count at utils.scala:135, took 0.019683 s
21/02/17 01:39:45 INFO CodeGenerator: Code generated in 4.226774 ms
21/02/17 01:39:45 INFO SparkContext: Starting job: collect at utils.scala:135
21/02/17 01:39:45 INFO DAGScheduler: Got job 29 (collect at utils.scala:135) with 1 output partitions
21/02/17 01:39:45 INFO DAGScheduler: Final stage: ResultStage 41 (collect at utils.scala:135)
21/02/17 01:39:45 INFO DAGScheduler: Parents of final stage: List()
21/02/17 01:39:45 INFO DAGScheduler: Missing parents: List()
21/02/17 01:39:45 INFO DAGScheduler: Submitting ResultStage 41 (MapPartitionsRDD[145] at collect at utils.scala:135), which has no missing parents
21/02/17 01:39:45 INFO MemoryStore: Block broadcast_44 stored as values in memory (estimated size 16.5 KB, free 911.5 MB)
21/02/17 01:39:45 INFO MemoryStore: Block broadcast_44_piece0 stored as bytes in memory (estimated size 8.2 KB, free 911.5 MB)
21/02/17 01:39:45 INFO BlockManagerInfo: Added broadcast_44_piece0 in memory on localhost:37301 (size: 8.2 KB, free: 912.2 MB)
21/02/17 01:39:45 INFO SparkContext: Created broadcast 44 from broadcast at DAGScheduler.scala:1161
21/02/17 01:39:45 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 41 (MapPartitionsRDD[145] at collect at utils.scala:135) (first 15 tasks are for partitions Vector(0))
21/02/17 01:39:45 INFO TaskSchedulerImpl: Adding task set 41.0 with 1 tasks
21/02/17 01:39:45 INFO TaskSetManager: Starting task 0.0 in stage 41.0 (TID 43, localhost, executor driver, partition 0, PROCESS_LOCAL, 8276 bytes)
21/02/17 01:39:45 INFO Executor: Running task 0.0 in stage 41.0 (TID 43)
21/02/17 01:39:45 INFO BlockManager: Found block rdd_108_0 locally
21/02/17 01:39:45 INFO CodeGenerator: Code generated in 10.269685 ms
21/02/17 01:39:45 INFO Executor: Finished task 0.0 in stage 41.0 (TID 43). 1615 bytes result sent to driver
21/02/17 01:39:45 INFO TaskSetManager: Finished task 0.0 in stage 41.0 (TID 43) in 17 ms on localhost (executor driver) (1/1)
21/02/17 01:39:45 INFO TaskSchedulerImpl: Removed TaskSet 41.0, whose tasks have all completed, from pool 
21/02/17 01:39:45 INFO DAGScheduler: ResultStage 41 (collect at utils.scala:135) finished in 0.020 s
21/02/17 01:39:45 INFO DAGScheduler: Job 29 finished: collect at utils.scala:135, took 0.022915 s
21/02/17 01:39:45 INFO SparkContext: Starting job: count at utils.scala:135
21/02/17 01:39:45 INFO DAGScheduler: Registering RDD 150 (count at utils.scala:135)
21/02/17 01:39:45 INFO DAGScheduler: Got job 30 (count at utils.scala:135) with 1 output partitions
21/02/17 01:39:45 INFO DAGScheduler: Final stage: ResultStage 43 (count at utils.scala:135)
21/02/17 01:39:45 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 42)
21/02/17 01:39:45 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 42)
21/02/17 01:39:45 INFO DAGScheduler: Submitting ShuffleMapStage 42 (MapPartitionsRDD[150] at count at utils.scala:135), which has no missing parents
21/02/17 01:39:45 INFO MemoryStore: Block broadcast_45 stored as values in memory (estimated size 20.2 KB, free 911.4 MB)
21/02/17 01:39:45 INFO MemoryStore: Block broadcast_45_piece0 stored as bytes in memory (estimated size 9.6 KB, free 911.4 MB)
21/02/17 01:39:45 INFO BlockManagerInfo: Added broadcast_45_piece0 in memory on localhost:37301 (size: 9.6 KB, free: 912.2 MB)
21/02/17 01:39:45 INFO SparkContext: Created broadcast 45 from broadcast at DAGScheduler.scala:1161
21/02/17 01:39:45 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 42 (MapPartitionsRDD[150] at count at utils.scala:135) (first 15 tasks are for partitions Vector(0))
21/02/17 01:39:45 INFO TaskSchedulerImpl: Adding task set 42.0 with 1 tasks
21/02/17 01:39:45 INFO TaskSetManager: Starting task 0.0 in stage 42.0 (TID 44, localhost, executor driver, partition 0, PROCESS_LOCAL, 8265 bytes)
21/02/17 01:39:45 INFO Executor: Running task 0.0 in stage 42.0 (TID 44)
21/02/17 01:39:45 INFO BlockManager: Found block rdd_108_0 locally
21/02/17 01:39:45 INFO Executor: Finished task 0.0 in stage 42.0 (TID 44). 1871 bytes result sent to driver
21/02/17 01:39:45 INFO TaskSetManager: Finished task 0.0 in stage 42.0 (TID 44) in 6 ms on localhost (executor driver) (1/1)
21/02/17 01:39:45 INFO TaskSchedulerImpl: Removed TaskSet 42.0, whose tasks have all completed, from pool 
21/02/17 01:39:45 INFO DAGScheduler: ShuffleMapStage 42 (count at utils.scala:135) finished in 0.011 s
21/02/17 01:39:45 INFO DAGScheduler: looking for newly runnable stages
21/02/17 01:39:45 INFO DAGScheduler: running: Set()
21/02/17 01:39:45 INFO DAGScheduler: waiting: Set(ResultStage 43)
21/02/17 01:39:45 INFO DAGScheduler: failed: Set()
21/02/17 01:39:45 INFO DAGScheduler: Submitting ResultStage 43 (MapPartitionsRDD[153] at count at utils.scala:135), which has no missing parents
21/02/17 01:39:45 INFO MemoryStore: Block broadcast_46 stored as values in memory (estimated size 7.1 KB, free 911.4 MB)
21/02/17 01:39:45 INFO MemoryStore: Block broadcast_46_piece0 stored as bytes in memory (estimated size 3.8 KB, free 911.4 MB)
21/02/17 01:39:45 INFO BlockManagerInfo: Added broadcast_46_piece0 in memory on localhost:37301 (size: 3.8 KB, free: 912.2 MB)
21/02/17 01:39:45 INFO SparkContext: Created broadcast 46 from broadcast at DAGScheduler.scala:1161
21/02/17 01:39:45 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 43 (MapPartitionsRDD[153] at count at utils.scala:135) (first 15 tasks are for partitions Vector(0))
21/02/17 01:39:45 INFO TaskSchedulerImpl: Adding task set 43.0 with 1 tasks
21/02/17 01:39:45 INFO TaskSetManager: Starting task 0.0 in stage 43.0 (TID 45, localhost, executor driver, partition 0, NODE_LOCAL, 7767 bytes)
21/02/17 01:39:45 INFO Executor: Running task 0.0 in stage 43.0 (TID 45)
21/02/17 01:39:45 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks including 1 local blocks and 0 remote blocks
21/02/17 01:39:45 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
21/02/17 01:39:45 INFO Executor: Finished task 0.0 in stage 43.0 (TID 45). 1739 bytes result sent to driver
21/02/17 01:39:45 INFO TaskSetManager: Finished task 0.0 in stage 43.0 (TID 45) in 4 ms on localhost (executor driver) (1/1)
21/02/17 01:39:45 INFO TaskSchedulerImpl: Removed TaskSet 43.0, whose tasks have all completed, from pool 
21/02/17 01:39:45 INFO DAGScheduler: ResultStage 43 (count at utils.scala:135) finished in 0.007 s
21/02/17 01:39:45 INFO DAGScheduler: Job 30 finished: count at utils.scala:135, took 0.021355 s
21/02/17 01:39:45 INFO MapPartitionsRDD: Removing RDD 108 from persistence list
21/02/17 01:39:45 INFO BlockManager: Removing RDD 108
21/02/17 01:39:45 INFO MemoryStore: Block broadcast_47 stored as values in memory (estimated size 239.6 KB, free 911.2 MB)
21/02/17 01:39:45 INFO MemoryStore: Block broadcast_47_piece0 stored as bytes in memory (estimated size 23.2 KB, free 911.2 MB)
21/02/17 01:39:45 INFO BlockManagerInfo: Added broadcast_47_piece0 in memory on localhost:37301 (size: 23.2 KB, free: 912.1 MB)
21/02/17 01:39:45 INFO SparkContext: Created broadcast 47 from textFile at ReadWrite.scala:615
21/02/17 01:39:45 INFO FileInputFormat: Total input paths to process : 1
21/02/17 01:39:45 INFO SparkContext: Starting job: first at ReadWrite.scala:615
21/02/17 01:39:45 INFO DAGScheduler: Got job 31 (first at ReadWrite.scala:615) with 1 output partitions
21/02/17 01:39:45 INFO DAGScheduler: Final stage: ResultStage 44 (first at ReadWrite.scala:615)
21/02/17 01:39:45 INFO DAGScheduler: Parents of final stage: List()
21/02/17 01:39:45 INFO DAGScheduler: Missing parents: List()
21/02/17 01:39:45 INFO DAGScheduler: Submitting ResultStage 44 (/tmp/RtmpaHGCHH/file22ad95b56a718/metadata MapPartitionsRDD[155] at textFile at ReadWrite.scala:615), which has no missing parents
21/02/17 01:39:45 INFO MemoryStore: Block broadcast_48 stored as values in memory (estimated size 3.5 KB, free 911.2 MB)
21/02/17 01:39:45 INFO MemoryStore: Block broadcast_48_piece0 stored as bytes in memory (estimated size 2.1 KB, free 911.2 MB)
21/02/17 01:39:45 INFO BlockManagerInfo: Added broadcast_48_piece0 in memory on localhost:37301 (size: 2.1 KB, free: 912.1 MB)
21/02/17 01:39:45 INFO SparkContext: Created broadcast 48 from broadcast at DAGScheduler.scala:1161
21/02/17 01:39:45 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 44 (/tmp/RtmpaHGCHH/file22ad95b56a718/metadata MapPartitionsRDD[155] at textFile at ReadWrite.scala:615) (first 15 tasks are for partitions Vector(0))
21/02/17 01:39:45 INFO TaskSchedulerImpl: Adding task set 44.0 with 1 tasks
21/02/17 01:39:45 INFO TaskSetManager: Starting task 0.0 in stage 44.0 (TID 46, localhost, executor driver, partition 0, PROCESS_LOCAL, 7918 bytes)
21/02/17 01:39:45 INFO Executor: Running task 0.0 in stage 44.0 (TID 46)
21/02/17 01:39:45 INFO HadoopRDD: Input split: file:/tmp/RtmpaHGCHH/file22ad95b56a718/metadata/part-00000:0+306
21/02/17 01:39:45 INFO Executor: Finished task 0.0 in stage 44.0 (TID 46). 1105 bytes result sent to driver
21/02/17 01:39:45 INFO TaskSetManager: Finished task 0.0 in stage 44.0 (TID 46) in 21 ms on localhost (executor driver) (1/1)
21/02/17 01:39:45 INFO TaskSchedulerImpl: Removed TaskSet 44.0, whose tasks have all completed, from pool 
21/02/17 01:39:45 INFO DAGScheduler: ResultStage 44 (first at ReadWrite.scala:615) finished in 0.023 s
21/02/17 01:39:45 INFO DAGScheduler: Job 31 finished: first at ReadWrite.scala:615, took 0.026263 s
21/02/17 01:39:45 INFO MemoryStore: Block broadcast_49 stored as values in memory (estimated size 239.6 KB, free 910.9 MB)
21/02/17 01:39:45 INFO MemoryStore: Block broadcast_49_piece0 stored as bytes in memory (estimated size 23.2 KB, free 910.9 MB)
21/02/17 01:39:45 INFO BlockManagerInfo: Added broadcast_49_piece0 in memory on localhost:37301 (size: 23.2 KB, free: 912.1 MB)
21/02/17 01:39:45 INFO SparkContext: Created broadcast 49 from textFile at ReadWrite.scala:615
21/02/17 01:39:45 INFO FileInputFormat: Total input paths to process : 1
21/02/17 01:39:45 INFO SparkContext: Starting job: first at ReadWrite.scala:615
21/02/17 01:39:45 INFO DAGScheduler: Got job 32 (first at ReadWrite.scala:615) with 1 output partitions
21/02/17 01:39:45 INFO DAGScheduler: Final stage: ResultStage 45 (first at ReadWrite.scala:615)
21/02/17 01:39:45 INFO DAGScheduler: Parents of final stage: List()
21/02/17 01:39:45 INFO DAGScheduler: Missing parents: List()
21/02/17 01:39:45 INFO DAGScheduler: Submitting ResultStage 45 (/tmp/RtmpaHGCHH/file22ad95b56a718/stages/0_r_formula__8eae6edf_b16e_4036_a8d6_baf58826f8d0/metadata MapPartitionsRDD[157] at textFile at ReadWrite.scala:615), which has no missing parents
21/02/17 01:39:45 INFO MemoryStore: Block broadcast_50 stored as values in memory (estimated size 3.5 KB, free 910.9 MB)
21/02/17 01:39:45 INFO MemoryStore: Block broadcast_50_piece0 stored as bytes in memory (estimated size 2.1 KB, free 910.9 MB)
21/02/17 01:39:45 INFO BlockManagerInfo: Added broadcast_50_piece0 in memory on localhost:37301 (size: 2.1 KB, free: 912.1 MB)
21/02/17 01:39:45 INFO SparkContext: Created broadcast 50 from broadcast at DAGScheduler.scala:1161
21/02/17 01:39:45 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 45 (/tmp/RtmpaHGCHH/file22ad95b56a718/stages/0_r_formula__8eae6edf_b16e_4036_a8d6_baf58826f8d0/metadata MapPartitionsRDD[157] at textFile at ReadWrite.scala:615) (first 15 tasks are for partitions Vector(0))
21/02/17 01:39:45 INFO TaskSchedulerImpl: Adding task set 45.0 with 1 tasks
21/02/17 01:39:45 INFO TaskSetManager: Starting task 0.0 in stage 45.0 (TID 47, localhost, executor driver, partition 0, PROCESS_LOCAL, 7975 bytes)
21/02/17 01:39:45 INFO Executor: Running task 0.0 in stage 45.0 (TID 47)
21/02/17 01:39:45 INFO HadoopRDD: Input split: file:/tmp/RtmpaHGCHH/file22ad95b56a718/stages/0_r_formula__8eae6edf_b16e_4036_a8d6_baf58826f8d0/metadata/part-00000:0+447
21/02/17 01:39:45 INFO Executor: Finished task 0.0 in stage 45.0 (TID 47). 1246 bytes result sent to driver
21/02/17 01:39:45 INFO TaskSetManager: Finished task 0.0 in stage 45.0 (TID 47) in 3 ms on localhost (executor driver) (1/1)
21/02/17 01:39:45 INFO TaskSchedulerImpl: Removed TaskSet 45.0, whose tasks have all completed, from pool 
21/02/17 01:39:45 INFO DAGScheduler: ResultStage 45 (first at ReadWrite.scala:615) finished in 0.007 s
21/02/17 01:39:45 INFO DAGScheduler: Job 32 finished: first at ReadWrite.scala:615, took 0.008465 s
21/02/17 01:39:45 INFO MemoryStore: Block broadcast_51 stored as values in memory (estimated size 239.6 KB, free 910.7 MB)
21/02/17 01:39:45 INFO MemoryStore: Block broadcast_51_piece0 stored as bytes in memory (estimated size 23.2 KB, free 910.6 MB)
21/02/17 01:39:45 INFO BlockManagerInfo: Added broadcast_51_piece0 in memory on localhost:37301 (size: 23.2 KB, free: 912.1 MB)
21/02/17 01:39:45 INFO SparkContext: Created broadcast 51 from textFile at ReadWrite.scala:615
21/02/17 01:39:45 INFO FileInputFormat: Total input paths to process : 1
21/02/17 01:39:45 INFO SparkContext: Starting job: first at ReadWrite.scala:615
21/02/17 01:39:45 INFO DAGScheduler: Got job 33 (first at ReadWrite.scala:615) with 1 output partitions
21/02/17 01:39:45 INFO DAGScheduler: Final stage: ResultStage 46 (first at ReadWrite.scala:615)
21/02/17 01:39:45 INFO DAGScheduler: Parents of final stage: List()
21/02/17 01:39:45 INFO DAGScheduler: Missing parents: List()
21/02/17 01:39:45 INFO DAGScheduler: Submitting ResultStage 46 (/tmp/RtmpaHGCHH/file22ad95b56a718/stages/0_r_formula__8eae6edf_b16e_4036_a8d6_baf58826f8d0/metadata MapPartitionsRDD[159] at textFile at ReadWrite.scala:615), which has no missing parents
21/02/17 01:39:45 INFO MemoryStore: Block broadcast_52 stored as values in memory (estimated size 3.5 KB, free 910.6 MB)
21/02/17 01:39:45 INFO MemoryStore: Block broadcast_52_piece0 stored as bytes in memory (estimated size 2.1 KB, free 910.6 MB)
21/02/17 01:39:45 INFO BlockManagerInfo: Added broadcast_52_piece0 in memory on localhost:37301 (size: 2.1 KB, free: 912.1 MB)
21/02/17 01:39:45 INFO SparkContext: Created broadcast 52 from broadcast at DAGScheduler.scala:1161
21/02/17 01:39:45 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 46 (/tmp/RtmpaHGCHH/file22ad95b56a718/stages/0_r_formula__8eae6edf_b16e_4036_a8d6_baf58826f8d0/metadata MapPartitionsRDD[159] at textFile at ReadWrite.scala:615) (first 15 tasks are for partitions Vector(0))
21/02/17 01:39:45 INFO TaskSchedulerImpl: Adding task set 46.0 with 1 tasks
21/02/17 01:39:45 INFO TaskSetManager: Starting task 0.0 in stage 46.0 (TID 48, localhost, executor driver, partition 0, PROCESS_LOCAL, 7975 bytes)
21/02/17 01:39:45 INFO Executor: Running task 0.0 in stage 46.0 (TID 48)
21/02/17 01:39:45 INFO HadoopRDD: Input split: file:/tmp/RtmpaHGCHH/file22ad95b56a718/stages/0_r_formula__8eae6edf_b16e_4036_a8d6_baf58826f8d0/metadata/part-00000:0+447
21/02/17 01:39:45 INFO Executor: Finished task 0.0 in stage 46.0 (TID 48). 1246 bytes result sent to driver
21/02/17 01:39:45 INFO TaskSetManager: Finished task 0.0 in stage 46.0 (TID 48) in 3 ms on localhost (executor driver) (1/1)
21/02/17 01:39:45 INFO TaskSchedulerImpl: Removed TaskSet 46.0, whose tasks have all completed, from pool 
21/02/17 01:39:45 INFO DAGScheduler: ResultStage 46 (first at ReadWrite.scala:615) finished in 0.007 s
21/02/17 01:39:45 INFO DAGScheduler: Job 33 finished: first at ReadWrite.scala:615, took 0.007859 s
21/02/17 01:39:45 INFO SparkContext: Starting job: parquet at RFormula.scala:438
21/02/17 01:39:45 INFO DAGScheduler: Got job 34 (parquet at RFormula.scala:438) with 1 output partitions
21/02/17 01:39:45 INFO DAGScheduler: Final stage: ResultStage 47 (parquet at RFormula.scala:438)
21/02/17 01:39:45 INFO DAGScheduler: Parents of final stage: List()
21/02/17 01:39:45 INFO DAGScheduler: Missing parents: List()
21/02/17 01:39:45 INFO DAGScheduler: Submitting ResultStage 47 (MapPartitionsRDD[161] at parquet at RFormula.scala:438), which has no missing parents
21/02/17 01:39:45 INFO MemoryStore: Block broadcast_53 stored as values in memory (estimated size 74.1 KB, free 910.6 MB)
21/02/17 01:39:45 INFO MemoryStore: Block broadcast_53_piece0 stored as bytes in memory (estimated size 26.1 KB, free 910.5 MB)
21/02/17 01:39:45 INFO BlockManagerInfo: Added broadcast_53_piece0 in memory on localhost:37301 (size: 26.1 KB, free: 912.1 MB)
21/02/17 01:39:45 INFO SparkContext: Created broadcast 53 from broadcast at DAGScheduler.scala:1161
21/02/17 01:39:45 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 47 (MapPartitionsRDD[161] at parquet at RFormula.scala:438) (first 15 tasks are for partitions Vector(0))
21/02/17 01:39:45 INFO TaskSchedulerImpl: Adding task set 47.0 with 1 tasks
21/02/17 01:39:45 INFO TaskSetManager: Starting task 0.0 in stage 47.0 (TID 49, localhost, executor driver, partition 0, PROCESS_LOCAL, 8135 bytes)
21/02/17 01:39:45 INFO Executor: Running task 0.0 in stage 47.0 (TID 49)
21/02/17 01:39:45 INFO Executor: Finished task 0.0 in stage 47.0 (TID 49). 1686 bytes result sent to driver
21/02/17 01:39:45 INFO TaskSetManager: Finished task 0.0 in stage 47.0 (TID 49) in 32 ms on localhost (executor driver) (1/1)
21/02/17 01:39:45 INFO TaskSchedulerImpl: Removed TaskSet 47.0, whose tasks have all completed, from pool 
21/02/17 01:39:45 INFO DAGScheduler: ResultStage 47 (parquet at RFormula.scala:438) finished in 0.041 s
21/02/17 01:39:45 INFO DAGScheduler: Job 34 finished: parquet at RFormula.scala:438, took 0.042953 s
21/02/17 01:39:45 INFO FileSourceStrategy: Pruning directories with: 
21/02/17 01:39:45 INFO FileSourceStrategy: Post-Scan Filters: 
21/02/17 01:39:45 INFO FileSourceStrategy: Output Data Schema: struct<label: string, terms: array<array<string>>, hasIntercept: boolean ... 1 more fields>
21/02/17 01:39:45 INFO FileSourceScanExec: Pushed Filters: 
21/02/17 01:39:45 INFO CodeGenerator: Code generated in 11.478409 ms
21/02/17 01:39:45 INFO CodeGenerator: Code generated in 7.850622 ms
21/02/17 01:39:45 INFO MemoryStore: Block broadcast_54 stored as values in memory (estimated size 293.1 KB, free 910.2 MB)
21/02/17 01:39:45 INFO MemoryStore: Block broadcast_54_piece0 stored as bytes in memory (estimated size 25.2 KB, free 910.2 MB)
21/02/17 01:39:45 INFO BlockManagerInfo: Added broadcast_54_piece0 in memory on localhost:37301 (size: 25.2 KB, free: 912.0 MB)
21/02/17 01:39:45 INFO SparkContext: Created broadcast 54 from head at RFormula.scala:438
21/02/17 01:39:45 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
21/02/17 01:39:45 INFO SparkContext: Starting job: head at RFormula.scala:438
21/02/17 01:39:45 INFO DAGScheduler: Got job 35 (head at RFormula.scala:438) with 1 output partitions
21/02/17 01:39:45 INFO DAGScheduler: Final stage: ResultStage 48 (head at RFormula.scala:438)
21/02/17 01:39:45 INFO DAGScheduler: Parents of final stage: List()
21/02/17 01:39:45 INFO DAGScheduler: Missing parents: List()
21/02/17 01:39:45 INFO DAGScheduler: Submitting ResultStage 48 (MapPartitionsRDD[165] at head at RFormula.scala:438), which has no missing parents
21/02/17 01:39:45 INFO MemoryStore: Block broadcast_55 stored as values in memory (estimated size 10.4 KB, free 910.2 MB)
21/02/17 01:39:45 INFO MemoryStore: Block broadcast_55_piece0 stored as bytes in memory (estimated size 4.9 KB, free 910.2 MB)
21/02/17 01:39:45 INFO BlockManagerInfo: Added broadcast_55_piece0 in memory on localhost:37301 (size: 4.9 KB, free: 912.0 MB)
21/02/17 01:39:45 INFO SparkContext: Created broadcast 55 from broadcast at DAGScheduler.scala:1161
21/02/17 01:39:45 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 48 (MapPartitionsRDD[165] at head at RFormula.scala:438) (first 15 tasks are for partitions Vector(0))
21/02/17 01:39:45 INFO TaskSchedulerImpl: Adding task set 48.0 with 1 tasks
21/02/17 01:39:45 INFO TaskSetManager: Starting task 0.0 in stage 48.0 (TID 50, localhost, executor driver, partition 0, PROCESS_LOCAL, 8386 bytes)
21/02/17 01:39:45 INFO Executor: Running task 0.0 in stage 48.0 (TID 50)
21/02/17 01:39:45 INFO FileScanRDD: Reading File path: file:///tmp/RtmpaHGCHH/file22ad95b56a718/stages/0_r_formula__8eae6edf_b16e_4036_a8d6_baf58826f8d0/data/part-00000-4eaa4ec7-ff1b-4c95-8a9d-1759aceb166c-c000.snappy.parquet, range: 0-1106, partition values: [empty row]
21/02/17 01:39:45 INFO ParquetReadSupport: Going to read the following fields from the Parquet file:

Parquet form:
message spark_schema {
  optional binary label (UTF8);
  optional group terms (LIST) {
    repeated group list {
      optional group element (LIST) {
        repeated group list {
          optional binary element (UTF8);
        }
      }
    }
  }
  required boolean hasIntercept;
}

Catalyst form:
StructType(StructField(label,StringType,true), StructField(terms,ArrayType(ArrayType(StringType,true),true),true), StructField(hasIntercept,BooleanType,true))
       
21/02/17 01:39:45 INFO BlockManagerInfo: Removed broadcast_44_piece0 on localhost:37301 in memory (size: 8.2 KB, free: 912.0 MB)
21/02/17 01:39:45 INFO ContextCleaner: Cleaned accumulator 1401
21/02/17 01:39:45 INFO ContextCleaner: Cleaned accumulator 1031
21/02/17 01:39:45 INFO ContextCleaner: Cleaned accumulator 1288
21/02/17 01:39:45 INFO ContextCleaner: Cleaned accumulator 949
21/02/17 01:39:45 INFO ContextCleaner: Cleaned accumulator 1050
21/02/17 01:39:45 INFO ContextCleaner: Cleaned accumulator 1184
21/02/17 01:39:45 INFO ContextCleaner: Cleaned accumulator 1398
21/02/17 01:39:45 INFO ContextCleaner: Cleaned accumulator 1412
21/02/17 01:39:45 INFO BlockManagerInfo: Removed broadcast_36_piece0 on localhost:37301 in memory (size: 3.8 KB, free: 912.0 MB)
21/02/17 01:39:45 INFO ContextCleaner: Cleaned accumulator 1368
21/02/17 01:39:45 INFO ContextCleaner: Cleaned accumulator 834
21/02/17 01:39:45 INFO ContextCleaner: Cleaned accumulator 1365
21/02/17 01:39:45 INFO ContextCleaner: Cleaned accumulator 1383
21/02/17 01:39:45 INFO ContextCleaner: Cleaned accumulator 1046
21/02/17 01:39:45 INFO ContextCleaner: Cleaned accumulator 972
21/02/17 01:39:45 INFO ContextCleaner: Cleaned accumulator 1137
21/02/17 01:39:45 INFO ContextCleaner: Cleaned accumulator 1150
21/02/17 01:39:45 INFO ContextCleaner: Cleaned accumulator 918
21/02/17 01:39:45 INFO ContextCleaner: Cleaned accumulator 1363
21/02/17 01:39:45 INFO ContextCleaner: Cleaned accumulator 883
21/02/17 01:39:45 INFO ContextCleaner: Cleaned accumulator 1367
21/02/17 01:39:45 INFO ContextCleaner: Cleaned accumulator 930
21/02/17 01:39:45 INFO ContextCleaner: Cleaned accumulator 1259
21/02/17 01:39:45 INFO ContextCleaner: Cleaned accumulator 998
21/02/17 01:39:45 INFO ContextCleaner: Cleaned accumulator 925
21/02/17 01:39:45 INFO ContextCleaner: Cleaned accumulator 1303
21/02/17 01:39:45 INFO BlockManagerInfo: Removed broadcast_49_piece0 on localhost:37301 in memory (size: 23.2 KB, free: 912.1 MB)
21/02/17 01:39:45 INFO ContextCleaner: Cleaned accumulator 853
21/02/17 01:39:45 INFO ContextCleaner: Cleaned shuffle 7
21/02/17 01:39:45 INFO ContextCleaner: Cleaned accumulator 1246
21/02/17 01:39:45 INFO ContextCleaner: Cleaned accumulator 1265
21/02/17 01:39:45 INFO ContextCleaner: Cleaned accumulator 1299
21/02/17 01:39:45 INFO ContextCleaner: Cleaned accumulator 897
21/02/17 01:39:45 INFO ContextCleaner: Cleaned accumulator 1316
21/02/17 01:39:45 INFO ContextCleaner: Cleaned accumulator 1381
21/02/17 01:39:45 INFO ContextCleaner: Cleaned accumulator 1054
21/02/17 01:39:45 INFO BlockManagerInfo: Removed broadcast_31_piece0 on localhost:37301 in memory (size: 5.2 KB, free: 912.1 MB)
21/02/17 01:39:45 INFO ContextCleaner: Cleaned accumulator 1053
21/02/17 01:39:45 INFO ContextCleaner: Cleaned accumulator 1186
21/02/17 01:39:45 INFO ContextCleaner: Cleaned accumulator 1196
21/02/17 01:39:45 INFO ContextCleaner: Cleaned accumulator 1133
21/02/17 01:39:45 INFO ContextCleaner: Cleaned accumulator 1307
21/02/17 01:39:45 INFO ContextCleaner: Cleaned accumulator 855
21/02/17 01:39:45 INFO ContextCleaner: Cleaned accumulator 1230
21/02/17 01:39:45 INFO ContextCleaner: Cleaned accumulator 886
21/02/17 01:39:45 INFO ContextCleaner: Cleaned accumulator 966
21/02/17 01:39:45 INFO ContextCleaner: Cleaned accumulator 1009
21/02/17 01:39:45 INFO ContextCleaner: Cleaned accumulator 1355
21/02/17 01:39:45 INFO ContextCleaner: Cleaned accumulator 1393
21/02/17 01:39:45 INFO ContextCleaner: Cleaned accumulator 1006
21/02/17 01:39:45 INFO ContextCleaner: Cleaned accumulator 1359
21/02/17 01:39:45 INFO ContextCleaner: Cleaned accumulator 911
21/02/17 01:39:45 INFO ContextCleaner: Cleaned accumulator 1123
21/02/17 01:39:45 INFO ContextCleaner: Cleaned accumulator 1001
21/02/17 01:39:45 INFO ContextCleaner: Cleaned accumulator 943
21/02/17 01:39:45 INFO ContextCleaner: Cleaned accumulator 1351
21/02/17 01:39:45 INFO ContextCleaner: Cleaned accumulator 1219
21/02/17 01:39:45 INFO ContextCleaner: Cleaned accumulator 1281
21/02/17 01:39:45 INFO ContextCleaner: Cleaned accumulator 835
21/02/17 01:39:45 INFO ContextCleaner: Cleaned accumulator 1060
21/02/17 01:39:45 INFO ContextCleaner: Cleaned accumulator 1066
21/02/17 01:39:45 INFO ContextCleaner: Cleaned accumulator 1397
21/02/17 01:39:45 INFO ContextCleaner: Cleaned accumulator 844
21/02/17 01:39:45 INFO ContextCleaner: Cleaned accumulator 1010
21/02/17 01:39:45 INFO ContextCleaner: Cleaned accumulator 826
21/02/17 01:39:45 INFO ContextCleaner: Cleaned accumulator 1121
21/02/17 01:39:45 INFO ContextCleaner: Cleaned accumulator 1158
21/02/17 01:39:45 INFO ContextCleaner: Cleaned accumulator 1361
21/02/17 01:39:45 INFO ContextCleaner: Cleaned accumulator 1069
21/02/17 01:39:45 INFO BlockManagerInfo: Removed broadcast_43_piece0 on localhost:37301 in memory (size: 3.8 KB, free: 912.1 MB)
21/02/17 01:39:45 INFO ContextCleaner: Cleaned accumulator 1337
21/02/17 01:39:45 INFO ContextCleaner: Cleaned accumulator 843
21/02/17 01:39:45 INFO ContextCleaner: Cleaned accumulator 1067
21/02/17 01:39:45 INFO ContextCleaner: Cleaned accumulator 1070
21/02/17 01:39:45 INFO BlockManagerInfo: Removed broadcast_51_piece0 on localhost:37301 in memory (size: 23.2 KB, free: 912.1 MB)
21/02/17 01:39:45 INFO ContextCleaner: Cleaned accumulator 874
21/02/17 01:39:45 INFO ContextCleaner: Cleaned accumulator 968
21/02/17 01:39:45 INFO ContextCleaner: Cleaned accumulator 1180
21/02/17 01:39:45 INFO ContextCleaner: Cleaned accumulator 1277
21/02/17 01:39:45 INFO ContextCleaner: Cleaned accumulator 983
21/02/17 01:39:45 INFO ContextCleaner: Cleaned accumulator 1311
21/02/17 01:39:45 INFO ContextCleaner: Cleaned accumulator 1212
21/02/17 01:39:45 INFO ContextCleaner: Cleaned shuffle 10
21/02/17 01:39:45 INFO ContextCleaner: Cleaned accumulator 976
21/02/17 01:39:45 INFO BlockManagerInfo: Removed broadcast_46_piece0 on localhost:37301 in memory (size: 3.8 KB, free: 912.1 MB)
21/02/17 01:39:45 INFO ContextCleaner: Cleaned accumulator 1411
21/02/17 01:39:45 INFO ContextCleaner: Cleaned accumulator 1037
21/02/17 01:39:45 INFO ContextCleaner: Cleaned accumulator 987
21/02/17 01:39:45 INFO ContextCleaner: Cleaned accumulator 1236
21/02/17 01:39:45 INFO ContextCleaner: Cleaned accumulator 1264
21/02/17 01:39:45 INFO ContextCleaner: Cleaned accumulator 858
21/02/17 01:39:45 INFO ContextCleaner: Cleaned accumulator 1322
21/02/17 01:39:45 INFO ContextCleaner: Cleaned accumulator 917
21/02/17 01:39:45 INFO ContextCleaner: Cleaned accumulator 1149
21/02/17 01:39:45 INFO ContextCleaner: Cleaned accumulator 1154
21/02/17 01:39:45 INFO ContextCleaner: Cleaned accumulator 904
21/02/17 01:39:45 INFO ContextCleaner: Cleaned accumulator 986
21/02/17 01:39:45 INFO ContextCleaner: Cleaned accumulator 1342
21/02/17 01:39:45 INFO ContextCleaner: Cleaned accumulator 1216
21/02/17 01:39:45 INFO ContextCleaner: Cleaned accumulator 932
21/02/17 01:39:45 INFO ContextCleaner: Cleaned accumulator 1007
21/02/17 01:39:45 INFO ContextCleaner: Cleaned accumulator 1283
21/02/17 01:39:45 INFO ContextCleaner: Cleaned accumulator 902
21/02/17 01:39:45 INFO ContextCleaner: Cleaned accumulator 1214
21/02/17 01:39:45 INFO ContextCleaner: Cleaned accumulator 1319
21/02/17 01:39:45 INFO ContextCleaner: Cleaned accumulator 924
21/02/17 01:39:45 INFO ContextCleaner: Cleaned accumulator 839
21/02/17 01:39:45 INFO ContextCleaner: Cleaned accumulator 1374
21/02/17 01:39:45 INFO ContextCleaner: Cleaned accumulator 1034
21/02/17 01:39:45 INFO ContextCleaner: Cleaned accumulator 907
21/02/17 01:39:45 INFO ContextCleaner: Cleaned accumulator 1022
21/02/17 01:39:45 INFO ContextCleaner: Cleaned accumulator 1399
21/02/17 01:39:45 INFO ContextCleaner: Cleaned accumulator 1257
21/02/17 01:39:45 INFO ContextCleaner: Cleaned accumulator 849
21/02/17 01:39:45 INFO ContextCleaner: Cleaned accumulator 895
21/02/17 01:39:45 INFO ContextCleaner: Cleaned accumulator 1336
21/02/17 01:39:45 INFO ContextCleaner: Cleaned accumulator 1234
21/02/17 01:39:45 INFO ContextCleaner: Cleaned accumulator 1159
21/02/17 01:39:45 INFO ContextCleaner: Cleaned accumulator 973
21/02/17 01:39:45 INFO ContextCleaner: Cleaned accumulator 974
21/02/17 01:39:45 INFO ContextCleaner: Cleaned accumulator 1386
21/02/17 01:39:45 INFO ContextCleaner: Cleaned accumulator 1052
21/02/17 01:39:45 INFO ContextCleaner: Cleaned accumulator 1084
21/02/17 01:39:45 INFO ContextCleaner: Cleaned accumulator 1286
21/02/17 01:39:45 INFO ContextCleaner: Cleaned accumulator 1168
21/02/17 01:39:45 INFO ContextCleaner: Cleaned accumulator 1204
21/02/17 01:39:45 INFO ContextCleaner: Cleaned accumulator 1263
21/02/17 01:39:45 INFO ContextCleaner: Cleaned accumulator 1417
21/02/17 01:39:45 INFO ContextCleaner: Cleaned accumulator 1171
21/02/17 01:39:45 INFO ContextCleaner: Cleaned accumulator 867
21/02/17 01:39:45 INFO ContextCleaner: Cleaned accumulator 1012
21/02/17 01:39:45 INFO ContextCleaner: Cleaned accumulator 1343
21/02/17 01:39:45 INFO ContextCleaner: Cleaned accumulator 1190
21/02/17 01:39:45 INFO ContextCleaner: Cleaned accumulator 1416
21/02/17 01:39:45 INFO ContextCleaner: Cleaned accumulator 981
21/02/17 01:39:45 INFO ContextCleaner: Cleaned accumulator 1278
21/02/17 01:39:45 INFO CodeGenerator: Code generated in 11.362007 ms
21/02/17 01:39:45 INFO ContextCleaner: Cleaned accumulator 1392
21/02/17 01:39:45 INFO ContextCleaner: Cleaned accumulator 1304
21/02/17 01:39:45 INFO ContextCleaner: Cleaned accumulator 1309
21/02/17 01:39:45 INFO ContextCleaner: Cleaned accumulator 1279
21/02/17 01:39:45 INFO ContextCleaner: Cleaned accumulator 1173
21/02/17 01:39:45 INFO ContextCleaner: Cleaned accumulator 1165
21/02/17 01:39:45 INFO ContextCleaner: Cleaned accumulator 1211
21/02/17 01:39:45 INFO ContextCleaner: Cleaned accumulator 1245
21/02/17 01:39:45 INFO ContextCleaner: Cleaned accumulator 1091
21/02/17 01:39:45 INFO ContextCleaner: Cleaned accumulator 1202
21/02/17 01:39:45 INFO ContextCleaner: Cleaned accumulator 1370
21/02/17 01:39:45 INFO ContextCleaner: Cleaned accumulator 863
21/02/17 01:39:45 INFO ContextCleaner: Cleaned accumulator 840
21/02/17 01:39:45 INFO ContextCleaner: Cleaned accumulator 1108
21/02/17 01:39:45 INFO ContextCleaner: Cleaned accumulator 1324
21/02/17 01:39:45 INFO ContextCleaner: Cleaned accumulator 928
21/02/17 01:39:45 INFO ContextCleaner: Cleaned accumulator 967
21/02/17 01:39:45 INFO ContextCleaner: Cleaned accumulator 1131
21/02/17 01:39:45 INFO ContextCleaner: Cleaned accumulator 1387
21/02/17 01:39:45 INFO ContextCleaner: Cleaned accumulator 1124
21/02/17 01:39:45 INFO ContextCleaner: Cleaned accumulator 859
21/02/17 01:39:45 INFO ContextCleaner: Cleaned accumulator 1102
21/02/17 01:39:45 INFO ContextCleaner: Cleaned accumulator 938
21/02/17 01:39:45 INFO ContextCleaner: Cleaned accumulator 1360
21/02/17 01:39:45 INFO ContextCleaner: Cleaned accumulator 885
21/02/17 01:39:45 INFO ContextCleaner: Cleaned accumulator 995
21/02/17 01:39:45 INFO ContextCleaner: Cleaned accumulator 1380
21/02/17 01:39:45 INFO ContextCleaner: Cleaned accumulator 1106
21/02/17 01:39:45 INFO ContextCleaner: Cleaned accumulator 848
21/02/17 01:39:45 INFO ContextCleaner: Cleaned accumulator 1164
21/02/17 01:39:45 INFO ContextCleaner: Cleaned accumulator 1178
21/02/17 01:39:45 INFO ContextCleaner: Cleaned accumulator 926
21/02/17 01:39:45 INFO ContextCleaner: Cleaned accumulator 1135
21/02/17 01:39:45 INFO ContextCleaner: Cleaned accumulator 1242
21/02/17 01:39:45 INFO ContextCleaner: Cleaned shuffle 8
21/02/17 01:39:45 INFO ContextCleaner: Cleaned accumulator 1296
21/02/17 01:39:45 INFO ContextCleaner: Cleaned accumulator 969
21/02/17 01:39:45 INFO ContextCleaner: Cleaned accumulator 1151
21/02/17 01:39:45 INFO ContextCleaner: Cleaned accumulator 1262
21/02/17 01:39:45 INFO ContextCleaner: Cleaned accumulator 1207
21/02/17 01:39:45 INFO ContextCleaner: Cleaned accumulator 1275
21/02/17 01:39:45 INFO ContextCleaner: Cleaned accumulator 1192
21/02/17 01:39:45 INFO ContextCleaner: Cleaned accumulator 831
21/02/17 01:39:45 INFO ContextCleaner: Cleaned accumulator 914
21/02/17 01:39:45 INFO ContextCleaner: Cleaned accumulator 1059
21/02/17 01:39:45 INFO ContextCleaner: Cleaned accumulator 1122
21/02/17 01:39:45 INFO BlockManagerInfo: Removed broadcast_50_piece0 on localhost:37301 in memory (size: 2.1 KB, free: 912.1 MB)
21/02/17 01:39:45 INFO ContextCleaner: Cleaned accumulator 941
21/02/17 01:39:45 INFO ContextCleaner: Cleaned accumulator 1323
21/02/17 01:39:45 INFO ContextCleaner: Cleaned accumulator 1415
21/02/17 01:39:45 INFO ContextCleaner: Cleaned accumulator 1064
21/02/17 01:39:45 INFO ContextCleaner: Cleaned accumulator 1376
21/02/17 01:39:45 INFO ContextCleaner: Cleaned accumulator 1082
21/02/17 01:39:45 INFO ContextCleaner: Cleaned accumulator 1129
21/02/17 01:39:45 INFO ContextCleaner: Cleaned accumulator 868
21/02/17 01:39:45 INFO ContextCleaner: Cleaned accumulator 951
21/02/17 01:39:45 INFO ContextCleaner: Cleaned accumulator 1308
21/02/17 01:39:45 INFO ContextCleaner: Cleaned accumulator 1377
21/02/17 01:39:45 INFO ContextCleaner: Cleaned accumulator 979
21/02/17 01:39:45 INFO ContextCleaner: Cleaned accumulator 1112
21/02/17 01:39:45 INFO ContextCleaner: Cleaned accumulator 1371
21/02/17 01:39:45 INFO ContextCleaner: Cleaned accumulator 878
21/02/17 01:39:45 INFO ContextCleaner: Cleaned accumulator 1162
21/02/17 01:39:45 INFO ContextCleaner: Cleaned accumulator 1117
21/02/17 01:39:45 INFO ContextCleaner: Cleaned shuffle 9
21/02/17 01:39:45 INFO ContextCleaner: Cleaned accumulator 1315
21/02/17 01:39:45 INFO ContextCleaner: Cleaned accumulator 1109
21/02/17 01:39:45 INFO ContextCleaner: Cleaned accumulator 1128
21/02/17 01:39:45 INFO ContextCleaner: Cleaned accumulator 955
21/02/17 01:39:45 INFO ContextCleaner: Cleaned accumulator 1220
21/02/17 01:39:45 INFO BlockManagerInfo: Removed broadcast_32_piece0 on localhost:37301 in memory (size: 4.2 KB, free: 912.1 MB)
21/02/17 01:39:45 INFO ContextCleaner: Cleaned accumulator 1267
21/02/17 01:39:45 INFO ContextCleaner: Cleaned accumulator 898
21/02/17 01:39:45 INFO ContextCleaner: Cleaned accumulator 1065
21/02/17 01:39:45 INFO ContextCleaner: Cleaned accumulator 881
21/02/17 01:39:45 INFO ContextCleaner: Cleaned accumulator 1061
21/02/17 01:39:45 INFO ContextCleaner: Cleaned accumulator 1396
21/02/17 01:39:45 INFO ContextCleaner: Cleaned accumulator 1002
21/02/17 01:39:45 INFO ContextCleaner: Cleaned accumulator 1221
21/02/17 01:39:45 INFO ContextCleaner: Cleaned accumulator 1240
21/02/17 01:39:45 INFO ContextCleaner: Cleaned accumulator 1027
21/02/17 01:39:45 INFO ContextCleaner: Cleaned accumulator 1338
21/02/17 01:39:45 INFO ContextCleaner: Cleaned accumulator 1284
21/02/17 01:39:45 INFO ContextCleaner: Cleaned accumulator 906
21/02/17 01:39:45 INFO ContextCleaner: Cleaned accumulator 1057
21/02/17 01:39:45 INFO ContextCleaner: Cleaned accumulator 1188
21/02/17 01:39:45 INFO ContextCleaner: Cleaned accumulator 1400
21/02/17 01:39:45 INFO ContextCleaner: Cleaned accumulator 909
21/02/17 01:39:45 INFO BlockManagerInfo: Removed broadcast_42_piece0 on localhost:37301 in memory (size: 4.5 KB, free: 912.1 MB)
21/02/17 01:39:45 INFO ContextCleaner: Cleaned accumulator 944
21/02/17 01:39:45 INFO BlockManagerInfo: Removed broadcast_37_piece0 on localhost:37301 in memory (size: 9.6 KB, free: 912.1 MB)
21/02/17 01:39:45 INFO ContextCleaner: Cleaned accumulator 1103
21/02/17 01:39:45 INFO ContextCleaner: Cleaned accumulator 1035
21/02/17 01:39:45 INFO ContextCleaner: Cleaned accumulator 1295
21/02/17 01:39:45 INFO ContextCleaner: Cleaned accumulator 884
21/02/17 01:39:45 INFO ContextCleaner: Cleaned accumulator 1024
21/02/17 01:39:45 INFO ContextCleaner: Cleaned accumulator 1146
21/02/17 01:39:45 INFO ContextCleaner: Cleaned accumulator 1395
21/02/17 01:39:45 INFO ContextCleaner: Cleaned accumulator 865
21/02/17 01:39:45 INFO ContextCleaner: Cleaned accumulator 1353
21/02/17 01:39:45 INFO ContextCleaner: Cleaned accumulator 1252
21/02/17 01:39:45 INFO ContextCleaner: Cleaned accumulator 1174
21/02/17 01:39:45 INFO ContextCleaner: Cleaned accumulator 862
21/02/17 01:39:45 INFO ContextCleaner: Cleaned accumulator 1156
21/02/17 01:39:45 INFO ContextCleaner: Cleaned accumulator 1167
21/02/17 01:39:45 INFO ContextCleaner: Cleaned accumulator 1298
21/02/17 01:39:45 INFO ContextCleaner: Cleaned accumulator 1249
21/02/17 01:39:45 INFO ContextCleaner: Cleaned accumulator 1339
21/02/17 01:39:45 INFO ContextCleaner: Cleaned accumulator 1169
21/02/17 01:39:45 INFO ContextCleaner: Cleaned accumulator 1153
21/02/17 01:39:45 INFO ContextCleaner: Cleaned accumulator 1199
21/02/17 01:39:45 INFO ContextCleaner: Cleaned accumulator 1116
21/02/17 01:39:45 INFO ContextCleaner: Cleaned accumulator 958
21/02/17 01:39:45 INFO ContextCleaner: Cleaned accumulator 982
21/02/17 01:39:45 INFO ContextCleaner: Cleaned accumulator 1077
21/02/17 01:39:45 INFO ContextCleaner: Cleaned accumulator 1026
21/02/17 01:39:45 INFO ContextCleaner: Cleaned accumulator 1141
21/02/17 01:39:45 INFO ContextCleaner: Cleaned accumulator 1235
21/02/17 01:39:45 INFO ContextCleaner: Cleaned accumulator 846
21/02/17 01:39:45 INFO ContextCleaner: Cleaned accumulator 1160
21/02/17 01:39:45 INFO ContextCleaner: Cleaned accumulator 1349
21/02/17 01:39:45 INFO ContextCleaner: Cleaned accumulator 1030
21/02/17 01:39:45 INFO ContextCleaner: Cleaned accumulator 1049
21/02/17 01:39:45 INFO BlockManager: Removing RDD 108
21/02/17 01:39:45 INFO ContextCleaner: Cleaned RDD 108
21/02/17 01:39:45 INFO ContextCleaner: Cleaned accumulator 1090
21/02/17 01:39:45 INFO ContextCleaner: Cleaned accumulator 1111
21/02/17 01:39:45 INFO ContextCleaner: Cleaned accumulator 1344
21/02/17 01:39:45 INFO ContextCleaner: Cleaned accumulator 1032
21/02/17 01:39:45 INFO ContextCleaner: Cleaned accumulator 1328
21/02/17 01:39:45 INFO ContextCleaner: Cleaned accumulator 957
21/02/17 01:39:45 INFO ContextCleaner: Cleaned accumulator 1187
21/02/17 01:39:45 INFO ContextCleaner: Cleaned accumulator 1033
21/02/17 01:39:45 INFO ContextCleaner: Cleaned accumulator 977
21/02/17 01:39:45 INFO ContextCleaner: Cleaned accumulator 1272
21/02/17 01:39:45 INFO ContextCleaner: Cleaned accumulator 827
21/02/17 01:39:45 INFO ContextCleaner: Cleaned accumulator 1198
21/02/17 01:39:45 INFO ContextCleaner: Cleaned accumulator 1231
21/02/17 01:39:45 INFO ContextCleaner: Cleaned accumulator 1357
21/02/17 01:39:45 INFO ContextCleaner: Cleaned accumulator 1093
21/02/17 01:39:45 INFO ContextCleaner: Cleaned accumulator 1142
21/02/17 01:39:45 INFO ContextCleaner: Cleaned accumulator 1305
21/02/17 01:39:45 INFO ContextCleaner: Cleaned accumulator 922
21/02/17 01:39:45 INFO BlockManagerInfo: Removed broadcast_34_piece0 on localhost:37301 in memory (size: 24.5 KB, free: 912.1 MB)
21/02/17 01:39:45 INFO ContextCleaner: Cleaned accumulator 1036
21/02/17 01:39:45 INFO ContextCleaner: Cleaned accumulator 916
21/02/17 01:39:45 INFO ContextCleaner: Cleaned accumulator 1228
21/02/17 01:39:45 INFO ContextCleaner: Cleaned accumulator 864
21/02/17 01:39:45 INFO ContextCleaner: Cleaned accumulator 961
21/02/17 01:39:45 INFO ContextCleaner: Cleaned accumulator 933
21/02/17 01:39:45 INFO ContextCleaner: Cleaned accumulator 1314
21/02/17 01:39:45 INFO ContextCleaner: Cleaned accumulator 1239
21/02/17 01:39:45 INFO ContextCleaner: Cleaned accumulator 1115
21/02/17 01:39:45 INFO ContextCleaner: Cleaned accumulator 856
21/02/17 01:39:45 INFO ContextCleaner: Cleaned accumulator 842
21/02/17 01:39:45 INFO ContextCleaner: Cleaned accumulator 1226
21/02/17 01:39:45 INFO ContextCleaner: Cleaned accumulator 1325
21/02/17 01:39:45 INFO ContextCleaner: Cleaned accumulator 956
21/02/17 01:39:45 INFO ContextCleaner: Cleaned accumulator 841
21/02/17 01:39:45 INFO ContextCleaner: Cleaned accumulator 1119
21/02/17 01:39:45 INFO ContextCleaner: Cleaned accumulator 1294
21/02/17 01:39:45 INFO ContextCleaner: Cleaned accumulator 876
21/02/17 01:39:45 INFO ContextCleaner: Cleaned accumulator 1260
21/02/17 01:39:45 INFO ContextCleaner: Cleaned accumulator 1191
21/02/17 01:39:45 INFO ContextCleaner: Cleaned shuffle 11
21/02/17 01:39:45 INFO ContextCleaner: Cleaned accumulator 993
21/02/17 01:39:45 INFO ContextCleaner: Cleaned accumulator 1130
21/02/17 01:39:45 INFO ContextCleaner: Cleaned accumulator 1335
21/02/17 01:39:45 INFO ContextCleaner: Cleaned accumulator 929
21/02/17 01:39:45 INFO ContextCleaner: Cleaned accumulator 1280
21/02/17 01:39:45 INFO ContextCleaner: Cleaned accumulator 921
21/02/17 01:39:45 INFO ContextCleaner: Cleaned accumulator 937
21/02/17 01:39:45 INFO ContextCleaner: Cleaned accumulator 960
21/02/17 01:39:45 INFO ContextCleaner: Cleaned shuffle 12
21/02/17 01:39:45 INFO ContextCleaner: Cleaned accumulator 1062
21/02/17 01:39:45 INFO ContextCleaner: Cleaned accumulator 866
21/02/17 01:39:45 INFO ContextCleaner: Cleaned accumulator 1244
21/02/17 01:39:45 INFO ContextCleaner: Cleaned accumulator 1013
21/02/17 01:39:45 INFO ContextCleaner: Cleaned accumulator 1148
21/02/17 01:39:45 INFO ContextCleaner: Cleaned accumulator 1005
21/02/17 01:39:45 INFO ContextCleaner: Cleaned accumulator 1210
21/02/17 01:39:45 INFO ContextCleaner: Cleaned accumulator 1287
21/02/17 01:39:45 INFO ContextCleaner: Cleaned accumulator 1016
21/02/17 01:39:45 INFO ContextCleaner: Cleaned accumulator 1313
21/02/17 01:39:45 INFO ContextCleaner: Cleaned accumulator 920
21/02/17 01:39:45 INFO ContextCleaner: Cleaned accumulator 1273
21/02/17 01:39:45 INFO ContextCleaner: Cleaned accumulator 1063
21/02/17 01:39:45 INFO ContextCleaner: Cleaned accumulator 1179
21/02/17 01:39:45 INFO ContextCleaner: Cleaned accumulator 1389
21/02/17 01:39:45 INFO ContextCleaner: Cleaned accumulator 1110
21/02/17 01:39:45 INFO ContextCleaner: Cleaned accumulator 1107
21/02/17 01:39:45 INFO ContextCleaner: Cleaned accumulator 891
21/02/17 01:39:45 INFO ContextCleaner: Cleaned accumulator 824
21/02/17 01:39:45 INFO ContextCleaner: Cleaned accumulator 1136
21/02/17 01:39:45 INFO ContextCleaner: Cleaned accumulator 1321
21/02/17 01:39:45 INFO ContextCleaner: Cleaned accumulator 1217
21/02/17 01:39:45 INFO ContextCleaner: Cleaned accumulator 990
21/02/17 01:39:45 INFO ContextCleaner: Cleaned accumulator 1072
21/02/17 01:39:45 INFO ContextCleaner: Cleaned accumulator 832
21/02/17 01:39:45 INFO ContextCleaner: Cleaned accumulator 1348
21/02/17 01:39:45 INFO ContextCleaner: Cleaned accumulator 1008
21/02/17 01:39:45 INFO ContextCleaner: Cleaned accumulator 871
21/02/17 01:39:45 INFO ContextCleaner: Cleaned accumulator 837
21/02/17 01:39:45 INFO ContextCleaner: Cleaned accumulator 1087
21/02/17 01:39:45 INFO ContextCleaner: Cleaned accumulator 882
21/02/17 01:39:45 INFO BlockManagerInfo: Removed broadcast_33_piece0 on localhost:37301 in memory (size: 3.8 KB, free: 912.1 MB)
21/02/17 01:39:45 INFO ContextCleaner: Cleaned accumulator 893
21/02/17 01:39:45 INFO ContextCleaner: Cleaned accumulator 1302
21/02/17 01:39:45 INFO ContextCleaner: Cleaned accumulator 970
21/02/17 01:39:45 INFO ContextCleaner: Cleaned accumulator 1075
21/02/17 01:39:45 INFO ContextCleaner: Cleaned accumulator 1418
21/02/17 01:39:45 INFO ContextCleaner: Cleaned accumulator 1254
21/02/17 01:39:45 INFO ContextCleaner: Cleaned accumulator 857
21/02/17 01:39:45 INFO ContextCleaner: Cleaned accumulator 896
21/02/17 01:39:45 INFO ContextCleaner: Cleaned accumulator 870
21/02/17 01:39:45 INFO ContextCleaner: Cleaned accumulator 1058
21/02/17 01:39:45 INFO ContextCleaner: Cleaned accumulator 984
21/02/17 01:39:45 INFO ContextCleaner: Cleaned accumulator 854
21/02/17 01:39:45 INFO ContextCleaner: Cleaned accumulator 1181
21/02/17 01:39:45 INFO ContextCleaner: Cleaned accumulator 1317
21/02/17 01:39:45 INFO ContextCleaner: Cleaned accumulator 825
21/02/17 01:39:45 INFO ContextCleaner: Cleaned accumulator 919
21/02/17 01:39:45 INFO ContextCleaner: Cleaned accumulator 1079
21/02/17 01:39:45 INFO ContextCleaner: Cleaned accumulator 1080
21/02/17 01:39:45 INFO ContextCleaner: Cleaned accumulator 1126
21/02/17 01:39:45 INFO ContextCleaner: Cleaned accumulator 1019
21/02/17 01:39:45 INFO ContextCleaner: Cleaned accumulator 1023
21/02/17 01:39:45 INFO ContextCleaner: Cleaned accumulator 873
21/02/17 01:39:45 INFO ContextCleaner: Cleaned accumulator 1000
21/02/17 01:39:45 INFO ContextCleaner: Cleaned accumulator 1345
21/02/17 01:39:45 INFO ContextCleaner: Cleaned accumulator 1297
21/02/17 01:39:45 INFO ContextCleaner: Cleaned accumulator 889
21/02/17 01:39:45 INFO ContextCleaner: Cleaned accumulator 887
21/02/17 01:39:45 INFO ContextCleaner: Cleaned accumulator 931
21/02/17 01:39:45 INFO ContextCleaner: Cleaned accumulator 1011
21/02/17 01:39:45 INFO ContextCleaner: Cleaned accumulator 1366
21/02/17 01:39:45 INFO ContextCleaner: Cleaned accumulator 1290
21/02/17 01:39:45 INFO ContextCleaner: Cleaned accumulator 1051
21/02/17 01:39:45 INFO ContextCleaner: Cleaned accumulator 1095
21/02/17 01:39:45 INFO ContextCleaner: Cleaned accumulator 1391
21/02/17 01:39:45 INFO ContextCleaner: Cleaned accumulator 923
21/02/17 01:39:45 INFO ContextCleaner: Cleaned accumulator 861
21/02/17 01:39:45 INFO ContextCleaner: Cleaned accumulator 1352
21/02/17 01:39:45 INFO ContextCleaner: Cleaned accumulator 1218
21/02/17 01:39:45 INFO ContextCleaner: Cleaned accumulator 1056
21/02/17 01:39:45 INFO ContextCleaner: Cleaned accumulator 1143
21/02/17 01:39:45 INFO ContextCleaner: Cleaned accumulator 1261
21/02/17 01:39:45 INFO ContextCleaner: Cleaned accumulator 1402
21/02/17 01:39:45 INFO ContextCleaner: Cleaned accumulator 1356
21/02/17 01:39:45 INFO ContextCleaner: Cleaned accumulator 880
21/02/17 01:39:45 INFO ContextCleaner: Cleaned accumulator 1243
21/02/17 01:39:45 INFO ContextCleaner: Cleaned accumulator 1213
21/02/17 01:39:45 INFO ContextCleaner: Cleaned accumulator 869
21/02/17 01:39:45 INFO ContextCleaner: Cleaned accumulator 1197
21/02/17 01:39:45 INFO ContextCleaner: Cleaned accumulator 1208
21/02/17 01:39:45 INFO ContextCleaner: Cleaned accumulator 1101
21/02/17 01:39:45 INFO ContextCleaner: Cleaned accumulator 1394
21/02/17 01:39:45 INFO ContextCleaner: Cleaned accumulator 1182
21/02/17 01:39:45 INFO ContextCleaner: Cleaned accumulator 1099
21/02/17 01:39:45 INFO ContextCleaner: Cleaned accumulator 1293
21/02/17 01:39:45 INFO ContextCleaner: Cleaned accumulator 1166
21/02/17 01:39:45 INFO ContextCleaner: Cleaned accumulator 1157
21/02/17 01:39:45 INFO ContextCleaner: Cleaned accumulator 1039
21/02/17 01:39:45 INFO ContextCleaner: Cleaned accumulator 1274
21/02/17 01:39:45 INFO ContextCleaner: Cleaned accumulator 852
21/02/17 01:39:45 INFO ContextCleaner: Cleaned accumulator 1100
21/02/17 01:39:45 INFO ContextCleaner: Cleaned accumulator 965
21/02/17 01:39:45 INFO ContextCleaner: Cleaned accumulator 980
21/02/17 01:39:45 INFO ContextCleaner: Cleaned accumulator 1233
21/02/17 01:39:45 INFO ContextCleaner: Cleaned accumulator 1237
21/02/17 01:39:45 INFO ContextCleaner: Cleaned accumulator 836
21/02/17 01:39:45 INFO BlockManagerInfo: Removed broadcast_30_piece0 on localhost:37301 in memory (size: 24.5 KB, free: 912.2 MB)
21/02/17 01:39:45 INFO ContextCleaner: Cleaned accumulator 877
21/02/17 01:39:45 INFO ContextCleaner: Cleaned accumulator 1224
21/02/17 01:39:45 INFO ContextCleaner: Cleaned accumulator 1247
21/02/17 01:39:45 INFO ContextCleaner: Cleaned accumulator 959
21/02/17 01:39:45 INFO ContextCleaner: Cleaned accumulator 1045
21/02/17 01:39:45 INFO ContextCleaner: Cleaned accumulator 1055
21/02/17 01:39:45 INFO ContextCleaner: Cleaned accumulator 1092
21/02/17 01:39:45 INFO ContextCleaner: Cleaned accumulator 1215
21/02/17 01:39:45 INFO BlockManagerInfo: Removed broadcast_45_piece0 on localhost:37301 in memory (size: 9.6 KB, free: 912.2 MB)
21/02/17 01:39:45 INFO ContextCleaner: Cleaned accumulator 1203
21/02/17 01:39:45 INFO ContextCleaner: Cleaned accumulator 1331
21/02/17 01:39:45 INFO ContextCleaner: Cleaned accumulator 903
21/02/17 01:39:45 INFO ContextCleaner: Cleaned accumulator 1003
21/02/17 01:39:45 INFO BlockManagerInfo: Removed broadcast_47_piece0 on localhost:37301 in memory (size: 23.2 KB, free: 912.2 MB)
21/02/17 01:39:45 INFO ContextCleaner: Cleaned accumulator 1347
21/02/17 01:39:45 INFO BlockManagerInfo: Removed broadcast_35_piece0 on localhost:37301 in memory (size: 9.6 KB, free: 912.2 MB)
21/02/17 01:39:45 INFO ContextCleaner: Cleaned accumulator 1408
21/02/17 01:39:45 INFO ContextCleaner: Cleaned accumulator 962
21/02/17 01:39:45 INFO ContextCleaner: Cleaned accumulator 1138
21/02/17 01:39:45 INFO ContextCleaner: Cleaned accumulator 910
21/02/17 01:39:45 INFO ContextCleaner: Cleaned accumulator 899
21/02/17 01:39:45 INFO ContextCleaner: Cleaned accumulator 1014
21/02/17 01:39:45 INFO ContextCleaner: Cleaned accumulator 1268
21/02/17 01:39:45 INFO ContextCleaner: Cleaned accumulator 963
21/02/17 01:39:45 INFO ContextCleaner: Cleaned accumulator 838
21/02/17 01:39:45 INFO ContextCleaner: Cleaned accumulator 1081
21/02/17 01:39:45 INFO BlockManagerInfo: Removed broadcast_39_piece0 on localhost:37301 in memory (size: 9.4 KB, free: 912.2 MB)
21/02/17 01:39:45 INFO ContextCleaner: Cleaned accumulator 1140
21/02/17 01:39:45 INFO ContextCleaner: Cleaned accumulator 1227
21/02/17 01:39:45 INFO ContextCleaner: Cleaned accumulator 847
21/02/17 01:39:45 INFO ContextCleaner: Cleaned accumulator 1028
21/02/17 01:39:45 INFO ContextCleaner: Cleaned accumulator 1333
21/02/17 01:39:45 INFO ContextCleaner: Cleaned accumulator 1073
21/02/17 01:39:45 INFO BlockManagerInfo: Removed broadcast_41_piece0 on localhost:37301 in memory (size: 3.3 KB, free: 912.2 MB)
21/02/17 01:39:45 INFO ContextCleaner: Cleaned accumulator 1372
21/02/17 01:39:45 INFO ContextCleaner: Cleaned accumulator 860
21/02/17 01:39:45 INFO ContextCleaner: Cleaned accumulator 1015
21/02/17 01:39:45 INFO ContextCleaner: Cleaned accumulator 1038
21/02/17 01:39:45 INFO ContextCleaner: Cleaned accumulator 1312
21/02/17 01:39:45 INFO ContextCleaner: Cleaned accumulator 908
21/02/17 01:39:45 INFO ContextCleaner: Cleaned accumulator 1362
21/02/17 01:39:45 INFO ContextCleaner: Cleaned accumulator 1041
21/02/17 01:39:45 INFO ContextCleaner: Cleaned accumulator 934
21/02/17 01:39:45 INFO ContextCleaner: Cleaned accumulator 1301
21/02/17 01:39:45 INFO ContextCleaner: Cleaned accumulator 1020
21/02/17 01:39:45 INFO ContextCleaner: Cleaned accumulator 947
21/02/17 01:39:45 INFO ContextCleaner: Cleaned accumulator 1250
21/02/17 01:39:45 INFO ContextCleaner: Cleaned accumulator 1369
21/02/17 01:39:45 INFO ContextCleaner: Cleaned accumulator 1334
21/02/17 01:39:45 INFO ContextCleaner: Cleaned accumulator 1238
21/02/17 01:39:45 INFO ContextCleaner: Cleaned accumulator 1375
21/02/17 01:39:45 INFO ContextCleaner: Cleaned accumulator 828
21/02/17 01:39:45 INFO ContextCleaner: Cleaned accumulator 1282
21/02/17 01:39:45 INFO ContextCleaner: Cleaned accumulator 1177
21/02/17 01:39:45 INFO ContextCleaner: Cleaned accumulator 1407
21/02/17 01:39:45 INFO ContextCleaner: Cleaned accumulator 1291
21/02/17 01:39:45 INFO ContextCleaner: Cleaned accumulator 935
21/02/17 01:39:45 INFO ContextCleaner: Cleaned accumulator 1229
21/02/17 01:39:45 INFO ContextCleaner: Cleaned accumulator 1118
21/02/17 01:39:45 INFO ContextCleaner: Cleaned accumulator 1068
21/02/17 01:39:45 INFO ContextCleaner: Cleaned accumulator 1241
21/02/17 01:39:45 INFO ContextCleaner: Cleaned accumulator 942
21/02/17 01:39:45 INFO ContextCleaner: Cleaned accumulator 992
21/02/17 01:39:45 INFO ContextCleaner: Cleaned accumulator 1097
21/02/17 01:39:45 INFO ContextCleaner: Cleaned accumulator 894
21/02/17 01:39:45 INFO ContextCleaner: Cleaned accumulator 1132
21/02/17 01:39:45 INFO ContextCleaner: Cleaned accumulator 1330
21/02/17 01:39:45 INFO ContextCleaner: Cleaned accumulator 1085
21/02/17 01:39:45 INFO ContextCleaner: Cleaned accumulator 1040
21/02/17 01:39:45 INFO ContextCleaner: Cleaned accumulator 940
21/02/17 01:39:45 INFO ContextCleaner: Cleaned accumulator 1021
21/02/17 01:39:45 INFO ContextCleaner: Cleaned accumulator 1222
21/02/17 01:39:45 INFO ContextCleaner: Cleaned accumulator 1350
21/02/17 01:39:45 INFO ContextCleaner: Cleaned accumulator 1413
21/02/17 01:39:45 INFO ContextCleaner: Cleaned accumulator 850
21/02/17 01:39:45 INFO ContextCleaner: Cleaned accumulator 994
21/02/17 01:39:45 INFO ContextCleaner: Cleaned accumulator 875
21/02/17 01:39:45 INFO ContextCleaner: Cleaned accumulator 997
21/02/17 01:39:45 INFO ContextCleaner: Cleaned accumulator 996
21/02/17 01:39:45 INFO ContextCleaner: Cleaned accumulator 1113
21/02/17 01:39:45 INFO ContextCleaner: Cleaned accumulator 1256
21/02/17 01:39:45 INFO ContextCleaner: Cleaned accumulator 1255
21/02/17 01:39:45 INFO ContextCleaner: Cleaned accumulator 901
21/02/17 01:39:45 INFO ContextCleaner: Cleaned accumulator 1120
21/02/17 01:39:45 INFO ContextCleaner: Cleaned accumulator 950
21/02/17 01:39:45 INFO ContextCleaner: Cleaned accumulator 988
21/02/17 01:39:45 INFO ContextCleaner: Cleaned accumulator 1206
21/02/17 01:39:45 INFO ContextCleaner: Cleaned accumulator 1147
21/02/17 01:39:45 INFO ContextCleaner: Cleaned accumulator 1232
21/02/17 01:39:45 INFO ContextCleaner: Cleaned accumulator 1004
21/02/17 01:39:45 INFO ContextCleaner: Cleaned accumulator 915
21/02/17 01:39:45 INFO ContextCleaner: Cleaned accumulator 1025
21/02/17 01:39:45 INFO BlockManagerInfo: Removed broadcast_52_piece0 on localhost:37301 in memory (size: 2.1 KB, free: 912.2 MB)
21/02/17 01:39:45 INFO ContextCleaner: Cleaned accumulator 1266
21/02/17 01:39:45 INFO ContextCleaner: Cleaned accumulator 1327
21/02/17 01:39:45 INFO ContextCleaner: Cleaned accumulator 1017
21/02/17 01:39:45 INFO ContextCleaner: Cleaned accumulator 1096
21/02/17 01:39:45 INFO ContextCleaner: Cleaned accumulator 1200
21/02/17 01:39:45 INFO ContextCleaner: Cleaned accumulator 1410
21/02/17 01:39:45 INFO ContextCleaner: Cleaned accumulator 888
21/02/17 01:39:45 INFO ContextCleaner: Cleaned accumulator 999
21/02/17 01:39:45 INFO ContextCleaner: Cleaned accumulator 1405
21/02/17 01:39:45 INFO ContextCleaner: Cleaned accumulator 905
21/02/17 01:39:45 INFO ContextCleaner: Cleaned accumulator 1170
21/02/17 01:39:45 INFO ContextCleaner: Cleaned accumulator 1201
21/02/17 01:39:45 INFO ContextCleaner: Cleaned accumulator 1358
21/02/17 01:39:45 INFO ContextCleaner: Cleaned accumulator 985
21/02/17 01:39:45 INFO ContextCleaner: Cleaned accumulator 1388
21/02/17 01:39:45 INFO ContextCleaner: Cleaned accumulator 833
21/02/17 01:39:45 INFO ContextCleaner: Cleaned accumulator 1176
21/02/17 01:39:45 INFO ContextCleaner: Cleaned accumulator 1125
21/02/17 01:39:45 INFO ContextCleaner: Cleaned accumulator 1373
21/02/17 01:39:45 INFO ContextCleaner: Cleaned accumulator 830
21/02/17 01:39:45 INFO ContextCleaner: Cleaned accumulator 1285
21/02/17 01:39:45 INFO ContextCleaner: Cleaned accumulator 1134
21/02/17 01:39:45 INFO ContextCleaner: Cleaned accumulator 892
21/02/17 01:39:45 INFO ContextCleaner: Cleaned accumulator 946
21/02/17 01:39:45 INFO ContextCleaner: Cleaned accumulator 1018
21/02/17 01:39:45 INFO ContextCleaner: Cleaned accumulator 1043
21/02/17 01:39:45 INFO ContextCleaner: Cleaned accumulator 1076
21/02/17 01:39:45 INFO ContextCleaner: Cleaned accumulator 1071
21/02/17 01:39:45 INFO ContextCleaner: Cleaned accumulator 1289
21/02/17 01:39:45 INFO ContextCleaner: Cleaned accumulator 1205
21/02/17 01:39:45 INFO ContextCleaner: Cleaned accumulator 1175
21/02/17 01:39:45 INFO ContextCleaner: Cleaned accumulator 1332
21/02/17 01:39:45 INFO BlockManagerInfo: Removed broadcast_48_piece0 on localhost:37301 in memory (size: 2.1 KB, free: 912.2 MB)
21/02/17 01:39:45 INFO ContextCleaner: Cleaned accumulator 1379
21/02/17 01:39:45 INFO ContextCleaner: Cleaned accumulator 1306
21/02/17 01:39:45 INFO ContextCleaner: Cleaned accumulator 1114
21/02/17 01:39:45 INFO ContextCleaner: Cleaned accumulator 1403
21/02/17 01:39:45 INFO ContextCleaner: Cleaned accumulator 1144
21/02/17 01:39:45 INFO ContextCleaner: Cleaned accumulator 1152
21/02/17 01:39:45 INFO ContextCleaner: Cleaned accumulator 1048
21/02/17 01:39:45 INFO ContextCleaner: Cleaned accumulator 989
21/02/17 01:39:45 INFO ContextCleaner: Cleaned accumulator 1384
21/02/17 01:39:45 INFO ContextCleaner: Cleaned accumulator 1320
21/02/17 01:39:45 INFO ContextCleaner: Cleaned accumulator 1163
21/02/17 01:39:45 INFO ContextCleaner: Cleaned accumulator 1172
21/02/17 01:39:45 INFO ContextCleaner: Cleaned accumulator 1390
21/02/17 01:39:45 INFO ContextCleaner: Cleaned accumulator 1225
21/02/17 01:39:45 INFO ContextCleaner: Cleaned accumulator 1414
21/02/17 01:39:45 INFO ContextCleaner: Cleaned accumulator 1127
21/02/17 01:39:45 INFO ContextCleaner: Cleaned accumulator 1089
21/02/17 01:39:45 INFO ContextCleaner: Cleaned accumulator 1086
21/02/17 01:39:45 INFO ContextCleaner: Cleaned accumulator 1354
21/02/17 01:39:45 INFO ContextCleaner: Cleaned accumulator 1378
21/02/17 01:39:45 INFO ContextCleaner: Cleaned accumulator 1341
21/02/17 01:39:45 INFO ContextCleaner: Cleaned accumulator 1155
21/02/17 01:39:45 INFO ContextCleaner: Cleaned accumulator 939
21/02/17 01:39:45 INFO ContextCleaner: Cleaned accumulator 1271
21/02/17 01:39:45 INFO BlockManagerInfo: Removed broadcast_53_piece0 on localhost:37301 in memory (size: 26.1 KB, free: 912.3 MB)
21/02/17 01:39:45 INFO ContextCleaner: Cleaned accumulator 851
21/02/17 01:39:45 INFO ContextCleaner: Cleaned accumulator 872
21/02/17 01:39:45 INFO ContextCleaner: Cleaned accumulator 1094
21/02/17 01:39:45 INFO ContextCleaner: Cleaned accumulator 1098
21/02/17 01:39:45 INFO ContextCleaner: Cleaned accumulator 1251
21/02/17 01:39:45 INFO ContextCleaner: Cleaned accumulator 971
21/02/17 01:39:45 INFO ContextCleaner: Cleaned accumulator 1329
21/02/17 01:39:45 INFO ContextCleaner: Cleaned accumulator 936
21/02/17 01:39:45 INFO ContextCleaner: Cleaned accumulator 978
21/02/17 01:39:45 INFO ContextCleaner: Cleaned accumulator 900
21/02/17 01:39:45 INFO ContextCleaner: Cleaned accumulator 1044
21/02/17 01:39:45 INFO ContextCleaner: Cleaned accumulator 1088
21/02/17 01:39:45 INFO ContextCleaner: Cleaned accumulator 829
21/02/17 01:39:45 INFO ContextCleaner: Cleaned accumulator 954
21/02/17 01:39:45 INFO ContextCleaner: Cleaned accumulator 1029
21/02/17 01:39:45 INFO ContextCleaner: Cleaned accumulator 964
21/02/17 01:39:45 INFO ContextCleaner: Cleaned accumulator 1161
21/02/17 01:39:45 INFO ContextCleaner: Cleaned accumulator 1318
21/02/17 01:39:45 INFO ContextCleaner: Cleaned accumulator 1194
21/02/17 01:39:45 INFO ContextCleaner: Cleaned accumulator 1258
21/02/17 01:39:45 INFO ContextCleaner: Cleaned accumulator 845
21/02/17 01:39:45 INFO ContextCleaner: Cleaned accumulator 1047
21/02/17 01:39:45 INFO ContextCleaner: Cleaned accumulator 1189
21/02/17 01:39:45 INFO ContextCleaner: Cleaned accumulator 1346
21/02/17 01:39:45 INFO ContextCleaner: Cleaned accumulator 1269
21/02/17 01:39:45 INFO ContextCleaner: Cleaned accumulator 1300
21/02/17 01:39:45 INFO ContextCleaner: Cleaned accumulator 1276
21/02/17 01:39:45 INFO ContextCleaner: Cleaned accumulator 1404
21/02/17 01:39:45 INFO ContextCleaner: Cleaned accumulator 927
21/02/17 01:39:45 INFO ContextCleaner: Cleaned accumulator 1195
21/02/17 01:39:45 INFO ContextCleaner: Cleaned accumulator 1185
21/02/17 01:39:45 INFO ContextCleaner: Cleaned accumulator 1406
21/02/17 01:39:45 INFO ContextCleaner: Cleaned accumulator 1385
21/02/17 01:39:45 INFO ContextCleaner: Cleaned accumulator 1340
21/02/17 01:39:45 INFO ContextCleaner: Cleaned accumulator 948
21/02/17 01:39:45 INFO ContextCleaner: Cleaned accumulator 975
21/02/17 01:39:45 INFO ContextCleaner: Cleaned accumulator 1292
21/02/17 01:39:45 INFO ContextCleaner: Cleaned accumulator 879
21/02/17 01:39:45 INFO ContextCleaner: Cleaned accumulator 912
21/02/17 01:39:45 INFO ContextCleaner: Cleaned accumulator 953
21/02/17 01:39:45 INFO ContextCleaner: Cleaned accumulator 1209
21/02/17 01:39:45 INFO ContextCleaner: Cleaned accumulator 1105
21/02/17 01:39:45 INFO ContextCleaner: Cleaned accumulator 1248
21/02/17 01:39:45 INFO ContextCleaner: Cleaned accumulator 1310
21/02/17 01:39:45 INFO ContextCleaner: Cleaned accumulator 1083
21/02/17 01:39:45 INFO ContextCleaner: Cleaned accumulator 1042
21/02/17 01:39:45 INFO ContextCleaner: Cleaned accumulator 952
21/02/17 01:39:45 INFO BlockManagerInfo: Removed broadcast_38_piece0 on localhost:37301 in memory (size: 3.8 KB, free: 912.3 MB)
21/02/17 01:39:45 INFO ContextCleaner: Cleaned accumulator 1270
21/02/17 01:39:45 INFO ContextCleaner: Cleaned accumulator 1326
21/02/17 01:39:45 INFO ContextCleaner: Cleaned accumulator 1078
21/02/17 01:39:45 INFO CodecPool: Got brand-new decompressor [.snappy]
21/02/17 01:39:45 INFO ContextCleaner: Cleaned accumulator 1223
21/02/17 01:39:45 INFO ContextCleaner: Cleaned accumulator 890
21/02/17 01:39:45 INFO ContextCleaner: Cleaned accumulator 1183
21/02/17 01:39:45 INFO ContextCleaner: Cleaned accumulator 1193
21/02/17 01:39:45 INFO ContextCleaner: Cleaned accumulator 1364
21/02/17 01:39:45 INFO ContextCleaner: Cleaned accumulator 945
21/02/17 01:39:45 INFO ContextCleaner: Cleaned accumulator 913
21/02/17 01:39:45 INFO ContextCleaner: Cleaned accumulator 1074
21/02/17 01:39:45 INFO ContextCleaner: Cleaned accumulator 1139
21/02/17 01:39:45 INFO ContextCleaner: Cleaned accumulator 1382
21/02/17 01:39:45 INFO ContextCleaner: Cleaned accumulator 1145
21/02/17 01:39:45 INFO BlockManagerInfo: Removed broadcast_40_piece0 on localhost:37301 in memory (size: 4.1 KB, free: 912.3 MB)
21/02/17 01:39:45 INFO ContextCleaner: Cleaned accumulator 1253
21/02/17 01:39:45 INFO ContextCleaner: Cleaned accumulator 1104
21/02/17 01:39:45 INFO ContextCleaner: Cleaned accumulator 1409
21/02/17 01:39:45 INFO ContextCleaner: Cleaned accumulator 991
21/02/17 01:39:45 INFO Executor: Finished task 0.0 in stage 48.0 (TID 50). 1321 bytes result sent to driver
21/02/17 01:39:45 INFO TaskSetManager: Finished task 0.0 in stage 48.0 (TID 50) in 101 ms on localhost (executor driver) (1/1)
21/02/17 01:39:45 INFO TaskSchedulerImpl: Removed TaskSet 48.0, whose tasks have all completed, from pool 
21/02/17 01:39:45 INFO DAGScheduler: ResultStage 48 (head at RFormula.scala:438) finished in 0.107 s
21/02/17 01:39:45 INFO DAGScheduler: Job 35 finished: head at RFormula.scala:438, took 0.109428 s
21/02/17 01:39:45 INFO MemoryStore: Block broadcast_56 stored as values in memory (estimated size 239.6 KB, free 911.7 MB)
21/02/17 01:39:45 INFO MemoryStore: Block broadcast_56_piece0 stored as bytes in memory (estimated size 23.2 KB, free 911.7 MB)
21/02/17 01:39:45 INFO BlockManagerInfo: Added broadcast_56_piece0 in memory on localhost:37301 (size: 23.2 KB, free: 912.2 MB)
21/02/17 01:39:45 INFO SparkContext: Created broadcast 56 from textFile at ReadWrite.scala:615
21/02/17 01:39:45 INFO FileInputFormat: Total input paths to process : 1
21/02/17 01:39:45 INFO SparkContext: Starting job: first at ReadWrite.scala:615
21/02/17 01:39:45 INFO DAGScheduler: Got job 36 (first at ReadWrite.scala:615) with 1 output partitions
21/02/17 01:39:45 INFO DAGScheduler: Final stage: ResultStage 49 (first at ReadWrite.scala:615)
21/02/17 01:39:45 INFO DAGScheduler: Parents of final stage: List()
21/02/17 01:39:45 INFO DAGScheduler: Missing parents: List()
21/02/17 01:39:45 INFO DAGScheduler: Submitting ResultStage 49 (/tmp/RtmpaHGCHH/file22ad95b56a718/stages/0_r_formula__8eae6edf_b16e_4036_a8d6_baf58826f8d0/pipelineModel/metadata MapPartitionsRDD[167] at textFile at ReadWrite.scala:615), which has no missing parents
21/02/17 01:39:45 INFO MemoryStore: Block broadcast_57 stored as values in memory (estimated size 3.5 KB, free 911.7 MB)
21/02/17 01:39:45 INFO MemoryStore: Block broadcast_57_piece0 stored as bytes in memory (estimated size 2.1 KB, free 911.7 MB)
21/02/17 01:39:45 INFO BlockManagerInfo: Added broadcast_57_piece0 in memory on localhost:37301 (size: 2.1 KB, free: 912.2 MB)
21/02/17 01:39:45 INFO SparkContext: Created broadcast 57 from broadcast at DAGScheduler.scala:1161
21/02/17 01:39:45 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 49 (/tmp/RtmpaHGCHH/file22ad95b56a718/stages/0_r_formula__8eae6edf_b16e_4036_a8d6_baf58826f8d0/pipelineModel/metadata MapPartitionsRDD[167] at textFile at ReadWrite.scala:615) (first 15 tasks are for partitions Vector(0))
21/02/17 01:39:45 INFO TaskSchedulerImpl: Adding task set 49.0 with 1 tasks
21/02/17 01:39:45 INFO TaskSetManager: Starting task 0.0 in stage 49.0 (TID 51, localhost, executor driver, partition 0, PROCESS_LOCAL, 7990 bytes)
21/02/17 01:39:45 INFO Executor: Running task 0.0 in stage 49.0 (TID 51)
21/02/17 01:39:45 INFO HadoopRDD: Input split: file:/tmp/RtmpaHGCHH/file22ad95b56a718/stages/0_r_formula__8eae6edf_b16e_4036_a8d6_baf58826f8d0/pipelineModel/metadata/part-00000:0+311
21/02/17 01:39:45 INFO Executor: Finished task 0.0 in stage 49.0 (TID 51). 1110 bytes result sent to driver
21/02/17 01:39:45 INFO TaskSetManager: Finished task 0.0 in stage 49.0 (TID 51) in 4 ms on localhost (executor driver) (1/1)
21/02/17 01:39:45 INFO TaskSchedulerImpl: Removed TaskSet 49.0, whose tasks have all completed, from pool 
21/02/17 01:39:45 INFO DAGScheduler: ResultStage 49 (first at ReadWrite.scala:615) finished in 0.007 s
21/02/17 01:39:45 INFO DAGScheduler: Job 36 finished: first at ReadWrite.scala:615, took 0.008127 s
21/02/17 01:39:45 INFO MemoryStore: Block broadcast_58 stored as values in memory (estimated size 239.6 KB, free 911.5 MB)
21/02/17 01:39:45 INFO MemoryStore: Block broadcast_58_piece0 stored as bytes in memory (estimated size 23.2 KB, free 911.4 MB)
21/02/17 01:39:45 INFO BlockManagerInfo: Added broadcast_58_piece0 in memory on localhost:37301 (size: 23.2 KB, free: 912.2 MB)
21/02/17 01:39:45 INFO SparkContext: Created broadcast 58 from textFile at ReadWrite.scala:615
21/02/17 01:39:45 INFO FileInputFormat: Total input paths to process : 1
21/02/17 01:39:45 INFO SparkContext: Starting job: first at ReadWrite.scala:615
21/02/17 01:39:45 INFO DAGScheduler: Got job 37 (first at ReadWrite.scala:615) with 1 output partitions
21/02/17 01:39:45 INFO DAGScheduler: Final stage: ResultStage 50 (first at ReadWrite.scala:615)
21/02/17 01:39:45 INFO DAGScheduler: Parents of final stage: List()
21/02/17 01:39:45 INFO DAGScheduler: Missing parents: List()
21/02/17 01:39:45 INFO DAGScheduler: Submitting ResultStage 50 (/tmp/RtmpaHGCHH/file22ad95b56a718/stages/0_r_formula__8eae6edf_b16e_4036_a8d6_baf58826f8d0/pipelineModel/stages/0_r_formula__8eae6edf_b16e_4036_a8d6_baf58826f8d0/metadata MapPartitionsRDD[169] at textFile at ReadWrite.scala:615), which has no missing parents
21/02/17 01:39:45 INFO MemoryStore: Block broadcast_59 stored as values in memory (estimated size 3.6 KB, free 911.4 MB)
21/02/17 01:39:45 INFO MemoryStore: Block broadcast_59_piece0 stored as bytes in memory (estimated size 2.1 KB, free 911.4 MB)
21/02/17 01:39:45 INFO BlockManagerInfo: Added broadcast_59_piece0 in memory on localhost:37301 (size: 2.1 KB, free: 912.2 MB)
21/02/17 01:39:45 INFO SparkContext: Created broadcast 59 from broadcast at DAGScheduler.scala:1161
21/02/17 01:39:45 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 50 (/tmp/RtmpaHGCHH/file22ad95b56a718/stages/0_r_formula__8eae6edf_b16e_4036_a8d6_baf58826f8d0/pipelineModel/stages/0_r_formula__8eae6edf_b16e_4036_a8d6_baf58826f8d0/metadata MapPartitionsRDD[169] at textFile at ReadWrite.scala:615) (first 15 tasks are for partitions Vector(0))
21/02/17 01:39:45 INFO TaskSchedulerImpl: Adding task set 50.0 with 1 tasks
21/02/17 01:39:45 INFO TaskSetManager: Starting task 0.0 in stage 50.0 (TID 52, localhost, executor driver, partition 0, PROCESS_LOCAL, 8050 bytes)
21/02/17 01:39:45 INFO Executor: Running task 0.0 in stage 50.0 (TID 52)
21/02/17 01:39:45 INFO HadoopRDD: Input split: file:/tmp/RtmpaHGCHH/file22ad95b56a718/stages/0_r_formula__8eae6edf_b16e_4036_a8d6_baf58826f8d0/pipelineModel/stages/0_r_formula__8eae6edf_b16e_4036_a8d6_baf58826f8d0/metadata/part-00000:0+378
21/02/17 01:39:45 INFO Executor: Finished task 0.0 in stage 50.0 (TID 52). 1177 bytes result sent to driver
21/02/17 01:39:45 INFO TaskSetManager: Finished task 0.0 in stage 50.0 (TID 52) in 3 ms on localhost (executor driver) (1/1)
21/02/17 01:39:45 INFO TaskSchedulerImpl: Removed TaskSet 50.0, whose tasks have all completed, from pool 
21/02/17 01:39:45 INFO DAGScheduler: ResultStage 50 (first at ReadWrite.scala:615) finished in 0.006 s
21/02/17 01:39:45 INFO DAGScheduler: Job 37 finished: first at ReadWrite.scala:615, took 0.007274 s
21/02/17 01:39:45 INFO MemoryStore: Block broadcast_60 stored as values in memory (estimated size 239.6 KB, free 911.2 MB)
21/02/17 01:39:45 INFO MemoryStore: Block broadcast_60_piece0 stored as bytes in memory (estimated size 23.2 KB, free 911.2 MB)
21/02/17 01:39:45 INFO BlockManagerInfo: Added broadcast_60_piece0 in memory on localhost:37301 (size: 23.2 KB, free: 912.2 MB)
21/02/17 01:39:45 INFO SparkContext: Created broadcast 60 from textFile at ReadWrite.scala:615
21/02/17 01:39:45 INFO FileInputFormat: Total input paths to process : 1
21/02/17 01:39:45 INFO SparkContext: Starting job: first at ReadWrite.scala:615
21/02/17 01:39:45 INFO DAGScheduler: Got job 38 (first at ReadWrite.scala:615) with 1 output partitions
21/02/17 01:39:45 INFO DAGScheduler: Final stage: ResultStage 51 (first at ReadWrite.scala:615)
21/02/17 01:39:45 INFO DAGScheduler: Parents of final stage: List()
21/02/17 01:39:45 INFO DAGScheduler: Missing parents: List()
21/02/17 01:39:45 INFO DAGScheduler: Submitting ResultStage 51 (/tmp/RtmpaHGCHH/file22ad95b56a718/stages/0_r_formula__8eae6edf_b16e_4036_a8d6_baf58826f8d0/pipelineModel/stages/0_r_formula__8eae6edf_b16e_4036_a8d6_baf58826f8d0/metadata MapPartitionsRDD[171] at textFile at ReadWrite.scala:615), which has no missing parents
21/02/17 01:39:45 INFO MemoryStore: Block broadcast_61 stored as values in memory (estimated size 3.6 KB, free 911.2 MB)
21/02/17 01:39:45 INFO MemoryStore: Block broadcast_61_piece0 stored as bytes in memory (estimated size 2.1 KB, free 911.2 MB)
21/02/17 01:39:45 INFO BlockManagerInfo: Added broadcast_61_piece0 in memory on localhost:37301 (size: 2.1 KB, free: 912.2 MB)
21/02/17 01:39:45 INFO SparkContext: Created broadcast 61 from broadcast at DAGScheduler.scala:1161
21/02/17 01:39:45 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 51 (/tmp/RtmpaHGCHH/file22ad95b56a718/stages/0_r_formula__8eae6edf_b16e_4036_a8d6_baf58826f8d0/pipelineModel/stages/0_r_formula__8eae6edf_b16e_4036_a8d6_baf58826f8d0/metadata MapPartitionsRDD[171] at textFile at ReadWrite.scala:615) (first 15 tasks are for partitions Vector(0))
21/02/17 01:39:45 INFO TaskSchedulerImpl: Adding task set 51.0 with 1 tasks
21/02/17 01:39:45 INFO TaskSetManager: Starting task 0.0 in stage 51.0 (TID 53, localhost, executor driver, partition 0, PROCESS_LOCAL, 8050 bytes)
21/02/17 01:39:45 INFO Executor: Running task 0.0 in stage 51.0 (TID 53)
21/02/17 01:39:45 INFO HadoopRDD: Input split: file:/tmp/RtmpaHGCHH/file22ad95b56a718/stages/0_r_formula__8eae6edf_b16e_4036_a8d6_baf58826f8d0/pipelineModel/stages/0_r_formula__8eae6edf_b16e_4036_a8d6_baf58826f8d0/metadata/part-00000:0+378
21/02/17 01:39:45 INFO Executor: Finished task 0.0 in stage 51.0 (TID 53). 1177 bytes result sent to driver
21/02/17 01:39:45 INFO TaskSetManager: Finished task 0.0 in stage 51.0 (TID 53) in 3 ms on localhost (executor driver) (1/1)
21/02/17 01:39:45 INFO TaskSchedulerImpl: Removed TaskSet 51.0, whose tasks have all completed, from pool 
21/02/17 01:39:45 INFO DAGScheduler: ResultStage 51 (first at ReadWrite.scala:615) finished in 0.006 s
21/02/17 01:39:45 INFO DAGScheduler: Job 38 finished: first at ReadWrite.scala:615, took 0.006893 s
21/02/17 01:39:45 INFO MemoryStore: Block broadcast_62 stored as values in memory (estimated size 239.6 KB, free 910.9 MB)
21/02/17 01:39:45 INFO MemoryStore: Block broadcast_62_piece0 stored as bytes in memory (estimated size 23.2 KB, free 910.9 MB)
21/02/17 01:39:45 INFO BlockManagerInfo: Added broadcast_62_piece0 in memory on localhost:37301 (size: 23.2 KB, free: 912.2 MB)
21/02/17 01:39:45 INFO SparkContext: Created broadcast 62 from textFile at ReadWrite.scala:615
21/02/17 01:39:45 INFO FileInputFormat: Total input paths to process : 1
21/02/17 01:39:45 INFO SparkContext: Starting job: first at ReadWrite.scala:615
21/02/17 01:39:45 INFO DAGScheduler: Got job 39 (first at ReadWrite.scala:615) with 1 output partitions
21/02/17 01:39:45 INFO DAGScheduler: Final stage: ResultStage 52 (first at ReadWrite.scala:615)
21/02/17 01:39:45 INFO DAGScheduler: Parents of final stage: List()
21/02/17 01:39:45 INFO DAGScheduler: Missing parents: List()
21/02/17 01:39:45 INFO DAGScheduler: Submitting ResultStage 52 (/tmp/RtmpaHGCHH/file22ad95b56a718/stages/0_r_formula__8eae6edf_b16e_4036_a8d6_baf58826f8d0/pipelineModel/stages/1_vectorAttrRewriter_82617fd1f646/metadata MapPartitionsRDD[173] at textFile at ReadWrite.scala:615), which has no missing parents
21/02/17 01:39:45 INFO MemoryStore: Block broadcast_63 stored as values in memory (estimated size 3.6 KB, free 910.9 MB)
21/02/17 01:39:45 INFO MemoryStore: Block broadcast_63_piece0 stored as bytes in memory (estimated size 2.2 KB, free 910.9 MB)
21/02/17 01:39:45 INFO BlockManagerInfo: Added broadcast_63_piece0 in memory on localhost:37301 (size: 2.2 KB, free: 912.2 MB)
21/02/17 01:39:45 INFO SparkContext: Created broadcast 63 from broadcast at DAGScheduler.scala:1161
21/02/17 01:39:45 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 52 (/tmp/RtmpaHGCHH/file22ad95b56a718/stages/0_r_formula__8eae6edf_b16e_4036_a8d6_baf58826f8d0/pipelineModel/stages/1_vectorAttrRewriter_82617fd1f646/metadata MapPartitionsRDD[173] at textFile at ReadWrite.scala:615) (first 15 tasks are for partitions Vector(0))
21/02/17 01:39:45 INFO TaskSchedulerImpl: Adding task set 52.0 with 1 tasks
21/02/17 01:39:45 INFO TaskSetManager: Starting task 0.0 in stage 52.0 (TID 54, localhost, executor driver, partition 0, PROCESS_LOCAL, 8034 bytes)
21/02/17 01:39:45 INFO Executor: Running task 0.0 in stage 52.0 (TID 54)
21/02/17 01:39:45 INFO HadoopRDD: Input split: file:/tmp/RtmpaHGCHH/file22ad95b56a718/stages/0_r_formula__8eae6edf_b16e_4036_a8d6_baf58826f8d0/pipelineModel/stages/1_vectorAttrRewriter_82617fd1f646/metadata/part-00000:0+188
21/02/17 01:39:45 INFO Executor: Finished task 0.0 in stage 52.0 (TID 54). 984 bytes result sent to driver
21/02/17 01:39:45 INFO TaskSetManager: Finished task 0.0 in stage 52.0 (TID 54) in 3 ms on localhost (executor driver) (1/1)
21/02/17 01:39:45 INFO TaskSchedulerImpl: Removed TaskSet 52.0, whose tasks have all completed, from pool 
21/02/17 01:39:45 INFO DAGScheduler: ResultStage 52 (first at ReadWrite.scala:615) finished in 0.005 s
21/02/17 01:39:45 INFO DAGScheduler: Job 39 finished: first at ReadWrite.scala:615, took 0.006580 s
21/02/17 01:39:45 INFO MemoryStore: Block broadcast_64 stored as values in memory (estimated size 239.6 KB, free 910.7 MB)
21/02/17 01:39:45 INFO MemoryStore: Block broadcast_64_piece0 stored as bytes in memory (estimated size 23.2 KB, free 910.7 MB)
21/02/17 01:39:45 INFO BlockManagerInfo: Added broadcast_64_piece0 in memory on localhost:37301 (size: 23.2 KB, free: 912.1 MB)
21/02/17 01:39:45 INFO SparkContext: Created broadcast 64 from textFile at ReadWrite.scala:615
21/02/17 01:39:45 INFO FileInputFormat: Total input paths to process : 1
21/02/17 01:39:45 INFO SparkContext: Starting job: first at ReadWrite.scala:615
21/02/17 01:39:45 INFO DAGScheduler: Got job 40 (first at ReadWrite.scala:615) with 1 output partitions
21/02/17 01:39:45 INFO DAGScheduler: Final stage: ResultStage 53 (first at ReadWrite.scala:615)
21/02/17 01:39:45 INFO DAGScheduler: Parents of final stage: List()
21/02/17 01:39:45 INFO DAGScheduler: Missing parents: List()
21/02/17 01:39:45 INFO DAGScheduler: Submitting ResultStage 53 (/tmp/RtmpaHGCHH/file22ad95b56a718/stages/0_r_formula__8eae6edf_b16e_4036_a8d6_baf58826f8d0/pipelineModel/stages/1_vectorAttrRewriter_82617fd1f646/metadata MapPartitionsRDD[175] at textFile at ReadWrite.scala:615), which has no missing parents
21/02/17 01:39:45 INFO MemoryStore: Block broadcast_65 stored as values in memory (estimated size 3.6 KB, free 910.7 MB)
21/02/17 01:39:45 INFO MemoryStore: Block broadcast_65_piece0 stored as bytes in memory (estimated size 2.2 KB, free 910.6 MB)
21/02/17 01:39:45 INFO BlockManagerInfo: Added broadcast_65_piece0 in memory on localhost:37301 (size: 2.2 KB, free: 912.1 MB)
21/02/17 01:39:45 INFO SparkContext: Created broadcast 65 from broadcast at DAGScheduler.scala:1161
21/02/17 01:39:45 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 53 (/tmp/RtmpaHGCHH/file22ad95b56a718/stages/0_r_formula__8eae6edf_b16e_4036_a8d6_baf58826f8d0/pipelineModel/stages/1_vectorAttrRewriter_82617fd1f646/metadata MapPartitionsRDD[175] at textFile at ReadWrite.scala:615) (first 15 tasks are for partitions Vector(0))
21/02/17 01:39:45 INFO TaskSchedulerImpl: Adding task set 53.0 with 1 tasks
21/02/17 01:39:45 INFO TaskSetManager: Starting task 0.0 in stage 53.0 (TID 55, localhost, executor driver, partition 0, PROCESS_LOCAL, 8034 bytes)
21/02/17 01:39:45 INFO Executor: Running task 0.0 in stage 53.0 (TID 55)
21/02/17 01:39:45 INFO HadoopRDD: Input split: file:/tmp/RtmpaHGCHH/file22ad95b56a718/stages/0_r_formula__8eae6edf_b16e_4036_a8d6_baf58826f8d0/pipelineModel/stages/1_vectorAttrRewriter_82617fd1f646/metadata/part-00000:0+188
21/02/17 01:39:45 INFO Executor: Finished task 0.0 in stage 53.0 (TID 55). 941 bytes result sent to driver
21/02/17 01:39:45 INFO TaskSetManager: Finished task 0.0 in stage 53.0 (TID 55) in 5 ms on localhost (executor driver) (1/1)
21/02/17 01:39:45 INFO TaskSchedulerImpl: Removed TaskSet 53.0, whose tasks have all completed, from pool 
21/02/17 01:39:45 INFO DAGScheduler: ResultStage 53 (first at ReadWrite.scala:615) finished in 0.007 s
21/02/17 01:39:45 INFO DAGScheduler: Job 40 finished: first at ReadWrite.scala:615, took 0.009258 s
21/02/17 01:39:45 INFO SparkContext: Starting job: parquet at RFormula.scala:600
21/02/17 01:39:45 INFO DAGScheduler: Got job 41 (parquet at RFormula.scala:600) with 1 output partitions
21/02/17 01:39:45 INFO DAGScheduler: Final stage: ResultStage 54 (parquet at RFormula.scala:600)
21/02/17 01:39:45 INFO DAGScheduler: Parents of final stage: List()
21/02/17 01:39:45 INFO DAGScheduler: Missing parents: List()
21/02/17 01:39:45 INFO DAGScheduler: Submitting ResultStage 54 (MapPartitionsRDD[177] at parquet at RFormula.scala:600), which has no missing parents
21/02/17 01:39:45 INFO MemoryStore: Block broadcast_66 stored as values in memory (estimated size 74.1 KB, free 910.6 MB)
21/02/17 01:39:45 INFO MemoryStore: Block broadcast_66_piece0 stored as bytes in memory (estimated size 26.1 KB, free 910.6 MB)
21/02/17 01:39:45 INFO BlockManagerInfo: Added broadcast_66_piece0 in memory on localhost:37301 (size: 26.1 KB, free: 912.1 MB)
21/02/17 01:39:45 INFO SparkContext: Created broadcast 66 from broadcast at DAGScheduler.scala:1161
21/02/17 01:39:45 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 54 (MapPartitionsRDD[177] at parquet at RFormula.scala:600) (first 15 tasks are for partitions Vector(0))
21/02/17 01:39:45 INFO TaskSchedulerImpl: Adding task set 54.0 with 1 tasks
21/02/17 01:39:45 INFO TaskSetManager: Starting task 0.0 in stage 54.0 (TID 56, localhost, executor driver, partition 0, PROCESS_LOCAL, 8190 bytes)
21/02/17 01:39:45 INFO Executor: Running task 0.0 in stage 54.0 (TID 56)
21/02/17 01:39:45 INFO Executor: Finished task 0.0 in stage 54.0 (TID 56). 1620 bytes result sent to driver
21/02/17 01:39:45 INFO TaskSetManager: Finished task 0.0 in stage 54.0 (TID 56) in 6 ms on localhost (executor driver) (1/1)
21/02/17 01:39:45 INFO TaskSchedulerImpl: Removed TaskSet 54.0, whose tasks have all completed, from pool 
21/02/17 01:39:45 INFO DAGScheduler: ResultStage 54 (parquet at RFormula.scala:600) finished in 0.014 s
21/02/17 01:39:45 INFO DAGScheduler: Job 41 finished: parquet at RFormula.scala:600, took 0.015283 s
21/02/17 01:39:45 INFO FileSourceStrategy: Pruning directories with: 
21/02/17 01:39:45 INFO FileSourceStrategy: Post-Scan Filters: 
21/02/17 01:39:45 INFO FileSourceStrategy: Output Data Schema: struct<vectorCol: string, prefixesToRewrite: map<string,string>>
21/02/17 01:39:45 INFO FileSourceScanExec: Pushed Filters: 
21/02/17 01:39:45 INFO CodeGenerator: Code generated in 12.246552 ms
21/02/17 01:39:45 INFO CodeGenerator: Code generated in 7.355552 ms
21/02/17 01:39:45 INFO MemoryStore: Block broadcast_67 stored as values in memory (estimated size 292.8 KB, free 910.3 MB)
21/02/17 01:39:45 INFO MemoryStore: Block broadcast_67_piece0 stored as bytes in memory (estimated size 25.1 KB, free 910.2 MB)
21/02/17 01:39:45 INFO BlockManagerInfo: Added broadcast_67_piece0 in memory on localhost:37301 (size: 25.1 KB, free: 912.1 MB)
21/02/17 01:39:45 INFO SparkContext: Created broadcast 67 from head at RFormula.scala:600
21/02/17 01:39:45 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
21/02/17 01:39:45 INFO SparkContext: Starting job: head at RFormula.scala:600
21/02/17 01:39:45 INFO DAGScheduler: Got job 42 (head at RFormula.scala:600) with 1 output partitions
21/02/17 01:39:45 INFO DAGScheduler: Final stage: ResultStage 55 (head at RFormula.scala:600)
21/02/17 01:39:45 INFO DAGScheduler: Parents of final stage: List()
21/02/17 01:39:45 INFO DAGScheduler: Missing parents: List()
21/02/17 01:39:45 INFO DAGScheduler: Submitting ResultStage 55 (MapPartitionsRDD[181] at head at RFormula.scala:600), which has no missing parents
21/02/17 01:39:45 INFO MemoryStore: Block broadcast_68 stored as values in memory (estimated size 10.5 KB, free 910.2 MB)
21/02/17 01:39:45 INFO MemoryStore: Block broadcast_68_piece0 stored as bytes in memory (estimated size 5.0 KB, free 910.2 MB)
21/02/17 01:39:45 INFO BlockManagerInfo: Added broadcast_68_piece0 in memory on localhost:37301 (size: 5.0 KB, free: 912.1 MB)
21/02/17 01:39:45 INFO SparkContext: Created broadcast 68 from broadcast at DAGScheduler.scala:1161
21/02/17 01:39:45 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 55 (MapPartitionsRDD[181] at head at RFormula.scala:600) (first 15 tasks are for partitions Vector(0))
21/02/17 01:39:45 INFO TaskSchedulerImpl: Adding task set 55.0 with 1 tasks
21/02/17 01:39:45 INFO TaskSetManager: Starting task 0.0 in stage 55.0 (TID 57, localhost, executor driver, partition 0, PROCESS_LOCAL, 8441 bytes)
21/02/17 01:39:45 INFO Executor: Running task 0.0 in stage 55.0 (TID 57)
21/02/17 01:39:45 INFO FileScanRDD: Reading File path: file:///tmp/RtmpaHGCHH/file22ad95b56a718/stages/0_r_formula__8eae6edf_b16e_4036_a8d6_baf58826f8d0/pipelineModel/stages/1_vectorAttrRewriter_82617fd1f646/data/part-00000-f0906cea-4b6d-4d12-b037-f72fe83ed43f-c000.snappy.parquet, range: 0-893, partition values: [empty row]
21/02/17 01:39:45 INFO ParquetReadSupport: Going to read the following fields from the Parquet file:

Parquet form:
message spark_schema {
  optional binary vectorCol (UTF8);
  optional group prefixesToRewrite (MAP) {
    repeated group key_value {
      required binary key (UTF8);
      optional binary value (UTF8);
    }
  }
}

Catalyst form:
StructType(StructField(vectorCol,StringType,true), StructField(prefixesToRewrite,MapType(StringType,StringType,true),true))
       
21/02/17 01:39:45 INFO Executor: Finished task 0.0 in stage 55.0 (TID 57). 1216 bytes result sent to driver
21/02/17 01:39:45 INFO TaskSetManager: Finished task 0.0 in stage 55.0 (TID 57) in 14 ms on localhost (executor driver) (1/1)
21/02/17 01:39:45 INFO TaskSchedulerImpl: Removed TaskSet 55.0, whose tasks have all completed, from pool 
21/02/17 01:39:45 INFO DAGScheduler: ResultStage 55 (head at RFormula.scala:600) finished in 0.019 s
21/02/17 01:39:45 INFO DAGScheduler: Job 42 finished: head at RFormula.scala:600, took 0.020393 s
21/02/17 01:39:45 INFO MemoryStore: Block broadcast_69 stored as values in memory (estimated size 239.6 KB, free 910.0 MB)
21/02/17 01:39:45 INFO MemoryStore: Block broadcast_69_piece0 stored as bytes in memory (estimated size 23.2 KB, free 910.0 MB)
21/02/17 01:39:45 INFO BlockManagerInfo: Added broadcast_69_piece0 in memory on localhost:37301 (size: 23.2 KB, free: 912.1 MB)
21/02/17 01:39:45 INFO SparkContext: Created broadcast 69 from textFile at ReadWrite.scala:615
21/02/17 01:39:45 INFO FileInputFormat: Total input paths to process : 1
21/02/17 01:39:45 INFO SparkContext: Starting job: first at ReadWrite.scala:615
21/02/17 01:39:45 INFO DAGScheduler: Got job 43 (first at ReadWrite.scala:615) with 1 output partitions
21/02/17 01:39:45 INFO DAGScheduler: Final stage: ResultStage 56 (first at ReadWrite.scala:615)
21/02/17 01:39:45 INFO DAGScheduler: Parents of final stage: List()
21/02/17 01:39:45 INFO DAGScheduler: Missing parents: List()
21/02/17 01:39:45 INFO DAGScheduler: Submitting ResultStage 56 (/tmp/RtmpaHGCHH/file22ad95b56a718/stages/0_r_formula__8eae6edf_b16e_4036_a8d6_baf58826f8d0/pipelineModel/stages/2_columnPruner_61c178682e95/metadata MapPartitionsRDD[183] at textFile at ReadWrite.scala:615), which has no missing parents
21/02/17 01:39:45 INFO MemoryStore: Block broadcast_70 stored as values in memory (estimated size 3.6 KB, free 910.0 MB)
21/02/17 01:39:45 INFO MemoryStore: Block broadcast_70_piece0 stored as bytes in memory (estimated size 2.2 KB, free 910.0 MB)
21/02/17 01:39:45 INFO BlockManagerInfo: Added broadcast_70_piece0 in memory on localhost:37301 (size: 2.2 KB, free: 912.1 MB)
21/02/17 01:39:45 INFO SparkContext: Created broadcast 70 from broadcast at DAGScheduler.scala:1161
21/02/17 01:39:45 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 56 (/tmp/RtmpaHGCHH/file22ad95b56a718/stages/0_r_formula__8eae6edf_b16e_4036_a8d6_baf58826f8d0/pipelineModel/stages/2_columnPruner_61c178682e95/metadata MapPartitionsRDD[183] at textFile at ReadWrite.scala:615) (first 15 tasks are for partitions Vector(0))
21/02/17 01:39:45 INFO TaskSchedulerImpl: Adding task set 56.0 with 1 tasks
21/02/17 01:39:45 INFO TaskSetManager: Starting task 0.0 in stage 56.0 (TID 58, localhost, executor driver, partition 0, PROCESS_LOCAL, 8025 bytes)
21/02/17 01:39:45 INFO Executor: Running task 0.0 in stage 56.0 (TID 58)
21/02/17 01:39:45 INFO HadoopRDD: Input split: file:/tmp/RtmpaHGCHH/file22ad95b56a718/stages/0_r_formula__8eae6edf_b16e_4036_a8d6_baf58826f8d0/pipelineModel/stages/2_columnPruner_61c178682e95/metadata/part-00000:0+171
21/02/17 01:39:45 INFO Executor: Finished task 0.0 in stage 56.0 (TID 58). 967 bytes result sent to driver
21/02/17 01:39:45 INFO TaskSetManager: Finished task 0.0 in stage 56.0 (TID 58) in 3 ms on localhost (executor driver) (1/1)
21/02/17 01:39:45 INFO TaskSchedulerImpl: Removed TaskSet 56.0, whose tasks have all completed, from pool 
21/02/17 01:39:45 INFO DAGScheduler: ResultStage 56 (first at ReadWrite.scala:615) finished in 0.006 s
21/02/17 01:39:45 INFO DAGScheduler: Job 43 finished: first at ReadWrite.scala:615, took 0.006565 s
21/02/17 01:39:45 INFO MemoryStore: Block broadcast_71 stored as values in memory (estimated size 239.6 KB, free 909.7 MB)
21/02/17 01:39:45 INFO MemoryStore: Block broadcast_71_piece0 stored as bytes in memory (estimated size 23.2 KB, free 909.7 MB)
21/02/17 01:39:45 INFO BlockManagerInfo: Added broadcast_71_piece0 in memory on localhost:37301 (size: 23.2 KB, free: 912.0 MB)
21/02/17 01:39:45 INFO SparkContext: Created broadcast 71 from textFile at ReadWrite.scala:615
21/02/17 01:39:45 INFO FileInputFormat: Total input paths to process : 1
21/02/17 01:39:45 INFO SparkContext: Starting job: first at ReadWrite.scala:615
21/02/17 01:39:45 INFO DAGScheduler: Got job 44 (first at ReadWrite.scala:615) with 1 output partitions
21/02/17 01:39:45 INFO DAGScheduler: Final stage: ResultStage 57 (first at ReadWrite.scala:615)
21/02/17 01:39:45 INFO DAGScheduler: Parents of final stage: List()
21/02/17 01:39:45 INFO DAGScheduler: Missing parents: List()
21/02/17 01:39:45 INFO DAGScheduler: Submitting ResultStage 57 (/tmp/RtmpaHGCHH/file22ad95b56a718/stages/0_r_formula__8eae6edf_b16e_4036_a8d6_baf58826f8d0/pipelineModel/stages/2_columnPruner_61c178682e95/metadata MapPartitionsRDD[185] at textFile at ReadWrite.scala:615), which has no missing parents
21/02/17 01:39:45 INFO MemoryStore: Block broadcast_72 stored as values in memory (estimated size 3.6 KB, free 909.7 MB)
21/02/17 01:39:45 INFO MemoryStore: Block broadcast_72_piece0 stored as bytes in memory (estimated size 2.2 KB, free 909.7 MB)
21/02/17 01:39:45 INFO BlockManagerInfo: Added broadcast_72_piece0 in memory on localhost:37301 (size: 2.2 KB, free: 912.0 MB)
21/02/17 01:39:45 INFO SparkContext: Created broadcast 72 from broadcast at DAGScheduler.scala:1161
21/02/17 01:39:45 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 57 (/tmp/RtmpaHGCHH/file22ad95b56a718/stages/0_r_formula__8eae6edf_b16e_4036_a8d6_baf58826f8d0/pipelineModel/stages/2_columnPruner_61c178682e95/metadata MapPartitionsRDD[185] at textFile at ReadWrite.scala:615) (first 15 tasks are for partitions Vector(0))
21/02/17 01:39:45 INFO TaskSchedulerImpl: Adding task set 57.0 with 1 tasks
21/02/17 01:39:45 INFO TaskSetManager: Starting task 0.0 in stage 57.0 (TID 59, localhost, executor driver, partition 0, PROCESS_LOCAL, 8025 bytes)
21/02/17 01:39:45 INFO Executor: Running task 0.0 in stage 57.0 (TID 59)
21/02/17 01:39:45 INFO HadoopRDD: Input split: file:/tmp/RtmpaHGCHH/file22ad95b56a718/stages/0_r_formula__8eae6edf_b16e_4036_a8d6_baf58826f8d0/pipelineModel/stages/2_columnPruner_61c178682e95/metadata/part-00000:0+171
21/02/17 01:39:45 INFO Executor: Finished task 0.0 in stage 57.0 (TID 59). 924 bytes result sent to driver
21/02/17 01:39:45 INFO TaskSetManager: Finished task 0.0 in stage 57.0 (TID 59) in 4 ms on localhost (executor driver) (1/1)
21/02/17 01:39:45 INFO TaskSchedulerImpl: Removed TaskSet 57.0, whose tasks have all completed, from pool 
21/02/17 01:39:45 INFO DAGScheduler: ResultStage 57 (first at ReadWrite.scala:615) finished in 0.007 s
21/02/17 01:39:45 INFO DAGScheduler: Job 44 finished: first at ReadWrite.scala:615, took 0.008252 s
21/02/17 01:39:45 INFO SparkContext: Starting job: parquet at RFormula.scala:509
21/02/17 01:39:45 INFO DAGScheduler: Got job 45 (parquet at RFormula.scala:509) with 1 output partitions
21/02/17 01:39:45 INFO DAGScheduler: Final stage: ResultStage 58 (parquet at RFormula.scala:509)
21/02/17 01:39:45 INFO DAGScheduler: Parents of final stage: List()
21/02/17 01:39:45 INFO DAGScheduler: Missing parents: List()
21/02/17 01:39:45 INFO DAGScheduler: Submitting ResultStage 58 (MapPartitionsRDD[187] at parquet at RFormula.scala:509), which has no missing parents
21/02/17 01:39:45 INFO MemoryStore: Block broadcast_73 stored as values in memory (estimated size 74.1 KB, free 909.6 MB)
21/02/17 01:39:45 INFO MemoryStore: Block broadcast_73_piece0 stored as bytes in memory (estimated size 26.1 KB, free 909.6 MB)
21/02/17 01:39:45 INFO BlockManagerInfo: Added broadcast_73_piece0 in memory on localhost:37301 (size: 26.1 KB, free: 912.0 MB)
21/02/17 01:39:45 INFO SparkContext: Created broadcast 73 from broadcast at DAGScheduler.scala:1161
21/02/17 01:39:45 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 58 (MapPartitionsRDD[187] at parquet at RFormula.scala:509) (first 15 tasks are for partitions Vector(0))
21/02/17 01:39:45 INFO TaskSchedulerImpl: Adding task set 58.0 with 1 tasks
21/02/17 01:39:45 INFO TaskSetManager: Starting task 0.0 in stage 58.0 (TID 60, localhost, executor driver, partition 0, PROCESS_LOCAL, 8184 bytes)
21/02/17 01:39:45 INFO Executor: Running task 0.0 in stage 58.0 (TID 60)
21/02/17 01:39:45 INFO Executor: Finished task 0.0 in stage 58.0 (TID 60). 1556 bytes result sent to driver
21/02/17 01:39:45 INFO TaskSetManager: Finished task 0.0 in stage 58.0 (TID 60) in 7 ms on localhost (executor driver) (1/1)
21/02/17 01:39:45 INFO TaskSchedulerImpl: Removed TaskSet 58.0, whose tasks have all completed, from pool 
21/02/17 01:39:45 INFO DAGScheduler: ResultStage 58 (parquet at RFormula.scala:509) finished in 0.017 s
21/02/17 01:39:45 INFO DAGScheduler: Job 45 finished: parquet at RFormula.scala:509, took 0.018650 s
21/02/17 01:39:45 INFO FileSourceStrategy: Pruning directories with: 
21/02/17 01:39:45 INFO FileSourceStrategy: Post-Scan Filters: 
21/02/17 01:39:45 INFO FileSourceStrategy: Output Data Schema: struct<columnsToPrune: array<string>>
21/02/17 01:39:45 INFO FileSourceScanExec: Pushed Filters: 
21/02/17 01:39:45 INFO CodeGenerator: Code generated in 7.986088 ms
21/02/17 01:39:45 INFO CodeGenerator: Code generated in 7.78604 ms
21/02/17 01:39:45 INFO MemoryStore: Block broadcast_74 stored as values in memory (estimated size 292.4 KB, free 909.3 MB)
21/02/17 01:39:45 INFO MemoryStore: Block broadcast_74_piece0 stored as bytes in memory (estimated size 25.1 KB, free 909.3 MB)
21/02/17 01:39:45 INFO BlockManagerInfo: Added broadcast_74_piece0 in memory on localhost:37301 (size: 25.1 KB, free: 912.0 MB)
21/02/17 01:39:45 INFO SparkContext: Created broadcast 74 from head at RFormula.scala:509
21/02/17 01:39:45 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
21/02/17 01:39:45 INFO SparkContext: Starting job: head at RFormula.scala:509
21/02/17 01:39:45 INFO DAGScheduler: Got job 46 (head at RFormula.scala:509) with 1 output partitions
21/02/17 01:39:45 INFO DAGScheduler: Final stage: ResultStage 59 (head at RFormula.scala:509)
21/02/17 01:39:45 INFO DAGScheduler: Parents of final stage: List()
21/02/17 01:39:45 INFO DAGScheduler: Missing parents: List()
21/02/17 01:39:45 INFO DAGScheduler: Submitting ResultStage 59 (MapPartitionsRDD[191] at head at RFormula.scala:509), which has no missing parents
21/02/17 01:39:45 INFO MemoryStore: Block broadcast_75 stored as values in memory (estimated size 8.9 KB, free 909.3 MB)
21/02/17 01:39:45 INFO MemoryStore: Block broadcast_75_piece0 stored as bytes in memory (estimated size 4.6 KB, free 909.3 MB)
21/02/17 01:39:45 INFO BlockManagerInfo: Added broadcast_75_piece0 in memory on localhost:37301 (size: 4.6 KB, free: 912.0 MB)
21/02/17 01:39:45 INFO SparkContext: Created broadcast 75 from broadcast at DAGScheduler.scala:1161
21/02/17 01:39:45 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 59 (MapPartitionsRDD[191] at head at RFormula.scala:509) (first 15 tasks are for partitions Vector(0))
21/02/17 01:39:45 INFO TaskSchedulerImpl: Adding task set 59.0 with 1 tasks
21/02/17 01:39:45 INFO TaskSetManager: Starting task 0.0 in stage 59.0 (TID 61, localhost, executor driver, partition 0, PROCESS_LOCAL, 8435 bytes)
21/02/17 01:39:45 INFO Executor: Running task 0.0 in stage 59.0 (TID 61)
21/02/17 01:39:45 INFO FileScanRDD: Reading File path: file:///tmp/RtmpaHGCHH/file22ad95b56a718/stages/0_r_formula__8eae6edf_b16e_4036_a8d6_baf58826f8d0/pipelineModel/stages/2_columnPruner_61c178682e95/data/part-00000-819d604e-cb2e-422e-bf09-c7027b636913-c000.snappy.parquet, range: 0-476, partition values: [empty row]
21/02/17 01:39:45 INFO ParquetReadSupport: Going to read the following fields from the Parquet file:

Parquet form:
message spark_schema {
  optional group columnsToPrune (LIST) {
    repeated group list {
      optional binary element (UTF8);
    }
  }
}

Catalyst form:
StructType(StructField(columnsToPrune,ArrayType(StringType,true),true))
       
21/02/17 01:39:45 INFO Executor: Finished task 0.0 in stage 59.0 (TID 61). 1200 bytes result sent to driver
21/02/17 01:39:45 INFO TaskSetManager: Finished task 0.0 in stage 59.0 (TID 61) in 9 ms on localhost (executor driver) (1/1)
21/02/17 01:39:45 INFO TaskSchedulerImpl: Removed TaskSet 59.0, whose tasks have all completed, from pool 
21/02/17 01:39:45 INFO DAGScheduler: ResultStage 59 (head at RFormula.scala:509) finished in 0.013 s
21/02/17 01:39:45 INFO DAGScheduler: Job 46 finished: head at RFormula.scala:509, took 0.014714 s
21/02/17 01:39:45 INFO MemoryStore: Block broadcast_76 stored as values in memory (estimated size 239.6 KB, free 909.0 MB)
21/02/17 01:39:46 INFO MemoryStore: Block broadcast_76_piece0 stored as bytes in memory (estimated size 23.2 KB, free 909.0 MB)
21/02/17 01:39:46 INFO BlockManagerInfo: Added broadcast_76_piece0 in memory on localhost:37301 (size: 23.2 KB, free: 912.0 MB)
21/02/17 01:39:46 INFO SparkContext: Created broadcast 76 from textFile at ReadWrite.scala:615
21/02/17 01:39:46 INFO FileInputFormat: Total input paths to process : 1
21/02/17 01:39:46 INFO SparkContext: Starting job: first at ReadWrite.scala:615
21/02/17 01:39:46 INFO DAGScheduler: Got job 47 (first at ReadWrite.scala:615) with 1 output partitions
21/02/17 01:39:46 INFO DAGScheduler: Final stage: ResultStage 60 (first at ReadWrite.scala:615)
21/02/17 01:39:46 INFO DAGScheduler: Parents of final stage: List()
21/02/17 01:39:46 INFO DAGScheduler: Missing parents: List()
21/02/17 01:39:46 INFO DAGScheduler: Submitting ResultStage 60 (/tmp/RtmpaHGCHH/file22ad95b56a718/stages/1_xgboost_regressor__ad18f29f_192b_48d7_935a_86a6e9bc9187/metadata MapPartitionsRDD[193] at textFile at ReadWrite.scala:615), which has no missing parents
21/02/17 01:39:46 INFO MemoryStore: Block broadcast_77 stored as values in memory (estimated size 3.5 KB, free 909.0 MB)
21/02/17 01:39:46 INFO MemoryStore: Block broadcast_77_piece0 stored as bytes in memory (estimated size 2.1 KB, free 909.0 MB)
21/02/17 01:39:46 INFO BlockManagerInfo: Added broadcast_77_piece0 in memory on localhost:37301 (size: 2.1 KB, free: 912.0 MB)
21/02/17 01:39:46 INFO SparkContext: Created broadcast 77 from broadcast at DAGScheduler.scala:1161
21/02/17 01:39:46 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 60 (/tmp/RtmpaHGCHH/file22ad95b56a718/stages/1_xgboost_regressor__ad18f29f_192b_48d7_935a_86a6e9bc9187/metadata MapPartitionsRDD[193] at textFile at ReadWrite.scala:615) (first 15 tasks are for partitions Vector(0))
21/02/17 01:39:46 INFO TaskSchedulerImpl: Adding task set 60.0 with 1 tasks
21/02/17 01:39:46 INFO TaskSetManager: Starting task 0.0 in stage 60.0 (TID 62, localhost, executor driver, partition 0, PROCESS_LOCAL, 7983 bytes)
21/02/17 01:39:46 INFO Executor: Running task 0.0 in stage 60.0 (TID 62)
21/02/17 01:39:46 INFO HadoopRDD: Input split: file:/tmp/RtmpaHGCHH/file22ad95b56a718/stages/1_xgboost_regressor__ad18f29f_192b_48d7_935a_86a6e9bc9187/metadata/part-00000:0+1245
21/02/17 01:39:46 INFO Executor: Finished task 0.0 in stage 60.0 (TID 62). 2006 bytes result sent to driver
21/02/17 01:39:46 INFO TaskSetManager: Finished task 0.0 in stage 60.0 (TID 62) in 4 ms on localhost (executor driver) (1/1)
21/02/17 01:39:46 INFO TaskSchedulerImpl: Removed TaskSet 60.0, whose tasks have all completed, from pool 
21/02/17 01:39:46 INFO DAGScheduler: ResultStage 60 (first at ReadWrite.scala:615) finished in 0.006 s
21/02/17 01:39:46 INFO DAGScheduler: Job 47 finished: first at ReadWrite.scala:615, took 0.007739 s
21/02/17 01:39:46 INFO MemoryStore: Block broadcast_78 stored as values in memory (estimated size 239.6 KB, free 908.8 MB)
21/02/17 01:39:46 INFO MemoryStore: Block broadcast_78_piece0 stored as bytes in memory (estimated size 23.2 KB, free 908.8 MB)
21/02/17 01:39:46 INFO BlockManagerInfo: Added broadcast_78_piece0 in memory on localhost:37301 (size: 23.2 KB, free: 911.9 MB)
21/02/17 01:39:46 INFO SparkContext: Created broadcast 78 from textFile at DefaultXGBoostParamsReader.scala:82
21/02/17 01:39:46 INFO FileInputFormat: Total input paths to process : 1
21/02/17 01:39:46 INFO SparkContext: Starting job: first at DefaultXGBoostParamsReader.scala:82
21/02/17 01:39:46 INFO DAGScheduler: Got job 48 (first at DefaultXGBoostParamsReader.scala:82) with 1 output partitions
21/02/17 01:39:46 INFO DAGScheduler: Final stage: ResultStage 61 (first at DefaultXGBoostParamsReader.scala:82)
21/02/17 01:39:46 INFO DAGScheduler: Parents of final stage: List()
21/02/17 01:39:46 INFO DAGScheduler: Missing parents: List()
21/02/17 01:39:46 INFO DAGScheduler: Submitting ResultStage 61 (/tmp/RtmpaHGCHH/file22ad95b56a718/stages/1_xgboost_regressor__ad18f29f_192b_48d7_935a_86a6e9bc9187/metadata MapPartitionsRDD[195] at textFile at DefaultXGBoostParamsReader.scala:82), which has no missing parents
21/02/17 01:39:46 INFO MemoryStore: Block broadcast_79 stored as values in memory (estimated size 3.5 KB, free 908.8 MB)
21/02/17 01:39:46 INFO MemoryStore: Block broadcast_79_piece0 stored as bytes in memory (estimated size 2.1 KB, free 908.8 MB)
21/02/17 01:39:46 INFO BlockManagerInfo: Added broadcast_79_piece0 in memory on localhost:37301 (size: 2.1 KB, free: 911.9 MB)
21/02/17 01:39:46 INFO SparkContext: Created broadcast 79 from broadcast at DAGScheduler.scala:1161
21/02/17 01:39:46 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 61 (/tmp/RtmpaHGCHH/file22ad95b56a718/stages/1_xgboost_regressor__ad18f29f_192b_48d7_935a_86a6e9bc9187/metadata MapPartitionsRDD[195] at textFile at DefaultXGBoostParamsReader.scala:82) (first 15 tasks are for partitions Vector(0))
21/02/17 01:39:46 INFO TaskSchedulerImpl: Adding task set 61.0 with 1 tasks
21/02/17 01:39:46 INFO TaskSetManager: Starting task 0.0 in stage 61.0 (TID 63, localhost, executor driver, partition 0, PROCESS_LOCAL, 7983 bytes)
21/02/17 01:39:46 INFO Executor: Running task 0.0 in stage 61.0 (TID 63)
21/02/17 01:39:46 INFO HadoopRDD: Input split: file:/tmp/RtmpaHGCHH/file22ad95b56a718/stages/1_xgboost_regressor__ad18f29f_192b_48d7_935a_86a6e9bc9187/metadata/part-00000:0+1245
21/02/17 01:39:46 INFO Executor: Finished task 0.0 in stage 61.0 (TID 63). 2049 bytes result sent to driver
21/02/17 01:39:46 INFO TaskSetManager: Finished task 0.0 in stage 61.0 (TID 63) in 4 ms on localhost (executor driver) (1/1)
21/02/17 01:39:46 INFO TaskSchedulerImpl: Removed TaskSet 61.0, whose tasks have all completed, from pool 
21/02/17 01:39:46 INFO DAGScheduler: ResultStage 61 (first at DefaultXGBoostParamsReader.scala:82) finished in 0.007 s
21/02/17 01:39:46 INFO DAGScheduler: Job 48 finished: first at DefaultXGBoostParamsReader.scala:82, took 0.008076 s
21/02/17 01:39:46 INFO MemoryStore: Block broadcast_80 stored as values in memory (estimated size 64.0 B, free 908.8 MB)
21/02/17 01:39:46 INFO MemoryStore: Block broadcast_80_piece0 stored as bytes in memory (estimated size 511.0 B, free 908.8 MB)
21/02/17 01:39:46 INFO BlockManagerInfo: Added broadcast_80_piece0 in memory on localhost:37301 (size: 511.0 B, free: 911.9 MB)
21/02/17 01:39:46 INFO SparkContext: Created broadcast 80 from broadcast at XGBoostRegressor.scala:271
21/02/17 01:39:46 INFO SparkContext: Starting job: collect at utils.scala:135
21/02/17 01:39:46 INFO DAGScheduler: Got job 49 (collect at utils.scala:135) with 1 output partitions
21/02/17 01:39:46 INFO DAGScheduler: Final stage: ResultStage 62 (collect at utils.scala:135)
21/02/17 01:39:46 INFO DAGScheduler: Parents of final stage: List()
21/02/17 01:39:46 INFO DAGScheduler: Missing parents: List()
21/02/17 01:39:46 INFO DAGScheduler: Submitting ResultStage 62 (MapPartitionsRDD[206] at collect at utils.scala:135), which has no missing parents
21/02/17 01:39:46 INFO MemoryStore: Block broadcast_81 stored as values in memory (estimated size 6.4 KB, free 908.7 MB)
21/02/17 01:39:46 INFO MemoryStore: Block broadcast_81_piece0 stored as bytes in memory (estimated size 3.3 KB, free 908.7 MB)
21/02/17 01:39:46 INFO BlockManagerInfo: Added broadcast_81_piece0 in memory on localhost:37301 (size: 3.3 KB, free: 911.9 MB)
21/02/17 01:39:46 INFO SparkContext: Created broadcast 81 from broadcast at DAGScheduler.scala:1161
21/02/17 01:39:46 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 62 (MapPartitionsRDD[206] at collect at utils.scala:135) (first 15 tasks are for partitions Vector(0))
21/02/17 01:39:46 INFO TaskSchedulerImpl: Adding task set 62.0 with 1 tasks
21/02/17 01:39:46 INFO TaskSetManager: Starting task 0.0 in stage 62.0 (TID 64, localhost, executor driver, partition 0, PROCESS_LOCAL, 8080 bytes)
21/02/17 01:39:46 INFO Executor: Running task 0.0 in stage 62.0 (TID 64)
21/02/17 01:39:46 INFO Executor: Finished task 0.0 in stage 62.0 (TID 64). 1243 bytes result sent to driver
21/02/17 01:39:46 INFO TaskSetManager: Finished task 0.0 in stage 62.0 (TID 64) in 3 ms on localhost (executor driver) (1/1)
21/02/17 01:39:46 INFO TaskSchedulerImpl: Removed TaskSet 62.0, whose tasks have all completed, from pool 
21/02/17 01:39:46 INFO DAGScheduler: ResultStage 62 (collect at utils.scala:135) finished in 0.006 s
21/02/17 01:39:46 INFO DAGScheduler: Job 49 finished: collect at utils.scala:135, took 0.007055 s
21/02/17 01:39:46 INFO SparkContext: Starting job: count at utils.scala:135
21/02/17 01:39:46 INFO DAGScheduler: Registering RDD 209 (count at utils.scala:135)
21/02/17 01:39:46 INFO DAGScheduler: Got job 50 (count at utils.scala:135) with 1 output partitions
21/02/17 01:39:46 INFO DAGScheduler: Final stage: ResultStage 64 (count at utils.scala:135)
21/02/17 01:39:46 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 63)
21/02/17 01:39:46 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 63)
21/02/17 01:39:46 INFO DAGScheduler: Submitting ShuffleMapStage 63 (MapPartitionsRDD[209] at count at utils.scala:135), which has no missing parents
21/02/17 01:39:46 INFO MemoryStore: Block broadcast_82 stored as values in memory (estimated size 8.4 KB, free 908.7 MB)
21/02/17 01:39:46 INFO MemoryStore: Block broadcast_82_piece0 stored as bytes in memory (estimated size 4.5 KB, free 908.7 MB)
21/02/17 01:39:46 INFO BlockManagerInfo: Added broadcast_82_piece0 in memory on localhost:37301 (size: 4.5 KB, free: 911.9 MB)
21/02/17 01:39:46 INFO SparkContext: Created broadcast 82 from broadcast at DAGScheduler.scala:1161
21/02/17 01:39:46 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 63 (MapPartitionsRDD[209] at count at utils.scala:135) (first 15 tasks are for partitions Vector(0))
21/02/17 01:39:46 INFO TaskSchedulerImpl: Adding task set 63.0 with 1 tasks
21/02/17 01:39:46 INFO TaskSetManager: Starting task 0.0 in stage 63.0 (TID 65, localhost, executor driver, partition 0, PROCESS_LOCAL, 8069 bytes)
21/02/17 01:39:46 INFO Executor: Running task 0.0 in stage 63.0 (TID 65)
21/02/17 01:39:46 INFO Executor: Finished task 0.0 in stage 63.0 (TID 65). 1499 bytes result sent to driver
21/02/17 01:39:46 INFO TaskSetManager: Finished task 0.0 in stage 63.0 (TID 65) in 3 ms on localhost (executor driver) (1/1)
21/02/17 01:39:46 INFO TaskSchedulerImpl: Removed TaskSet 63.0, whose tasks have all completed, from pool 
21/02/17 01:39:46 INFO DAGScheduler: ShuffleMapStage 63 (count at utils.scala:135) finished in 0.007 s
21/02/17 01:39:46 INFO DAGScheduler: looking for newly runnable stages
21/02/17 01:39:46 INFO DAGScheduler: running: Set()
21/02/17 01:39:46 INFO DAGScheduler: waiting: Set(ResultStage 64)
21/02/17 01:39:46 INFO DAGScheduler: failed: Set()
21/02/17 01:39:46 INFO DAGScheduler: Submitting ResultStage 64 (MapPartitionsRDD[212] at count at utils.scala:135), which has no missing parents
21/02/17 01:39:46 INFO MemoryStore: Block broadcast_83 stored as values in memory (estimated size 7.1 KB, free 908.7 MB)
21/02/17 01:39:46 INFO MemoryStore: Block broadcast_83_piece0 stored as bytes in memory (estimated size 3.8 KB, free 908.7 MB)
21/02/17 01:39:46 INFO BlockManagerInfo: Added broadcast_83_piece0 in memory on localhost:37301 (size: 3.8 KB, free: 911.9 MB)
21/02/17 01:39:46 INFO SparkContext: Created broadcast 83 from broadcast at DAGScheduler.scala:1161
21/02/17 01:39:46 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 64 (MapPartitionsRDD[212] at count at utils.scala:135) (first 15 tasks are for partitions Vector(0))
21/02/17 01:39:46 INFO TaskSchedulerImpl: Adding task set 64.0 with 1 tasks
21/02/17 01:39:46 INFO TaskSetManager: Starting task 0.0 in stage 64.0 (TID 66, localhost, executor driver, partition 0, NODE_LOCAL, 7767 bytes)
21/02/17 01:39:46 INFO Executor: Running task 0.0 in stage 64.0 (TID 66)
21/02/17 01:39:46 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks including 1 local blocks and 0 remote blocks
21/02/17 01:39:46 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
21/02/17 01:39:46 INFO Executor: Finished task 0.0 in stage 64.0 (TID 66). 1782 bytes result sent to driver
21/02/17 01:39:46 INFO TaskSetManager: Finished task 0.0 in stage 64.0 (TID 66) in 3 ms on localhost (executor driver) (1/1)
21/02/17 01:39:46 INFO TaskSchedulerImpl: Removed TaskSet 64.0, whose tasks have all completed, from pool 
21/02/17 01:39:46 INFO DAGScheduler: ResultStage 64 (count at utils.scala:135) finished in 0.005 s
21/02/17 01:39:46 INFO DAGScheduler: Job 50 finished: count at utils.scala:135, took 0.014614 s
21/02/17 01:39:46 INFO SparkContext: Starting job: collect at utils.scala:135
21/02/17 01:39:46 INFO DAGScheduler: Got job 51 (collect at utils.scala:135) with 1 output partitions
21/02/17 01:39:46 INFO DAGScheduler: Final stage: ResultStage 65 (collect at utils.scala:135)
21/02/17 01:39:46 INFO DAGScheduler: Parents of final stage: List()
21/02/17 01:39:46 INFO DAGScheduler: Missing parents: List()
21/02/17 01:39:46 INFO DAGScheduler: Submitting ResultStage 65 (MapPartitionsRDD[215] at collect at utils.scala:135), which has no missing parents
21/02/17 01:39:46 INFO MemoryStore: Block broadcast_84 stored as values in memory (estimated size 59.1 KB, free 908.7 MB)
21/02/17 01:39:46 INFO MemoryStore: Block broadcast_84_piece0 stored as bytes in memory (estimated size 25.5 KB, free 908.6 MB)
21/02/17 01:39:46 INFO BlockManagerInfo: Added broadcast_84_piece0 in memory on localhost:37301 (size: 25.5 KB, free: 911.9 MB)
21/02/17 01:39:46 INFO SparkContext: Created broadcast 84 from broadcast at DAGScheduler.scala:1161
21/02/17 01:39:46 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 65 (MapPartitionsRDD[215] at collect at utils.scala:135) (first 15 tasks are for partitions Vector(0))
21/02/17 01:39:46 INFO TaskSchedulerImpl: Adding task set 65.0 with 1 tasks
21/02/17 01:39:46 INFO TaskSetManager: Starting task 0.0 in stage 65.0 (TID 67, localhost, executor driver, partition 0, PROCESS_LOCAL, 19011 bytes)
21/02/17 01:39:46 INFO Executor: Running task 0.0 in stage 65.0 (TID 67)
21/02/17 01:39:46 INFO BlockManager: Found block rdd_26_0 locally
21/02/17 01:39:46 INFO Executor: Finished task 0.0 in stage 65.0 (TID 67). 1858 bytes result sent to driver
21/02/17 01:39:46 INFO TaskSetManager: Finished task 0.0 in stage 65.0 (TID 67) in 33 ms on localhost (executor driver) (1/1)
21/02/17 01:39:46 INFO TaskSchedulerImpl: Removed TaskSet 65.0, whose tasks have all completed, from pool 
21/02/17 01:39:46 INFO DAGScheduler: ResultStage 65 (collect at utils.scala:135) finished in 0.039 s
21/02/17 01:39:46 INFO DAGScheduler: Job 51 finished: collect at utils.scala:135, took 0.040213 s
21/02/17 01:39:46 INFO SparkContext: Starting job: count at utils.scala:135
21/02/17 01:39:46 INFO DAGScheduler: Registering RDD 218 (count at utils.scala:135)
21/02/17 01:39:46 INFO DAGScheduler: Got job 52 (count at utils.scala:135) with 1 output partitions
21/02/17 01:39:46 INFO DAGScheduler: Final stage: ResultStage 67 (count at utils.scala:135)
21/02/17 01:39:46 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 66)
21/02/17 01:39:46 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 66)
21/02/17 01:39:46 INFO DAGScheduler: Submitting ShuffleMapStage 66 (MapPartitionsRDD[218] at count at utils.scala:135), which has no missing parents
21/02/17 01:39:46 INFO MemoryStore: Block broadcast_85 stored as values in memory (estimated size 60.0 KB, free 908.6 MB)
21/02/17 01:39:46 INFO MemoryStore: Block broadcast_85_piece0 stored as bytes in memory (estimated size 26.0 KB, free 908.6 MB)
21/02/17 01:39:46 INFO BlockManagerInfo: Added broadcast_85_piece0 in memory on localhost:37301 (size: 26.0 KB, free: 911.9 MB)
21/02/17 01:39:46 INFO SparkContext: Created broadcast 85 from broadcast at DAGScheduler.scala:1161
21/02/17 01:39:46 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 66 (MapPartitionsRDD[218] at count at utils.scala:135) (first 15 tasks are for partitions Vector(0))
21/02/17 01:39:46 INFO TaskSchedulerImpl: Adding task set 66.0 with 1 tasks
21/02/17 01:39:46 INFO TaskSetManager: Starting task 0.0 in stage 66.0 (TID 68, localhost, executor driver, partition 0, PROCESS_LOCAL, 19000 bytes)
21/02/17 01:39:46 INFO Executor: Running task 0.0 in stage 66.0 (TID 68)
21/02/17 01:39:46 INFO BlockManager: Found block rdd_26_0 locally
21/02/17 01:39:46 INFO Executor: Finished task 0.0 in stage 66.0 (TID 68). 1933 bytes result sent to driver
21/02/17 01:39:46 INFO TaskSetManager: Finished task 0.0 in stage 66.0 (TID 68) in 61 ms on localhost (executor driver) (1/1)
21/02/17 01:39:46 INFO TaskSchedulerImpl: Removed TaskSet 66.0, whose tasks have all completed, from pool 
21/02/17 01:39:46 INFO DAGScheduler: ShuffleMapStage 66 (count at utils.scala:135) finished in 0.066 s
21/02/17 01:39:46 INFO DAGScheduler: looking for newly runnable stages
21/02/17 01:39:46 INFO DAGScheduler: running: Set()
21/02/17 01:39:46 INFO DAGScheduler: waiting: Set(ResultStage 67)
21/02/17 01:39:46 INFO DAGScheduler: failed: Set()
21/02/17 01:39:46 INFO DAGScheduler: Submitting ResultStage 67 (MapPartitionsRDD[221] at count at utils.scala:135), which has no missing parents
21/02/17 01:39:46 INFO MemoryStore: Block broadcast_86 stored as values in memory (estimated size 7.1 KB, free 908.5 MB)
21/02/17 01:39:46 INFO MemoryStore: Block broadcast_86_piece0 stored as bytes in memory (estimated size 3.8 KB, free 908.5 MB)
21/02/17 01:39:46 INFO BlockManagerInfo: Added broadcast_86_piece0 in memory on localhost:37301 (size: 3.8 KB, free: 911.9 MB)
21/02/17 01:39:46 INFO SparkContext: Created broadcast 86 from broadcast at DAGScheduler.scala:1161
21/02/17 01:39:46 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 67 (MapPartitionsRDD[221] at count at utils.scala:135) (first 15 tasks are for partitions Vector(0))
21/02/17 01:39:46 INFO TaskSchedulerImpl: Adding task set 67.0 with 1 tasks
21/02/17 01:39:46 INFO TaskSetManager: Starting task 0.0 in stage 67.0 (TID 69, localhost, executor driver, partition 0, NODE_LOCAL, 7767 bytes)
21/02/17 01:39:46 INFO Executor: Running task 0.0 in stage 67.0 (TID 69)
21/02/17 01:39:46 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks including 1 local blocks and 0 remote blocks
21/02/17 01:39:46 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
21/02/17 01:39:46 INFO Executor: Finished task 0.0 in stage 67.0 (TID 69). 1782 bytes result sent to driver
21/02/17 01:39:46 INFO TaskSetManager: Finished task 0.0 in stage 67.0 (TID 69) in 3 ms on localhost (executor driver) (1/1)
21/02/17 01:39:46 INFO TaskSchedulerImpl: Removed TaskSet 67.0, whose tasks have all completed, from pool 
21/02/17 01:39:46 INFO DAGScheduler: ResultStage 67 (count at utils.scala:135) finished in 0.007 s
21/02/17 01:39:46 INFO DAGScheduler: Job 52 finished: count at utils.scala:135, took 0.076416 s
21/02/17 01:39:48 INFO SparkContext: Invoking stop() from shutdown hook
21/02/17 01:39:48 INFO SparkUI: Stopped Spark web UI at http://localhost:4040
21/02/17 01:39:48 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!
21/02/17 01:39:48 INFO MemoryStore: MemoryStore cleared
21/02/17 01:39:48 INFO BlockManager: BlockManager stopped
21/02/17 01:39:48 INFO BlockManagerMaster: BlockManagerMaster stopped
21/02/17 01:39:48 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!
21/02/17 01:39:48 INFO SparkContext: Successfully stopped SparkContext
21/02/17 01:39:48 INFO ShutdownHookManager: Shutdown hook called
21/02/17 01:39:48 INFO ShutdownHookManager: Deleting directory /tmp/spark-69f6b622-6206-4816-a96f-a21c6e016b5b
21/02/17 01:39:48 INFO ShutdownHookManager: Deleting directory /tmp/spark-8bf7e157-a23d-4374-ba4f-5e728582deb6
21/02/17 01:41:27 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
21/02/17 01:41:28 INFO SparkContext: Running Spark version 2.4.4
21/02/17 01:41:28 INFO SparkContext: Submitted application: sparklyr
21/02/17 01:41:28 INFO SecurityManager: Changing view acls to: yitaoli
21/02/17 01:41:28 INFO SecurityManager: Changing modify acls to: yitaoli
21/02/17 01:41:28 INFO SecurityManager: Changing view acls groups to: 
21/02/17 01:41:28 INFO SecurityManager: Changing modify acls groups to: 
21/02/17 01:41:28 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(yitaoli); groups with view permissions: Set(); users  with modify permissions: Set(yitaoli); groups with modify permissions: Set()
21/02/17 01:41:28 INFO Utils: Successfully started service 'sparkDriver' on port 43283.
21/02/17 01:41:28 INFO SparkEnv: Registering MapOutputTracker
21/02/17 01:41:28 INFO SparkEnv: Registering BlockManagerMaster
21/02/17 01:41:28 INFO BlockManagerMasterEndpoint: Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
21/02/17 01:41:28 INFO BlockManagerMasterEndpoint: BlockManagerMasterEndpoint up
21/02/17 01:41:28 INFO DiskBlockManager: Created local directory at /tmp/blockmgr-8251124e-2217-4316-a43c-81fb9a9b16a1
21/02/17 01:41:28 INFO MemoryStore: MemoryStore started with capacity 912.3 MB
21/02/17 01:41:28 INFO SparkEnv: Registering OutputCommitCoordinator
21/02/17 01:41:28 INFO Utils: Successfully started service 'SparkUI' on port 4040.
21/02/17 01:41:28 INFO SparkUI: Bound SparkUI to 127.0.0.1, and started at http://localhost:4040
21/02/17 01:41:28 INFO SparkContext: Added JAR file:///home/yitaoli/R/x86_64-pc-linux-gnu-library/4.0/sparkxgb/java/sparkxgb-2.3-2.11.jar at spark://localhost:43283/jars/sparkxgb-2.3-2.11.jar with timestamp 1613526088485
21/02/17 01:41:28 INFO SparkContext: Added JAR file:///home/yitaoli/.ivy2/jars/ml.dmlc_xgboost4j-spark_2.11-1.1.2.jar at spark://localhost:43283/jars/ml.dmlc_xgboost4j-spark_2.11-1.1.2.jar with timestamp 1613526088486
21/02/17 01:41:28 INFO SparkContext: Added JAR file:///home/yitaoli/.ivy2/jars/org.json4s_json4s-jackson_2.11-3.2.11.jar at spark://localhost:43283/jars/org.json4s_json4s-jackson_2.11-3.2.11.jar with timestamp 1613526088486
21/02/17 01:41:28 INFO SparkContext: Added JAR file:///home/yitaoli/.ivy2/jars/ml.dmlc_xgboost4j_2.11-1.1.2.jar at spark://localhost:43283/jars/ml.dmlc_xgboost4j_2.11-1.1.2.jar with timestamp 1613526088486
21/02/17 01:41:28 INFO SparkContext: Added JAR file:///home/yitaoli/.ivy2/jars/com.esotericsoftware.kryo_kryo-2.22.jar at spark://localhost:43283/jars/com.esotericsoftware.kryo_kryo-2.22.jar with timestamp 1613526088486
21/02/17 01:41:28 INFO SparkContext: Added JAR file:///home/yitaoli/.ivy2/jars/org.scala-lang_scala-compiler-2.11.12.jar at spark://localhost:43283/jars/org.scala-lang_scala-compiler-2.11.12.jar with timestamp 1613526088486
21/02/17 01:41:28 INFO SparkContext: Added JAR file:///home/yitaoli/.ivy2/jars/org.scala-lang_scala-reflect-2.11.12.jar at spark://localhost:43283/jars/org.scala-lang_scala-reflect-2.11.12.jar with timestamp 1613526088487
21/02/17 01:41:28 INFO SparkContext: Added JAR file:///home/yitaoli/.ivy2/jars/commons-logging_commons-logging-1.2.jar at spark://localhost:43283/jars/commons-logging_commons-logging-1.2.jar with timestamp 1613526088487
21/02/17 01:41:28 INFO SparkContext: Added JAR file:///home/yitaoli/.ivy2/jars/com.typesafe.akka_akka-actor_2.11-2.5.23.jar at spark://localhost:43283/jars/com.typesafe.akka_akka-actor_2.11-2.5.23.jar with timestamp 1613526088487
21/02/17 01:41:28 INFO SparkContext: Added JAR file:///home/yitaoli/.ivy2/jars/com.typesafe_config-1.3.3.jar at spark://localhost:43283/jars/com.typesafe_config-1.3.3.jar with timestamp 1613526088487
21/02/17 01:41:28 INFO SparkContext: Added JAR file:///home/yitaoli/.ivy2/jars/org.scala-lang.modules_scala-java8-compat_2.11-0.7.0.jar at spark://localhost:43283/jars/org.scala-lang.modules_scala-java8-compat_2.11-0.7.0.jar with timestamp 1613526088487
21/02/17 01:41:28 INFO SparkContext: Added JAR file:///home/yitaoli/.ivy2/jars/org.scala-lang.modules_scala-xml_2.11-1.0.5.jar at spark://localhost:43283/jars/org.scala-lang.modules_scala-xml_2.11-1.0.5.jar with timestamp 1613526088487
21/02/17 01:41:28 INFO SparkContext: Added JAR file:///home/yitaoli/.ivy2/jars/org.scala-lang.modules_scala-parser-combinators_2.11-1.0.4.jar at spark://localhost:43283/jars/org.scala-lang.modules_scala-parser-combinators_2.11-1.0.4.jar with timestamp 1613526088487
21/02/17 01:41:28 INFO SparkContext: Added JAR file:///home/yitaoli/.ivy2/jars/org.json4s_json4s-core_2.11-3.2.11.jar at spark://localhost:43283/jars/org.json4s_json4s-core_2.11-3.2.11.jar with timestamp 1613526088487
21/02/17 01:41:28 INFO SparkContext: Added JAR file:///home/yitaoli/.ivy2/jars/com.fasterxml.jackson.core_jackson-databind-2.3.1.jar at spark://localhost:43283/jars/com.fasterxml.jackson.core_jackson-databind-2.3.1.jar with timestamp 1613526088488
21/02/17 01:41:28 INFO SparkContext: Added JAR file:///home/yitaoli/.ivy2/jars/org.json4s_json4s-ast_2.11-3.2.11.jar at spark://localhost:43283/jars/org.json4s_json4s-ast_2.11-3.2.11.jar with timestamp 1613526088488
21/02/17 01:41:28 INFO SparkContext: Added JAR file:///home/yitaoli/.ivy2/jars/com.thoughtworks.paranamer_paranamer-2.6.jar at spark://localhost:43283/jars/com.thoughtworks.paranamer_paranamer-2.6.jar with timestamp 1613526088488
21/02/17 01:41:28 INFO SparkContext: Added JAR file:///home/yitaoli/.ivy2/jars/org.scala-lang_scalap-2.11.0.jar at spark://localhost:43283/jars/org.scala-lang_scalap-2.11.0.jar with timestamp 1613526088488
21/02/17 01:41:28 INFO SparkContext: Added JAR file:///home/yitaoli/.ivy2/jars/com.fasterxml.jackson.core_jackson-annotations-2.3.0.jar at spark://localhost:43283/jars/com.fasterxml.jackson.core_jackson-annotations-2.3.0.jar with timestamp 1613526088488
21/02/17 01:41:28 INFO SparkContext: Added JAR file:///home/yitaoli/.ivy2/jars/com.fasterxml.jackson.core_jackson-core-2.3.1.jar at spark://localhost:43283/jars/com.fasterxml.jackson.core_jackson-core-2.3.1.jar with timestamp 1613526088488
21/02/17 01:41:28 INFO SparkContext: Added JAR file:/home/yitaoli/R/x86_64-pc-linux-gnu-library/4.0/sparklyr/java/sparklyr-2.4-2.11.jar at spark://localhost:43283/jars/sparklyr-2.4-2.11.jar with timestamp 1613526088488
21/02/17 01:41:28 INFO Executor: Starting executor ID driver on host localhost
21/02/17 01:41:28 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 41253.
21/02/17 01:41:28 INFO NettyBlockTransferService: Server created on localhost:41253
21/02/17 01:41:28 INFO BlockManager: Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
21/02/17 01:41:28 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, localhost, 41253, None)
21/02/17 01:41:28 INFO BlockManagerMasterEndpoint: Registering block manager localhost:41253 with 912.3 MB RAM, BlockManagerId(driver, localhost, 41253, None)
21/02/17 01:41:28 INFO BlockManagerMaster: Registered BlockManager BlockManagerId(driver, localhost, 41253, None)
21/02/17 01:41:28 INFO BlockManager: Initialized BlockManager: BlockManagerId(driver, localhost, 41253, None)
21/02/17 01:41:28 INFO SharedState: loading hive config file: file:/home/yitaoli/spark/spark-2.4.4-bin-hadoop2.7/conf/hive-site.xml
21/02/17 01:41:28 INFO SharedState: Setting hive.metastore.warehouse.dir ('null') to the value of spark.sql.warehouse.dir ('file:/home/yitaoli/sparkxgb/tests/testthat/spark-warehouse').
21/02/17 01:41:28 INFO SharedState: Warehouse path is 'file:/home/yitaoli/sparkxgb/tests/testthat/spark-warehouse'.
21/02/17 01:41:29 INFO StateStoreCoordinatorRef: Registered StateStoreCoordinator endpoint
21/02/17 01:41:30 INFO HiveUtils: Initializing HiveMetastoreConnection version 1.2.1 using Spark classes.
21/02/17 01:41:30 INFO HiveMetaStore: 0: Opening raw store with implemenation class:org.apache.hadoop.hive.metastore.ObjectStore
21/02/17 01:41:30 INFO ObjectStore: ObjectStore, initialize called
21/02/17 01:41:31 INFO Persistence: Property hive.metastore.integral.jdo.pushdown unknown - will be ignored
21/02/17 01:41:31 INFO Persistence: Property datanucleus.cache.level2 unknown - will be ignored
21/02/17 01:41:32 INFO ObjectStore: Setting MetaStore object pin classes with hive.metastore.cache.pinobjtypes="Table,StorageDescriptor,SerDeInfo,Partition,Database,Type,FieldSchema,Order"
21/02/17 01:41:32 INFO Datastore: The class "org.apache.hadoop.hive.metastore.model.MFieldSchema" is tagged as "embedded-only" so does not have its own datastore table.
21/02/17 01:41:32 INFO Datastore: The class "org.apache.hadoop.hive.metastore.model.MOrder" is tagged as "embedded-only" so does not have its own datastore table.
21/02/17 01:41:33 INFO Datastore: The class "org.apache.hadoop.hive.metastore.model.MFieldSchema" is tagged as "embedded-only" so does not have its own datastore table.
21/02/17 01:41:33 INFO Datastore: The class "org.apache.hadoop.hive.metastore.model.MOrder" is tagged as "embedded-only" so does not have its own datastore table.
21/02/17 01:41:33 INFO MetaStoreDirectSql: Using direct SQL, underlying DB is DERBY
21/02/17 01:41:33 INFO ObjectStore: Initialized ObjectStore
21/02/17 01:41:33 WARN ObjectStore: Version information not found in metastore. hive.metastore.schema.verification is not enabled so recording the schema version 1.2.0
21/02/17 01:41:33 WARN ObjectStore: Failed to get database default, returning NoSuchObjectException
21/02/17 01:41:33 INFO HiveMetaStore: Added admin role in metastore
21/02/17 01:41:33 INFO HiveMetaStore: Added public role in metastore
21/02/17 01:41:33 INFO HiveMetaStore: No user is added in admin role, since config is empty
21/02/17 01:41:33 INFO HiveMetaStore: 0: get_all_databases
21/02/17 01:41:33 INFO audit: ugi=yitaoli	ip=unknown-ip-addr	cmd=get_all_databases	
21/02/17 01:41:33 INFO HiveMetaStore: 0: get_functions: db=default pat=*
21/02/17 01:41:33 INFO audit: ugi=yitaoli	ip=unknown-ip-addr	cmd=get_functions: db=default pat=*	
21/02/17 01:41:33 INFO Datastore: The class "org.apache.hadoop.hive.metastore.model.MResourceUri" is tagged as "embedded-only" so does not have its own datastore table.
21/02/17 01:41:33 INFO SessionState: Created local directory: /tmp/404fd7b3-9397-432b-9e1b-d9565382ee89_resources
21/02/17 01:41:33 INFO SessionState: Created HDFS directory: /tmp/hive/yitaoli/404fd7b3-9397-432b-9e1b-d9565382ee89
21/02/17 01:41:33 INFO SessionState: Created local directory: /tmp/yitaoli/404fd7b3-9397-432b-9e1b-d9565382ee89
21/02/17 01:41:33 INFO SessionState: Created HDFS directory: /tmp/hive/yitaoli/404fd7b3-9397-432b-9e1b-d9565382ee89/_tmp_space.db
21/02/17 01:41:33 INFO HiveClientImpl: Warehouse location for Hive client (version 1.2.2) is file:/home/yitaoli/sparkxgb/tests/testthat/spark-warehouse
21/02/17 01:41:33 INFO HiveMetaStore: 0: get_database: default
21/02/17 01:41:33 INFO audit: ugi=yitaoli	ip=unknown-ip-addr	cmd=get_database: default	
21/02/17 01:41:33 INFO HiveMetaStore: 0: get_database: global_temp
21/02/17 01:41:33 INFO audit: ugi=yitaoli	ip=unknown-ip-addr	cmd=get_database: global_temp	
21/02/17 01:41:33 WARN ObjectStore: Failed to get database global_temp, returning NoSuchObjectException
21/02/17 01:41:33 INFO HiveMetaStore: 0: get_table : db=default tbl=iris
21/02/17 01:41:33 INFO audit: ugi=yitaoli	ip=unknown-ip-addr	cmd=get_table : db=default tbl=iris	
21/02/17 01:41:33 INFO HiveMetaStore: 0: get_database: default
21/02/17 01:41:33 INFO audit: ugi=yitaoli	ip=unknown-ip-addr	cmd=get_database: default	
21/02/17 01:41:33 INFO HiveMetaStore: 0: get_database: default
21/02/17 01:41:33 INFO audit: ugi=yitaoli	ip=unknown-ip-addr	cmd=get_database: default	
21/02/17 01:41:33 INFO HiveMetaStore: 0: get_tables: db=default pat=*
21/02/17 01:41:33 INFO audit: ugi=yitaoli	ip=unknown-ip-addr	cmd=get_tables: db=default pat=*	
21/02/17 01:41:34 INFO SparkContext: Starting job: collect at utils.scala:61
21/02/17 01:41:34 INFO DAGScheduler: Got job 0 (collect at utils.scala:61) with 1 output partitions
21/02/17 01:41:34 INFO DAGScheduler: Final stage: ResultStage 0 (collect at utils.scala:61)
21/02/17 01:41:34 INFO DAGScheduler: Parents of final stage: List()
21/02/17 01:41:34 INFO DAGScheduler: Missing parents: List()
21/02/17 01:41:34 INFO DAGScheduler: Submitting ResultStage 0 (MapPartitionsRDD[4] at map at utils.scala:54), which has no missing parents
21/02/17 01:41:34 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 6.0 KB, free 912.3 MB)
21/02/17 01:41:34 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 3.4 KB, free 912.3 MB)
21/02/17 01:41:34 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on localhost:41253 (size: 3.4 KB, free: 912.3 MB)
21/02/17 01:41:34 INFO SparkContext: Created broadcast 0 from broadcast at DAGScheduler.scala:1161
21/02/17 01:41:34 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 0 (MapPartitionsRDD[4] at map at utils.scala:54) (first 15 tasks are for partitions Vector(0))
21/02/17 01:41:34 INFO TaskSchedulerImpl: Adding task set 0.0 with 1 tasks
21/02/17 01:41:34 INFO TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0, localhost, executor driver, partition 0, PROCESS_LOCAL, 7893 bytes)
21/02/17 01:41:34 INFO Executor: Running task 0.0 in stage 0.0 (TID 0)
21/02/17 01:41:34 INFO Executor: Fetching spark://localhost:43283/jars/org.scala-lang.modules_scala-java8-compat_2.11-0.7.0.jar with timestamp 1613526088487
21/02/17 01:41:34 INFO TransportClientFactory: Successfully created connection to localhost/127.0.0.1:43283 after 13 ms (0 ms spent in bootstraps)
21/02/17 01:41:34 INFO Utils: Fetching spark://localhost:43283/jars/org.scala-lang.modules_scala-java8-compat_2.11-0.7.0.jar to /tmp/spark-2a224719-1a63-41af-b9d1-6c3c5850d7b1/userFiles-1a4bed90-ba4a-4212-b325-d669e082a8fa/fetchFileTemp5314221555813802063.tmp
21/02/17 01:41:34 INFO Executor: Adding file:/tmp/spark-2a224719-1a63-41af-b9d1-6c3c5850d7b1/userFiles-1a4bed90-ba4a-4212-b325-d669e082a8fa/org.scala-lang.modules_scala-java8-compat_2.11-0.7.0.jar to class loader
21/02/17 01:41:34 INFO Executor: Fetching spark://localhost:43283/jars/com.fasterxml.jackson.core_jackson-annotations-2.3.0.jar with timestamp 1613526088488
21/02/17 01:41:34 INFO Utils: Fetching spark://localhost:43283/jars/com.fasterxml.jackson.core_jackson-annotations-2.3.0.jar to /tmp/spark-2a224719-1a63-41af-b9d1-6c3c5850d7b1/userFiles-1a4bed90-ba4a-4212-b325-d669e082a8fa/fetchFileTemp556796120035902756.tmp
21/02/17 01:41:34 INFO Executor: Adding file:/tmp/spark-2a224719-1a63-41af-b9d1-6c3c5850d7b1/userFiles-1a4bed90-ba4a-4212-b325-d669e082a8fa/com.fasterxml.jackson.core_jackson-annotations-2.3.0.jar to class loader
21/02/17 01:41:34 INFO Executor: Fetching spark://localhost:43283/jars/commons-logging_commons-logging-1.2.jar with timestamp 1613526088487
21/02/17 01:41:34 INFO Utils: Fetching spark://localhost:43283/jars/commons-logging_commons-logging-1.2.jar to /tmp/spark-2a224719-1a63-41af-b9d1-6c3c5850d7b1/userFiles-1a4bed90-ba4a-4212-b325-d669e082a8fa/fetchFileTemp3751825769563364880.tmp
21/02/17 01:41:34 INFO Executor: Adding file:/tmp/spark-2a224719-1a63-41af-b9d1-6c3c5850d7b1/userFiles-1a4bed90-ba4a-4212-b325-d669e082a8fa/commons-logging_commons-logging-1.2.jar to class loader
21/02/17 01:41:34 INFO Executor: Fetching spark://localhost:43283/jars/org.scala-lang_scala-reflect-2.11.12.jar with timestamp 1613526088487
21/02/17 01:41:34 INFO Utils: Fetching spark://localhost:43283/jars/org.scala-lang_scala-reflect-2.11.12.jar to /tmp/spark-2a224719-1a63-41af-b9d1-6c3c5850d7b1/userFiles-1a4bed90-ba4a-4212-b325-d669e082a8fa/fetchFileTemp9197198092674119983.tmp
21/02/17 01:41:34 INFO Executor: Adding file:/tmp/spark-2a224719-1a63-41af-b9d1-6c3c5850d7b1/userFiles-1a4bed90-ba4a-4212-b325-d669e082a8fa/org.scala-lang_scala-reflect-2.11.12.jar to class loader
21/02/17 01:41:34 INFO Executor: Fetching spark://localhost:43283/jars/ml.dmlc_xgboost4j-spark_2.11-1.1.2.jar with timestamp 1613526088486
21/02/17 01:41:34 INFO Utils: Fetching spark://localhost:43283/jars/ml.dmlc_xgboost4j-spark_2.11-1.1.2.jar to /tmp/spark-2a224719-1a63-41af-b9d1-6c3c5850d7b1/userFiles-1a4bed90-ba4a-4212-b325-d669e082a8fa/fetchFileTemp7019646516732464204.tmp
21/02/17 01:41:34 INFO Executor: Adding file:/tmp/spark-2a224719-1a63-41af-b9d1-6c3c5850d7b1/userFiles-1a4bed90-ba4a-4212-b325-d669e082a8fa/ml.dmlc_xgboost4j-spark_2.11-1.1.2.jar to class loader
21/02/17 01:41:34 INFO Executor: Fetching spark://localhost:43283/jars/org.scala-lang.modules_scala-xml_2.11-1.0.5.jar with timestamp 1613526088487
21/02/17 01:41:34 INFO Utils: Fetching spark://localhost:43283/jars/org.scala-lang.modules_scala-xml_2.11-1.0.5.jar to /tmp/spark-2a224719-1a63-41af-b9d1-6c3c5850d7b1/userFiles-1a4bed90-ba4a-4212-b325-d669e082a8fa/fetchFileTemp6963178294499545757.tmp
21/02/17 01:41:34 INFO Executor: Adding file:/tmp/spark-2a224719-1a63-41af-b9d1-6c3c5850d7b1/userFiles-1a4bed90-ba4a-4212-b325-d669e082a8fa/org.scala-lang.modules_scala-xml_2.11-1.0.5.jar to class loader
21/02/17 01:41:34 INFO Executor: Fetching spark://localhost:43283/jars/org.json4s_json4s-jackson_2.11-3.2.11.jar with timestamp 1613526088486
21/02/17 01:41:34 INFO Utils: Fetching spark://localhost:43283/jars/org.json4s_json4s-jackson_2.11-3.2.11.jar to /tmp/spark-2a224719-1a63-41af-b9d1-6c3c5850d7b1/userFiles-1a4bed90-ba4a-4212-b325-d669e082a8fa/fetchFileTemp3905447048353235681.tmp
21/02/17 01:41:34 INFO Executor: Adding file:/tmp/spark-2a224719-1a63-41af-b9d1-6c3c5850d7b1/userFiles-1a4bed90-ba4a-4212-b325-d669e082a8fa/org.json4s_json4s-jackson_2.11-3.2.11.jar to class loader
21/02/17 01:41:34 INFO Executor: Fetching spark://localhost:43283/jars/org.scala-lang_scalap-2.11.0.jar with timestamp 1613526088488
21/02/17 01:41:34 INFO Utils: Fetching spark://localhost:43283/jars/org.scala-lang_scalap-2.11.0.jar to /tmp/spark-2a224719-1a63-41af-b9d1-6c3c5850d7b1/userFiles-1a4bed90-ba4a-4212-b325-d669e082a8fa/fetchFileTemp2891544075476868487.tmp
21/02/17 01:41:34 INFO Executor: Adding file:/tmp/spark-2a224719-1a63-41af-b9d1-6c3c5850d7b1/userFiles-1a4bed90-ba4a-4212-b325-d669e082a8fa/org.scala-lang_scalap-2.11.0.jar to class loader
21/02/17 01:41:34 INFO Executor: Fetching spark://localhost:43283/jars/sparkxgb-2.3-2.11.jar with timestamp 1613526088485
21/02/17 01:41:34 INFO Utils: Fetching spark://localhost:43283/jars/sparkxgb-2.3-2.11.jar to /tmp/spark-2a224719-1a63-41af-b9d1-6c3c5850d7b1/userFiles-1a4bed90-ba4a-4212-b325-d669e082a8fa/fetchFileTemp8714666889160721363.tmp
21/02/17 01:41:34 INFO Executor: Adding file:/tmp/spark-2a224719-1a63-41af-b9d1-6c3c5850d7b1/userFiles-1a4bed90-ba4a-4212-b325-d669e082a8fa/sparkxgb-2.3-2.11.jar to class loader
21/02/17 01:41:34 INFO Executor: Fetching spark://localhost:43283/jars/org.json4s_json4s-ast_2.11-3.2.11.jar with timestamp 1613526088488
21/02/17 01:41:34 INFO Utils: Fetching spark://localhost:43283/jars/org.json4s_json4s-ast_2.11-3.2.11.jar to /tmp/spark-2a224719-1a63-41af-b9d1-6c3c5850d7b1/userFiles-1a4bed90-ba4a-4212-b325-d669e082a8fa/fetchFileTemp6564091184166586495.tmp
21/02/17 01:41:34 INFO Executor: Adding file:/tmp/spark-2a224719-1a63-41af-b9d1-6c3c5850d7b1/userFiles-1a4bed90-ba4a-4212-b325-d669e082a8fa/org.json4s_json4s-ast_2.11-3.2.11.jar to class loader
21/02/17 01:41:34 INFO Executor: Fetching spark://localhost:43283/jars/com.fasterxml.jackson.core_jackson-core-2.3.1.jar with timestamp 1613526088488
21/02/17 01:41:34 INFO Utils: Fetching spark://localhost:43283/jars/com.fasterxml.jackson.core_jackson-core-2.3.1.jar to /tmp/spark-2a224719-1a63-41af-b9d1-6c3c5850d7b1/userFiles-1a4bed90-ba4a-4212-b325-d669e082a8fa/fetchFileTemp3561313653264440393.tmp
21/02/17 01:41:34 INFO Executor: Adding file:/tmp/spark-2a224719-1a63-41af-b9d1-6c3c5850d7b1/userFiles-1a4bed90-ba4a-4212-b325-d669e082a8fa/com.fasterxml.jackson.core_jackson-core-2.3.1.jar to class loader
21/02/17 01:41:34 INFO Executor: Fetching spark://localhost:43283/jars/org.scala-lang.modules_scala-parser-combinators_2.11-1.0.4.jar with timestamp 1613526088487
21/02/17 01:41:34 INFO Utils: Fetching spark://localhost:43283/jars/org.scala-lang.modules_scala-parser-combinators_2.11-1.0.4.jar to /tmp/spark-2a224719-1a63-41af-b9d1-6c3c5850d7b1/userFiles-1a4bed90-ba4a-4212-b325-d669e082a8fa/fetchFileTemp7514345088097836660.tmp
21/02/17 01:41:34 INFO Executor: Adding file:/tmp/spark-2a224719-1a63-41af-b9d1-6c3c5850d7b1/userFiles-1a4bed90-ba4a-4212-b325-d669e082a8fa/org.scala-lang.modules_scala-parser-combinators_2.11-1.0.4.jar to class loader
21/02/17 01:41:34 INFO Executor: Fetching spark://localhost:43283/jars/org.scala-lang_scala-compiler-2.11.12.jar with timestamp 1613526088486
21/02/17 01:41:34 INFO Utils: Fetching spark://localhost:43283/jars/org.scala-lang_scala-compiler-2.11.12.jar to /tmp/spark-2a224719-1a63-41af-b9d1-6c3c5850d7b1/userFiles-1a4bed90-ba4a-4212-b325-d669e082a8fa/fetchFileTemp8179489390882908517.tmp
21/02/17 01:41:34 INFO Executor: Adding file:/tmp/spark-2a224719-1a63-41af-b9d1-6c3c5850d7b1/userFiles-1a4bed90-ba4a-4212-b325-d669e082a8fa/org.scala-lang_scala-compiler-2.11.12.jar to class loader
21/02/17 01:41:34 INFO Executor: Fetching spark://localhost:43283/jars/org.json4s_json4s-core_2.11-3.2.11.jar with timestamp 1613526088487
21/02/17 01:41:34 INFO Utils: Fetching spark://localhost:43283/jars/org.json4s_json4s-core_2.11-3.2.11.jar to /tmp/spark-2a224719-1a63-41af-b9d1-6c3c5850d7b1/userFiles-1a4bed90-ba4a-4212-b325-d669e082a8fa/fetchFileTemp2484963417340743759.tmp
21/02/17 01:41:34 INFO Executor: Adding file:/tmp/spark-2a224719-1a63-41af-b9d1-6c3c5850d7b1/userFiles-1a4bed90-ba4a-4212-b325-d669e082a8fa/org.json4s_json4s-core_2.11-3.2.11.jar to class loader
21/02/17 01:41:34 INFO Executor: Fetching spark://localhost:43283/jars/sparklyr-2.4-2.11.jar with timestamp 1613526088488
21/02/17 01:41:34 INFO Utils: Fetching spark://localhost:43283/jars/sparklyr-2.4-2.11.jar to /tmp/spark-2a224719-1a63-41af-b9d1-6c3c5850d7b1/userFiles-1a4bed90-ba4a-4212-b325-d669e082a8fa/fetchFileTemp2669464263329418371.tmp
21/02/17 01:41:34 INFO Executor: Adding file:/tmp/spark-2a224719-1a63-41af-b9d1-6c3c5850d7b1/userFiles-1a4bed90-ba4a-4212-b325-d669e082a8fa/sparklyr-2.4-2.11.jar to class loader
21/02/17 01:41:34 INFO Executor: Fetching spark://localhost:43283/jars/com.fasterxml.jackson.core_jackson-databind-2.3.1.jar with timestamp 1613526088488
21/02/17 01:41:34 INFO Utils: Fetching spark://localhost:43283/jars/com.fasterxml.jackson.core_jackson-databind-2.3.1.jar to /tmp/spark-2a224719-1a63-41af-b9d1-6c3c5850d7b1/userFiles-1a4bed90-ba4a-4212-b325-d669e082a8fa/fetchFileTemp8753093772180228769.tmp
21/02/17 01:41:34 INFO Executor: Adding file:/tmp/spark-2a224719-1a63-41af-b9d1-6c3c5850d7b1/userFiles-1a4bed90-ba4a-4212-b325-d669e082a8fa/com.fasterxml.jackson.core_jackson-databind-2.3.1.jar to class loader
21/02/17 01:41:34 INFO Executor: Fetching spark://localhost:43283/jars/com.esotericsoftware.kryo_kryo-2.22.jar with timestamp 1613526088486
21/02/17 01:41:34 INFO Utils: Fetching spark://localhost:43283/jars/com.esotericsoftware.kryo_kryo-2.22.jar to /tmp/spark-2a224719-1a63-41af-b9d1-6c3c5850d7b1/userFiles-1a4bed90-ba4a-4212-b325-d669e082a8fa/fetchFileTemp2715720214039257808.tmp
21/02/17 01:41:34 INFO Executor: Adding file:/tmp/spark-2a224719-1a63-41af-b9d1-6c3c5850d7b1/userFiles-1a4bed90-ba4a-4212-b325-d669e082a8fa/com.esotericsoftware.kryo_kryo-2.22.jar to class loader
21/02/17 01:41:34 INFO Executor: Fetching spark://localhost:43283/jars/com.typesafe.akka_akka-actor_2.11-2.5.23.jar with timestamp 1613526088487
21/02/17 01:41:34 INFO Utils: Fetching spark://localhost:43283/jars/com.typesafe.akka_akka-actor_2.11-2.5.23.jar to /tmp/spark-2a224719-1a63-41af-b9d1-6c3c5850d7b1/userFiles-1a4bed90-ba4a-4212-b325-d669e082a8fa/fetchFileTemp5937649332908472898.tmp
21/02/17 01:41:34 INFO Executor: Adding file:/tmp/spark-2a224719-1a63-41af-b9d1-6c3c5850d7b1/userFiles-1a4bed90-ba4a-4212-b325-d669e082a8fa/com.typesafe.akka_akka-actor_2.11-2.5.23.jar to class loader
21/02/17 01:41:34 INFO Executor: Fetching spark://localhost:43283/jars/com.thoughtworks.paranamer_paranamer-2.6.jar with timestamp 1613526088488
21/02/17 01:41:34 INFO Utils: Fetching spark://localhost:43283/jars/com.thoughtworks.paranamer_paranamer-2.6.jar to /tmp/spark-2a224719-1a63-41af-b9d1-6c3c5850d7b1/userFiles-1a4bed90-ba4a-4212-b325-d669e082a8fa/fetchFileTemp2820390459259770012.tmp
21/02/17 01:41:34 INFO Executor: Adding file:/tmp/spark-2a224719-1a63-41af-b9d1-6c3c5850d7b1/userFiles-1a4bed90-ba4a-4212-b325-d669e082a8fa/com.thoughtworks.paranamer_paranamer-2.6.jar to class loader
21/02/17 01:41:34 INFO Executor: Fetching spark://localhost:43283/jars/ml.dmlc_xgboost4j_2.11-1.1.2.jar with timestamp 1613526088486
21/02/17 01:41:34 INFO Utils: Fetching spark://localhost:43283/jars/ml.dmlc_xgboost4j_2.11-1.1.2.jar to /tmp/spark-2a224719-1a63-41af-b9d1-6c3c5850d7b1/userFiles-1a4bed90-ba4a-4212-b325-d669e082a8fa/fetchFileTemp9147508238322652508.tmp
21/02/17 01:41:34 INFO Executor: Adding file:/tmp/spark-2a224719-1a63-41af-b9d1-6c3c5850d7b1/userFiles-1a4bed90-ba4a-4212-b325-d669e082a8fa/ml.dmlc_xgboost4j_2.11-1.1.2.jar to class loader
21/02/17 01:41:34 INFO Executor: Fetching spark://localhost:43283/jars/com.typesafe_config-1.3.3.jar with timestamp 1613526088487
21/02/17 01:41:34 INFO Utils: Fetching spark://localhost:43283/jars/com.typesafe_config-1.3.3.jar to /tmp/spark-2a224719-1a63-41af-b9d1-6c3c5850d7b1/userFiles-1a4bed90-ba4a-4212-b325-d669e082a8fa/fetchFileTemp3786095358867779630.tmp
21/02/17 01:41:34 INFO Executor: Adding file:/tmp/spark-2a224719-1a63-41af-b9d1-6c3c5850d7b1/userFiles-1a4bed90-ba4a-4212-b325-d669e082a8fa/com.typesafe_config-1.3.3.jar to class loader
21/02/17 01:41:35 INFO CodeGenerator: Code generated in 134.680265 ms
21/02/17 01:41:35 INFO Executor: Finished task 0.0 in stage 0.0 (TID 0). 1013 bytes result sent to driver
21/02/17 01:41:35 INFO TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in 576 ms on localhost (executor driver) (1/1)
21/02/17 01:41:35 INFO TaskSchedulerImpl: Removed TaskSet 0.0, whose tasks have all completed, from pool 
21/02/17 01:41:35 INFO DAGScheduler: ResultStage 0 (collect at utils.scala:61) finished in 0.701 s
21/02/17 01:41:35 INFO DAGScheduler: Job 0 finished: collect at utils.scala:61, took 0.739961 s
21/02/17 01:41:35 INFO CodeGenerator: Code generated in 9.700556 ms
21/02/17 01:41:35 INFO CodeGenerator: Code generated in 12.656107 ms
21/02/17 01:41:35 INFO SparkContext: Starting job: collect at utils.scala:135
21/02/17 01:41:35 INFO DAGScheduler: Got job 1 (collect at utils.scala:135) with 1 output partitions
21/02/17 01:41:35 INFO DAGScheduler: Final stage: ResultStage 1 (collect at utils.scala:135)
21/02/17 01:41:35 INFO DAGScheduler: Parents of final stage: List()
21/02/17 01:41:35 INFO DAGScheduler: Missing parents: List()
21/02/17 01:41:35 INFO DAGScheduler: Submitting ResultStage 1 (MapPartitionsRDD[9] at collect at utils.scala:135), which has no missing parents
21/02/17 01:41:35 INFO MemoryStore: Block broadcast_1 stored as values in memory (estimated size 6.2 KB, free 912.3 MB)
21/02/17 01:41:35 INFO MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 3.3 KB, free 912.3 MB)
21/02/17 01:41:35 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on localhost:41253 (size: 3.3 KB, free: 912.3 MB)
21/02/17 01:41:35 INFO SparkContext: Created broadcast 1 from broadcast at DAGScheduler.scala:1161
21/02/17 01:41:35 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 1 (MapPartitionsRDD[9] at collect at utils.scala:135) (first 15 tasks are for partitions Vector(0))
21/02/17 01:41:35 INFO TaskSchedulerImpl: Adding task set 1.0 with 1 tasks
21/02/17 01:41:35 INFO TaskSetManager: Starting task 0.0 in stage 1.0 (TID 1, localhost, executor driver, partition 0, PROCESS_LOCAL, 8080 bytes)
21/02/17 01:41:35 INFO Executor: Running task 0.0 in stage 1.0 (TID 1)
21/02/17 01:41:35 INFO CodeGenerator: Code generated in 8.537403 ms
21/02/17 01:41:35 INFO Executor: Finished task 0.0 in stage 1.0 (TID 1). 1329 bytes result sent to driver
21/02/17 01:41:35 INFO TaskSetManager: Finished task 0.0 in stage 1.0 (TID 1) in 30 ms on localhost (executor driver) (1/1)
21/02/17 01:41:35 INFO TaskSchedulerImpl: Removed TaskSet 1.0, whose tasks have all completed, from pool 
21/02/17 01:41:35 INFO DAGScheduler: ResultStage 1 (collect at utils.scala:135) finished in 0.038 s
21/02/17 01:41:35 INFO DAGScheduler: Job 1 finished: collect at utils.scala:135, took 0.041564 s
21/02/17 01:41:35 INFO CodeGenerator: Code generated in 15.05522 ms
21/02/17 01:41:35 INFO CodeGenerator: Code generated in 12.520108 ms
21/02/17 01:41:35 INFO SparkContext: Starting job: count at utils.scala:135
21/02/17 01:41:35 INFO DAGScheduler: Registering RDD 12 (count at utils.scala:135)
21/02/17 01:41:35 INFO DAGScheduler: Got job 2 (count at utils.scala:135) with 1 output partitions
21/02/17 01:41:35 INFO DAGScheduler: Final stage: ResultStage 3 (count at utils.scala:135)
21/02/17 01:41:35 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 2)
21/02/17 01:41:35 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 2)
21/02/17 01:41:35 INFO DAGScheduler: Submitting ShuffleMapStage 2 (MapPartitionsRDD[12] at count at utils.scala:135), which has no missing parents
21/02/17 01:41:35 INFO MemoryStore: Block broadcast_2 stored as values in memory (estimated size 8.4 KB, free 912.3 MB)
21/02/17 01:41:35 INFO MemoryStore: Block broadcast_2_piece0 stored as bytes in memory (estimated size 4.5 KB, free 912.3 MB)
21/02/17 01:41:35 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on localhost:41253 (size: 4.5 KB, free: 912.3 MB)
21/02/17 01:41:35 INFO SparkContext: Created broadcast 2 from broadcast at DAGScheduler.scala:1161
21/02/17 01:41:35 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 2 (MapPartitionsRDD[12] at count at utils.scala:135) (first 15 tasks are for partitions Vector(0))
21/02/17 01:41:35 INFO TaskSchedulerImpl: Adding task set 2.0 with 1 tasks
21/02/17 01:41:35 INFO TaskSetManager: Starting task 0.0 in stage 2.0 (TID 2, localhost, executor driver, partition 0, PROCESS_LOCAL, 8069 bytes)
21/02/17 01:41:35 INFO Executor: Running task 0.0 in stage 2.0 (TID 2)
21/02/17 01:41:35 INFO Executor: Finished task 0.0 in stage 2.0 (TID 2). 1542 bytes result sent to driver
21/02/17 01:41:35 INFO TaskSetManager: Finished task 0.0 in stage 2.0 (TID 2) in 34 ms on localhost (executor driver) (1/1)
21/02/17 01:41:35 INFO TaskSchedulerImpl: Removed TaskSet 2.0, whose tasks have all completed, from pool 
21/02/17 01:41:35 INFO DAGScheduler: ShuffleMapStage 2 (count at utils.scala:135) finished in 0.045 s
21/02/17 01:41:35 INFO DAGScheduler: looking for newly runnable stages
21/02/17 01:41:35 INFO DAGScheduler: running: Set()
21/02/17 01:41:35 INFO DAGScheduler: waiting: Set(ResultStage 3)
21/02/17 01:41:35 INFO DAGScheduler: failed: Set()
21/02/17 01:41:35 INFO DAGScheduler: Submitting ResultStage 3 (MapPartitionsRDD[15] at count at utils.scala:135), which has no missing parents
21/02/17 01:41:35 INFO MemoryStore: Block broadcast_3 stored as values in memory (estimated size 7.1 KB, free 912.3 MB)
21/02/17 01:41:35 INFO MemoryStore: Block broadcast_3_piece0 stored as bytes in memory (estimated size 3.8 KB, free 912.3 MB)
21/02/17 01:41:35 INFO BlockManagerInfo: Added broadcast_3_piece0 in memory on localhost:41253 (size: 3.8 KB, free: 912.3 MB)
21/02/17 01:41:35 INFO SparkContext: Created broadcast 3 from broadcast at DAGScheduler.scala:1161
21/02/17 01:41:35 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 3 (MapPartitionsRDD[15] at count at utils.scala:135) (first 15 tasks are for partitions Vector(0))
21/02/17 01:41:35 INFO TaskSchedulerImpl: Adding task set 3.0 with 1 tasks
21/02/17 01:41:35 INFO TaskSetManager: Starting task 0.0 in stage 3.0 (TID 3, localhost, executor driver, partition 0, NODE_LOCAL, 7767 bytes)
21/02/17 01:41:35 INFO Executor: Running task 0.0 in stage 3.0 (TID 3)
21/02/17 01:41:35 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks including 1 local blocks and 0 remote blocks
21/02/17 01:41:35 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 5 ms
21/02/17 01:41:35 INFO Executor: Finished task 0.0 in stage 3.0 (TID 3). 1782 bytes result sent to driver
21/02/17 01:41:35 INFO TaskSetManager: Finished task 0.0 in stage 3.0 (TID 3) in 36 ms on localhost (executor driver) (1/1)
21/02/17 01:41:35 INFO TaskSchedulerImpl: Removed TaskSet 3.0, whose tasks have all completed, from pool 
21/02/17 01:41:35 INFO DAGScheduler: ResultStage 3 (count at utils.scala:135) finished in 0.043 s
21/02/17 01:41:35 INFO DAGScheduler: Job 2 finished: count at utils.scala:135, took 0.107974 s
21/02/17 01:41:36 INFO SparkContext: Starting job: collect at utils.scala:135
21/02/17 01:41:36 INFO DAGScheduler: Got job 3 (collect at utils.scala:135) with 1 output partitions
21/02/17 01:41:36 INFO DAGScheduler: Final stage: ResultStage 4 (collect at utils.scala:135)
21/02/17 01:41:36 INFO DAGScheduler: Parents of final stage: List()
21/02/17 01:41:36 INFO DAGScheduler: Missing parents: List()
21/02/17 01:41:36 INFO DAGScheduler: Submitting ResultStage 4 (MapPartitionsRDD[18] at collect at utils.scala:135), which has no missing parents
21/02/17 01:41:36 INFO MemoryStore: Block broadcast_4 stored as values in memory (estimated size 6.2 KB, free 912.3 MB)
21/02/17 01:41:36 INFO MemoryStore: Block broadcast_4_piece0 stored as bytes in memory (estimated size 3.3 KB, free 912.2 MB)
21/02/17 01:41:36 INFO BlockManagerInfo: Added broadcast_4_piece0 in memory on localhost:41253 (size: 3.3 KB, free: 912.3 MB)
21/02/17 01:41:36 INFO SparkContext: Created broadcast 4 from broadcast at DAGScheduler.scala:1161
21/02/17 01:41:36 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 4 (MapPartitionsRDD[18] at collect at utils.scala:135) (first 15 tasks are for partitions Vector(0))
21/02/17 01:41:36 INFO TaskSchedulerImpl: Adding task set 4.0 with 1 tasks
21/02/17 01:41:36 INFO TaskSetManager: Starting task 0.0 in stage 4.0 (TID 4, localhost, executor driver, partition 0, PROCESS_LOCAL, 8080 bytes)
21/02/17 01:41:36 INFO Executor: Running task 0.0 in stage 4.0 (TID 4)
21/02/17 01:41:36 INFO Executor: Finished task 0.0 in stage 4.0 (TID 4). 1286 bytes result sent to driver
21/02/17 01:41:36 INFO TaskSetManager: Finished task 0.0 in stage 4.0 (TID 4) in 5 ms on localhost (executor driver) (1/1)
21/02/17 01:41:36 INFO TaskSchedulerImpl: Removed TaskSet 4.0, whose tasks have all completed, from pool 
21/02/17 01:41:36 INFO DAGScheduler: ResultStage 4 (collect at utils.scala:135) finished in 0.010 s
21/02/17 01:41:36 INFO DAGScheduler: Job 3 finished: collect at utils.scala:135, took 0.013069 s
21/02/17 01:41:36 INFO SparkContext: Starting job: count at utils.scala:135
21/02/17 01:41:36 INFO DAGScheduler: Registering RDD 21 (count at utils.scala:135)
21/02/17 01:41:36 INFO DAGScheduler: Got job 4 (count at utils.scala:135) with 1 output partitions
21/02/17 01:41:36 INFO DAGScheduler: Final stage: ResultStage 6 (count at utils.scala:135)
21/02/17 01:41:36 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 5)
21/02/17 01:41:36 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 5)
21/02/17 01:41:36 INFO DAGScheduler: Submitting ShuffleMapStage 5 (MapPartitionsRDD[21] at count at utils.scala:135), which has no missing parents
21/02/17 01:41:36 INFO MemoryStore: Block broadcast_5 stored as values in memory (estimated size 8.4 KB, free 912.2 MB)
21/02/17 01:41:36 INFO MemoryStore: Block broadcast_5_piece0 stored as bytes in memory (estimated size 4.5 KB, free 912.2 MB)
21/02/17 01:41:36 INFO BlockManagerInfo: Added broadcast_5_piece0 in memory on localhost:41253 (size: 4.5 KB, free: 912.3 MB)
21/02/17 01:41:36 INFO SparkContext: Created broadcast 5 from broadcast at DAGScheduler.scala:1161
21/02/17 01:41:36 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 5 (MapPartitionsRDD[21] at count at utils.scala:135) (first 15 tasks are for partitions Vector(0))
21/02/17 01:41:36 INFO TaskSchedulerImpl: Adding task set 5.0 with 1 tasks
21/02/17 01:41:36 INFO TaskSetManager: Starting task 0.0 in stage 5.0 (TID 5, localhost, executor driver, partition 0, PROCESS_LOCAL, 8069 bytes)
21/02/17 01:41:36 INFO Executor: Running task 0.0 in stage 5.0 (TID 5)
21/02/17 01:41:36 INFO Executor: Finished task 0.0 in stage 5.0 (TID 5). 1499 bytes result sent to driver
21/02/17 01:41:36 INFO TaskSetManager: Finished task 0.0 in stage 5.0 (TID 5) in 6 ms on localhost (executor driver) (1/1)
21/02/17 01:41:36 INFO TaskSchedulerImpl: Removed TaskSet 5.0, whose tasks have all completed, from pool 
21/02/17 01:41:36 INFO DAGScheduler: ShuffleMapStage 5 (count at utils.scala:135) finished in 0.013 s
21/02/17 01:41:36 INFO DAGScheduler: looking for newly runnable stages
21/02/17 01:41:36 INFO DAGScheduler: running: Set()
21/02/17 01:41:36 INFO DAGScheduler: waiting: Set(ResultStage 6)
21/02/17 01:41:36 INFO DAGScheduler: failed: Set()
21/02/17 01:41:36 INFO DAGScheduler: Submitting ResultStage 6 (MapPartitionsRDD[24] at count at utils.scala:135), which has no missing parents
21/02/17 01:41:36 INFO MemoryStore: Block broadcast_6 stored as values in memory (estimated size 7.1 KB, free 912.2 MB)
21/02/17 01:41:36 INFO MemoryStore: Block broadcast_6_piece0 stored as bytes in memory (estimated size 3.8 KB, free 912.2 MB)
21/02/17 01:41:36 INFO BlockManagerInfo: Added broadcast_6_piece0 in memory on localhost:41253 (size: 3.8 KB, free: 912.3 MB)
21/02/17 01:41:36 INFO SparkContext: Created broadcast 6 from broadcast at DAGScheduler.scala:1161
21/02/17 01:41:36 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 6 (MapPartitionsRDD[24] at count at utils.scala:135) (first 15 tasks are for partitions Vector(0))
21/02/17 01:41:36 INFO TaskSchedulerImpl: Adding task set 6.0 with 1 tasks
21/02/17 01:41:36 INFO TaskSetManager: Starting task 0.0 in stage 6.0 (TID 6, localhost, executor driver, partition 0, NODE_LOCAL, 7767 bytes)
21/02/17 01:41:36 INFO Executor: Running task 0.0 in stage 6.0 (TID 6)
21/02/17 01:41:36 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks including 1 local blocks and 0 remote blocks
21/02/17 01:41:36 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
21/02/17 01:41:36 INFO Executor: Finished task 0.0 in stage 6.0 (TID 6). 1782 bytes result sent to driver
21/02/17 01:41:36 INFO TaskSetManager: Finished task 0.0 in stage 6.0 (TID 6) in 5 ms on localhost (executor driver) (1/1)
21/02/17 01:41:36 INFO TaskSchedulerImpl: Removed TaskSet 6.0, whose tasks have all completed, from pool 
21/02/17 01:41:36 INFO DAGScheduler: ResultStage 6 (count at utils.scala:135) finished in 0.011 s
21/02/17 01:41:36 INFO DAGScheduler: Job 4 finished: count at utils.scala:135, took 0.028673 s
21/02/17 01:41:36 INFO CodeGenerator: Code generated in 40.227039 ms
21/02/17 01:41:36 INFO ContextCleaner: Cleaned accumulator 69
21/02/17 01:41:36 INFO ContextCleaner: Cleaned accumulator 44
21/02/17 01:41:36 INFO ContextCleaner: Cleaned accumulator 198
21/02/17 01:41:36 INFO ContextCleaner: Cleaned accumulator 132
21/02/17 01:41:36 INFO ContextCleaner: Cleaned accumulator 204
21/02/17 01:41:36 INFO ContextCleaner: Cleaned accumulator 83
21/02/17 01:41:36 INFO ContextCleaner: Cleaned accumulator 88
21/02/17 01:41:36 INFO ContextCleaner: Cleaned accumulator 86
21/02/17 01:41:37 INFO BlockManagerInfo: Removed broadcast_5_piece0 on localhost:41253 in memory (size: 4.5 KB, free: 912.3 MB)
21/02/17 01:41:37 INFO ContextCleaner: Cleaned accumulator 172
21/02/17 01:41:37 INFO ContextCleaner: Cleaned accumulator 153
21/02/17 01:41:37 INFO ContextCleaner: Cleaned accumulator 123
21/02/17 01:41:37 INFO ContextCleaner: Cleaned accumulator 103
21/02/17 01:41:37 INFO ContextCleaner: Cleaned accumulator 178
21/02/17 01:41:37 INFO ContextCleaner: Cleaned accumulator 160
21/02/17 01:41:37 INFO ContextCleaner: Cleaned accumulator 29
21/02/17 01:41:37 INFO ContextCleaner: Cleaned accumulator 107
21/02/17 01:41:37 INFO ContextCleaner: Cleaned accumulator 146
21/02/17 01:41:37 INFO ContextCleaner: Cleaned accumulator 51
21/02/17 01:41:37 INFO ContextCleaner: Cleaned accumulator 130
21/02/17 01:41:37 INFO ContextCleaner: Cleaned accumulator 81
21/02/17 01:41:37 INFO ContextCleaner: Cleaned accumulator 186
21/02/17 01:41:37 INFO ContextCleaner: Cleaned accumulator 89
21/02/17 01:41:37 INFO ContextCleaner: Cleaned accumulator 171
21/02/17 01:41:37 INFO ContextCleaner: Cleaned accumulator 208
21/02/17 01:41:37 INFO ContextCleaner: Cleaned accumulator 91
21/02/17 01:41:37 INFO ContextCleaner: Cleaned accumulator 195
21/02/17 01:41:37 INFO ContextCleaner: Cleaned accumulator 122
21/02/17 01:41:37 INFO ContextCleaner: Cleaned accumulator 182
21/02/17 01:41:37 INFO ContextCleaner: Cleaned accumulator 161
21/02/17 01:41:37 INFO ContextCleaner: Cleaned accumulator 159
21/02/17 01:41:37 INFO ContextCleaner: Cleaned accumulator 196
21/02/17 01:41:37 INFO ContextCleaner: Cleaned accumulator 202
21/02/17 01:41:37 INFO ContextCleaner: Cleaned accumulator 137
21/02/17 01:41:37 INFO ContextCleaner: Cleaned accumulator 49
21/02/17 01:41:37 INFO ContextCleaner: Cleaned accumulator 54
21/02/17 01:41:37 INFO ContextCleaner: Cleaned accumulator 109
21/02/17 01:41:37 INFO ContextCleaner: Cleaned accumulator 39
21/02/17 01:41:37 INFO ContextCleaner: Cleaned accumulator 77
21/02/17 01:41:37 INFO ContextCleaner: Cleaned accumulator 40
21/02/17 01:41:37 INFO ContextCleaner: Cleaned accumulator 194
21/02/17 01:41:37 INFO ContextCleaner: Cleaned accumulator 41
21/02/17 01:41:37 INFO ContextCleaner: Cleaned shuffle 0
21/02/17 01:41:37 INFO ContextCleaner: Cleaned accumulator 176
21/02/17 01:41:37 INFO ContextCleaner: Cleaned accumulator 110
21/02/17 01:41:37 INFO ContextCleaner: Cleaned accumulator 210
21/02/17 01:41:37 INFO ContextCleaner: Cleaned accumulator 135
21/02/17 01:41:37 INFO ContextCleaner: Cleaned accumulator 166
21/02/17 01:41:37 INFO ContextCleaner: Cleaned accumulator 30
21/02/17 01:41:37 INFO ContextCleaner: Cleaned accumulator 170
21/02/17 01:41:37 INFO ContextCleaner: Cleaned accumulator 119
21/02/17 01:41:37 INFO ContextCleaner: Cleaned accumulator 62
21/02/17 01:41:37 INFO ContextCleaner: Cleaned accumulator 94
21/02/17 01:41:37 INFO ContextCleaner: Cleaned accumulator 53
21/02/17 01:41:37 INFO ContextCleaner: Cleaned accumulator 27
21/02/17 01:41:37 INFO ContextCleaner: Cleaned accumulator 28
21/02/17 01:41:37 INFO ContextCleaner: Cleaned accumulator 192
21/02/17 01:41:37 INFO ContextCleaner: Cleaned accumulator 168
21/02/17 01:41:37 INFO ContextCleaner: Cleaned accumulator 199
21/02/17 01:41:37 INFO ContextCleaner: Cleaned accumulator 184
21/02/17 01:41:37 INFO ContextCleaner: Cleaned accumulator 162
21/02/17 01:41:37 INFO ContextCleaner: Cleaned accumulator 79
21/02/17 01:41:37 INFO ContextCleaner: Cleaned accumulator 31
21/02/17 01:41:37 INFO ContextCleaner: Cleaned accumulator 46
21/02/17 01:41:37 INFO ContextCleaner: Cleaned accumulator 32
21/02/17 01:41:37 INFO ContextCleaner: Cleaned accumulator 99
21/02/17 01:41:37 INFO ContextCleaner: Cleaned accumulator 207
21/02/17 01:41:37 INFO ContextCleaner: Cleaned accumulator 209
21/02/17 01:41:37 INFO ContextCleaner: Cleaned accumulator 80
21/02/17 01:41:37 INFO ContextCleaner: Cleaned accumulator 74
21/02/17 01:41:37 INFO ContextCleaner: Cleaned accumulator 78
21/02/17 01:41:37 INFO ContextCleaner: Cleaned accumulator 124
21/02/17 01:41:37 INFO ContextCleaner: Cleaned accumulator 48
21/02/17 01:41:37 INFO ContextCleaner: Cleaned accumulator 187
21/02/17 01:41:37 INFO ContextCleaner: Cleaned accumulator 133
21/02/17 01:41:37 INFO ContextCleaner: Cleaned accumulator 144
21/02/17 01:41:37 INFO ContextCleaner: Cleaned accumulator 98
21/02/17 01:41:37 INFO ContextCleaner: Cleaned accumulator 84
21/02/17 01:41:37 INFO ContextCleaner: Cleaned accumulator 45
21/02/17 01:41:37 INFO ContextCleaner: Cleaned accumulator 188
21/02/17 01:41:37 INFO ContextCleaner: Cleaned accumulator 143
21/02/17 01:41:37 INFO ContextCleaner: Cleaned accumulator 71
21/02/17 01:41:37 INFO ContextCleaner: Cleaned accumulator 65
21/02/17 01:41:37 INFO ContextCleaner: Cleaned accumulator 148
21/02/17 01:41:37 INFO ContextCleaner: Cleaned accumulator 36
21/02/17 01:41:37 INFO ContextCleaner: Cleaned accumulator 154
21/02/17 01:41:37 INFO ContextCleaner: Cleaned accumulator 147
21/02/17 01:41:37 INFO BlockManagerInfo: Removed broadcast_3_piece0 on localhost:41253 in memory (size: 3.8 KB, free: 912.3 MB)
21/02/17 01:41:37 INFO ContextCleaner: Cleaned accumulator 97
21/02/17 01:41:37 INFO ContextCleaner: Cleaned accumulator 127
21/02/17 01:41:37 INFO ContextCleaner: Cleaned accumulator 156
21/02/17 01:41:37 INFO ContextCleaner: Cleaned accumulator 38
21/02/17 01:41:37 INFO ContextCleaner: Cleaned accumulator 73
21/02/17 01:41:37 INFO ContextCleaner: Cleaned accumulator 96
21/02/17 01:41:37 INFO ContextCleaner: Cleaned accumulator 85
21/02/17 01:41:37 INFO ContextCleaner: Cleaned accumulator 75
21/02/17 01:41:37 INFO ContextCleaner: Cleaned accumulator 117
21/02/17 01:41:37 INFO ContextCleaner: Cleaned accumulator 64
21/02/17 01:41:37 INFO ContextCleaner: Cleaned accumulator 33
21/02/17 01:41:37 INFO ContextCleaner: Cleaned accumulator 158
21/02/17 01:41:37 INFO ContextCleaner: Cleaned accumulator 200
21/02/17 01:41:37 INFO ContextCleaner: Cleaned accumulator 68
21/02/17 01:41:37 INFO ContextCleaner: Cleaned accumulator 60
21/02/17 01:41:37 INFO BlockManagerInfo: Removed broadcast_6_piece0 on localhost:41253 in memory (size: 3.8 KB, free: 912.3 MB)
21/02/17 01:41:37 INFO ContextCleaner: Cleaned accumulator 164
21/02/17 01:41:37 INFO ContextCleaner: Cleaned accumulator 104
21/02/17 01:41:37 INFO ContextCleaner: Cleaned accumulator 87
21/02/17 01:41:37 INFO ContextCleaner: Cleaned accumulator 136
21/02/17 01:41:37 INFO ContextCleaner: Cleaned accumulator 165
21/02/17 01:41:37 INFO ContextCleaner: Cleaned accumulator 95
21/02/17 01:41:37 INFO ContextCleaner: Cleaned accumulator 90
21/02/17 01:41:37 INFO ContextCleaner: Cleaned accumulator 108
21/02/17 01:41:37 INFO ContextCleaner: Cleaned accumulator 152
21/02/17 01:41:37 INFO ContextCleaner: Cleaned accumulator 163
21/02/17 01:41:37 INFO ContextCleaner: Cleaned accumulator 57
21/02/17 01:41:37 INFO ContextCleaner: Cleaned accumulator 131
21/02/17 01:41:37 INFO ContextCleaner: Cleaned accumulator 55
21/02/17 01:41:37 INFO BlockManagerInfo: Removed broadcast_1_piece0 on localhost:41253 in memory (size: 3.3 KB, free: 912.3 MB)
21/02/17 01:41:37 INFO ContextCleaner: Cleaned accumulator 72
21/02/17 01:41:37 INFO ContextCleaner: Cleaned accumulator 66
21/02/17 01:41:37 INFO ContextCleaner: Cleaned accumulator 52
21/02/17 01:41:37 INFO ContextCleaner: Cleaned accumulator 193
21/02/17 01:41:37 INFO ContextCleaner: Cleaned accumulator 34
21/02/17 01:41:37 INFO ContextCleaner: Cleaned accumulator 177
21/02/17 01:41:37 INFO ContextCleaner: Cleaned accumulator 128
21/02/17 01:41:37 INFO BlockManagerInfo: Removed broadcast_2_piece0 on localhost:41253 in memory (size: 4.5 KB, free: 912.3 MB)
21/02/17 01:41:37 INFO ContextCleaner: Cleaned accumulator 101
21/02/17 01:41:37 INFO ContextCleaner: Cleaned accumulator 145
21/02/17 01:41:37 INFO ContextCleaner: Cleaned accumulator 150
21/02/17 01:41:37 INFO ContextCleaner: Cleaned accumulator 179
21/02/17 01:41:37 INFO ContextCleaner: Cleaned accumulator 183
21/02/17 01:41:37 INFO ContextCleaner: Cleaned accumulator 63
21/02/17 01:41:37 INFO ContextCleaner: Cleaned accumulator 115
21/02/17 01:41:37 INFO ContextCleaner: Cleaned shuffle 1
21/02/17 01:41:37 INFO ContextCleaner: Cleaned accumulator 125
21/02/17 01:41:37 INFO ContextCleaner: Cleaned accumulator 43
21/02/17 01:41:37 INFO ContextCleaner: Cleaned accumulator 141
21/02/17 01:41:37 INFO ContextCleaner: Cleaned accumulator 121
21/02/17 01:41:37 INFO ContextCleaner: Cleaned accumulator 129
21/02/17 01:41:37 INFO BlockManagerInfo: Removed broadcast_4_piece0 on localhost:41253 in memory (size: 3.3 KB, free: 912.3 MB)
21/02/17 01:41:37 INFO ContextCleaner: Cleaned accumulator 116
21/02/17 01:41:37 INFO ContextCleaner: Cleaned accumulator 70
21/02/17 01:41:37 INFO ContextCleaner: Cleaned accumulator 197
21/02/17 01:41:37 INFO ContextCleaner: Cleaned accumulator 111
21/02/17 01:41:37 INFO ContextCleaner: Cleaned accumulator 114
21/02/17 01:41:37 INFO ContextCleaner: Cleaned accumulator 112
21/02/17 01:41:37 INFO ContextCleaner: Cleaned accumulator 138
21/02/17 01:41:37 INFO ContextCleaner: Cleaned accumulator 201
21/02/17 01:41:37 INFO ContextCleaner: Cleaned accumulator 37
21/02/17 01:41:37 INFO ContextCleaner: Cleaned accumulator 82
21/02/17 01:41:37 INFO ContextCleaner: Cleaned accumulator 50
21/02/17 01:41:37 INFO ContextCleaner: Cleaned accumulator 93
21/02/17 01:41:37 INFO ContextCleaner: Cleaned accumulator 175
21/02/17 01:41:37 INFO ContextCleaner: Cleaned accumulator 106
21/02/17 01:41:37 INFO ContextCleaner: Cleaned accumulator 100
21/02/17 01:41:37 INFO ContextCleaner: Cleaned accumulator 105
21/02/17 01:41:37 INFO ContextCleaner: Cleaned accumulator 134
21/02/17 01:41:37 INFO ContextCleaner: Cleaned accumulator 180
21/02/17 01:41:37 INFO ContextCleaner: Cleaned accumulator 67
21/02/17 01:41:37 INFO ContextCleaner: Cleaned accumulator 151
21/02/17 01:41:37 INFO ContextCleaner: Cleaned accumulator 126
21/02/17 01:41:37 INFO ContextCleaner: Cleaned accumulator 167
21/02/17 01:41:37 INFO ContextCleaner: Cleaned accumulator 35
21/02/17 01:41:37 INFO ContextCleaner: Cleaned accumulator 139
21/02/17 01:41:37 INFO ContextCleaner: Cleaned accumulator 191
21/02/17 01:41:37 INFO ContextCleaner: Cleaned accumulator 157
21/02/17 01:41:37 INFO ContextCleaner: Cleaned accumulator 174
21/02/17 01:41:37 INFO ContextCleaner: Cleaned accumulator 102
21/02/17 01:41:37 INFO ContextCleaner: Cleaned accumulator 205
21/02/17 01:41:37 INFO ContextCleaner: Cleaned accumulator 56
21/02/17 01:41:37 INFO ContextCleaner: Cleaned accumulator 113
21/02/17 01:41:37 INFO ContextCleaner: Cleaned accumulator 61
21/02/17 01:41:37 INFO ContextCleaner: Cleaned accumulator 203
21/02/17 01:41:37 INFO ContextCleaner: Cleaned accumulator 42
21/02/17 01:41:37 INFO ContextCleaner: Cleaned accumulator 76
21/02/17 01:41:37 INFO ContextCleaner: Cleaned accumulator 169
21/02/17 01:41:37 INFO ContextCleaner: Cleaned accumulator 92
21/02/17 01:41:37 INFO ContextCleaner: Cleaned accumulator 185
21/02/17 01:41:37 INFO ContextCleaner: Cleaned accumulator 149
21/02/17 01:41:37 INFO ContextCleaner: Cleaned accumulator 173
21/02/17 01:41:37 INFO ContextCleaner: Cleaned accumulator 190
21/02/17 01:41:37 INFO ContextCleaner: Cleaned accumulator 142
21/02/17 01:41:37 INFO ContextCleaner: Cleaned accumulator 189
21/02/17 01:41:37 INFO ContextCleaner: Cleaned accumulator 120
21/02/17 01:41:37 INFO ContextCleaner: Cleaned accumulator 47
21/02/17 01:41:37 INFO ContextCleaner: Cleaned accumulator 58
21/02/17 01:41:37 INFO ContextCleaner: Cleaned accumulator 140
21/02/17 01:41:37 INFO ContextCleaner: Cleaned accumulator 181
21/02/17 01:41:37 INFO ContextCleaner: Cleaned accumulator 59
21/02/17 01:41:37 INFO ContextCleaner: Cleaned accumulator 206
21/02/17 01:41:37 INFO ContextCleaner: Cleaned accumulator 26
21/02/17 01:41:37 INFO ContextCleaner: Cleaned accumulator 155
21/02/17 01:41:37 INFO XGBoostSpark: Running XGBoost 1.1.2 with parameters:
alpha -> 0.0
min_child_weight -> 1.0
sample_type -> uniform
base_score -> 0.5
rabit_timeout -> -1
colsample_bylevel -> 1.0
grow_policy -> depthwise
skip_drop -> 0.0
lambda_bias -> 0.0
silent -> 0
scale_pos_weight -> 1.0
seed -> 0
cache_training_set -> false
features_col -> features
num_early_stopping_rounds -> 0
label_col -> label
num_workers -> 1
subsample -> 1.0
lambda -> 1.0
max_depth -> 6
tree_limit -> 0
custom_eval -> null
dmlc_worker_connect_retry -> 5
rate_drop -> 0.0
max_bin -> 16
train_test_ratio -> 1.0
use_external_memory -> false
objective -> reg:linear
eval_metric -> rmse
num_round -> 1
maximize_evaluation_metrics -> false
timeout_request_workers -> 1800000
missing -> NaN
rabit_ring_reduce_threshold -> 32768
checkpoint_path -> 
tracker_conf -> TrackerConf(0,python)
tree_method -> auto
max_delta_step -> 0.0
eta -> 0.3
verbosity -> 1
colsample_bytree -> 1.0
objective_type -> regression
normalize_type -> tree
allow_non_zero_for_missing -> false
custom_obj -> null
gamma -> 0.0
sketch_eps -> 0.03
nthread -> 1
prediction_col -> prediction
checkpoint_interval -> -1
21/02/17 01:41:37 WARN XGBoostSpark: train_test_ratio is deprecated since XGBoost 0.82, we recommend to explicitly pass a training and multiple evaluation datasets by passing 'eval_sets' and 'eval_set_names'
21/02/17 01:41:37 INFO RabitTracker$TrackerProcessLogger: 2021-02-17 01:41:37,130 INFO start listen on 192.168.2.12:9091
21/02/17 01:41:37 INFO XGBoostSpark: starting training with timeout set as 1800000 ms for waiting for resources
21/02/17 01:41:37 INFO SparkContext: Starting job: foreachPartition at XGBoost.scala:565
21/02/17 01:41:37 INFO DAGScheduler: Got job 5 (foreachPartition at XGBoost.scala:565) with 1 output partitions
21/02/17 01:41:37 INFO DAGScheduler: Final stage: ResultStage 7 (foreachPartition at XGBoost.scala:565)
21/02/17 01:41:37 INFO DAGScheduler: Parents of final stage: List()
21/02/17 01:41:37 INFO DAGScheduler: Missing parents: List()
21/02/17 01:41:37 INFO DAGScheduler: Submitting ResultStage 7 (MapPartitionsRDD[35] at mapPartitions at XGBoost.scala:450), which has no missing parents
21/02/17 01:41:37 INFO MemoryStore: Block broadcast_7 stored as values in memory (estimated size 31.7 KB, free 912.3 MB)
21/02/17 01:41:37 INFO MemoryStore: Block broadcast_7_piece0 stored as bytes in memory (estimated size 13.6 KB, free 912.2 MB)
21/02/17 01:41:37 INFO BlockManagerInfo: Added broadcast_7_piece0 in memory on localhost:41253 (size: 13.6 KB, free: 912.3 MB)
21/02/17 01:41:37 INFO SparkContext: Created broadcast 7 from broadcast at DAGScheduler.scala:1161
21/02/17 01:41:37 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 7 (MapPartitionsRDD[35] at mapPartitions at XGBoost.scala:450) (first 15 tasks are for partitions Vector(0))
21/02/17 01:41:37 INFO TaskSchedulerImpl: Adding task set 7.0 with 1 tasks
21/02/17 01:41:37 INFO TaskSetManager: Starting task 0.0 in stage 7.0 (TID 7, localhost, executor driver, partition 0, PROCESS_LOCAL, 19011 bytes)
21/02/17 01:41:37 INFO Executor: Running task 0.0 in stage 7.0 (TID 7)
21/02/17 01:41:37 INFO CodeGenerator: Code generated in 13.509523 ms
21/02/17 01:41:37 INFO MemoryStore: Block rdd_26_0 stored as values in memory (estimated size 5.6 KB, free 912.2 MB)
21/02/17 01:41:37 INFO BlockManagerInfo: Added rdd_26_0 in memory on localhost:41253 (size: 5.6 KB, free: 912.3 MB)
21/02/17 01:41:37 INFO CodeGenerator: Code generated in 4.964287 ms
21/02/17 01:41:37 INFO CodeGenerator: Code generated in 19.802395 ms
21/02/17 01:41:37 INFO CodeGenerator: Code generated in 8.337079 ms
21/02/17 01:41:37 INFO RabitTracker$TrackerProcessLogger: /tmp/tracker5383020246044674796.py:330: DeprecationWarning: isAlive() is deprecated, use is_alive() instead
21/02/17 01:41:37 INFO RabitTracker$TrackerProcessLogger:   while self.thread.isAlive():
21/02/17 01:41:37 INFO RabitTracker$TrackerProcessLogger: 2021-02-17 01:41:37,426 DEBUG Recieve start signal from 192.168.2.12; assign rank 0
21/02/17 01:41:37 INFO RabitTracker$TrackerProcessLogger: 2021-02-17 01:41:37,426 INFO @tracker All of 1 nodes getting started
21/02/17 01:41:37 INFO RabitTracker$TrackerProcessLogger: 2021-02-17 01:41:37,434 INFO [0]	train-rmse:2.633044
21/02/17 01:41:37 INFO RabitTracker$TrackerProcessLogger: 2021-02-17 01:41:37,435 DEBUG Recieve shutdown signal from 0
21/02/17 01:41:37 INFO RabitTracker$TrackerProcessLogger: 2021-02-17 01:41:37,435 INFO @tracker All nodes finishes job
21/02/17 01:41:37 INFO RabitTracker$TrackerProcessLogger: 2021-02-17 01:41:37,435 INFO @tracker 0.008830547332763672 secs between node start and job finish
21/02/17 01:41:37 INFO MemoryStore: Block rdd_35_0 stored as values in memory (estimated size 192.0 B, free 912.2 MB)
21/02/17 01:41:37 INFO BlockManagerInfo: Added rdd_35_0 in memory on localhost:41253 (size: 192.0 B, free: 912.3 MB)
21/02/17 01:41:37 INFO RabitTracker$TrackerProcessLogger: Tracker Process ends with exit code 0
21/02/17 01:41:37 INFO RabitTracker: Tracker Process ends with exit code 0
21/02/17 01:41:37 INFO XGBoostSpark: Rabit returns with exit code 0
21/02/17 01:41:37 INFO Executor: 1 block locks were not released by TID = 7:
[rdd_35_0]
21/02/17 01:41:37 INFO Executor: Finished task 0.0 in stage 7.0 (TID 7). 1303 bytes result sent to driver
21/02/17 01:41:37 INFO TaskSetManager: Finished task 0.0 in stage 7.0 (TID 7) in 245 ms on localhost (executor driver) (1/1)
21/02/17 01:41:37 INFO TaskSchedulerImpl: Removed TaskSet 7.0, whose tasks have all completed, from pool 
21/02/17 01:41:37 INFO DAGScheduler: ResultStage 7 (foreachPartition at XGBoost.scala:565) finished in 0.288 s
21/02/17 01:41:37 INFO DAGScheduler: Job 5 finished: foreachPartition at XGBoost.scala:565, took 0.296006 s
21/02/17 01:41:37 INFO SparkContext: Starting job: first at XGBoost.scala:685
21/02/17 01:41:37 INFO DAGScheduler: Got job 6 (first at XGBoost.scala:685) with 1 output partitions
21/02/17 01:41:37 INFO DAGScheduler: Final stage: ResultStage 8 (first at XGBoost.scala:685)
21/02/17 01:41:37 INFO DAGScheduler: Parents of final stage: List()
21/02/17 01:41:37 INFO DAGScheduler: Missing parents: List()
21/02/17 01:41:37 INFO DAGScheduler: Submitting ResultStage 8 (MapPartitionsRDD[35] at mapPartitions at XGBoost.scala:450), which has no missing parents
21/02/17 01:41:37 INFO MemoryStore: Block broadcast_8 stored as values in memory (estimated size 31.7 KB, free 912.2 MB)
21/02/17 01:41:37 INFO MemoryStore: Block broadcast_8_piece0 stored as bytes in memory (estimated size 13.7 KB, free 912.2 MB)
21/02/17 01:41:37 INFO BlockManagerInfo: Added broadcast_8_piece0 in memory on localhost:41253 (size: 13.7 KB, free: 912.3 MB)
21/02/17 01:41:37 INFO SparkContext: Created broadcast 8 from broadcast at DAGScheduler.scala:1161
21/02/17 01:41:37 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 8 (MapPartitionsRDD[35] at mapPartitions at XGBoost.scala:450) (first 15 tasks are for partitions Vector(0))
21/02/17 01:41:37 INFO TaskSchedulerImpl: Adding task set 8.0 with 1 tasks
21/02/17 01:41:37 INFO TaskSetManager: Starting task 0.0 in stage 8.0 (TID 8, localhost, executor driver, partition 0, PROCESS_LOCAL, 19011 bytes)
21/02/17 01:41:37 INFO Executor: Running task 0.0 in stage 8.0 (TID 8)
21/02/17 01:41:37 INFO BlockManager: Found block rdd_35_0 locally
21/02/17 01:41:37 INFO Executor: 1 block locks were not released by TID = 8:
[rdd_35_0]
21/02/17 01:41:37 INFO Executor: Finished task 0.0 in stage 8.0 (TID 8). 2551 bytes result sent to driver
21/02/17 01:41:37 INFO TaskSetManager: Finished task 0.0 in stage 8.0 (TID 8) in 9 ms on localhost (executor driver) (1/1)
21/02/17 01:41:37 INFO TaskSchedulerImpl: Removed TaskSet 8.0, whose tasks have all completed, from pool 
21/02/17 01:41:37 INFO DAGScheduler: ResultStage 8 (first at XGBoost.scala:685) finished in 0.016 s
21/02/17 01:41:37 INFO DAGScheduler: Job 6 finished: first at XGBoost.scala:685, took 0.018387 s
21/02/17 01:41:37 INFO MapPartitionsRDD: Removing RDD 35 from persistence list
21/02/17 01:41:37 INFO BlockManager: Removing RDD 35
21/02/17 01:41:37 INFO MemoryStore: Block broadcast_9 stored as values in memory (estimated size 64.0 B, free 912.2 MB)
21/02/17 01:41:37 INFO MemoryStore: Block broadcast_9_piece0 stored as bytes in memory (estimated size 510.0 B, free 912.2 MB)
21/02/17 01:41:37 INFO BlockManagerInfo: Added broadcast_9_piece0 in memory on localhost:41253 (size: 510.0 B, free: 912.3 MB)
21/02/17 01:41:37 INFO SparkContext: Created broadcast 9 from broadcast at XGBoostRegressor.scala:271
21/02/17 01:41:37 INFO CodeGenerator: Code generated in 20.756858 ms
21/02/17 01:41:37 INFO CodeGenerator: Code generated in 6.749236 ms
21/02/17 01:41:37 INFO CodeGenerator: Code generated in 7.042299 ms
21/02/17 01:41:37 INFO SparkContext: Starting job: collect at utils.scala:135
21/02/17 01:41:37 INFO DAGScheduler: Got job 7 (collect at utils.scala:135) with 1 output partitions
21/02/17 01:41:37 INFO DAGScheduler: Final stage: ResultStage 9 (collect at utils.scala:135)
21/02/17 01:41:37 INFO DAGScheduler: Parents of final stage: List()
21/02/17 01:41:37 INFO DAGScheduler: Missing parents: List()
21/02/17 01:41:37 INFO DAGScheduler: Submitting ResultStage 9 (MapPartitionsRDD[46] at collect at utils.scala:135), which has no missing parents
21/02/17 01:41:37 INFO MemoryStore: Block broadcast_10 stored as values in memory (estimated size 6.4 KB, free 912.2 MB)
21/02/17 01:41:37 INFO MemoryStore: Block broadcast_10_piece0 stored as bytes in memory (estimated size 3.3 KB, free 912.2 MB)
21/02/17 01:41:37 INFO BlockManagerInfo: Added broadcast_10_piece0 in memory on localhost:41253 (size: 3.3 KB, free: 912.3 MB)
21/02/17 01:41:37 INFO SparkContext: Created broadcast 10 from broadcast at DAGScheduler.scala:1161
21/02/17 01:41:37 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 9 (MapPartitionsRDD[46] at collect at utils.scala:135) (first 15 tasks are for partitions Vector(0))
21/02/17 01:41:37 INFO TaskSchedulerImpl: Adding task set 9.0 with 1 tasks
21/02/17 01:41:37 INFO TaskSetManager: Starting task 0.0 in stage 9.0 (TID 9, localhost, executor driver, partition 0, PROCESS_LOCAL, 8080 bytes)
21/02/17 01:41:37 INFO Executor: Running task 0.0 in stage 9.0 (TID 9)
21/02/17 01:41:37 INFO Executor: Finished task 0.0 in stage 9.0 (TID 9). 1286 bytes result sent to driver
21/02/17 01:41:37 INFO TaskSetManager: Finished task 0.0 in stage 9.0 (TID 9) in 7 ms on localhost (executor driver) (1/1)
21/02/17 01:41:37 INFO TaskSchedulerImpl: Removed TaskSet 9.0, whose tasks have all completed, from pool 
21/02/17 01:41:37 INFO DAGScheduler: ResultStage 9 (collect at utils.scala:135) finished in 0.011 s
21/02/17 01:41:37 INFO DAGScheduler: Job 7 finished: collect at utils.scala:135, took 0.013123 s
21/02/17 01:41:38 INFO SparkContext: Starting job: count at utils.scala:135
21/02/17 01:41:38 INFO DAGScheduler: Registering RDD 49 (count at utils.scala:135)
21/02/17 01:41:38 INFO DAGScheduler: Got job 8 (count at utils.scala:135) with 1 output partitions
21/02/17 01:41:38 INFO DAGScheduler: Final stage: ResultStage 11 (count at utils.scala:135)
21/02/17 01:41:38 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 10)
21/02/17 01:41:38 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 10)
21/02/17 01:41:38 INFO DAGScheduler: Submitting ShuffleMapStage 10 (MapPartitionsRDD[49] at count at utils.scala:135), which has no missing parents
21/02/17 01:41:38 INFO MemoryStore: Block broadcast_11 stored as values in memory (estimated size 8.4 KB, free 912.2 MB)
21/02/17 01:41:38 INFO MemoryStore: Block broadcast_11_piece0 stored as bytes in memory (estimated size 4.5 KB, free 912.2 MB)
21/02/17 01:41:38 INFO BlockManagerInfo: Added broadcast_11_piece0 in memory on localhost:41253 (size: 4.5 KB, free: 912.3 MB)
21/02/17 01:41:38 INFO SparkContext: Created broadcast 11 from broadcast at DAGScheduler.scala:1161
21/02/17 01:41:38 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 10 (MapPartitionsRDD[49] at count at utils.scala:135) (first 15 tasks are for partitions Vector(0))
21/02/17 01:41:38 INFO TaskSchedulerImpl: Adding task set 10.0 with 1 tasks
21/02/17 01:41:38 INFO TaskSetManager: Starting task 0.0 in stage 10.0 (TID 10, localhost, executor driver, partition 0, PROCESS_LOCAL, 8069 bytes)
21/02/17 01:41:38 INFO Executor: Running task 0.0 in stage 10.0 (TID 10)
21/02/17 01:41:38 INFO Executor: Finished task 0.0 in stage 10.0 (TID 10). 1499 bytes result sent to driver
21/02/17 01:41:38 INFO TaskSetManager: Finished task 0.0 in stage 10.0 (TID 10) in 6 ms on localhost (executor driver) (1/1)
21/02/17 01:41:38 INFO TaskSchedulerImpl: Removed TaskSet 10.0, whose tasks have all completed, from pool 
21/02/17 01:41:38 INFO DAGScheduler: ShuffleMapStage 10 (count at utils.scala:135) finished in 0.013 s
21/02/17 01:41:38 INFO DAGScheduler: looking for newly runnable stages
21/02/17 01:41:38 INFO DAGScheduler: running: Set()
21/02/17 01:41:38 INFO DAGScheduler: waiting: Set(ResultStage 11)
21/02/17 01:41:38 INFO DAGScheduler: failed: Set()
21/02/17 01:41:38 INFO DAGScheduler: Submitting ResultStage 11 (MapPartitionsRDD[52] at count at utils.scala:135), which has no missing parents
21/02/17 01:41:38 INFO MemoryStore: Block broadcast_12 stored as values in memory (estimated size 7.1 KB, free 912.2 MB)
21/02/17 01:41:38 INFO MemoryStore: Block broadcast_12_piece0 stored as bytes in memory (estimated size 3.8 KB, free 912.2 MB)
21/02/17 01:41:38 INFO BlockManagerInfo: Added broadcast_12_piece0 in memory on localhost:41253 (size: 3.8 KB, free: 912.3 MB)
21/02/17 01:41:38 INFO SparkContext: Created broadcast 12 from broadcast at DAGScheduler.scala:1161
21/02/17 01:41:38 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 11 (MapPartitionsRDD[52] at count at utils.scala:135) (first 15 tasks are for partitions Vector(0))
21/02/17 01:41:38 INFO TaskSchedulerImpl: Adding task set 11.0 with 1 tasks
21/02/17 01:41:38 INFO TaskSetManager: Starting task 0.0 in stage 11.0 (TID 11, localhost, executor driver, partition 0, NODE_LOCAL, 7767 bytes)
21/02/17 01:41:38 INFO Executor: Running task 0.0 in stage 11.0 (TID 11)
21/02/17 01:41:38 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks including 1 local blocks and 0 remote blocks
21/02/17 01:41:38 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
21/02/17 01:41:38 INFO Executor: Finished task 0.0 in stage 11.0 (TID 11). 1782 bytes result sent to driver
21/02/17 01:41:38 INFO TaskSetManager: Finished task 0.0 in stage 11.0 (TID 11) in 4 ms on localhost (executor driver) (1/1)
21/02/17 01:41:38 INFO TaskSchedulerImpl: Removed TaskSet 11.0, whose tasks have all completed, from pool 
21/02/17 01:41:38 INFO DAGScheduler: ResultStage 11 (count at utils.scala:135) finished in 0.010 s
21/02/17 01:41:38 INFO DAGScheduler: Job 8 finished: count at utils.scala:135, took 0.025934 s
21/02/17 01:41:38 INFO CodeGenerator: Code generated in 5.250434 ms
21/02/17 01:41:38 INFO CodeGenerator: Code generated in 6.786444 ms
21/02/17 01:41:38 INFO SparkContext: Starting job: collect at utils.scala:135
21/02/17 01:41:38 INFO DAGScheduler: Got job 9 (collect at utils.scala:135) with 1 output partitions
21/02/17 01:41:38 INFO DAGScheduler: Final stage: ResultStage 12 (collect at utils.scala:135)
21/02/17 01:41:38 INFO DAGScheduler: Parents of final stage: List()
21/02/17 01:41:38 INFO DAGScheduler: Missing parents: List()
21/02/17 01:41:38 INFO DAGScheduler: Submitting ResultStage 12 (MapPartitionsRDD[55] at collect at utils.scala:135), which has no missing parents
21/02/17 01:41:38 INFO MemoryStore: Block broadcast_13 stored as values in memory (estimated size 59.1 KB, free 912.1 MB)
21/02/17 01:41:38 INFO MemoryStore: Block broadcast_13_piece0 stored as bytes in memory (estimated size 25.4 KB, free 912.1 MB)
21/02/17 01:41:38 INFO BlockManagerInfo: Added broadcast_13_piece0 in memory on localhost:41253 (size: 25.4 KB, free: 912.2 MB)
21/02/17 01:41:38 INFO SparkContext: Created broadcast 13 from broadcast at DAGScheduler.scala:1161
21/02/17 01:41:38 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 12 (MapPartitionsRDD[55] at collect at utils.scala:135) (first 15 tasks are for partitions Vector(0))
21/02/17 01:41:38 INFO TaskSchedulerImpl: Adding task set 12.0 with 1 tasks
21/02/17 01:41:38 INFO TaskSetManager: Starting task 0.0 in stage 12.0 (TID 12, localhost, executor driver, partition 0, PROCESS_LOCAL, 19011 bytes)
21/02/17 01:41:38 INFO Executor: Running task 0.0 in stage 12.0 (TID 12)
21/02/17 01:41:38 INFO BlockManager: Found block rdd_26_0 locally
21/02/17 01:41:38 INFO CodeGenerator: Code generated in 8.680629 ms
21/02/17 01:41:38 INFO CodeGenerator: Code generated in 12.818737 ms
21/02/17 01:41:38 INFO CodeGenerator: Code generated in 36.394899 ms
21/02/17 01:41:38 INFO Executor: Finished task 0.0 in stage 12.0 (TID 12). 1815 bytes result sent to driver
21/02/17 01:41:38 INFO TaskSetManager: Finished task 0.0 in stage 12.0 (TID 12) in 117 ms on localhost (executor driver) (1/1)
21/02/17 01:41:38 INFO TaskSchedulerImpl: Removed TaskSet 12.0, whose tasks have all completed, from pool 
21/02/17 01:41:38 INFO DAGScheduler: ResultStage 12 (collect at utils.scala:135) finished in 0.124 s
21/02/17 01:41:38 INFO DAGScheduler: Job 9 finished: collect at utils.scala:135, took 0.126386 s
21/02/17 01:41:38 INFO CodeGenerator: Code generated in 10.645228 ms
21/02/17 01:41:38 INFO SparkContext: Starting job: count at utils.scala:135
21/02/17 01:41:38 INFO DAGScheduler: Registering RDD 58 (count at utils.scala:135)
21/02/17 01:41:38 INFO DAGScheduler: Got job 10 (count at utils.scala:135) with 1 output partitions
21/02/17 01:41:38 INFO DAGScheduler: Final stage: ResultStage 14 (count at utils.scala:135)
21/02/17 01:41:38 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 13)
21/02/17 01:41:38 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 13)
21/02/17 01:41:38 INFO DAGScheduler: Submitting ShuffleMapStage 13 (MapPartitionsRDD[58] at count at utils.scala:135), which has no missing parents
21/02/17 01:41:38 INFO MemoryStore: Block broadcast_14 stored as values in memory (estimated size 60.0 KB, free 912.0 MB)
21/02/17 01:41:38 INFO MemoryStore: Block broadcast_14_piece0 stored as bytes in memory (estimated size 25.9 KB, free 912.0 MB)
21/02/17 01:41:38 INFO BlockManagerInfo: Added broadcast_14_piece0 in memory on localhost:41253 (size: 25.9 KB, free: 912.2 MB)
21/02/17 01:41:38 INFO SparkContext: Created broadcast 14 from broadcast at DAGScheduler.scala:1161
21/02/17 01:41:38 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 13 (MapPartitionsRDD[58] at count at utils.scala:135) (first 15 tasks are for partitions Vector(0))
21/02/17 01:41:38 INFO TaskSchedulerImpl: Adding task set 13.0 with 1 tasks
21/02/17 01:41:38 INFO TaskSetManager: Starting task 0.0 in stage 13.0 (TID 13, localhost, executor driver, partition 0, PROCESS_LOCAL, 19000 bytes)
21/02/17 01:41:38 INFO Executor: Running task 0.0 in stage 13.0 (TID 13)
21/02/17 01:41:38 INFO BlockManager: Found block rdd_26_0 locally
21/02/17 01:41:38 INFO Executor: Finished task 0.0 in stage 13.0 (TID 13). 1933 bytes result sent to driver
21/02/17 01:41:38 INFO TaskSetManager: Finished task 0.0 in stage 13.0 (TID 13) in 37 ms on localhost (executor driver) (1/1)
21/02/17 01:41:38 INFO TaskSchedulerImpl: Removed TaskSet 13.0, whose tasks have all completed, from pool 
21/02/17 01:41:38 INFO DAGScheduler: ShuffleMapStage 13 (count at utils.scala:135) finished in 0.045 s
21/02/17 01:41:38 INFO DAGScheduler: looking for newly runnable stages
21/02/17 01:41:38 INFO DAGScheduler: running: Set()
21/02/17 01:41:38 INFO DAGScheduler: waiting: Set(ResultStage 14)
21/02/17 01:41:38 INFO DAGScheduler: failed: Set()
21/02/17 01:41:38 INFO DAGScheduler: Submitting ResultStage 14 (MapPartitionsRDD[61] at count at utils.scala:135), which has no missing parents
21/02/17 01:41:38 INFO MemoryStore: Block broadcast_15 stored as values in memory (estimated size 7.1 KB, free 912.0 MB)
21/02/17 01:41:38 INFO MemoryStore: Block broadcast_15_piece0 stored as bytes in memory (estimated size 3.8 KB, free 912.0 MB)
21/02/17 01:41:38 INFO BlockManagerInfo: Added broadcast_15_piece0 in memory on localhost:41253 (size: 3.8 KB, free: 912.2 MB)
21/02/17 01:41:38 INFO SparkContext: Created broadcast 15 from broadcast at DAGScheduler.scala:1161
21/02/17 01:41:38 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 14 (MapPartitionsRDD[61] at count at utils.scala:135) (first 15 tasks are for partitions Vector(0))
21/02/17 01:41:38 INFO TaskSchedulerImpl: Adding task set 14.0 with 1 tasks
21/02/17 01:41:38 INFO TaskSetManager: Starting task 0.0 in stage 14.0 (TID 14, localhost, executor driver, partition 0, NODE_LOCAL, 7767 bytes)
21/02/17 01:41:38 INFO Executor: Running task 0.0 in stage 14.0 (TID 14)
21/02/17 01:41:38 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks including 1 local blocks and 0 remote blocks
21/02/17 01:41:38 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
21/02/17 01:41:38 INFO Executor: Finished task 0.0 in stage 14.0 (TID 14). 1782 bytes result sent to driver
21/02/17 01:41:38 INFO TaskSetManager: Finished task 0.0 in stage 14.0 (TID 14) in 5 ms on localhost (executor driver) (1/1)
21/02/17 01:41:38 INFO TaskSchedulerImpl: Removed TaskSet 14.0, whose tasks have all completed, from pool 
21/02/17 01:41:38 INFO DAGScheduler: ResultStage 14 (count at utils.scala:135) finished in 0.009 s
21/02/17 01:41:38 INFO DAGScheduler: Job 10 finished: count at utils.scala:135, took 0.058854 s
21/02/17 01:41:38 INFO deprecation: mapred.output.dir is deprecated. Instead, use mapreduce.output.fileoutputformat.outputdir
21/02/17 01:41:38 INFO HadoopMapRedCommitProtocol: Using output committer class org.apache.hadoop.mapred.FileOutputCommitter
21/02/17 01:41:38 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
21/02/17 01:41:38 INFO SparkContext: Starting job: runJob at SparkHadoopWriter.scala:78
21/02/17 01:41:38 INFO DAGScheduler: Got job 11 (runJob at SparkHadoopWriter.scala:78) with 1 output partitions
21/02/17 01:41:38 INFO DAGScheduler: Final stage: ResultStage 15 (runJob at SparkHadoopWriter.scala:78)
21/02/17 01:41:38 INFO DAGScheduler: Parents of final stage: List()
21/02/17 01:41:38 INFO DAGScheduler: Missing parents: List()
21/02/17 01:41:38 INFO DAGScheduler: Submitting ResultStage 15 (MapPartitionsRDD[63] at saveAsTextFile at ReadWrite.scala:441), which has no missing parents
21/02/17 01:41:38 INFO MemoryStore: Block broadcast_16 stored as values in memory (estimated size 71.1 KB, free 911.9 MB)
21/02/17 01:41:38 INFO MemoryStore: Block broadcast_16_piece0 stored as bytes in memory (estimated size 25.4 KB, free 911.9 MB)
21/02/17 01:41:38 INFO BlockManagerInfo: Added broadcast_16_piece0 in memory on localhost:41253 (size: 25.4 KB, free: 912.2 MB)
21/02/17 01:41:38 INFO SparkContext: Created broadcast 16 from broadcast at DAGScheduler.scala:1161
21/02/17 01:41:38 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 15 (MapPartitionsRDD[63] at saveAsTextFile at ReadWrite.scala:441) (first 15 tasks are for partitions Vector(0))
21/02/17 01:41:38 INFO TaskSchedulerImpl: Adding task set 15.0 with 1 tasks
21/02/17 01:41:38 INFO TaskSetManager: Starting task 0.0 in stage 15.0 (TID 15, localhost, executor driver, partition 0, PROCESS_LOCAL, 8176 bytes)
21/02/17 01:41:38 INFO Executor: Running task 0.0 in stage 15.0 (TID 15)
21/02/17 01:41:38 INFO HadoopMapRedCommitProtocol: Using output committer class org.apache.hadoop.mapred.FileOutputCommitter
21/02/17 01:41:38 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
21/02/17 01:41:38 INFO FileOutputCommitter: Saved output of task 'attempt_20210217014138_0063_m_000000_0' to file:/tmp/Rtmp09Oz4e/file22e22736a8feb/metadata/_temporary/0/task_20210217014138_0063_m_000000
21/02/17 01:41:38 INFO SparkHadoopMapRedUtil: attempt_20210217014138_0063_m_000000_0: Committed
21/02/17 01:41:38 INFO Executor: Finished task 0.0 in stage 15.0 (TID 15). 1072 bytes result sent to driver
21/02/17 01:41:38 INFO TaskSetManager: Finished task 0.0 in stage 15.0 (TID 15) in 44 ms on localhost (executor driver) (1/1)
21/02/17 01:41:38 INFO TaskSchedulerImpl: Removed TaskSet 15.0, whose tasks have all completed, from pool 
21/02/17 01:41:38 INFO DAGScheduler: ResultStage 15 (runJob at SparkHadoopWriter.scala:78) finished in 0.060 s
21/02/17 01:41:38 INFO DAGScheduler: Job 11 finished: runJob at SparkHadoopWriter.scala:78, took 0.062284 s
21/02/17 01:41:38 INFO SparkHadoopWriter: Job job_20210217014138_0063 committed.
21/02/17 01:41:38 INFO HadoopMapRedCommitProtocol: Using output committer class org.apache.hadoop.mapred.FileOutputCommitter
21/02/17 01:41:38 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
21/02/17 01:41:38 INFO SparkContext: Starting job: runJob at SparkHadoopWriter.scala:78
21/02/17 01:41:38 INFO DAGScheduler: Got job 12 (runJob at SparkHadoopWriter.scala:78) with 1 output partitions
21/02/17 01:41:38 INFO DAGScheduler: Final stage: ResultStage 16 (runJob at SparkHadoopWriter.scala:78)
21/02/17 01:41:38 INFO DAGScheduler: Parents of final stage: List()
21/02/17 01:41:38 INFO DAGScheduler: Missing parents: List()
21/02/17 01:41:38 INFO DAGScheduler: Submitting ResultStage 16 (MapPartitionsRDD[65] at saveAsTextFile at ReadWrite.scala:441), which has no missing parents
21/02/17 01:41:38 INFO MemoryStore: Block broadcast_17 stored as values in memory (estimated size 71.2 KB, free 911.8 MB)
21/02/17 01:41:38 INFO ContextCleaner: Cleaned accumulator 413
21/02/17 01:41:38 INFO ContextCleaner: Cleaned accumulator 428
21/02/17 01:41:38 INFO ContextCleaner: Cleaned accumulator 250
21/02/17 01:41:38 INFO ContextCleaner: Cleaned accumulator 319
21/02/17 01:41:38 INFO ContextCleaner: Cleaned accumulator 315
21/02/17 01:41:38 INFO ContextCleaner: Cleaned accumulator 229
21/02/17 01:41:38 INFO ContextCleaner: Cleaned accumulator 264
21/02/17 01:41:38 INFO ContextCleaner: Cleaned accumulator 389
21/02/17 01:41:38 INFO ContextCleaner: Cleaned accumulator 352
21/02/17 01:41:38 INFO ContextCleaner: Cleaned accumulator 291
21/02/17 01:41:38 INFO ContextCleaner: Cleaned accumulator 320
21/02/17 01:41:38 INFO ContextCleaner: Cleaned accumulator 429
21/02/17 01:41:38 INFO ContextCleaner: Cleaned accumulator 430
21/02/17 01:41:38 INFO ContextCleaner: Cleaned accumulator 281
21/02/17 01:41:38 INFO ContextCleaner: Cleaned accumulator 222
21/02/17 01:41:38 INFO ContextCleaner: Cleaned accumulator 411
21/02/17 01:41:38 INFO ContextCleaner: Cleaned accumulator 245
21/02/17 01:41:38 INFO ContextCleaner: Cleaned accumulator 334
21/02/17 01:41:38 INFO ContextCleaner: Cleaned accumulator 387
21/02/17 01:41:38 INFO ContextCleaner: Cleaned accumulator 307
21/02/17 01:41:38 INFO ContextCleaner: Cleaned accumulator 215
21/02/17 01:41:38 INFO ContextCleaner: Cleaned accumulator 301
21/02/17 01:41:38 INFO ContextCleaner: Cleaned accumulator 398
21/02/17 01:41:38 INFO ContextCleaner: Cleaned accumulator 445
21/02/17 01:41:38 INFO ContextCleaner: Cleaned accumulator 228
21/02/17 01:41:38 INFO ContextCleaner: Cleaned accumulator 395
21/02/17 01:41:38 INFO ContextCleaner: Cleaned accumulator 224
21/02/17 01:41:38 INFO ContextCleaner: Cleaned accumulator 462
21/02/17 01:41:38 INFO ContextCleaner: Cleaned accumulator 311
21/02/17 01:41:38 INFO ContextCleaner: Cleaned accumulator 258
21/02/17 01:41:38 INFO ContextCleaner: Cleaned accumulator 377
21/02/17 01:41:38 INFO ContextCleaner: Cleaned accumulator 275
21/02/17 01:41:38 INFO ContextCleaner: Cleaned accumulator 285
21/02/17 01:41:38 INFO ContextCleaner: Cleaned accumulator 332
21/02/17 01:41:38 INFO ContextCleaner: Cleaned accumulator 338
21/02/17 01:41:38 INFO ContextCleaner: Cleaned accumulator 347
21/02/17 01:41:38 INFO ContextCleaner: Cleaned accumulator 293
21/02/17 01:41:38 INFO ContextCleaner: Cleaned accumulator 370
21/02/17 01:41:38 INFO ContextCleaner: Cleaned accumulator 380
21/02/17 01:41:38 INFO ContextCleaner: Cleaned accumulator 431
21/02/17 01:41:38 INFO ContextCleaner: Cleaned accumulator 455
21/02/17 01:41:38 INFO ContextCleaner: Cleaned accumulator 217
21/02/17 01:41:38 INFO ContextCleaner: Cleaned accumulator 330
21/02/17 01:41:38 INFO ContextCleaner: Cleaned accumulator 457
21/02/17 01:41:38 INFO ContextCleaner: Cleaned accumulator 225
21/02/17 01:41:38 INFO ContextCleaner: Cleaned accumulator 304
21/02/17 01:41:38 INFO ContextCleaner: Cleaned accumulator 231
21/02/17 01:41:38 INFO MemoryStore: Block broadcast_17_piece0 stored as bytes in memory (estimated size 25.5 KB, free 911.8 MB)
21/02/17 01:41:38 INFO ContextCleaner: Cleaned accumulator 359
21/02/17 01:41:38 INFO ContextCleaner: Cleaned accumulator 436
21/02/17 01:41:38 INFO ContextCleaner: Cleaned accumulator 336
21/02/17 01:41:38 INFO ContextCleaner: Cleaned accumulator 303
21/02/17 01:41:38 INFO ContextCleaner: Cleaned accumulator 441
21/02/17 01:41:38 INFO ContextCleaner: Cleaned accumulator 227
21/02/17 01:41:38 INFO ContextCleaner: Cleaned accumulator 458
21/02/17 01:41:38 INFO ContextCleaner: Cleaned accumulator 385
21/02/17 01:41:38 INFO ContextCleaner: Cleaned accumulator 214
21/02/17 01:41:38 INFO ContextCleaner: Cleaned accumulator 254
21/02/17 01:41:38 INFO ContextCleaner: Cleaned accumulator 465
21/02/17 01:41:38 INFO ContextCleaner: Cleaned accumulator 368
21/02/17 01:41:38 INFO BlockManagerInfo: Added broadcast_17_piece0 in memory on localhost:41253 (size: 25.5 KB, free: 912.1 MB)
21/02/17 01:41:38 INFO SparkContext: Created broadcast 17 from broadcast at DAGScheduler.scala:1161
21/02/17 01:41:38 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 16 (MapPartitionsRDD[65] at saveAsTextFile at ReadWrite.scala:441) (first 15 tasks are for partitions Vector(0))
21/02/17 01:41:38 INFO TaskSchedulerImpl: Adding task set 16.0 with 1 tasks
21/02/17 01:41:38 INFO BlockManagerInfo: Removed broadcast_7_piece0 on localhost:41253 in memory (size: 13.6 KB, free: 912.2 MB)
21/02/17 01:41:38 INFO TaskSetManager: Starting task 0.0 in stage 16.0 (TID 16, localhost, executor driver, partition 0, PROCESS_LOCAL, 8317 bytes)
21/02/17 01:41:38 INFO Executor: Running task 0.0 in stage 16.0 (TID 16)
21/02/17 01:41:38 INFO ContextCleaner: Cleaned accumulator 390
21/02/17 01:41:38 INFO ContextCleaner: Cleaned accumulator 407
21/02/17 01:41:38 INFO ContextCleaner: Cleaned accumulator 452
21/02/17 01:41:38 INFO ContextCleaner: Cleaned accumulator 366
21/02/17 01:41:38 INFO ContextCleaner: Cleaned accumulator 410
21/02/17 01:41:38 INFO ContextCleaner: Cleaned accumulator 379
21/02/17 01:41:38 INFO ContextCleaner: Cleaned accumulator 408
21/02/17 01:41:38 INFO ContextCleaner: Cleaned accumulator 367
21/02/17 01:41:38 INFO ContextCleaner: Cleaned accumulator 288
21/02/17 01:41:38 INFO BlockManagerInfo: Removed broadcast_8_piece0 on localhost:41253 in memory (size: 13.7 KB, free: 912.2 MB)
21/02/17 01:41:38 INFO ContextCleaner: Cleaned accumulator 232
21/02/17 01:41:38 INFO ContextCleaner: Cleaned accumulator 312
21/02/17 01:41:38 INFO ContextCleaner: Cleaned accumulator 369
21/02/17 01:41:38 INFO ContextCleaner: Cleaned accumulator 308
21/02/17 01:41:38 INFO ContextCleaner: Cleaned accumulator 310
21/02/17 01:41:38 INFO ContextCleaner: Cleaned accumulator 340
21/02/17 01:41:38 INFO ContextCleaner: Cleaned accumulator 357
21/02/17 01:41:38 INFO ContextCleaner: Cleaned accumulator 392
21/02/17 01:41:38 INFO ContextCleaner: Cleaned accumulator 287
21/02/17 01:41:38 INFO ContextCleaner: Cleaned accumulator 360
21/02/17 01:41:38 INFO ContextCleaner: Cleaned accumulator 251
21/02/17 01:41:38 INFO ContextCleaner: Cleaned accumulator 414
21/02/17 01:41:38 INFO ContextCleaner: Cleaned accumulator 421
21/02/17 01:41:38 INFO ContextCleaner: Cleaned accumulator 437
21/02/17 01:41:38 INFO ContextCleaner: Cleaned accumulator 345
21/02/17 01:41:38 INFO ContextCleaner: Cleaned accumulator 219
21/02/17 01:41:38 INFO ContextCleaner: Cleaned accumulator 273
21/02/17 01:41:38 INFO ContextCleaner: Cleaned accumulator 469
21/02/17 01:41:38 INFO ContextCleaner: Cleaned accumulator 376
21/02/17 01:41:38 INFO ContextCleaner: Cleaned accumulator 432
21/02/17 01:41:38 INFO ContextCleaner: Cleaned accumulator 294
21/02/17 01:41:38 INFO ContextCleaner: Cleaned accumulator 349
21/02/17 01:41:38 INFO ContextCleaner: Cleaned accumulator 467
21/02/17 01:41:38 INFO ContextCleaner: Cleaned accumulator 439
21/02/17 01:41:38 INFO ContextCleaner: Cleaned accumulator 451
21/02/17 01:41:38 INFO ContextCleaner: Cleaned accumulator 326
21/02/17 01:41:38 INFO ContextCleaner: Cleaned accumulator 339
21/02/17 01:41:38 INFO ContextCleaner: Cleaned accumulator 350
21/02/17 01:41:38 INFO ContextCleaner: Cleaned accumulator 244
21/02/17 01:41:38 INFO ContextCleaner: Cleaned accumulator 386
21/02/17 01:41:38 INFO ContextCleaner: Cleaned accumulator 473
21/02/17 01:41:38 INFO ContextCleaner: Cleaned accumulator 474
21/02/17 01:41:38 INFO ContextCleaner: Cleaned accumulator 434
21/02/17 01:41:38 INFO ContextCleaner: Cleaned accumulator 384
21/02/17 01:41:38 INFO ContextCleaner: Cleaned accumulator 438
21/02/17 01:41:38 INFO BlockManagerInfo: Removed broadcast_13_piece0 on localhost:41253 in memory (size: 25.4 KB, free: 912.2 MB)
21/02/17 01:41:38 INFO ContextCleaner: Cleaned accumulator 382
21/02/17 01:41:38 INFO ContextCleaner: Cleaned accumulator 235
21/02/17 01:41:38 INFO ContextCleaner: Cleaned accumulator 397
21/02/17 01:41:38 INFO ContextCleaner: Cleaned accumulator 454
21/02/17 01:41:38 INFO ContextCleaner: Cleaned accumulator 372
21/02/17 01:41:38 INFO ContextCleaner: Cleaned accumulator 286
21/02/17 01:41:38 INFO ContextCleaner: Cleaned accumulator 243
21/02/17 01:41:38 INFO ContextCleaner: Cleaned accumulator 242
21/02/17 01:41:38 INFO ContextCleaner: Cleaned accumulator 257
21/02/17 01:41:38 INFO ContextCleaner: Cleaned accumulator 221
21/02/17 01:41:38 INFO ContextCleaner: Cleaned accumulator 351
21/02/17 01:41:38 INFO ContextCleaner: Cleaned accumulator 292
21/02/17 01:41:38 INFO ContextCleaner: Cleaned accumulator 233
21/02/17 01:41:38 INFO ContextCleaner: Cleaned accumulator 321
21/02/17 01:41:38 INFO BlockManagerInfo: Removed broadcast_12_piece0 on localhost:41253 in memory (size: 3.8 KB, free: 912.2 MB)
21/02/17 01:41:38 INFO ContextCleaner: Cleaned accumulator 284
21/02/17 01:41:38 INFO ContextCleaner: Cleaned accumulator 361
21/02/17 01:41:38 INFO ContextCleaner: Cleaned accumulator 241
21/02/17 01:41:38 INFO ContextCleaner: Cleaned accumulator 252
21/02/17 01:41:38 INFO ContextCleaner: Cleaned accumulator 274
21/02/17 01:41:38 INFO ContextCleaner: Cleaned accumulator 358
21/02/17 01:41:38 INFO ContextCleaner: Cleaned accumulator 355
21/02/17 01:41:38 INFO ContextCleaner: Cleaned accumulator 337
21/02/17 01:41:38 INFO ContextCleaner: Cleaned accumulator 348
21/02/17 01:41:38 INFO ContextCleaner: Cleaned accumulator 435
21/02/17 01:41:38 INFO ContextCleaner: Cleaned accumulator 278
21/02/17 01:41:38 INFO ContextCleaner: Cleaned accumulator 280
21/02/17 01:41:38 INFO ContextCleaner: Cleaned accumulator 323
21/02/17 01:41:38 INFO ContextCleaner: Cleaned accumulator 466
21/02/17 01:41:38 INFO ContextCleaner: Cleaned accumulator 329
21/02/17 01:41:38 INFO ContextCleaner: Cleaned accumulator 433
21/02/17 01:41:38 INFO ContextCleaner: Cleaned accumulator 282
21/02/17 01:41:38 INFO ContextCleaner: Cleaned accumulator 269
21/02/17 01:41:38 INFO ContextCleaner: Cleaned accumulator 277
21/02/17 01:41:38 INFO ContextCleaner: Cleaned accumulator 313
21/02/17 01:41:38 INFO ContextCleaner: Cleaned accumulator 443
21/02/17 01:41:38 INFO BlockManagerInfo: Removed broadcast_11_piece0 on localhost:41253 in memory (size: 4.5 KB, free: 912.2 MB)
21/02/17 01:41:38 INFO HadoopMapRedCommitProtocol: Using output committer class org.apache.hadoop.mapred.FileOutputCommitter
21/02/17 01:41:38 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
21/02/17 01:41:38 INFO ContextCleaner: Cleaned shuffle 2
21/02/17 01:41:38 INFO ContextCleaner: Cleaned accumulator 464
21/02/17 01:41:38 INFO ContextCleaner: Cleaned accumulator 256
21/02/17 01:41:38 INFO ContextCleaner: Cleaned accumulator 343
21/02/17 01:41:38 INFO ContextCleaner: Cleaned accumulator 400
21/02/17 01:41:38 INFO ContextCleaner: Cleaned accumulator 383
21/02/17 01:41:38 INFO ContextCleaner: Cleaned accumulator 226
21/02/17 01:41:38 INFO ContextCleaner: Cleaned accumulator 424
21/02/17 01:41:38 INFO ContextCleaner: Cleaned accumulator 218
21/02/17 01:41:38 INFO ContextCleaner: Cleaned accumulator 248
21/02/17 01:41:38 INFO ContextCleaner: Cleaned accumulator 300
21/02/17 01:41:38 INFO ContextCleaner: Cleaned accumulator 309
21/02/17 01:41:38 INFO ContextCleaner: Cleaned accumulator 461
21/02/17 01:41:38 INFO ContextCleaner: Cleaned accumulator 236
21/02/17 01:41:38 INFO ContextCleaner: Cleaned accumulator 261
21/02/17 01:41:38 INFO ContextCleaner: Cleaned accumulator 331
21/02/17 01:41:38 INFO ContextCleaner: Cleaned accumulator 417
21/02/17 01:41:38 INFO ContextCleaner: Cleaned accumulator 471
21/02/17 01:41:38 INFO ContextCleaner: Cleaned accumulator 305
21/02/17 01:41:38 INFO ContextCleaner: Cleaned accumulator 409
21/02/17 01:41:38 INFO ContextCleaner: Cleaned accumulator 402
21/02/17 01:41:38 INFO ContextCleaner: Cleaned accumulator 373
21/02/17 01:41:38 INFO ContextCleaner: Cleaned accumulator 375
21/02/17 01:41:38 INFO ContextCleaner: Cleaned accumulator 475
21/02/17 01:41:38 INFO ContextCleaner: Cleaned accumulator 324
21/02/17 01:41:38 INFO ContextCleaner: Cleaned accumulator 333
21/02/17 01:41:38 INFO ContextCleaner: Cleaned accumulator 314
21/02/17 01:41:38 INFO ContextCleaner: Cleaned accumulator 271
21/02/17 01:41:38 INFO ContextCleaner: Cleaned accumulator 365
21/02/17 01:41:38 INFO ContextCleaner: Cleaned accumulator 460
21/02/17 01:41:38 INFO ContextCleaner: Cleaned accumulator 362
21/02/17 01:41:38 INFO ContextCleaner: Cleaned accumulator 418
21/02/17 01:41:38 INFO ContextCleaner: Cleaned accumulator 290
21/02/17 01:41:38 INFO ContextCleaner: Cleaned accumulator 213
21/02/17 01:41:38 INFO ContextCleaner: Cleaned accumulator 388
21/02/17 01:41:38 INFO ContextCleaner: Cleaned accumulator 447
21/02/17 01:41:38 INFO ContextCleaner: Cleaned accumulator 415
21/02/17 01:41:38 INFO ContextCleaner: Cleaned accumulator 223
21/02/17 01:41:38 INFO ContextCleaner: Cleaned accumulator 381
21/02/17 01:41:38 INFO ContextCleaner: Cleaned accumulator 295
21/02/17 01:41:38 INFO ContextCleaner: Cleaned accumulator 317
21/02/17 01:41:38 INFO ContextCleaner: Cleaned accumulator 346
21/02/17 01:41:38 INFO ContextCleaner: Cleaned accumulator 378
21/02/17 01:41:38 INFO ContextCleaner: Cleaned accumulator 316
21/02/17 01:41:38 INFO ContextCleaner: Cleaned accumulator 322
21/02/17 01:41:38 INFO ContextCleaner: Cleaned accumulator 356
21/02/17 01:41:38 INFO ContextCleaner: Cleaned accumulator 363
21/02/17 01:41:38 INFO ContextCleaner: Cleaned accumulator 450
21/02/17 01:41:38 INFO ContextCleaner: Cleaned accumulator 237
21/02/17 01:41:38 INFO ContextCleaner: Cleaned accumulator 449
21/02/17 01:41:38 INFO ContextCleaner: Cleaned accumulator 406
21/02/17 01:41:38 INFO ContextCleaner: Cleaned accumulator 403
21/02/17 01:41:38 INFO ContextCleaner: Cleaned accumulator 364
21/02/17 01:41:38 INFO ContextCleaner: Cleaned accumulator 391
21/02/17 01:41:38 INFO ContextCleaner: Cleaned accumulator 396
21/02/17 01:41:38 INFO ContextCleaner: Cleaned accumulator 240
21/02/17 01:41:38 INFO ContextCleaner: Cleaned accumulator 399
21/02/17 01:41:38 INFO ContextCleaner: Cleaned accumulator 297
21/02/17 01:41:38 INFO ContextCleaner: Cleaned accumulator 404
21/02/17 01:41:38 INFO ContextCleaner: Cleaned accumulator 246
21/02/17 01:41:38 INFO ContextCleaner: Cleaned accumulator 448
21/02/17 01:41:38 INFO ContextCleaner: Cleaned accumulator 374
21/02/17 01:41:38 INFO ContextCleaner: Cleaned accumulator 272
21/02/17 01:41:38 INFO ContextCleaner: Cleaned accumulator 302
21/02/17 01:41:38 INFO ContextCleaner: Cleaned accumulator 427
21/02/17 01:41:38 INFO ContextCleaner: Cleaned accumulator 344
21/02/17 01:41:38 INFO ContextCleaner: Cleaned accumulator 470
21/02/17 01:41:38 INFO ContextCleaner: Cleaned accumulator 342
21/02/17 01:41:38 INFO ContextCleaner: Cleaned accumulator 472
21/02/17 01:41:38 INFO BlockManagerInfo: Removed broadcast_16_piece0 on localhost:41253 in memory (size: 25.4 KB, free: 912.2 MB)
21/02/17 01:41:38 INFO ContextCleaner: Cleaned accumulator 276
21/02/17 01:41:38 INFO ContextCleaner: Cleaned accumulator 306
21/02/17 01:41:38 INFO ContextCleaner: Cleaned accumulator 423
21/02/17 01:41:38 INFO ContextCleaner: Cleaned accumulator 270
21/02/17 01:41:38 INFO ContextCleaner: Cleaned accumulator 283
21/02/17 01:41:38 INFO ContextCleaner: Cleaned accumulator 401
21/02/17 01:41:38 INFO ContextCleaner: Cleaned accumulator 419
21/02/17 01:41:38 INFO ContextCleaner: Cleaned accumulator 325
21/02/17 01:41:38 INFO ContextCleaner: Cleaned accumulator 468
21/02/17 01:41:38 INFO ContextCleaner: Cleaned accumulator 318
21/02/17 01:41:38 INFO ContextCleaner: Cleaned accumulator 328
21/02/17 01:41:38 INFO BlockManagerInfo: Removed broadcast_15_piece0 on localhost:41253 in memory (size: 3.8 KB, free: 912.2 MB)
21/02/17 01:41:38 INFO FileOutputCommitter: Saved output of task 'attempt_20210217014138_0065_m_000000_0' to file:/tmp/Rtmp09Oz4e/file22e22736a8feb/stages/0_r_formula__9467ebc0_1e9a_44aa_b6e1_220b95e6649f/metadata/_temporary/0/task_20210217014138_0065_m_000000
21/02/17 01:41:38 INFO SparkHadoopMapRedUtil: attempt_20210217014138_0065_m_000000_0: Committed
21/02/17 01:41:38 INFO Executor: Finished task 0.0 in stage 16.0 (TID 16). 1029 bytes result sent to driver
21/02/17 01:41:38 INFO ContextCleaner: Cleaned accumulator 476
21/02/17 01:41:38 INFO ContextCleaner: Cleaned accumulator 335
21/02/17 01:41:38 INFO ContextCleaner: Cleaned accumulator 394
21/02/17 01:41:38 INFO ContextCleaner: Cleaned accumulator 405
21/02/17 01:41:38 INFO ContextCleaner: Cleaned accumulator 262
21/02/17 01:41:38 INFO ContextCleaner: Cleaned accumulator 296
21/02/17 01:41:38 INFO ContextCleaner: Cleaned accumulator 263
21/02/17 01:41:38 INFO ContextCleaner: Cleaned accumulator 220
21/02/17 01:41:38 INFO ContextCleaner: Cleaned accumulator 253
21/02/17 01:41:38 INFO TaskSetManager: Finished task 0.0 in stage 16.0 (TID 16) in 22 ms on localhost (executor driver) (1/1)
21/02/17 01:41:38 INFO TaskSchedulerImpl: Removed TaskSet 16.0, whose tasks have all completed, from pool 
21/02/17 01:41:38 INFO DAGScheduler: ResultStage 16 (runJob at SparkHadoopWriter.scala:78) finished in 0.050 s
21/02/17 01:41:38 INFO DAGScheduler: Job 12 finished: runJob at SparkHadoopWriter.scala:78, took 0.052348 s
21/02/17 01:41:38 INFO BlockManagerInfo: Removed broadcast_14_piece0 on localhost:41253 in memory (size: 25.9 KB, free: 912.3 MB)
21/02/17 01:41:38 INFO ContextCleaner: Cleaned accumulator 216
21/02/17 01:41:38 INFO ContextCleaner: Cleaned accumulator 249
21/02/17 01:41:38 INFO ContextCleaner: Cleaned accumulator 298
21/02/17 01:41:38 INFO ContextCleaner: Cleaned accumulator 327
21/02/17 01:41:38 INFO ContextCleaner: Cleaned accumulator 247
21/02/17 01:41:38 INFO ContextCleaner: Cleaned accumulator 456
21/02/17 01:41:38 INFO ContextCleaner: Cleaned accumulator 463
21/02/17 01:41:38 INFO BlockManager: Removing RDD 35
21/02/17 01:41:38 INFO ContextCleaner: Cleaned RDD 35
21/02/17 01:41:38 INFO ContextCleaner: Cleaned accumulator 234
21/02/17 01:41:38 INFO ContextCleaner: Cleaned accumulator 289
21/02/17 01:41:38 INFO ContextCleaner: Cleaned accumulator 453
21/02/17 01:41:38 INFO ContextCleaner: Cleaned accumulator 259
21/02/17 01:41:38 INFO ContextCleaner: Cleaned accumulator 354
21/02/17 01:41:38 INFO ContextCleaner: Cleaned accumulator 268
21/02/17 01:41:38 INFO ContextCleaner: Cleaned accumulator 444
21/02/17 01:41:38 INFO ContextCleaner: Cleaned accumulator 239
21/02/17 01:41:38 INFO ContextCleaner: Cleaned accumulator 393
21/02/17 01:41:38 INFO ContextCleaner: Cleaned accumulator 440
21/02/17 01:41:38 INFO SparkHadoopWriter: Job job_20210217014138_0065 committed.
21/02/17 01:41:38 INFO ContextCleaner: Cleaned shuffle 3
21/02/17 01:41:38 INFO ContextCleaner: Cleaned accumulator 422
21/02/17 01:41:38 INFO ContextCleaner: Cleaned accumulator 238
21/02/17 01:41:38 INFO ContextCleaner: Cleaned accumulator 230
21/02/17 01:41:38 INFO ContextCleaner: Cleaned accumulator 416
21/02/17 01:41:38 INFO ContextCleaner: Cleaned accumulator 459
21/02/17 01:41:38 INFO ContextCleaner: Cleaned accumulator 420
21/02/17 01:41:38 INFO ContextCleaner: Cleaned accumulator 260
21/02/17 01:41:38 INFO ContextCleaner: Cleaned accumulator 341
21/02/17 01:41:38 INFO ContextCleaner: Cleaned accumulator 255
21/02/17 01:41:38 INFO ContextCleaner: Cleaned accumulator 353
21/02/17 01:41:38 INFO BlockManagerInfo: Removed broadcast_10_piece0 on localhost:41253 in memory (size: 3.3 KB, free: 912.3 MB)
21/02/17 01:41:38 INFO ContextCleaner: Cleaned accumulator 442
21/02/17 01:41:38 INFO ContextCleaner: Cleaned accumulator 446
21/02/17 01:41:38 INFO ContextCleaner: Cleaned accumulator 299
21/02/17 01:41:38 INFO ContextCleaner: Cleaned accumulator 425
21/02/17 01:41:38 INFO ContextCleaner: Cleaned accumulator 279
21/02/17 01:41:38 INFO ContextCleaner: Cleaned accumulator 426
21/02/17 01:41:38 INFO ContextCleaner: Cleaned accumulator 412
21/02/17 01:41:38 INFO ContextCleaner: Cleaned accumulator 371
21/02/17 01:41:39 INFO ParquetFileFormat: Using default output committer for Parquet: org.apache.parquet.hadoop.ParquetOutputCommitter
21/02/17 01:41:39 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
21/02/17 01:41:39 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
21/02/17 01:41:39 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
21/02/17 01:41:39 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
21/02/17 01:41:39 INFO CodeGenerator: Code generated in 7.693408 ms
21/02/17 01:41:39 INFO SparkContext: Starting job: parquet at RFormula.scala:422
21/02/17 01:41:39 INFO DAGScheduler: Registering RDD 68 (parquet at RFormula.scala:422)
21/02/17 01:41:39 INFO DAGScheduler: Got job 13 (parquet at RFormula.scala:422) with 1 output partitions
21/02/17 01:41:39 INFO DAGScheduler: Final stage: ResultStage 18 (parquet at RFormula.scala:422)
21/02/17 01:41:39 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 17)
21/02/17 01:41:39 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 17)
21/02/17 01:41:39 INFO DAGScheduler: Submitting ShuffleMapStage 17 (MapPartitionsRDD[68] at parquet at RFormula.scala:422), which has no missing parents
21/02/17 01:41:39 INFO MemoryStore: Block broadcast_18 stored as values in memory (estimated size 5.0 KB, free 912.2 MB)
21/02/17 01:41:39 INFO MemoryStore: Block broadcast_18_piece0 stored as bytes in memory (estimated size 3.0 KB, free 912.2 MB)
21/02/17 01:41:39 INFO BlockManagerInfo: Added broadcast_18_piece0 in memory on localhost:41253 (size: 3.0 KB, free: 912.3 MB)
21/02/17 01:41:39 INFO SparkContext: Created broadcast 18 from broadcast at DAGScheduler.scala:1161
21/02/17 01:41:39 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 17 (MapPartitionsRDD[68] at parquet at RFormula.scala:422) (first 15 tasks are for partitions Vector(0))
21/02/17 01:41:39 INFO TaskSchedulerImpl: Adding task set 17.0 with 1 tasks
21/02/17 01:41:39 INFO TaskSetManager: Starting task 0.0 in stage 17.0 (TID 17, localhost, executor driver, partition 0, PROCESS_LOCAL, 8177 bytes)
21/02/17 01:41:39 INFO Executor: Running task 0.0 in stage 17.0 (TID 17)
21/02/17 01:41:39 INFO Executor: Finished task 0.0 in stage 17.0 (TID 17). 1247 bytes result sent to driver
21/02/17 01:41:39 INFO TaskSetManager: Finished task 0.0 in stage 17.0 (TID 17) in 4 ms on localhost (executor driver) (1/1)
21/02/17 01:41:39 INFO TaskSchedulerImpl: Removed TaskSet 17.0, whose tasks have all completed, from pool 
21/02/17 01:41:39 INFO DAGScheduler: ShuffleMapStage 17 (parquet at RFormula.scala:422) finished in 0.011 s
21/02/17 01:41:39 INFO DAGScheduler: looking for newly runnable stages
21/02/17 01:41:39 INFO DAGScheduler: running: Set()
21/02/17 01:41:39 INFO DAGScheduler: waiting: Set(ResultStage 18)
21/02/17 01:41:39 INFO DAGScheduler: failed: Set()
21/02/17 01:41:39 INFO DAGScheduler: Submitting ResultStage 18 (ShuffledRowRDD[69] at parquet at RFormula.scala:422), which has no missing parents
21/02/17 01:41:39 INFO MemoryStore: Block broadcast_19 stored as values in memory (estimated size 151.0 KB, free 912.0 MB)
21/02/17 01:41:39 INFO MemoryStore: Block broadcast_19_piece0 stored as bytes in memory (estimated size 53.6 KB, free 912.0 MB)
21/02/17 01:41:39 INFO BlockManagerInfo: Added broadcast_19_piece0 in memory on localhost:41253 (size: 53.6 KB, free: 912.2 MB)
21/02/17 01:41:39 INFO SparkContext: Created broadcast 19 from broadcast at DAGScheduler.scala:1161
21/02/17 01:41:39 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 18 (ShuffledRowRDD[69] at parquet at RFormula.scala:422) (first 15 tasks are for partitions Vector(0))
21/02/17 01:41:39 INFO TaskSchedulerImpl: Adding task set 18.0 with 1 tasks
21/02/17 01:41:39 INFO TaskSetManager: Starting task 0.0 in stage 18.0 (TID 18, localhost, executor driver, partition 0, NODE_LOCAL, 7767 bytes)
21/02/17 01:41:39 INFO Executor: Running task 0.0 in stage 18.0 (TID 18)
21/02/17 01:41:39 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks including 1 local blocks and 0 remote blocks
21/02/17 01:41:39 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
21/02/17 01:41:39 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
21/02/17 01:41:39 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
21/02/17 01:41:39 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
21/02/17 01:41:39 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
21/02/17 01:41:39 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:
{
  "type" : "struct",
  "fields" : [ {
    "name" : "label",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "terms",
    "type" : {
      "type" : "array",
      "elementType" : {
        "type" : "array",
        "elementType" : "string",
        "containsNull" : true
      },
      "containsNull" : true
    },
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "hasIntercept",
    "type" : "boolean",
    "nullable" : false,
    "metadata" : { }
  } ]
}
and corresponding Parquet message type:
message spark_schema {
  optional binary label (UTF8);
  optional group terms (LIST) {
    repeated group list {
      optional group element (LIST) {
        repeated group list {
          optional binary element (UTF8);
        }
      }
    }
  }
  required boolean hasIntercept;
}

       
21/02/17 01:41:39 INFO CodecPool: Got brand-new compressor [.snappy]
21/02/17 01:41:39 INFO FileOutputCommitter: Saved output of task 'attempt_20210217014139_0018_m_000000_18' to file:/tmp/Rtmp09Oz4e/file22e22736a8feb/stages/0_r_formula__9467ebc0_1e9a_44aa_b6e1_220b95e6649f/data/_temporary/0/task_20210217014139_0018_m_000000
21/02/17 01:41:39 INFO SparkHadoopMapRedUtil: attempt_20210217014139_0018_m_000000_18: Committed
21/02/17 01:41:39 INFO Executor: Finished task 0.0 in stage 18.0 (TID 18). 2334 bytes result sent to driver
21/02/17 01:41:39 INFO TaskSetManager: Finished task 0.0 in stage 18.0 (TID 18) in 298 ms on localhost (executor driver) (1/1)
21/02/17 01:41:39 INFO TaskSchedulerImpl: Removed TaskSet 18.0, whose tasks have all completed, from pool 
21/02/17 01:41:39 INFO DAGScheduler: ResultStage 18 (parquet at RFormula.scala:422) finished in 0.321 s
21/02/17 01:41:39 INFO DAGScheduler: Job 13 finished: parquet at RFormula.scala:422, took 0.335487 s
21/02/17 01:41:39 INFO FileFormatWriter: Write Job 38e44a1d-4036-4cbc-b2fe-251339f6fb46 committed.
21/02/17 01:41:39 INFO FileFormatWriter: Finished processing stats for write job 38e44a1d-4036-4cbc-b2fe-251339f6fb46.
21/02/17 01:41:39 INFO HadoopMapRedCommitProtocol: Using output committer class org.apache.hadoop.mapred.FileOutputCommitter
21/02/17 01:41:39 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
21/02/17 01:41:39 INFO SparkContext: Starting job: runJob at SparkHadoopWriter.scala:78
21/02/17 01:41:39 INFO DAGScheduler: Got job 14 (runJob at SparkHadoopWriter.scala:78) with 1 output partitions
21/02/17 01:41:39 INFO DAGScheduler: Final stage: ResultStage 19 (runJob at SparkHadoopWriter.scala:78)
21/02/17 01:41:39 INFO DAGScheduler: Parents of final stage: List()
21/02/17 01:41:39 INFO DAGScheduler: Missing parents: List()
21/02/17 01:41:39 INFO DAGScheduler: Submitting ResultStage 19 (MapPartitionsRDD[72] at saveAsTextFile at ReadWrite.scala:441), which has no missing parents
21/02/17 01:41:39 INFO MemoryStore: Block broadcast_20 stored as values in memory (estimated size 71.3 KB, free 911.9 MB)
21/02/17 01:41:39 INFO MemoryStore: Block broadcast_20_piece0 stored as bytes in memory (estimated size 25.6 KB, free 911.9 MB)
21/02/17 01:41:39 INFO BlockManagerInfo: Added broadcast_20_piece0 in memory on localhost:41253 (size: 25.6 KB, free: 912.2 MB)
21/02/17 01:41:39 INFO SparkContext: Created broadcast 20 from broadcast at DAGScheduler.scala:1161
21/02/17 01:41:39 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 19 (MapPartitionsRDD[72] at saveAsTextFile at ReadWrite.scala:441) (first 15 tasks are for partitions Vector(0))
21/02/17 01:41:39 INFO TaskSchedulerImpl: Adding task set 19.0 with 1 tasks
21/02/17 01:41:39 INFO TaskSetManager: Starting task 0.0 in stage 19.0 (TID 19, localhost, executor driver, partition 0, PROCESS_LOCAL, 8181 bytes)
21/02/17 01:41:39 INFO Executor: Running task 0.0 in stage 19.0 (TID 19)
21/02/17 01:41:39 INFO HadoopMapRedCommitProtocol: Using output committer class org.apache.hadoop.mapred.FileOutputCommitter
21/02/17 01:41:39 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
21/02/17 01:41:39 INFO FileOutputCommitter: Saved output of task 'attempt_20210217014139_0072_m_000000_0' to file:/tmp/Rtmp09Oz4e/file22e22736a8feb/stages/0_r_formula__9467ebc0_1e9a_44aa_b6e1_220b95e6649f/pipelineModel/metadata/_temporary/0/task_20210217014139_0072_m_000000
21/02/17 01:41:39 INFO SparkHadoopMapRedUtil: attempt_20210217014139_0072_m_000000_0: Committed
21/02/17 01:41:39 INFO Executor: Finished task 0.0 in stage 19.0 (TID 19). 1029 bytes result sent to driver
21/02/17 01:41:39 INFO TaskSetManager: Finished task 0.0 in stage 19.0 (TID 19) in 16 ms on localhost (executor driver) (1/1)
21/02/17 01:41:39 INFO TaskSchedulerImpl: Removed TaskSet 19.0, whose tasks have all completed, from pool 
21/02/17 01:41:39 INFO DAGScheduler: ResultStage 19 (runJob at SparkHadoopWriter.scala:78) finished in 0.031 s
21/02/17 01:41:39 INFO DAGScheduler: Job 14 finished: runJob at SparkHadoopWriter.scala:78, took 0.033115 s
21/02/17 01:41:39 INFO SparkHadoopWriter: Job job_20210217014139_0072 committed.
21/02/17 01:41:39 INFO HadoopMapRedCommitProtocol: Using output committer class org.apache.hadoop.mapred.FileOutputCommitter
21/02/17 01:41:39 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
21/02/17 01:41:39 INFO SparkContext: Starting job: runJob at SparkHadoopWriter.scala:78
21/02/17 01:41:39 INFO DAGScheduler: Got job 15 (runJob at SparkHadoopWriter.scala:78) with 1 output partitions
21/02/17 01:41:39 INFO DAGScheduler: Final stage: ResultStage 20 (runJob at SparkHadoopWriter.scala:78)
21/02/17 01:41:39 INFO DAGScheduler: Parents of final stage: List()
21/02/17 01:41:39 INFO DAGScheduler: Missing parents: List()
21/02/17 01:41:39 INFO DAGScheduler: Submitting ResultStage 20 (MapPartitionsRDD[74] at saveAsTextFile at ReadWrite.scala:441), which has no missing parents
21/02/17 01:41:39 INFO MemoryStore: Block broadcast_21 stored as values in memory (estimated size 71.4 KB, free 911.8 MB)
21/02/17 01:41:39 INFO MemoryStore: Block broadcast_21_piece0 stored as bytes in memory (estimated size 25.5 KB, free 911.8 MB)
21/02/17 01:41:39 INFO BlockManagerInfo: Added broadcast_21_piece0 in memory on localhost:41253 (size: 25.5 KB, free: 912.2 MB)
21/02/17 01:41:39 INFO SparkContext: Created broadcast 21 from broadcast at DAGScheduler.scala:1161
21/02/17 01:41:39 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 20 (MapPartitionsRDD[74] at saveAsTextFile at ReadWrite.scala:441) (first 15 tasks are for partitions Vector(0))
21/02/17 01:41:39 INFO TaskSchedulerImpl: Adding task set 20.0 with 1 tasks
21/02/17 01:41:39 INFO TaskSetManager: Starting task 0.0 in stage 20.0 (TID 20, localhost, executor driver, partition 0, PROCESS_LOCAL, 8248 bytes)
21/02/17 01:41:39 INFO Executor: Running task 0.0 in stage 20.0 (TID 20)
21/02/17 01:41:39 INFO HadoopMapRedCommitProtocol: Using output committer class org.apache.hadoop.mapred.FileOutputCommitter
21/02/17 01:41:39 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
21/02/17 01:41:39 INFO FileOutputCommitter: Saved output of task 'attempt_20210217014139_0074_m_000000_0' to file:/tmp/Rtmp09Oz4e/file22e22736a8feb/stages/0_r_formula__9467ebc0_1e9a_44aa_b6e1_220b95e6649f/pipelineModel/stages/0_r_formula__9467ebc0_1e9a_44aa_b6e1_220b95e6649f/metadata/_temporary/0/task_20210217014139_0074_m_000000
21/02/17 01:41:39 INFO SparkHadoopMapRedUtil: attempt_20210217014139_0074_m_000000_0: Committed
21/02/17 01:41:39 INFO Executor: Finished task 0.0 in stage 20.0 (TID 20). 1072 bytes result sent to driver
21/02/17 01:41:39 INFO TaskSetManager: Finished task 0.0 in stage 20.0 (TID 20) in 17 ms on localhost (executor driver) (1/1)
21/02/17 01:41:39 INFO TaskSchedulerImpl: Removed TaskSet 20.0, whose tasks have all completed, from pool 
21/02/17 01:41:39 INFO DAGScheduler: ResultStage 20 (runJob at SparkHadoopWriter.scala:78) finished in 0.028 s
21/02/17 01:41:39 INFO DAGScheduler: Job 15 finished: runJob at SparkHadoopWriter.scala:78, took 0.029341 s
21/02/17 01:41:39 INFO SparkHadoopWriter: Job job_20210217014139_0074 committed.
21/02/17 01:41:39 INFO HadoopMapRedCommitProtocol: Using output committer class org.apache.hadoop.mapred.FileOutputCommitter
21/02/17 01:41:39 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
21/02/17 01:41:39 INFO SparkContext: Starting job: runJob at SparkHadoopWriter.scala:78
21/02/17 01:41:39 INFO DAGScheduler: Got job 16 (runJob at SparkHadoopWriter.scala:78) with 1 output partitions
21/02/17 01:41:39 INFO DAGScheduler: Final stage: ResultStage 21 (runJob at SparkHadoopWriter.scala:78)
21/02/17 01:41:39 INFO DAGScheduler: Parents of final stage: List()
21/02/17 01:41:39 INFO DAGScheduler: Missing parents: List()
21/02/17 01:41:39 INFO DAGScheduler: Submitting ResultStage 21 (MapPartitionsRDD[76] at saveAsTextFile at ReadWrite.scala:441), which has no missing parents
21/02/17 01:41:39 INFO MemoryStore: Block broadcast_22 stored as values in memory (estimated size 71.3 KB, free 911.7 MB)
21/02/17 01:41:39 INFO MemoryStore: Block broadcast_22_piece0 stored as bytes in memory (estimated size 25.6 KB, free 911.7 MB)
21/02/17 01:41:39 INFO BlockManagerInfo: Added broadcast_22_piece0 in memory on localhost:41253 (size: 25.6 KB, free: 912.1 MB)
21/02/17 01:41:39 INFO SparkContext: Created broadcast 22 from broadcast at DAGScheduler.scala:1161
21/02/17 01:41:39 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 21 (MapPartitionsRDD[76] at saveAsTextFile at ReadWrite.scala:441) (first 15 tasks are for partitions Vector(0))
21/02/17 01:41:39 INFO TaskSchedulerImpl: Adding task set 21.0 with 1 tasks
21/02/17 01:41:39 INFO TaskSetManager: Starting task 0.0 in stage 21.0 (TID 21, localhost, executor driver, partition 0, PROCESS_LOCAL, 8058 bytes)
21/02/17 01:41:39 INFO Executor: Running task 0.0 in stage 21.0 (TID 21)
21/02/17 01:41:39 INFO HadoopMapRedCommitProtocol: Using output committer class org.apache.hadoop.mapred.FileOutputCommitter
21/02/17 01:41:39 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
21/02/17 01:41:39 INFO FileOutputCommitter: Saved output of task 'attempt_20210217014139_0076_m_000000_0' to file:/tmp/Rtmp09Oz4e/file22e22736a8feb/stages/0_r_formula__9467ebc0_1e9a_44aa_b6e1_220b95e6649f/pipelineModel/stages/1_vectorAttrRewriter_f6945e4c4508/metadata/_temporary/0/task_20210217014139_0076_m_000000
21/02/17 01:41:39 INFO SparkHadoopMapRedUtil: attempt_20210217014139_0076_m_000000_0: Committed
21/02/17 01:41:39 INFO Executor: Finished task 0.0 in stage 21.0 (TID 21). 1029 bytes result sent to driver
21/02/17 01:41:39 INFO TaskSetManager: Finished task 0.0 in stage 21.0 (TID 21) in 13 ms on localhost (executor driver) (1/1)
21/02/17 01:41:39 INFO TaskSchedulerImpl: Removed TaskSet 21.0, whose tasks have all completed, from pool 
21/02/17 01:41:39 INFO DAGScheduler: ResultStage 21 (runJob at SparkHadoopWriter.scala:78) finished in 0.021 s
21/02/17 01:41:39 INFO DAGScheduler: Job 16 finished: runJob at SparkHadoopWriter.scala:78, took 0.023641 s
21/02/17 01:41:39 INFO SparkHadoopWriter: Job job_20210217014139_0076 committed.
21/02/17 01:41:39 INFO ParquetFileFormat: Using default output committer for Parquet: org.apache.parquet.hadoop.ParquetOutputCommitter
21/02/17 01:41:39 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
21/02/17 01:41:39 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
21/02/17 01:41:39 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
21/02/17 01:41:39 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
21/02/17 01:41:39 INFO CodeGenerator: Code generated in 8.078684 ms
21/02/17 01:41:39 INFO SparkContext: Starting job: parquet at RFormula.scala:587
21/02/17 01:41:39 INFO DAGScheduler: Registering RDD 79 (parquet at RFormula.scala:587)
21/02/17 01:41:39 INFO DAGScheduler: Got job 17 (parquet at RFormula.scala:587) with 1 output partitions
21/02/17 01:41:39 INFO DAGScheduler: Final stage: ResultStage 23 (parquet at RFormula.scala:587)
21/02/17 01:41:39 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 22)
21/02/17 01:41:39 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 22)
21/02/17 01:41:39 INFO DAGScheduler: Submitting ShuffleMapStage 22 (MapPartitionsRDD[79] at parquet at RFormula.scala:587), which has no missing parents
21/02/17 01:41:39 INFO MemoryStore: Block broadcast_23 stored as values in memory (estimated size 4.9 KB, free 911.7 MB)
21/02/17 01:41:39 INFO MemoryStore: Block broadcast_23_piece0 stored as bytes in memory (estimated size 3.0 KB, free 911.7 MB)
21/02/17 01:41:39 INFO BlockManagerInfo: Added broadcast_23_piece0 in memory on localhost:41253 (size: 3.0 KB, free: 912.1 MB)
21/02/17 01:41:39 INFO SparkContext: Created broadcast 23 from broadcast at DAGScheduler.scala:1161
21/02/17 01:41:39 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 22 (MapPartitionsRDD[79] at parquet at RFormula.scala:587) (first 15 tasks are for partitions Vector(0))
21/02/17 01:41:39 INFO TaskSchedulerImpl: Adding task set 22.0 with 1 tasks
21/02/17 01:41:39 INFO TaskSetManager: Starting task 0.0 in stage 22.0 (TID 22, localhost, executor driver, partition 0, PROCESS_LOCAL, 8073 bytes)
21/02/17 01:41:39 INFO Executor: Running task 0.0 in stage 22.0 (TID 22)
21/02/17 01:41:39 INFO Executor: Finished task 0.0 in stage 22.0 (TID 22). 1247 bytes result sent to driver
21/02/17 01:41:39 INFO TaskSetManager: Finished task 0.0 in stage 22.0 (TID 22) in 4 ms on localhost (executor driver) (1/1)
21/02/17 01:41:39 INFO TaskSchedulerImpl: Removed TaskSet 22.0, whose tasks have all completed, from pool 
21/02/17 01:41:39 INFO DAGScheduler: ShuffleMapStage 22 (parquet at RFormula.scala:587) finished in 0.008 s
21/02/17 01:41:39 INFO DAGScheduler: looking for newly runnable stages
21/02/17 01:41:39 INFO DAGScheduler: running: Set()
21/02/17 01:41:39 INFO DAGScheduler: waiting: Set(ResultStage 23)
21/02/17 01:41:39 INFO DAGScheduler: failed: Set()
21/02/17 01:41:39 INFO DAGScheduler: Submitting ResultStage 23 (ShuffledRowRDD[80] at parquet at RFormula.scala:587), which has no missing parents
21/02/17 01:41:39 INFO MemoryStore: Block broadcast_24 stored as values in memory (estimated size 151.0 KB, free 911.5 MB)
21/02/17 01:41:39 INFO MemoryStore: Block broadcast_24_piece0 stored as bytes in memory (estimated size 53.6 KB, free 911.5 MB)
21/02/17 01:41:39 INFO BlockManagerInfo: Added broadcast_24_piece0 in memory on localhost:41253 (size: 53.6 KB, free: 912.1 MB)
21/02/17 01:41:39 INFO SparkContext: Created broadcast 24 from broadcast at DAGScheduler.scala:1161
21/02/17 01:41:39 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 23 (ShuffledRowRDD[80] at parquet at RFormula.scala:587) (first 15 tasks are for partitions Vector(0))
21/02/17 01:41:39 INFO TaskSchedulerImpl: Adding task set 23.0 with 1 tasks
21/02/17 01:41:39 INFO TaskSetManager: Starting task 0.0 in stage 23.0 (TID 23, localhost, executor driver, partition 0, NODE_LOCAL, 7767 bytes)
21/02/17 01:41:39 INFO Executor: Running task 0.0 in stage 23.0 (TID 23)
21/02/17 01:41:39 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks including 1 local blocks and 0 remote blocks
21/02/17 01:41:39 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
21/02/17 01:41:39 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
21/02/17 01:41:39 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
21/02/17 01:41:39 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
21/02/17 01:41:39 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
21/02/17 01:41:39 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:
{
  "type" : "struct",
  "fields" : [ {
    "name" : "vectorCol",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "prefixesToRewrite",
    "type" : {
      "type" : "map",
      "keyType" : "string",
      "valueType" : "string",
      "valueContainsNull" : true
    },
    "nullable" : true,
    "metadata" : { }
  } ]
}
and corresponding Parquet message type:
message spark_schema {
  optional binary vectorCol (UTF8);
  optional group prefixesToRewrite (MAP) {
    repeated group key_value {
      required binary key (UTF8);
      optional binary value (UTF8);
    }
  }
}

       
21/02/17 01:41:39 INFO FileOutputCommitter: Saved output of task 'attempt_20210217014139_0023_m_000000_23' to file:/tmp/Rtmp09Oz4e/file22e22736a8feb/stages/0_r_formula__9467ebc0_1e9a_44aa_b6e1_220b95e6649f/pipelineModel/stages/1_vectorAttrRewriter_f6945e4c4508/data/_temporary/0/task_20210217014139_0023_m_000000
21/02/17 01:41:39 INFO SparkHadoopMapRedUtil: attempt_20210217014139_0023_m_000000_23: Committed
21/02/17 01:41:39 INFO Executor: Finished task 0.0 in stage 23.0 (TID 23). 2291 bytes result sent to driver
21/02/17 01:41:39 INFO TaskSetManager: Finished task 0.0 in stage 23.0 (TID 23) in 37 ms on localhost (executor driver) (1/1)
21/02/17 01:41:39 INFO TaskSchedulerImpl: Removed TaskSet 23.0, whose tasks have all completed, from pool 
21/02/17 01:41:39 INFO DAGScheduler: ResultStage 23 (parquet at RFormula.scala:587) finished in 0.054 s
21/02/17 01:41:39 INFO DAGScheduler: Job 17 finished: parquet at RFormula.scala:587, took 0.065380 s
21/02/17 01:41:39 INFO FileFormatWriter: Write Job c4b5b2fc-29bd-43f2-80c3-a720005d7d87 committed.
21/02/17 01:41:39 INFO FileFormatWriter: Finished processing stats for write job c4b5b2fc-29bd-43f2-80c3-a720005d7d87.
21/02/17 01:41:39 INFO HadoopMapRedCommitProtocol: Using output committer class org.apache.hadoop.mapred.FileOutputCommitter
21/02/17 01:41:39 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
21/02/17 01:41:39 INFO SparkContext: Starting job: runJob at SparkHadoopWriter.scala:78
21/02/17 01:41:39 INFO DAGScheduler: Got job 18 (runJob at SparkHadoopWriter.scala:78) with 1 output partitions
21/02/17 01:41:39 INFO DAGScheduler: Final stage: ResultStage 24 (runJob at SparkHadoopWriter.scala:78)
21/02/17 01:41:39 INFO DAGScheduler: Parents of final stage: List()
21/02/17 01:41:39 INFO DAGScheduler: Missing parents: List()
21/02/17 01:41:39 INFO DAGScheduler: Submitting ResultStage 24 (MapPartitionsRDD[83] at saveAsTextFile at ReadWrite.scala:441), which has no missing parents
21/02/17 01:41:39 INFO MemoryStore: Block broadcast_25 stored as values in memory (estimated size 71.3 KB, free 911.4 MB)
21/02/17 01:41:39 INFO MemoryStore: Block broadcast_25_piece0 stored as bytes in memory (estimated size 25.6 KB, free 911.4 MB)
21/02/17 01:41:39 INFO BlockManagerInfo: Added broadcast_25_piece0 in memory on localhost:41253 (size: 25.6 KB, free: 912.1 MB)
21/02/17 01:41:39 INFO SparkContext: Created broadcast 25 from broadcast at DAGScheduler.scala:1161
21/02/17 01:41:39 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 24 (MapPartitionsRDD[83] at saveAsTextFile at ReadWrite.scala:441) (first 15 tasks are for partitions Vector(0))
21/02/17 01:41:39 INFO TaskSchedulerImpl: Adding task set 24.0 with 1 tasks
21/02/17 01:41:39 INFO TaskSetManager: Starting task 0.0 in stage 24.0 (TID 24, localhost, executor driver, partition 0, PROCESS_LOCAL, 8041 bytes)
21/02/17 01:41:39 INFO Executor: Running task 0.0 in stage 24.0 (TID 24)
21/02/17 01:41:39 INFO HadoopMapRedCommitProtocol: Using output committer class org.apache.hadoop.mapred.FileOutputCommitter
21/02/17 01:41:39 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
21/02/17 01:41:39 INFO FileOutputCommitter: Saved output of task 'attempt_20210217014139_0083_m_000000_0' to file:/tmp/Rtmp09Oz4e/file22e22736a8feb/stages/0_r_formula__9467ebc0_1e9a_44aa_b6e1_220b95e6649f/pipelineModel/stages/2_columnPruner_54113b6a0e68/metadata/_temporary/0/task_20210217014139_0083_m_000000
21/02/17 01:41:39 INFO SparkHadoopMapRedUtil: attempt_20210217014139_0083_m_000000_0: Committed
21/02/17 01:41:39 INFO Executor: Finished task 0.0 in stage 24.0 (TID 24). 1029 bytes result sent to driver
21/02/17 01:41:39 INFO TaskSetManager: Finished task 0.0 in stage 24.0 (TID 24) in 10 ms on localhost (executor driver) (1/1)
21/02/17 01:41:39 INFO TaskSchedulerImpl: Removed TaskSet 24.0, whose tasks have all completed, from pool 
21/02/17 01:41:39 INFO DAGScheduler: ResultStage 24 (runJob at SparkHadoopWriter.scala:78) finished in 0.019 s
21/02/17 01:41:39 INFO DAGScheduler: Job 18 finished: runJob at SparkHadoopWriter.scala:78, took 0.020702 s
21/02/17 01:41:39 INFO SparkHadoopWriter: Job job_20210217014139_0083 committed.
21/02/17 01:41:39 INFO ParquetFileFormat: Using default output committer for Parquet: org.apache.parquet.hadoop.ParquetOutputCommitter
21/02/17 01:41:39 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
21/02/17 01:41:39 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
21/02/17 01:41:39 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
21/02/17 01:41:39 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
21/02/17 01:41:39 INFO CodeGenerator: Code generated in 8.053636 ms
21/02/17 01:41:39 INFO SparkContext: Starting job: parquet at RFormula.scala:496
21/02/17 01:41:39 INFO DAGScheduler: Registering RDD 86 (parquet at RFormula.scala:496)
21/02/17 01:41:39 INFO DAGScheduler: Got job 19 (parquet at RFormula.scala:496) with 1 output partitions
21/02/17 01:41:39 INFO DAGScheduler: Final stage: ResultStage 26 (parquet at RFormula.scala:496)
21/02/17 01:41:39 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 25)
21/02/17 01:41:39 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 25)
21/02/17 01:41:39 INFO DAGScheduler: Submitting ShuffleMapStage 25 (MapPartitionsRDD[86] at parquet at RFormula.scala:496), which has no missing parents
21/02/17 01:41:39 INFO MemoryStore: Block broadcast_26 stored as values in memory (estimated size 4.9 KB, free 911.4 MB)
21/02/17 01:41:39 INFO MemoryStore: Block broadcast_26_piece0 stored as bytes in memory (estimated size 2.9 KB, free 911.4 MB)
21/02/17 01:41:39 INFO BlockManagerInfo: Added broadcast_26_piece0 in memory on localhost:41253 (size: 2.9 KB, free: 912.1 MB)
21/02/17 01:41:39 INFO SparkContext: Created broadcast 26 from broadcast at DAGScheduler.scala:1161
21/02/17 01:41:39 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 25 (MapPartitionsRDD[86] at parquet at RFormula.scala:496) (first 15 tasks are for partitions Vector(0))
21/02/17 01:41:39 INFO TaskSchedulerImpl: Adding task set 25.0 with 1 tasks
21/02/17 01:41:39 INFO TaskSetManager: Starting task 0.0 in stage 25.0 (TID 25, localhost, executor driver, partition 0, PROCESS_LOCAL, 8041 bytes)
21/02/17 01:41:39 INFO Executor: Running task 0.0 in stage 25.0 (TID 25)
21/02/17 01:41:39 INFO Executor: Finished task 0.0 in stage 25.0 (TID 25). 1247 bytes result sent to driver
21/02/17 01:41:39 INFO TaskSetManager: Finished task 0.0 in stage 25.0 (TID 25) in 5 ms on localhost (executor driver) (1/1)
21/02/17 01:41:39 INFO TaskSchedulerImpl: Removed TaskSet 25.0, whose tasks have all completed, from pool 
21/02/17 01:41:39 INFO DAGScheduler: ShuffleMapStage 25 (parquet at RFormula.scala:496) finished in 0.008 s
21/02/17 01:41:39 INFO DAGScheduler: looking for newly runnable stages
21/02/17 01:41:39 INFO DAGScheduler: running: Set()
21/02/17 01:41:39 INFO DAGScheduler: waiting: Set(ResultStage 26)
21/02/17 01:41:39 INFO DAGScheduler: failed: Set()
21/02/17 01:41:39 INFO DAGScheduler: Submitting ResultStage 26 (ShuffledRowRDD[87] at parquet at RFormula.scala:496), which has no missing parents
21/02/17 01:41:39 INFO MemoryStore: Block broadcast_27 stored as values in memory (estimated size 150.8 KB, free 911.2 MB)
21/02/17 01:41:39 INFO MemoryStore: Block broadcast_27_piece0 stored as bytes in memory (estimated size 53.4 KB, free 911.2 MB)
21/02/17 01:41:39 INFO BlockManagerInfo: Added broadcast_27_piece0 in memory on localhost:41253 (size: 53.4 KB, free: 912.0 MB)
21/02/17 01:41:39 INFO SparkContext: Created broadcast 27 from broadcast at DAGScheduler.scala:1161
21/02/17 01:41:39 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 26 (ShuffledRowRDD[87] at parquet at RFormula.scala:496) (first 15 tasks are for partitions Vector(0))
21/02/17 01:41:39 INFO TaskSchedulerImpl: Adding task set 26.0 with 1 tasks
21/02/17 01:41:39 INFO TaskSetManager: Starting task 0.0 in stage 26.0 (TID 26, localhost, executor driver, partition 0, NODE_LOCAL, 7767 bytes)
21/02/17 01:41:39 INFO Executor: Running task 0.0 in stage 26.0 (TID 26)
21/02/17 01:41:39 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks including 1 local blocks and 0 remote blocks
21/02/17 01:41:39 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
21/02/17 01:41:39 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
21/02/17 01:41:39 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
21/02/17 01:41:39 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
21/02/17 01:41:39 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
21/02/17 01:41:39 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:
{
  "type" : "struct",
  "fields" : [ {
    "name" : "columnsToPrune",
    "type" : {
      "type" : "array",
      "elementType" : "string",
      "containsNull" : true
    },
    "nullable" : true,
    "metadata" : { }
  } ]
}
and corresponding Parquet message type:
message spark_schema {
  optional group columnsToPrune (LIST) {
    repeated group list {
      optional binary element (UTF8);
    }
  }
}

       
21/02/17 01:41:39 INFO FileOutputCommitter: Saved output of task 'attempt_20210217014139_0026_m_000000_26' to file:/tmp/Rtmp09Oz4e/file22e22736a8feb/stages/0_r_formula__9467ebc0_1e9a_44aa_b6e1_220b95e6649f/pipelineModel/stages/2_columnPruner_54113b6a0e68/data/_temporary/0/task_20210217014139_0026_m_000000
21/02/17 01:41:39 INFO SparkHadoopMapRedUtil: attempt_20210217014139_0026_m_000000_26: Committed
21/02/17 01:41:39 INFO Executor: Finished task 0.0 in stage 26.0 (TID 26). 2291 bytes result sent to driver
21/02/17 01:41:39 INFO TaskSetManager: Finished task 0.0 in stage 26.0 (TID 26) in 18 ms on localhost (executor driver) (1/1)
21/02/17 01:41:39 INFO TaskSchedulerImpl: Removed TaskSet 26.0, whose tasks have all completed, from pool 
21/02/17 01:41:39 INFO DAGScheduler: ResultStage 26 (parquet at RFormula.scala:496) finished in 0.035 s
21/02/17 01:41:39 INFO DAGScheduler: Job 19 finished: parquet at RFormula.scala:496, took 0.046169 s
21/02/17 01:41:39 INFO FileFormatWriter: Write Job b44f4534-9f48-4aee-a927-9c15fc60b0b1 committed.
21/02/17 01:41:39 INFO FileFormatWriter: Finished processing stats for write job b44f4534-9f48-4aee-a927-9c15fc60b0b1.
21/02/17 01:41:39 INFO HadoopMapRedCommitProtocol: Using output committer class org.apache.hadoop.mapred.FileOutputCommitter
21/02/17 01:41:39 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
21/02/17 01:41:39 INFO SparkContext: Starting job: runJob at SparkHadoopWriter.scala:78
21/02/17 01:41:39 INFO DAGScheduler: Got job 20 (runJob at SparkHadoopWriter.scala:78) with 1 output partitions
21/02/17 01:41:39 INFO DAGScheduler: Final stage: ResultStage 27 (runJob at SparkHadoopWriter.scala:78)
21/02/17 01:41:39 INFO DAGScheduler: Parents of final stage: List()
21/02/17 01:41:39 INFO DAGScheduler: Missing parents: List()
21/02/17 01:41:39 INFO DAGScheduler: Submitting ResultStage 27 (MapPartitionsRDD[90] at saveAsTextFile at DefaultXGBoostParamsWriter.scala:52), which has no missing parents
21/02/17 01:41:39 INFO MemoryStore: Block broadcast_28 stored as values in memory (estimated size 71.2 KB, free 911.1 MB)
21/02/17 01:41:39 INFO MemoryStore: Block broadcast_28_piece0 stored as bytes in memory (estimated size 25.5 KB, free 911.1 MB)
21/02/17 01:41:39 INFO BlockManagerInfo: Added broadcast_28_piece0 in memory on localhost:41253 (size: 25.5 KB, free: 912.0 MB)
21/02/17 01:41:39 INFO SparkContext: Created broadcast 28 from broadcast at DAGScheduler.scala:1161
21/02/17 01:41:39 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 27 (MapPartitionsRDD[90] at saveAsTextFile at DefaultXGBoostParamsWriter.scala:52) (first 15 tasks are for partitions Vector(0))
21/02/17 01:41:39 INFO TaskSchedulerImpl: Adding task set 27.0 with 1 tasks
21/02/17 01:41:39 INFO TaskSetManager: Starting task 0.0 in stage 27.0 (TID 27, localhost, executor driver, partition 0, PROCESS_LOCAL, 9115 bytes)
21/02/17 01:41:39 INFO Executor: Running task 0.0 in stage 27.0 (TID 27)
21/02/17 01:41:39 INFO HadoopMapRedCommitProtocol: Using output committer class org.apache.hadoop.mapred.FileOutputCommitter
21/02/17 01:41:39 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
21/02/17 01:41:39 INFO FileOutputCommitter: Saved output of task 'attempt_20210217014139_0090_m_000000_0' to file:/tmp/Rtmp09Oz4e/file22e22736a8feb/stages/1_xgboost_regressor__dbadb0af_de87_45b0_93ff_cc50903fe025/metadata/_temporary/0/task_20210217014139_0090_m_000000
21/02/17 01:41:39 INFO SparkHadoopMapRedUtil: attempt_20210217014139_0090_m_000000_0: Committed
21/02/17 01:41:39 INFO Executor: Finished task 0.0 in stage 27.0 (TID 27). 1029 bytes result sent to driver
21/02/17 01:41:39 INFO TaskSetManager: Finished task 0.0 in stage 27.0 (TID 27) in 10 ms on localhost (executor driver) (1/1)
21/02/17 01:41:39 INFO TaskSchedulerImpl: Removed TaskSet 27.0, whose tasks have all completed, from pool 
21/02/17 01:41:39 INFO DAGScheduler: ResultStage 27 (runJob at SparkHadoopWriter.scala:78) finished in 0.018 s
21/02/17 01:41:39 INFO DAGScheduler: Job 20 finished: runJob at SparkHadoopWriter.scala:78, took 0.020663 s
21/02/17 01:41:39 INFO SparkHadoopWriter: Job job_20210217014139_0090 committed.
21/02/17 01:41:39 INFO HiveMetaStore: 0: get_database: default
21/02/17 01:41:39 INFO audit: ugi=yitaoli	ip=unknown-ip-addr	cmd=get_database: default	
21/02/17 01:41:39 INFO HiveMetaStore: 0: get_database: default
21/02/17 01:41:39 INFO audit: ugi=yitaoli	ip=unknown-ip-addr	cmd=get_database: default	
21/02/17 01:41:39 INFO HiveMetaStore: 0: get_tables: db=default pat=*
21/02/17 01:41:39 INFO audit: ugi=yitaoli	ip=unknown-ip-addr	cmd=get_tables: db=default pat=*	
21/02/17 01:41:40 INFO CodeGenerator: Code generated in 3.933291 ms
21/02/17 01:41:40 INFO SparkContext: Starting job: collect at utils.scala:61
21/02/17 01:41:40 INFO DAGScheduler: Got job 21 (collect at utils.scala:61) with 2 output partitions
21/02/17 01:41:40 INFO DAGScheduler: Final stage: ResultStage 28 (collect at utils.scala:61)
21/02/17 01:41:40 INFO DAGScheduler: Parents of final stage: List()
21/02/17 01:41:40 INFO DAGScheduler: Missing parents: List()
21/02/17 01:41:40 INFO DAGScheduler: Submitting ResultStage 28 (MapPartitionsRDD[95] at map at utils.scala:54), which has no missing parents
21/02/17 01:41:40 INFO MemoryStore: Block broadcast_29 stored as values in memory (estimated size 6.0 KB, free 911.1 MB)
21/02/17 01:41:40 INFO MemoryStore: Block broadcast_29_piece0 stored as bytes in memory (estimated size 3.4 KB, free 911.1 MB)
21/02/17 01:41:40 INFO BlockManagerInfo: Added broadcast_29_piece0 in memory on localhost:41253 (size: 3.4 KB, free: 912.0 MB)
21/02/17 01:41:40 INFO SparkContext: Created broadcast 29 from broadcast at DAGScheduler.scala:1161
21/02/17 01:41:40 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 28 (MapPartitionsRDD[95] at map at utils.scala:54) (first 15 tasks are for partitions Vector(0, 1))
21/02/17 01:41:40 INFO TaskSchedulerImpl: Adding task set 28.0 with 2 tasks
21/02/17 01:41:40 INFO TaskSetManager: Starting task 0.0 in stage 28.0 (TID 28, localhost, executor driver, partition 0, PROCESS_LOCAL, 8052 bytes)
21/02/17 01:41:40 INFO TaskSetManager: Starting task 1.0 in stage 28.0 (TID 29, localhost, executor driver, partition 1, PROCESS_LOCAL, 8100 bytes)
21/02/17 01:41:40 INFO Executor: Running task 0.0 in stage 28.0 (TID 28)
21/02/17 01:41:40 INFO Executor: Running task 1.0 in stage 28.0 (TID 29)
21/02/17 01:41:40 INFO Executor: Finished task 1.0 in stage 28.0 (TID 29). 1022 bytes result sent to driver
21/02/17 01:41:40 INFO Executor: Finished task 0.0 in stage 28.0 (TID 28). 977 bytes result sent to driver
21/02/17 01:41:40 INFO TaskSetManager: Finished task 1.0 in stage 28.0 (TID 29) in 5 ms on localhost (executor driver) (1/2)
21/02/17 01:41:40 INFO TaskSetManager: Finished task 0.0 in stage 28.0 (TID 28) in 5 ms on localhost (executor driver) (2/2)
21/02/17 01:41:40 INFO TaskSchedulerImpl: Removed TaskSet 28.0, whose tasks have all completed, from pool 
21/02/17 01:41:40 INFO DAGScheduler: ResultStage 28 (collect at utils.scala:61) finished in 0.009 s
21/02/17 01:41:40 INFO DAGScheduler: Job 21 finished: collect at utils.scala:61, took 0.010799 s
21/02/17 01:41:40 INFO FileSourceStrategy: Pruning directories with: 
21/02/17 01:41:40 INFO FileSourceStrategy: Post-Scan Filters: 
21/02/17 01:41:40 INFO FileSourceStrategy: Output Data Schema: struct<value: string>
21/02/17 01:41:40 INFO FileSourceScanExec: Pushed Filters: 
21/02/17 01:41:40 INFO CodeGenerator: Code generated in 4.140514 ms
21/02/17 01:41:40 INFO MemoryStore: Block broadcast_30 stored as values in memory (estimated size 290.3 KB, free 910.8 MB)
21/02/17 01:41:40 INFO MemoryStore: Block broadcast_30_piece0 stored as bytes in memory (estimated size 24.5 KB, free 910.8 MB)
21/02/17 01:41:40 INFO BlockManagerInfo: Added broadcast_30_piece0 in memory on localhost:41253 (size: 24.5 KB, free: 911.9 MB)
21/02/17 01:41:40 INFO SparkContext: Created broadcast 30 from json at NativeMethodAccessorImpl.java:0
21/02/17 01:41:40 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
21/02/17 01:41:40 INFO SparkContext: Starting job: json at NativeMethodAccessorImpl.java:0
21/02/17 01:41:40 INFO DAGScheduler: Got job 22 (json at NativeMethodAccessorImpl.java:0) with 1 output partitions
21/02/17 01:41:40 INFO DAGScheduler: Final stage: ResultStage 29 (json at NativeMethodAccessorImpl.java:0)
21/02/17 01:41:40 INFO DAGScheduler: Parents of final stage: List()
21/02/17 01:41:40 INFO DAGScheduler: Missing parents: List()
21/02/17 01:41:40 INFO DAGScheduler: Submitting ResultStage 29 (MapPartitionsRDD[98] at json at NativeMethodAccessorImpl.java:0), which has no missing parents
21/02/17 01:41:40 INFO MemoryStore: Block broadcast_31 stored as values in memory (estimated size 9.6 KB, free 910.8 MB)
21/02/17 01:41:40 INFO MemoryStore: Block broadcast_31_piece0 stored as bytes in memory (estimated size 5.2 KB, free 910.8 MB)
21/02/17 01:41:40 INFO BlockManagerInfo: Added broadcast_31_piece0 in memory on localhost:41253 (size: 5.2 KB, free: 911.9 MB)
21/02/17 01:41:40 INFO SparkContext: Created broadcast 31 from broadcast at DAGScheduler.scala:1161
21/02/17 01:41:40 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 29 (MapPartitionsRDD[98] at json at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
21/02/17 01:41:40 INFO TaskSchedulerImpl: Adding task set 29.0 with 1 tasks
21/02/17 01:41:40 INFO TaskSetManager: Starting task 0.0 in stage 29.0 (TID 30, localhost, executor driver, partition 0, PROCESS_LOCAL, 8276 bytes)
21/02/17 01:41:40 INFO Executor: Running task 0.0 in stage 29.0 (TID 30)
21/02/17 01:41:40 INFO FileScanRDD: Reading File path: file:///tmp/Rtmp09Oz4e/file22e22736a8feb/metadata/part-00000, range: 0-306, partition values: [empty row]
21/02/17 01:41:40 INFO CodeGenerator: Code generated in 6.685056 ms
21/02/17 01:41:40 INFO Executor: Finished task 0.0 in stage 29.0 (TID 30). 2192 bytes result sent to driver
21/02/17 01:41:40 INFO TaskSetManager: Finished task 0.0 in stage 29.0 (TID 30) in 51 ms on localhost (executor driver) (1/1)
21/02/17 01:41:40 INFO TaskSchedulerImpl: Removed TaskSet 29.0, whose tasks have all completed, from pool 
21/02/17 01:41:40 INFO DAGScheduler: ResultStage 29 (json at NativeMethodAccessorImpl.java:0) finished in 0.057 s
21/02/17 01:41:40 INFO DAGScheduler: Job 22 finished: json at NativeMethodAccessorImpl.java:0, took 0.061297 s
21/02/17 01:41:40 INFO HiveMetaStore: 0: get_database: default
21/02/17 01:41:40 INFO audit: ugi=yitaoli	ip=unknown-ip-addr	cmd=get_database: default	
21/02/17 01:41:40 INFO HiveMetaStore: 0: get_database: default
21/02/17 01:41:40 INFO audit: ugi=yitaoli	ip=unknown-ip-addr	cmd=get_database: default	
21/02/17 01:41:40 INFO HiveMetaStore: 0: get_tables: db=default pat=*
21/02/17 01:41:40 INFO audit: ugi=yitaoli	ip=unknown-ip-addr	cmd=get_tables: db=default pat=*	
21/02/17 01:41:40 INFO CodeGenerator: Code generated in 6.274368 ms
21/02/17 01:41:40 INFO CodeGenerator: Code generated in 4.932795 ms
21/02/17 01:41:40 INFO SparkContext: Starting job: count at utils.scala:135
21/02/17 01:41:40 INFO DAGScheduler: Registering RDD 102 (count at utils.scala:135)
21/02/17 01:41:40 INFO DAGScheduler: Got job 23 (count at utils.scala:135) with 1 output partitions
21/02/17 01:41:40 INFO DAGScheduler: Final stage: ResultStage 31 (count at utils.scala:135)
21/02/17 01:41:40 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 30)
21/02/17 01:41:40 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 30)
21/02/17 01:41:40 INFO DAGScheduler: Submitting ShuffleMapStage 30 (MapPartitionsRDD[102] at count at utils.scala:135), which has no missing parents
21/02/17 01:41:40 INFO MemoryStore: Block broadcast_32 stored as values in memory (estimated size 7.9 KB, free 910.8 MB)
21/02/17 01:41:40 INFO MemoryStore: Block broadcast_32_piece0 stored as bytes in memory (estimated size 4.2 KB, free 910.8 MB)
21/02/17 01:41:40 INFO BlockManagerInfo: Added broadcast_32_piece0 in memory on localhost:41253 (size: 4.2 KB, free: 911.9 MB)
21/02/17 01:41:40 INFO SparkContext: Created broadcast 32 from broadcast at DAGScheduler.scala:1161
21/02/17 01:41:40 INFO DAGScheduler: Submitting 2 missing tasks from ShuffleMapStage 30 (MapPartitionsRDD[102] at count at utils.scala:135) (first 15 tasks are for partitions Vector(0, 1))
21/02/17 01:41:40 INFO TaskSchedulerImpl: Adding task set 30.0 with 2 tasks
21/02/17 01:41:40 INFO TaskSetManager: Starting task 0.0 in stage 30.0 (TID 31, localhost, executor driver, partition 0, PROCESS_LOCAL, 8017 bytes)
21/02/17 01:41:40 INFO TaskSetManager: Starting task 1.0 in stage 30.0 (TID 32, localhost, executor driver, partition 1, PROCESS_LOCAL, 8017 bytes)
21/02/17 01:41:40 INFO Executor: Running task 1.0 in stage 30.0 (TID 32)
21/02/17 01:41:40 INFO Executor: Running task 0.0 in stage 30.0 (TID 31)
21/02/17 01:41:40 INFO Executor: Finished task 0.0 in stage 30.0 (TID 31). 1499 bytes result sent to driver
21/02/17 01:41:40 INFO Executor: Finished task 1.0 in stage 30.0 (TID 32). 1499 bytes result sent to driver
21/02/17 01:41:40 INFO TaskSetManager: Finished task 0.0 in stage 30.0 (TID 31) in 5 ms on localhost (executor driver) (1/2)
21/02/17 01:41:40 INFO TaskSetManager: Finished task 1.0 in stage 30.0 (TID 32) in 5 ms on localhost (executor driver) (2/2)
21/02/17 01:41:40 INFO TaskSchedulerImpl: Removed TaskSet 30.0, whose tasks have all completed, from pool 
21/02/17 01:41:40 INFO DAGScheduler: ShuffleMapStage 30 (count at utils.scala:135) finished in 0.011 s
21/02/17 01:41:40 INFO DAGScheduler: looking for newly runnable stages
21/02/17 01:41:40 INFO DAGScheduler: running: Set()
21/02/17 01:41:40 INFO DAGScheduler: waiting: Set(ResultStage 31)
21/02/17 01:41:40 INFO DAGScheduler: failed: Set()
21/02/17 01:41:40 INFO DAGScheduler: Submitting ResultStage 31 (MapPartitionsRDD[105] at count at utils.scala:135), which has no missing parents
21/02/17 01:41:40 INFO MemoryStore: Block broadcast_33 stored as values in memory (estimated size 7.1 KB, free 910.7 MB)
21/02/17 01:41:40 INFO MemoryStore: Block broadcast_33_piece0 stored as bytes in memory (estimated size 3.8 KB, free 910.7 MB)
21/02/17 01:41:40 INFO BlockManagerInfo: Added broadcast_33_piece0 in memory on localhost:41253 (size: 3.8 KB, free: 911.9 MB)
21/02/17 01:41:40 INFO SparkContext: Created broadcast 33 from broadcast at DAGScheduler.scala:1161
21/02/17 01:41:40 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 31 (MapPartitionsRDD[105] at count at utils.scala:135) (first 15 tasks are for partitions Vector(0))
21/02/17 01:41:40 INFO TaskSchedulerImpl: Adding task set 31.0 with 1 tasks
21/02/17 01:41:40 INFO TaskSetManager: Starting task 0.0 in stage 31.0 (TID 33, localhost, executor driver, partition 0, NODE_LOCAL, 7767 bytes)
21/02/17 01:41:40 INFO Executor: Running task 0.0 in stage 31.0 (TID 33)
21/02/17 01:41:40 INFO ShuffleBlockFetcherIterator: Getting 2 non-empty blocks including 2 local blocks and 0 remote blocks
21/02/17 01:41:40 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
21/02/17 01:41:40 INFO Executor: Finished task 0.0 in stage 31.0 (TID 33). 1739 bytes result sent to driver
21/02/17 01:41:40 INFO TaskSetManager: Finished task 0.0 in stage 31.0 (TID 33) in 5 ms on localhost (executor driver) (1/1)
21/02/17 01:41:40 INFO TaskSchedulerImpl: Removed TaskSet 31.0, whose tasks have all completed, from pool 
21/02/17 01:41:40 INFO DAGScheduler: ResultStage 31 (count at utils.scala:135) finished in 0.010 s
21/02/17 01:41:40 INFO DAGScheduler: Job 23 finished: count at utils.scala:135, took 0.023803 s
21/02/17 01:41:40 INFO FileSourceStrategy: Pruning directories with: 
21/02/17 01:41:40 INFO FileSourceStrategy: Post-Scan Filters: 
21/02/17 01:41:40 INFO FileSourceStrategy: Output Data Schema: struct<class: string, paramMap: struct<stageUids: array<string>>, sparkVersion: string, timestamp: bigint, uid: string ... 3 more fields>
21/02/17 01:41:40 INFO FileSourceScanExec: Pushed Filters: 
21/02/17 01:41:40 INFO ContextCleaner: Cleaned accumulator 834
21/02/17 01:41:40 INFO ContextCleaner: Cleaned accumulator 766
21/02/17 01:41:40 INFO ContextCleaner: Cleaned accumulator 814
21/02/17 01:41:40 INFO ContextCleaner: Cleaned accumulator 916
21/02/17 01:41:40 INFO ContextCleaner: Cleaned accumulator 914
21/02/17 01:41:40 INFO ContextCleaner: Cleaned accumulator 904
21/02/17 01:41:40 INFO ContextCleaner: Cleaned accumulator 527
21/02/17 01:41:40 INFO ContextCleaner: Cleaned accumulator 696
21/02/17 01:41:40 INFO ContextCleaner: Cleaned accumulator 543
21/02/17 01:41:40 INFO ContextCleaner: Cleaned accumulator 652
21/02/17 01:41:40 INFO ContextCleaner: Cleaned accumulator 608
21/02/17 01:41:40 INFO ContextCleaner: Cleaned accumulator 530
21/02/17 01:41:40 INFO ContextCleaner: Cleaned accumulator 524
21/02/17 01:41:40 INFO ContextCleaner: Cleaned accumulator 799
21/02/17 01:41:40 INFO ContextCleaner: Cleaned accumulator 669
21/02/17 01:41:40 INFO ContextCleaner: Cleaned accumulator 677
21/02/17 01:41:40 INFO ContextCleaner: Cleaned accumulator 683
21/02/17 01:41:40 INFO ContextCleaner: Cleaned accumulator 575
21/02/17 01:41:40 INFO ContextCleaner: Cleaned accumulator 594
21/02/17 01:41:40 INFO ContextCleaner: Cleaned accumulator 531
21/02/17 01:41:40 INFO ContextCleaner: Cleaned accumulator 590
21/02/17 01:41:40 INFO ContextCleaner: Cleaned accumulator 665
21/02/17 01:41:40 INFO ContextCleaner: Cleaned accumulator 554
21/02/17 01:41:40 INFO BlockManagerInfo: Removed broadcast_21_piece0 on localhost:41253 in memory (size: 25.5 KB, free: 912.0 MB)
21/02/17 01:41:40 INFO ContextCleaner: Cleaned accumulator 584
21/02/17 01:41:40 INFO ContextCleaner: Cleaned accumulator 663
21/02/17 01:41:40 INFO ContextCleaner: Cleaned accumulator 802
21/02/17 01:41:40 INFO ContextCleaner: Cleaned accumulator 876
21/02/17 01:41:40 INFO ContextCleaner: Cleaned accumulator 514
21/02/17 01:41:40 INFO ContextCleaner: Cleaned accumulator 605
21/02/17 01:41:40 INFO ContextCleaner: Cleaned accumulator 827
21/02/17 01:41:40 INFO ContextCleaner: Cleaned accumulator 915
21/02/17 01:41:40 INFO ContextCleaner: Cleaned accumulator 721
21/02/17 01:41:40 INFO ContextCleaner: Cleaned accumulator 670
21/02/17 01:41:40 INFO ContextCleaner: Cleaned accumulator 505
21/02/17 01:41:40 INFO ContextCleaner: Cleaned accumulator 618
21/02/17 01:41:40 INFO ContextCleaner: Cleaned accumulator 762
21/02/17 01:41:40 INFO ContextCleaner: Cleaned accumulator 789
21/02/17 01:41:40 INFO ContextCleaner: Cleaned accumulator 912
21/02/17 01:41:40 INFO ContextCleaner: Cleaned accumulator 604
21/02/17 01:41:40 INFO ContextCleaner: Cleaned accumulator 689
21/02/17 01:41:40 INFO ContextCleaner: Cleaned accumulator 728
21/02/17 01:41:40 INFO ContextCleaner: Cleaned accumulator 647
21/02/17 01:41:40 INFO ContextCleaner: Cleaned accumulator 691
21/02/17 01:41:40 INFO ContextCleaner: Cleaned accumulator 508
21/02/17 01:41:40 INFO ContextCleaner: Cleaned accumulator 674
21/02/17 01:41:40 INFO ContextCleaner: Cleaned accumulator 522
21/02/17 01:41:40 INFO ContextCleaner: Cleaned accumulator 666
21/02/17 01:41:40 INFO ContextCleaner: Cleaned accumulator 811
21/02/17 01:41:40 INFO ContextCleaner: Cleaned accumulator 905
21/02/17 01:41:40 INFO ContextCleaner: Cleaned accumulator 842
21/02/17 01:41:40 INFO ContextCleaner: Cleaned accumulator 588
21/02/17 01:41:40 INFO ContextCleaner: Cleaned accumulator 761
21/02/17 01:41:40 INFO ContextCleaner: Cleaned accumulator 867
21/02/17 01:41:40 INFO ContextCleaner: Cleaned accumulator 841
21/02/17 01:41:40 INFO ContextCleaner: Cleaned accumulator 846
21/02/17 01:41:40 INFO ContextCleaner: Cleaned accumulator 857
21/02/17 01:41:40 INFO ContextCleaner: Cleaned accumulator 564
21/02/17 01:41:40 INFO ContextCleaner: Cleaned accumulator 661
21/02/17 01:41:40 INFO ContextCleaner: Cleaned accumulator 591
21/02/17 01:41:40 INFO ContextCleaner: Cleaned accumulator 750
21/02/17 01:41:40 INFO ContextCleaner: Cleaned accumulator 729
21/02/17 01:41:40 INFO ContextCleaner: Cleaned accumulator 537
21/02/17 01:41:40 INFO ContextCleaner: Cleaned accumulator 724
21/02/17 01:41:40 INFO ContextCleaner: Cleaned accumulator 770
21/02/17 01:41:40 INFO ContextCleaner: Cleaned accumulator 569
21/02/17 01:41:40 INFO ContextCleaner: Cleaned accumulator 556
21/02/17 01:41:40 INFO ContextCleaner: Cleaned accumulator 828
21/02/17 01:41:40 INFO ContextCleaner: Cleaned accumulator 868
21/02/17 01:41:40 INFO ContextCleaner: Cleaned accumulator 697
21/02/17 01:41:40 INFO ContextCleaner: Cleaned accumulator 727
21/02/17 01:41:40 INFO ContextCleaner: Cleaned accumulator 582
21/02/17 01:41:40 INFO ContextCleaner: Cleaned accumulator 773
21/02/17 01:41:40 INFO ContextCleaner: Cleaned accumulator 855
21/02/17 01:41:40 INFO BlockManagerInfo: Removed broadcast_24_piece0 on localhost:41253 in memory (size: 53.6 KB, free: 912.0 MB)
21/02/17 01:41:40 INFO ContextCleaner: Cleaned accumulator 717
21/02/17 01:41:40 INFO ContextCleaner: Cleaned accumulator 836
21/02/17 01:41:40 INFO ContextCleaner: Cleaned accumulator 507
21/02/17 01:41:40 INFO ContextCleaner: Cleaned accumulator 801
21/02/17 01:41:40 INFO ContextCleaner: Cleaned accumulator 830
21/02/17 01:41:40 INFO BlockManagerInfo: Removed broadcast_31_piece0 on localhost:41253 in memory (size: 5.2 KB, free: 912.0 MB)
21/02/17 01:41:40 INFO ContextCleaner: Cleaned accumulator 897
21/02/17 01:41:40 INFO ContextCleaner: Cleaned accumulator 702
21/02/17 01:41:40 INFO ContextCleaner: Cleaned accumulator 736
21/02/17 01:41:40 INFO ContextCleaner: Cleaned accumulator 793
21/02/17 01:41:40 INFO ContextCleaner: Cleaned accumulator 909
21/02/17 01:41:40 INFO ContextCleaner: Cleaned accumulator 574
21/02/17 01:41:40 INFO ContextCleaner: Cleaned accumulator 529
21/02/17 01:41:40 INFO ContextCleaner: Cleaned accumulator 545
21/02/17 01:41:40 INFO ContextCleaner: Cleaned accumulator 752
21/02/17 01:41:40 INFO ContextCleaner: Cleaned accumulator 620
21/02/17 01:41:40 INFO ContextCleaner: Cleaned accumulator 734
21/02/17 01:41:40 INFO ContextCleaner: Cleaned accumulator 800
21/02/17 01:41:40 INFO ContextCleaner: Cleaned accumulator 577
21/02/17 01:41:40 INFO BlockManagerInfo: Removed broadcast_28_piece0 on localhost:41253 in memory (size: 25.5 KB, free: 912.0 MB)
21/02/17 01:41:40 INFO ContextCleaner: Cleaned accumulator 882
21/02/17 01:41:40 INFO ContextCleaner: Cleaned accumulator 521
21/02/17 01:41:40 INFO ContextCleaner: Cleaned accumulator 895
21/02/17 01:41:40 INFO ContextCleaner: Cleaned accumulator 825
21/02/17 01:41:40 INFO ContextCleaner: Cleaned accumulator 822
21/02/17 01:41:40 INFO ContextCleaner: Cleaned accumulator 659
21/02/17 01:41:40 INFO ContextCleaner: Cleaned accumulator 642
21/02/17 01:41:40 INFO ContextCleaner: Cleaned accumulator 818
21/02/17 01:41:40 INFO ContextCleaner: Cleaned accumulator 548
21/02/17 01:41:40 INFO ContextCleaner: Cleaned accumulator 804
21/02/17 01:41:40 INFO ContextCleaner: Cleaned accumulator 617
21/02/17 01:41:40 INFO ContextCleaner: Cleaned accumulator 743
21/02/17 01:41:40 INFO ContextCleaner: Cleaned accumulator 838
21/02/17 01:41:40 INFO ContextCleaner: Cleaned accumulator 589
21/02/17 01:41:40 INFO ContextCleaner: Cleaned accumulator 694
21/02/17 01:41:40 INFO ContextCleaner: Cleaned accumulator 720
21/02/17 01:41:40 INFO ContextCleaner: Cleaned accumulator 782
21/02/17 01:41:40 INFO BlockManagerInfo: Removed broadcast_29_piece0 on localhost:41253 in memory (size: 3.4 KB, free: 912.0 MB)
21/02/17 01:41:40 INFO ContextCleaner: Cleaned accumulator 656
21/02/17 01:41:40 INFO ContextCleaner: Cleaned accumulator 646
21/02/17 01:41:40 INFO ContextCleaner: Cleaned accumulator 563
21/02/17 01:41:40 INFO ContextCleaner: Cleaned accumulator 894
21/02/17 01:41:40 INFO ContextCleaner: Cleaned accumulator 731
21/02/17 01:41:40 INFO ContextCleaner: Cleaned accumulator 558
21/02/17 01:41:40 INFO ContextCleaner: Cleaned accumulator 672
21/02/17 01:41:40 INFO ContextCleaner: Cleaned accumulator 870
21/02/17 01:41:40 INFO ContextCleaner: Cleaned accumulator 712
21/02/17 01:41:40 INFO ContextCleaner: Cleaned accumulator 630
21/02/17 01:41:40 INFO ContextCleaner: Cleaned accumulator 744
21/02/17 01:41:40 INFO ContextCleaner: Cleaned accumulator 754
21/02/17 01:41:40 INFO ContextCleaner: Cleaned accumulator 625
21/02/17 01:41:40 INFO ContextCleaner: Cleaned accumulator 645
21/02/17 01:41:40 INFO ContextCleaner: Cleaned accumulator 693
21/02/17 01:41:40 INFO ContextCleaner: Cleaned shuffle 5
21/02/17 01:41:40 INFO ContextCleaner: Cleaned shuffle 7
21/02/17 01:41:40 INFO ContextCleaner: Cleaned accumulator 673
21/02/17 01:41:40 INFO ContextCleaner: Cleaned accumulator 732
21/02/17 01:41:40 INFO ContextCleaner: Cleaned accumulator 687
21/02/17 01:41:40 INFO ContextCleaner: Cleaned accumulator 843
21/02/17 01:41:40 INFO ContextCleaner: Cleaned accumulator 826
21/02/17 01:41:40 INFO ContextCleaner: Cleaned accumulator 713
21/02/17 01:41:40 INFO ContextCleaner: Cleaned accumulator 599
21/02/17 01:41:40 INFO ContextCleaner: Cleaned accumulator 676
21/02/17 01:41:40 INFO ContextCleaner: Cleaned accumulator 756
21/02/17 01:41:40 INFO ContextCleaner: Cleaned accumulator 809
21/02/17 01:41:40 INFO ContextCleaner: Cleaned accumulator 600
21/02/17 01:41:40 INFO ContextCleaner: Cleaned accumulator 797
21/02/17 01:41:40 INFO ContextCleaner: Cleaned accumulator 511
21/02/17 01:41:40 INFO ContextCleaner: Cleaned accumulator 866
21/02/17 01:41:40 INFO ContextCleaner: Cleaned accumulator 660
21/02/17 01:41:40 INFO ContextCleaner: Cleaned accumulator 561
21/02/17 01:41:40 INFO ContextCleaner: Cleaned accumulator 881
21/02/17 01:41:40 INFO ContextCleaner: Cleaned accumulator 901
21/02/17 01:41:40 INFO ContextCleaner: Cleaned accumulator 655
21/02/17 01:41:40 INFO ContextCleaner: Cleaned accumulator 699
21/02/17 01:41:40 INFO ContextCleaner: Cleaned accumulator 619
21/02/17 01:41:40 INFO ContextCleaner: Cleaned accumulator 853
21/02/17 01:41:40 INFO ContextCleaner: Cleaned accumulator 680
21/02/17 01:41:40 INFO ContextCleaner: Cleaned accumulator 751
21/02/17 01:41:40 INFO ContextCleaner: Cleaned accumulator 910
21/02/17 01:41:40 INFO ContextCleaner: Cleaned accumulator 755
21/02/17 01:41:40 INFO ContextCleaner: Cleaned accumulator 613
21/02/17 01:41:40 INFO ContextCleaner: Cleaned accumulator 784
21/02/17 01:41:40 INFO ContextCleaner: Cleaned accumulator 562
21/02/17 01:41:40 INFO ContextCleaner: Cleaned accumulator 695
21/02/17 01:41:40 INFO ContextCleaner: Cleaned accumulator 795
21/02/17 01:41:40 INFO ContextCleaner: Cleaned accumulator 824
21/02/17 01:41:40 INFO ContextCleaner: Cleaned accumulator 578
21/02/17 01:41:40 INFO ContextCleaner: Cleaned accumulator 871
21/02/17 01:41:40 INFO ContextCleaner: Cleaned accumulator 906
21/02/17 01:41:40 INFO ContextCleaner: Cleaned accumulator 719
21/02/17 01:41:40 INFO ContextCleaner: Cleaned accumulator 821
21/02/17 01:41:40 INFO ContextCleaner: Cleaned accumulator 506
21/02/17 01:41:40 INFO ContextCleaner: Cleaned accumulator 675
21/02/17 01:41:40 INFO ContextCleaner: Cleaned accumulator 716
21/02/17 01:41:40 INFO ContextCleaner: Cleaned accumulator 534
21/02/17 01:41:40 INFO ContextCleaner: Cleaned accumulator 792
21/02/17 01:41:40 INFO BlockManagerInfo: Removed broadcast_32_piece0 on localhost:41253 in memory (size: 4.2 KB, free: 912.0 MB)
21/02/17 01:41:40 INFO ContextCleaner: Cleaned accumulator 778
21/02/17 01:41:40 INFO ContextCleaner: Cleaned accumulator 540
21/02/17 01:41:40 INFO ContextCleaner: Cleaned accumulator 638
21/02/17 01:41:40 INFO ContextCleaner: Cleaned accumulator 597
21/02/17 01:41:40 INFO ContextCleaner: Cleaned accumulator 681
21/02/17 01:41:40 INFO ContextCleaner: Cleaned accumulator 844
21/02/17 01:41:40 INFO ContextCleaner: Cleaned accumulator 845
21/02/17 01:41:40 INFO ContextCleaner: Cleaned accumulator 807
21/02/17 01:41:40 INFO ContextCleaner: Cleaned accumulator 890
21/02/17 01:41:40 INFO ContextCleaner: Cleaned accumulator 559
21/02/17 01:41:40 INFO ContextCleaner: Cleaned accumulator 889
21/02/17 01:41:40 INFO ContextCleaner: Cleaned accumulator 819
21/02/17 01:41:40 INFO ContextCleaner: Cleaned accumulator 557
21/02/17 01:41:40 INFO ContextCleaner: Cleaned accumulator 609
21/02/17 01:41:40 INFO ContextCleaner: Cleaned accumulator 607
21/02/17 01:41:40 INFO ContextCleaner: Cleaned accumulator 739
21/02/17 01:41:40 INFO ContextCleaner: Cleaned accumulator 785
21/02/17 01:41:40 INFO ContextCleaner: Cleaned accumulator 682
21/02/17 01:41:40 INFO ContextCleaner: Cleaned accumulator 572
21/02/17 01:41:40 INFO ContextCleaner: Cleaned accumulator 606
21/02/17 01:41:40 INFO ContextCleaner: Cleaned accumulator 854
21/02/17 01:41:40 INFO ContextCleaner: Cleaned accumulator 806
21/02/17 01:41:40 INFO ContextCleaner: Cleaned accumulator 581
21/02/17 01:41:40 INFO ContextCleaner: Cleaned accumulator 516
21/02/17 01:41:40 INFO ContextCleaner: Cleaned accumulator 570
21/02/17 01:41:40 INFO ContextCleaner: Cleaned accumulator 832
21/02/17 01:41:40 INFO ContextCleaner: Cleaned accumulator 783
21/02/17 01:41:40 INFO ContextCleaner: Cleaned accumulator 887
21/02/17 01:41:40 INFO ContextCleaner: Cleaned accumulator 786
21/02/17 01:41:40 INFO ContextCleaner: Cleaned accumulator 861
21/02/17 01:41:40 INFO ContextCleaner: Cleaned accumulator 907
21/02/17 01:41:40 INFO ContextCleaner: Cleaned accumulator 598
21/02/17 01:41:40 INFO ContextCleaner: Cleaned accumulator 641
21/02/17 01:41:40 INFO ContextCleaner: Cleaned accumulator 624
21/02/17 01:41:40 INFO ContextCleaner: Cleaned accumulator 863
21/02/17 01:41:40 INFO ContextCleaner: Cleaned accumulator 787
21/02/17 01:41:40 INFO ContextCleaner: Cleaned accumulator 515
21/02/17 01:41:40 INFO ContextCleaner: Cleaned accumulator 536
21/02/17 01:41:40 INFO ContextCleaner: Cleaned accumulator 775
21/02/17 01:41:40 INFO ContextCleaner: Cleaned accumulator 873
21/02/17 01:41:40 INFO ContextCleaner: Cleaned accumulator 553
21/02/17 01:41:40 INFO ContextCleaner: Cleaned accumulator 637
21/02/17 01:41:40 INFO ContextCleaner: Cleaned accumulator 576
21/02/17 01:41:40 INFO ContextCleaner: Cleaned accumulator 746
21/02/17 01:41:40 INFO ContextCleaner: Cleaned accumulator 851
21/02/17 01:41:40 INFO ContextCleaner: Cleaned accumulator 510
21/02/17 01:41:40 INFO BlockManagerInfo: Removed broadcast_26_piece0 on localhost:41253 in memory (size: 2.9 KB, free: 912.1 MB)
21/02/17 01:41:40 INFO ContextCleaner: Cleaned accumulator 726
21/02/17 01:41:40 INFO ContextCleaner: Cleaned accumulator 869
21/02/17 01:41:40 INFO ContextCleaner: Cleaned accumulator 723
21/02/17 01:41:40 INFO ContextCleaner: Cleaned accumulator 631
21/02/17 01:41:40 INFO ContextCleaner: Cleaned accumulator 877
21/02/17 01:41:40 INFO ContextCleaner: Cleaned accumulator 690
21/02/17 01:41:40 INFO ContextCleaner: Cleaned accumulator 835
21/02/17 01:41:40 INFO ContextCleaner: Cleaned accumulator 587
21/02/17 01:41:40 INFO ContextCleaner: Cleaned accumulator 550
21/02/17 01:41:40 INFO ContextCleaner: Cleaned accumulator 603
21/02/17 01:41:40 INFO ContextCleaner: Cleaned accumulator 715
21/02/17 01:41:40 INFO ContextCleaner: Cleaned accumulator 593
21/02/17 01:41:40 INFO ContextCleaner: Cleaned accumulator 552
21/02/17 01:41:40 INFO ContextCleaner: Cleaned accumulator 742
21/02/17 01:41:40 INFO ContextCleaner: Cleaned accumulator 688
21/02/17 01:41:40 INFO ContextCleaner: Cleaned accumulator 903
21/02/17 01:41:40 INFO BlockManagerInfo: Removed broadcast_22_piece0 on localhost:41253 in memory (size: 25.6 KB, free: 912.1 MB)
21/02/17 01:41:40 INFO MemoryStore: Block broadcast_34 stored as values in memory (estimated size 290.3 KB, free 911.0 MB)
21/02/17 01:41:40 INFO ContextCleaner: Cleaned accumulator 733
21/02/17 01:41:40 INFO ContextCleaner: Cleaned accumulator 678
21/02/17 01:41:40 INFO ContextCleaner: Cleaned accumulator 649
21/02/17 01:41:40 INFO ContextCleaner: Cleaned accumulator 512
21/02/17 01:41:40 INFO ContextCleaner: Cleaned accumulator 626
21/02/17 01:41:40 INFO ContextCleaner: Cleaned accumulator 885
21/02/17 01:41:40 INFO ContextCleaner: Cleaned accumulator 711
21/02/17 01:41:40 INFO ContextCleaner: Cleaned accumulator 708
21/02/17 01:41:40 INFO ContextCleaner: Cleaned accumulator 639
21/02/17 01:41:40 INFO ContextCleaner: Cleaned accumulator 664
21/02/17 01:41:40 INFO ContextCleaner: Cleaned accumulator 555
21/02/17 01:41:40 INFO ContextCleaner: Cleaned accumulator 520
21/02/17 01:41:40 INFO ContextCleaner: Cleaned accumulator 533
21/02/17 01:41:40 INFO ContextCleaner: Cleaned shuffle 4
21/02/17 01:41:40 INFO ContextCleaner: Cleaned accumulator 737
21/02/17 01:41:40 INFO ContextCleaner: Cleaned accumulator 704
21/02/17 01:41:40 INFO ContextCleaner: Cleaned accumulator 714
21/02/17 01:41:40 INFO ContextCleaner: Cleaned accumulator 612
21/02/17 01:41:40 INFO ContextCleaner: Cleaned accumulator 627
21/02/17 01:41:40 INFO ContextCleaner: Cleaned accumulator 880
21/02/17 01:41:40 INFO ContextCleaner: Cleaned accumulator 735
21/02/17 01:41:40 INFO ContextCleaner: Cleaned accumulator 686
21/02/17 01:41:40 INFO ContextCleaner: Cleaned accumulator 701
21/02/17 01:41:40 INFO ContextCleaner: Cleaned accumulator 776
21/02/17 01:41:40 INFO ContextCleaner: Cleaned accumulator 908
21/02/17 01:41:40 INFO ContextCleaner: Cleaned accumulator 763
21/02/17 01:41:40 INFO ContextCleaner: Cleaned accumulator 884
21/02/17 01:41:40 INFO ContextCleaner: Cleaned accumulator 816
21/02/17 01:41:40 INFO ContextCleaner: Cleaned accumulator 872
21/02/17 01:41:40 INFO ContextCleaner: Cleaned accumulator 791
21/02/17 01:41:40 INFO ContextCleaner: Cleaned accumulator 565
21/02/17 01:41:40 INFO ContextCleaner: Cleaned accumulator 771
21/02/17 01:41:40 INFO MemoryStore: Block broadcast_34_piece0 stored as bytes in memory (estimated size 24.5 KB, free 911.0 MB)
21/02/17 01:41:40 INFO BlockManagerInfo: Removed broadcast_20_piece0 on localhost:41253 in memory (size: 25.6 KB, free: 912.1 MB)
21/02/17 01:41:40 INFO BlockManagerInfo: Added broadcast_34_piece0 in memory on localhost:41253 (size: 24.5 KB, free: 912.1 MB)
21/02/17 01:41:40 INFO ContextCleaner: Cleaned accumulator 525
21/02/17 01:41:40 INFO ContextCleaner: Cleaned accumulator 653
21/02/17 01:41:40 INFO SparkContext: Created broadcast 34 from sql at <unknown>:0
21/02/17 01:41:40 INFO BlockManagerInfo: Removed broadcast_23_piece0 on localhost:41253 in memory (size: 3.0 KB, free: 912.1 MB)
21/02/17 01:41:40 INFO ContextCleaner: Cleaned accumulator 757
21/02/17 01:41:40 INFO ContextCleaner: Cleaned accumulator 803
21/02/17 01:41:40 INFO ContextCleaner: Cleaned accumulator 817
21/02/17 01:41:40 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
21/02/17 01:41:40 INFO BlockManagerInfo: Removed broadcast_18_piece0 on localhost:41253 in memory (size: 3.0 KB, free: 912.1 MB)
21/02/17 01:41:40 INFO ContextCleaner: Cleaned accumulator 837
21/02/17 01:41:40 INFO ContextCleaner: Cleaned accumulator 883
21/02/17 01:41:40 INFO ContextCleaner: Cleaned accumulator 777
21/02/17 01:41:40 INFO BlockManagerInfo: Removed broadcast_19_piece0 on localhost:41253 in memory (size: 53.6 KB, free: 912.1 MB)
21/02/17 01:41:40 INFO ContextCleaner: Cleaned accumulator 900
21/02/17 01:41:40 INFO ContextCleaner: Cleaned accumulator 622
21/02/17 01:41:40 INFO ContextCleaner: Cleaned accumulator 768
21/02/17 01:41:40 INFO ContextCleaner: Cleaned accumulator 585
21/02/17 01:41:40 INFO ContextCleaner: Cleaned accumulator 747
21/02/17 01:41:40 INFO ContextCleaner: Cleaned accumulator 544
21/02/17 01:41:40 INFO ContextCleaner: Cleaned accumulator 583
21/02/17 01:41:40 INFO ContextCleaner: Cleaned accumulator 718
21/02/17 01:41:40 INFO ContextCleaner: Cleaned accumulator 632
21/02/17 01:41:40 INFO ContextCleaner: Cleaned accumulator 610
21/02/17 01:41:40 INFO ContextCleaner: Cleaned accumulator 790
21/02/17 01:41:40 INFO ContextCleaner: Cleaned accumulator 705
21/02/17 01:41:40 INFO ContextCleaner: Cleaned accumulator 685
21/02/17 01:41:40 INFO ContextCleaner: Cleaned accumulator 808
21/02/17 01:41:40 INFO ContextCleaner: Cleaned accumulator 614
21/02/17 01:41:40 INFO ContextCleaner: Cleaned accumulator 539
21/02/17 01:41:40 INFO ContextCleaner: Cleaned accumulator 667
21/02/17 01:41:40 INFO ContextCleaner: Cleaned accumulator 519
21/02/17 01:41:40 INFO ContextCleaner: Cleaned accumulator 615
21/02/17 01:41:40 INFO ContextCleaner: Cleaned accumulator 878
21/02/17 01:41:40 INFO ContextCleaner: Cleaned accumulator 891
21/02/17 01:41:40 INFO ContextCleaner: Cleaned accumulator 722
21/02/17 01:41:40 INFO ContextCleaner: Cleaned accumulator 595
21/02/17 01:41:40 INFO ContextCleaner: Cleaned accumulator 764
21/02/17 01:41:40 INFO ContextCleaner: Cleaned accumulator 740
21/02/17 01:41:40 INFO ContextCleaner: Cleaned accumulator 636
21/02/17 01:41:40 INFO ContextCleaner: Cleaned shuffle 6
21/02/17 01:41:40 INFO ContextCleaner: Cleaned accumulator 657
21/02/17 01:41:40 INFO BlockManagerInfo: Removed broadcast_25_piece0 on localhost:41253 in memory (size: 25.6 KB, free: 912.2 MB)
21/02/17 01:41:40 INFO ContextCleaner: Cleaned accumulator 725
21/02/17 01:41:40 INFO ContextCleaner: Cleaned accumulator 535
21/02/17 01:41:40 INFO ContextCleaner: Cleaned accumulator 810
21/02/17 01:41:40 INFO ContextCleaner: Cleaned accumulator 513
21/02/17 01:41:40 INFO ContextCleaner: Cleaned accumulator 635
21/02/17 01:41:40 INFO ContextCleaner: Cleaned accumulator 551
21/02/17 01:41:40 INFO ContextCleaner: Cleaned accumulator 865
21/02/17 01:41:40 INFO ContextCleaner: Cleaned accumulator 753
21/02/17 01:41:40 INFO ContextCleaner: Cleaned accumulator 772
21/02/17 01:41:40 INFO ContextCleaner: Cleaned accumulator 586
21/02/17 01:41:40 INFO ContextCleaner: Cleaned accumulator 517
21/02/17 01:41:40 INFO ContextCleaner: Cleaned accumulator 749
21/02/17 01:41:40 INFO ContextCleaner: Cleaned accumulator 629
21/02/17 01:41:40 INFO ContextCleaner: Cleaned accumulator 538
21/02/17 01:41:40 INFO ContextCleaner: Cleaned accumulator 760
21/02/17 01:41:40 INFO ContextCleaner: Cleaned accumulator 798
21/02/17 01:41:40 INFO ContextCleaner: Cleaned accumulator 654
21/02/17 01:41:40 INFO ContextCleaner: Cleaned accumulator 738
21/02/17 01:41:40 INFO ContextCleaner: Cleaned accumulator 840
21/02/17 01:41:40 INFO BlockManagerInfo: Removed broadcast_30_piece0 on localhost:41253 in memory (size: 24.5 KB, free: 912.2 MB)
21/02/17 01:41:40 INFO BlockManagerInfo: Removed broadcast_33_piece0 on localhost:41253 in memory (size: 3.8 KB, free: 912.2 MB)
21/02/17 01:41:40 INFO ContextCleaner: Cleaned accumulator 706
21/02/17 01:41:40 INFO ContextCleaner: Cleaned accumulator 710
21/02/17 01:41:40 INFO ContextCleaner: Cleaned accumulator 541
21/02/17 01:41:40 INFO ContextCleaner: Cleaned accumulator 741
21/02/17 01:41:40 INFO ContextCleaner: Cleaned accumulator 796
21/02/17 01:41:40 INFO ContextCleaner: Cleaned accumulator 748
21/02/17 01:41:40 INFO ContextCleaner: Cleaned accumulator 623
21/02/17 01:41:40 INFO ContextCleaner: Cleaned accumulator 911
21/02/17 01:41:40 INFO ContextCleaner: Cleaned accumulator 902
21/02/17 01:41:40 INFO ContextCleaner: Cleaned accumulator 596
21/02/17 01:41:40 INFO ContextCleaner: Cleaned accumulator 573
21/02/17 01:41:40 INFO ContextCleaner: Cleaned accumulator 658
21/02/17 01:41:40 INFO ContextCleaner: Cleaned accumulator 831
21/02/17 01:41:40 INFO ContextCleaner: Cleaned accumulator 918
21/02/17 01:41:40 INFO ContextCleaner: Cleaned accumulator 602
21/02/17 01:41:40 INFO ContextCleaner: Cleaned accumulator 859
21/02/17 01:41:40 INFO ContextCleaner: Cleaned accumulator 893
21/02/17 01:41:40 INFO ContextCleaner: Cleaned accumulator 526
21/02/17 01:41:40 INFO ContextCleaner: Cleaned accumulator 780
21/02/17 01:41:40 INFO ContextCleaner: Cleaned accumulator 805
21/02/17 01:41:40 INFO ContextCleaner: Cleaned accumulator 812
21/02/17 01:41:40 INFO ContextCleaner: Cleaned accumulator 523
21/02/17 01:41:40 INFO ContextCleaner: Cleaned accumulator 648
21/02/17 01:41:40 INFO ContextCleaner: Cleaned accumulator 839
21/02/17 01:41:40 INFO ContextCleaner: Cleaned accumulator 679
21/02/17 01:41:40 INFO ContextCleaner: Cleaned accumulator 860
21/02/17 01:41:40 INFO ContextCleaner: Cleaned accumulator 847
21/02/17 01:41:40 INFO ContextCleaner: Cleaned accumulator 813
21/02/17 01:41:40 INFO ContextCleaner: Cleaned accumulator 875
21/02/17 01:41:40 INFO ContextCleaner: Cleaned accumulator 892
21/02/17 01:41:40 INFO ContextCleaner: Cleaned accumulator 549
21/02/17 01:41:40 INFO ContextCleaner: Cleaned accumulator 698
21/02/17 01:41:40 INFO ContextCleaner: Cleaned accumulator 899
21/02/17 01:41:40 INFO ContextCleaner: Cleaned accumulator 502
21/02/17 01:41:40 INFO ContextCleaner: Cleaned accumulator 579
21/02/17 01:41:40 INFO ContextCleaner: Cleaned accumulator 833
21/02/17 01:41:40 INFO ContextCleaner: Cleaned accumulator 849
21/02/17 01:41:40 INFO ContextCleaner: Cleaned accumulator 592
21/02/17 01:41:40 INFO ContextCleaner: Cleaned accumulator 616
21/02/17 01:41:40 INFO ContextCleaner: Cleaned accumulator 781
21/02/17 01:41:40 INFO ContextCleaner: Cleaned accumulator 684
21/02/17 01:41:40 INFO ContextCleaner: Cleaned accumulator 651
21/02/17 01:41:40 INFO ContextCleaner: Cleaned accumulator 567
21/02/17 01:41:40 INFO ContextCleaner: Cleaned accumulator 692
21/02/17 01:41:40 INFO ContextCleaner: Cleaned accumulator 858
21/02/17 01:41:40 INFO ContextCleaner: Cleaned accumulator 874
21/02/17 01:41:40 INFO ContextCleaner: Cleaned accumulator 571
21/02/17 01:41:40 INFO ContextCleaner: Cleaned accumulator 560
21/02/17 01:41:40 INFO ContextCleaner: Cleaned accumulator 644
21/02/17 01:41:40 INFO ContextCleaner: Cleaned accumulator 919
21/02/17 01:41:40 INFO ContextCleaner: Cleaned accumulator 888
21/02/17 01:41:40 INFO ContextCleaner: Cleaned accumulator 707
21/02/17 01:41:40 INFO ContextCleaner: Cleaned accumulator 913
21/02/17 01:41:40 INFO ContextCleaner: Cleaned accumulator 850
21/02/17 01:41:40 INFO ContextCleaner: Cleaned accumulator 640
21/02/17 01:41:40 INFO ContextCleaner: Cleaned accumulator 703
21/02/17 01:41:40 INFO ContextCleaner: Cleaned accumulator 542
21/02/17 01:41:40 INFO ContextCleaner: Cleaned accumulator 730
21/02/17 01:41:40 INFO ContextCleaner: Cleaned accumulator 546
21/02/17 01:41:40 INFO ContextCleaner: Cleaned accumulator 896
21/02/17 01:41:40 INFO ContextCleaner: Cleaned accumulator 671
21/02/17 01:41:40 INFO ContextCleaner: Cleaned accumulator 829
21/02/17 01:41:40 INFO ContextCleaner: Cleaned accumulator 823
21/02/17 01:41:40 INFO ContextCleaner: Cleaned accumulator 879
21/02/17 01:41:40 INFO ContextCleaner: Cleaned accumulator 668
21/02/17 01:41:40 INFO ContextCleaner: Cleaned accumulator 628
21/02/17 01:41:40 INFO ContextCleaner: Cleaned accumulator 745
21/02/17 01:41:40 INFO ContextCleaner: Cleaned accumulator 820
21/02/17 01:41:40 INFO ContextCleaner: Cleaned accumulator 611
21/02/17 01:41:40 INFO ContextCleaner: Cleaned accumulator 769
21/02/17 01:41:40 INFO ContextCleaner: Cleaned accumulator 794
21/02/17 01:41:40 INFO ContextCleaner: Cleaned accumulator 621
21/02/17 01:41:40 INFO ContextCleaner: Cleaned accumulator 503
21/02/17 01:41:40 INFO ContextCleaner: Cleaned accumulator 898
21/02/17 01:41:40 INFO ContextCleaner: Cleaned accumulator 504
21/02/17 01:41:40 INFO ContextCleaner: Cleaned accumulator 509
21/02/17 01:41:40 INFO ContextCleaner: Cleaned accumulator 788
21/02/17 01:41:40 INFO ContextCleaner: Cleaned accumulator 862
21/02/17 01:41:40 INFO BlockManagerInfo: Removed broadcast_27_piece0 on localhost:41253 in memory (size: 53.4 KB, free: 912.2 MB)
21/02/17 01:41:40 INFO ContextCleaner: Cleaned accumulator 518
21/02/17 01:41:40 INFO ContextCleaner: Cleaned accumulator 547
21/02/17 01:41:40 INFO ContextCleaner: Cleaned accumulator 779
21/02/17 01:41:40 INFO ContextCleaner: Cleaned accumulator 580
21/02/17 01:41:40 INFO ContextCleaner: Cleaned accumulator 643
21/02/17 01:41:40 INFO ContextCleaner: Cleaned accumulator 568
21/02/17 01:41:40 INFO ContextCleaner: Cleaned accumulator 709
21/02/17 01:41:40 INFO ContextCleaner: Cleaned accumulator 917
21/02/17 01:41:40 INFO ContextCleaner: Cleaned accumulator 662
21/02/17 01:41:40 INFO ContextCleaner: Cleaned accumulator 864
21/02/17 01:41:40 INFO ContextCleaner: Cleaned accumulator 650
21/02/17 01:41:40 INFO ContextCleaner: Cleaned accumulator 848
21/02/17 01:41:40 INFO ContextCleaner: Cleaned accumulator 566
21/02/17 01:41:40 INFO ContextCleaner: Cleaned accumulator 856
21/02/17 01:41:40 INFO ContextCleaner: Cleaned accumulator 815
21/02/17 01:41:40 INFO BlockManagerInfo: Removed broadcast_17_piece0 on localhost:41253 in memory (size: 25.5 KB, free: 912.3 MB)
21/02/17 01:41:40 INFO ContextCleaner: Cleaned accumulator 633
21/02/17 01:41:40 INFO ContextCleaner: Cleaned accumulator 774
21/02/17 01:41:40 INFO ContextCleaner: Cleaned accumulator 758
21/02/17 01:41:40 INFO ContextCleaner: Cleaned accumulator 528
21/02/17 01:41:40 INFO ContextCleaner: Cleaned accumulator 532
21/02/17 01:41:40 INFO ContextCleaner: Cleaned accumulator 767
21/02/17 01:41:40 INFO ContextCleaner: Cleaned accumulator 886
21/02/17 01:41:40 INFO ContextCleaner: Cleaned accumulator 601
21/02/17 01:41:40 INFO ContextCleaner: Cleaned accumulator 765
21/02/17 01:41:40 INFO ContextCleaner: Cleaned accumulator 852
21/02/17 01:41:40 INFO ContextCleaner: Cleaned accumulator 634
21/02/17 01:41:40 INFO ContextCleaner: Cleaned accumulator 700
21/02/17 01:41:40 INFO ContextCleaner: Cleaned accumulator 759
21/02/17 01:41:40 INFO SparkContext: Starting job: sql at <unknown>:0
21/02/17 01:41:40 INFO DAGScheduler: Registering RDD 113 (sql at <unknown>:0)
21/02/17 01:41:40 INFO DAGScheduler: Got job 24 (sql at <unknown>:0) with 1 output partitions
21/02/17 01:41:40 INFO DAGScheduler: Final stage: ResultStage 33 (sql at <unknown>:0)
21/02/17 01:41:40 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 32)
21/02/17 01:41:40 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 32)
21/02/17 01:41:40 INFO DAGScheduler: Submitting ShuffleMapStage 32 (MapPartitionsRDD[113] at sql at <unknown>:0), which has no missing parents
21/02/17 01:41:40 INFO MemoryStore: Block broadcast_35 stored as values in memory (estimated size 20.2 KB, free 912.0 MB)
21/02/17 01:41:40 INFO MemoryStore: Block broadcast_35_piece0 stored as bytes in memory (estimated size 9.6 KB, free 911.9 MB)
21/02/17 01:41:40 INFO BlockManagerInfo: Added broadcast_35_piece0 in memory on localhost:41253 (size: 9.6 KB, free: 912.3 MB)
21/02/17 01:41:40 INFO SparkContext: Created broadcast 35 from broadcast at DAGScheduler.scala:1161
21/02/17 01:41:40 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 32 (MapPartitionsRDD[113] at sql at <unknown>:0) (first 15 tasks are for partitions Vector(0))
21/02/17 01:41:40 INFO TaskSchedulerImpl: Adding task set 32.0 with 1 tasks
21/02/17 01:41:40 INFO TaskSetManager: Starting task 0.0 in stage 32.0 (TID 34, localhost, executor driver, partition 0, PROCESS_LOCAL, 8265 bytes)
21/02/17 01:41:40 INFO Executor: Running task 0.0 in stage 32.0 (TID 34)
21/02/17 01:41:40 INFO FileScanRDD: Reading File path: file:///tmp/Rtmp09Oz4e/file22e22736a8feb/metadata/part-00000, range: 0-306, partition values: [empty row]
21/02/17 01:41:40 INFO CodeGenerator: Code generated in 7.305302 ms
21/02/17 01:41:40 INFO MemoryStore: Block rdd_108_0 stored as values in memory (estimated size 1296.0 B, free 911.9 MB)
21/02/17 01:41:40 INFO BlockManagerInfo: Added rdd_108_0 in memory on localhost:41253 (size: 1296.0 B, free: 912.3 MB)
21/02/17 01:41:40 INFO CodeGenerator: Code generated in 8.008841 ms
21/02/17 01:41:40 INFO Executor: Finished task 0.0 in stage 32.0 (TID 34). 1871 bytes result sent to driver
21/02/17 01:41:40 INFO TaskSetManager: Finished task 0.0 in stage 32.0 (TID 34) in 49 ms on localhost (executor driver) (1/1)
21/02/17 01:41:40 INFO TaskSchedulerImpl: Removed TaskSet 32.0, whose tasks have all completed, from pool 
21/02/17 01:41:40 INFO DAGScheduler: ShuffleMapStage 32 (sql at <unknown>:0) finished in 0.055 s
21/02/17 01:41:40 INFO DAGScheduler: looking for newly runnable stages
21/02/17 01:41:40 INFO DAGScheduler: running: Set()
21/02/17 01:41:40 INFO DAGScheduler: waiting: Set(ResultStage 33)
21/02/17 01:41:40 INFO DAGScheduler: failed: Set()
21/02/17 01:41:40 INFO DAGScheduler: Submitting ResultStage 33 (MapPartitionsRDD[116] at sql at <unknown>:0), which has no missing parents
21/02/17 01:41:40 INFO MemoryStore: Block broadcast_36 stored as values in memory (estimated size 7.1 KB, free 911.9 MB)
21/02/17 01:41:40 INFO MemoryStore: Block broadcast_36_piece0 stored as bytes in memory (estimated size 3.8 KB, free 911.9 MB)
21/02/17 01:41:40 INFO BlockManagerInfo: Added broadcast_36_piece0 in memory on localhost:41253 (size: 3.8 KB, free: 912.3 MB)
21/02/17 01:41:40 INFO SparkContext: Created broadcast 36 from broadcast at DAGScheduler.scala:1161
21/02/17 01:41:40 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 33 (MapPartitionsRDD[116] at sql at <unknown>:0) (first 15 tasks are for partitions Vector(0))
21/02/17 01:41:40 INFO TaskSchedulerImpl: Adding task set 33.0 with 1 tasks
21/02/17 01:41:40 INFO TaskSetManager: Starting task 0.0 in stage 33.0 (TID 35, localhost, executor driver, partition 0, NODE_LOCAL, 7767 bytes)
21/02/17 01:41:40 INFO Executor: Running task 0.0 in stage 33.0 (TID 35)
21/02/17 01:41:40 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks including 1 local blocks and 0 remote blocks
21/02/17 01:41:40 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
21/02/17 01:41:40 INFO Executor: Finished task 0.0 in stage 33.0 (TID 35). 1782 bytes result sent to driver
21/02/17 01:41:40 INFO TaskSetManager: Finished task 0.0 in stage 33.0 (TID 35) in 4 ms on localhost (executor driver) (1/1)
21/02/17 01:41:40 INFO TaskSchedulerImpl: Removed TaskSet 33.0, whose tasks have all completed, from pool 
21/02/17 01:41:40 INFO DAGScheduler: ResultStage 33 (sql at <unknown>:0) finished in 0.007 s
21/02/17 01:41:40 INFO DAGScheduler: Job 24 finished: sql at <unknown>:0, took 0.064432 s
21/02/17 01:41:40 INFO CodeGenerator: Code generated in 6.347648 ms
21/02/17 01:41:40 INFO SparkContext: Starting job: collect at utils.scala:135
21/02/17 01:41:40 INFO DAGScheduler: Registering RDD 121 (collect at utils.scala:135)
21/02/17 01:41:40 INFO DAGScheduler: Got job 25 (collect at utils.scala:135) with 1 output partitions
21/02/17 01:41:40 INFO DAGScheduler: Final stage: ResultStage 35 (collect at utils.scala:135)
21/02/17 01:41:40 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 34)
21/02/17 01:41:40 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 34)
21/02/17 01:41:40 INFO DAGScheduler: Submitting ShuffleMapStage 34 (MapPartitionsRDD[121] at collect at utils.scala:135), which has no missing parents
21/02/17 01:41:40 INFO MemoryStore: Block broadcast_37 stored as values in memory (estimated size 20.2 KB, free 911.9 MB)
21/02/17 01:41:40 INFO MemoryStore: Block broadcast_37_piece0 stored as bytes in memory (estimated size 9.6 KB, free 911.9 MB)
21/02/17 01:41:40 INFO BlockManagerInfo: Added broadcast_37_piece0 in memory on localhost:41253 (size: 9.6 KB, free: 912.2 MB)
21/02/17 01:41:40 INFO SparkContext: Created broadcast 37 from broadcast at DAGScheduler.scala:1161
21/02/17 01:41:40 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 34 (MapPartitionsRDD[121] at collect at utils.scala:135) (first 15 tasks are for partitions Vector(0))
21/02/17 01:41:40 INFO TaskSchedulerImpl: Adding task set 34.0 with 1 tasks
21/02/17 01:41:40 INFO TaskSetManager: Starting task 0.0 in stage 34.0 (TID 36, localhost, executor driver, partition 0, PROCESS_LOCAL, 8265 bytes)
21/02/17 01:41:40 INFO Executor: Running task 0.0 in stage 34.0 (TID 36)
21/02/17 01:41:40 INFO BlockManager: Found block rdd_108_0 locally
21/02/17 01:41:40 INFO Executor: Finished task 0.0 in stage 34.0 (TID 36). 1871 bytes result sent to driver
21/02/17 01:41:40 INFO TaskSetManager: Finished task 0.0 in stage 34.0 (TID 36) in 7 ms on localhost (executor driver) (1/1)
21/02/17 01:41:40 INFO TaskSchedulerImpl: Removed TaskSet 34.0, whose tasks have all completed, from pool 
21/02/17 01:41:40 INFO DAGScheduler: ShuffleMapStage 34 (collect at utils.scala:135) finished in 0.011 s
21/02/17 01:41:40 INFO DAGScheduler: looking for newly runnable stages
21/02/17 01:41:40 INFO DAGScheduler: running: Set()
21/02/17 01:41:40 INFO DAGScheduler: waiting: Set(ResultStage 35)
21/02/17 01:41:40 INFO DAGScheduler: failed: Set()
21/02/17 01:41:40 INFO DAGScheduler: Submitting ResultStage 35 (MapPartitionsRDD[124] at collect at utils.scala:135), which has no missing parents
21/02/17 01:41:40 INFO MemoryStore: Block broadcast_38 stored as values in memory (estimated size 7.1 KB, free 911.9 MB)
21/02/17 01:41:40 INFO MemoryStore: Block broadcast_38_piece0 stored as bytes in memory (estimated size 3.8 KB, free 911.9 MB)
21/02/17 01:41:40 INFO BlockManagerInfo: Added broadcast_38_piece0 in memory on localhost:41253 (size: 3.8 KB, free: 912.2 MB)
21/02/17 01:41:40 INFO SparkContext: Created broadcast 38 from broadcast at DAGScheduler.scala:1161
21/02/17 01:41:40 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 35 (MapPartitionsRDD[124] at collect at utils.scala:135) (first 15 tasks are for partitions Vector(0))
21/02/17 01:41:40 INFO TaskSchedulerImpl: Adding task set 35.0 with 1 tasks
21/02/17 01:41:40 INFO TaskSetManager: Starting task 0.0 in stage 35.0 (TID 37, localhost, executor driver, partition 0, NODE_LOCAL, 7767 bytes)
21/02/17 01:41:40 INFO Executor: Running task 0.0 in stage 35.0 (TID 37)
21/02/17 01:41:40 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks including 1 local blocks and 0 remote blocks
21/02/17 01:41:40 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
21/02/17 01:41:40 INFO Executor: Finished task 0.0 in stage 35.0 (TID 37). 1782 bytes result sent to driver
21/02/17 01:41:40 INFO TaskSetManager: Finished task 0.0 in stage 35.0 (TID 37) in 4 ms on localhost (executor driver) (1/1)
21/02/17 01:41:40 INFO TaskSchedulerImpl: Removed TaskSet 35.0, whose tasks have all completed, from pool 
21/02/17 01:41:40 INFO DAGScheduler: ResultStage 35 (collect at utils.scala:135) finished in 0.007 s
21/02/17 01:41:40 INFO DAGScheduler: Job 25 finished: collect at utils.scala:135, took 0.021283 s
21/02/17 01:41:40 INFO CodeGenerator: Code generated in 9.446658 ms
21/02/17 01:41:40 INFO CodeGenerator: Code generated in 6.869989 ms
21/02/17 01:41:40 INFO SparkContext: Starting job: count at utils.scala:135
21/02/17 01:41:40 INFO DAGScheduler: Registering RDD 129 (count at utils.scala:135)
21/02/17 01:41:40 INFO DAGScheduler: Got job 26 (count at utils.scala:135) with 1 output partitions
21/02/17 01:41:40 INFO DAGScheduler: Final stage: ResultStage 37 (count at utils.scala:135)
21/02/17 01:41:40 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 36)
21/02/17 01:41:40 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 36)
21/02/17 01:41:40 INFO DAGScheduler: Submitting ShuffleMapStage 36 (MapPartitionsRDD[129] at count at utils.scala:135), which has no missing parents
21/02/17 01:41:40 INFO MemoryStore: Block broadcast_39 stored as values in memory (estimated size 19.6 KB, free 911.9 MB)
21/02/17 01:41:40 INFO MemoryStore: Block broadcast_39_piece0 stored as bytes in memory (estimated size 9.4 KB, free 911.9 MB)
21/02/17 01:41:40 INFO BlockManagerInfo: Added broadcast_39_piece0 in memory on localhost:41253 (size: 9.4 KB, free: 912.2 MB)
21/02/17 01:41:40 INFO SparkContext: Created broadcast 39 from broadcast at DAGScheduler.scala:1161
21/02/17 01:41:40 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 36 (MapPartitionsRDD[129] at count at utils.scala:135) (first 15 tasks are for partitions Vector(0))
21/02/17 01:41:40 INFO TaskSchedulerImpl: Adding task set 36.0 with 1 tasks
21/02/17 01:41:40 INFO TaskSetManager: Starting task 0.0 in stage 36.0 (TID 38, localhost, executor driver, partition 0, PROCESS_LOCAL, 8265 bytes)
21/02/17 01:41:40 INFO Executor: Running task 0.0 in stage 36.0 (TID 38)
21/02/17 01:41:40 INFO BlockManager: Found block rdd_108_0 locally
21/02/17 01:41:40 INFO Executor: Finished task 0.0 in stage 36.0 (TID 38). 1871 bytes result sent to driver
21/02/17 01:41:40 INFO TaskSetManager: Finished task 0.0 in stage 36.0 (TID 38) in 6 ms on localhost (executor driver) (1/1)
21/02/17 01:41:40 INFO TaskSchedulerImpl: Removed TaskSet 36.0, whose tasks have all completed, from pool 
21/02/17 01:41:40 INFO DAGScheduler: ShuffleMapStage 36 (count at utils.scala:135) finished in 0.011 s
21/02/17 01:41:40 INFO DAGScheduler: looking for newly runnable stages
21/02/17 01:41:40 INFO DAGScheduler: running: Set()
21/02/17 01:41:40 INFO DAGScheduler: waiting: Set(ResultStage 37)
21/02/17 01:41:40 INFO DAGScheduler: failed: Set()
21/02/17 01:41:40 INFO DAGScheduler: Submitting ResultStage 37 (MapPartitionsRDD[132] at count at utils.scala:135), which has no missing parents
21/02/17 01:41:40 INFO MemoryStore: Block broadcast_40 stored as values in memory (estimated size 9.1 KB, free 911.9 MB)
21/02/17 01:41:40 INFO MemoryStore: Block broadcast_40_piece0 stored as bytes in memory (estimated size 4.1 KB, free 911.9 MB)
21/02/17 01:41:40 INFO BlockManagerInfo: Added broadcast_40_piece0 in memory on localhost:41253 (size: 4.1 KB, free: 912.2 MB)
21/02/17 01:41:40 INFO SparkContext: Created broadcast 40 from broadcast at DAGScheduler.scala:1161
21/02/17 01:41:40 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 37 (MapPartitionsRDD[132] at count at utils.scala:135) (first 15 tasks are for partitions Vector(0))
21/02/17 01:41:40 INFO TaskSchedulerImpl: Adding task set 37.0 with 1 tasks
21/02/17 01:41:40 INFO TaskSetManager: Starting task 0.0 in stage 37.0 (TID 39, localhost, executor driver, partition 0, NODE_LOCAL, 7767 bytes)
21/02/17 01:41:40 INFO Executor: Running task 0.0 in stage 37.0 (TID 39)
21/02/17 01:41:40 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks including 1 local blocks and 0 remote blocks
21/02/17 01:41:40 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
21/02/17 01:41:40 INFO Executor: Finished task 0.0 in stage 37.0 (TID 39). 2098 bytes result sent to driver
21/02/17 01:41:40 INFO TaskSetManager: Finished task 0.0 in stage 37.0 (TID 39) in 7 ms on localhost (executor driver) (1/1)
21/02/17 01:41:40 INFO TaskSchedulerImpl: Removed TaskSet 37.0, whose tasks have all completed, from pool 
21/02/17 01:41:40 INFO DAGScheduler: ResultStage 37 (count at utils.scala:135) finished in 0.011 s
21/02/17 01:41:40 INFO DAGScheduler: Job 26 finished: count at utils.scala:135, took 0.024881 s
21/02/17 01:41:40 INFO SparkContext: Starting job: collect at utils.scala:135
21/02/17 01:41:40 INFO DAGScheduler: Got job 27 (collect at utils.scala:135) with 1 output partitions
21/02/17 01:41:40 INFO DAGScheduler: Final stage: ResultStage 38 (collect at utils.scala:135)
21/02/17 01:41:40 INFO DAGScheduler: Parents of final stage: List()
21/02/17 01:41:40 INFO DAGScheduler: Missing parents: List()
21/02/17 01:41:40 INFO DAGScheduler: Submitting ResultStage 38 (MapPartitionsRDD[135] at collect at utils.scala:135), which has no missing parents
21/02/17 01:41:40 INFO MemoryStore: Block broadcast_41 stored as values in memory (estimated size 6.2 KB, free 911.8 MB)
21/02/17 01:41:40 INFO MemoryStore: Block broadcast_41_piece0 stored as bytes in memory (estimated size 3.3 KB, free 911.8 MB)
21/02/17 01:41:40 INFO BlockManagerInfo: Added broadcast_41_piece0 in memory on localhost:41253 (size: 3.3 KB, free: 912.2 MB)
21/02/17 01:41:40 INFO SparkContext: Created broadcast 41 from broadcast at DAGScheduler.scala:1161
21/02/17 01:41:40 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 38 (MapPartitionsRDD[135] at collect at utils.scala:135) (first 15 tasks are for partitions Vector(0))
21/02/17 01:41:40 INFO TaskSchedulerImpl: Adding task set 38.0 with 1 tasks
21/02/17 01:41:40 INFO TaskSetManager: Starting task 0.0 in stage 38.0 (TID 40, localhost, executor driver, partition 0, PROCESS_LOCAL, 8080 bytes)
21/02/17 01:41:40 INFO Executor: Running task 0.0 in stage 38.0 (TID 40)
21/02/17 01:41:40 INFO Executor: Finished task 0.0 in stage 38.0 (TID 40). 1243 bytes result sent to driver
21/02/17 01:41:40 INFO TaskSetManager: Finished task 0.0 in stage 38.0 (TID 40) in 3 ms on localhost (executor driver) (1/1)
21/02/17 01:41:40 INFO TaskSchedulerImpl: Removed TaskSet 38.0, whose tasks have all completed, from pool 
21/02/17 01:41:40 INFO DAGScheduler: ResultStage 38 (collect at utils.scala:135) finished in 0.007 s
21/02/17 01:41:40 INFO DAGScheduler: Job 27 finished: collect at utils.scala:135, took 0.008388 s
21/02/17 01:41:40 INFO SparkContext: Starting job: count at utils.scala:135
21/02/17 01:41:40 INFO DAGScheduler: Registering RDD 138 (count at utils.scala:135)
21/02/17 01:41:40 INFO DAGScheduler: Got job 28 (count at utils.scala:135) with 1 output partitions
21/02/17 01:41:40 INFO DAGScheduler: Final stage: ResultStage 40 (count at utils.scala:135)
21/02/17 01:41:40 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 39)
21/02/17 01:41:40 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 39)
21/02/17 01:41:40 INFO DAGScheduler: Submitting ShuffleMapStage 39 (MapPartitionsRDD[138] at count at utils.scala:135), which has no missing parents
21/02/17 01:41:40 INFO MemoryStore: Block broadcast_42 stored as values in memory (estimated size 8.4 KB, free 911.8 MB)
21/02/17 01:41:40 INFO MemoryStore: Block broadcast_42_piece0 stored as bytes in memory (estimated size 4.5 KB, free 911.8 MB)
21/02/17 01:41:40 INFO BlockManagerInfo: Added broadcast_42_piece0 in memory on localhost:41253 (size: 4.5 KB, free: 912.2 MB)
21/02/17 01:41:40 INFO SparkContext: Created broadcast 42 from broadcast at DAGScheduler.scala:1161
21/02/17 01:41:40 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 39 (MapPartitionsRDD[138] at count at utils.scala:135) (first 15 tasks are for partitions Vector(0))
21/02/17 01:41:40 INFO TaskSchedulerImpl: Adding task set 39.0 with 1 tasks
21/02/17 01:41:40 INFO TaskSetManager: Starting task 0.0 in stage 39.0 (TID 41, localhost, executor driver, partition 0, PROCESS_LOCAL, 8069 bytes)
21/02/17 01:41:40 INFO Executor: Running task 0.0 in stage 39.0 (TID 41)
21/02/17 01:41:40 INFO Executor: Finished task 0.0 in stage 39.0 (TID 41). 1499 bytes result sent to driver
21/02/17 01:41:40 INFO TaskSetManager: Finished task 0.0 in stage 39.0 (TID 41) in 5 ms on localhost (executor driver) (1/1)
21/02/17 01:41:40 INFO TaskSchedulerImpl: Removed TaskSet 39.0, whose tasks have all completed, from pool 
21/02/17 01:41:40 INFO DAGScheduler: ShuffleMapStage 39 (count at utils.scala:135) finished in 0.011 s
21/02/17 01:41:40 INFO DAGScheduler: looking for newly runnable stages
21/02/17 01:41:40 INFO DAGScheduler: running: Set()
21/02/17 01:41:40 INFO DAGScheduler: waiting: Set(ResultStage 40)
21/02/17 01:41:40 INFO DAGScheduler: failed: Set()
21/02/17 01:41:40 INFO DAGScheduler: Submitting ResultStage 40 (MapPartitionsRDD[141] at count at utils.scala:135), which has no missing parents
21/02/17 01:41:40 INFO MemoryStore: Block broadcast_43 stored as values in memory (estimated size 7.1 KB, free 911.8 MB)
21/02/17 01:41:40 INFO MemoryStore: Block broadcast_43_piece0 stored as bytes in memory (estimated size 3.8 KB, free 911.8 MB)
21/02/17 01:41:40 INFO BlockManagerInfo: Added broadcast_43_piece0 in memory on localhost:41253 (size: 3.8 KB, free: 912.2 MB)
21/02/17 01:41:40 INFO SparkContext: Created broadcast 43 from broadcast at DAGScheduler.scala:1161
21/02/17 01:41:40 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 40 (MapPartitionsRDD[141] at count at utils.scala:135) (first 15 tasks are for partitions Vector(0))
21/02/17 01:41:40 INFO TaskSchedulerImpl: Adding task set 40.0 with 1 tasks
21/02/17 01:41:40 INFO TaskSetManager: Starting task 0.0 in stage 40.0 (TID 42, localhost, executor driver, partition 0, NODE_LOCAL, 7767 bytes)
21/02/17 01:41:40 INFO Executor: Running task 0.0 in stage 40.0 (TID 42)
21/02/17 01:41:40 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks including 1 local blocks and 0 remote blocks
21/02/17 01:41:40 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
21/02/17 01:41:40 INFO Executor: Finished task 0.0 in stage 40.0 (TID 42). 1782 bytes result sent to driver
21/02/17 01:41:40 INFO TaskSetManager: Finished task 0.0 in stage 40.0 (TID 42) in 5 ms on localhost (executor driver) (1/1)
21/02/17 01:41:40 INFO TaskSchedulerImpl: Removed TaskSet 40.0, whose tasks have all completed, from pool 
21/02/17 01:41:40 INFO DAGScheduler: ResultStage 40 (count at utils.scala:135) finished in 0.008 s
21/02/17 01:41:40 INFO DAGScheduler: Job 28 finished: count at utils.scala:135, took 0.022283 s
21/02/17 01:41:41 INFO CodeGenerator: Code generated in 4.443831 ms
21/02/17 01:41:41 INFO SparkContext: Starting job: collect at utils.scala:135
21/02/17 01:41:41 INFO DAGScheduler: Got job 29 (collect at utils.scala:135) with 1 output partitions
21/02/17 01:41:41 INFO DAGScheduler: Final stage: ResultStage 41 (collect at utils.scala:135)
21/02/17 01:41:41 INFO DAGScheduler: Parents of final stage: List()
21/02/17 01:41:41 INFO DAGScheduler: Missing parents: List()
21/02/17 01:41:41 INFO DAGScheduler: Submitting ResultStage 41 (MapPartitionsRDD[145] at collect at utils.scala:135), which has no missing parents
21/02/17 01:41:41 INFO MemoryStore: Block broadcast_44 stored as values in memory (estimated size 16.5 KB, free 911.8 MB)
21/02/17 01:41:41 INFO MemoryStore: Block broadcast_44_piece0 stored as bytes in memory (estimated size 8.2 KB, free 911.8 MB)
21/02/17 01:41:41 INFO BlockManagerInfo: Added broadcast_44_piece0 in memory on localhost:41253 (size: 8.2 KB, free: 912.2 MB)
21/02/17 01:41:41 INFO SparkContext: Created broadcast 44 from broadcast at DAGScheduler.scala:1161
21/02/17 01:41:41 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 41 (MapPartitionsRDD[145] at collect at utils.scala:135) (first 15 tasks are for partitions Vector(0))
21/02/17 01:41:41 INFO TaskSchedulerImpl: Adding task set 41.0 with 1 tasks
21/02/17 01:41:41 INFO TaskSetManager: Starting task 0.0 in stage 41.0 (TID 43, localhost, executor driver, partition 0, PROCESS_LOCAL, 8276 bytes)
21/02/17 01:41:41 INFO Executor: Running task 0.0 in stage 41.0 (TID 43)
21/02/17 01:41:41 INFO BlockManager: Found block rdd_108_0 locally
21/02/17 01:41:41 INFO CodeGenerator: Code generated in 11.643827 ms
21/02/17 01:41:41 INFO Executor: Finished task 0.0 in stage 41.0 (TID 43). 1615 bytes result sent to driver
21/02/17 01:41:41 INFO TaskSetManager: Finished task 0.0 in stage 41.0 (TID 43) in 17 ms on localhost (executor driver) (1/1)
21/02/17 01:41:41 INFO TaskSchedulerImpl: Removed TaskSet 41.0, whose tasks have all completed, from pool 
21/02/17 01:41:41 INFO DAGScheduler: ResultStage 41 (collect at utils.scala:135) finished in 0.023 s
21/02/17 01:41:41 INFO DAGScheduler: Job 29 finished: collect at utils.scala:135, took 0.024915 s
21/02/17 01:41:41 INFO SparkContext: Starting job: count at utils.scala:135
21/02/17 01:41:41 INFO DAGScheduler: Registering RDD 150 (count at utils.scala:135)
21/02/17 01:41:41 INFO DAGScheduler: Got job 30 (count at utils.scala:135) with 1 output partitions
21/02/17 01:41:41 INFO DAGScheduler: Final stage: ResultStage 43 (count at utils.scala:135)
21/02/17 01:41:41 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 42)
21/02/17 01:41:41 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 42)
21/02/17 01:41:41 INFO DAGScheduler: Submitting ShuffleMapStage 42 (MapPartitionsRDD[150] at count at utils.scala:135), which has no missing parents
21/02/17 01:41:41 INFO MemoryStore: Block broadcast_45 stored as values in memory (estimated size 20.2 KB, free 911.8 MB)
21/02/17 01:41:41 INFO MemoryStore: Block broadcast_45_piece0 stored as bytes in memory (estimated size 9.6 KB, free 911.8 MB)
21/02/17 01:41:41 INFO BlockManagerInfo: Added broadcast_45_piece0 in memory on localhost:41253 (size: 9.6 KB, free: 912.2 MB)
21/02/17 01:41:41 INFO SparkContext: Created broadcast 45 from broadcast at DAGScheduler.scala:1161
21/02/17 01:41:41 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 42 (MapPartitionsRDD[150] at count at utils.scala:135) (first 15 tasks are for partitions Vector(0))
21/02/17 01:41:41 INFO TaskSchedulerImpl: Adding task set 42.0 with 1 tasks
21/02/17 01:41:41 INFO TaskSetManager: Starting task 0.0 in stage 42.0 (TID 44, localhost, executor driver, partition 0, PROCESS_LOCAL, 8265 bytes)
21/02/17 01:41:41 INFO Executor: Running task 0.0 in stage 42.0 (TID 44)
21/02/17 01:41:41 INFO BlockManager: Found block rdd_108_0 locally
21/02/17 01:41:41 INFO Executor: Finished task 0.0 in stage 42.0 (TID 44). 1871 bytes result sent to driver
21/02/17 01:41:41 INFO TaskSetManager: Finished task 0.0 in stage 42.0 (TID 44) in 6 ms on localhost (executor driver) (1/1)
21/02/17 01:41:41 INFO TaskSchedulerImpl: Removed TaskSet 42.0, whose tasks have all completed, from pool 
21/02/17 01:41:41 INFO DAGScheduler: ShuffleMapStage 42 (count at utils.scala:135) finished in 0.012 s
21/02/17 01:41:41 INFO DAGScheduler: looking for newly runnable stages
21/02/17 01:41:41 INFO DAGScheduler: running: Set()
21/02/17 01:41:41 INFO DAGScheduler: waiting: Set(ResultStage 43)
21/02/17 01:41:41 INFO DAGScheduler: failed: Set()
21/02/17 01:41:41 INFO DAGScheduler: Submitting ResultStage 43 (MapPartitionsRDD[153] at count at utils.scala:135), which has no missing parents
21/02/17 01:41:41 INFO MemoryStore: Block broadcast_46 stored as values in memory (estimated size 7.1 KB, free 911.8 MB)
21/02/17 01:41:41 INFO MemoryStore: Block broadcast_46_piece0 stored as bytes in memory (estimated size 3.8 KB, free 911.8 MB)
21/02/17 01:41:41 INFO BlockManagerInfo: Added broadcast_46_piece0 in memory on localhost:41253 (size: 3.8 KB, free: 912.2 MB)
21/02/17 01:41:41 INFO SparkContext: Created broadcast 46 from broadcast at DAGScheduler.scala:1161
21/02/17 01:41:41 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 43 (MapPartitionsRDD[153] at count at utils.scala:135) (first 15 tasks are for partitions Vector(0))
21/02/17 01:41:41 INFO TaskSchedulerImpl: Adding task set 43.0 with 1 tasks
21/02/17 01:41:41 INFO TaskSetManager: Starting task 0.0 in stage 43.0 (TID 45, localhost, executor driver, partition 0, NODE_LOCAL, 7767 bytes)
21/02/17 01:41:41 INFO Executor: Running task 0.0 in stage 43.0 (TID 45)
21/02/17 01:41:41 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks including 1 local blocks and 0 remote blocks
21/02/17 01:41:41 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
21/02/17 01:41:41 INFO Executor: Finished task 0.0 in stage 43.0 (TID 45). 1782 bytes result sent to driver
21/02/17 01:41:41 INFO TaskSetManager: Finished task 0.0 in stage 43.0 (TID 45) in 4 ms on localhost (executor driver) (1/1)
21/02/17 01:41:41 INFO TaskSchedulerImpl: Removed TaskSet 43.0, whose tasks have all completed, from pool 
21/02/17 01:41:41 INFO DAGScheduler: ResultStage 43 (count at utils.scala:135) finished in 0.009 s
21/02/17 01:41:41 INFO DAGScheduler: Job 30 finished: count at utils.scala:135, took 0.024866 s
21/02/17 01:41:41 INFO MapPartitionsRDD: Removing RDD 108 from persistence list
21/02/17 01:41:41 INFO BlockManager: Removing RDD 108
21/02/17 01:41:41 INFO MemoryStore: Block broadcast_47 stored as values in memory (estimated size 239.6 KB, free 911.5 MB)
21/02/17 01:41:41 INFO MemoryStore: Block broadcast_47_piece0 stored as bytes in memory (estimated size 23.2 KB, free 911.5 MB)
21/02/17 01:41:41 INFO BlockManagerInfo: Added broadcast_47_piece0 in memory on localhost:41253 (size: 23.2 KB, free: 912.2 MB)
21/02/17 01:41:41 INFO SparkContext: Created broadcast 47 from textFile at ReadWrite.scala:615
21/02/17 01:41:41 INFO FileInputFormat: Total input paths to process : 1
21/02/17 01:41:41 INFO SparkContext: Starting job: first at ReadWrite.scala:615
21/02/17 01:41:41 INFO DAGScheduler: Got job 31 (first at ReadWrite.scala:615) with 1 output partitions
21/02/17 01:41:41 INFO DAGScheduler: Final stage: ResultStage 44 (first at ReadWrite.scala:615)
21/02/17 01:41:41 INFO DAGScheduler: Parents of final stage: List()
21/02/17 01:41:41 INFO DAGScheduler: Missing parents: List()
21/02/17 01:41:41 INFO DAGScheduler: Submitting ResultStage 44 (/tmp/Rtmp09Oz4e/file22e22736a8feb/metadata MapPartitionsRDD[155] at textFile at ReadWrite.scala:615), which has no missing parents
21/02/17 01:41:41 INFO MemoryStore: Block broadcast_48 stored as values in memory (estimated size 3.5 KB, free 911.5 MB)
21/02/17 01:41:41 INFO MemoryStore: Block broadcast_48_piece0 stored as bytes in memory (estimated size 2.1 KB, free 911.5 MB)
21/02/17 01:41:41 INFO BlockManagerInfo: Added broadcast_48_piece0 in memory on localhost:41253 (size: 2.1 KB, free: 912.2 MB)
21/02/17 01:41:41 INFO SparkContext: Created broadcast 48 from broadcast at DAGScheduler.scala:1161
21/02/17 01:41:41 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 44 (/tmp/Rtmp09Oz4e/file22e22736a8feb/metadata MapPartitionsRDD[155] at textFile at ReadWrite.scala:615) (first 15 tasks are for partitions Vector(0))
21/02/17 01:41:41 INFO TaskSchedulerImpl: Adding task set 44.0 with 1 tasks
21/02/17 01:41:41 INFO TaskSetManager: Starting task 0.0 in stage 44.0 (TID 46, localhost, executor driver, partition 0, PROCESS_LOCAL, 7918 bytes)
21/02/17 01:41:41 INFO Executor: Running task 0.0 in stage 44.0 (TID 46)
21/02/17 01:41:41 INFO HadoopRDD: Input split: file:/tmp/Rtmp09Oz4e/file22e22736a8feb/metadata/part-00000:0+306
21/02/17 01:41:41 INFO Executor: Finished task 0.0 in stage 44.0 (TID 46). 1105 bytes result sent to driver
21/02/17 01:41:41 INFO TaskSetManager: Finished task 0.0 in stage 44.0 (TID 46) in 21 ms on localhost (executor driver) (1/1)
21/02/17 01:41:41 INFO TaskSchedulerImpl: Removed TaskSet 44.0, whose tasks have all completed, from pool 
21/02/17 01:41:41 INFO DAGScheduler: ResultStage 44 (first at ReadWrite.scala:615) finished in 0.024 s
21/02/17 01:41:41 INFO DAGScheduler: Job 31 finished: first at ReadWrite.scala:615, took 0.027392 s
21/02/17 01:41:41 INFO MemoryStore: Block broadcast_49 stored as values in memory (estimated size 239.6 KB, free 911.3 MB)
21/02/17 01:41:41 INFO MemoryStore: Block broadcast_49_piece0 stored as bytes in memory (estimated size 23.2 KB, free 911.2 MB)
21/02/17 01:41:41 INFO BlockManagerInfo: Added broadcast_49_piece0 in memory on localhost:41253 (size: 23.2 KB, free: 912.1 MB)
21/02/17 01:41:41 INFO SparkContext: Created broadcast 49 from textFile at ReadWrite.scala:615
21/02/17 01:41:41 INFO FileInputFormat: Total input paths to process : 1
21/02/17 01:41:41 INFO SparkContext: Starting job: first at ReadWrite.scala:615
21/02/17 01:41:41 INFO DAGScheduler: Got job 32 (first at ReadWrite.scala:615) with 1 output partitions
21/02/17 01:41:41 INFO DAGScheduler: Final stage: ResultStage 45 (first at ReadWrite.scala:615)
21/02/17 01:41:41 INFO DAGScheduler: Parents of final stage: List()
21/02/17 01:41:41 INFO DAGScheduler: Missing parents: List()
21/02/17 01:41:41 INFO DAGScheduler: Submitting ResultStage 45 (/tmp/Rtmp09Oz4e/file22e22736a8feb/stages/0_r_formula__9467ebc0_1e9a_44aa_b6e1_220b95e6649f/metadata MapPartitionsRDD[157] at textFile at ReadWrite.scala:615), which has no missing parents
21/02/17 01:41:41 INFO MemoryStore: Block broadcast_50 stored as values in memory (estimated size 3.5 KB, free 911.2 MB)
21/02/17 01:41:41 INFO MemoryStore: Block broadcast_50_piece0 stored as bytes in memory (estimated size 2.1 KB, free 911.2 MB)
21/02/17 01:41:41 INFO BlockManagerInfo: Added broadcast_50_piece0 in memory on localhost:41253 (size: 2.1 KB, free: 912.1 MB)
21/02/17 01:41:41 INFO SparkContext: Created broadcast 50 from broadcast at DAGScheduler.scala:1161
21/02/17 01:41:41 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 45 (/tmp/Rtmp09Oz4e/file22e22736a8feb/stages/0_r_formula__9467ebc0_1e9a_44aa_b6e1_220b95e6649f/metadata MapPartitionsRDD[157] at textFile at ReadWrite.scala:615) (first 15 tasks are for partitions Vector(0))
21/02/17 01:41:41 INFO TaskSchedulerImpl: Adding task set 45.0 with 1 tasks
21/02/17 01:41:41 INFO TaskSetManager: Starting task 0.0 in stage 45.0 (TID 47, localhost, executor driver, partition 0, PROCESS_LOCAL, 7975 bytes)
21/02/17 01:41:41 INFO Executor: Running task 0.0 in stage 45.0 (TID 47)
21/02/17 01:41:41 INFO HadoopRDD: Input split: file:/tmp/Rtmp09Oz4e/file22e22736a8feb/stages/0_r_formula__9467ebc0_1e9a_44aa_b6e1_220b95e6649f/metadata/part-00000:0+447
21/02/17 01:41:41 INFO Executor: Finished task 0.0 in stage 45.0 (TID 47). 1246 bytes result sent to driver
21/02/17 01:41:41 INFO TaskSetManager: Finished task 0.0 in stage 45.0 (TID 47) in 3 ms on localhost (executor driver) (1/1)
21/02/17 01:41:41 INFO TaskSchedulerImpl: Removed TaskSet 45.0, whose tasks have all completed, from pool 
21/02/17 01:41:41 INFO DAGScheduler: ResultStage 45 (first at ReadWrite.scala:615) finished in 0.006 s
21/02/17 01:41:41 INFO DAGScheduler: Job 32 finished: first at ReadWrite.scala:615, took 0.008156 s
21/02/17 01:41:41 INFO MemoryStore: Block broadcast_51 stored as values in memory (estimated size 239.6 KB, free 911.0 MB)
21/02/17 01:41:41 INFO MemoryStore: Block broadcast_51_piece0 stored as bytes in memory (estimated size 23.2 KB, free 911.0 MB)
21/02/17 01:41:41 INFO BlockManagerInfo: Added broadcast_51_piece0 in memory on localhost:41253 (size: 23.2 KB, free: 912.1 MB)
21/02/17 01:41:41 INFO SparkContext: Created broadcast 51 from textFile at ReadWrite.scala:615
21/02/17 01:41:41 INFO FileInputFormat: Total input paths to process : 1
21/02/17 01:41:41 INFO SparkContext: Starting job: first at ReadWrite.scala:615
21/02/17 01:41:41 INFO DAGScheduler: Got job 33 (first at ReadWrite.scala:615) with 1 output partitions
21/02/17 01:41:41 INFO DAGScheduler: Final stage: ResultStage 46 (first at ReadWrite.scala:615)
21/02/17 01:41:41 INFO DAGScheduler: Parents of final stage: List()
21/02/17 01:41:41 INFO DAGScheduler: Missing parents: List()
21/02/17 01:41:41 INFO DAGScheduler: Submitting ResultStage 46 (/tmp/Rtmp09Oz4e/file22e22736a8feb/stages/0_r_formula__9467ebc0_1e9a_44aa_b6e1_220b95e6649f/metadata MapPartitionsRDD[159] at textFile at ReadWrite.scala:615), which has no missing parents
21/02/17 01:41:41 INFO MemoryStore: Block broadcast_52 stored as values in memory (estimated size 3.5 KB, free 911.0 MB)
21/02/17 01:41:41 INFO MemoryStore: Block broadcast_52_piece0 stored as bytes in memory (estimated size 2.1 KB, free 911.0 MB)
21/02/17 01:41:41 INFO BlockManagerInfo: Added broadcast_52_piece0 in memory on localhost:41253 (size: 2.1 KB, free: 912.1 MB)
21/02/17 01:41:41 INFO SparkContext: Created broadcast 52 from broadcast at DAGScheduler.scala:1161
21/02/17 01:41:41 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 46 (/tmp/Rtmp09Oz4e/file22e22736a8feb/stages/0_r_formula__9467ebc0_1e9a_44aa_b6e1_220b95e6649f/metadata MapPartitionsRDD[159] at textFile at ReadWrite.scala:615) (first 15 tasks are for partitions Vector(0))
21/02/17 01:41:41 INFO TaskSchedulerImpl: Adding task set 46.0 with 1 tasks
21/02/17 01:41:41 INFO TaskSetManager: Starting task 0.0 in stage 46.0 (TID 48, localhost, executor driver, partition 0, PROCESS_LOCAL, 7975 bytes)
21/02/17 01:41:41 INFO Executor: Running task 0.0 in stage 46.0 (TID 48)
21/02/17 01:41:41 INFO HadoopRDD: Input split: file:/tmp/Rtmp09Oz4e/file22e22736a8feb/stages/0_r_formula__9467ebc0_1e9a_44aa_b6e1_220b95e6649f/metadata/part-00000:0+447
21/02/17 01:41:41 INFO Executor: Finished task 0.0 in stage 46.0 (TID 48). 1246 bytes result sent to driver
21/02/17 01:41:41 INFO TaskSetManager: Finished task 0.0 in stage 46.0 (TID 48) in 3 ms on localhost (executor driver) (1/1)
21/02/17 01:41:41 INFO TaskSchedulerImpl: Removed TaskSet 46.0, whose tasks have all completed, from pool 
21/02/17 01:41:41 INFO DAGScheduler: ResultStage 46 (first at ReadWrite.scala:615) finished in 0.006 s
21/02/17 01:41:41 INFO DAGScheduler: Job 33 finished: first at ReadWrite.scala:615, took 0.007581 s
21/02/17 01:41:41 INFO SparkContext: Starting job: parquet at RFormula.scala:438
21/02/17 01:41:41 INFO DAGScheduler: Got job 34 (parquet at RFormula.scala:438) with 1 output partitions
21/02/17 01:41:41 INFO DAGScheduler: Final stage: ResultStage 47 (parquet at RFormula.scala:438)
21/02/17 01:41:41 INFO DAGScheduler: Parents of final stage: List()
21/02/17 01:41:41 INFO DAGScheduler: Missing parents: List()
21/02/17 01:41:41 INFO DAGScheduler: Submitting ResultStage 47 (MapPartitionsRDD[161] at parquet at RFormula.scala:438), which has no missing parents
21/02/17 01:41:41 INFO MemoryStore: Block broadcast_53 stored as values in memory (estimated size 74.1 KB, free 910.9 MB)
21/02/17 01:41:41 INFO MemoryStore: Block broadcast_53_piece0 stored as bytes in memory (estimated size 26.1 KB, free 910.9 MB)
21/02/17 01:41:41 INFO BlockManagerInfo: Added broadcast_53_piece0 in memory on localhost:41253 (size: 26.1 KB, free: 912.1 MB)
21/02/17 01:41:41 INFO SparkContext: Created broadcast 53 from broadcast at DAGScheduler.scala:1161
21/02/17 01:41:41 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 47 (MapPartitionsRDD[161] at parquet at RFormula.scala:438) (first 15 tasks are for partitions Vector(0))
21/02/17 01:41:41 INFO TaskSchedulerImpl: Adding task set 47.0 with 1 tasks
21/02/17 01:41:41 INFO TaskSetManager: Starting task 0.0 in stage 47.0 (TID 49, localhost, executor driver, partition 0, PROCESS_LOCAL, 8135 bytes)
21/02/17 01:41:41 INFO Executor: Running task 0.0 in stage 47.0 (TID 49)
21/02/17 01:41:41 INFO Executor: Finished task 0.0 in stage 47.0 (TID 49). 1686 bytes result sent to driver
21/02/17 01:41:41 INFO TaskSetManager: Finished task 0.0 in stage 47.0 (TID 49) in 28 ms on localhost (executor driver) (1/1)
21/02/17 01:41:41 INFO TaskSchedulerImpl: Removed TaskSet 47.0, whose tasks have all completed, from pool 
21/02/17 01:41:41 INFO DAGScheduler: ResultStage 47 (parquet at RFormula.scala:438) finished in 0.037 s
21/02/17 01:41:41 INFO DAGScheduler: Job 34 finished: parquet at RFormula.scala:438, took 0.038237 s
21/02/17 01:41:41 INFO FileSourceStrategy: Pruning directories with: 
21/02/17 01:41:41 INFO FileSourceStrategy: Post-Scan Filters: 
21/02/17 01:41:41 INFO FileSourceStrategy: Output Data Schema: struct<label: string, terms: array<array<string>>, hasIntercept: boolean ... 1 more fields>
21/02/17 01:41:41 INFO FileSourceScanExec: Pushed Filters: 
21/02/17 01:41:41 INFO CodeGenerator: Code generated in 11.665573 ms
21/02/17 01:41:41 INFO CodeGenerator: Code generated in 6.191534 ms
21/02/17 01:41:41 INFO MemoryStore: Block broadcast_54 stored as values in memory (estimated size 293.1 KB, free 910.6 MB)
21/02/17 01:41:41 INFO MemoryStore: Block broadcast_54_piece0 stored as bytes in memory (estimated size 25.2 KB, free 910.6 MB)
21/02/17 01:41:41 INFO BlockManagerInfo: Added broadcast_54_piece0 in memory on localhost:41253 (size: 25.2 KB, free: 912.1 MB)
21/02/17 01:41:41 INFO SparkContext: Created broadcast 54 from head at RFormula.scala:438
21/02/17 01:41:41 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
21/02/17 01:41:41 INFO SparkContext: Starting job: head at RFormula.scala:438
21/02/17 01:41:41 INFO DAGScheduler: Got job 35 (head at RFormula.scala:438) with 1 output partitions
21/02/17 01:41:41 INFO DAGScheduler: Final stage: ResultStage 48 (head at RFormula.scala:438)
21/02/17 01:41:41 INFO DAGScheduler: Parents of final stage: List()
21/02/17 01:41:41 INFO DAGScheduler: Missing parents: List()
21/02/17 01:41:41 INFO DAGScheduler: Submitting ResultStage 48 (MapPartitionsRDD[165] at head at RFormula.scala:438), which has no missing parents
21/02/17 01:41:41 INFO MemoryStore: Block broadcast_55 stored as values in memory (estimated size 10.4 KB, free 910.6 MB)
21/02/17 01:41:41 INFO MemoryStore: Block broadcast_55_piece0 stored as bytes in memory (estimated size 4.9 KB, free 910.6 MB)
21/02/17 01:41:41 INFO BlockManagerInfo: Added broadcast_55_piece0 in memory on localhost:41253 (size: 4.9 KB, free: 912.1 MB)
21/02/17 01:41:41 INFO SparkContext: Created broadcast 55 from broadcast at DAGScheduler.scala:1161
21/02/17 01:41:41 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 48 (MapPartitionsRDD[165] at head at RFormula.scala:438) (first 15 tasks are for partitions Vector(0))
21/02/17 01:41:41 INFO TaskSchedulerImpl: Adding task set 48.0 with 1 tasks
21/02/17 01:41:41 INFO TaskSetManager: Starting task 0.0 in stage 48.0 (TID 50, localhost, executor driver, partition 0, PROCESS_LOCAL, 8386 bytes)
21/02/17 01:41:41 INFO Executor: Running task 0.0 in stage 48.0 (TID 50)
21/02/17 01:41:41 INFO FileScanRDD: Reading File path: file:///tmp/Rtmp09Oz4e/file22e22736a8feb/stages/0_r_formula__9467ebc0_1e9a_44aa_b6e1_220b95e6649f/data/part-00000-33c6b504-0b5c-4c02-9080-6a9d71fe48e5-c000.snappy.parquet, range: 0-1106, partition values: [empty row]
21/02/17 01:41:41 INFO ParquetReadSupport: Going to read the following fields from the Parquet file:

Parquet form:
message spark_schema {
  optional binary label (UTF8);
  optional group terms (LIST) {
    repeated group list {
      optional group element (LIST) {
        repeated group list {
          optional binary element (UTF8);
        }
      }
    }
  }
  required boolean hasIntercept;
}

Catalyst form:
StructType(StructField(label,StringType,true), StructField(terms,ArrayType(ArrayType(StringType,true),true),true), StructField(hasIntercept,BooleanType,true))
       
21/02/17 01:41:41 INFO CodeGenerator: Code generated in 7.548583 ms
21/02/17 01:41:41 INFO CodecPool: Got brand-new decompressor [.snappy]
21/02/17 01:41:41 INFO Executor: Finished task 0.0 in stage 48.0 (TID 50). 1235 bytes result sent to driver
21/02/17 01:41:41 INFO TaskSetManager: Finished task 0.0 in stage 48.0 (TID 50) in 70 ms on localhost (executor driver) (1/1)
21/02/17 01:41:41 INFO TaskSchedulerImpl: Removed TaskSet 48.0, whose tasks have all completed, from pool 
21/02/17 01:41:41 INFO DAGScheduler: ResultStage 48 (head at RFormula.scala:438) finished in 0.077 s
21/02/17 01:41:41 INFO DAGScheduler: Job 35 finished: head at RFormula.scala:438, took 0.079956 s
21/02/17 01:41:41 INFO MemoryStore: Block broadcast_56 stored as values in memory (estimated size 239.6 KB, free 910.3 MB)
21/02/17 01:41:41 INFO MemoryStore: Block broadcast_56_piece0 stored as bytes in memory (estimated size 23.2 KB, free 910.3 MB)
21/02/17 01:41:41 INFO BlockManagerInfo: Added broadcast_56_piece0 in memory on localhost:41253 (size: 23.2 KB, free: 912.0 MB)
21/02/17 01:41:41 INFO SparkContext: Created broadcast 56 from textFile at ReadWrite.scala:615
21/02/17 01:41:41 INFO FileInputFormat: Total input paths to process : 1
21/02/17 01:41:41 INFO SparkContext: Starting job: first at ReadWrite.scala:615
21/02/17 01:41:41 INFO DAGScheduler: Got job 36 (first at ReadWrite.scala:615) with 1 output partitions
21/02/17 01:41:41 INFO DAGScheduler: Final stage: ResultStage 49 (first at ReadWrite.scala:615)
21/02/17 01:41:41 INFO DAGScheduler: Parents of final stage: List()
21/02/17 01:41:41 INFO DAGScheduler: Missing parents: List()
21/02/17 01:41:41 INFO DAGScheduler: Submitting ResultStage 49 (/tmp/Rtmp09Oz4e/file22e22736a8feb/stages/0_r_formula__9467ebc0_1e9a_44aa_b6e1_220b95e6649f/pipelineModel/metadata MapPartitionsRDD[167] at textFile at ReadWrite.scala:615), which has no missing parents
21/02/17 01:41:41 INFO MemoryStore: Block broadcast_57 stored as values in memory (estimated size 3.5 KB, free 910.3 MB)
21/02/17 01:41:41 INFO MemoryStore: Block broadcast_57_piece0 stored as bytes in memory (estimated size 2.1 KB, free 910.3 MB)
21/02/17 01:41:41 INFO BlockManagerInfo: Added broadcast_57_piece0 in memory on localhost:41253 (size: 2.1 KB, free: 912.0 MB)
21/02/17 01:41:41 INFO SparkContext: Created broadcast 57 from broadcast at DAGScheduler.scala:1161
21/02/17 01:41:41 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 49 (/tmp/Rtmp09Oz4e/file22e22736a8feb/stages/0_r_formula__9467ebc0_1e9a_44aa_b6e1_220b95e6649f/pipelineModel/metadata MapPartitionsRDD[167] at textFile at ReadWrite.scala:615) (first 15 tasks are for partitions Vector(0))
21/02/17 01:41:41 INFO TaskSchedulerImpl: Adding task set 49.0 with 1 tasks
21/02/17 01:41:41 INFO TaskSetManager: Starting task 0.0 in stage 49.0 (TID 51, localhost, executor driver, partition 0, PROCESS_LOCAL, 7990 bytes)
21/02/17 01:41:41 INFO Executor: Running task 0.0 in stage 49.0 (TID 51)
21/02/17 01:41:41 INFO HadoopRDD: Input split: file:/tmp/Rtmp09Oz4e/file22e22736a8feb/stages/0_r_formula__9467ebc0_1e9a_44aa_b6e1_220b95e6649f/pipelineModel/metadata/part-00000:0+311
21/02/17 01:41:41 INFO Executor: Finished task 0.0 in stage 49.0 (TID 51). 1110 bytes result sent to driver
21/02/17 01:41:41 INFO TaskSetManager: Finished task 0.0 in stage 49.0 (TID 51) in 4 ms on localhost (executor driver) (1/1)
21/02/17 01:41:41 INFO TaskSchedulerImpl: Removed TaskSet 49.0, whose tasks have all completed, from pool 
21/02/17 01:41:41 INFO DAGScheduler: ResultStage 49 (first at ReadWrite.scala:615) finished in 0.008 s
21/02/17 01:41:41 INFO DAGScheduler: Job 36 finished: first at ReadWrite.scala:615, took 0.009513 s
21/02/17 01:41:41 INFO MemoryStore: Block broadcast_58 stored as values in memory (estimated size 239.6 KB, free 910.1 MB)
21/02/17 01:41:41 INFO MemoryStore: Block broadcast_58_piece0 stored as bytes in memory (estimated size 23.2 KB, free 910.0 MB)
21/02/17 01:41:41 INFO BlockManagerInfo: Added broadcast_58_piece0 in memory on localhost:41253 (size: 23.2 KB, free: 912.0 MB)
21/02/17 01:41:41 INFO SparkContext: Created broadcast 58 from textFile at ReadWrite.scala:615
21/02/17 01:41:41 INFO FileInputFormat: Total input paths to process : 1
21/02/17 01:41:41 INFO SparkContext: Starting job: first at ReadWrite.scala:615
21/02/17 01:41:41 INFO DAGScheduler: Got job 37 (first at ReadWrite.scala:615) with 1 output partitions
21/02/17 01:41:41 INFO DAGScheduler: Final stage: ResultStage 50 (first at ReadWrite.scala:615)
21/02/17 01:41:41 INFO DAGScheduler: Parents of final stage: List()
21/02/17 01:41:41 INFO DAGScheduler: Missing parents: List()
21/02/17 01:41:41 INFO DAGScheduler: Submitting ResultStage 50 (/tmp/Rtmp09Oz4e/file22e22736a8feb/stages/0_r_formula__9467ebc0_1e9a_44aa_b6e1_220b95e6649f/pipelineModel/stages/0_r_formula__9467ebc0_1e9a_44aa_b6e1_220b95e6649f/metadata MapPartitionsRDD[169] at textFile at ReadWrite.scala:615), which has no missing parents
21/02/17 01:41:41 INFO MemoryStore: Block broadcast_59 stored as values in memory (estimated size 3.6 KB, free 910.0 MB)
21/02/17 01:41:41 INFO MemoryStore: Block broadcast_59_piece0 stored as bytes in memory (estimated size 2.1 KB, free 910.0 MB)
21/02/17 01:41:41 INFO BlockManagerInfo: Added broadcast_59_piece0 in memory on localhost:41253 (size: 2.1 KB, free: 912.0 MB)
21/02/17 01:41:41 INFO SparkContext: Created broadcast 59 from broadcast at DAGScheduler.scala:1161
21/02/17 01:41:41 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 50 (/tmp/Rtmp09Oz4e/file22e22736a8feb/stages/0_r_formula__9467ebc0_1e9a_44aa_b6e1_220b95e6649f/pipelineModel/stages/0_r_formula__9467ebc0_1e9a_44aa_b6e1_220b95e6649f/metadata MapPartitionsRDD[169] at textFile at ReadWrite.scala:615) (first 15 tasks are for partitions Vector(0))
21/02/17 01:41:41 INFO TaskSchedulerImpl: Adding task set 50.0 with 1 tasks
21/02/17 01:41:41 INFO TaskSetManager: Starting task 0.0 in stage 50.0 (TID 52, localhost, executor driver, partition 0, PROCESS_LOCAL, 8050 bytes)
21/02/17 01:41:41 INFO Executor: Running task 0.0 in stage 50.0 (TID 52)
21/02/17 01:41:41 INFO HadoopRDD: Input split: file:/tmp/Rtmp09Oz4e/file22e22736a8feb/stages/0_r_formula__9467ebc0_1e9a_44aa_b6e1_220b95e6649f/pipelineModel/stages/0_r_formula__9467ebc0_1e9a_44aa_b6e1_220b95e6649f/metadata/part-00000:0+378
21/02/17 01:41:41 INFO Executor: Finished task 0.0 in stage 50.0 (TID 52). 1177 bytes result sent to driver
21/02/17 01:41:41 INFO TaskSetManager: Finished task 0.0 in stage 50.0 (TID 52) in 3 ms on localhost (executor driver) (1/1)
21/02/17 01:41:41 INFO TaskSchedulerImpl: Removed TaskSet 50.0, whose tasks have all completed, from pool 
21/02/17 01:41:41 INFO DAGScheduler: ResultStage 50 (first at ReadWrite.scala:615) finished in 0.005 s
21/02/17 01:41:41 INFO DAGScheduler: Job 37 finished: first at ReadWrite.scala:615, took 0.007139 s
21/02/17 01:41:41 INFO MemoryStore: Block broadcast_60 stored as values in memory (estimated size 239.6 KB, free 909.8 MB)
21/02/17 01:41:41 INFO MemoryStore: Block broadcast_60_piece0 stored as bytes in memory (estimated size 23.2 KB, free 909.8 MB)
21/02/17 01:41:41 INFO BlockManagerInfo: Added broadcast_60_piece0 in memory on localhost:41253 (size: 23.2 KB, free: 912.0 MB)
21/02/17 01:41:41 INFO SparkContext: Created broadcast 60 from textFile at ReadWrite.scala:615
21/02/17 01:41:41 INFO FileInputFormat: Total input paths to process : 1
21/02/17 01:41:41 INFO SparkContext: Starting job: first at ReadWrite.scala:615
21/02/17 01:41:41 INFO DAGScheduler: Got job 38 (first at ReadWrite.scala:615) with 1 output partitions
21/02/17 01:41:41 INFO DAGScheduler: Final stage: ResultStage 51 (first at ReadWrite.scala:615)
21/02/17 01:41:41 INFO DAGScheduler: Parents of final stage: List()
21/02/17 01:41:41 INFO DAGScheduler: Missing parents: List()
21/02/17 01:41:41 INFO DAGScheduler: Submitting ResultStage 51 (/tmp/Rtmp09Oz4e/file22e22736a8feb/stages/0_r_formula__9467ebc0_1e9a_44aa_b6e1_220b95e6649f/pipelineModel/stages/0_r_formula__9467ebc0_1e9a_44aa_b6e1_220b95e6649f/metadata MapPartitionsRDD[171] at textFile at ReadWrite.scala:615), which has no missing parents
21/02/17 01:41:41 INFO MemoryStore: Block broadcast_61 stored as values in memory (estimated size 3.6 KB, free 909.8 MB)
21/02/17 01:41:41 INFO MemoryStore: Block broadcast_61_piece0 stored as bytes in memory (estimated size 2.1 KB, free 909.8 MB)
21/02/17 01:41:41 INFO BlockManagerInfo: Added broadcast_61_piece0 in memory on localhost:41253 (size: 2.1 KB, free: 912.0 MB)
21/02/17 01:41:41 INFO SparkContext: Created broadcast 61 from broadcast at DAGScheduler.scala:1161
21/02/17 01:41:41 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 51 (/tmp/Rtmp09Oz4e/file22e22736a8feb/stages/0_r_formula__9467ebc0_1e9a_44aa_b6e1_220b95e6649f/pipelineModel/stages/0_r_formula__9467ebc0_1e9a_44aa_b6e1_220b95e6649f/metadata MapPartitionsRDD[171] at textFile at ReadWrite.scala:615) (first 15 tasks are for partitions Vector(0))
21/02/17 01:41:41 INFO TaskSchedulerImpl: Adding task set 51.0 with 1 tasks
21/02/17 01:41:41 INFO TaskSetManager: Starting task 0.0 in stage 51.0 (TID 53, localhost, executor driver, partition 0, PROCESS_LOCAL, 8050 bytes)
21/02/17 01:41:41 INFO Executor: Running task 0.0 in stage 51.0 (TID 53)
21/02/17 01:41:41 INFO HadoopRDD: Input split: file:/tmp/Rtmp09Oz4e/file22e22736a8feb/stages/0_r_formula__9467ebc0_1e9a_44aa_b6e1_220b95e6649f/pipelineModel/stages/0_r_formula__9467ebc0_1e9a_44aa_b6e1_220b95e6649f/metadata/part-00000:0+378
21/02/17 01:41:41 INFO Executor: Finished task 0.0 in stage 51.0 (TID 53). 1177 bytes result sent to driver
21/02/17 01:41:41 INFO TaskSetManager: Finished task 0.0 in stage 51.0 (TID 53) in 3 ms on localhost (executor driver) (1/1)
21/02/17 01:41:41 INFO TaskSchedulerImpl: Removed TaskSet 51.0, whose tasks have all completed, from pool 
21/02/17 01:41:41 INFO DAGScheduler: ResultStage 51 (first at ReadWrite.scala:615) finished in 0.006 s
21/02/17 01:41:41 INFO DAGScheduler: Job 38 finished: first at ReadWrite.scala:615, took 0.007979 s
21/02/17 01:41:41 INFO MemoryStore: Block broadcast_62 stored as values in memory (estimated size 239.6 KB, free 909.5 MB)
21/02/17 01:41:41 INFO MemoryStore: Block broadcast_62_piece0 stored as bytes in memory (estimated size 23.2 KB, free 909.5 MB)
21/02/17 01:41:41 INFO BlockManagerInfo: Added broadcast_62_piece0 in memory on localhost:41253 (size: 23.2 KB, free: 912.0 MB)
21/02/17 01:41:41 INFO SparkContext: Created broadcast 62 from textFile at ReadWrite.scala:615
21/02/17 01:41:41 INFO FileInputFormat: Total input paths to process : 1
21/02/17 01:41:41 INFO SparkContext: Starting job: first at ReadWrite.scala:615
21/02/17 01:41:41 INFO DAGScheduler: Got job 39 (first at ReadWrite.scala:615) with 1 output partitions
21/02/17 01:41:41 INFO DAGScheduler: Final stage: ResultStage 52 (first at ReadWrite.scala:615)
21/02/17 01:41:41 INFO DAGScheduler: Parents of final stage: List()
21/02/17 01:41:41 INFO DAGScheduler: Missing parents: List()
21/02/17 01:41:41 INFO DAGScheduler: Submitting ResultStage 52 (/tmp/Rtmp09Oz4e/file22e22736a8feb/stages/0_r_formula__9467ebc0_1e9a_44aa_b6e1_220b95e6649f/pipelineModel/stages/1_vectorAttrRewriter_f6945e4c4508/metadata MapPartitionsRDD[173] at textFile at ReadWrite.scala:615), which has no missing parents
21/02/17 01:41:41 INFO MemoryStore: Block broadcast_63 stored as values in memory (estimated size 3.6 KB, free 909.5 MB)
21/02/17 01:41:41 INFO MemoryStore: Block broadcast_63_piece0 stored as bytes in memory (estimated size 2.2 KB, free 909.5 MB)
21/02/17 01:41:41 INFO BlockManagerInfo: Added broadcast_63_piece0 in memory on localhost:41253 (size: 2.2 KB, free: 912.0 MB)
21/02/17 01:41:41 INFO SparkContext: Created broadcast 63 from broadcast at DAGScheduler.scala:1161
21/02/17 01:41:41 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 52 (/tmp/Rtmp09Oz4e/file22e22736a8feb/stages/0_r_formula__9467ebc0_1e9a_44aa_b6e1_220b95e6649f/pipelineModel/stages/1_vectorAttrRewriter_f6945e4c4508/metadata MapPartitionsRDD[173] at textFile at ReadWrite.scala:615) (first 15 tasks are for partitions Vector(0))
21/02/17 01:41:41 INFO TaskSchedulerImpl: Adding task set 52.0 with 1 tasks
21/02/17 01:41:41 INFO TaskSetManager: Starting task 0.0 in stage 52.0 (TID 54, localhost, executor driver, partition 0, PROCESS_LOCAL, 8034 bytes)
21/02/17 01:41:41 INFO Executor: Running task 0.0 in stage 52.0 (TID 54)
21/02/17 01:41:41 INFO HadoopRDD: Input split: file:/tmp/Rtmp09Oz4e/file22e22736a8feb/stages/0_r_formula__9467ebc0_1e9a_44aa_b6e1_220b95e6649f/pipelineModel/stages/1_vectorAttrRewriter_f6945e4c4508/metadata/part-00000:0+188
21/02/17 01:41:41 INFO Executor: Finished task 0.0 in stage 52.0 (TID 54). 984 bytes result sent to driver
21/02/17 01:41:41 INFO TaskSetManager: Finished task 0.0 in stage 52.0 (TID 54) in 3 ms on localhost (executor driver) (1/1)
21/02/17 01:41:41 INFO TaskSchedulerImpl: Removed TaskSet 52.0, whose tasks have all completed, from pool 
21/02/17 01:41:41 INFO DAGScheduler: ResultStage 52 (first at ReadWrite.scala:615) finished in 0.006 s
21/02/17 01:41:41 INFO DAGScheduler: Job 39 finished: first at ReadWrite.scala:615, took 0.007578 s
21/02/17 01:41:41 INFO MemoryStore: Block broadcast_64 stored as values in memory (estimated size 239.6 KB, free 909.3 MB)
21/02/17 01:41:41 INFO MemoryStore: Block broadcast_64_piece0 stored as bytes in memory (estimated size 23.2 KB, free 909.2 MB)
21/02/17 01:41:41 INFO BlockManagerInfo: Added broadcast_64_piece0 in memory on localhost:41253 (size: 23.2 KB, free: 911.9 MB)
21/02/17 01:41:41 INFO SparkContext: Created broadcast 64 from textFile at ReadWrite.scala:615
21/02/17 01:41:41 INFO FileInputFormat: Total input paths to process : 1
21/02/17 01:41:41 INFO SparkContext: Starting job: first at ReadWrite.scala:615
21/02/17 01:41:41 INFO DAGScheduler: Got job 40 (first at ReadWrite.scala:615) with 1 output partitions
21/02/17 01:41:41 INFO DAGScheduler: Final stage: ResultStage 53 (first at ReadWrite.scala:615)
21/02/17 01:41:41 INFO DAGScheduler: Parents of final stage: List()
21/02/17 01:41:41 INFO DAGScheduler: Missing parents: List()
21/02/17 01:41:41 INFO DAGScheduler: Submitting ResultStage 53 (/tmp/Rtmp09Oz4e/file22e22736a8feb/stages/0_r_formula__9467ebc0_1e9a_44aa_b6e1_220b95e6649f/pipelineModel/stages/1_vectorAttrRewriter_f6945e4c4508/metadata MapPartitionsRDD[175] at textFile at ReadWrite.scala:615), which has no missing parents
21/02/17 01:41:41 INFO MemoryStore: Block broadcast_65 stored as values in memory (estimated size 3.6 KB, free 909.2 MB)
21/02/17 01:41:41 INFO MemoryStore: Block broadcast_65_piece0 stored as bytes in memory (estimated size 2.2 KB, free 909.2 MB)
21/02/17 01:41:41 INFO BlockManagerInfo: Added broadcast_65_piece0 in memory on localhost:41253 (size: 2.2 KB, free: 911.9 MB)
21/02/17 01:41:41 INFO SparkContext: Created broadcast 65 from broadcast at DAGScheduler.scala:1161
21/02/17 01:41:41 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 53 (/tmp/Rtmp09Oz4e/file22e22736a8feb/stages/0_r_formula__9467ebc0_1e9a_44aa_b6e1_220b95e6649f/pipelineModel/stages/1_vectorAttrRewriter_f6945e4c4508/metadata MapPartitionsRDD[175] at textFile at ReadWrite.scala:615) (first 15 tasks are for partitions Vector(0))
21/02/17 01:41:41 INFO TaskSchedulerImpl: Adding task set 53.0 with 1 tasks
21/02/17 01:41:41 INFO TaskSetManager: Starting task 0.0 in stage 53.0 (TID 55, localhost, executor driver, partition 0, PROCESS_LOCAL, 8034 bytes)
21/02/17 01:41:41 INFO Executor: Running task 0.0 in stage 53.0 (TID 55)
21/02/17 01:41:41 INFO HadoopRDD: Input split: file:/tmp/Rtmp09Oz4e/file22e22736a8feb/stages/0_r_formula__9467ebc0_1e9a_44aa_b6e1_220b95e6649f/pipelineModel/stages/1_vectorAttrRewriter_f6945e4c4508/metadata/part-00000:0+188
21/02/17 01:41:41 INFO Executor: Finished task 0.0 in stage 53.0 (TID 55). 984 bytes result sent to driver
21/02/17 01:41:41 INFO TaskSetManager: Finished task 0.0 in stage 53.0 (TID 55) in 4 ms on localhost (executor driver) (1/1)
21/02/17 01:41:41 INFO TaskSchedulerImpl: Removed TaskSet 53.0, whose tasks have all completed, from pool 
21/02/17 01:41:41 INFO DAGScheduler: ResultStage 53 (first at ReadWrite.scala:615) finished in 0.007 s
21/02/17 01:41:41 INFO DAGScheduler: Job 40 finished: first at ReadWrite.scala:615, took 0.008070 s
21/02/17 01:41:41 INFO SparkContext: Starting job: parquet at RFormula.scala:600
21/02/17 01:41:41 INFO DAGScheduler: Got job 41 (parquet at RFormula.scala:600) with 1 output partitions
21/02/17 01:41:41 INFO DAGScheduler: Final stage: ResultStage 54 (parquet at RFormula.scala:600)
21/02/17 01:41:41 INFO DAGScheduler: Parents of final stage: List()
21/02/17 01:41:41 INFO DAGScheduler: Missing parents: List()
21/02/17 01:41:41 INFO DAGScheduler: Submitting ResultStage 54 (MapPartitionsRDD[177] at parquet at RFormula.scala:600), which has no missing parents
21/02/17 01:41:41 INFO MemoryStore: Block broadcast_66 stored as values in memory (estimated size 74.1 KB, free 909.2 MB)
21/02/17 01:41:41 INFO MemoryStore: Block broadcast_66_piece0 stored as bytes in memory (estimated size 26.1 KB, free 909.1 MB)
21/02/17 01:41:41 INFO BlockManagerInfo: Added broadcast_66_piece0 in memory on localhost:41253 (size: 26.1 KB, free: 911.9 MB)
21/02/17 01:41:41 INFO SparkContext: Created broadcast 66 from broadcast at DAGScheduler.scala:1161
21/02/17 01:41:41 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 54 (MapPartitionsRDD[177] at parquet at RFormula.scala:600) (first 15 tasks are for partitions Vector(0))
21/02/17 01:41:41 INFO TaskSchedulerImpl: Adding task set 54.0 with 1 tasks
21/02/17 01:41:41 INFO TaskSetManager: Starting task 0.0 in stage 54.0 (TID 56, localhost, executor driver, partition 0, PROCESS_LOCAL, 8190 bytes)
21/02/17 01:41:41 INFO Executor: Running task 0.0 in stage 54.0 (TID 56)
21/02/17 01:41:41 INFO Executor: Finished task 0.0 in stage 54.0 (TID 56). 1620 bytes result sent to driver
21/02/17 01:41:41 INFO TaskSetManager: Finished task 0.0 in stage 54.0 (TID 56) in 7 ms on localhost (executor driver) (1/1)
21/02/17 01:41:41 INFO TaskSchedulerImpl: Removed TaskSet 54.0, whose tasks have all completed, from pool 
21/02/17 01:41:41 INFO DAGScheduler: ResultStage 54 (parquet at RFormula.scala:600) finished in 0.014 s
21/02/17 01:41:41 INFO DAGScheduler: Job 41 finished: parquet at RFormula.scala:600, took 0.015281 s
21/02/17 01:41:41 INFO FileSourceStrategy: Pruning directories with: 
21/02/17 01:41:41 INFO FileSourceStrategy: Post-Scan Filters: 
21/02/17 01:41:41 INFO FileSourceStrategy: Output Data Schema: struct<vectorCol: string, prefixesToRewrite: map<string,string>>
21/02/17 01:41:41 INFO FileSourceScanExec: Pushed Filters: 
21/02/17 01:41:41 INFO ContextCleaner: Cleaned accumulator 1554
21/02/17 01:41:41 INFO ContextCleaner: Cleaned accumulator 1211
21/02/17 01:41:41 INFO ContextCleaner: Cleaned accumulator 1481
21/02/17 01:41:41 INFO ContextCleaner: Cleaned accumulator 1450
21/02/17 01:41:41 INFO ContextCleaner: Cleaned accumulator 1397
21/02/17 01:41:41 INFO ContextCleaner: Cleaned accumulator 1584
21/02/17 01:41:41 INFO ContextCleaner: Cleaned accumulator 1059
21/02/17 01:41:41 INFO ContextCleaner: Cleaned accumulator 921
21/02/17 01:41:41 INFO ContextCleaner: Cleaned accumulator 1273
21/02/17 01:41:41 INFO BlockManagerInfo: Removed broadcast_44_piece0 on localhost:41253 in memory (size: 8.2 KB, free: 911.9 MB)
21/02/17 01:41:41 INFO ContextCleaner: Cleaned accumulator 1507
21/02/17 01:41:41 INFO ContextCleaner: Cleaned accumulator 1200
21/02/17 01:41:41 INFO ContextCleaner: Cleaned accumulator 1314
21/02/17 01:41:41 INFO ContextCleaner: Cleaned accumulator 1486
21/02/17 01:41:41 INFO BlockManagerInfo: Removed broadcast_65_piece0 on localhost:41253 in memory (size: 2.2 KB, free: 911.9 MB)
21/02/17 01:41:41 INFO ContextCleaner: Cleaned accumulator 1068
21/02/17 01:41:41 INFO ContextCleaner: Cleaned accumulator 1110
21/02/17 01:41:41 INFO ContextCleaner: Cleaned accumulator 1031
21/02/17 01:41:41 INFO ContextCleaner: Cleaned accumulator 1245
21/02/17 01:41:41 INFO ContextCleaner: Cleaned accumulator 1435
21/02/17 01:41:41 INFO ContextCleaner: Cleaned accumulator 1240
21/02/17 01:41:41 INFO ContextCleaner: Cleaned accumulator 1213
21/02/17 01:41:41 INFO ContextCleaner: Cleaned accumulator 1019
21/02/17 01:41:41 INFO ContextCleaner: Cleaned accumulator 963
21/02/17 01:41:41 INFO ContextCleaner: Cleaned accumulator 1539
21/02/17 01:41:41 INFO ContextCleaner: Cleaned accumulator 1182
21/02/17 01:41:41 INFO ContextCleaner: Cleaned accumulator 940
21/02/17 01:41:41 INFO ContextCleaner: Cleaned accumulator 1455
21/02/17 01:41:41 INFO ContextCleaner: Cleaned accumulator 931
21/02/17 01:41:41 INFO ContextCleaner: Cleaned accumulator 1157
21/02/17 01:41:41 INFO ContextCleaner: Cleaned accumulator 1511
21/02/17 01:41:41 INFO BlockManagerInfo: Removed broadcast_61_piece0 on localhost:41253 in memory (size: 2.1 KB, free: 911.9 MB)
21/02/17 01:41:41 INFO ContextCleaner: Cleaned accumulator 1122
21/02/17 01:41:41 INFO ContextCleaner: Cleaned accumulator 1367
21/02/17 01:41:41 INFO ContextCleaner: Cleaned accumulator 1180
21/02/17 01:41:41 INFO ContextCleaner: Cleaned accumulator 1351
21/02/17 01:41:41 INFO ContextCleaner: Cleaned accumulator 1015
21/02/17 01:41:41 INFO ContextCleaner: Cleaned accumulator 1355
21/02/17 01:41:41 INFO ContextCleaner: Cleaned accumulator 1330
21/02/17 01:41:41 INFO ContextCleaner: Cleaned accumulator 1262
21/02/17 01:41:41 INFO ContextCleaner: Cleaned accumulator 995
21/02/17 01:41:41 INFO ContextCleaner: Cleaned accumulator 961
21/02/17 01:41:41 INFO ContextCleaner: Cleaned accumulator 998
21/02/17 01:41:41 INFO ContextCleaner: Cleaned accumulator 1552
21/02/17 01:41:41 INFO ContextCleaner: Cleaned accumulator 1147
21/02/17 01:41:41 INFO ContextCleaner: Cleaned accumulator 1506
21/02/17 01:41:41 INFO ContextCleaner: Cleaned accumulator 1146
21/02/17 01:41:41 INFO ContextCleaner: Cleaned accumulator 1256
21/02/17 01:41:41 INFO ContextCleaner: Cleaned accumulator 1025
21/02/17 01:41:41 INFO ContextCleaner: Cleaned accumulator 1064
21/02/17 01:41:41 INFO ContextCleaner: Cleaned accumulator 1328
21/02/17 01:41:41 INFO ContextCleaner: Cleaned accumulator 1188
21/02/17 01:41:41 INFO ContextCleaner: Cleaned accumulator 1448
21/02/17 01:41:41 INFO ContextCleaner: Cleaned accumulator 1482
21/02/17 01:41:41 INFO ContextCleaner: Cleaned accumulator 1444
21/02/17 01:41:41 INFO ContextCleaner: Cleaned accumulator 1322
21/02/17 01:41:41 INFO ContextCleaner: Cleaned accumulator 1449
21/02/17 01:41:41 INFO ContextCleaner: Cleaned accumulator 1598
21/02/17 01:41:41 INFO ContextCleaner: Cleaned accumulator 1121
21/02/17 01:41:41 INFO ContextCleaner: Cleaned accumulator 968
21/02/17 01:41:41 INFO ContextCleaner: Cleaned accumulator 1158
21/02/17 01:41:41 INFO ContextCleaner: Cleaned accumulator 925
21/02/17 01:41:41 INFO ContextCleaner: Cleaned accumulator 1118
21/02/17 01:41:41 INFO ContextCleaner: Cleaned accumulator 1195
21/02/17 01:41:41 INFO ContextCleaner: Cleaned accumulator 1533
21/02/17 01:41:41 INFO ContextCleaner: Cleaned accumulator 1083
21/02/17 01:41:41 INFO BlockManagerInfo: Removed broadcast_37_piece0 on localhost:41253 in memory (size: 9.6 KB, free: 911.9 MB)
21/02/17 01:41:41 INFO ContextCleaner: Cleaned accumulator 1488
21/02/17 01:41:41 INFO ContextCleaner: Cleaned accumulator 1589
21/02/17 01:41:41 INFO ContextCleaner: Cleaned accumulator 1512
21/02/17 01:41:41 INFO ContextCleaner: Cleaned accumulator 1588
21/02/17 01:41:41 INFO ContextCleaner: Cleaned accumulator 1077
21/02/17 01:41:41 INFO ContextCleaner: Cleaned accumulator 970
21/02/17 01:41:41 INFO ContextCleaner: Cleaned accumulator 1254
21/02/17 01:41:41 INFO ContextCleaner: Cleaned accumulator 1401
21/02/17 01:41:41 INFO ContextCleaner: Cleaned accumulator 1431
21/02/17 01:41:41 INFO ContextCleaner: Cleaned accumulator 1261
21/02/17 01:41:41 INFO ContextCleaner: Cleaned accumulator 1057
21/02/17 01:41:41 INFO ContextCleaner: Cleaned accumulator 1208
21/02/17 01:41:41 INFO ContextCleaner: Cleaned accumulator 1536
21/02/17 01:41:41 INFO ContextCleaner: Cleaned accumulator 990
21/02/17 01:41:41 INFO ContextCleaner: Cleaned accumulator 1362
21/02/17 01:41:41 INFO ContextCleaner: Cleaned accumulator 1143
21/02/17 01:41:41 INFO ContextCleaner: Cleaned accumulator 1292
21/02/17 01:41:41 INFO ContextCleaner: Cleaned accumulator 1388
21/02/17 01:41:41 INFO ContextCleaner: Cleaned accumulator 1274
21/02/17 01:41:41 INFO ContextCleaner: Cleaned accumulator 1542
21/02/17 01:41:41 INFO ContextCleaner: Cleaned accumulator 1472
21/02/17 01:41:41 INFO ContextCleaner: Cleaned accumulator 1227
21/02/17 01:41:41 INFO ContextCleaner: Cleaned accumulator 971
21/02/17 01:41:41 INFO ContextCleaner: Cleaned accumulator 1162
21/02/17 01:41:41 INFO ContextCleaner: Cleaned accumulator 1246
21/02/17 01:41:41 INFO ContextCleaner: Cleaned accumulator 1595
21/02/17 01:41:41 INFO ContextCleaner: Cleaned accumulator 1183
21/02/17 01:41:41 INFO ContextCleaner: Cleaned accumulator 1013
21/02/17 01:41:41 INFO ContextCleaner: Cleaned accumulator 1167
21/02/17 01:41:41 INFO ContextCleaner: Cleaned accumulator 1417
21/02/17 01:41:41 INFO ContextCleaner: Cleaned accumulator 946
21/02/17 01:41:41 INFO ContextCleaner: Cleaned accumulator 1204
21/02/17 01:41:41 INFO ContextCleaner: Cleaned accumulator 1387
21/02/17 01:41:41 INFO ContextCleaner: Cleaned accumulator 1339
21/02/17 01:41:41 INFO ContextCleaner: Cleaned accumulator 1199
21/02/17 01:41:41 INFO ContextCleaner: Cleaned accumulator 1497
21/02/17 01:41:41 INFO ContextCleaner: Cleaned accumulator 1074
21/02/17 01:41:41 INFO ContextCleaner: Cleaned accumulator 1526
21/02/17 01:41:41 INFO ContextCleaner: Cleaned accumulator 1216
21/02/17 01:41:41 INFO ContextCleaner: Cleaned accumulator 1563
21/02/17 01:41:41 INFO ContextCleaner: Cleaned accumulator 1393
21/02/17 01:41:41 INFO ContextCleaner: Cleaned accumulator 1215
21/02/17 01:41:41 INFO ContextCleaner: Cleaned accumulator 1218
21/02/17 01:41:41 INFO BlockManagerInfo: Removed broadcast_36_piece0 on localhost:41253 in memory (size: 3.8 KB, free: 911.9 MB)
21/02/17 01:41:41 INFO ContextCleaner: Cleaned accumulator 1086
21/02/17 01:41:41 INFO ContextCleaner: Cleaned accumulator 1150
21/02/17 01:41:41 INFO ContextCleaner: Cleaned accumulator 1311
21/02/17 01:41:41 INFO ContextCleaner: Cleaned accumulator 1091
21/02/17 01:41:41 INFO ContextCleaner: Cleaned accumulator 1587
21/02/17 01:41:41 INFO ContextCleaner: Cleaned accumulator 1007
21/02/17 01:41:41 INFO ContextCleaner: Cleaned accumulator 1237
21/02/17 01:41:41 INFO ContextCleaner: Cleaned accumulator 1072
21/02/17 01:41:41 INFO ContextCleaner: Cleaned accumulator 1473
21/02/17 01:41:41 INFO ContextCleaner: Cleaned accumulator 1138
21/02/17 01:41:41 INFO ContextCleaner: Cleaned accumulator 1454
21/02/17 01:41:41 INFO ContextCleaner: Cleaned accumulator 1168
21/02/17 01:41:41 INFO ContextCleaner: Cleaned accumulator 1055
21/02/17 01:41:41 INFO ContextCleaner: Cleaned accumulator 1120
21/02/17 01:41:41 INFO ContextCleaner: Cleaned accumulator 1229
21/02/17 01:41:41 INFO BlockManagerInfo: Removed broadcast_48_piece0 on localhost:41253 in memory (size: 2.1 KB, free: 911.9 MB)
21/02/17 01:41:41 INFO ContextCleaner: Cleaned accumulator 1316
21/02/17 01:41:41 INFO ContextCleaner: Cleaned accumulator 1582
21/02/17 01:41:41 INFO ContextCleaner: Cleaned accumulator 945
21/02/17 01:41:41 INFO ContextCleaner: Cleaned accumulator 1382
21/02/17 01:41:41 INFO ContextCleaner: Cleaned accumulator 1416
21/02/17 01:41:41 INFO ContextCleaner: Cleaned accumulator 1436
21/02/17 01:41:41 INFO ContextCleaner: Cleaned accumulator 1396
21/02/17 01:41:41 INFO ContextCleaner: Cleaned accumulator 1276
21/02/17 01:41:41 INFO ContextCleaner: Cleaned accumulator 1411
21/02/17 01:41:41 INFO ContextCleaner: Cleaned accumulator 1327
21/02/17 01:41:41 INFO ContextCleaner: Cleaned accumulator 922
21/02/17 01:41:41 INFO ContextCleaner: Cleaned accumulator 1445
21/02/17 01:41:41 INFO ContextCleaner: Cleaned accumulator 1056
21/02/17 01:41:41 INFO ContextCleaner: Cleaned accumulator 1047
21/02/17 01:41:41 INFO ContextCleaner: Cleaned accumulator 1136
21/02/17 01:41:41 INFO ContextCleaner: Cleaned accumulator 1305
21/02/17 01:41:41 INFO ContextCleaner: Cleaned accumulator 1139
21/02/17 01:41:41 INFO ContextCleaner: Cleaned accumulator 1241
21/02/17 01:41:41 INFO ContextCleaner: Cleaned accumulator 1350
21/02/17 01:41:41 INFO ContextCleaner: Cleaned accumulator 1492
21/02/17 01:41:41 INFO ContextCleaner: Cleaned accumulator 1391
21/02/17 01:41:41 INFO BlockManagerInfo: Removed broadcast_54_piece0 on localhost:41253 in memory (size: 25.2 KB, free: 912.0 MB)
21/02/17 01:41:41 INFO ContextCleaner: Cleaned accumulator 1024
21/02/17 01:41:41 INFO ContextCleaner: Cleaned accumulator 1555
21/02/17 01:41:41 INFO ContextCleaner: Cleaned accumulator 1092
21/02/17 01:41:41 INFO ContextCleaner: Cleaned accumulator 1424
21/02/17 01:41:41 INFO ContextCleaner: Cleaned accumulator 1384
21/02/17 01:41:41 INFO ContextCleaner: Cleaned accumulator 1390
21/02/17 01:41:41 INFO ContextCleaner: Cleaned accumulator 1478
21/02/17 01:41:41 INFO ContextCleaner: Cleaned accumulator 1198
21/02/17 01:41:41 INFO ContextCleaner: Cleaned accumulator 1569
21/02/17 01:41:41 INFO ContextCleaner: Cleaned accumulator 1117
21/02/17 01:41:41 INFO ContextCleaner: Cleaned accumulator 1469
21/02/17 01:41:41 INFO BlockManagerInfo: Removed broadcast_34_piece0 on localhost:41253 in memory (size: 24.5 KB, free: 912.0 MB)
21/02/17 01:41:41 INFO ContextCleaner: Cleaned accumulator 1088
21/02/17 01:41:41 INFO ContextCleaner: Cleaned accumulator 1399
21/02/17 01:41:41 INFO ContextCleaner: Cleaned accumulator 1549
21/02/17 01:41:41 INFO ContextCleaner: Cleaned accumulator 1239
21/02/17 01:41:41 INFO ContextCleaner: Cleaned accumulator 1194
21/02/17 01:41:41 INFO ContextCleaner: Cleaned accumulator 1385
21/02/17 01:41:41 INFO ContextCleaner: Cleaned accumulator 943
21/02/17 01:41:41 INFO ContextCleaner: Cleaned accumulator 1039
21/02/17 01:41:41 INFO ContextCleaner: Cleaned accumulator 1585
21/02/17 01:41:41 INFO ContextCleaner: Cleaned accumulator 999
21/02/17 01:41:41 INFO ContextCleaner: Cleaned accumulator 948
21/02/17 01:41:41 INFO ContextCleaner: Cleaned accumulator 1080
21/02/17 01:41:41 INFO ContextCleaner: Cleaned accumulator 1103
21/02/17 01:41:41 INFO ContextCleaner: Cleaned accumulator 1052
21/02/17 01:41:41 INFO ContextCleaner: Cleaned accumulator 1360
21/02/17 01:41:41 INFO ContextCleaner: Cleaned accumulator 1037
21/02/17 01:41:41 INFO ContextCleaner: Cleaned accumulator 1574
21/02/17 01:41:41 INFO ContextCleaner: Cleaned accumulator 1550
21/02/17 01:41:41 INFO ContextCleaner: Cleaned accumulator 1332
21/02/17 01:41:41 INFO ContextCleaner: Cleaned accumulator 991
21/02/17 01:41:41 INFO ContextCleaner: Cleaned accumulator 1495
21/02/17 01:41:41 INFO ContextCleaner: Cleaned accumulator 1133
21/02/17 01:41:41 INFO ContextCleaner: Cleaned accumulator 984
21/02/17 01:41:41 INFO ContextCleaner: Cleaned accumulator 1085
21/02/17 01:41:41 INFO ContextCleaner: Cleaned accumulator 1475
21/02/17 01:41:41 INFO ContextCleaner: Cleaned accumulator 1521
21/02/17 01:41:41 INFO ContextCleaner: Cleaned accumulator 1291
21/02/17 01:41:41 INFO ContextCleaner: Cleaned accumulator 993
21/02/17 01:41:41 INFO ContextCleaner: Cleaned accumulator 1060
21/02/17 01:41:41 INFO ContextCleaner: Cleaned accumulator 1104
21/02/17 01:41:41 INFO ContextCleaner: Cleaned accumulator 1283
21/02/17 01:41:41 INFO ContextCleaner: Cleaned accumulator 983
21/02/17 01:41:41 INFO ContextCleaner: Cleaned accumulator 1464
21/02/17 01:41:41 INFO ContextCleaner: Cleaned accumulator 1370
21/02/17 01:41:41 INFO ContextCleaner: Cleaned accumulator 1275
21/02/17 01:41:41 INFO ContextCleaner: Cleaned accumulator 1278
21/02/17 01:41:41 INFO ContextCleaner: Cleaned accumulator 972
21/02/17 01:41:41 INFO ContextCleaner: Cleaned accumulator 1161
21/02/17 01:41:41 INFO ContextCleaner: Cleaned accumulator 936
21/02/17 01:41:41 INFO ContextCleaner: Cleaned accumulator 1038
21/02/17 01:41:41 INFO ContextCleaner: Cleaned accumulator 977
21/02/17 01:41:41 INFO ContextCleaner: Cleaned accumulator 1242
21/02/17 01:41:41 INFO ContextCleaner: Cleaned accumulator 1172
21/02/17 01:41:41 INFO ContextCleaner: Cleaned accumulator 1559
21/02/17 01:41:41 INFO ContextCleaner: Cleaned accumulator 1144
21/02/17 01:41:41 INFO ContextCleaner: Cleaned accumulator 1043
21/02/17 01:41:41 INFO ContextCleaner: Cleaned accumulator 920
21/02/17 01:41:41 INFO ContextCleaner: Cleaned accumulator 1288
21/02/17 01:41:41 INFO ContextCleaner: Cleaned accumulator 1516
21/02/17 01:41:41 INFO ContextCleaner: Cleaned accumulator 1269
21/02/17 01:41:41 INFO ContextCleaner: Cleaned accumulator 1268
21/02/17 01:41:41 INFO ContextCleaner: Cleaned accumulator 1185
21/02/17 01:41:41 INFO ContextCleaner: Cleaned accumulator 1069
21/02/17 01:41:41 INFO ContextCleaner: Cleaned accumulator 1081
21/02/17 01:41:41 INFO ContextCleaner: Cleaned accumulator 1232
21/02/17 01:41:41 INFO ContextCleaner: Cleaned accumulator 1476
21/02/17 01:41:41 INFO ContextCleaner: Cleaned accumulator 1509
21/02/17 01:41:41 INFO ContextCleaner: Cleaned accumulator 1054
21/02/17 01:41:41 INFO ContextCleaner: Cleaned accumulator 1114
21/02/17 01:41:41 INFO ContextCleaner: Cleaned accumulator 1371
21/02/17 01:41:41 INFO ContextCleaner: Cleaned accumulator 1395
21/02/17 01:41:41 INFO ContextCleaner: Cleaned accumulator 1576
21/02/17 01:41:41 INFO ContextCleaner: Cleaned accumulator 1325
21/02/17 01:41:41 INFO ContextCleaner: Cleaned accumulator 1458
21/02/17 01:41:41 INFO ContextCleaner: Cleaned accumulator 1517
21/02/17 01:41:41 INFO ContextCleaner: Cleaned accumulator 1315
21/02/17 01:41:41 INFO ContextCleaner: Cleaned accumulator 1358
21/02/17 01:41:41 INFO ContextCleaner: Cleaned accumulator 1046
21/02/17 01:41:41 INFO ContextCleaner: Cleaned accumulator 989
21/02/17 01:41:41 INFO ContextCleaner: Cleaned accumulator 1070
21/02/17 01:41:41 INFO ContextCleaner: Cleaned accumulator 1267
21/02/17 01:41:41 INFO ContextCleaner: Cleaned accumulator 1251
21/02/17 01:41:41 INFO ContextCleaner: Cleaned accumulator 1405
21/02/17 01:41:41 INFO ContextCleaner: Cleaned accumulator 1048
21/02/17 01:41:41 INFO ContextCleaner: Cleaned accumulator 1337
21/02/17 01:41:41 INFO ContextCleaner: Cleaned accumulator 1501
21/02/17 01:41:41 INFO ContextCleaner: Cleaned accumulator 1142
21/02/17 01:41:41 INFO ContextCleaner: Cleaned accumulator 930
21/02/17 01:41:41 INFO ContextCleaner: Cleaned accumulator 1100
21/02/17 01:41:41 INFO ContextCleaner: Cleaned accumulator 1504
21/02/17 01:41:41 INFO ContextCleaner: Cleaned accumulator 1543
21/02/17 01:41:41 INFO ContextCleaner: Cleaned accumulator 1298
21/02/17 01:41:41 INFO ContextCleaner: Cleaned accumulator 1558
21/02/17 01:41:41 INFO ContextCleaner: Cleaned accumulator 1353
21/02/17 01:41:41 INFO BlockManagerInfo: Removed broadcast_66_piece0 on localhost:41253 in memory (size: 26.1 KB, free: 912.0 MB)
21/02/17 01:41:41 INFO ContextCleaner: Cleaned accumulator 1084
21/02/17 01:41:41 INFO ContextCleaner: Cleaned accumulator 1061
21/02/17 01:41:41 INFO ContextCleaner: Cleaned accumulator 1519
21/02/17 01:41:41 INFO ContextCleaner: Cleaned accumulator 1352
21/02/17 01:41:41 INFO ContextCleaner: Cleaned accumulator 1402
21/02/17 01:41:41 INFO ContextCleaner: Cleaned accumulator 1223
21/02/17 01:41:41 INFO ContextCleaner: Cleaned accumulator 1152
21/02/17 01:41:41 INFO ContextCleaner: Cleaned accumulator 1287
21/02/17 01:41:41 INFO ContextCleaner: Cleaned accumulator 1346
21/02/17 01:41:41 INFO ContextCleaner: Cleaned accumulator 992
21/02/17 01:41:41 INFO ContextCleaner: Cleaned accumulator 1463
21/02/17 01:41:41 INFO ContextCleaner: Cleaned shuffle 11
21/02/17 01:41:41 INFO ContextCleaner: Cleaned accumulator 1153
21/02/17 01:41:41 INFO ContextCleaner: Cleaned accumulator 924
21/02/17 01:41:41 INFO ContextCleaner: Cleaned accumulator 969
21/02/17 01:41:41 INFO ContextCleaner: Cleaned accumulator 1409
21/02/17 01:41:41 INFO BlockManagerInfo: Removed broadcast_51_piece0 on localhost:41253 in memory (size: 23.2 KB, free: 912.0 MB)
21/02/17 01:41:41 INFO ContextCleaner: Cleaned accumulator 1494
21/02/17 01:41:41 INFO ContextCleaner: Cleaned accumulator 1264
21/02/17 01:41:41 INFO ContextCleaner: Cleaned accumulator 1535
21/02/17 01:41:41 INFO ContextCleaner: Cleaned accumulator 1419
21/02/17 01:41:41 INFO ContextCleaner: Cleaned accumulator 1116
21/02/17 01:41:41 INFO ContextCleaner: Cleaned accumulator 1210
21/02/17 01:41:41 INFO ContextCleaner: Cleaned accumulator 1460
21/02/17 01:41:41 INFO ContextCleaner: Cleaned accumulator 1244
21/02/17 01:41:41 INFO ContextCleaner: Cleaned accumulator 1203
21/02/17 01:41:41 INFO ContextCleaner: Cleaned accumulator 1441
21/02/17 01:41:41 INFO ContextCleaner: Cleaned accumulator 1462
21/02/17 01:41:41 INFO ContextCleaner: Cleaned accumulator 955
21/02/17 01:41:41 INFO ContextCleaner: Cleaned accumulator 982
21/02/17 01:41:41 INFO BlockManagerInfo: Removed broadcast_40_piece0 on localhost:41253 in memory (size: 4.1 KB, free: 912.0 MB)
21/02/17 01:41:41 INFO ContextCleaner: Cleaned accumulator 1364
21/02/17 01:41:41 INFO ContextCleaner: Cleaned accumulator 1004
21/02/17 01:41:41 INFO ContextCleaner: Cleaned accumulator 932
21/02/17 01:41:41 INFO ContextCleaner: Cleaned accumulator 1228
21/02/17 01:41:41 INFO ContextCleaner: Cleaned accumulator 953
21/02/17 01:41:41 INFO ContextCleaner: Cleaned accumulator 1406
21/02/17 01:41:41 INFO ContextCleaner: Cleaned accumulator 1548
21/02/17 01:41:41 INFO ContextCleaner: Cleaned accumulator 1111
21/02/17 01:41:41 INFO ContextCleaner: Cleaned accumulator 1420
21/02/17 01:41:41 INFO ContextCleaner: Cleaned accumulator 1438
21/02/17 01:41:41 INFO ContextCleaner: Cleaned accumulator 1505
21/02/17 01:41:41 INFO ContextCleaner: Cleaned accumulator 1089
21/02/17 01:41:41 INFO ContextCleaner: Cleaned accumulator 1394
21/02/17 01:41:41 INFO ContextCleaner: Cleaned accumulator 1284
21/02/17 01:41:41 INFO ContextCleaner: Cleaned accumulator 1354
21/02/17 01:41:41 INFO ContextCleaner: Cleaned accumulator 1319
21/02/17 01:41:41 INFO BlockManagerInfo: Removed broadcast_53_piece0 on localhost:41253 in memory (size: 26.1 KB, free: 912.1 MB)
21/02/17 01:41:41 INFO ContextCleaner: Cleaned accumulator 1534
21/02/17 01:41:41 INFO ContextCleaner: Cleaned accumulator 1271
21/02/17 01:41:41 INFO ContextCleaner: Cleaned accumulator 1368
21/02/17 01:41:41 INFO ContextCleaner: Cleaned accumulator 987
21/02/17 01:41:41 INFO ContextCleaner: Cleaned accumulator 1447
21/02/17 01:41:41 INFO ContextCleaner: Cleaned accumulator 1434
21/02/17 01:41:41 INFO ContextCleaner: Cleaned accumulator 1202
21/02/17 01:41:41 INFO ContextCleaner: Cleaned accumulator 1163
21/02/17 01:41:41 INFO ContextCleaner: Cleaned accumulator 1484
21/02/17 01:41:41 INFO ContextCleaner: Cleaned accumulator 1302
21/02/17 01:41:41 INFO ContextCleaner: Cleaned accumulator 1530
21/02/17 01:41:41 INFO ContextCleaner: Cleaned accumulator 1366
21/02/17 01:41:41 INFO ContextCleaner: Cleaned accumulator 1217
21/02/17 01:41:41 INFO ContextCleaner: Cleaned accumulator 1219
21/02/17 01:41:41 INFO ContextCleaner: Cleaned accumulator 928
21/02/17 01:41:41 INFO ContextCleaner: Cleaned accumulator 1022
21/02/17 01:41:41 INFO ContextCleaner: Cleaned accumulator 1130
21/02/17 01:41:41 INFO ContextCleaner: Cleaned accumulator 1238
21/02/17 01:41:41 INFO BlockManagerInfo: Removed broadcast_55_piece0 on localhost:41253 in memory (size: 4.9 KB, free: 912.1 MB)
21/02/17 01:41:41 INFO ContextCleaner: Cleaned accumulator 1318
21/02/17 01:41:41 INFO ContextCleaner: Cleaned accumulator 1392
21/02/17 01:41:41 INFO ContextCleaner: Cleaned accumulator 1586
21/02/17 01:41:41 INFO ContextCleaner: Cleaned accumulator 1049
21/02/17 01:41:41 INFO ContextCleaner: Cleaned accumulator 1579
21/02/17 01:41:41 INFO ContextCleaner: Cleaned accumulator 1149
21/02/17 01:41:41 INFO ContextCleaner: Cleaned accumulator 986
21/02/17 01:41:41 INFO ContextCleaner: Cleaned accumulator 1356
21/02/17 01:41:41 INFO ContextCleaner: Cleaned accumulator 1073
21/02/17 01:41:41 INFO ContextCleaner: Cleaned accumulator 1266
21/02/17 01:41:41 INFO ContextCleaner: Cleaned accumulator 1124
21/02/17 01:41:41 INFO ContextCleaner: Cleaned accumulator 1285
21/02/17 01:41:41 INFO ContextCleaner: Cleaned accumulator 1580
21/02/17 01:41:41 INFO ContextCleaner: Cleaned accumulator 1250
21/02/17 01:41:41 INFO ContextCleaner: Cleaned accumulator 1456
21/02/17 01:41:41 INFO ContextCleaner: Cleaned accumulator 1561
21/02/17 01:41:41 INFO ContextCleaner: Cleaned accumulator 976
21/02/17 01:41:41 INFO ContextCleaner: Cleaned accumulator 1221
21/02/17 01:41:41 INFO ContextCleaner: Cleaned accumulator 1551
21/02/17 01:41:41 INFO ContextCleaner: Cleaned accumulator 965
21/02/17 01:41:41 INFO ContextCleaner: Cleaned accumulator 1336
21/02/17 01:41:41 INFO ContextCleaner: Cleaned accumulator 1429
21/02/17 01:41:41 INFO ContextCleaner: Cleaned accumulator 1174
21/02/17 01:41:41 INFO ContextCleaner: Cleaned accumulator 1252
21/02/17 01:41:41 INFO ContextCleaner: Cleaned accumulator 1452
21/02/17 01:41:41 INFO ContextCleaner: Cleaned accumulator 978
21/02/17 01:41:41 INFO ContextCleaner: Cleaned accumulator 1023
21/02/17 01:41:41 INFO ContextCleaner: Cleaned accumulator 1171
21/02/17 01:41:41 INFO ContextCleaner: Cleaned accumulator 960
21/02/17 01:41:41 INFO ContextCleaner: Cleaned accumulator 1016
21/02/17 01:41:41 INFO ContextCleaner: Cleaned accumulator 1207
21/02/17 01:41:41 INFO ContextCleaner: Cleaned accumulator 1079
21/02/17 01:41:41 INFO ContextCleaner: Cleaned accumulator 1470
21/02/17 01:41:41 INFO ContextCleaner: Cleaned accumulator 1490
21/02/17 01:41:41 INFO ContextCleaner: Cleaned accumulator 1524
21/02/17 01:41:41 INFO ContextCleaner: Cleaned accumulator 956
21/02/17 01:41:41 INFO ContextCleaner: Cleaned accumulator 1027
21/02/17 01:41:41 INFO ContextCleaner: Cleaned accumulator 1045
21/02/17 01:41:41 INFO ContextCleaner: Cleaned accumulator 1065
21/02/17 01:41:41 INFO ContextCleaner: Cleaned accumulator 1442
21/02/17 01:41:41 INFO ContextCleaner: Cleaned accumulator 1443
21/02/17 01:41:41 INFO ContextCleaner: Cleaned accumulator 1562
21/02/17 01:41:41 INFO ContextCleaner: Cleaned accumulator 1544
21/02/17 01:41:41 INFO ContextCleaner: Cleaned accumulator 1467
21/02/17 01:41:41 INFO ContextCleaner: Cleaned accumulator 1564
21/02/17 01:41:41 INFO ContextCleaner: Cleaned accumulator 1423
21/02/17 01:41:41 INFO BlockManagerInfo: Removed broadcast_46_piece0 on localhost:41253 in memory (size: 3.8 KB, free: 912.1 MB)
21/02/17 01:41:41 INFO ContextCleaner: Cleaned accumulator 1432
21/02/17 01:41:41 INFO ContextCleaner: Cleaned accumulator 942
21/02/17 01:41:41 INFO ContextCleaner: Cleaned accumulator 1272
21/02/17 01:41:41 INFO ContextCleaner: Cleaned accumulator 1164
21/02/17 01:41:41 INFO ContextCleaner: Cleaned accumulator 1082
21/02/17 01:41:41 INFO ContextCleaner: Cleaned accumulator 1063
21/02/17 01:41:41 INFO ContextCleaner: Cleaned accumulator 1280
21/02/17 01:41:41 INFO ContextCleaner: Cleaned accumulator 1538
21/02/17 01:41:41 INFO ContextCleaner: Cleaned accumulator 957
21/02/17 01:41:41 INFO ContextCleaner: Cleaned accumulator 1374
21/02/17 01:41:41 INFO ContextCleaner: Cleaned accumulator 1378
21/02/17 01:41:41 INFO ContextCleaner: Cleaned accumulator 1323
21/02/17 01:41:41 INFO ContextCleaner: Cleaned accumulator 1134
21/02/17 01:41:41 INFO ContextCleaner: Cleaned accumulator 1340
21/02/17 01:41:41 INFO ContextCleaner: Cleaned accumulator 1383
21/02/17 01:41:41 INFO ContextCleaner: Cleaned accumulator 1556
21/02/17 01:41:41 INFO ContextCleaner: Cleaned accumulator 1098
21/02/17 01:41:41 INFO ContextCleaner: Cleaned accumulator 1422
21/02/17 01:41:41 INFO ContextCleaner: Cleaned accumulator 1439
21/02/17 01:41:41 INFO ContextCleaner: Cleaned accumulator 1050
21/02/17 01:41:41 INFO ContextCleaner: Cleaned accumulator 1087
21/02/17 01:41:41 INFO ContextCleaner: Cleaned accumulator 1249
21/02/17 01:41:41 INFO ContextCleaner: Cleaned accumulator 1304
21/02/17 01:41:41 INFO ContextCleaner: Cleaned accumulator 1290
21/02/17 01:41:41 INFO BlockManagerInfo: Removed broadcast_63_piece0 on localhost:41253 in memory (size: 2.2 KB, free: 912.1 MB)
21/02/17 01:41:41 INFO ContextCleaner: Cleaned accumulator 1212
21/02/17 01:41:41 INFO ContextCleaner: Cleaned accumulator 1173
21/02/17 01:41:41 INFO ContextCleaner: Cleaned accumulator 1529
21/02/17 01:41:41 INFO ContextCleaner: Cleaned accumulator 1309
21/02/17 01:41:41 INFO ContextCleaner: Cleaned accumulator 1361
21/02/17 01:41:41 INFO ContextCleaner: Cleaned accumulator 1289
21/02/17 01:41:41 INFO BlockManagerInfo: Removed broadcast_57_piece0 on localhost:41253 in memory (size: 2.1 KB, free: 912.1 MB)
21/02/17 01:41:41 INFO ContextCleaner: Cleaned accumulator 1572
21/02/17 01:41:41 INFO ContextCleaner: Cleaned accumulator 1115
21/02/17 01:41:41 INFO ContextCleaner: Cleaned accumulator 1578
21/02/17 01:41:41 INFO ContextCleaner: Cleaned accumulator 1474
21/02/17 01:41:41 INFO ContextCleaner: Cleaned accumulator 1260
21/02/17 01:41:41 INFO ContextCleaner: Cleaned accumulator 1003
21/02/17 01:41:41 INFO ContextCleaner: Cleaned accumulator 1522
21/02/17 01:41:41 INFO ContextCleaner: Cleaned accumulator 1466
21/02/17 01:41:41 INFO ContextCleaner: Cleaned accumulator 1489
21/02/17 01:41:41 INFO ContextCleaner: Cleaned accumulator 1546
21/02/17 01:41:41 INFO ContextCleaner: Cleaned accumulator 1034
21/02/17 01:41:41 INFO ContextCleaner: Cleaned accumulator 1090
21/02/17 01:41:41 INFO BlockManagerInfo: Removed broadcast_35_piece0 on localhost:41253 in memory (size: 9.6 KB, free: 912.1 MB)
21/02/17 01:41:41 INFO ContextCleaner: Cleaned accumulator 988
21/02/17 01:41:41 INFO ContextCleaner: Cleaned accumulator 1363
21/02/17 01:41:41 INFO ContextCleaner: Cleaned accumulator 964
21/02/17 01:41:41 INFO ContextCleaner: Cleaned accumulator 994
21/02/17 01:41:41 INFO ContextCleaner: Cleaned accumulator 1566
21/02/17 01:41:41 INFO ContextCleaner: Cleaned shuffle 9
21/02/17 01:41:41 INFO ContextCleaner: Cleaned accumulator 1334
21/02/17 01:41:41 INFO ContextCleaner: Cleaned accumulator 1222
21/02/17 01:41:41 INFO ContextCleaner: Cleaned accumulator 1175
21/02/17 01:41:41 INFO ContextCleaner: Cleaned accumulator 1220
21/02/17 01:41:41 INFO ContextCleaner: Cleaned accumulator 1537
21/02/17 01:41:41 INFO ContextCleaner: Cleaned accumulator 1430
21/02/17 01:41:41 INFO ContextCleaner: Cleaned accumulator 1214
21/02/17 01:41:41 INFO ContextCleaner: Cleaned accumulator 1224
21/02/17 01:41:41 INFO ContextCleaner: Cleaned accumulator 1426
21/02/17 01:41:41 INFO ContextCleaner: Cleaned accumulator 1532
21/02/17 01:41:41 INFO ContextCleaner: Cleaned accumulator 1341
21/02/17 01:41:41 INFO ContextCleaner: Cleaned accumulator 1131
21/02/17 01:41:41 INFO ContextCleaner: Cleaned accumulator 1357
21/02/17 01:41:41 INFO ContextCleaner: Cleaned accumulator 1514
21/02/17 01:41:41 INFO BlockManagerInfo: Removed broadcast_47_piece0 on localhost:41253 in memory (size: 23.2 KB, free: 912.1 MB)
21/02/17 01:41:41 INFO ContextCleaner: Cleaned accumulator 997
21/02/17 01:41:41 INFO ContextCleaner: Cleaned accumulator 1297
21/02/17 01:41:41 INFO ContextCleaner: Cleaned accumulator 1498
21/02/17 01:41:41 INFO ContextCleaner: Cleaned accumulator 1018
21/02/17 01:41:41 INFO BlockManagerInfo: Removed broadcast_49_piece0 on localhost:41253 in memory (size: 23.2 KB, free: 912.1 MB)
21/02/17 01:41:41 INFO ContextCleaner: Cleaned accumulator 927
21/02/17 01:41:41 INFO ContextCleaner: Cleaned accumulator 1541
21/02/17 01:41:41 INFO ContextCleaner: Cleaned accumulator 1258
21/02/17 01:41:41 INFO ContextCleaner: Cleaned accumulator 1570
21/02/17 01:41:41 INFO ContextCleaner: Cleaned accumulator 1035
21/02/17 01:41:41 INFO ContextCleaner: Cleaned accumulator 1457
21/02/17 01:41:41 INFO ContextCleaner: Cleaned accumulator 1333
21/02/17 01:41:41 INFO ContextCleaner: Cleaned accumulator 1433
21/02/17 01:41:41 INFO ContextCleaner: Cleaned accumulator 1471
21/02/17 01:41:41 INFO ContextCleaner: Cleaned accumulator 1166
21/02/17 01:41:41 INFO ContextCleaner: Cleaned accumulator 1525
21/02/17 01:41:41 INFO ContextCleaner: Cleaned accumulator 1010
21/02/17 01:41:41 INFO ContextCleaner: Cleaned accumulator 1307
21/02/17 01:41:41 INFO ContextCleaner: Cleaned accumulator 1165
21/02/17 01:41:41 INFO ContextCleaner: Cleaned accumulator 1201
21/02/17 01:41:41 INFO ContextCleaner: Cleaned accumulator 1592
21/02/17 01:41:41 INFO ContextCleaner: Cleaned accumulator 1594
21/02/17 01:41:41 INFO ContextCleaner: Cleaned accumulator 1321
21/02/17 01:41:41 INFO ContextCleaner: Cleaned accumulator 1575
21/02/17 01:41:41 INFO ContextCleaner: Cleaned accumulator 1177
21/02/17 01:41:41 INFO ContextCleaner: Cleaned accumulator 1344
21/02/17 01:41:41 INFO ContextCleaner: Cleaned accumulator 1404
21/02/17 01:41:41 INFO ContextCleaner: Cleaned accumulator 941
21/02/17 01:41:41 INFO ContextCleaner: Cleaned accumulator 1437
21/02/17 01:41:41 INFO ContextCleaner: Cleaned accumulator 934
21/02/17 01:41:41 INFO ContextCleaner: Cleaned accumulator 1513
21/02/17 01:41:41 INFO ContextCleaner: Cleaned accumulator 1282
21/02/17 01:41:41 INFO ContextCleaner: Cleaned accumulator 1253
21/02/17 01:41:41 INFO ContextCleaner: Cleaned accumulator 1597
21/02/17 01:41:41 INFO ContextCleaner: Cleaned accumulator 1225
21/02/17 01:41:41 INFO ContextCleaner: Cleaned accumulator 937
21/02/17 01:41:41 INFO ContextCleaner: Cleaned accumulator 952
21/02/17 01:41:41 INFO ContextCleaner: Cleaned accumulator 1008
21/02/17 01:41:41 INFO ContextCleaner: Cleaned accumulator 1477
21/02/17 01:41:41 INFO ContextCleaner: Cleaned accumulator 1567
21/02/17 01:41:41 INFO ContextCleaner: Cleaned accumulator 1560
21/02/17 01:41:41 INFO ContextCleaner: Cleaned accumulator 1093
21/02/17 01:41:41 INFO ContextCleaner: Cleaned accumulator 1320
21/02/17 01:41:41 INFO ContextCleaner: Cleaned accumulator 1365
21/02/17 01:41:41 INFO ContextCleaner: Cleaned accumulator 1596
21/02/17 01:41:41 INFO ContextCleaner: Cleaned accumulator 1407
21/02/17 01:41:41 INFO ContextCleaner: Cleaned accumulator 1568
21/02/17 01:41:41 INFO BlockManagerInfo: Removed broadcast_39_piece0 on localhost:41253 in memory (size: 9.4 KB, free: 912.1 MB)
21/02/17 01:41:41 INFO ContextCleaner: Cleaned accumulator 1186
21/02/17 01:41:41 INFO ContextCleaner: Cleaned accumulator 1234
21/02/17 01:41:41 INFO ContextCleaner: Cleaned accumulator 1193
21/02/17 01:41:41 INFO ContextCleaner: Cleaned accumulator 1156
21/02/17 01:41:41 INFO ContextCleaner: Cleaned accumulator 938
21/02/17 01:41:41 INFO ContextCleaner: Cleaned accumulator 1247
21/02/17 01:41:41 INFO ContextCleaner: Cleaned accumulator 1255
21/02/17 01:41:41 INFO ContextCleaner: Cleaned accumulator 1545
21/02/17 01:41:41 INFO ContextCleaner: Cleaned accumulator 1112
21/02/17 01:41:41 INFO ContextCleaner: Cleaned accumulator 1096
21/02/17 01:41:41 INFO ContextCleaner: Cleaned accumulator 1373
21/02/17 01:41:41 INFO BlockManager: Removing RDD 108
21/02/17 01:41:41 INFO ContextCleaner: Cleaned RDD 108
21/02/17 01:41:41 INFO ContextCleaner: Cleaned accumulator 1485
21/02/17 01:41:41 INFO ContextCleaner: Cleaned accumulator 1425
21/02/17 01:41:41 INFO ContextCleaner: Cleaned accumulator 1379
21/02/17 01:41:41 INFO ContextCleaner: Cleaned accumulator 1296
21/02/17 01:41:41 INFO ContextCleaner: Cleaned accumulator 1032
21/02/17 01:41:41 INFO ContextCleaner: Cleaned accumulator 1403
21/02/17 01:41:41 INFO ContextCleaner: Cleaned accumulator 967
21/02/17 01:41:41 INFO ContextCleaner: Cleaned accumulator 1123
21/02/17 01:41:41 INFO ContextCleaner: Cleaned accumulator 929
21/02/17 01:41:41 INFO ContextCleaner: Cleaned accumulator 1593
21/02/17 01:41:41 INFO ContextCleaner: Cleaned accumulator 1531
21/02/17 01:41:41 INFO ContextCleaner: Cleaned accumulator 1510
21/02/17 01:41:41 INFO ContextCleaner: Cleaned accumulator 1026
21/02/17 01:41:41 INFO ContextCleaner: Cleaned accumulator 1155
21/02/17 01:41:41 INFO ContextCleaner: Cleaned accumulator 1343
21/02/17 01:41:41 INFO ContextCleaner: Cleaned accumulator 1128
21/02/17 01:41:41 INFO ContextCleaner: Cleaned accumulator 1036
21/02/17 01:41:41 INFO ContextCleaner: Cleaned accumulator 1547
21/02/17 01:41:41 INFO ContextCleaner: Cleaned accumulator 1113
21/02/17 01:41:41 INFO ContextCleaner: Cleaned shuffle 12
21/02/17 01:41:41 INFO ContextCleaner: Cleaned accumulator 1181
21/02/17 01:41:41 INFO ContextCleaner: Cleaned accumulator 1480
21/02/17 01:41:41 INFO ContextCleaner: Cleaned accumulator 1359
21/02/17 01:41:41 INFO ContextCleaner: Cleaned accumulator 1066
21/02/17 01:41:41 INFO ContextCleaner: Cleaned accumulator 1313
21/02/17 01:41:41 INFO ContextCleaner: Cleaned accumulator 947
21/02/17 01:41:41 INFO ContextCleaner: Cleaned accumulator 1300
21/02/17 01:41:41 INFO ContextCleaner: Cleaned accumulator 1265
21/02/17 01:41:41 INFO ContextCleaner: Cleaned accumulator 935
21/02/17 01:41:41 INFO ContextCleaner: Cleaned accumulator 1413
21/02/17 01:41:41 INFO ContextCleaner: Cleaned accumulator 1317
21/02/17 01:41:41 INFO ContextCleaner: Cleaned accumulator 1310
21/02/17 01:41:41 INFO ContextCleaner: Cleaned accumulator 1259
21/02/17 01:41:41 INFO ContextCleaner: Cleaned accumulator 1493
21/02/17 01:41:41 INFO ContextCleaner: Cleaned accumulator 1583
21/02/17 01:41:41 INFO ContextCleaner: Cleaned accumulator 1076
21/02/17 01:41:41 INFO ContextCleaner: Cleaned accumulator 1571
21/02/17 01:41:41 INFO ContextCleaner: Cleaned shuffle 10
21/02/17 01:41:41 INFO ContextCleaner: Cleaned accumulator 1465
21/02/17 01:41:41 INFO ContextCleaner: Cleaned accumulator 1345
21/02/17 01:41:41 INFO ContextCleaner: Cleaned accumulator 1303
21/02/17 01:41:41 INFO ContextCleaner: Cleaned accumulator 1428
21/02/17 01:41:41 INFO ContextCleaner: Cleaned accumulator 1029
21/02/17 01:41:41 INFO ContextCleaner: Cleaned accumulator 1293
21/02/17 01:41:41 INFO ContextCleaner: Cleaned accumulator 1308
21/02/17 01:41:41 INFO ContextCleaner: Cleaned accumulator 1329
21/02/17 01:41:41 INFO ContextCleaner: Cleaned accumulator 996
21/02/17 01:41:41 INFO BlockManagerInfo: Removed broadcast_56_piece0 on localhost:41253 in memory (size: 23.2 KB, free: 912.2 MB)
21/02/17 01:41:41 INFO ContextCleaner: Cleaned accumulator 1277
21/02/17 01:41:41 INFO ContextCleaner: Cleaned accumulator 1101
21/02/17 01:41:41 INFO ContextCleaner: Cleaned accumulator 1226
21/02/17 01:41:41 INFO ContextCleaner: Cleaned accumulator 1132
21/02/17 01:41:41 INFO ContextCleaner: Cleaned accumulator 1461
21/02/17 01:41:41 INFO ContextCleaner: Cleaned accumulator 1418
21/02/17 01:41:41 INFO ContextCleaner: Cleaned accumulator 1040
21/02/17 01:41:41 INFO ContextCleaner: Cleaned accumulator 1140
21/02/17 01:41:41 INFO ContextCleaner: Cleaned accumulator 1348
21/02/17 01:41:41 INFO ContextCleaner: Cleaned accumulator 1014
21/02/17 01:41:41 INFO ContextCleaner: Cleaned accumulator 1190
21/02/17 01:41:41 INFO ContextCleaner: Cleaned accumulator 1281
21/02/17 01:41:41 INFO ContextCleaner: Cleaned accumulator 1372
21/02/17 01:41:41 INFO ContextCleaner: Cleaned accumulator 1487
21/02/17 01:41:41 INFO ContextCleaner: Cleaned shuffle 8
21/02/17 01:41:41 INFO ContextCleaner: Cleaned accumulator 1324
21/02/17 01:41:41 INFO ContextCleaner: Cleaned accumulator 1178
21/02/17 01:41:41 INFO ContextCleaner: Cleaned accumulator 1108
21/02/17 01:41:41 INFO ContextCleaner: Cleaned accumulator 1270
21/02/17 01:41:41 INFO ContextCleaner: Cleaned accumulator 1102
21/02/17 01:41:41 INFO ContextCleaner: Cleaned accumulator 1094
21/02/17 01:41:41 INFO ContextCleaner: Cleaned accumulator 1294
21/02/17 01:41:41 INFO ContextCleaner: Cleaned accumulator 1414
21/02/17 01:41:41 INFO ContextCleaner: Cleaned accumulator 1499
21/02/17 01:41:41 INFO ContextCleaner: Cleaned accumulator 966
21/02/17 01:41:41 INFO ContextCleaner: Cleaned accumulator 1349
21/02/17 01:41:41 INFO ContextCleaner: Cleaned accumulator 1179
21/02/17 01:41:41 INFO ContextCleaner: Cleaned accumulator 923
21/02/17 01:41:41 INFO ContextCleaner: Cleaned accumulator 1410
21/02/17 01:41:41 INFO ContextCleaner: Cleaned accumulator 1389
21/02/17 01:41:41 INFO ContextCleaner: Cleaned accumulator 1196
21/02/17 01:41:41 INFO ContextCleaner: Cleaned accumulator 1306
21/02/17 01:41:41 INFO ContextCleaner: Cleaned accumulator 1042
21/02/17 01:41:41 INFO ContextCleaner: Cleaned accumulator 1299
21/02/17 01:41:41 INFO ContextCleaner: Cleaned accumulator 959
21/02/17 01:41:41 INFO ContextCleaner: Cleaned accumulator 1058
21/02/17 01:41:41 INFO ContextCleaner: Cleaned accumulator 1263
21/02/17 01:41:41 INFO ContextCleaner: Cleaned accumulator 1496
21/02/17 01:41:41 INFO ContextCleaner: Cleaned accumulator 1075
21/02/17 01:41:41 INFO ContextCleaner: Cleaned accumulator 1446
21/02/17 01:41:41 INFO ContextCleaner: Cleaned accumulator 1502
21/02/17 01:41:41 INFO ContextCleaner: Cleaned accumulator 1109
21/02/17 01:41:41 INFO ContextCleaner: Cleaned accumulator 1500
21/02/17 01:41:41 INFO ContextCleaner: Cleaned accumulator 1527
21/02/17 01:41:41 INFO ContextCleaner: Cleaned accumulator 1028
21/02/17 01:41:41 INFO ContextCleaner: Cleaned accumulator 1051
21/02/17 01:41:41 INFO ContextCleaner: Cleaned accumulator 1095
21/02/17 01:41:41 INFO ContextCleaner: Cleaned accumulator 1105
21/02/17 01:41:41 INFO ContextCleaner: Cleaned accumulator 1107
21/02/17 01:41:41 INFO ContextCleaner: Cleaned accumulator 1145
21/02/17 01:41:41 INFO ContextCleaner: Cleaned accumulator 1295
21/02/17 01:41:41 INFO ContextCleaner: Cleaned accumulator 1479
21/02/17 01:41:41 INFO ContextCleaner: Cleaned accumulator 1159
21/02/17 01:41:41 INFO ContextCleaner: Cleaned accumulator 1126
21/02/17 01:41:41 INFO ContextCleaner: Cleaned accumulator 1184
21/02/17 01:41:41 INFO ContextCleaner: Cleaned accumulator 1012
21/02/17 01:41:41 INFO ContextCleaner: Cleaned accumulator 1573
21/02/17 01:41:41 INFO ContextCleaner: Cleaned accumulator 1005
21/02/17 01:41:41 INFO ContextCleaner: Cleaned accumulator 1141
21/02/17 01:41:41 INFO ContextCleaner: Cleaned accumulator 979
21/02/17 01:41:41 INFO ContextCleaner: Cleaned accumulator 1468
21/02/17 01:41:41 INFO ContextCleaner: Cleaned accumulator 1001
21/02/17 01:41:41 INFO ContextCleaner: Cleaned accumulator 1577
21/02/17 01:41:41 INFO ContextCleaner: Cleaned accumulator 1342
21/02/17 01:41:41 INFO ContextCleaner: Cleaned accumulator 1151
21/02/17 01:41:41 INFO ContextCleaner: Cleaned accumulator 1020
21/02/17 01:41:41 INFO ContextCleaner: Cleaned accumulator 1230
21/02/17 01:41:41 INFO ContextCleaner: Cleaned accumulator 1398
21/02/17 01:41:41 INFO BlockManagerInfo: Removed broadcast_59_piece0 on localhost:41253 in memory (size: 2.1 KB, free: 912.2 MB)
21/02/17 01:41:41 INFO ContextCleaner: Cleaned accumulator 1540
21/02/17 01:41:41 INFO ContextCleaner: Cleaned accumulator 1528
21/02/17 01:41:41 INFO ContextCleaner: Cleaned accumulator 1565
21/02/17 01:41:41 INFO ContextCleaner: Cleaned accumulator 1400
21/02/17 01:41:41 INFO ContextCleaner: Cleaned accumulator 950
21/02/17 01:41:41 INFO ContextCleaner: Cleaned accumulator 1518
21/02/17 01:41:41 INFO ContextCleaner: Cleaned accumulator 1062
21/02/17 01:41:41 INFO ContextCleaner: Cleaned accumulator 1148
21/02/17 01:41:41 INFO ContextCleaner: Cleaned accumulator 1421
21/02/17 01:41:41 INFO ContextCleaner: Cleaned accumulator 1067
21/02/17 01:41:41 INFO BlockManagerInfo: Removed broadcast_42_piece0 on localhost:41253 in memory (size: 4.5 KB, free: 912.2 MB)
21/02/17 01:41:41 INFO ContextCleaner: Cleaned accumulator 1326
21/02/17 01:41:41 INFO ContextCleaner: Cleaned accumulator 1233
21/02/17 01:41:41 INFO ContextCleaner: Cleaned accumulator 1381
21/02/17 01:41:41 INFO ContextCleaner: Cleaned accumulator 1041
21/02/17 01:41:41 INFO ContextCleaner: Cleaned accumulator 1097
21/02/17 01:41:41 INFO ContextCleaner: Cleaned accumulator 1160
21/02/17 01:41:41 INFO ContextCleaner: Cleaned accumulator 1248
21/02/17 01:41:41 INFO ContextCleaner: Cleaned accumulator 1235
21/02/17 01:41:41 INFO ContextCleaner: Cleaned accumulator 1338
21/02/17 01:41:41 INFO ContextCleaner: Cleaned accumulator 1581
21/02/17 01:41:41 INFO ContextCleaner: Cleaned accumulator 1191
21/02/17 01:41:41 INFO ContextCleaner: Cleaned accumulator 1197
21/02/17 01:41:41 INFO ContextCleaner: Cleaned accumulator 1503
21/02/17 01:41:41 INFO ContextCleaner: Cleaned accumulator 1154
21/02/17 01:41:41 INFO ContextCleaner: Cleaned accumulator 939
21/02/17 01:41:41 INFO ContextCleaner: Cleaned accumulator 1412
21/02/17 01:41:41 INFO ContextCleaner: Cleaned accumulator 1523
21/02/17 01:41:41 INFO ContextCleaner: Cleaned accumulator 981
21/02/17 01:41:41 INFO ContextCleaner: Cleaned accumulator 1557
21/02/17 01:41:41 INFO ContextCleaner: Cleaned accumulator 980
21/02/17 01:41:41 INFO ContextCleaner: Cleaned accumulator 973
21/02/17 01:41:41 INFO ContextCleaner: Cleaned accumulator 1553
21/02/17 01:41:41 INFO ContextCleaner: Cleaned accumulator 1176
21/02/17 01:41:41 INFO BlockManagerInfo: Removed broadcast_52_piece0 on localhost:41253 in memory (size: 2.1 KB, free: 912.2 MB)
21/02/17 01:41:41 INFO ContextCleaner: Cleaned accumulator 1236
21/02/17 01:41:41 INFO ContextCleaner: Cleaned accumulator 1301
21/02/17 01:41:41 INFO ContextCleaner: Cleaned accumulator 1376
21/02/17 01:41:41 INFO ContextCleaner: Cleaned accumulator 1508
21/02/17 01:41:41 INFO BlockManagerInfo: Removed broadcast_60_piece0 on localhost:41253 in memory (size: 23.2 KB, free: 912.2 MB)
21/02/17 01:41:41 INFO ContextCleaner: Cleaned accumulator 1459
21/02/17 01:41:41 INFO BlockManagerInfo: Removed broadcast_38_piece0 on localhost:41253 in memory (size: 3.8 KB, free: 912.2 MB)
21/02/17 01:41:41 INFO ContextCleaner: Cleaned accumulator 1021
21/02/17 01:41:41 INFO ContextCleaner: Cleaned accumulator 1078
21/02/17 01:41:41 INFO ContextCleaner: Cleaned accumulator 1440
21/02/17 01:41:41 INFO CodeGenerator: Code generated in 20.700425 ms
21/02/17 01:41:41 INFO ContextCleaner: Cleaned accumulator 944
21/02/17 01:41:41 INFO ContextCleaner: Cleaned accumulator 1044
21/02/17 01:41:41 INFO ContextCleaner: Cleaned accumulator 1170
21/02/17 01:41:41 INFO ContextCleaner: Cleaned accumulator 1515
21/02/17 01:41:41 INFO ContextCleaner: Cleaned accumulator 1017
21/02/17 01:41:41 INFO ContextCleaner: Cleaned accumulator 1030
21/02/17 01:41:41 INFO ContextCleaner: Cleaned accumulator 1483
21/02/17 01:41:41 INFO ContextCleaner: Cleaned accumulator 1451
21/02/17 01:41:41 INFO ContextCleaner: Cleaned accumulator 1206
21/02/17 01:41:41 INFO ContextCleaner: Cleaned accumulator 1011
21/02/17 01:41:41 INFO ContextCleaner: Cleaned accumulator 1187
21/02/17 01:41:41 INFO ContextCleaner: Cleaned accumulator 1331
21/02/17 01:41:41 INFO ContextCleaner: Cleaned accumulator 985
21/02/17 01:41:41 INFO ContextCleaner: Cleaned accumulator 1000
21/02/17 01:41:41 INFO ContextCleaner: Cleaned accumulator 958
21/02/17 01:41:41 INFO ContextCleaner: Cleaned accumulator 1375
21/02/17 01:41:41 INFO ContextCleaner: Cleaned accumulator 974
21/02/17 01:41:41 INFO ContextCleaner: Cleaned accumulator 1009
21/02/17 01:41:41 INFO ContextCleaner: Cleaned accumulator 1106
21/02/17 01:41:41 INFO ContextCleaner: Cleaned accumulator 1453
21/02/17 01:41:41 INFO ContextCleaner: Cleaned accumulator 1189
21/02/17 01:41:41 INFO ContextCleaner: Cleaned accumulator 1408
21/02/17 01:41:41 INFO ContextCleaner: Cleaned accumulator 1135
21/02/17 01:41:41 INFO ContextCleaner: Cleaned accumulator 1377
21/02/17 01:41:41 INFO BlockManagerInfo: Removed broadcast_62_piece0 on localhost:41253 in memory (size: 23.2 KB, free: 912.2 MB)
21/02/17 01:41:41 INFO ContextCleaner: Cleaned accumulator 1243
21/02/17 01:41:41 INFO ContextCleaner: Cleaned accumulator 933
21/02/17 01:41:41 INFO ContextCleaner: Cleaned accumulator 951
21/02/17 01:41:41 INFO ContextCleaner: Cleaned accumulator 1125
21/02/17 01:41:41 INFO ContextCleaner: Cleaned accumulator 1386
21/02/17 01:41:41 INFO ContextCleaner: Cleaned accumulator 1129
21/02/17 01:41:41 INFO ContextCleaner: Cleaned accumulator 926
21/02/17 01:41:41 INFO ContextCleaner: Cleaned accumulator 1335
21/02/17 01:41:41 INFO ContextCleaner: Cleaned accumulator 1279
21/02/17 01:41:41 INFO ContextCleaner: Cleaned accumulator 1427
21/02/17 01:41:41 INFO ContextCleaner: Cleaned accumulator 1137
21/02/17 01:41:41 INFO ContextCleaner: Cleaned accumulator 1380
21/02/17 01:41:41 INFO BlockManagerInfo: Removed broadcast_50_piece0 on localhost:41253 in memory (size: 2.1 KB, free: 912.2 MB)
21/02/17 01:41:41 INFO ContextCleaner: Cleaned accumulator 1347
21/02/17 01:41:41 INFO BlockManagerInfo: Removed broadcast_45_piece0 on localhost:41253 in memory (size: 9.6 KB, free: 912.2 MB)
21/02/17 01:41:41 INFO ContextCleaner: Cleaned accumulator 1053
21/02/17 01:41:41 INFO ContextCleaner: Cleaned accumulator 1205
21/02/17 01:41:41 INFO BlockManagerInfo: Removed broadcast_58_piece0 on localhost:41253 in memory (size: 23.2 KB, free: 912.3 MB)
21/02/17 01:41:41 INFO ContextCleaner: Cleaned accumulator 1209
21/02/17 01:41:41 INFO ContextCleaner: Cleaned accumulator 1099
21/02/17 01:41:41 INFO BlockManagerInfo: Removed broadcast_41_piece0 on localhost:41253 in memory (size: 3.3 KB, free: 912.3 MB)
21/02/17 01:41:41 INFO ContextCleaner: Cleaned accumulator 1591
21/02/17 01:41:41 INFO ContextCleaner: Cleaned accumulator 1520
21/02/17 01:41:41 INFO ContextCleaner: Cleaned accumulator 1033
21/02/17 01:41:41 INFO ContextCleaner: Cleaned accumulator 1286
21/02/17 01:41:41 INFO ContextCleaner: Cleaned accumulator 1192
21/02/17 01:41:41 INFO ContextCleaner: Cleaned accumulator 1002
21/02/17 01:41:41 INFO ContextCleaner: Cleaned accumulator 962
21/02/17 01:41:41 INFO ContextCleaner: Cleaned accumulator 1071
21/02/17 01:41:41 INFO ContextCleaner: Cleaned accumulator 1231
21/02/17 01:41:41 INFO BlockManagerInfo: Removed broadcast_43_piece0 on localhost:41253 in memory (size: 3.8 KB, free: 912.3 MB)
21/02/17 01:41:41 INFO ContextCleaner: Cleaned accumulator 1369
21/02/17 01:41:41 INFO ContextCleaner: Cleaned accumulator 1491
21/02/17 01:41:41 INFO ContextCleaner: Cleaned accumulator 1169
21/02/17 01:41:41 INFO BlockManagerInfo: Removed broadcast_64_piece0 on localhost:41253 in memory (size: 23.2 KB, free: 912.3 MB)
21/02/17 01:41:41 INFO ContextCleaner: Cleaned accumulator 1312
21/02/17 01:41:41 INFO ContextCleaner: Cleaned accumulator 1127
21/02/17 01:41:41 INFO ContextCleaner: Cleaned accumulator 1119
21/02/17 01:41:41 INFO ContextCleaner: Cleaned accumulator 1590
21/02/17 01:41:41 INFO ContextCleaner: Cleaned accumulator 949
21/02/17 01:41:41 INFO ContextCleaner: Cleaned accumulator 954
21/02/17 01:41:41 INFO ContextCleaner: Cleaned accumulator 1006
21/02/17 01:41:41 INFO ContextCleaner: Cleaned accumulator 1415
21/02/17 01:41:41 INFO ContextCleaner: Cleaned accumulator 975
21/02/17 01:41:41 INFO ContextCleaner: Cleaned accumulator 1257
21/02/17 01:41:41 INFO CodeGenerator: Code generated in 10.749605 ms
21/02/17 01:41:41 INFO MemoryStore: Block broadcast_67 stored as values in memory (estimated size 292.8 KB, free 912.0 MB)
21/02/17 01:41:41 INFO MemoryStore: Block broadcast_67_piece0 stored as bytes in memory (estimated size 25.0 KB, free 912.0 MB)
21/02/17 01:41:41 INFO BlockManagerInfo: Added broadcast_67_piece0 in memory on localhost:41253 (size: 25.0 KB, free: 912.3 MB)
21/02/17 01:41:41 INFO SparkContext: Created broadcast 67 from head at RFormula.scala:600
21/02/17 01:41:41 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
21/02/17 01:41:41 INFO SparkContext: Starting job: head at RFormula.scala:600
21/02/17 01:41:41 INFO DAGScheduler: Got job 42 (head at RFormula.scala:600) with 1 output partitions
21/02/17 01:41:41 INFO DAGScheduler: Final stage: ResultStage 55 (head at RFormula.scala:600)
21/02/17 01:41:41 INFO DAGScheduler: Parents of final stage: List()
21/02/17 01:41:41 INFO DAGScheduler: Missing parents: List()
21/02/17 01:41:41 INFO DAGScheduler: Submitting ResultStage 55 (MapPartitionsRDD[181] at head at RFormula.scala:600), which has no missing parents
21/02/17 01:41:41 INFO MemoryStore: Block broadcast_68 stored as values in memory (estimated size 10.5 KB, free 912.0 MB)
21/02/17 01:41:41 INFO MemoryStore: Block broadcast_68_piece0 stored as bytes in memory (estimated size 5.0 KB, free 912.0 MB)
21/02/17 01:41:41 INFO BlockManagerInfo: Added broadcast_68_piece0 in memory on localhost:41253 (size: 5.0 KB, free: 912.3 MB)
21/02/17 01:41:41 INFO SparkContext: Created broadcast 68 from broadcast at DAGScheduler.scala:1161
21/02/17 01:41:41 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 55 (MapPartitionsRDD[181] at head at RFormula.scala:600) (first 15 tasks are for partitions Vector(0))
21/02/17 01:41:41 INFO TaskSchedulerImpl: Adding task set 55.0 with 1 tasks
21/02/17 01:41:41 INFO TaskSetManager: Starting task 0.0 in stage 55.0 (TID 57, localhost, executor driver, partition 0, PROCESS_LOCAL, 8441 bytes)
21/02/17 01:41:41 INFO Executor: Running task 0.0 in stage 55.0 (TID 57)
21/02/17 01:41:41 INFO FileScanRDD: Reading File path: file:///tmp/Rtmp09Oz4e/file22e22736a8feb/stages/0_r_formula__9467ebc0_1e9a_44aa_b6e1_220b95e6649f/pipelineModel/stages/1_vectorAttrRewriter_f6945e4c4508/data/part-00000-99cb7fe4-7cfd-4587-8f81-c55dc4635142-c000.snappy.parquet, range: 0-893, partition values: [empty row]
21/02/17 01:41:41 INFO ParquetReadSupport: Going to read the following fields from the Parquet file:

Parquet form:
message spark_schema {
  optional binary vectorCol (UTF8);
  optional group prefixesToRewrite (MAP) {
    repeated group key_value {
      required binary key (UTF8);
      optional binary value (UTF8);
    }
  }
}

Catalyst form:
StructType(StructField(vectorCol,StringType,true), StructField(prefixesToRewrite,MapType(StringType,StringType,true),true))
       
21/02/17 01:41:41 INFO Executor: Finished task 0.0 in stage 55.0 (TID 57). 1216 bytes result sent to driver
21/02/17 01:41:41 INFO TaskSetManager: Finished task 0.0 in stage 55.0 (TID 57) in 18 ms on localhost (executor driver) (1/1)
21/02/17 01:41:41 INFO TaskSchedulerImpl: Removed TaskSet 55.0, whose tasks have all completed, from pool 
21/02/17 01:41:41 INFO DAGScheduler: ResultStage 55 (head at RFormula.scala:600) finished in 0.023 s
21/02/17 01:41:41 INFO DAGScheduler: Job 42 finished: head at RFormula.scala:600, took 0.023928 s
21/02/17 01:41:41 INFO MemoryStore: Block broadcast_69 stored as values in memory (estimated size 239.6 KB, free 911.7 MB)
21/02/17 01:41:41 INFO MemoryStore: Block broadcast_69_piece0 stored as bytes in memory (estimated size 23.2 KB, free 911.7 MB)
21/02/17 01:41:41 INFO BlockManagerInfo: Added broadcast_69_piece0 in memory on localhost:41253 (size: 23.2 KB, free: 912.2 MB)
21/02/17 01:41:41 INFO SparkContext: Created broadcast 69 from textFile at ReadWrite.scala:615
21/02/17 01:41:41 INFO FileInputFormat: Total input paths to process : 1
21/02/17 01:41:41 INFO SparkContext: Starting job: first at ReadWrite.scala:615
21/02/17 01:41:41 INFO DAGScheduler: Got job 43 (first at ReadWrite.scala:615) with 1 output partitions
21/02/17 01:41:41 INFO DAGScheduler: Final stage: ResultStage 56 (first at ReadWrite.scala:615)
21/02/17 01:41:41 INFO DAGScheduler: Parents of final stage: List()
21/02/17 01:41:41 INFO DAGScheduler: Missing parents: List()
21/02/17 01:41:41 INFO DAGScheduler: Submitting ResultStage 56 (/tmp/Rtmp09Oz4e/file22e22736a8feb/stages/0_r_formula__9467ebc0_1e9a_44aa_b6e1_220b95e6649f/pipelineModel/stages/2_columnPruner_54113b6a0e68/metadata MapPartitionsRDD[183] at textFile at ReadWrite.scala:615), which has no missing parents
21/02/17 01:41:41 INFO MemoryStore: Block broadcast_70 stored as values in memory (estimated size 3.6 KB, free 911.7 MB)
21/02/17 01:41:41 INFO MemoryStore: Block broadcast_70_piece0 stored as bytes in memory (estimated size 2.2 KB, free 911.7 MB)
21/02/17 01:41:41 INFO BlockManagerInfo: Added broadcast_70_piece0 in memory on localhost:41253 (size: 2.2 KB, free: 912.2 MB)
21/02/17 01:41:41 INFO SparkContext: Created broadcast 70 from broadcast at DAGScheduler.scala:1161
21/02/17 01:41:41 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 56 (/tmp/Rtmp09Oz4e/file22e22736a8feb/stages/0_r_formula__9467ebc0_1e9a_44aa_b6e1_220b95e6649f/pipelineModel/stages/2_columnPruner_54113b6a0e68/metadata MapPartitionsRDD[183] at textFile at ReadWrite.scala:615) (first 15 tasks are for partitions Vector(0))
21/02/17 01:41:41 INFO TaskSchedulerImpl: Adding task set 56.0 with 1 tasks
21/02/17 01:41:41 INFO TaskSetManager: Starting task 0.0 in stage 56.0 (TID 58, localhost, executor driver, partition 0, PROCESS_LOCAL, 8025 bytes)
21/02/17 01:41:41 INFO Executor: Running task 0.0 in stage 56.0 (TID 58)
21/02/17 01:41:41 INFO HadoopRDD: Input split: file:/tmp/Rtmp09Oz4e/file22e22736a8feb/stages/0_r_formula__9467ebc0_1e9a_44aa_b6e1_220b95e6649f/pipelineModel/stages/2_columnPruner_54113b6a0e68/metadata/part-00000:0+171
21/02/17 01:41:41 INFO Executor: Finished task 0.0 in stage 56.0 (TID 58). 967 bytes result sent to driver
21/02/17 01:41:41 INFO TaskSetManager: Finished task 0.0 in stage 56.0 (TID 58) in 3 ms on localhost (executor driver) (1/1)
21/02/17 01:41:41 INFO TaskSchedulerImpl: Removed TaskSet 56.0, whose tasks have all completed, from pool 
21/02/17 01:41:41 INFO DAGScheduler: ResultStage 56 (first at ReadWrite.scala:615) finished in 0.009 s
21/02/17 01:41:41 INFO DAGScheduler: Job 43 finished: first at ReadWrite.scala:615, took 0.009699 s
21/02/17 01:41:41 INFO MemoryStore: Block broadcast_71 stored as values in memory (estimated size 239.6 KB, free 911.5 MB)
21/02/17 01:41:42 INFO MemoryStore: Block broadcast_71_piece0 stored as bytes in memory (estimated size 23.2 KB, free 911.4 MB)
21/02/17 01:41:42 INFO BlockManagerInfo: Added broadcast_71_piece0 in memory on localhost:41253 (size: 23.2 KB, free: 912.2 MB)
21/02/17 01:41:42 INFO SparkContext: Created broadcast 71 from textFile at ReadWrite.scala:615
21/02/17 01:41:42 INFO FileInputFormat: Total input paths to process : 1
21/02/17 01:41:42 INFO SparkContext: Starting job: first at ReadWrite.scala:615
21/02/17 01:41:42 INFO DAGScheduler: Got job 44 (first at ReadWrite.scala:615) with 1 output partitions
21/02/17 01:41:42 INFO DAGScheduler: Final stage: ResultStage 57 (first at ReadWrite.scala:615)
21/02/17 01:41:42 INFO DAGScheduler: Parents of final stage: List()
21/02/17 01:41:42 INFO DAGScheduler: Missing parents: List()
21/02/17 01:41:42 INFO DAGScheduler: Submitting ResultStage 57 (/tmp/Rtmp09Oz4e/file22e22736a8feb/stages/0_r_formula__9467ebc0_1e9a_44aa_b6e1_220b95e6649f/pipelineModel/stages/2_columnPruner_54113b6a0e68/metadata MapPartitionsRDD[185] at textFile at ReadWrite.scala:615), which has no missing parents
21/02/17 01:41:42 INFO MemoryStore: Block broadcast_72 stored as values in memory (estimated size 3.6 KB, free 911.4 MB)
21/02/17 01:41:42 INFO MemoryStore: Block broadcast_72_piece0 stored as bytes in memory (estimated size 2.2 KB, free 911.4 MB)
21/02/17 01:41:42 INFO BlockManagerInfo: Added broadcast_72_piece0 in memory on localhost:41253 (size: 2.2 KB, free: 912.2 MB)
21/02/17 01:41:42 INFO SparkContext: Created broadcast 72 from broadcast at DAGScheduler.scala:1161
21/02/17 01:41:42 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 57 (/tmp/Rtmp09Oz4e/file22e22736a8feb/stages/0_r_formula__9467ebc0_1e9a_44aa_b6e1_220b95e6649f/pipelineModel/stages/2_columnPruner_54113b6a0e68/metadata MapPartitionsRDD[185] at textFile at ReadWrite.scala:615) (first 15 tasks are for partitions Vector(0))
21/02/17 01:41:42 INFO TaskSchedulerImpl: Adding task set 57.0 with 1 tasks
21/02/17 01:41:42 INFO TaskSetManager: Starting task 0.0 in stage 57.0 (TID 59, localhost, executor driver, partition 0, PROCESS_LOCAL, 8025 bytes)
21/02/17 01:41:42 INFO Executor: Running task 0.0 in stage 57.0 (TID 59)
21/02/17 01:41:42 INFO HadoopRDD: Input split: file:/tmp/Rtmp09Oz4e/file22e22736a8feb/stages/0_r_formula__9467ebc0_1e9a_44aa_b6e1_220b95e6649f/pipelineModel/stages/2_columnPruner_54113b6a0e68/metadata/part-00000:0+171
21/02/17 01:41:42 INFO Executor: Finished task 0.0 in stage 57.0 (TID 59). 924 bytes result sent to driver
21/02/17 01:41:42 INFO TaskSetManager: Finished task 0.0 in stage 57.0 (TID 59) in 3 ms on localhost (executor driver) (1/1)
21/02/17 01:41:42 INFO TaskSchedulerImpl: Removed TaskSet 57.0, whose tasks have all completed, from pool 
21/02/17 01:41:42 INFO DAGScheduler: ResultStage 57 (first at ReadWrite.scala:615) finished in 0.006 s
21/02/17 01:41:42 INFO DAGScheduler: Job 44 finished: first at ReadWrite.scala:615, took 0.007285 s
21/02/17 01:41:42 INFO SparkContext: Starting job: parquet at RFormula.scala:509
21/02/17 01:41:42 INFO DAGScheduler: Got job 45 (parquet at RFormula.scala:509) with 1 output partitions
21/02/17 01:41:42 INFO DAGScheduler: Final stage: ResultStage 58 (parquet at RFormula.scala:509)
21/02/17 01:41:42 INFO DAGScheduler: Parents of final stage: List()
21/02/17 01:41:42 INFO DAGScheduler: Missing parents: List()
21/02/17 01:41:42 INFO DAGScheduler: Submitting ResultStage 58 (MapPartitionsRDD[187] at parquet at RFormula.scala:509), which has no missing parents
21/02/17 01:41:42 INFO MemoryStore: Block broadcast_73 stored as values in memory (estimated size 74.1 KB, free 911.4 MB)
21/02/17 01:41:42 INFO MemoryStore: Block broadcast_73_piece0 stored as bytes in memory (estimated size 26.1 KB, free 911.3 MB)
21/02/17 01:41:42 INFO BlockManagerInfo: Added broadcast_73_piece0 in memory on localhost:41253 (size: 26.1 KB, free: 912.2 MB)
21/02/17 01:41:42 INFO SparkContext: Created broadcast 73 from broadcast at DAGScheduler.scala:1161
21/02/17 01:41:42 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 58 (MapPartitionsRDD[187] at parquet at RFormula.scala:509) (first 15 tasks are for partitions Vector(0))
21/02/17 01:41:42 INFO TaskSchedulerImpl: Adding task set 58.0 with 1 tasks
21/02/17 01:41:42 INFO TaskSetManager: Starting task 0.0 in stage 58.0 (TID 60, localhost, executor driver, partition 0, PROCESS_LOCAL, 8184 bytes)
21/02/17 01:41:42 INFO Executor: Running task 0.0 in stage 58.0 (TID 60)
21/02/17 01:41:42 INFO Executor: Finished task 0.0 in stage 58.0 (TID 60). 1556 bytes result sent to driver
21/02/17 01:41:42 INFO TaskSetManager: Finished task 0.0 in stage 58.0 (TID 60) in 8 ms on localhost (executor driver) (1/1)
21/02/17 01:41:42 INFO TaskSchedulerImpl: Removed TaskSet 58.0, whose tasks have all completed, from pool 
21/02/17 01:41:42 INFO DAGScheduler: ResultStage 58 (parquet at RFormula.scala:509) finished in 0.015 s
21/02/17 01:41:42 INFO DAGScheduler: Job 45 finished: parquet at RFormula.scala:509, took 0.017060 s
21/02/17 01:41:42 INFO FileSourceStrategy: Pruning directories with: 
21/02/17 01:41:42 INFO FileSourceStrategy: Post-Scan Filters: 
21/02/17 01:41:42 INFO FileSourceStrategy: Output Data Schema: struct<columnsToPrune: array<string>>
21/02/17 01:41:42 INFO FileSourceScanExec: Pushed Filters: 
21/02/17 01:41:42 INFO CodeGenerator: Code generated in 8.399769 ms
21/02/17 01:41:42 INFO CodeGenerator: Code generated in 5.605516 ms
21/02/17 01:41:42 INFO MemoryStore: Block broadcast_74 stored as values in memory (estimated size 292.4 KB, free 911.1 MB)
21/02/17 01:41:42 INFO MemoryStore: Block broadcast_74_piece0 stored as bytes in memory (estimated size 25.1 KB, free 911.0 MB)
21/02/17 01:41:42 INFO BlockManagerInfo: Added broadcast_74_piece0 in memory on localhost:41253 (size: 25.1 KB, free: 912.2 MB)
21/02/17 01:41:42 INFO SparkContext: Created broadcast 74 from head at RFormula.scala:509
21/02/17 01:41:42 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
21/02/17 01:41:42 INFO SparkContext: Starting job: head at RFormula.scala:509
21/02/17 01:41:42 INFO DAGScheduler: Got job 46 (head at RFormula.scala:509) with 1 output partitions
21/02/17 01:41:42 INFO DAGScheduler: Final stage: ResultStage 59 (head at RFormula.scala:509)
21/02/17 01:41:42 INFO DAGScheduler: Parents of final stage: List()
21/02/17 01:41:42 INFO DAGScheduler: Missing parents: List()
21/02/17 01:41:42 INFO DAGScheduler: Submitting ResultStage 59 (MapPartitionsRDD[191] at head at RFormula.scala:509), which has no missing parents
21/02/17 01:41:42 INFO MemoryStore: Block broadcast_75 stored as values in memory (estimated size 8.9 KB, free 911.0 MB)
21/02/17 01:41:42 INFO MemoryStore: Block broadcast_75_piece0 stored as bytes in memory (estimated size 4.6 KB, free 911.0 MB)
21/02/17 01:41:42 INFO BlockManagerInfo: Added broadcast_75_piece0 in memory on localhost:41253 (size: 4.6 KB, free: 912.2 MB)
21/02/17 01:41:42 INFO SparkContext: Created broadcast 75 from broadcast at DAGScheduler.scala:1161
21/02/17 01:41:42 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 59 (MapPartitionsRDD[191] at head at RFormula.scala:509) (first 15 tasks are for partitions Vector(0))
21/02/17 01:41:42 INFO TaskSchedulerImpl: Adding task set 59.0 with 1 tasks
21/02/17 01:41:42 INFO TaskSetManager: Starting task 0.0 in stage 59.0 (TID 61, localhost, executor driver, partition 0, PROCESS_LOCAL, 8435 bytes)
21/02/17 01:41:42 INFO Executor: Running task 0.0 in stage 59.0 (TID 61)
21/02/17 01:41:42 INFO FileScanRDD: Reading File path: file:///tmp/Rtmp09Oz4e/file22e22736a8feb/stages/0_r_formula__9467ebc0_1e9a_44aa_b6e1_220b95e6649f/pipelineModel/stages/2_columnPruner_54113b6a0e68/data/part-00000-7902622c-81b1-47f2-8cf1-628c5c73af50-c000.snappy.parquet, range: 0-476, partition values: [empty row]
21/02/17 01:41:42 INFO ParquetReadSupport: Going to read the following fields from the Parquet file:

Parquet form:
message spark_schema {
  optional group columnsToPrune (LIST) {
    repeated group list {
      optional binary element (UTF8);
    }
  }
}

Catalyst form:
StructType(StructField(columnsToPrune,ArrayType(StringType,true),true))
       
21/02/17 01:41:42 INFO Executor: Finished task 0.0 in stage 59.0 (TID 61). 1200 bytes result sent to driver
21/02/17 01:41:42 INFO TaskSetManager: Finished task 0.0 in stage 59.0 (TID 61) in 11 ms on localhost (executor driver) (1/1)
21/02/17 01:41:42 INFO TaskSchedulerImpl: Removed TaskSet 59.0, whose tasks have all completed, from pool 
21/02/17 01:41:42 INFO DAGScheduler: ResultStage 59 (head at RFormula.scala:509) finished in 0.016 s
21/02/17 01:41:42 INFO DAGScheduler: Job 46 finished: head at RFormula.scala:509, took 0.017444 s
21/02/17 01:41:42 INFO MemoryStore: Block broadcast_76 stored as values in memory (estimated size 239.6 KB, free 910.8 MB)
21/02/17 01:41:42 INFO MemoryStore: Block broadcast_76_piece0 stored as bytes in memory (estimated size 23.2 KB, free 910.8 MB)
21/02/17 01:41:42 INFO BlockManagerInfo: Added broadcast_76_piece0 in memory on localhost:41253 (size: 23.2 KB, free: 912.1 MB)
21/02/17 01:41:42 INFO SparkContext: Created broadcast 76 from textFile at ReadWrite.scala:615
21/02/17 01:41:42 INFO FileInputFormat: Total input paths to process : 1
21/02/17 01:41:42 INFO SparkContext: Starting job: first at ReadWrite.scala:615
21/02/17 01:41:42 INFO DAGScheduler: Got job 47 (first at ReadWrite.scala:615) with 1 output partitions
21/02/17 01:41:42 INFO DAGScheduler: Final stage: ResultStage 60 (first at ReadWrite.scala:615)
21/02/17 01:41:42 INFO DAGScheduler: Parents of final stage: List()
21/02/17 01:41:42 INFO DAGScheduler: Missing parents: List()
21/02/17 01:41:42 INFO DAGScheduler: Submitting ResultStage 60 (/tmp/Rtmp09Oz4e/file22e22736a8feb/stages/1_xgboost_regressor__dbadb0af_de87_45b0_93ff_cc50903fe025/metadata MapPartitionsRDD[193] at textFile at ReadWrite.scala:615), which has no missing parents
21/02/17 01:41:42 INFO MemoryStore: Block broadcast_77 stored as values in memory (estimated size 3.5 KB, free 910.8 MB)
21/02/17 01:41:42 INFO MemoryStore: Block broadcast_77_piece0 stored as bytes in memory (estimated size 2.1 KB, free 910.8 MB)
21/02/17 01:41:42 INFO BlockManagerInfo: Added broadcast_77_piece0 in memory on localhost:41253 (size: 2.1 KB, free: 912.1 MB)
21/02/17 01:41:42 INFO SparkContext: Created broadcast 77 from broadcast at DAGScheduler.scala:1161
21/02/17 01:41:42 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 60 (/tmp/Rtmp09Oz4e/file22e22736a8feb/stages/1_xgboost_regressor__dbadb0af_de87_45b0_93ff_cc50903fe025/metadata MapPartitionsRDD[193] at textFile at ReadWrite.scala:615) (first 15 tasks are for partitions Vector(0))
21/02/17 01:41:42 INFO TaskSchedulerImpl: Adding task set 60.0 with 1 tasks
21/02/17 01:41:42 INFO TaskSetManager: Starting task 0.0 in stage 60.0 (TID 62, localhost, executor driver, partition 0, PROCESS_LOCAL, 7983 bytes)
21/02/17 01:41:42 INFO Executor: Running task 0.0 in stage 60.0 (TID 62)
21/02/17 01:41:42 INFO HadoopRDD: Input split: file:/tmp/Rtmp09Oz4e/file22e22736a8feb/stages/1_xgboost_regressor__dbadb0af_de87_45b0_93ff_cc50903fe025/metadata/part-00000:0+1245
21/02/17 01:41:42 INFO Executor: Finished task 0.0 in stage 60.0 (TID 62). 2049 bytes result sent to driver
21/02/17 01:41:42 INFO TaskSetManager: Finished task 0.0 in stage 60.0 (TID 62) in 3 ms on localhost (executor driver) (1/1)
21/02/17 01:41:42 INFO TaskSchedulerImpl: Removed TaskSet 60.0, whose tasks have all completed, from pool 
21/02/17 01:41:42 INFO DAGScheduler: ResultStage 60 (first at ReadWrite.scala:615) finished in 0.007 s
21/02/17 01:41:42 INFO DAGScheduler: Job 47 finished: first at ReadWrite.scala:615, took 0.008474 s
21/02/17 01:41:42 INFO MemoryStore: Block broadcast_78 stored as values in memory (estimated size 239.6 KB, free 910.5 MB)
21/02/17 01:41:42 INFO MemoryStore: Block broadcast_78_piece0 stored as bytes in memory (estimated size 23.2 KB, free 910.5 MB)
21/02/17 01:41:42 INFO BlockManagerInfo: Added broadcast_78_piece0 in memory on localhost:41253 (size: 23.2 KB, free: 912.1 MB)
21/02/17 01:41:42 INFO SparkContext: Created broadcast 78 from textFile at DefaultXGBoostParamsReader.scala:82
21/02/17 01:41:42 INFO FileInputFormat: Total input paths to process : 1
21/02/17 01:41:42 INFO SparkContext: Starting job: first at DefaultXGBoostParamsReader.scala:82
21/02/17 01:41:42 INFO DAGScheduler: Got job 48 (first at DefaultXGBoostParamsReader.scala:82) with 1 output partitions
21/02/17 01:41:42 INFO DAGScheduler: Final stage: ResultStage 61 (first at DefaultXGBoostParamsReader.scala:82)
21/02/17 01:41:42 INFO DAGScheduler: Parents of final stage: List()
21/02/17 01:41:42 INFO DAGScheduler: Missing parents: List()
21/02/17 01:41:42 INFO DAGScheduler: Submitting ResultStage 61 (/tmp/Rtmp09Oz4e/file22e22736a8feb/stages/1_xgboost_regressor__dbadb0af_de87_45b0_93ff_cc50903fe025/metadata MapPartitionsRDD[195] at textFile at DefaultXGBoostParamsReader.scala:82), which has no missing parents
21/02/17 01:41:42 INFO MemoryStore: Block broadcast_79 stored as values in memory (estimated size 3.5 KB, free 910.5 MB)
21/02/17 01:41:42 INFO MemoryStore: Block broadcast_79_piece0 stored as bytes in memory (estimated size 2.1 KB, free 910.5 MB)
21/02/17 01:41:42 INFO BlockManagerInfo: Added broadcast_79_piece0 in memory on localhost:41253 (size: 2.1 KB, free: 912.1 MB)
21/02/17 01:41:42 INFO SparkContext: Created broadcast 79 from broadcast at DAGScheduler.scala:1161
21/02/17 01:41:42 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 61 (/tmp/Rtmp09Oz4e/file22e22736a8feb/stages/1_xgboost_regressor__dbadb0af_de87_45b0_93ff_cc50903fe025/metadata MapPartitionsRDD[195] at textFile at DefaultXGBoostParamsReader.scala:82) (first 15 tasks are for partitions Vector(0))
21/02/17 01:41:42 INFO TaskSchedulerImpl: Adding task set 61.0 with 1 tasks
21/02/17 01:41:42 INFO TaskSetManager: Starting task 0.0 in stage 61.0 (TID 63, localhost, executor driver, partition 0, PROCESS_LOCAL, 7983 bytes)
21/02/17 01:41:42 INFO Executor: Running task 0.0 in stage 61.0 (TID 63)
21/02/17 01:41:42 INFO HadoopRDD: Input split: file:/tmp/Rtmp09Oz4e/file22e22736a8feb/stages/1_xgboost_regressor__dbadb0af_de87_45b0_93ff_cc50903fe025/metadata/part-00000:0+1245
21/02/17 01:41:42 INFO Executor: Finished task 0.0 in stage 61.0 (TID 63). 2049 bytes result sent to driver
21/02/17 01:41:42 INFO TaskSetManager: Finished task 0.0 in stage 61.0 (TID 63) in 3 ms on localhost (executor driver) (1/1)
21/02/17 01:41:42 INFO TaskSchedulerImpl: Removed TaskSet 61.0, whose tasks have all completed, from pool 
21/02/17 01:41:42 INFO DAGScheduler: ResultStage 61 (first at DefaultXGBoostParamsReader.scala:82) finished in 0.006 s
21/02/17 01:41:42 INFO DAGScheduler: Job 48 finished: first at DefaultXGBoostParamsReader.scala:82, took 0.007012 s
21/02/17 01:41:42 INFO MemoryStore: Block broadcast_80 stored as values in memory (estimated size 64.0 B, free 910.5 MB)
21/02/17 01:41:42 INFO MemoryStore: Block broadcast_80_piece0 stored as bytes in memory (estimated size 511.0 B, free 910.5 MB)
21/02/17 01:41:42 INFO BlockManagerInfo: Added broadcast_80_piece0 in memory on localhost:41253 (size: 511.0 B, free: 912.1 MB)
21/02/17 01:41:42 INFO SparkContext: Created broadcast 80 from broadcast at XGBoostRegressor.scala:271
21/02/17 01:41:42 INFO SparkContext: Starting job: collect at utils.scala:135
21/02/17 01:41:42 INFO DAGScheduler: Got job 49 (collect at utils.scala:135) with 1 output partitions
21/02/17 01:41:42 INFO DAGScheduler: Final stage: ResultStage 62 (collect at utils.scala:135)
21/02/17 01:41:42 INFO DAGScheduler: Parents of final stage: List()
21/02/17 01:41:42 INFO DAGScheduler: Missing parents: List()
21/02/17 01:41:42 INFO DAGScheduler: Submitting ResultStage 62 (MapPartitionsRDD[206] at collect at utils.scala:135), which has no missing parents
21/02/17 01:41:42 INFO MemoryStore: Block broadcast_81 stored as values in memory (estimated size 6.4 KB, free 910.5 MB)
21/02/17 01:41:42 INFO MemoryStore: Block broadcast_81_piece0 stored as bytes in memory (estimated size 3.3 KB, free 910.5 MB)
21/02/17 01:41:42 INFO BlockManagerInfo: Added broadcast_81_piece0 in memory on localhost:41253 (size: 3.3 KB, free: 912.1 MB)
21/02/17 01:41:42 INFO SparkContext: Created broadcast 81 from broadcast at DAGScheduler.scala:1161
21/02/17 01:41:42 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 62 (MapPartitionsRDD[206] at collect at utils.scala:135) (first 15 tasks are for partitions Vector(0))
21/02/17 01:41:42 INFO TaskSchedulerImpl: Adding task set 62.0 with 1 tasks
21/02/17 01:41:42 INFO TaskSetManager: Starting task 0.0 in stage 62.0 (TID 64, localhost, executor driver, partition 0, PROCESS_LOCAL, 8080 bytes)
21/02/17 01:41:42 INFO Executor: Running task 0.0 in stage 62.0 (TID 64)
21/02/17 01:41:42 INFO Executor: Finished task 0.0 in stage 62.0 (TID 64). 1286 bytes result sent to driver
21/02/17 01:41:42 INFO TaskSetManager: Finished task 0.0 in stage 62.0 (TID 64) in 3 ms on localhost (executor driver) (1/1)
21/02/17 01:41:42 INFO TaskSchedulerImpl: Removed TaskSet 62.0, whose tasks have all completed, from pool 
21/02/17 01:41:42 INFO DAGScheduler: ResultStage 62 (collect at utils.scala:135) finished in 0.008 s
21/02/17 01:41:42 INFO DAGScheduler: Job 49 finished: collect at utils.scala:135, took 0.008842 s
21/02/17 01:41:42 INFO SparkContext: Starting job: count at utils.scala:135
21/02/17 01:41:42 INFO DAGScheduler: Registering RDD 209 (count at utils.scala:135)
21/02/17 01:41:42 INFO DAGScheduler: Got job 50 (count at utils.scala:135) with 1 output partitions
21/02/17 01:41:42 INFO DAGScheduler: Final stage: ResultStage 64 (count at utils.scala:135)
21/02/17 01:41:42 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 63)
21/02/17 01:41:42 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 63)
21/02/17 01:41:42 INFO DAGScheduler: Submitting ShuffleMapStage 63 (MapPartitionsRDD[209] at count at utils.scala:135), which has no missing parents
21/02/17 01:41:42 INFO MemoryStore: Block broadcast_82 stored as values in memory (estimated size 8.4 KB, free 910.5 MB)
21/02/17 01:41:42 INFO MemoryStore: Block broadcast_82_piece0 stored as bytes in memory (estimated size 4.5 KB, free 910.5 MB)
21/02/17 01:41:42 INFO BlockManagerInfo: Added broadcast_82_piece0 in memory on localhost:41253 (size: 4.5 KB, free: 912.1 MB)
21/02/17 01:41:42 INFO SparkContext: Created broadcast 82 from broadcast at DAGScheduler.scala:1161
21/02/17 01:41:42 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 63 (MapPartitionsRDD[209] at count at utils.scala:135) (first 15 tasks are for partitions Vector(0))
21/02/17 01:41:42 INFO TaskSchedulerImpl: Adding task set 63.0 with 1 tasks
21/02/17 01:41:42 INFO TaskSetManager: Starting task 0.0 in stage 63.0 (TID 65, localhost, executor driver, partition 0, PROCESS_LOCAL, 8069 bytes)
21/02/17 01:41:42 INFO Executor: Running task 0.0 in stage 63.0 (TID 65)
21/02/17 01:41:42 INFO Executor: Finished task 0.0 in stage 63.0 (TID 65). 1499 bytes result sent to driver
21/02/17 01:41:42 INFO TaskSetManager: Finished task 0.0 in stage 63.0 (TID 65) in 4 ms on localhost (executor driver) (1/1)
21/02/17 01:41:42 INFO TaskSchedulerImpl: Removed TaskSet 63.0, whose tasks have all completed, from pool 
21/02/17 01:41:42 INFO DAGScheduler: ShuffleMapStage 63 (count at utils.scala:135) finished in 0.007 s
21/02/17 01:41:42 INFO DAGScheduler: looking for newly runnable stages
21/02/17 01:41:42 INFO DAGScheduler: running: Set()
21/02/17 01:41:42 INFO DAGScheduler: waiting: Set(ResultStage 64)
21/02/17 01:41:42 INFO DAGScheduler: failed: Set()
21/02/17 01:41:42 INFO DAGScheduler: Submitting ResultStage 64 (MapPartitionsRDD[212] at count at utils.scala:135), which has no missing parents
21/02/17 01:41:42 INFO MemoryStore: Block broadcast_83 stored as values in memory (estimated size 7.1 KB, free 910.5 MB)
21/02/17 01:41:42 INFO MemoryStore: Block broadcast_83_piece0 stored as bytes in memory (estimated size 3.8 KB, free 910.5 MB)
21/02/17 01:41:42 INFO BlockManagerInfo: Added broadcast_83_piece0 in memory on localhost:41253 (size: 3.8 KB, free: 912.1 MB)
21/02/17 01:41:42 INFO SparkContext: Created broadcast 83 from broadcast at DAGScheduler.scala:1161
21/02/17 01:41:42 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 64 (MapPartitionsRDD[212] at count at utils.scala:135) (first 15 tasks are for partitions Vector(0))
21/02/17 01:41:42 INFO TaskSchedulerImpl: Adding task set 64.0 with 1 tasks
21/02/17 01:41:42 INFO TaskSetManager: Starting task 0.0 in stage 64.0 (TID 66, localhost, executor driver, partition 0, NODE_LOCAL, 7767 bytes)
21/02/17 01:41:42 INFO Executor: Running task 0.0 in stage 64.0 (TID 66)
21/02/17 01:41:42 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks including 1 local blocks and 0 remote blocks
21/02/17 01:41:42 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
21/02/17 01:41:42 INFO Executor: Finished task 0.0 in stage 64.0 (TID 66). 1782 bytes result sent to driver
21/02/17 01:41:42 INFO TaskSetManager: Finished task 0.0 in stage 64.0 (TID 66) in 4 ms on localhost (executor driver) (1/1)
21/02/17 01:41:42 INFO TaskSchedulerImpl: Removed TaskSet 64.0, whose tasks have all completed, from pool 
21/02/17 01:41:42 INFO DAGScheduler: ResultStage 64 (count at utils.scala:135) finished in 0.007 s
21/02/17 01:41:42 INFO DAGScheduler: Job 50 finished: count at utils.scala:135, took 0.017099 s
21/02/17 01:41:42 INFO SparkContext: Starting job: collect at utils.scala:135
21/02/17 01:41:42 INFO DAGScheduler: Got job 51 (collect at utils.scala:135) with 1 output partitions
21/02/17 01:41:42 INFO DAGScheduler: Final stage: ResultStage 65 (collect at utils.scala:135)
21/02/17 01:41:42 INFO DAGScheduler: Parents of final stage: List()
21/02/17 01:41:42 INFO DAGScheduler: Missing parents: List()
21/02/17 01:41:42 INFO DAGScheduler: Submitting ResultStage 65 (MapPartitionsRDD[215] at collect at utils.scala:135), which has no missing parents
21/02/17 01:41:42 INFO MemoryStore: Block broadcast_84 stored as values in memory (estimated size 59.1 KB, free 910.4 MB)
21/02/17 01:41:42 INFO MemoryStore: Block broadcast_84_piece0 stored as bytes in memory (estimated size 25.5 KB, free 910.4 MB)
21/02/17 01:41:42 INFO BlockManagerInfo: Added broadcast_84_piece0 in memory on localhost:41253 (size: 25.5 KB, free: 912.1 MB)
21/02/17 01:41:42 INFO SparkContext: Created broadcast 84 from broadcast at DAGScheduler.scala:1161
21/02/17 01:41:42 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 65 (MapPartitionsRDD[215] at collect at utils.scala:135) (first 15 tasks are for partitions Vector(0))
21/02/17 01:41:42 INFO TaskSchedulerImpl: Adding task set 65.0 with 1 tasks
21/02/17 01:41:42 INFO TaskSetManager: Starting task 0.0 in stage 65.0 (TID 67, localhost, executor driver, partition 0, PROCESS_LOCAL, 19011 bytes)
21/02/17 01:41:42 INFO Executor: Running task 0.0 in stage 65.0 (TID 67)
21/02/17 01:41:42 INFO BlockManager: Found block rdd_26_0 locally
21/02/17 01:41:42 INFO Executor: Finished task 0.0 in stage 65.0 (TID 67). 1815 bytes result sent to driver
21/02/17 01:41:42 INFO TaskSetManager: Finished task 0.0 in stage 65.0 (TID 67) in 58 ms on localhost (executor driver) (1/1)
21/02/17 01:41:42 INFO TaskSchedulerImpl: Removed TaskSet 65.0, whose tasks have all completed, from pool 
21/02/17 01:41:42 INFO DAGScheduler: ResultStage 65 (collect at utils.scala:135) finished in 0.061 s
21/02/17 01:41:42 INFO DAGScheduler: Job 51 finished: collect at utils.scala:135, took 0.063238 s
21/02/17 01:41:42 INFO SparkContext: Starting job: count at utils.scala:135
21/02/17 01:41:42 INFO DAGScheduler: Registering RDD 218 (count at utils.scala:135)
21/02/17 01:41:42 INFO DAGScheduler: Got job 52 (count at utils.scala:135) with 1 output partitions
21/02/17 01:41:42 INFO DAGScheduler: Final stage: ResultStage 67 (count at utils.scala:135)
21/02/17 01:41:42 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 66)
21/02/17 01:41:42 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 66)
21/02/17 01:41:42 INFO DAGScheduler: Submitting ShuffleMapStage 66 (MapPartitionsRDD[218] at count at utils.scala:135), which has no missing parents
21/02/17 01:41:42 INFO MemoryStore: Block broadcast_85 stored as values in memory (estimated size 60.0 KB, free 910.3 MB)
21/02/17 01:41:42 INFO MemoryStore: Block broadcast_85_piece0 stored as bytes in memory (estimated size 25.9 KB, free 910.3 MB)
21/02/17 01:41:42 INFO BlockManagerInfo: Added broadcast_85_piece0 in memory on localhost:41253 (size: 25.9 KB, free: 912.0 MB)
21/02/17 01:41:42 INFO SparkContext: Created broadcast 85 from broadcast at DAGScheduler.scala:1161
21/02/17 01:41:42 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 66 (MapPartitionsRDD[218] at count at utils.scala:135) (first 15 tasks are for partitions Vector(0))
21/02/17 01:41:42 INFO TaskSchedulerImpl: Adding task set 66.0 with 1 tasks
21/02/17 01:41:42 INFO TaskSetManager: Starting task 0.0 in stage 66.0 (TID 68, localhost, executor driver, partition 0, PROCESS_LOCAL, 19000 bytes)
21/02/17 01:41:42 INFO Executor: Running task 0.0 in stage 66.0 (TID 68)
21/02/17 01:41:43 INFO BlockManager: Found block rdd_26_0 locally
21/02/17 01:41:43 INFO Executor: Finished task 0.0 in stage 66.0 (TID 68). 1933 bytes result sent to driver
21/02/17 01:41:43 INFO TaskSetManager: Finished task 0.0 in stage 66.0 (TID 68) in 44 ms on localhost (executor driver) (1/1)
21/02/17 01:41:43 INFO TaskSchedulerImpl: Removed TaskSet 66.0, whose tasks have all completed, from pool 
21/02/17 01:41:43 INFO DAGScheduler: ShuffleMapStage 66 (count at utils.scala:135) finished in 0.049 s
21/02/17 01:41:43 INFO DAGScheduler: looking for newly runnable stages
21/02/17 01:41:43 INFO DAGScheduler: running: Set()
21/02/17 01:41:43 INFO DAGScheduler: waiting: Set(ResultStage 67)
21/02/17 01:41:43 INFO DAGScheduler: failed: Set()
21/02/17 01:41:43 INFO DAGScheduler: Submitting ResultStage 67 (MapPartitionsRDD[221] at count at utils.scala:135), which has no missing parents
21/02/17 01:41:43 INFO MemoryStore: Block broadcast_86 stored as values in memory (estimated size 7.1 KB, free 910.3 MB)
21/02/17 01:41:43 INFO MemoryStore: Block broadcast_86_piece0 stored as bytes in memory (estimated size 3.8 KB, free 910.3 MB)
21/02/17 01:41:43 INFO BlockManagerInfo: Added broadcast_86_piece0 in memory on localhost:41253 (size: 3.8 KB, free: 912.0 MB)
21/02/17 01:41:43 INFO SparkContext: Created broadcast 86 from broadcast at DAGScheduler.scala:1161
21/02/17 01:41:43 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 67 (MapPartitionsRDD[221] at count at utils.scala:135) (first 15 tasks are for partitions Vector(0))
21/02/17 01:41:43 INFO TaskSchedulerImpl: Adding task set 67.0 with 1 tasks
21/02/17 01:41:43 INFO TaskSetManager: Starting task 0.0 in stage 67.0 (TID 69, localhost, executor driver, partition 0, NODE_LOCAL, 7767 bytes)
21/02/17 01:41:43 INFO Executor: Running task 0.0 in stage 67.0 (TID 69)
21/02/17 01:41:43 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks including 1 local blocks and 0 remote blocks
21/02/17 01:41:43 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
21/02/17 01:41:43 INFO Executor: Finished task 0.0 in stage 67.0 (TID 69). 1739 bytes result sent to driver
21/02/17 01:41:43 INFO TaskSetManager: Finished task 0.0 in stage 67.0 (TID 69) in 11 ms on localhost (executor driver) (1/1)
21/02/17 01:41:43 INFO TaskSchedulerImpl: Removed TaskSet 67.0, whose tasks have all completed, from pool 
21/02/17 01:41:43 INFO DAGScheduler: ResultStage 67 (count at utils.scala:135) finished in 0.014 s
21/02/17 01:41:43 INFO DAGScheduler: Job 52 finished: count at utils.scala:135, took 0.068229 s
21/02/17 01:41:44 INFO SparkContext: Invoking stop() from shutdown hook
21/02/17 01:41:44 INFO SparkUI: Stopped Spark web UI at http://localhost:4040
21/02/17 01:41:44 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!
21/02/17 01:41:44 INFO MemoryStore: MemoryStore cleared
21/02/17 01:41:44 INFO BlockManager: BlockManager stopped
21/02/17 01:41:44 INFO BlockManagerMaster: BlockManagerMaster stopped
21/02/17 01:41:44 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!
21/02/17 01:41:44 INFO SparkContext: Successfully stopped SparkContext
21/02/17 01:41:44 INFO ShutdownHookManager: Shutdown hook called
21/02/17 01:41:44 INFO ShutdownHookManager: Deleting directory /tmp/spark-2a224719-1a63-41af-b9d1-6c3c5850d7b1
21/02/17 01:41:44 INFO ShutdownHookManager: Deleting directory /tmp/spark-5aaba24c-a6be-48e5-bfa2-4b6f3c9243b5
21/02/17 01:41:53 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
21/02/17 01:41:54 INFO SecurityManager: Changing view acls to: yitaoli
21/02/17 01:41:54 INFO SecurityManager: Changing modify acls to: yitaoli
21/02/17 01:41:54 INFO SecurityManager: Changing view acls groups to: 
21/02/17 01:41:54 INFO SecurityManager: Changing modify acls groups to: 
21/02/17 01:41:54 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(yitaoli); groups with view permissions: Set(); users  with modify permissions: Set(yitaoli); groups with modify permissions: Set()
21/02/17 01:41:54 INFO HiveConf: Found configuration file file:/home/yitaoli/spark/spark-3.0.0-bin-hadoop3.2/conf/hive-site.xml
21/02/17 01:41:54 INFO SparkContext: Running Spark version 3.0.0
21/02/17 01:41:54 INFO ResourceUtils: ==============================================================
21/02/17 01:41:54 INFO ResourceUtils: Resources for spark.driver:

21/02/17 01:41:54 INFO ResourceUtils: ==============================================================
21/02/17 01:41:54 INFO SparkContext: Submitted application: sparklyr
21/02/17 01:41:54 INFO SecurityManager: Changing view acls to: yitaoli
21/02/17 01:41:54 INFO SecurityManager: Changing modify acls to: yitaoli
21/02/17 01:41:54 INFO SecurityManager: Changing view acls groups to: 
21/02/17 01:41:54 INFO SecurityManager: Changing modify acls groups to: 
21/02/17 01:41:54 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(yitaoli); groups with view permissions: Set(); users  with modify permissions: Set(yitaoli); groups with modify permissions: Set()
21/02/17 01:41:54 INFO Utils: Successfully started service 'sparkDriver' on port 35157.
21/02/17 01:41:54 INFO SparkEnv: Registering MapOutputTracker
21/02/17 01:41:54 INFO SparkEnv: Registering BlockManagerMaster
21/02/17 01:41:55 INFO BlockManagerMasterEndpoint: Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
21/02/17 01:41:55 INFO BlockManagerMasterEndpoint: BlockManagerMasterEndpoint up
21/02/17 01:41:55 INFO SparkEnv: Registering BlockManagerMasterHeartbeat
21/02/17 01:41:55 INFO DiskBlockManager: Created local directory at /tmp/blockmgr-580a7ad5-4014-4408-aa26-c004f4238ab9
21/02/17 01:41:55 INFO MemoryStore: MemoryStore started with capacity 912.3 MiB
21/02/17 01:41:55 INFO SparkEnv: Registering OutputCommitCoordinator
21/02/17 01:41:55 INFO Utils: Successfully started service 'SparkUI' on port 4040.
21/02/17 01:41:55 INFO SparkUI: Bound SparkUI to 127.0.0.1, and started at http://localhost:4040
21/02/17 01:41:55 INFO SparkContext: Added JAR file:///home/yitaoli/.ivy2/jars/ml.dmlc_xgboost4j-spark_2.12-1.3.1.jar at spark://localhost:35157/jars/ml.dmlc_xgboost4j-spark_2.12-1.3.1.jar with timestamp 1613526115309
21/02/17 01:41:55 INFO SparkContext: Added JAR file:///home/yitaoli/.ivy2/jars/org.json4s_json4s-jackson_2.12-3.6.10.jar at spark://localhost:35157/jars/org.json4s_json4s-jackson_2.12-3.6.10.jar with timestamp 1613526115310
21/02/17 01:41:55 INFO SparkContext: Added JAR file:///home/yitaoli/.ivy2/jars/ml.dmlc_xgboost4j_2.12-1.3.1.jar at spark://localhost:35157/jars/ml.dmlc_xgboost4j_2.12-1.3.1.jar with timestamp 1613526115310
21/02/17 01:41:55 INFO SparkContext: Added JAR file:///home/yitaoli/.ivy2/jars/com.esotericsoftware_kryo-4.0.2.jar at spark://localhost:35157/jars/com.esotericsoftware_kryo-4.0.2.jar with timestamp 1613526115310
21/02/17 01:41:55 INFO SparkContext: Added JAR file:///home/yitaoli/.ivy2/jars/org.scala-lang_scala-compiler-2.12.8.jar at spark://localhost:35157/jars/org.scala-lang_scala-compiler-2.12.8.jar with timestamp 1613526115310
21/02/17 01:41:55 INFO SparkContext: Added JAR file:///home/yitaoli/.ivy2/jars/org.scala-lang_scala-reflect-2.12.8.jar at spark://localhost:35157/jars/org.scala-lang_scala-reflect-2.12.8.jar with timestamp 1613526115311
21/02/17 01:41:55 INFO SparkContext: Added JAR file:///home/yitaoli/.ivy2/jars/commons-logging_commons-logging-1.2.jar at spark://localhost:35157/jars/commons-logging_commons-logging-1.2.jar with timestamp 1613526115311
21/02/17 01:41:55 INFO SparkContext: Added JAR file:///home/yitaoli/.ivy2/jars/com.typesafe.akka_akka-actor_2.12-2.5.23.jar at spark://localhost:35157/jars/com.typesafe.akka_akka-actor_2.12-2.5.23.jar with timestamp 1613526115311
21/02/17 01:41:55 INFO SparkContext: Added JAR file:///home/yitaoli/.ivy2/jars/org.scalatest_scalatest_2.12-3.0.5.jar at spark://localhost:35157/jars/org.scalatest_scalatest_2.12-3.0.5.jar with timestamp 1613526115311
21/02/17 01:41:55 INFO SparkContext: Added JAR file:///home/yitaoli/.ivy2/jars/com.typesafe_config-1.3.3.jar at spark://localhost:35157/jars/com.typesafe_config-1.3.3.jar with timestamp 1613526115311
21/02/17 01:41:55 INFO SparkContext: Added JAR file:///home/yitaoli/.ivy2/jars/org.scala-lang.modules_scala-java8-compat_2.12-0.8.0.jar at spark://localhost:35157/jars/org.scala-lang.modules_scala-java8-compat_2.12-0.8.0.jar with timestamp 1613526115311
21/02/17 01:41:55 INFO SparkContext: Added JAR file:///home/yitaoli/.ivy2/jars/org.scalactic_scalactic_2.12-3.0.5.jar at spark://localhost:35157/jars/org.scalactic_scalactic_2.12-3.0.5.jar with timestamp 1613526115311
21/02/17 01:41:55 INFO SparkContext: Added JAR file:///home/yitaoli/.ivy2/jars/org.scala-lang.modules_scala-xml_2.12-1.0.6.jar at spark://localhost:35157/jars/org.scala-lang.modules_scala-xml_2.12-1.0.6.jar with timestamp 1613526115312
21/02/17 01:41:55 INFO SparkContext: Added JAR file:///home/yitaoli/.ivy2/jars/com.esotericsoftware_reflectasm-1.11.3.jar at spark://localhost:35157/jars/com.esotericsoftware_reflectasm-1.11.3.jar with timestamp 1613526115312
21/02/17 01:41:55 INFO SparkContext: Added JAR file:///home/yitaoli/.ivy2/jars/com.esotericsoftware_minlog-1.3.0.jar at spark://localhost:35157/jars/com.esotericsoftware_minlog-1.3.0.jar with timestamp 1613526115312
21/02/17 01:41:55 INFO SparkContext: Added JAR file:///home/yitaoli/.ivy2/jars/org.objenesis_objenesis-2.5.1.jar at spark://localhost:35157/jars/org.objenesis_objenesis-2.5.1.jar with timestamp 1613526115312
21/02/17 01:41:55 INFO SparkContext: Added JAR file:///home/yitaoli/.ivy2/jars/org.ow2.asm_asm-5.0.4.jar at spark://localhost:35157/jars/org.ow2.asm_asm-5.0.4.jar with timestamp 1613526115312
21/02/17 01:41:55 INFO SparkContext: Added JAR file:///home/yitaoli/.ivy2/jars/org.json4s_json4s-core_2.12-3.6.10.jar at spark://localhost:35157/jars/org.json4s_json4s-core_2.12-3.6.10.jar with timestamp 1613526115312
21/02/17 01:41:55 INFO SparkContext: Added JAR file:///home/yitaoli/.ivy2/jars/com.fasterxml.jackson.core_jackson-databind-2.9.10.6.jar at spark://localhost:35157/jars/com.fasterxml.jackson.core_jackson-databind-2.9.10.6.jar with timestamp 1613526115312
21/02/17 01:41:55 INFO SparkContext: Added JAR file:///home/yitaoli/.ivy2/jars/org.json4s_json4s-ast_2.12-3.6.10.jar at spark://localhost:35157/jars/org.json4s_json4s-ast_2.12-3.6.10.jar with timestamp 1613526115312
21/02/17 01:41:55 INFO SparkContext: Added JAR file:///home/yitaoli/.ivy2/jars/org.json4s_json4s-scalap_2.12-3.6.10.jar at spark://localhost:35157/jars/org.json4s_json4s-scalap_2.12-3.6.10.jar with timestamp 1613526115313
21/02/17 01:41:55 INFO SparkContext: Added JAR file:///home/yitaoli/.ivy2/jars/com.thoughtworks.paranamer_paranamer-2.8.jar at spark://localhost:35157/jars/com.thoughtworks.paranamer_paranamer-2.8.jar with timestamp 1613526115313
21/02/17 01:41:55 INFO SparkContext: Added JAR file:///home/yitaoli/.ivy2/jars/com.fasterxml.jackson.core_jackson-annotations-2.9.10.jar at spark://localhost:35157/jars/com.fasterxml.jackson.core_jackson-annotations-2.9.10.jar with timestamp 1613526115313
21/02/17 01:41:55 INFO SparkContext: Added JAR file:///home/yitaoli/.ivy2/jars/com.fasterxml.jackson.core_jackson-core-2.9.10.jar at spark://localhost:35157/jars/com.fasterxml.jackson.core_jackson-core-2.9.10.jar with timestamp 1613526115313
21/02/17 01:41:55 INFO SparkContext: Added JAR file:/home/yitaoli/R/x86_64-pc-linux-gnu-library/4.0/sparklyr/java/sparklyr-3.0-2.12.jar at spark://localhost:35157/jars/sparklyr-3.0-2.12.jar with timestamp 1613526115313
21/02/17 01:41:55 INFO Executor: Starting executor ID driver on host localhost
21/02/17 01:41:55 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 42591.
21/02/17 01:41:55 INFO NettyBlockTransferService: Server created on localhost:42591
21/02/17 01:41:55 INFO BlockManager: Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
21/02/17 01:41:55 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, localhost, 42591, None)
21/02/17 01:41:55 INFO BlockManagerMasterEndpoint: Registering block manager localhost:42591 with 912.3 MiB RAM, BlockManagerId(driver, localhost, 42591, None)
21/02/17 01:41:55 INFO BlockManagerMaster: Registered BlockManager BlockManagerId(driver, localhost, 42591, None)
21/02/17 01:41:55 INFO BlockManager: Initialized BlockManager: BlockManagerId(driver, localhost, 42591, None)
21/02/17 01:41:55 INFO SharedState: loading hive config file: file:/home/yitaoli/spark/spark-3.0.0-bin-hadoop3.2/conf/hive-site.xml
21/02/17 01:41:55 INFO SharedState: Setting hive.metastore.warehouse.dir ('null') to the value of spark.sql.warehouse.dir ('file:/home/yitaoli/sparkxgb/tests/testthat/spark-warehouse').
21/02/17 01:41:55 INFO SharedState: Warehouse path is 'file:/home/yitaoli/sparkxgb/tests/testthat/spark-warehouse'.
21/02/17 01:41:57 INFO HiveUtils: Initializing HiveMetastoreConnection version 2.3.7 using Spark classes.
21/02/17 01:41:57 INFO HiveConf: Found configuration file file:/home/yitaoli/spark/spark-3.0.0-bin-hadoop3.2/conf/hive-site.xml
21/02/17 01:41:57 INFO SessionState: Created HDFS directory: /tmp/hive/yitaoli/7002cc0a-b4ae-415c-8362-629acaae694c
21/02/17 01:41:57 INFO SessionState: Created local directory: /tmp/yitaoli/7002cc0a-b4ae-415c-8362-629acaae694c
21/02/17 01:41:57 INFO SessionState: Created HDFS directory: /tmp/hive/yitaoli/7002cc0a-b4ae-415c-8362-629acaae694c/_tmp_space.db
21/02/17 01:41:57 INFO HiveClientImpl: Warehouse location for Hive client (version 2.3.7) is file:/home/yitaoli/sparkxgb/tests/testthat/spark-warehouse
21/02/17 01:41:58 WARN HiveConf: HiveConf of name hive.stats.jdbc.timeout does not exist
21/02/17 01:41:58 WARN HiveConf: HiveConf of name hive.stats.retries.wait does not exist
21/02/17 01:41:58 INFO HiveMetaStore: 0: Opening raw store with implementation class:org.apache.hadoop.hive.metastore.ObjectStore
21/02/17 01:41:58 INFO ObjectStore: ObjectStore, initialize called
21/02/17 01:41:58 INFO Persistence: Property hive.metastore.integral.jdo.pushdown unknown - will be ignored
21/02/17 01:41:58 INFO Persistence: Property datanucleus.cache.level2 unknown - will be ignored
21/02/17 01:41:59 INFO ObjectStore: Setting MetaStore object pin classes with hive.metastore.cache.pinobjtypes="Table,StorageDescriptor,SerDeInfo,Partition,Database,Type,FieldSchema,Order"
21/02/17 01:42:00 INFO MetaStoreDirectSql: Using direct SQL, underlying DB is DERBY
21/02/17 01:42:00 INFO ObjectStore: Initialized ObjectStore
21/02/17 01:42:00 WARN ObjectStore: Version information not found in metastore. hive.metastore.schema.verification is not enabled so recording the schema version 2.3.0
21/02/17 01:42:00 WARN ObjectStore: setMetaStoreSchemaVersion called but recording version is disabled: version = 2.3.0, comment = Set by MetaStore yitaoli@127.0.1.1
21/02/17 01:42:00 WARN ObjectStore: Failed to get database default, returning NoSuchObjectException
21/02/17 01:42:01 INFO HiveMetaStore: Added admin role in metastore
21/02/17 01:42:01 INFO HiveMetaStore: Added public role in metastore
21/02/17 01:42:01 INFO HiveMetaStore: No user is added in admin role, since config is empty
21/02/17 01:42:01 INFO HiveMetaStore: 0: get_all_functions
21/02/17 01:42:01 INFO audit: ugi=yitaoli	ip=unknown-ip-addr	cmd=get_all_functions	
21/02/17 01:42:01 INFO HiveMetaStore: 0: get_database: default
21/02/17 01:42:01 INFO audit: ugi=yitaoli	ip=unknown-ip-addr	cmd=get_database: default	
21/02/17 01:42:01 INFO HiveMetaStore: 0: get_database: default
21/02/17 01:42:01 INFO audit: ugi=yitaoli	ip=unknown-ip-addr	cmd=get_database: default	
21/02/17 01:42:01 INFO HiveMetaStore: 0: get_table : db=default tbl=iris
21/02/17 01:42:01 INFO audit: ugi=yitaoli	ip=unknown-ip-addr	cmd=get_table : db=default tbl=iris	
21/02/17 01:42:01 INFO HiveMetaStore: 0: get_database: global_temp
21/02/17 01:42:01 INFO audit: ugi=yitaoli	ip=unknown-ip-addr	cmd=get_database: global_temp	
21/02/17 01:42:01 WARN ObjectStore: Failed to get database global_temp, returning NoSuchObjectException
21/02/17 01:42:01 INFO HiveMetaStore: 0: get_database: default
21/02/17 01:42:01 INFO audit: ugi=yitaoli	ip=unknown-ip-addr	cmd=get_database: default	
21/02/17 01:42:01 INFO HiveMetaStore: 0: get_database: default
21/02/17 01:42:01 INFO audit: ugi=yitaoli	ip=unknown-ip-addr	cmd=get_database: default	
21/02/17 01:42:01 INFO HiveMetaStore: 0: get_tables: db=default pat=*
21/02/17 01:42:01 INFO audit: ugi=yitaoli	ip=unknown-ip-addr	cmd=get_tables: db=default pat=*	
21/02/17 01:42:02 INFO SparkContext: Starting job: collect at utils.scala:54
21/02/17 01:42:02 INFO DAGScheduler: Job 0 finished: collect at utils.scala:54, took 0.004200 s
21/02/17 01:42:02 INFO CodeGenerator: Code generated in 181.784139 ms
21/02/17 01:42:03 INFO SparkContext: Starting job: collect at utils.scala:137
21/02/17 01:42:03 INFO DAGScheduler: Got job 1 (collect at utils.scala:137) with 1 output partitions
21/02/17 01:42:03 INFO DAGScheduler: Final stage: ResultStage 0 (collect at utils.scala:137)
21/02/17 01:42:03 INFO DAGScheduler: Parents of final stage: List()
21/02/17 01:42:03 INFO DAGScheduler: Missing parents: List()
21/02/17 01:42:03 INFO DAGScheduler: Submitting ResultStage 0 (MapPartitionsRDD[9] at collect at utils.scala:137), which has no missing parents
21/02/17 01:42:03 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 6.5 KiB, free 912.3 MiB)
21/02/17 01:42:03 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 3.2 KiB, free 912.3 MiB)
21/02/17 01:42:03 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on localhost:42591 (size: 3.2 KiB, free: 912.3 MiB)
21/02/17 01:42:03 INFO SparkContext: Created broadcast 0 from broadcast at DAGScheduler.scala:1200
21/02/17 01:42:03 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 0 (MapPartitionsRDD[9] at collect at utils.scala:137) (first 15 tasks are for partitions Vector(0))
21/02/17 01:42:03 INFO TaskSchedulerImpl: Adding task set 0.0 with 1 tasks
21/02/17 01:42:03 INFO TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0, localhost, executor driver, partition 0, PROCESS_LOCAL, 7561 bytes)
21/02/17 01:42:03 INFO Executor: Running task 0.0 in stage 0.0 (TID 0)
21/02/17 01:42:03 INFO Executor: Fetching spark://localhost:35157/jars/com.esotericsoftware_minlog-1.3.0.jar with timestamp 1613526115312
21/02/17 01:42:03 INFO TransportClientFactory: Successfully created connection to localhost/127.0.0.1:35157 after 15 ms (0 ms spent in bootstraps)
21/02/17 01:42:03 INFO Utils: Fetching spark://localhost:35157/jars/com.esotericsoftware_minlog-1.3.0.jar to /tmp/spark-e4d01697-77d8-438c-adea-d54815b81a46/userFiles-c9134761-6fd5-472e-b3ca-97c676433268/fetchFileTemp417979657813487136.tmp
21/02/17 01:42:03 INFO Executor: Adding file:/tmp/spark-e4d01697-77d8-438c-adea-d54815b81a46/userFiles-c9134761-6fd5-472e-b3ca-97c676433268/com.esotericsoftware_minlog-1.3.0.jar to class loader
21/02/17 01:42:03 INFO Executor: Fetching spark://localhost:35157/jars/org.scala-lang.modules_scala-xml_2.12-1.0.6.jar with timestamp 1613526115312
21/02/17 01:42:03 INFO Utils: Fetching spark://localhost:35157/jars/org.scala-lang.modules_scala-xml_2.12-1.0.6.jar to /tmp/spark-e4d01697-77d8-438c-adea-d54815b81a46/userFiles-c9134761-6fd5-472e-b3ca-97c676433268/fetchFileTemp4179924821356740632.tmp
21/02/17 01:42:03 INFO Executor: Adding file:/tmp/spark-e4d01697-77d8-438c-adea-d54815b81a46/userFiles-c9134761-6fd5-472e-b3ca-97c676433268/org.scala-lang.modules_scala-xml_2.12-1.0.6.jar to class loader
21/02/17 01:42:03 INFO Executor: Fetching spark://localhost:35157/jars/com.esotericsoftware_reflectasm-1.11.3.jar with timestamp 1613526115312
21/02/17 01:42:03 INFO Utils: Fetching spark://localhost:35157/jars/com.esotericsoftware_reflectasm-1.11.3.jar to /tmp/spark-e4d01697-77d8-438c-adea-d54815b81a46/userFiles-c9134761-6fd5-472e-b3ca-97c676433268/fetchFileTemp8884287553039299979.tmp
21/02/17 01:42:03 INFO Executor: Adding file:/tmp/spark-e4d01697-77d8-438c-adea-d54815b81a46/userFiles-c9134761-6fd5-472e-b3ca-97c676433268/com.esotericsoftware_reflectasm-1.11.3.jar to class loader
21/02/17 01:42:03 INFO Executor: Fetching spark://localhost:35157/jars/com.esotericsoftware_kryo-4.0.2.jar with timestamp 1613526115310
21/02/17 01:42:03 INFO Utils: Fetching spark://localhost:35157/jars/com.esotericsoftware_kryo-4.0.2.jar to /tmp/spark-e4d01697-77d8-438c-adea-d54815b81a46/userFiles-c9134761-6fd5-472e-b3ca-97c676433268/fetchFileTemp4924580175604623088.tmp
21/02/17 01:42:03 INFO Executor: Adding file:/tmp/spark-e4d01697-77d8-438c-adea-d54815b81a46/userFiles-c9134761-6fd5-472e-b3ca-97c676433268/com.esotericsoftware_kryo-4.0.2.jar to class loader
21/02/17 01:42:03 INFO Executor: Fetching spark://localhost:35157/jars/ml.dmlc_xgboost4j-spark_2.12-1.3.1.jar with timestamp 1613526115309
21/02/17 01:42:03 INFO Utils: Fetching spark://localhost:35157/jars/ml.dmlc_xgboost4j-spark_2.12-1.3.1.jar to /tmp/spark-e4d01697-77d8-438c-adea-d54815b81a46/userFiles-c9134761-6fd5-472e-b3ca-97c676433268/fetchFileTemp8277048119120141362.tmp
21/02/17 01:42:03 INFO Executor: Adding file:/tmp/spark-e4d01697-77d8-438c-adea-d54815b81a46/userFiles-c9134761-6fd5-472e-b3ca-97c676433268/ml.dmlc_xgboost4j-spark_2.12-1.3.1.jar to class loader
21/02/17 01:42:03 INFO Executor: Fetching spark://localhost:35157/jars/org.scala-lang_scala-reflect-2.12.8.jar with timestamp 1613526115311
21/02/17 01:42:03 INFO Utils: Fetching spark://localhost:35157/jars/org.scala-lang_scala-reflect-2.12.8.jar to /tmp/spark-e4d01697-77d8-438c-adea-d54815b81a46/userFiles-c9134761-6fd5-472e-b3ca-97c676433268/fetchFileTemp8477038368606231922.tmp
21/02/17 01:42:03 INFO Executor: Adding file:/tmp/spark-e4d01697-77d8-438c-adea-d54815b81a46/userFiles-c9134761-6fd5-472e-b3ca-97c676433268/org.scala-lang_scala-reflect-2.12.8.jar to class loader
21/02/17 01:42:03 INFO Executor: Fetching spark://localhost:35157/jars/sparklyr-3.0-2.12.jar with timestamp 1613526115313
21/02/17 01:42:03 INFO Utils: Fetching spark://localhost:35157/jars/sparklyr-3.0-2.12.jar to /tmp/spark-e4d01697-77d8-438c-adea-d54815b81a46/userFiles-c9134761-6fd5-472e-b3ca-97c676433268/fetchFileTemp8392181366301785582.tmp
21/02/17 01:42:03 INFO Executor: Adding file:/tmp/spark-e4d01697-77d8-438c-adea-d54815b81a46/userFiles-c9134761-6fd5-472e-b3ca-97c676433268/sparklyr-3.0-2.12.jar to class loader
21/02/17 01:42:03 INFO Executor: Fetching spark://localhost:35157/jars/org.json4s_json4s-jackson_2.12-3.6.10.jar with timestamp 1613526115310
21/02/17 01:42:03 INFO Utils: Fetching spark://localhost:35157/jars/org.json4s_json4s-jackson_2.12-3.6.10.jar to /tmp/spark-e4d01697-77d8-438c-adea-d54815b81a46/userFiles-c9134761-6fd5-472e-b3ca-97c676433268/fetchFileTemp1793616039146140585.tmp
21/02/17 01:42:03 INFO Executor: Adding file:/tmp/spark-e4d01697-77d8-438c-adea-d54815b81a46/userFiles-c9134761-6fd5-472e-b3ca-97c676433268/org.json4s_json4s-jackson_2.12-3.6.10.jar to class loader
21/02/17 01:42:03 INFO Executor: Fetching spark://localhost:35157/jars/org.objenesis_objenesis-2.5.1.jar with timestamp 1613526115312
21/02/17 01:42:03 INFO Utils: Fetching spark://localhost:35157/jars/org.objenesis_objenesis-2.5.1.jar to /tmp/spark-e4d01697-77d8-438c-adea-d54815b81a46/userFiles-c9134761-6fd5-472e-b3ca-97c676433268/fetchFileTemp6637680461218409190.tmp
21/02/17 01:42:03 INFO Executor: Adding file:/tmp/spark-e4d01697-77d8-438c-adea-d54815b81a46/userFiles-c9134761-6fd5-472e-b3ca-97c676433268/org.objenesis_objenesis-2.5.1.jar to class loader
21/02/17 01:42:03 INFO Executor: Fetching spark://localhost:35157/jars/org.json4s_json4s-scalap_2.12-3.6.10.jar with timestamp 1613526115313
21/02/17 01:42:03 INFO Utils: Fetching spark://localhost:35157/jars/org.json4s_json4s-scalap_2.12-3.6.10.jar to /tmp/spark-e4d01697-77d8-438c-adea-d54815b81a46/userFiles-c9134761-6fd5-472e-b3ca-97c676433268/fetchFileTemp8643676677804961444.tmp
21/02/17 01:42:03 INFO Executor: Adding file:/tmp/spark-e4d01697-77d8-438c-adea-d54815b81a46/userFiles-c9134761-6fd5-472e-b3ca-97c676433268/org.json4s_json4s-scalap_2.12-3.6.10.jar to class loader
21/02/17 01:42:03 INFO Executor: Fetching spark://localhost:35157/jars/com.fasterxml.jackson.core_jackson-annotations-2.9.10.jar with timestamp 1613526115313
21/02/17 01:42:03 INFO Utils: Fetching spark://localhost:35157/jars/com.fasterxml.jackson.core_jackson-annotations-2.9.10.jar to /tmp/spark-e4d01697-77d8-438c-adea-d54815b81a46/userFiles-c9134761-6fd5-472e-b3ca-97c676433268/fetchFileTemp3771693469303977726.tmp
21/02/17 01:42:03 INFO Executor: Adding file:/tmp/spark-e4d01697-77d8-438c-adea-d54815b81a46/userFiles-c9134761-6fd5-472e-b3ca-97c676433268/com.fasterxml.jackson.core_jackson-annotations-2.9.10.jar to class loader
21/02/17 01:42:03 INFO Executor: Fetching spark://localhost:35157/jars/com.typesafe_config-1.3.3.jar with timestamp 1613526115311
21/02/17 01:42:03 INFO Utils: Fetching spark://localhost:35157/jars/com.typesafe_config-1.3.3.jar to /tmp/spark-e4d01697-77d8-438c-adea-d54815b81a46/userFiles-c9134761-6fd5-472e-b3ca-97c676433268/fetchFileTemp3010477429755469184.tmp
21/02/17 01:42:03 INFO Executor: Adding file:/tmp/spark-e4d01697-77d8-438c-adea-d54815b81a46/userFiles-c9134761-6fd5-472e-b3ca-97c676433268/com.typesafe_config-1.3.3.jar to class loader
21/02/17 01:42:03 INFO Executor: Fetching spark://localhost:35157/jars/org.scala-lang.modules_scala-java8-compat_2.12-0.8.0.jar with timestamp 1613526115311
21/02/17 01:42:03 INFO Utils: Fetching spark://localhost:35157/jars/org.scala-lang.modules_scala-java8-compat_2.12-0.8.0.jar to /tmp/spark-e4d01697-77d8-438c-adea-d54815b81a46/userFiles-c9134761-6fd5-472e-b3ca-97c676433268/fetchFileTemp7106812788819858363.tmp
21/02/17 01:42:03 INFO Executor: Adding file:/tmp/spark-e4d01697-77d8-438c-adea-d54815b81a46/userFiles-c9134761-6fd5-472e-b3ca-97c676433268/org.scala-lang.modules_scala-java8-compat_2.12-0.8.0.jar to class loader
21/02/17 01:42:03 INFO Executor: Fetching spark://localhost:35157/jars/com.fasterxml.jackson.core_jackson-databind-2.9.10.6.jar with timestamp 1613526115312
21/02/17 01:42:03 INFO Utils: Fetching spark://localhost:35157/jars/com.fasterxml.jackson.core_jackson-databind-2.9.10.6.jar to /tmp/spark-e4d01697-77d8-438c-adea-d54815b81a46/userFiles-c9134761-6fd5-472e-b3ca-97c676433268/fetchFileTemp8931165741148230250.tmp
21/02/17 01:42:03 INFO Executor: Adding file:/tmp/spark-e4d01697-77d8-438c-adea-d54815b81a46/userFiles-c9134761-6fd5-472e-b3ca-97c676433268/com.fasterxml.jackson.core_jackson-databind-2.9.10.6.jar to class loader
21/02/17 01:42:03 INFO Executor: Fetching spark://localhost:35157/jars/org.ow2.asm_asm-5.0.4.jar with timestamp 1613526115312
21/02/17 01:42:03 INFO Utils: Fetching spark://localhost:35157/jars/org.ow2.asm_asm-5.0.4.jar to /tmp/spark-e4d01697-77d8-438c-adea-d54815b81a46/userFiles-c9134761-6fd5-472e-b3ca-97c676433268/fetchFileTemp6003012492875226365.tmp
21/02/17 01:42:03 INFO Executor: Adding file:/tmp/spark-e4d01697-77d8-438c-adea-d54815b81a46/userFiles-c9134761-6fd5-472e-b3ca-97c676433268/org.ow2.asm_asm-5.0.4.jar to class loader
21/02/17 01:42:03 INFO Executor: Fetching spark://localhost:35157/jars/org.scalactic_scalactic_2.12-3.0.5.jar with timestamp 1613526115311
21/02/17 01:42:03 INFO Utils: Fetching spark://localhost:35157/jars/org.scalactic_scalactic_2.12-3.0.5.jar to /tmp/spark-e4d01697-77d8-438c-adea-d54815b81a46/userFiles-c9134761-6fd5-472e-b3ca-97c676433268/fetchFileTemp8331062387207581625.tmp
21/02/17 01:42:03 INFO Executor: Adding file:/tmp/spark-e4d01697-77d8-438c-adea-d54815b81a46/userFiles-c9134761-6fd5-472e-b3ca-97c676433268/org.scalactic_scalactic_2.12-3.0.5.jar to class loader
21/02/17 01:42:03 INFO Executor: Fetching spark://localhost:35157/jars/com.thoughtworks.paranamer_paranamer-2.8.jar with timestamp 1613526115313
21/02/17 01:42:03 INFO Utils: Fetching spark://localhost:35157/jars/com.thoughtworks.paranamer_paranamer-2.8.jar to /tmp/spark-e4d01697-77d8-438c-adea-d54815b81a46/userFiles-c9134761-6fd5-472e-b3ca-97c676433268/fetchFileTemp1862920733083839353.tmp
21/02/17 01:42:03 INFO Executor: Adding file:/tmp/spark-e4d01697-77d8-438c-adea-d54815b81a46/userFiles-c9134761-6fd5-472e-b3ca-97c676433268/com.thoughtworks.paranamer_paranamer-2.8.jar to class loader
21/02/17 01:42:03 INFO Executor: Fetching spark://localhost:35157/jars/org.json4s_json4s-ast_2.12-3.6.10.jar with timestamp 1613526115312
21/02/17 01:42:03 INFO Utils: Fetching spark://localhost:35157/jars/org.json4s_json4s-ast_2.12-3.6.10.jar to /tmp/spark-e4d01697-77d8-438c-adea-d54815b81a46/userFiles-c9134761-6fd5-472e-b3ca-97c676433268/fetchFileTemp6576765357020086179.tmp
21/02/17 01:42:03 INFO Executor: Adding file:/tmp/spark-e4d01697-77d8-438c-adea-d54815b81a46/userFiles-c9134761-6fd5-472e-b3ca-97c676433268/org.json4s_json4s-ast_2.12-3.6.10.jar to class loader
21/02/17 01:42:03 INFO Executor: Fetching spark://localhost:35157/jars/com.typesafe.akka_akka-actor_2.12-2.5.23.jar with timestamp 1613526115311
21/02/17 01:42:03 INFO Utils: Fetching spark://localhost:35157/jars/com.typesafe.akka_akka-actor_2.12-2.5.23.jar to /tmp/spark-e4d01697-77d8-438c-adea-d54815b81a46/userFiles-c9134761-6fd5-472e-b3ca-97c676433268/fetchFileTemp3840802443233863327.tmp
21/02/17 01:42:03 INFO Executor: Adding file:/tmp/spark-e4d01697-77d8-438c-adea-d54815b81a46/userFiles-c9134761-6fd5-472e-b3ca-97c676433268/com.typesafe.akka_akka-actor_2.12-2.5.23.jar to class loader
21/02/17 01:42:03 INFO Executor: Fetching spark://localhost:35157/jars/com.fasterxml.jackson.core_jackson-core-2.9.10.jar with timestamp 1613526115313
21/02/17 01:42:03 INFO Utils: Fetching spark://localhost:35157/jars/com.fasterxml.jackson.core_jackson-core-2.9.10.jar to /tmp/spark-e4d01697-77d8-438c-adea-d54815b81a46/userFiles-c9134761-6fd5-472e-b3ca-97c676433268/fetchFileTemp5549604831274963338.tmp
21/02/17 01:42:03 INFO Executor: Adding file:/tmp/spark-e4d01697-77d8-438c-adea-d54815b81a46/userFiles-c9134761-6fd5-472e-b3ca-97c676433268/com.fasterxml.jackson.core_jackson-core-2.9.10.jar to class loader
21/02/17 01:42:03 INFO Executor: Fetching spark://localhost:35157/jars/commons-logging_commons-logging-1.2.jar with timestamp 1613526115311
21/02/17 01:42:03 INFO Utils: Fetching spark://localhost:35157/jars/commons-logging_commons-logging-1.2.jar to /tmp/spark-e4d01697-77d8-438c-adea-d54815b81a46/userFiles-c9134761-6fd5-472e-b3ca-97c676433268/fetchFileTemp6184884404844861522.tmp
21/02/17 01:42:03 INFO Executor: Adding file:/tmp/spark-e4d01697-77d8-438c-adea-d54815b81a46/userFiles-c9134761-6fd5-472e-b3ca-97c676433268/commons-logging_commons-logging-1.2.jar to class loader
21/02/17 01:42:03 INFO Executor: Fetching spark://localhost:35157/jars/org.scalatest_scalatest_2.12-3.0.5.jar with timestamp 1613526115311
21/02/17 01:42:03 INFO Utils: Fetching spark://localhost:35157/jars/org.scalatest_scalatest_2.12-3.0.5.jar to /tmp/spark-e4d01697-77d8-438c-adea-d54815b81a46/userFiles-c9134761-6fd5-472e-b3ca-97c676433268/fetchFileTemp364774596583821348.tmp
21/02/17 01:42:03 INFO Executor: Adding file:/tmp/spark-e4d01697-77d8-438c-adea-d54815b81a46/userFiles-c9134761-6fd5-472e-b3ca-97c676433268/org.scalatest_scalatest_2.12-3.0.5.jar to class loader
21/02/17 01:42:03 INFO Executor: Fetching spark://localhost:35157/jars/ml.dmlc_xgboost4j_2.12-1.3.1.jar with timestamp 1613526115310
21/02/17 01:42:03 INFO Utils: Fetching spark://localhost:35157/jars/ml.dmlc_xgboost4j_2.12-1.3.1.jar to /tmp/spark-e4d01697-77d8-438c-adea-d54815b81a46/userFiles-c9134761-6fd5-472e-b3ca-97c676433268/fetchFileTemp7388599030954121090.tmp
21/02/17 01:42:03 INFO Executor: Adding file:/tmp/spark-e4d01697-77d8-438c-adea-d54815b81a46/userFiles-c9134761-6fd5-472e-b3ca-97c676433268/ml.dmlc_xgboost4j_2.12-1.3.1.jar to class loader
21/02/17 01:42:03 INFO Executor: Fetching spark://localhost:35157/jars/org.json4s_json4s-core_2.12-3.6.10.jar with timestamp 1613526115312
21/02/17 01:42:03 INFO Utils: Fetching spark://localhost:35157/jars/org.json4s_json4s-core_2.12-3.6.10.jar to /tmp/spark-e4d01697-77d8-438c-adea-d54815b81a46/userFiles-c9134761-6fd5-472e-b3ca-97c676433268/fetchFileTemp1364651159719425103.tmp
21/02/17 01:42:03 INFO Executor: Adding file:/tmp/spark-e4d01697-77d8-438c-adea-d54815b81a46/userFiles-c9134761-6fd5-472e-b3ca-97c676433268/org.json4s_json4s-core_2.12-3.6.10.jar to class loader
21/02/17 01:42:03 INFO Executor: Fetching spark://localhost:35157/jars/org.scala-lang_scala-compiler-2.12.8.jar with timestamp 1613526115310
21/02/17 01:42:03 INFO Utils: Fetching spark://localhost:35157/jars/org.scala-lang_scala-compiler-2.12.8.jar to /tmp/spark-e4d01697-77d8-438c-adea-d54815b81a46/userFiles-c9134761-6fd5-472e-b3ca-97c676433268/fetchFileTemp3877870649367063887.tmp
21/02/17 01:42:03 INFO Executor: Adding file:/tmp/spark-e4d01697-77d8-438c-adea-d54815b81a46/userFiles-c9134761-6fd5-472e-b3ca-97c676433268/org.scala-lang_scala-compiler-2.12.8.jar to class loader
21/02/17 01:42:03 INFO Executor: Finished task 0.0 in stage 0.0 (TID 0). 1397 bytes result sent to driver
21/02/17 01:42:03 INFO TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in 429 ms on localhost (executor driver) (1/1)
21/02/17 01:42:03 INFO TaskSchedulerImpl: Removed TaskSet 0.0, whose tasks have all completed, from pool 
21/02/17 01:42:03 INFO DAGScheduler: ResultStage 0 (collect at utils.scala:137) finished in 0.549 s
21/02/17 01:42:03 INFO DAGScheduler: Job 1 is finished. Cancelling potential speculative or zombie tasks for this job
21/02/17 01:42:03 INFO TaskSchedulerImpl: Killing all running tasks in stage 0: Stage finished
21/02/17 01:42:03 INFO DAGScheduler: Job 1 finished: collect at utils.scala:137, took 0.579459 s
21/02/17 01:42:03 INFO CodeGenerator: Code generated in 12.832434 ms
21/02/17 01:42:03 INFO CodeGenerator: Code generated in 11.985275 ms
21/02/17 01:42:03 INFO CodeGenerator: Code generated in 14.372774 ms
21/02/17 01:42:03 INFO SparkContext: Starting job: count at utils.scala:135
21/02/17 01:42:03 INFO DAGScheduler: Registering RDD 11 (count at utils.scala:135) as input to shuffle 0
21/02/17 01:42:03 INFO DAGScheduler: Got job 2 (count at utils.scala:135) with 1 output partitions
21/02/17 01:42:03 INFO DAGScheduler: Final stage: ResultStage 2 (count at utils.scala:135)
21/02/17 01:42:03 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 1)
21/02/17 01:42:03 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 1)
21/02/17 01:42:03 INFO DAGScheduler: Submitting ShuffleMapStage 1 (MapPartitionsRDD[11] at count at utils.scala:135), which has no missing parents
21/02/17 01:42:03 INFO MemoryStore: Block broadcast_1 stored as values in memory (estimated size 10.0 KiB, free 912.3 MiB)
21/02/17 01:42:03 INFO MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 5.2 KiB, free 912.3 MiB)
21/02/17 01:42:03 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on localhost:42591 (size: 5.2 KiB, free: 912.3 MiB)
21/02/17 01:42:03 INFO SparkContext: Created broadcast 1 from broadcast at DAGScheduler.scala:1200
21/02/17 01:42:03 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 1 (MapPartitionsRDD[11] at count at utils.scala:135) (first 15 tasks are for partitions Vector(0))
21/02/17 01:42:03 INFO TaskSchedulerImpl: Adding task set 1.0 with 1 tasks
21/02/17 01:42:03 INFO TaskSetManager: Starting task 0.0 in stage 1.0 (TID 1, localhost, executor driver, partition 0, PROCESS_LOCAL, 7550 bytes)
21/02/17 01:42:03 INFO Executor: Running task 0.0 in stage 1.0 (TID 1)
21/02/17 01:42:03 INFO BlockManagerInfo: Removed broadcast_0_piece0 on localhost:42591 in memory (size: 3.2 KiB, free: 912.3 MiB)
21/02/17 01:42:03 INFO Executor: Finished task 0.0 in stage 1.0 (TID 1). 1876 bytes result sent to driver
21/02/17 01:42:03 INFO TaskSetManager: Finished task 0.0 in stage 1.0 (TID 1) in 47 ms on localhost (executor driver) (1/1)
21/02/17 01:42:03 INFO TaskSchedulerImpl: Removed TaskSet 1.0, whose tasks have all completed, from pool 
21/02/17 01:42:03 INFO DAGScheduler: ShuffleMapStage 1 (count at utils.scala:135) finished in 0.078 s
21/02/17 01:42:03 INFO DAGScheduler: looking for newly runnable stages
21/02/17 01:42:03 INFO DAGScheduler: running: Set()
21/02/17 01:42:03 INFO DAGScheduler: waiting: Set(ResultStage 2)
21/02/17 01:42:03 INFO DAGScheduler: failed: Set()
21/02/17 01:42:03 INFO DAGScheduler: Submitting ResultStage 2 (MapPartitionsRDD[14] at count at utils.scala:135), which has no missing parents
21/02/17 01:42:03 INFO MemoryStore: Block broadcast_2 stored as values in memory (estimated size 10.1 KiB, free 912.3 MiB)
21/02/17 01:42:03 INFO MemoryStore: Block broadcast_2_piece0 stored as bytes in memory (estimated size 5.0 KiB, free 912.3 MiB)
21/02/17 01:42:03 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on localhost:42591 (size: 5.0 KiB, free: 912.3 MiB)
21/02/17 01:42:03 INFO SparkContext: Created broadcast 2 from broadcast at DAGScheduler.scala:1200
21/02/17 01:42:03 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 2 (MapPartitionsRDD[14] at count at utils.scala:135) (first 15 tasks are for partitions Vector(0))
21/02/17 01:42:03 INFO TaskSchedulerImpl: Adding task set 2.0 with 1 tasks
21/02/17 01:42:03 INFO TaskSetManager: Starting task 0.0 in stage 2.0 (TID 2, localhost, executor driver, partition 0, NODE_LOCAL, 7325 bytes)
21/02/17 01:42:03 INFO Executor: Running task 0.0 in stage 2.0 (TID 2)
21/02/17 01:42:03 INFO ShuffleBlockFetcherIterator: Getting 1 (60.0 B) non-empty blocks including 1 (60.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
21/02/17 01:42:03 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 6 ms
21/02/17 01:42:03 INFO Executor: Finished task 0.0 in stage 2.0 (TID 2). 2648 bytes result sent to driver
21/02/17 01:42:03 INFO TaskSetManager: Finished task 0.0 in stage 2.0 (TID 2) in 41 ms on localhost (executor driver) (1/1)
21/02/17 01:42:03 INFO TaskSchedulerImpl: Removed TaskSet 2.0, whose tasks have all completed, from pool 
21/02/17 01:42:03 INFO DAGScheduler: ResultStage 2 (count at utils.scala:135) finished in 0.050 s
21/02/17 01:42:03 INFO DAGScheduler: Job 2 is finished. Cancelling potential speculative or zombie tasks for this job
21/02/17 01:42:03 INFO TaskSchedulerImpl: Killing all running tasks in stage 2: Stage finished
21/02/17 01:42:03 INFO DAGScheduler: Job 2 finished: count at utils.scala:135, took 0.148294 s
21/02/17 01:42:04 INFO SparkContext: Starting job: collect at utils.scala:137
21/02/17 01:42:04 INFO DAGScheduler: Got job 3 (collect at utils.scala:137) with 1 output partitions
21/02/17 01:42:04 INFO DAGScheduler: Final stage: ResultStage 3 (collect at utils.scala:137)
21/02/17 01:42:04 INFO DAGScheduler: Parents of final stage: List()
21/02/17 01:42:04 INFO DAGScheduler: Missing parents: List()
21/02/17 01:42:04 INFO DAGScheduler: Submitting ResultStage 3 (MapPartitionsRDD[16] at collect at utils.scala:137), which has no missing parents
21/02/17 01:42:04 INFO MemoryStore: Block broadcast_3 stored as values in memory (estimated size 7.2 KiB, free 912.3 MiB)
21/02/17 01:42:04 INFO MemoryStore: Block broadcast_3_piece0 stored as bytes in memory (estimated size 3.7 KiB, free 912.3 MiB)
21/02/17 01:42:04 INFO BlockManagerInfo: Added broadcast_3_piece0 in memory on localhost:42591 (size: 3.7 KiB, free: 912.3 MiB)
21/02/17 01:42:04 INFO SparkContext: Created broadcast 3 from broadcast at DAGScheduler.scala:1200
21/02/17 01:42:04 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 3 (MapPartitionsRDD[16] at collect at utils.scala:137) (first 15 tasks are for partitions Vector(0))
21/02/17 01:42:04 INFO TaskSchedulerImpl: Adding task set 3.0 with 1 tasks
21/02/17 01:42:04 INFO TaskSetManager: Starting task 0.0 in stage 3.0 (TID 3, localhost, executor driver, partition 0, PROCESS_LOCAL, 7561 bytes)
21/02/17 01:42:04 INFO Executor: Running task 0.0 in stage 3.0 (TID 3)
21/02/17 01:42:04 INFO Executor: Finished task 0.0 in stage 3.0 (TID 3). 1354 bytes result sent to driver
21/02/17 01:42:04 INFO TaskSetManager: Finished task 0.0 in stage 3.0 (TID 3) in 5 ms on localhost (executor driver) (1/1)
21/02/17 01:42:04 INFO TaskSchedulerImpl: Removed TaskSet 3.0, whose tasks have all completed, from pool 
21/02/17 01:42:04 INFO DAGScheduler: ResultStage 3 (collect at utils.scala:137) finished in 0.011 s
21/02/17 01:42:04 INFO DAGScheduler: Job 3 is finished. Cancelling potential speculative or zombie tasks for this job
21/02/17 01:42:04 INFO TaskSchedulerImpl: Killing all running tasks in stage 3: Stage finished
21/02/17 01:42:04 INFO DAGScheduler: Job 3 finished: collect at utils.scala:137, took 0.014785 s
21/02/17 01:42:04 INFO SparkContext: Starting job: count at utils.scala:135
21/02/17 01:42:04 INFO DAGScheduler: Registering RDD 18 (count at utils.scala:135) as input to shuffle 1
21/02/17 01:42:04 INFO DAGScheduler: Got job 4 (count at utils.scala:135) with 1 output partitions
21/02/17 01:42:04 INFO DAGScheduler: Final stage: ResultStage 5 (count at utils.scala:135)
21/02/17 01:42:04 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 4)
21/02/17 01:42:04 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 4)
21/02/17 01:42:04 INFO DAGScheduler: Submitting ShuffleMapStage 4 (MapPartitionsRDD[18] at count at utils.scala:135), which has no missing parents
21/02/17 01:42:04 INFO MemoryStore: Block broadcast_4 stored as values in memory (estimated size 10.0 KiB, free 912.3 MiB)
21/02/17 01:42:04 INFO MemoryStore: Block broadcast_4_piece0 stored as bytes in memory (estimated size 5.2 KiB, free 912.2 MiB)
21/02/17 01:42:04 INFO BlockManagerInfo: Added broadcast_4_piece0 in memory on localhost:42591 (size: 5.2 KiB, free: 912.3 MiB)
21/02/17 01:42:04 INFO SparkContext: Created broadcast 4 from broadcast at DAGScheduler.scala:1200
21/02/17 01:42:04 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 4 (MapPartitionsRDD[18] at count at utils.scala:135) (first 15 tasks are for partitions Vector(0))
21/02/17 01:42:04 INFO TaskSchedulerImpl: Adding task set 4.0 with 1 tasks
21/02/17 01:42:04 INFO TaskSetManager: Starting task 0.0 in stage 4.0 (TID 4, localhost, executor driver, partition 0, PROCESS_LOCAL, 7550 bytes)
21/02/17 01:42:04 INFO Executor: Running task 0.0 in stage 4.0 (TID 4)
21/02/17 01:42:04 INFO Executor: Finished task 0.0 in stage 4.0 (TID 4). 1833 bytes result sent to driver
21/02/17 01:42:04 INFO TaskSetManager: Finished task 0.0 in stage 4.0 (TID 4) in 10 ms on localhost (executor driver) (1/1)
21/02/17 01:42:04 INFO TaskSchedulerImpl: Removed TaskSet 4.0, whose tasks have all completed, from pool 
21/02/17 01:42:04 INFO DAGScheduler: ShuffleMapStage 4 (count at utils.scala:135) finished in 0.016 s
21/02/17 01:42:04 INFO DAGScheduler: looking for newly runnable stages
21/02/17 01:42:04 INFO DAGScheduler: running: Set()
21/02/17 01:42:04 INFO DAGScheduler: waiting: Set(ResultStage 5)
21/02/17 01:42:04 INFO DAGScheduler: failed: Set()
21/02/17 01:42:04 INFO DAGScheduler: Submitting ResultStage 5 (MapPartitionsRDD[21] at count at utils.scala:135), which has no missing parents
21/02/17 01:42:04 INFO MemoryStore: Block broadcast_5 stored as values in memory (estimated size 10.1 KiB, free 912.2 MiB)
21/02/17 01:42:04 INFO MemoryStore: Block broadcast_5_piece0 stored as bytes in memory (estimated size 5.0 KiB, free 912.2 MiB)
21/02/17 01:42:04 INFO BlockManagerInfo: Added broadcast_5_piece0 in memory on localhost:42591 (size: 5.0 KiB, free: 912.3 MiB)
21/02/17 01:42:04 INFO SparkContext: Created broadcast 5 from broadcast at DAGScheduler.scala:1200
21/02/17 01:42:04 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 5 (MapPartitionsRDD[21] at count at utils.scala:135) (first 15 tasks are for partitions Vector(0))
21/02/17 01:42:04 INFO TaskSchedulerImpl: Adding task set 5.0 with 1 tasks
21/02/17 01:42:04 INFO TaskSetManager: Starting task 0.0 in stage 5.0 (TID 5, localhost, executor driver, partition 0, NODE_LOCAL, 7325 bytes)
21/02/17 01:42:04 INFO Executor: Running task 0.0 in stage 5.0 (TID 5)
21/02/17 01:42:04 INFO ShuffleBlockFetcherIterator: Getting 1 (60.0 B) non-empty blocks including 1 (60.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
21/02/17 01:42:04 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
21/02/17 01:42:04 INFO Executor: Finished task 0.0 in stage 5.0 (TID 5). 2648 bytes result sent to driver
21/02/17 01:42:04 INFO TaskSetManager: Finished task 0.0 in stage 5.0 (TID 5) in 8 ms on localhost (executor driver) (1/1)
21/02/17 01:42:04 INFO TaskSchedulerImpl: Removed TaskSet 5.0, whose tasks have all completed, from pool 
21/02/17 01:42:04 INFO DAGScheduler: ResultStage 5 (count at utils.scala:135) finished in 0.014 s
21/02/17 01:42:04 INFO DAGScheduler: Job 4 is finished. Cancelling potential speculative or zombie tasks for this job
21/02/17 01:42:04 INFO TaskSchedulerImpl: Killing all running tasks in stage 5: Stage finished
21/02/17 01:42:04 INFO DAGScheduler: Job 4 finished: count at utils.scala:135, took 0.037028 s
21/02/17 01:42:04 INFO Instrumentation: [73185862] training finished
21/02/17 01:42:04 INFO Instrumentation: [4270ab85] training finished
21/02/17 01:42:05 INFO CodeGenerator: Code generated in 32.747011 ms
21/02/17 01:42:05 INFO CodeGenerator: Code generated in 11.236251 ms
21/02/17 01:42:05 INFO XGBoostSpark: Running XGBoost 1.3.1 with parameters:
alpha -> 0.0
min_child_weight -> 1.0
sample_type -> uniform
base_score -> 0.5
rabit_timeout -> -1
colsample_bylevel -> 1.0
grow_policy -> depthwise
skip_drop -> 0.0
lambda_bias -> 0.0
silent -> 0
scale_pos_weight -> 1.0
seed -> 0
cache_training_set -> false
features_col -> features
num_early_stopping_rounds -> 0
label_col -> label
num_workers -> 1
subsample -> 1.0
lambda -> 1.0
max_depth -> 6
kill_spark_context_on_worker_failure -> true
tree_limit -> 0
custom_eval -> null
dmlc_worker_connect_retry -> 5
rate_drop -> 0.0
max_bin -> 16
train_test_ratio -> 1.0
use_external_memory -> false
objective -> reg:linear
eval_metric -> rmse
num_round -> 1
maximize_evaluation_metrics -> false
timeout_request_workers -> 1800000
missing -> NaN
rabit_ring_reduce_threshold -> 32768
checkpoint_path -> 
tracker_conf -> TrackerConf(0,python)
tree_method -> auto
max_delta_step -> 0.0
eta -> 0.3
verbosity -> 1
colsample_bytree -> 1.0
objective_type -> regression
normalize_type -> tree
allow_non_zero_for_missing -> false
custom_obj -> null
gamma -> 0.0
sketch_eps -> 0.03
nthread -> 1
prediction_col -> prediction
checkpoint_interval -> -1
21/02/17 01:42:05 WARN XGBoostSpark: train_test_ratio is deprecated since XGBoost 0.82, we recommend to explicitly pass a training and multiple evaluation datasets by passing 'eval_sets' and 'eval_set_names'
21/02/17 01:42:05 INFO RabitTracker$TrackerProcessLogger: 2021-02-17 01:42:05,240 INFO start listen on 192.168.2.12:9091
21/02/17 01:42:05 INFO XGBoostSpark: starting training with timeout set as 1800000 ms for waiting for resources
21/02/17 01:42:05 INFO SparkContext: Starting job: foreachPartition at XGBoost.scala:612
21/02/17 01:42:05 INFO DAGScheduler: Got job 5 (foreachPartition at XGBoost.scala:612) with 1 output partitions
21/02/17 01:42:05 INFO DAGScheduler: Final stage: ResultStage 6 (foreachPartition at XGBoost.scala:612)
21/02/17 01:42:05 INFO DAGScheduler: Parents of final stage: List()
21/02/17 01:42:05 INFO DAGScheduler: Missing parents: List()
21/02/17 01:42:05 INFO DAGScheduler: Submitting ResultStage 6 (MapPartitionsRDD[32] at mapPartitions at XGBoost.scala:493), which has no missing parents
21/02/17 01:42:05 INFO MemoryStore: Block broadcast_6 stored as values in memory (estimated size 41.0 KiB, free 912.2 MiB)
21/02/17 01:42:05 INFO MemoryStore: Block broadcast_6_piece0 stored as bytes in memory (estimated size 16.8 KiB, free 912.2 MiB)
21/02/17 01:42:05 INFO BlockManagerInfo: Added broadcast_6_piece0 in memory on localhost:42591 (size: 16.8 KiB, free: 912.3 MiB)
21/02/17 01:42:05 INFO SparkContext: Created broadcast 6 from broadcast at DAGScheduler.scala:1200
21/02/17 01:42:05 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 6 (MapPartitionsRDD[32] at mapPartitions at XGBoost.scala:493) (first 15 tasks are for partitions Vector(0))
21/02/17 01:42:05 INFO TaskSchedulerImpl: Adding task set 6.0 with 1 tasks
21/02/17 01:42:05 INFO TaskSetManager: Starting task 0.0 in stage 6.0 (TID 6, localhost, executor driver, partition 0, PROCESS_LOCAL, 18492 bytes)
21/02/17 01:42:05 INFO Executor: Running task 0.0 in stage 6.0 (TID 6)
21/02/17 01:42:05 INFO MemoryStore: Block rdd_23_0 stored as values in memory (estimated size 5.6 KiB, free 912.2 MiB)
21/02/17 01:42:05 INFO BlockManagerInfo: Added rdd_23_0 in memory on localhost:42591 (size: 5.6 KiB, free: 912.3 MiB)
21/02/17 01:42:05 INFO BlockManagerInfo: Removed broadcast_4_piece0 on localhost:42591 in memory (size: 5.2 KiB, free: 912.3 MiB)
21/02/17 01:42:05 INFO CodeGenerator: Code generated in 27.088712 ms
21/02/17 01:42:05 INFO BlockManagerInfo: Removed broadcast_3_piece0 on localhost:42591 in memory (size: 3.7 KiB, free: 912.3 MiB)
21/02/17 01:42:05 INFO BlockManagerInfo: Removed broadcast_2_piece0 on localhost:42591 in memory (size: 5.0 KiB, free: 912.3 MiB)
21/02/17 01:42:05 INFO BlockManagerInfo: Removed broadcast_1_piece0 on localhost:42591 in memory (size: 5.2 KiB, free: 912.3 MiB)
21/02/17 01:42:05 INFO BlockManagerInfo: Removed broadcast_5_piece0 on localhost:42591 in memory (size: 5.0 KiB, free: 912.3 MiB)
21/02/17 01:42:05 INFO CodeGenerator: Code generated in 32.687102 ms
21/02/17 01:42:05 INFO CodeGenerator: Code generated in 12.526056 ms
21/02/17 01:42:05 INFO RabitTracker$TrackerProcessLogger: /tmp/tracker5419301908830741084.py:330: DeprecationWarning: isAlive() is deprecated, use is_alive() instead
21/02/17 01:42:05 INFO RabitTracker$TrackerProcessLogger:   while self.thread.isAlive():
21/02/17 01:42:05 INFO RabitTracker$TrackerProcessLogger: 2021-02-17 01:42:05,647 DEBUG Recieve start signal from 192.168.2.12; assign rank 0
21/02/17 01:42:05 INFO RabitTracker$TrackerProcessLogger: 2021-02-17 01:42:05,647 INFO @tracker All of 1 nodes getting started
21/02/17 01:42:05 INFO RabitTracker$TrackerProcessLogger: 2021-02-17 01:42:05,655 INFO [0]	train-rmse:2.633044
21/02/17 01:42:05 INFO RabitTracker$TrackerProcessLogger: 2021-02-17 01:42:05,655 DEBUG Recieve shutdown signal from 0
21/02/17 01:42:05 INFO RabitTracker$TrackerProcessLogger: 2021-02-17 01:42:05,655 INFO @tracker All nodes finishes job
21/02/17 01:42:05 INFO RabitTracker$TrackerProcessLogger: 2021-02-17 01:42:05,655 INFO @tracker 0.00818490982055664 secs between node start and job finish
21/02/17 01:42:05 INFO MemoryStore: Block rdd_32_0 stored as values in memory (estimated size 192.0 B, free 912.2 MiB)
21/02/17 01:42:05 INFO BlockManagerInfo: Added rdd_32_0 in memory on localhost:42591 (size: 192.0 B, free: 912.3 MiB)
21/02/17 01:42:05 INFO RabitTracker$TrackerProcessLogger: Tracker Process ends with exit code 0
21/02/17 01:42:05 INFO RabitTracker: Tracker Process ends with exit code 0
21/02/17 01:42:05 INFO XGBoostSpark: Rabit returns with exit code 0
21/02/17 01:42:05 INFO Executor: 1 block locks were not released by TID = 6:
[rdd_32_0]
21/02/17 01:42:05 INFO Executor: Finished task 0.0 in stage 6.0 (TID 6). 1428 bytes result sent to driver
21/02/17 01:42:05 INFO TaskSetManager: Finished task 0.0 in stage 6.0 (TID 6) in 325 ms on localhost (executor driver) (1/1)
21/02/17 01:42:05 INFO TaskSchedulerImpl: Removed TaskSet 6.0, whose tasks have all completed, from pool 
21/02/17 01:42:05 INFO DAGScheduler: ResultStage 6 (foreachPartition at XGBoost.scala:612) finished in 0.386 s
21/02/17 01:42:05 INFO DAGScheduler: Job 5 is finished. Cancelling potential speculative or zombie tasks for this job
21/02/17 01:42:05 INFO TaskSchedulerImpl: Killing all running tasks in stage 6: Stage finished
21/02/17 01:42:05 INFO DAGScheduler: Job 5 finished: foreachPartition at XGBoost.scala:612, took 0.393936 s
21/02/17 01:42:05 INFO SparkContext: Starting job: first at XGBoost.scala:734
21/02/17 01:42:05 INFO DAGScheduler: Got job 6 (first at XGBoost.scala:734) with 1 output partitions
21/02/17 01:42:05 INFO DAGScheduler: Final stage: ResultStage 7 (first at XGBoost.scala:734)
21/02/17 01:42:05 INFO DAGScheduler: Parents of final stage: List()
21/02/17 01:42:05 INFO DAGScheduler: Missing parents: List()
21/02/17 01:42:05 INFO DAGScheduler: Submitting ResultStage 7 (MapPartitionsRDD[32] at mapPartitions at XGBoost.scala:493), which has no missing parents
21/02/17 01:42:05 INFO MemoryStore: Block broadcast_7 stored as values in memory (estimated size 40.8 KiB, free 912.2 MiB)
21/02/17 01:42:05 INFO MemoryStore: Block broadcast_7_piece0 stored as bytes in memory (estimated size 16.8 KiB, free 912.2 MiB)
21/02/17 01:42:05 INFO BlockManagerInfo: Added broadcast_7_piece0 in memory on localhost:42591 (size: 16.8 KiB, free: 912.3 MiB)
21/02/17 01:42:05 INFO SparkContext: Created broadcast 7 from broadcast at DAGScheduler.scala:1200
21/02/17 01:42:05 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 7 (MapPartitionsRDD[32] at mapPartitions at XGBoost.scala:493) (first 15 tasks are for partitions Vector(0))
21/02/17 01:42:05 INFO TaskSchedulerImpl: Adding task set 7.0 with 1 tasks
21/02/17 01:42:05 INFO TaskSetManager: Starting task 0.0 in stage 7.0 (TID 7, localhost, executor driver, partition 0, PROCESS_LOCAL, 18492 bytes)
21/02/17 01:42:05 INFO Executor: Running task 0.0 in stage 7.0 (TID 7)
21/02/17 01:42:05 INFO BlockManager: Found block rdd_32_0 locally
21/02/17 01:42:05 INFO Executor: 1 block locks were not released by TID = 7:
[rdd_32_0]
21/02/17 01:42:05 INFO Executor: Finished task 0.0 in stage 7.0 (TID 7). 2676 bytes result sent to driver
21/02/17 01:42:05 INFO TaskSetManager: Finished task 0.0 in stage 7.0 (TID 7) in 11 ms on localhost (executor driver) (1/1)
21/02/17 01:42:05 INFO TaskSchedulerImpl: Removed TaskSet 7.0, whose tasks have all completed, from pool 
21/02/17 01:42:05 INFO DAGScheduler: ResultStage 7 (first at XGBoost.scala:734) finished in 0.018 s
21/02/17 01:42:05 INFO DAGScheduler: Job 6 is finished. Cancelling potential speculative or zombie tasks for this job
21/02/17 01:42:05 INFO TaskSchedulerImpl: Killing all running tasks in stage 7: Stage finished
21/02/17 01:42:05 INFO DAGScheduler: Job 6 finished: first at XGBoost.scala:734, took 0.022491 s
21/02/17 01:42:05 INFO MapPartitionsRDD: Removing RDD 32 from persistence list
21/02/17 01:42:05 INFO BlockManager: Removing RDD 32
21/02/17 01:42:05 INFO Instrumentation: [d3fa72fe] training finished
21/02/17 01:42:05 INFO Instrumentation: [0bed0008] training finished
21/02/17 01:42:05 INFO MemoryStore: Block broadcast_8 stored as values in memory (estimated size 64.0 B, free 912.2 MiB)
21/02/17 01:42:05 INFO MemoryStore: Block broadcast_8_piece0 stored as bytes in memory (estimated size 514.0 B, free 912.2 MiB)
21/02/17 01:42:05 INFO BlockManagerInfo: Added broadcast_8_piece0 in memory on localhost:42591 (size: 514.0 B, free: 912.3 MiB)
21/02/17 01:42:05 INFO SparkContext: Created broadcast 8 from broadcast at XGBoostRegressor.scala:279
21/02/17 01:42:05 INFO CodeGenerator: Code generated in 29.354346 ms
21/02/17 01:42:06 INFO Instrumentation: [2af13f05] training finished
21/02/17 01:42:06 INFO CodeGenerator: Code generated in 8.031313 ms
21/02/17 01:42:06 INFO SparkContext: Starting job: collect at utils.scala:137
21/02/17 01:42:06 INFO DAGScheduler: Got job 7 (collect at utils.scala:137) with 1 output partitions
21/02/17 01:42:06 INFO DAGScheduler: Final stage: ResultStage 8 (collect at utils.scala:137)
21/02/17 01:42:06 INFO DAGScheduler: Parents of final stage: List()
21/02/17 01:42:06 INFO DAGScheduler: Missing parents: List()
21/02/17 01:42:06 INFO DAGScheduler: Submitting ResultStage 8 (MapPartitionsRDD[42] at collect at utils.scala:137), which has no missing parents
21/02/17 01:42:06 INFO MemoryStore: Block broadcast_9 stored as values in memory (estimated size 7.3 KiB, free 912.2 MiB)
21/02/17 01:42:06 INFO MemoryStore: Block broadcast_9_piece0 stored as bytes in memory (estimated size 3.7 KiB, free 912.2 MiB)
21/02/17 01:42:06 INFO BlockManagerInfo: Added broadcast_9_piece0 in memory on localhost:42591 (size: 3.7 KiB, free: 912.3 MiB)
21/02/17 01:42:06 INFO SparkContext: Created broadcast 9 from broadcast at DAGScheduler.scala:1200
21/02/17 01:42:06 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 8 (MapPartitionsRDD[42] at collect at utils.scala:137) (first 15 tasks are for partitions Vector(0))
21/02/17 01:42:06 INFO TaskSchedulerImpl: Adding task set 8.0 with 1 tasks
21/02/17 01:42:06 INFO TaskSetManager: Starting task 0.0 in stage 8.0 (TID 8, localhost, executor driver, partition 0, PROCESS_LOCAL, 7561 bytes)
21/02/17 01:42:06 INFO Executor: Running task 0.0 in stage 8.0 (TID 8)
21/02/17 01:42:06 INFO Executor: Finished task 0.0 in stage 8.0 (TID 8). 1397 bytes result sent to driver
21/02/17 01:42:06 INFO TaskSetManager: Finished task 0.0 in stage 8.0 (TID 8) in 7 ms on localhost (executor driver) (1/1)
21/02/17 01:42:06 INFO TaskSchedulerImpl: Removed TaskSet 8.0, whose tasks have all completed, from pool 
21/02/17 01:42:06 INFO DAGScheduler: ResultStage 8 (collect at utils.scala:137) finished in 0.013 s
21/02/17 01:42:06 INFO DAGScheduler: Job 7 is finished. Cancelling potential speculative or zombie tasks for this job
21/02/17 01:42:06 INFO TaskSchedulerImpl: Killing all running tasks in stage 8: Stage finished
21/02/17 01:42:06 INFO DAGScheduler: Job 7 finished: collect at utils.scala:137, took 0.016176 s
21/02/17 01:42:06 INFO CodeGenerator: Code generated in 9.783456 ms
21/02/17 01:42:06 INFO SparkContext: Starting job: count at utils.scala:135
21/02/17 01:42:06 INFO DAGScheduler: Registering RDD 44 (count at utils.scala:135) as input to shuffle 2
21/02/17 01:42:06 INFO DAGScheduler: Got job 8 (count at utils.scala:135) with 1 output partitions
21/02/17 01:42:06 INFO DAGScheduler: Final stage: ResultStage 10 (count at utils.scala:135)
21/02/17 01:42:06 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 9)
21/02/17 01:42:06 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 9)
21/02/17 01:42:06 INFO DAGScheduler: Submitting ShuffleMapStage 9 (MapPartitionsRDD[44] at count at utils.scala:135), which has no missing parents
21/02/17 01:42:06 INFO MemoryStore: Block broadcast_10 stored as values in memory (estimated size 10.0 KiB, free 912.2 MiB)
21/02/17 01:42:06 INFO MemoryStore: Block broadcast_10_piece0 stored as bytes in memory (estimated size 5.2 KiB, free 912.2 MiB)
21/02/17 01:42:06 INFO BlockManagerInfo: Added broadcast_10_piece0 in memory on localhost:42591 (size: 5.2 KiB, free: 912.3 MiB)
21/02/17 01:42:06 INFO SparkContext: Created broadcast 10 from broadcast at DAGScheduler.scala:1200
21/02/17 01:42:06 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 9 (MapPartitionsRDD[44] at count at utils.scala:135) (first 15 tasks are for partitions Vector(0))
21/02/17 01:42:06 INFO TaskSchedulerImpl: Adding task set 9.0 with 1 tasks
21/02/17 01:42:06 INFO TaskSetManager: Starting task 0.0 in stage 9.0 (TID 9, localhost, executor driver, partition 0, PROCESS_LOCAL, 7550 bytes)
21/02/17 01:42:06 INFO Executor: Running task 0.0 in stage 9.0 (TID 9)
21/02/17 01:42:06 INFO Executor: Finished task 0.0 in stage 9.0 (TID 9). 1833 bytes result sent to driver
21/02/17 01:42:06 INFO TaskSetManager: Finished task 0.0 in stage 9.0 (TID 9) in 6 ms on localhost (executor driver) (1/1)
21/02/17 01:42:06 INFO TaskSchedulerImpl: Removed TaskSet 9.0, whose tasks have all completed, from pool 
21/02/17 01:42:06 INFO DAGScheduler: ShuffleMapStage 9 (count at utils.scala:135) finished in 0.013 s
21/02/17 01:42:06 INFO DAGScheduler: looking for newly runnable stages
21/02/17 01:42:06 INFO DAGScheduler: running: Set()
21/02/17 01:42:06 INFO DAGScheduler: waiting: Set(ResultStage 10)
21/02/17 01:42:06 INFO DAGScheduler: failed: Set()
21/02/17 01:42:06 INFO DAGScheduler: Submitting ResultStage 10 (MapPartitionsRDD[47] at count at utils.scala:135), which has no missing parents
21/02/17 01:42:06 INFO MemoryStore: Block broadcast_11 stored as values in memory (estimated size 10.1 KiB, free 912.1 MiB)
21/02/17 01:42:06 INFO MemoryStore: Block broadcast_11_piece0 stored as bytes in memory (estimated size 5.0 KiB, free 912.1 MiB)
21/02/17 01:42:06 INFO BlockManagerInfo: Added broadcast_11_piece0 in memory on localhost:42591 (size: 5.0 KiB, free: 912.2 MiB)
21/02/17 01:42:06 INFO SparkContext: Created broadcast 11 from broadcast at DAGScheduler.scala:1200
21/02/17 01:42:06 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 10 (MapPartitionsRDD[47] at count at utils.scala:135) (first 15 tasks are for partitions Vector(0))
21/02/17 01:42:06 INFO TaskSchedulerImpl: Adding task set 10.0 with 1 tasks
21/02/17 01:42:06 INFO TaskSetManager: Starting task 0.0 in stage 10.0 (TID 10, localhost, executor driver, partition 0, NODE_LOCAL, 7325 bytes)
21/02/17 01:42:06 INFO Executor: Running task 0.0 in stage 10.0 (TID 10)
21/02/17 01:42:06 INFO ShuffleBlockFetcherIterator: Getting 1 (60.0 B) non-empty blocks including 1 (60.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
21/02/17 01:42:06 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
21/02/17 01:42:06 INFO Executor: Finished task 0.0 in stage 10.0 (TID 10). 2648 bytes result sent to driver
21/02/17 01:42:06 INFO TaskSetManager: Finished task 0.0 in stage 10.0 (TID 10) in 6 ms on localhost (executor driver) (1/1)
21/02/17 01:42:06 INFO TaskSchedulerImpl: Removed TaskSet 10.0, whose tasks have all completed, from pool 
21/02/17 01:42:06 INFO DAGScheduler: ResultStage 10 (count at utils.scala:135) finished in 0.013 s
21/02/17 01:42:06 INFO DAGScheduler: Job 8 is finished. Cancelling potential speculative or zombie tasks for this job
21/02/17 01:42:06 INFO TaskSchedulerImpl: Killing all running tasks in stage 10: Stage finished
21/02/17 01:42:06 INFO DAGScheduler: Job 8 finished: count at utils.scala:135, took 0.030458 s
21/02/17 01:42:06 INFO CodeGenerator: Code generated in 11.013535 ms
21/02/17 01:42:06 INFO SparkContext: Starting job: collect at utils.scala:137
21/02/17 01:42:06 INFO DAGScheduler: Got job 9 (collect at utils.scala:137) with 1 output partitions
21/02/17 01:42:06 INFO DAGScheduler: Final stage: ResultStage 11 (collect at utils.scala:137)
21/02/17 01:42:06 INFO DAGScheduler: Parents of final stage: List()
21/02/17 01:42:06 INFO DAGScheduler: Missing parents: List()
21/02/17 01:42:06 INFO DAGScheduler: Submitting ResultStage 11 (MapPartitionsRDD[49] at collect at utils.scala:137), which has no missing parents
21/02/17 01:42:06 INFO MemoryStore: Block broadcast_12 stored as values in memory (estimated size 71.9 KiB, free 912.1 MiB)
21/02/17 01:42:06 INFO MemoryStore: Block broadcast_12_piece0 stored as bytes in memory (estimated size 28.2 KiB, free 912.0 MiB)
21/02/17 01:42:06 INFO BlockManagerInfo: Added broadcast_12_piece0 in memory on localhost:42591 (size: 28.2 KiB, free: 912.2 MiB)
21/02/17 01:42:06 INFO SparkContext: Created broadcast 12 from broadcast at DAGScheduler.scala:1200
21/02/17 01:42:06 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 11 (MapPartitionsRDD[49] at collect at utils.scala:137) (first 15 tasks are for partitions Vector(0))
21/02/17 01:42:06 INFO TaskSchedulerImpl: Adding task set 11.0 with 1 tasks
21/02/17 01:42:06 INFO TaskSetManager: Starting task 0.0 in stage 11.0 (TID 11, localhost, executor driver, partition 0, PROCESS_LOCAL, 18492 bytes)
21/02/17 01:42:06 INFO Executor: Running task 0.0 in stage 11.0 (TID 11)
21/02/17 01:42:06 INFO BlockManager: Found block rdd_23_0 locally
21/02/17 01:42:06 INFO CodeGenerator: Code generated in 10.045382 ms
21/02/17 01:42:06 INFO CodeGenerator: Code generated in 39.05851 ms
21/02/17 01:42:06 INFO Executor: Finished task 0.0 in stage 11.0 (TID 11). 1912 bytes result sent to driver
21/02/17 01:42:06 INFO TaskSetManager: Finished task 0.0 in stage 11.0 (TID 11) in 148 ms on localhost (executor driver) (1/1)
21/02/17 01:42:06 INFO TaskSchedulerImpl: Removed TaskSet 11.0, whose tasks have all completed, from pool 
21/02/17 01:42:06 INFO DAGScheduler: ResultStage 11 (collect at utils.scala:137) finished in 0.154 s
21/02/17 01:42:06 INFO DAGScheduler: Job 9 is finished. Cancelling potential speculative or zombie tasks for this job
21/02/17 01:42:06 INFO TaskSchedulerImpl: Killing all running tasks in stage 11: Stage finished
21/02/17 01:42:06 INFO DAGScheduler: Job 9 finished: collect at utils.scala:137, took 0.157286 s
21/02/17 01:42:06 INFO CodeGenerator: Code generated in 5.617835 ms
21/02/17 01:42:07 INFO CodeGenerator: Code generated in 9.996047 ms
21/02/17 01:42:07 INFO SparkContext: Starting job: count at utils.scala:135
21/02/17 01:42:07 INFO DAGScheduler: Registering RDD 51 (count at utils.scala:135) as input to shuffle 3
21/02/17 01:42:07 INFO DAGScheduler: Got job 10 (count at utils.scala:135) with 1 output partitions
21/02/17 01:42:07 INFO DAGScheduler: Final stage: ResultStage 13 (count at utils.scala:135)
21/02/17 01:42:07 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 12)
21/02/17 01:42:07 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 12)
21/02/17 01:42:07 INFO DAGScheduler: Submitting ShuffleMapStage 12 (MapPartitionsRDD[51] at count at utils.scala:135), which has no missing parents
21/02/17 01:42:07 INFO MemoryStore: Block broadcast_13 stored as values in memory (estimated size 74.1 KiB, free 912.0 MiB)
21/02/17 01:42:07 INFO MemoryStore: Block broadcast_13_piece0 stored as bytes in memory (estimated size 29.4 KiB, free 911.9 MiB)
21/02/17 01:42:07 INFO BlockManagerInfo: Added broadcast_13_piece0 in memory on localhost:42591 (size: 29.4 KiB, free: 912.2 MiB)
21/02/17 01:42:07 INFO SparkContext: Created broadcast 13 from broadcast at DAGScheduler.scala:1200
21/02/17 01:42:07 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 12 (MapPartitionsRDD[51] at count at utils.scala:135) (first 15 tasks are for partitions Vector(0))
21/02/17 01:42:07 INFO TaskSchedulerImpl: Adding task set 12.0 with 1 tasks
21/02/17 01:42:07 INFO TaskSetManager: Starting task 0.0 in stage 12.0 (TID 12, localhost, executor driver, partition 0, PROCESS_LOCAL, 18481 bytes)
21/02/17 01:42:07 INFO Executor: Running task 0.0 in stage 12.0 (TID 12)
21/02/17 01:42:07 INFO BlockManager: Found block rdd_23_0 locally
21/02/17 01:42:07 INFO Executor: Finished task 0.0 in stage 12.0 (TID 12). 2253 bytes result sent to driver
21/02/17 01:42:07 INFO TaskSetManager: Finished task 0.0 in stage 12.0 (TID 12) in 58 ms on localhost (executor driver) (1/1)
21/02/17 01:42:07 INFO TaskSchedulerImpl: Removed TaskSet 12.0, whose tasks have all completed, from pool 
21/02/17 01:42:07 INFO DAGScheduler: ShuffleMapStage 12 (count at utils.scala:135) finished in 0.065 s
21/02/17 01:42:07 INFO DAGScheduler: looking for newly runnable stages
21/02/17 01:42:07 INFO DAGScheduler: running: Set()
21/02/17 01:42:07 INFO DAGScheduler: waiting: Set(ResultStage 13)
21/02/17 01:42:07 INFO DAGScheduler: failed: Set()
21/02/17 01:42:07 INFO DAGScheduler: Submitting ResultStage 13 (MapPartitionsRDD[54] at count at utils.scala:135), which has no missing parents
21/02/17 01:42:07 INFO MemoryStore: Block broadcast_14 stored as values in memory (estimated size 10.1 KiB, free 911.9 MiB)
21/02/17 01:42:07 INFO MemoryStore: Block broadcast_14_piece0 stored as bytes in memory (estimated size 5.0 KiB, free 911.9 MiB)
21/02/17 01:42:07 INFO BlockManagerInfo: Added broadcast_14_piece0 in memory on localhost:42591 (size: 5.0 KiB, free: 912.2 MiB)
21/02/17 01:42:07 INFO BlockManagerInfo: Removed broadcast_9_piece0 on localhost:42591 in memory (size: 3.7 KiB, free: 912.2 MiB)
21/02/17 01:42:07 INFO SparkContext: Created broadcast 14 from broadcast at DAGScheduler.scala:1200
21/02/17 01:42:07 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 13 (MapPartitionsRDD[54] at count at utils.scala:135) (first 15 tasks are for partitions Vector(0))
21/02/17 01:42:07 INFO TaskSchedulerImpl: Adding task set 13.0 with 1 tasks
21/02/17 01:42:07 INFO TaskSetManager: Starting task 0.0 in stage 13.0 (TID 13, localhost, executor driver, partition 0, NODE_LOCAL, 7325 bytes)
21/02/17 01:42:07 INFO Executor: Running task 0.0 in stage 13.0 (TID 13)
21/02/17 01:42:07 INFO BlockManagerInfo: Removed broadcast_10_piece0 on localhost:42591 in memory (size: 5.2 KiB, free: 912.2 MiB)
21/02/17 01:42:07 INFO BlockManagerInfo: Removed broadcast_7_piece0 on localhost:42591 in memory (size: 16.8 KiB, free: 912.2 MiB)
21/02/17 01:42:07 INFO ShuffleBlockFetcherIterator: Getting 1 (60.0 B) non-empty blocks including 1 (60.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
21/02/17 01:42:07 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
21/02/17 01:42:07 INFO BlockManagerInfo: Removed broadcast_12_piece0 on localhost:42591 in memory (size: 28.2 KiB, free: 912.2 MiB)
21/02/17 01:42:07 INFO Executor: Finished task 0.0 in stage 13.0 (TID 13). 2648 bytes result sent to driver
21/02/17 01:42:07 INFO TaskSetManager: Finished task 0.0 in stage 13.0 (TID 13) in 8 ms on localhost (executor driver) (1/1)
21/02/17 01:42:07 INFO TaskSchedulerImpl: Removed TaskSet 13.0, whose tasks have all completed, from pool 
21/02/17 01:42:07 INFO DAGScheduler: ResultStage 13 (count at utils.scala:135) finished in 0.029 s
21/02/17 01:42:07 INFO DAGScheduler: Job 10 is finished. Cancelling potential speculative or zombie tasks for this job
21/02/17 01:42:07 INFO TaskSchedulerImpl: Killing all running tasks in stage 13: Stage finished
21/02/17 01:42:07 INFO DAGScheduler: Job 10 finished: count at utils.scala:135, took 0.099637 s
21/02/17 01:42:07 INFO BlockManager: Removing RDD 32
21/02/17 01:42:07 INFO BlockManagerInfo: Removed broadcast_6_piece0 on localhost:42591 in memory (size: 16.8 KiB, free: 912.3 MiB)
21/02/17 01:42:07 INFO BlockManagerInfo: Removed broadcast_11_piece0 on localhost:42591 in memory (size: 5.0 KiB, free: 912.3 MiB)
21/02/17 01:42:07 INFO deprecation: mapred.output.dir is deprecated. Instead, use mapreduce.output.fileoutputformat.outputdir
21/02/17 01:42:07 INFO HadoopMapRedCommitProtocol: Using output committer class org.apache.hadoop.mapred.FileOutputCommitter
21/02/17 01:42:07 INFO FileOutputCommitter: File Output Committer Algorithm version is 2
21/02/17 01:42:07 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
21/02/17 01:42:07 INFO SparkContext: Starting job: runJob at SparkHadoopWriter.scala:78
21/02/17 01:42:07 INFO DAGScheduler: Got job 11 (runJob at SparkHadoopWriter.scala:78) with 1 output partitions
21/02/17 01:42:07 INFO DAGScheduler: Final stage: ResultStage 14 (runJob at SparkHadoopWriter.scala:78)
21/02/17 01:42:07 INFO DAGScheduler: Parents of final stage: List()
21/02/17 01:42:07 INFO DAGScheduler: Missing parents: List()
21/02/17 01:42:07 INFO DAGScheduler: Submitting ResultStage 14 (MapPartitionsRDD[56] at saveAsTextFile at ReadWrite.scala:413), which has no missing parents
21/02/17 01:42:07 INFO MemoryStore: Block broadcast_15 stored as values in memory (estimated size 83.9 KiB, free 912.1 MiB)
21/02/17 01:42:07 INFO MemoryStore: Block broadcast_15_piece0 stored as bytes in memory (estimated size 29.9 KiB, free 912.1 MiB)
21/02/17 01:42:07 INFO BlockManagerInfo: Added broadcast_15_piece0 in memory on localhost:42591 (size: 29.9 KiB, free: 912.2 MiB)
21/02/17 01:42:07 INFO SparkContext: Created broadcast 15 from broadcast at DAGScheduler.scala:1200
21/02/17 01:42:07 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 14 (MapPartitionsRDD[56] at saveAsTextFile at ReadWrite.scala:413) (first 15 tasks are for partitions Vector(0))
21/02/17 01:42:07 INFO TaskSchedulerImpl: Adding task set 14.0 with 1 tasks
21/02/17 01:42:07 INFO TaskSetManager: Starting task 0.0 in stage 14.0 (TID 14, localhost, executor driver, partition 0, PROCESS_LOCAL, 7657 bytes)
21/02/17 01:42:07 INFO Executor: Running task 0.0 in stage 14.0 (TID 14)
21/02/17 01:42:07 INFO HadoopMapRedCommitProtocol: Using output committer class org.apache.hadoop.mapred.FileOutputCommitter
21/02/17 01:42:07 INFO FileOutputCommitter: File Output Committer Algorithm version is 2
21/02/17 01:42:07 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
21/02/17 01:42:07 INFO FileOutputCommitter: Saved output of task 'attempt_20210217014207_0056_m_000000_0' to file:/tmp/RtmpzND6YJ/file230be61cffde9/metadata
21/02/17 01:42:07 INFO SparkHadoopMapRedUtil: attempt_20210217014207_0056_m_000000_0: Committed
21/02/17 01:42:07 INFO Executor: Finished task 0.0 in stage 14.0 (TID 14). 1158 bytes result sent to driver
21/02/17 01:42:07 INFO TaskSetManager: Finished task 0.0 in stage 14.0 (TID 14) in 52 ms on localhost (executor driver) (1/1)
21/02/17 01:42:07 INFO TaskSchedulerImpl: Removed TaskSet 14.0, whose tasks have all completed, from pool 
21/02/17 01:42:07 INFO DAGScheduler: ResultStage 14 (runJob at SparkHadoopWriter.scala:78) finished in 0.064 s
21/02/17 01:42:07 INFO DAGScheduler: Job 11 is finished. Cancelling potential speculative or zombie tasks for this job
21/02/17 01:42:07 INFO TaskSchedulerImpl: Killing all running tasks in stage 14: Stage finished
21/02/17 01:42:07 INFO DAGScheduler: Job 11 finished: runJob at SparkHadoopWriter.scala:78, took 0.067121 s
21/02/17 01:42:07 INFO SparkHadoopWriter: Job job_20210217014207_0056 committed.
21/02/17 01:42:07 INFO HadoopMapRedCommitProtocol: Using output committer class org.apache.hadoop.mapred.FileOutputCommitter
21/02/17 01:42:07 INFO FileOutputCommitter: File Output Committer Algorithm version is 2
21/02/17 01:42:07 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
21/02/17 01:42:07 INFO SparkContext: Starting job: runJob at SparkHadoopWriter.scala:78
21/02/17 01:42:07 INFO DAGScheduler: Got job 12 (runJob at SparkHadoopWriter.scala:78) with 1 output partitions
21/02/17 01:42:07 INFO DAGScheduler: Final stage: ResultStage 15 (runJob at SparkHadoopWriter.scala:78)
21/02/17 01:42:07 INFO DAGScheduler: Parents of final stage: List()
21/02/17 01:42:07 INFO DAGScheduler: Missing parents: List()
21/02/17 01:42:07 INFO DAGScheduler: Submitting ResultStage 15 (MapPartitionsRDD[58] at saveAsTextFile at ReadWrite.scala:413), which has no missing parents
21/02/17 01:42:07 INFO MemoryStore: Block broadcast_16 stored as values in memory (estimated size 84.0 KiB, free 912.0 MiB)
21/02/17 01:42:07 INFO MemoryStore: Block broadcast_16_piece0 stored as bytes in memory (estimated size 29.9 KiB, free 912.0 MiB)
21/02/17 01:42:07 INFO BlockManagerInfo: Added broadcast_16_piece0 in memory on localhost:42591 (size: 29.9 KiB, free: 912.2 MiB)
21/02/17 01:42:07 INFO SparkContext: Created broadcast 16 from broadcast at DAGScheduler.scala:1200
21/02/17 01:42:07 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 15 (MapPartitionsRDD[58] at saveAsTextFile at ReadWrite.scala:413) (first 15 tasks are for partitions Vector(0))
21/02/17 01:42:07 INFO TaskSchedulerImpl: Adding task set 15.0 with 1 tasks
21/02/17 01:42:07 INFO TaskSetManager: Starting task 0.0 in stage 15.0 (TID 15, localhost, executor driver, partition 0, PROCESS_LOCAL, 7798 bytes)
21/02/17 01:42:07 INFO Executor: Running task 0.0 in stage 15.0 (TID 15)
21/02/17 01:42:07 INFO HadoopMapRedCommitProtocol: Using output committer class org.apache.hadoop.mapred.FileOutputCommitter
21/02/17 01:42:07 INFO FileOutputCommitter: File Output Committer Algorithm version is 2
21/02/17 01:42:07 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
21/02/17 01:42:07 INFO FileOutputCommitter: Saved output of task 'attempt_20210217014207_0058_m_000000_0' to file:/tmp/RtmpzND6YJ/file230be61cffde9/stages/0_r_formula__ae8e0faf_6bf9_456d_bc45_2aca30f7aea4/metadata
21/02/17 01:42:07 INFO SparkHadoopMapRedUtil: attempt_20210217014207_0058_m_000000_0: Committed
21/02/17 01:42:07 INFO Executor: Finished task 0.0 in stage 15.0 (TID 15). 1158 bytes result sent to driver
21/02/17 01:42:07 INFO TaskSetManager: Finished task 0.0 in stage 15.0 (TID 15) in 19 ms on localhost (executor driver) (1/1)
21/02/17 01:42:07 INFO TaskSchedulerImpl: Removed TaskSet 15.0, whose tasks have all completed, from pool 
21/02/17 01:42:07 INFO DAGScheduler: ResultStage 15 (runJob at SparkHadoopWriter.scala:78) finished in 0.032 s
21/02/17 01:42:07 INFO DAGScheduler: Job 12 is finished. Cancelling potential speculative or zombie tasks for this job
21/02/17 01:42:07 INFO TaskSchedulerImpl: Killing all running tasks in stage 15: Stage finished
21/02/17 01:42:07 INFO DAGScheduler: Job 12 finished: runJob at SparkHadoopWriter.scala:78, took 0.034056 s
21/02/17 01:42:07 INFO SparkHadoopWriter: Job job_20210217014207_0058 committed.
21/02/17 01:42:07 INFO ParquetFileFormat: Using default output committer for Parquet: org.apache.parquet.hadoop.ParquetOutputCommitter
21/02/17 01:42:07 INFO FileOutputCommitter: File Output Committer Algorithm version is 2
21/02/17 01:42:07 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
21/02/17 01:42:07 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
21/02/17 01:42:07 INFO FileOutputCommitter: File Output Committer Algorithm version is 2
21/02/17 01:42:07 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
21/02/17 01:42:07 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
21/02/17 01:42:07 INFO CodeGenerator: Code generated in 12.532861 ms
21/02/17 01:42:07 INFO SparkContext: Starting job: parquet at RFormula.scala:434
21/02/17 01:42:07 INFO DAGScheduler: Registering RDD 61 (parquet at RFormula.scala:434) as input to shuffle 4
21/02/17 01:42:07 INFO DAGScheduler: Got job 13 (parquet at RFormula.scala:434) with 1 output partitions
21/02/17 01:42:07 INFO DAGScheduler: Final stage: ResultStage 17 (parquet at RFormula.scala:434)
21/02/17 01:42:07 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 16)
21/02/17 01:42:07 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 16)
21/02/17 01:42:07 INFO DAGScheduler: Submitting ShuffleMapStage 16 (MapPartitionsRDD[61] at parquet at RFormula.scala:434), which has no missing parents
21/02/17 01:42:07 INFO MemoryStore: Block broadcast_17 stored as values in memory (estimated size 7.7 KiB, free 911.9 MiB)
21/02/17 01:42:07 INFO MemoryStore: Block broadcast_17_piece0 stored as bytes in memory (estimated size 4.2 KiB, free 911.9 MiB)
21/02/17 01:42:07 INFO BlockManagerInfo: Added broadcast_17_piece0 in memory on localhost:42591 (size: 4.2 KiB, free: 912.2 MiB)
21/02/17 01:42:07 INFO SparkContext: Created broadcast 17 from broadcast at DAGScheduler.scala:1200
21/02/17 01:42:07 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 16 (MapPartitionsRDD[61] at parquet at RFormula.scala:434) (first 15 tasks are for partitions Vector(0))
21/02/17 01:42:07 INFO TaskSchedulerImpl: Adding task set 16.0 with 1 tasks
21/02/17 01:42:07 INFO TaskSetManager: Starting task 0.0 in stage 16.0 (TID 16, localhost, executor driver, partition 0, PROCESS_LOCAL, 7658 bytes)
21/02/17 01:42:07 INFO Executor: Running task 0.0 in stage 16.0 (TID 16)
21/02/17 01:42:07 INFO Executor: Finished task 0.0 in stage 16.0 (TID 16). 1614 bytes result sent to driver
21/02/17 01:42:07 INFO TaskSetManager: Finished task 0.0 in stage 16.0 (TID 16) in 5 ms on localhost (executor driver) (1/1)
21/02/17 01:42:07 INFO TaskSchedulerImpl: Removed TaskSet 16.0, whose tasks have all completed, from pool 
21/02/17 01:42:07 INFO DAGScheduler: ShuffleMapStage 16 (parquet at RFormula.scala:434) finished in 0.012 s
21/02/17 01:42:07 INFO DAGScheduler: looking for newly runnable stages
21/02/17 01:42:07 INFO DAGScheduler: running: Set()
21/02/17 01:42:07 INFO DAGScheduler: waiting: Set(ResultStage 17)
21/02/17 01:42:07 INFO DAGScheduler: failed: Set()
21/02/17 01:42:07 INFO DAGScheduler: Submitting ResultStage 17 (ShuffledRowRDD[62] at parquet at RFormula.scala:434), which has no missing parents
21/02/17 01:42:07 INFO MemoryStore: Block broadcast_18 stored as values in memory (estimated size 177.6 KiB, free 911.8 MiB)
21/02/17 01:42:07 INFO MemoryStore: Block broadcast_18_piece0 stored as bytes in memory (estimated size 62.1 KiB, free 911.7 MiB)
21/02/17 01:42:07 INFO BlockManagerInfo: Added broadcast_18_piece0 in memory on localhost:42591 (size: 62.1 KiB, free: 912.1 MiB)
21/02/17 01:42:07 INFO SparkContext: Created broadcast 18 from broadcast at DAGScheduler.scala:1200
21/02/17 01:42:07 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 17 (ShuffledRowRDD[62] at parquet at RFormula.scala:434) (first 15 tasks are for partitions Vector(0))
21/02/17 01:42:07 INFO TaskSchedulerImpl: Adding task set 17.0 with 1 tasks
21/02/17 01:42:07 INFO TaskSetManager: Starting task 0.0 in stage 17.0 (TID 17, localhost, executor driver, partition 0, NODE_LOCAL, 7325 bytes)
21/02/17 01:42:07 INFO Executor: Running task 0.0 in stage 17.0 (TID 17)
21/02/17 01:42:07 INFO ShuffleBlockFetcherIterator: Getting 1 (156.0 B) non-empty blocks including 1 (156.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
21/02/17 01:42:07 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
21/02/17 01:42:07 INFO FileOutputCommitter: File Output Committer Algorithm version is 2
21/02/17 01:42:07 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
21/02/17 01:42:07 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
21/02/17 01:42:07 INFO FileOutputCommitter: File Output Committer Algorithm version is 2
21/02/17 01:42:07 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
21/02/17 01:42:07 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
21/02/17 01:42:07 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:
{
  "type" : "struct",
  "fields" : [ {
    "name" : "label",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "terms",
    "type" : {
      "type" : "array",
      "elementType" : {
        "type" : "array",
        "elementType" : "string",
        "containsNull" : true
      },
      "containsNull" : true
    },
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "hasIntercept",
    "type" : "boolean",
    "nullable" : false,
    "metadata" : { }
  } ]
}
and corresponding Parquet message type:
message spark_schema {
  optional binary label (UTF8);
  optional group terms (LIST) {
    repeated group list {
      optional group element (LIST) {
        repeated group list {
          optional binary element (UTF8);
        }
      }
    }
  }
  required boolean hasIntercept;
}

       
21/02/17 01:42:07 INFO CodecPool: Got brand-new compressor [.snappy]
21/02/17 01:42:08 INFO BlockManagerInfo: Removed broadcast_14_piece0 on localhost:42591 in memory (size: 5.0 KiB, free: 912.1 MiB)
21/02/17 01:42:08 INFO BlockManagerInfo: Removed broadcast_13_piece0 on localhost:42591 in memory (size: 29.4 KiB, free: 912.2 MiB)
21/02/17 01:42:08 INFO BlockManagerInfo: Removed broadcast_17_piece0 on localhost:42591 in memory (size: 4.2 KiB, free: 912.2 MiB)
21/02/17 01:42:08 INFO BlockManagerInfo: Removed broadcast_16_piece0 on localhost:42591 in memory (size: 29.9 KiB, free: 912.2 MiB)
21/02/17 01:42:08 INFO BlockManagerInfo: Removed broadcast_15_piece0 on localhost:42591 in memory (size: 29.9 KiB, free: 912.2 MiB)
21/02/17 01:42:08 INFO FileOutputCommitter: Saved output of task 'attempt_20210217014207_0017_m_000000_17' to file:/tmp/RtmpzND6YJ/file230be61cffde9/stages/0_r_formula__ae8e0faf_6bf9_456d_bc45_2aca30f7aea4/data
21/02/17 01:42:08 INFO SparkHadoopMapRedUtil: attempt_20210217014207_0017_m_000000_17: Committed
21/02/17 01:42:08 INFO Executor: Finished task 0.0 in stage 17.0 (TID 17). 3281 bytes result sent to driver
21/02/17 01:42:08 INFO TaskSetManager: Finished task 0.0 in stage 17.0 (TID 17) in 556 ms on localhost (executor driver) (1/1)
21/02/17 01:42:08 INFO TaskSchedulerImpl: Removed TaskSet 17.0, whose tasks have all completed, from pool 
21/02/17 01:42:08 INFO DAGScheduler: ResultStage 17 (parquet at RFormula.scala:434) finished in 0.575 s
21/02/17 01:42:08 INFO DAGScheduler: Job 13 is finished. Cancelling potential speculative or zombie tasks for this job
21/02/17 01:42:08 INFO TaskSchedulerImpl: Killing all running tasks in stage 17: Stage finished
21/02/17 01:42:08 INFO DAGScheduler: Job 13 finished: parquet at RFormula.scala:434, took 0.590842 s
21/02/17 01:42:08 INFO FileFormatWriter: Write Job 9a47a50d-10c1-434a-8bf1-4810a793aead committed.
21/02/17 01:42:08 INFO FileFormatWriter: Finished processing stats for write job 9a47a50d-10c1-434a-8bf1-4810a793aead.
21/02/17 01:42:08 INFO HadoopMapRedCommitProtocol: Using output committer class org.apache.hadoop.mapred.FileOutputCommitter
21/02/17 01:42:08 INFO FileOutputCommitter: File Output Committer Algorithm version is 2
21/02/17 01:42:08 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
21/02/17 01:42:08 INFO SparkContext: Starting job: runJob at SparkHadoopWriter.scala:78
21/02/17 01:42:08 INFO DAGScheduler: Got job 14 (runJob at SparkHadoopWriter.scala:78) with 1 output partitions
21/02/17 01:42:08 INFO DAGScheduler: Final stage: ResultStage 18 (runJob at SparkHadoopWriter.scala:78)
21/02/17 01:42:08 INFO DAGScheduler: Parents of final stage: List()
21/02/17 01:42:08 INFO DAGScheduler: Missing parents: List()
21/02/17 01:42:08 INFO DAGScheduler: Submitting ResultStage 18 (MapPartitionsRDD[66] at saveAsTextFile at ReadWrite.scala:413), which has no missing parents
21/02/17 01:42:08 INFO MemoryStore: Block broadcast_19 stored as values in memory (estimated size 84.1 KiB, free 912.0 MiB)
21/02/17 01:42:08 INFO MemoryStore: Block broadcast_19_piece0 stored as bytes in memory (estimated size 30.0 KiB, free 911.9 MiB)
21/02/17 01:42:08 INFO BlockManagerInfo: Added broadcast_19_piece0 in memory on localhost:42591 (size: 30.0 KiB, free: 912.2 MiB)
21/02/17 01:42:08 INFO SparkContext: Created broadcast 19 from broadcast at DAGScheduler.scala:1200
21/02/17 01:42:08 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 18 (MapPartitionsRDD[66] at saveAsTextFile at ReadWrite.scala:413) (first 15 tasks are for partitions Vector(0))
21/02/17 01:42:08 INFO TaskSchedulerImpl: Adding task set 18.0 with 1 tasks
21/02/17 01:42:08 INFO TaskSetManager: Starting task 0.0 in stage 18.0 (TID 18, localhost, executor driver, partition 0, PROCESS_LOCAL, 7662 bytes)
21/02/17 01:42:08 INFO Executor: Running task 0.0 in stage 18.0 (TID 18)
21/02/17 01:42:08 INFO HadoopMapRedCommitProtocol: Using output committer class org.apache.hadoop.mapred.FileOutputCommitter
21/02/17 01:42:08 INFO FileOutputCommitter: File Output Committer Algorithm version is 2
21/02/17 01:42:08 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
21/02/17 01:42:08 INFO FileOutputCommitter: Saved output of task 'attempt_20210217014208_0066_m_000000_0' to file:/tmp/RtmpzND6YJ/file230be61cffde9/stages/0_r_formula__ae8e0faf_6bf9_456d_bc45_2aca30f7aea4/pipelineModel/metadata
21/02/17 01:42:08 INFO SparkHadoopMapRedUtil: attempt_20210217014208_0066_m_000000_0: Committed
21/02/17 01:42:08 INFO Executor: Finished task 0.0 in stage 18.0 (TID 18). 1158 bytes result sent to driver
21/02/17 01:42:08 INFO TaskSetManager: Finished task 0.0 in stage 18.0 (TID 18) in 20 ms on localhost (executor driver) (1/1)
21/02/17 01:42:08 INFO TaskSchedulerImpl: Removed TaskSet 18.0, whose tasks have all completed, from pool 
21/02/17 01:42:08 INFO DAGScheduler: ResultStage 18 (runJob at SparkHadoopWriter.scala:78) finished in 0.037 s
21/02/17 01:42:08 INFO DAGScheduler: Job 14 is finished. Cancelling potential speculative or zombie tasks for this job
21/02/17 01:42:08 INFO TaskSchedulerImpl: Killing all running tasks in stage 18: Stage finished
21/02/17 01:42:08 INFO DAGScheduler: Job 14 finished: runJob at SparkHadoopWriter.scala:78, took 0.039399 s
21/02/17 01:42:08 INFO SparkHadoopWriter: Job job_20210217014208_0066 committed.
21/02/17 01:42:08 INFO HadoopMapRedCommitProtocol: Using output committer class org.apache.hadoop.mapred.FileOutputCommitter
21/02/17 01:42:08 INFO FileOutputCommitter: File Output Committer Algorithm version is 2
21/02/17 01:42:08 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
21/02/17 01:42:08 INFO SparkContext: Starting job: runJob at SparkHadoopWriter.scala:78
21/02/17 01:42:08 INFO DAGScheduler: Got job 15 (runJob at SparkHadoopWriter.scala:78) with 1 output partitions
21/02/17 01:42:08 INFO DAGScheduler: Final stage: ResultStage 19 (runJob at SparkHadoopWriter.scala:78)
21/02/17 01:42:08 INFO DAGScheduler: Parents of final stage: List()
21/02/17 01:42:08 INFO DAGScheduler: Missing parents: List()
21/02/17 01:42:08 INFO DAGScheduler: Submitting ResultStage 19 (MapPartitionsRDD[68] at saveAsTextFile at ReadWrite.scala:413), which has no missing parents
21/02/17 01:42:08 INFO MemoryStore: Block broadcast_20 stored as values in memory (estimated size 84.2 KiB, free 911.9 MiB)
21/02/17 01:42:08 INFO MemoryStore: Block broadcast_20_piece0 stored as bytes in memory (estimated size 30.0 KiB, free 911.8 MiB)
21/02/17 01:42:08 INFO BlockManagerInfo: Added broadcast_20_piece0 in memory on localhost:42591 (size: 30.0 KiB, free: 912.2 MiB)
21/02/17 01:42:08 INFO SparkContext: Created broadcast 20 from broadcast at DAGScheduler.scala:1200
21/02/17 01:42:08 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 19 (MapPartitionsRDD[68] at saveAsTextFile at ReadWrite.scala:413) (first 15 tasks are for partitions Vector(0))
21/02/17 01:42:08 INFO TaskSchedulerImpl: Adding task set 19.0 with 1 tasks
21/02/17 01:42:08 INFO TaskSetManager: Starting task 0.0 in stage 19.0 (TID 19, localhost, executor driver, partition 0, PROCESS_LOCAL, 7729 bytes)
21/02/17 01:42:08 INFO Executor: Running task 0.0 in stage 19.0 (TID 19)
21/02/17 01:42:08 INFO HadoopMapRedCommitProtocol: Using output committer class org.apache.hadoop.mapred.FileOutputCommitter
21/02/17 01:42:08 INFO FileOutputCommitter: File Output Committer Algorithm version is 2
21/02/17 01:42:08 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
21/02/17 01:42:08 INFO FileOutputCommitter: Saved output of task 'attempt_20210217014208_0068_m_000000_0' to file:/tmp/RtmpzND6YJ/file230be61cffde9/stages/0_r_formula__ae8e0faf_6bf9_456d_bc45_2aca30f7aea4/pipelineModel/stages/0_r_formula__ae8e0faf_6bf9_456d_bc45_2aca30f7aea4/metadata
21/02/17 01:42:08 INFO SparkHadoopMapRedUtil: attempt_20210217014208_0068_m_000000_0: Committed
21/02/17 01:42:08 INFO Executor: Finished task 0.0 in stage 19.0 (TID 19). 1158 bytes result sent to driver
21/02/17 01:42:08 INFO TaskSetManager: Finished task 0.0 in stage 19.0 (TID 19) in 21 ms on localhost (executor driver) (1/1)
21/02/17 01:42:08 INFO TaskSchedulerImpl: Removed TaskSet 19.0, whose tasks have all completed, from pool 
21/02/17 01:42:08 INFO DAGScheduler: ResultStage 19 (runJob at SparkHadoopWriter.scala:78) finished in 0.036 s
21/02/17 01:42:08 INFO DAGScheduler: Job 15 is finished. Cancelling potential speculative or zombie tasks for this job
21/02/17 01:42:08 INFO TaskSchedulerImpl: Killing all running tasks in stage 19: Stage finished
21/02/17 01:42:08 INFO DAGScheduler: Job 15 finished: runJob at SparkHadoopWriter.scala:78, took 0.038926 s
21/02/17 01:42:08 INFO SparkHadoopWriter: Job job_20210217014208_0068 committed.
21/02/17 01:42:08 INFO HadoopMapRedCommitProtocol: Using output committer class org.apache.hadoop.mapred.FileOutputCommitter
21/02/17 01:42:08 INFO FileOutputCommitter: File Output Committer Algorithm version is 2
21/02/17 01:42:08 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
21/02/17 01:42:08 INFO SparkContext: Starting job: runJob at SparkHadoopWriter.scala:78
21/02/17 01:42:08 INFO DAGScheduler: Got job 16 (runJob at SparkHadoopWriter.scala:78) with 1 output partitions
21/02/17 01:42:08 INFO DAGScheduler: Final stage: ResultStage 20 (runJob at SparkHadoopWriter.scala:78)
21/02/17 01:42:08 INFO DAGScheduler: Parents of final stage: List()
21/02/17 01:42:08 INFO DAGScheduler: Missing parents: List()
21/02/17 01:42:08 INFO DAGScheduler: Submitting ResultStage 20 (MapPartitionsRDD[70] at saveAsTextFile at ReadWrite.scala:413), which has no missing parents
21/02/17 01:42:08 INFO MemoryStore: Block broadcast_21 stored as values in memory (estimated size 84.1 KiB, free 911.8 MiB)
21/02/17 01:42:08 INFO MemoryStore: Block broadcast_21_piece0 stored as bytes in memory (estimated size 30.0 KiB, free 911.7 MiB)
21/02/17 01:42:08 INFO BlockManagerInfo: Added broadcast_21_piece0 in memory on localhost:42591 (size: 30.0 KiB, free: 912.1 MiB)
21/02/17 01:42:08 INFO SparkContext: Created broadcast 21 from broadcast at DAGScheduler.scala:1200
21/02/17 01:42:08 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 20 (MapPartitionsRDD[70] at saveAsTextFile at ReadWrite.scala:413) (first 15 tasks are for partitions Vector(0))
21/02/17 01:42:08 INFO TaskSchedulerImpl: Adding task set 20.0 with 1 tasks
21/02/17 01:42:08 INFO TaskSetManager: Starting task 0.0 in stage 20.0 (TID 20, localhost, executor driver, partition 0, PROCESS_LOCAL, 7539 bytes)
21/02/17 01:42:08 INFO Executor: Running task 0.0 in stage 20.0 (TID 20)
21/02/17 01:42:08 INFO HadoopMapRedCommitProtocol: Using output committer class org.apache.hadoop.mapred.FileOutputCommitter
21/02/17 01:42:08 INFO FileOutputCommitter: File Output Committer Algorithm version is 2
21/02/17 01:42:08 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
21/02/17 01:42:08 INFO FileOutputCommitter: Saved output of task 'attempt_20210217014208_0070_m_000000_0' to file:/tmp/RtmpzND6YJ/file230be61cffde9/stages/0_r_formula__ae8e0faf_6bf9_456d_bc45_2aca30f7aea4/pipelineModel/stages/1_vectorAttrRewriter_20c63bd9776a/metadata
21/02/17 01:42:08 INFO SparkHadoopMapRedUtil: attempt_20210217014208_0070_m_000000_0: Committed
21/02/17 01:42:08 INFO Executor: Finished task 0.0 in stage 20.0 (TID 20). 1158 bytes result sent to driver
21/02/17 01:42:08 INFO TaskSetManager: Finished task 0.0 in stage 20.0 (TID 20) in 22 ms on localhost (executor driver) (1/1)
21/02/17 01:42:08 INFO TaskSchedulerImpl: Removed TaskSet 20.0, whose tasks have all completed, from pool 
21/02/17 01:42:08 INFO DAGScheduler: ResultStage 20 (runJob at SparkHadoopWriter.scala:78) finished in 0.031 s
21/02/17 01:42:08 INFO DAGScheduler: Job 16 is finished. Cancelling potential speculative or zombie tasks for this job
21/02/17 01:42:08 INFO TaskSchedulerImpl: Killing all running tasks in stage 20: Stage finished
21/02/17 01:42:08 INFO DAGScheduler: Job 16 finished: runJob at SparkHadoopWriter.scala:78, took 0.034228 s
21/02/17 01:42:08 INFO SparkHadoopWriter: Job job_20210217014208_0070 committed.
21/02/17 01:42:08 INFO ParquetFileFormat: Using default output committer for Parquet: org.apache.parquet.hadoop.ParquetOutputCommitter
21/02/17 01:42:08 INFO FileOutputCommitter: File Output Committer Algorithm version is 2
21/02/17 01:42:08 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
21/02/17 01:42:08 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
21/02/17 01:42:08 INFO FileOutputCommitter: File Output Committer Algorithm version is 2
21/02/17 01:42:08 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
21/02/17 01:42:08 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
21/02/17 01:42:08 INFO CodeGenerator: Code generated in 12.294028 ms
21/02/17 01:42:08 INFO SparkContext: Starting job: parquet at RFormula.scala:599
21/02/17 01:42:08 INFO DAGScheduler: Registering RDD 73 (parquet at RFormula.scala:599) as input to shuffle 5
21/02/17 01:42:08 INFO DAGScheduler: Got job 17 (parquet at RFormula.scala:599) with 1 output partitions
21/02/17 01:42:08 INFO DAGScheduler: Final stage: ResultStage 22 (parquet at RFormula.scala:599)
21/02/17 01:42:08 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 21)
21/02/17 01:42:08 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 21)
21/02/17 01:42:08 INFO DAGScheduler: Submitting ShuffleMapStage 21 (MapPartitionsRDD[73] at parquet at RFormula.scala:599), which has no missing parents
21/02/17 01:42:08 INFO MemoryStore: Block broadcast_22 stored as values in memory (estimated size 7.7 KiB, free 911.7 MiB)
21/02/17 01:42:08 INFO MemoryStore: Block broadcast_22_piece0 stored as bytes in memory (estimated size 4.2 KiB, free 911.7 MiB)
21/02/17 01:42:08 INFO BlockManagerInfo: Added broadcast_22_piece0 in memory on localhost:42591 (size: 4.2 KiB, free: 912.1 MiB)
21/02/17 01:42:08 INFO SparkContext: Created broadcast 22 from broadcast at DAGScheduler.scala:1200
21/02/17 01:42:08 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 21 (MapPartitionsRDD[73] at parquet at RFormula.scala:599) (first 15 tasks are for partitions Vector(0))
21/02/17 01:42:08 INFO TaskSchedulerImpl: Adding task set 21.0 with 1 tasks
21/02/17 01:42:08 INFO TaskSetManager: Starting task 0.0 in stage 21.0 (TID 21, localhost, executor driver, partition 0, PROCESS_LOCAL, 7554 bytes)
21/02/17 01:42:08 INFO Executor: Running task 0.0 in stage 21.0 (TID 21)
21/02/17 01:42:08 INFO Executor: Finished task 0.0 in stage 21.0 (TID 21). 1614 bytes result sent to driver
21/02/17 01:42:08 INFO TaskSetManager: Finished task 0.0 in stage 21.0 (TID 21) in 10 ms on localhost (executor driver) (1/1)
21/02/17 01:42:08 INFO TaskSchedulerImpl: Removed TaskSet 21.0, whose tasks have all completed, from pool 
21/02/17 01:42:08 INFO DAGScheduler: ShuffleMapStage 21 (parquet at RFormula.scala:599) finished in 0.015 s
21/02/17 01:42:08 INFO DAGScheduler: looking for newly runnable stages
21/02/17 01:42:08 INFO DAGScheduler: running: Set()
21/02/17 01:42:08 INFO DAGScheduler: waiting: Set(ResultStage 22)
21/02/17 01:42:08 INFO DAGScheduler: failed: Set()
21/02/17 01:42:08 INFO DAGScheduler: Submitting ResultStage 22 (ShuffledRowRDD[74] at parquet at RFormula.scala:599), which has no missing parents
21/02/17 01:42:08 INFO MemoryStore: Block broadcast_23 stored as values in memory (estimated size 177.6 KiB, free 911.5 MiB)
21/02/17 01:42:08 INFO MemoryStore: Block broadcast_23_piece0 stored as bytes in memory (estimated size 62.2 KiB, free 911.5 MiB)
21/02/17 01:42:08 INFO BlockManagerInfo: Added broadcast_23_piece0 in memory on localhost:42591 (size: 62.2 KiB, free: 912.1 MiB)
21/02/17 01:42:08 INFO SparkContext: Created broadcast 23 from broadcast at DAGScheduler.scala:1200
21/02/17 01:42:08 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 22 (ShuffledRowRDD[74] at parquet at RFormula.scala:599) (first 15 tasks are for partitions Vector(0))
21/02/17 01:42:08 INFO TaskSchedulerImpl: Adding task set 22.0 with 1 tasks
21/02/17 01:42:08 INFO TaskSetManager: Starting task 0.0 in stage 22.0 (TID 22, localhost, executor driver, partition 0, NODE_LOCAL, 7325 bytes)
21/02/17 01:42:08 INFO Executor: Running task 0.0 in stage 22.0 (TID 22)
21/02/17 01:42:08 INFO ShuffleBlockFetcherIterator: Getting 1 (88.0 B) non-empty blocks including 1 (88.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
21/02/17 01:42:08 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
21/02/17 01:42:08 INFO FileOutputCommitter: File Output Committer Algorithm version is 2
21/02/17 01:42:08 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
21/02/17 01:42:08 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
21/02/17 01:42:08 INFO FileOutputCommitter: File Output Committer Algorithm version is 2
21/02/17 01:42:08 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
21/02/17 01:42:08 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
21/02/17 01:42:08 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:
{
  "type" : "struct",
  "fields" : [ {
    "name" : "vectorCol",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "prefixesToRewrite",
    "type" : {
      "type" : "map",
      "keyType" : "string",
      "valueType" : "string",
      "valueContainsNull" : true
    },
    "nullable" : true,
    "metadata" : { }
  } ]
}
and corresponding Parquet message type:
message spark_schema {
  optional binary vectorCol (UTF8);
  optional group prefixesToRewrite (MAP) {
    repeated group key_value {
      required binary key (UTF8);
      optional binary value (UTF8);
    }
  }
}

       
21/02/17 01:42:08 INFO FileOutputCommitter: Saved output of task 'attempt_20210217014208_0022_m_000000_22' to file:/tmp/RtmpzND6YJ/file230be61cffde9/stages/0_r_formula__ae8e0faf_6bf9_456d_bc45_2aca30f7aea4/pipelineModel/stages/1_vectorAttrRewriter_20c63bd9776a/data
21/02/17 01:42:08 INFO SparkHadoopMapRedUtil: attempt_20210217014208_0022_m_000000_22: Committed
21/02/17 01:42:08 INFO Executor: Finished task 0.0 in stage 22.0 (TID 22). 3195 bytes result sent to driver
21/02/17 01:42:08 INFO TaskSetManager: Finished task 0.0 in stage 22.0 (TID 22) in 42 ms on localhost (executor driver) (1/1)
21/02/17 01:42:08 INFO TaskSchedulerImpl: Removed TaskSet 22.0, whose tasks have all completed, from pool 
21/02/17 01:42:08 INFO DAGScheduler: ResultStage 22 (parquet at RFormula.scala:599) finished in 0.068 s
21/02/17 01:42:08 INFO DAGScheduler: Job 17 is finished. Cancelling potential speculative or zombie tasks for this job
21/02/17 01:42:08 INFO TaskSchedulerImpl: Killing all running tasks in stage 22: Stage finished
21/02/17 01:42:08 INFO DAGScheduler: Job 17 finished: parquet at RFormula.scala:599, took 0.088069 s
21/02/17 01:42:08 INFO FileFormatWriter: Write Job 7151bd0f-1e7a-4904-8c27-a2a64efc90e7 committed.
21/02/17 01:42:08 INFO FileFormatWriter: Finished processing stats for write job 7151bd0f-1e7a-4904-8c27-a2a64efc90e7.
21/02/17 01:42:08 INFO HadoopMapRedCommitProtocol: Using output committer class org.apache.hadoop.mapred.FileOutputCommitter
21/02/17 01:42:08 INFO FileOutputCommitter: File Output Committer Algorithm version is 2
21/02/17 01:42:08 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
21/02/17 01:42:08 INFO SparkContext: Starting job: runJob at SparkHadoopWriter.scala:78
21/02/17 01:42:08 INFO DAGScheduler: Got job 18 (runJob at SparkHadoopWriter.scala:78) with 1 output partitions
21/02/17 01:42:08 INFO DAGScheduler: Final stage: ResultStage 23 (runJob at SparkHadoopWriter.scala:78)
21/02/17 01:42:08 INFO DAGScheduler: Parents of final stage: List()
21/02/17 01:42:08 INFO DAGScheduler: Missing parents: List()
21/02/17 01:42:08 INFO DAGScheduler: Submitting ResultStage 23 (MapPartitionsRDD[78] at saveAsTextFile at ReadWrite.scala:413), which has no missing parents
21/02/17 01:42:08 INFO MemoryStore: Block broadcast_24 stored as values in memory (estimated size 84.1 KiB, free 911.4 MiB)
21/02/17 01:42:08 INFO MemoryStore: Block broadcast_24_piece0 stored as bytes in memory (estimated size 30.0 KiB, free 911.4 MiB)
21/02/17 01:42:08 INFO BlockManagerInfo: Added broadcast_24_piece0 in memory on localhost:42591 (size: 30.0 KiB, free: 912.1 MiB)
21/02/17 01:42:08 INFO SparkContext: Created broadcast 24 from broadcast at DAGScheduler.scala:1200
21/02/17 01:42:08 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 23 (MapPartitionsRDD[78] at saveAsTextFile at ReadWrite.scala:413) (first 15 tasks are for partitions Vector(0))
21/02/17 01:42:08 INFO TaskSchedulerImpl: Adding task set 23.0 with 1 tasks
21/02/17 01:42:08 INFO TaskSetManager: Starting task 0.0 in stage 23.0 (TID 23, localhost, executor driver, partition 0, PROCESS_LOCAL, 7522 bytes)
21/02/17 01:42:08 INFO Executor: Running task 0.0 in stage 23.0 (TID 23)
21/02/17 01:42:08 INFO HadoopMapRedCommitProtocol: Using output committer class org.apache.hadoop.mapred.FileOutputCommitter
21/02/17 01:42:08 INFO FileOutputCommitter: File Output Committer Algorithm version is 2
21/02/17 01:42:08 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
21/02/17 01:42:08 INFO FileOutputCommitter: Saved output of task 'attempt_20210217014208_0078_m_000000_0' to file:/tmp/RtmpzND6YJ/file230be61cffde9/stages/0_r_formula__ae8e0faf_6bf9_456d_bc45_2aca30f7aea4/pipelineModel/stages/2_columnPruner_78c00bc6a66f/metadata
21/02/17 01:42:08 INFO SparkHadoopMapRedUtil: attempt_20210217014208_0078_m_000000_0: Committed
21/02/17 01:42:08 INFO Executor: Finished task 0.0 in stage 23.0 (TID 23). 1158 bytes result sent to driver
21/02/17 01:42:08 INFO TaskSetManager: Finished task 0.0 in stage 23.0 (TID 23) in 18 ms on localhost (executor driver) (1/1)
21/02/17 01:42:08 INFO TaskSchedulerImpl: Removed TaskSet 23.0, whose tasks have all completed, from pool 
21/02/17 01:42:08 INFO DAGScheduler: ResultStage 23 (runJob at SparkHadoopWriter.scala:78) finished in 0.029 s
21/02/17 01:42:08 INFO DAGScheduler: Job 18 is finished. Cancelling potential speculative or zombie tasks for this job
21/02/17 01:42:08 INFO TaskSchedulerImpl: Killing all running tasks in stage 23: Stage finished
21/02/17 01:42:08 INFO DAGScheduler: Job 18 finished: runJob at SparkHadoopWriter.scala:78, took 0.030919 s
21/02/17 01:42:08 INFO SparkHadoopWriter: Job job_20210217014208_0078 committed.
21/02/17 01:42:08 INFO ParquetFileFormat: Using default output committer for Parquet: org.apache.parquet.hadoop.ParquetOutputCommitter
21/02/17 01:42:08 INFO FileOutputCommitter: File Output Committer Algorithm version is 2
21/02/17 01:42:08 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
21/02/17 01:42:08 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
21/02/17 01:42:08 INFO FileOutputCommitter: File Output Committer Algorithm version is 2
21/02/17 01:42:08 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
21/02/17 01:42:08 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
21/02/17 01:42:08 INFO CodeGenerator: Code generated in 7.11395 ms
21/02/17 01:42:08 INFO SparkContext: Starting job: parquet at RFormula.scala:508
21/02/17 01:42:08 INFO DAGScheduler: Registering RDD 81 (parquet at RFormula.scala:508) as input to shuffle 6
21/02/17 01:42:08 INFO DAGScheduler: Got job 19 (parquet at RFormula.scala:508) with 1 output partitions
21/02/17 01:42:08 INFO DAGScheduler: Final stage: ResultStage 25 (parquet at RFormula.scala:508)
21/02/17 01:42:08 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 24)
21/02/17 01:42:08 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 24)
21/02/17 01:42:08 INFO DAGScheduler: Submitting ShuffleMapStage 24 (MapPartitionsRDD[81] at parquet at RFormula.scala:508), which has no missing parents
21/02/17 01:42:08 INFO MemoryStore: Block broadcast_25 stored as values in memory (estimated size 7.6 KiB, free 911.4 MiB)
21/02/17 01:42:08 INFO MemoryStore: Block broadcast_25_piece0 stored as bytes in memory (estimated size 4.1 KiB, free 911.4 MiB)
21/02/17 01:42:08 INFO BlockManagerInfo: Added broadcast_25_piece0 in memory on localhost:42591 (size: 4.1 KiB, free: 912.0 MiB)
21/02/17 01:42:08 INFO SparkContext: Created broadcast 25 from broadcast at DAGScheduler.scala:1200
21/02/17 01:42:08 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 24 (MapPartitionsRDD[81] at parquet at RFormula.scala:508) (first 15 tasks are for partitions Vector(0))
21/02/17 01:42:08 INFO TaskSchedulerImpl: Adding task set 24.0 with 1 tasks
21/02/17 01:42:08 INFO TaskSetManager: Starting task 0.0 in stage 24.0 (TID 24, localhost, executor driver, partition 0, PROCESS_LOCAL, 7522 bytes)
21/02/17 01:42:08 INFO Executor: Running task 0.0 in stage 24.0 (TID 24)
21/02/17 01:42:08 INFO Executor: Finished task 0.0 in stage 24.0 (TID 24). 1614 bytes result sent to driver
21/02/17 01:42:08 INFO TaskSetManager: Finished task 0.0 in stage 24.0 (TID 24) in 5 ms on localhost (executor driver) (1/1)
21/02/17 01:42:08 INFO TaskSchedulerImpl: Removed TaskSet 24.0, whose tasks have all completed, from pool 
21/02/17 01:42:08 INFO DAGScheduler: ShuffleMapStage 24 (parquet at RFormula.scala:508) finished in 0.010 s
21/02/17 01:42:08 INFO DAGScheduler: looking for newly runnable stages
21/02/17 01:42:08 INFO DAGScheduler: running: Set()
21/02/17 01:42:08 INFO DAGScheduler: waiting: Set(ResultStage 25)
21/02/17 01:42:08 INFO DAGScheduler: failed: Set()
21/02/17 01:42:08 INFO DAGScheduler: Submitting ResultStage 25 (ShuffledRowRDD[82] at parquet at RFormula.scala:508), which has no missing parents
21/02/17 01:42:08 INFO MemoryStore: Block broadcast_26 stored as values in memory (estimated size 177.4 KiB, free 911.2 MiB)
21/02/17 01:42:08 INFO MemoryStore: Block broadcast_26_piece0 stored as bytes in memory (estimated size 62.0 KiB, free 911.1 MiB)
21/02/17 01:42:08 INFO BlockManagerInfo: Added broadcast_26_piece0 in memory on localhost:42591 (size: 62.0 KiB, free: 912.0 MiB)
21/02/17 01:42:08 INFO SparkContext: Created broadcast 26 from broadcast at DAGScheduler.scala:1200
21/02/17 01:42:08 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 25 (ShuffledRowRDD[82] at parquet at RFormula.scala:508) (first 15 tasks are for partitions Vector(0))
21/02/17 01:42:08 INFO TaskSchedulerImpl: Adding task set 25.0 with 1 tasks
21/02/17 01:42:08 INFO TaskSetManager: Starting task 0.0 in stage 25.0 (TID 25, localhost, executor driver, partition 0, NODE_LOCAL, 7325 bytes)
21/02/17 01:42:08 INFO Executor: Running task 0.0 in stage 25.0 (TID 25)
21/02/17 01:42:08 INFO ShuffleBlockFetcherIterator: Getting 1 (72.0 B) non-empty blocks including 1 (72.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
21/02/17 01:42:08 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
21/02/17 01:42:08 INFO FileOutputCommitter: File Output Committer Algorithm version is 2
21/02/17 01:42:08 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
21/02/17 01:42:08 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
21/02/17 01:42:08 INFO FileOutputCommitter: File Output Committer Algorithm version is 2
21/02/17 01:42:08 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
21/02/17 01:42:08 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
21/02/17 01:42:08 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:
{
  "type" : "struct",
  "fields" : [ {
    "name" : "columnsToPrune",
    "type" : {
      "type" : "array",
      "elementType" : "string",
      "containsNull" : true
    },
    "nullable" : true,
    "metadata" : { }
  } ]
}
and corresponding Parquet message type:
message spark_schema {
  optional group columnsToPrune (LIST) {
    repeated group list {
      optional binary element (UTF8);
    }
  }
}

       
21/02/17 01:42:08 INFO FileOutputCommitter: Saved output of task 'attempt_20210217014208_0025_m_000000_25' to file:/tmp/RtmpzND6YJ/file230be61cffde9/stages/0_r_formula__ae8e0faf_6bf9_456d_bc45_2aca30f7aea4/pipelineModel/stages/2_columnPruner_78c00bc6a66f/data
21/02/17 01:42:08 INFO SparkHadoopMapRedUtil: attempt_20210217014208_0025_m_000000_25: Committed
21/02/17 01:42:08 INFO Executor: Finished task 0.0 in stage 25.0 (TID 25). 3195 bytes result sent to driver
21/02/17 01:42:08 INFO TaskSetManager: Finished task 0.0 in stage 25.0 (TID 25) in 25 ms on localhost (executor driver) (1/1)
21/02/17 01:42:08 INFO TaskSchedulerImpl: Removed TaskSet 25.0, whose tasks have all completed, from pool 
21/02/17 01:42:08 INFO DAGScheduler: ResultStage 25 (parquet at RFormula.scala:508) finished in 0.045 s
21/02/17 01:42:08 INFO DAGScheduler: Job 19 is finished. Cancelling potential speculative or zombie tasks for this job
21/02/17 01:42:08 INFO TaskSchedulerImpl: Killing all running tasks in stage 25: Stage finished
21/02/17 01:42:08 INFO DAGScheduler: Job 19 finished: parquet at RFormula.scala:508, took 0.058667 s
21/02/17 01:42:08 INFO FileFormatWriter: Write Job b0c9845b-b63b-4d4b-889d-5cd6c6065bf2 committed.
21/02/17 01:42:08 INFO FileFormatWriter: Finished processing stats for write job b0c9845b-b63b-4d4b-889d-5cd6c6065bf2.
21/02/17 01:42:08 INFO Instrumentation: [9b86a5aa] training finished
21/02/17 01:42:08 INFO Instrumentation: [e987b631] training finished
21/02/17 01:42:08 INFO HadoopMapRedCommitProtocol: Using output committer class org.apache.hadoop.mapred.FileOutputCommitter
21/02/17 01:42:08 INFO FileOutputCommitter: File Output Committer Algorithm version is 2
21/02/17 01:42:08 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
21/02/17 01:42:08 INFO SparkContext: Starting job: runJob at SparkHadoopWriter.scala:78
21/02/17 01:42:08 INFO DAGScheduler: Got job 20 (runJob at SparkHadoopWriter.scala:78) with 1 output partitions
21/02/17 01:42:08 INFO DAGScheduler: Final stage: ResultStage 26 (runJob at SparkHadoopWriter.scala:78)
21/02/17 01:42:08 INFO DAGScheduler: Parents of final stage: List()
21/02/17 01:42:08 INFO DAGScheduler: Missing parents: List()
21/02/17 01:42:08 INFO DAGScheduler: Submitting ResultStage 26 (MapPartitionsRDD[86] at saveAsTextFile at DefaultXGBoostParamsWriter.scala:52), which has no missing parents
21/02/17 01:42:08 INFO MemoryStore: Block broadcast_27 stored as values in memory (estimated size 84.0 KiB, free 911.0 MiB)
21/02/17 01:42:08 INFO MemoryStore: Block broadcast_27_piece0 stored as bytes in memory (estimated size 30.0 KiB, free 911.0 MiB)
21/02/17 01:42:08 INFO BlockManagerInfo: Added broadcast_27_piece0 in memory on localhost:42591 (size: 30.0 KiB, free: 912.0 MiB)
21/02/17 01:42:08 INFO SparkContext: Created broadcast 27 from broadcast at DAGScheduler.scala:1200
21/02/17 01:42:08 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 26 (MapPartitionsRDD[86] at saveAsTextFile at DefaultXGBoostParamsWriter.scala:52) (first 15 tasks are for partitions Vector(0))
21/02/17 01:42:08 INFO TaskSchedulerImpl: Adding task set 26.0 with 1 tasks
21/02/17 01:42:08 INFO TaskSetManager: Starting task 0.0 in stage 26.0 (TID 26, localhost, executor driver, partition 0, PROCESS_LOCAL, 8635 bytes)
21/02/17 01:42:08 INFO Executor: Running task 0.0 in stage 26.0 (TID 26)
21/02/17 01:42:08 INFO HadoopMapRedCommitProtocol: Using output committer class org.apache.hadoop.mapred.FileOutputCommitter
21/02/17 01:42:08 INFO FileOutputCommitter: File Output Committer Algorithm version is 2
21/02/17 01:42:08 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
21/02/17 01:42:08 INFO FileOutputCommitter: Saved output of task 'attempt_20210217014208_0086_m_000000_0' to file:/tmp/RtmpzND6YJ/file230be61cffde9/stages/1_xgboost_regressor__540d2dbb_07f3_4ca0_b88c_803ab842d259/metadata
21/02/17 01:42:08 INFO SparkHadoopMapRedUtil: attempt_20210217014208_0086_m_000000_0: Committed
21/02/17 01:42:08 INFO Executor: Finished task 0.0 in stage 26.0 (TID 26). 1158 bytes result sent to driver
21/02/17 01:42:08 INFO TaskSetManager: Finished task 0.0 in stage 26.0 (TID 26) in 14 ms on localhost (executor driver) (1/1)
21/02/17 01:42:08 INFO TaskSchedulerImpl: Removed TaskSet 26.0, whose tasks have all completed, from pool 
21/02/17 01:42:08 INFO DAGScheduler: ResultStage 26 (runJob at SparkHadoopWriter.scala:78) finished in 0.024 s
21/02/17 01:42:08 INFO DAGScheduler: Job 20 is finished. Cancelling potential speculative or zombie tasks for this job
21/02/17 01:42:08 INFO TaskSchedulerImpl: Killing all running tasks in stage 26: Stage finished
21/02/17 01:42:08 INFO DAGScheduler: Job 20 finished: runJob at SparkHadoopWriter.scala:78, took 0.026323 s
21/02/17 01:42:08 INFO SparkHadoopWriter: Job job_20210217014208_0086 committed.
21/02/17 01:42:08 INFO Instrumentation: [989ebcaa] training finished
21/02/17 01:42:08 INFO Instrumentation: [78b19d54] training finished
21/02/17 01:42:09 INFO HiveMetaStore: 0: get_database: default
21/02/17 01:42:09 INFO audit: ugi=yitaoli	ip=unknown-ip-addr	cmd=get_database: default	
21/02/17 01:42:09 INFO HiveMetaStore: 0: get_database: default
21/02/17 01:42:09 INFO audit: ugi=yitaoli	ip=unknown-ip-addr	cmd=get_database: default	
21/02/17 01:42:09 INFO HiveMetaStore: 0: get_tables: db=default pat=*
21/02/17 01:42:09 INFO audit: ugi=yitaoli	ip=unknown-ip-addr	cmd=get_tables: db=default pat=*	
21/02/17 01:42:09 INFO CodeGenerator: Code generated in 4.392451 ms
21/02/17 01:42:09 INFO SparkContext: Starting job: collect at utils.scala:54
21/02/17 01:42:09 INFO DAGScheduler: Got job 21 (collect at utils.scala:54) with 2 output partitions
21/02/17 01:42:09 INFO DAGScheduler: Final stage: ResultStage 27 (collect at utils.scala:54)
21/02/17 01:42:09 INFO DAGScheduler: Parents of final stage: List()
21/02/17 01:42:09 INFO DAGScheduler: Missing parents: List()
21/02/17 01:42:09 INFO DAGScheduler: Submitting ResultStage 27 (MapPartitionsRDD[92] at map at utils.scala:54), which has no missing parents
21/02/17 01:42:09 INFO MemoryStore: Block broadcast_28 stored as values in memory (estimated size 12.0 KiB, free 911.0 MiB)
21/02/17 01:42:09 INFO MemoryStore: Block broadcast_28_piece0 stored as bytes in memory (estimated size 5.1 KiB, free 911.0 MiB)
21/02/17 01:42:09 INFO BlockManagerInfo: Added broadcast_28_piece0 in memory on localhost:42591 (size: 5.1 KiB, free: 912.0 MiB)
21/02/17 01:42:09 INFO SparkContext: Created broadcast 28 from broadcast at DAGScheduler.scala:1200
21/02/17 01:42:09 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 27 (MapPartitionsRDD[92] at map at utils.scala:54) (first 15 tasks are for partitions Vector(0, 1))
21/02/17 01:42:09 INFO TaskSchedulerImpl: Adding task set 27.0 with 2 tasks
21/02/17 01:42:09 INFO TaskSetManager: Starting task 0.0 in stage 27.0 (TID 27, localhost, executor driver, partition 0, PROCESS_LOCAL, 7533 bytes)
21/02/17 01:42:09 INFO TaskSetManager: Starting task 1.0 in stage 27.0 (TID 28, localhost, executor driver, partition 1, PROCESS_LOCAL, 7581 bytes)
21/02/17 01:42:09 INFO Executor: Running task 0.0 in stage 27.0 (TID 27)
21/02/17 01:42:09 INFO Executor: Running task 1.0 in stage 27.0 (TID 28)
21/02/17 01:42:09 INFO CodeGenerator: Code generated in 5.590712 ms
21/02/17 01:42:09 INFO Executor: Finished task 0.0 in stage 27.0 (TID 27). 1110 bytes result sent to driver
21/02/17 01:42:09 INFO Executor: Finished task 1.0 in stage 27.0 (TID 28). 1155 bytes result sent to driver
21/02/17 01:42:09 INFO TaskSetManager: Finished task 0.0 in stage 27.0 (TID 27) in 28 ms on localhost (executor driver) (1/2)
21/02/17 01:42:09 INFO TaskSetManager: Finished task 1.0 in stage 27.0 (TID 28) in 28 ms on localhost (executor driver) (2/2)
21/02/17 01:42:09 INFO TaskSchedulerImpl: Removed TaskSet 27.0, whose tasks have all completed, from pool 
21/02/17 01:42:09 INFO DAGScheduler: ResultStage 27 (collect at utils.scala:54) finished in 0.033 s
21/02/17 01:42:09 INFO DAGScheduler: Job 21 is finished. Cancelling potential speculative or zombie tasks for this job
21/02/17 01:42:09 INFO TaskSchedulerImpl: Killing all running tasks in stage 27: Stage finished
21/02/17 01:42:09 INFO DAGScheduler: Job 21 finished: collect at utils.scala:54, took 0.035973 s
21/02/17 01:42:09 INFO InMemoryFileIndex: It took 8 ms to list leaf files for 1 paths.
21/02/17 01:42:09 INFO InMemoryFileIndex: It took 0 ms to list leaf files for 1 paths.
21/02/17 01:42:09 INFO FileSourceStrategy: Pruning directories with: 
21/02/17 01:42:09 INFO FileSourceStrategy: Pushed Filters: 
21/02/17 01:42:09 INFO FileSourceStrategy: Post-Scan Filters: 
21/02/17 01:42:09 INFO FileSourceStrategy: Output Data Schema: struct<value: string>
21/02/17 01:42:09 INFO MemoryStore: Block broadcast_29 stored as values in memory (estimated size 316.4 KiB, free 910.7 MiB)
21/02/17 01:42:09 INFO MemoryStore: Block broadcast_29_piece0 stored as bytes in memory (estimated size 28.9 KiB, free 910.7 MiB)
21/02/17 01:42:09 INFO BlockManagerInfo: Added broadcast_29_piece0 in memory on localhost:42591 (size: 28.9 KiB, free: 911.9 MiB)
21/02/17 01:42:09 INFO SparkContext: Created broadcast 29 from json at NativeMethodAccessorImpl.java:0
21/02/17 01:42:09 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
21/02/17 01:42:09 INFO BlockManagerInfo: Removed broadcast_21_piece0 on localhost:42591 in memory (size: 30.0 KiB, free: 912.0 MiB)
21/02/17 01:42:09 INFO BlockManagerInfo: Removed broadcast_24_piece0 on localhost:42591 in memory (size: 30.0 KiB, free: 912.0 MiB)
21/02/17 01:42:09 INFO BlockManagerInfo: Removed broadcast_27_piece0 on localhost:42591 in memory (size: 30.0 KiB, free: 912.0 MiB)
21/02/17 01:42:09 INFO BlockManagerInfo: Removed broadcast_20_piece0 on localhost:42591 in memory (size: 30.0 KiB, free: 912.0 MiB)
21/02/17 01:42:09 INFO SparkContext: Starting job: json at NativeMethodAccessorImpl.java:0
21/02/17 01:42:09 INFO DAGScheduler: Got job 22 (json at NativeMethodAccessorImpl.java:0) with 1 output partitions
21/02/17 01:42:09 INFO DAGScheduler: Final stage: ResultStage 28 (json at NativeMethodAccessorImpl.java:0)
21/02/17 01:42:09 INFO DAGScheduler: Parents of final stage: List()
21/02/17 01:42:09 INFO DAGScheduler: Missing parents: List()
21/02/17 01:42:09 INFO DAGScheduler: Submitting ResultStage 28 (MapPartitionsRDD[96] at json at NativeMethodAccessorImpl.java:0), which has no missing parents
21/02/17 01:42:09 INFO BlockManagerInfo: Removed broadcast_26_piece0 on localhost:42591 in memory (size: 62.0 KiB, free: 912.1 MiB)
21/02/17 01:42:09 INFO BlockManagerInfo: Removed broadcast_22_piece0 on localhost:42591 in memory (size: 4.2 KiB, free: 912.1 MiB)
21/02/17 01:42:09 INFO BlockManagerInfo: Removed broadcast_23_piece0 on localhost:42591 in memory (size: 62.2 KiB, free: 912.2 MiB)
21/02/17 01:42:09 INFO BlockManagerInfo: Removed broadcast_19_piece0 on localhost:42591 in memory (size: 30.0 KiB, free: 912.2 MiB)
21/02/17 01:42:09 INFO BlockManagerInfo: Removed broadcast_25_piece0 on localhost:42591 in memory (size: 4.1 KiB, free: 912.2 MiB)
21/02/17 01:42:09 INFO MemoryStore: Block broadcast_30 stored as values in memory (estimated size 15.6 KiB, free 911.7 MiB)
21/02/17 01:42:09 INFO BlockManagerInfo: Removed broadcast_28_piece0 on localhost:42591 in memory (size: 5.1 KiB, free: 912.2 MiB)
21/02/17 01:42:09 INFO MemoryStore: Block broadcast_30_piece0 stored as bytes in memory (estimated size 7.0 KiB, free 911.7 MiB)
21/02/17 01:42:09 INFO BlockManagerInfo: Added broadcast_30_piece0 in memory on localhost:42591 (size: 7.0 KiB, free: 912.2 MiB)
21/02/17 01:42:09 INFO SparkContext: Created broadcast 30 from broadcast at DAGScheduler.scala:1200
21/02/17 01:42:09 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 28 (MapPartitionsRDD[96] at json at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
21/02/17 01:42:09 INFO TaskSchedulerImpl: Adding task set 28.0 with 1 tasks
21/02/17 01:42:09 INFO TaskSetManager: Starting task 0.0 in stage 28.0 (TID 29, localhost, executor driver, partition 0, PROCESS_LOCAL, 7757 bytes)
21/02/17 01:42:09 INFO Executor: Running task 0.0 in stage 28.0 (TID 29)
21/02/17 01:42:09 INFO FileScanRDD: Reading File path: file:///tmp/RtmpzND6YJ/file230be61cffde9/metadata/part-00000, range: 0-306, partition values: [empty row]
21/02/17 01:42:09 INFO CodeGenerator: Code generated in 6.597667 ms
21/02/17 01:42:09 INFO Executor: Finished task 0.0 in stage 28.0 (TID 29). 2251 bytes result sent to driver
21/02/17 01:42:09 INFO TaskSetManager: Finished task 0.0 in stage 28.0 (TID 29) in 85 ms on localhost (executor driver) (1/1)
21/02/17 01:42:09 INFO TaskSchedulerImpl: Removed TaskSet 28.0, whose tasks have all completed, from pool 
21/02/17 01:42:09 INFO DAGScheduler: ResultStage 28 (json at NativeMethodAccessorImpl.java:0) finished in 0.096 s
21/02/17 01:42:09 INFO DAGScheduler: Job 22 is finished. Cancelling potential speculative or zombie tasks for this job
21/02/17 01:42:09 INFO TaskSchedulerImpl: Killing all running tasks in stage 28: Stage finished
21/02/17 01:42:09 INFO DAGScheduler: Job 22 finished: json at NativeMethodAccessorImpl.java:0, took 0.101351 s
21/02/17 01:42:09 INFO HiveMetaStore: 0: get_database: default
21/02/17 01:42:09 INFO audit: ugi=yitaoli	ip=unknown-ip-addr	cmd=get_database: default	
21/02/17 01:42:09 INFO HiveMetaStore: 0: get_database: default
21/02/17 01:42:09 INFO audit: ugi=yitaoli	ip=unknown-ip-addr	cmd=get_database: default	
21/02/17 01:42:09 INFO HiveMetaStore: 0: get_tables: db=default pat=*
21/02/17 01:42:09 INFO audit: ugi=yitaoli	ip=unknown-ip-addr	cmd=get_tables: db=default pat=*	
21/02/17 01:42:09 INFO CodeGenerator: Code generated in 5.79585 ms
21/02/17 01:42:09 INFO CodeGenerator: Code generated in 5.042353 ms
21/02/17 01:42:09 INFO CodeGenerator: Code generated in 5.952031 ms
21/02/17 01:42:09 INFO CodeGenerator: Code generated in 4.737131 ms
21/02/17 01:42:09 INFO SparkContext: Starting job: count at utils.scala:135
21/02/17 01:42:09 INFO DAGScheduler: Registering RDD 99 (count at utils.scala:135) as input to shuffle 7
21/02/17 01:42:09 INFO DAGScheduler: Got job 23 (count at utils.scala:135) with 1 output partitions
21/02/17 01:42:09 INFO DAGScheduler: Final stage: ResultStage 30 (count at utils.scala:135)
21/02/17 01:42:09 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 29)
21/02/17 01:42:09 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 29)
21/02/17 01:42:09 INFO DAGScheduler: Submitting ShuffleMapStage 29 (MapPartitionsRDD[99] at count at utils.scala:135), which has no missing parents
21/02/17 01:42:09 INFO MemoryStore: Block broadcast_31 stored as values in memory (estimated size 10.1 KiB, free 911.7 MiB)
21/02/17 01:42:09 INFO MemoryStore: Block broadcast_31_piece0 stored as bytes in memory (estimated size 5.3 KiB, free 911.7 MiB)
21/02/17 01:42:09 INFO BlockManagerInfo: Added broadcast_31_piece0 in memory on localhost:42591 (size: 5.3 KiB, free: 912.2 MiB)
21/02/17 01:42:09 INFO SparkContext: Created broadcast 31 from broadcast at DAGScheduler.scala:1200
21/02/17 01:42:09 INFO DAGScheduler: Submitting 2 missing tasks from ShuffleMapStage 29 (MapPartitionsRDD[99] at count at utils.scala:135) (first 15 tasks are for partitions Vector(0, 1))
21/02/17 01:42:09 INFO TaskSchedulerImpl: Adding task set 29.0 with 2 tasks
21/02/17 01:42:09 INFO TaskSetManager: Starting task 0.0 in stage 29.0 (TID 30, localhost, executor driver, partition 0, PROCESS_LOCAL, 7498 bytes)
21/02/17 01:42:09 INFO TaskSetManager: Starting task 1.0 in stage 29.0 (TID 31, localhost, executor driver, partition 1, PROCESS_LOCAL, 7498 bytes)
21/02/17 01:42:09 INFO Executor: Running task 0.0 in stage 29.0 (TID 30)
21/02/17 01:42:09 INFO Executor: Running task 1.0 in stage 29.0 (TID 31)
21/02/17 01:42:09 INFO Executor: Finished task 0.0 in stage 29.0 (TID 30). 1833 bytes result sent to driver
21/02/17 01:42:09 INFO Executor: Finished task 1.0 in stage 29.0 (TID 31). 1833 bytes result sent to driver
21/02/17 01:42:09 INFO TaskSetManager: Finished task 0.0 in stage 29.0 (TID 30) in 9 ms on localhost (executor driver) (1/2)
21/02/17 01:42:09 INFO TaskSetManager: Finished task 1.0 in stage 29.0 (TID 31) in 8 ms on localhost (executor driver) (2/2)
21/02/17 01:42:09 INFO TaskSchedulerImpl: Removed TaskSet 29.0, whose tasks have all completed, from pool 
21/02/17 01:42:09 INFO DAGScheduler: ShuffleMapStage 29 (count at utils.scala:135) finished in 0.014 s
21/02/17 01:42:09 INFO DAGScheduler: looking for newly runnable stages
21/02/17 01:42:09 INFO DAGScheduler: running: Set()
21/02/17 01:42:09 INFO DAGScheduler: waiting: Set(ResultStage 30)
21/02/17 01:42:09 INFO DAGScheduler: failed: Set()
21/02/17 01:42:09 INFO DAGScheduler: Submitting ResultStage 30 (MapPartitionsRDD[102] at count at utils.scala:135), which has no missing parents
21/02/17 01:42:09 INFO MemoryStore: Block broadcast_32 stored as values in memory (estimated size 10.1 KiB, free 911.7 MiB)
21/02/17 01:42:09 INFO MemoryStore: Block broadcast_32_piece0 stored as bytes in memory (estimated size 5.0 KiB, free 911.7 MiB)
21/02/17 01:42:09 INFO BlockManagerInfo: Added broadcast_32_piece0 in memory on localhost:42591 (size: 5.0 KiB, free: 912.2 MiB)
21/02/17 01:42:09 INFO SparkContext: Created broadcast 32 from broadcast at DAGScheduler.scala:1200
21/02/17 01:42:09 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 30 (MapPartitionsRDD[102] at count at utils.scala:135) (first 15 tasks are for partitions Vector(0))
21/02/17 01:42:09 INFO TaskSchedulerImpl: Adding task set 30.0 with 1 tasks
21/02/17 01:42:09 INFO TaskSetManager: Starting task 0.0 in stage 30.0 (TID 32, localhost, executor driver, partition 0, NODE_LOCAL, 7325 bytes)
21/02/17 01:42:09 INFO Executor: Running task 0.0 in stage 30.0 (TID 32)
21/02/17 01:42:09 INFO ShuffleBlockFetcherIterator: Getting 2 (120.0 B) non-empty blocks including 2 (120.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
21/02/17 01:42:09 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
21/02/17 01:42:09 INFO Executor: Finished task 0.0 in stage 30.0 (TID 32). 2648 bytes result sent to driver
21/02/17 01:42:09 INFO TaskSetManager: Finished task 0.0 in stage 30.0 (TID 32) in 4 ms on localhost (executor driver) (1/1)
21/02/17 01:42:09 INFO TaskSchedulerImpl: Removed TaskSet 30.0, whose tasks have all completed, from pool 
21/02/17 01:42:09 INFO DAGScheduler: ResultStage 30 (count at utils.scala:135) finished in 0.009 s
21/02/17 01:42:09 INFO DAGScheduler: Job 23 is finished. Cancelling potential speculative or zombie tasks for this job
21/02/17 01:42:09 INFO TaskSchedulerImpl: Killing all running tasks in stage 30: Stage finished
21/02/17 01:42:09 INFO DAGScheduler: Job 23 finished: count at utils.scala:135, took 0.025910 s
21/02/17 01:42:09 INFO FileSourceStrategy: Pruning directories with: 
21/02/17 01:42:09 INFO FileSourceStrategy: Pushed Filters: 
21/02/17 01:42:09 INFO FileSourceStrategy: Post-Scan Filters: 
21/02/17 01:42:09 INFO FileSourceStrategy: Output Data Schema: struct<class: string, paramMap: struct<stageUids: array<string>>, sparkVersion: string, timestamp: bigint, uid: string ... 3 more fields>
21/02/17 01:42:09 INFO CodeGenerator: Code generated in 5.852782 ms
21/02/17 01:42:09 INFO MemoryStore: Block broadcast_33 stored as values in memory (estimated size 316.4 KiB, free 911.4 MiB)
21/02/17 01:42:09 INFO MemoryStore: Block broadcast_33_piece0 stored as bytes in memory (estimated size 28.9 KiB, free 911.3 MiB)
21/02/17 01:42:09 INFO BlockManagerInfo: Added broadcast_33_piece0 in memory on localhost:42591 (size: 28.9 KiB, free: 912.2 MiB)
21/02/17 01:42:09 INFO SparkContext: Created broadcast 33 from sql at <unknown>:0
21/02/17 01:42:09 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
21/02/17 01:42:09 INFO SparkContext: Starting job: sql at <unknown>:0
21/02/17 01:42:09 INFO DAGScheduler: Registering RDD 109 (sql at <unknown>:0) as input to shuffle 8
21/02/17 01:42:09 INFO DAGScheduler: Got job 24 (sql at <unknown>:0) with 1 output partitions
21/02/17 01:42:09 INFO DAGScheduler: Final stage: ResultStage 32 (sql at <unknown>:0)
21/02/17 01:42:09 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 31)
21/02/17 01:42:09 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 31)
21/02/17 01:42:09 INFO DAGScheduler: Submitting ShuffleMapStage 31 (MapPartitionsRDD[109] at sql at <unknown>:0), which has no missing parents
21/02/17 01:42:09 INFO MemoryStore: Block broadcast_34 stored as values in memory (estimated size 21.5 KiB, free 911.3 MiB)
21/02/17 01:42:09 INFO MemoryStore: Block broadcast_34_piece0 stored as bytes in memory (estimated size 10.1 KiB, free 911.3 MiB)
21/02/17 01:42:09 INFO BlockManagerInfo: Added broadcast_34_piece0 in memory on localhost:42591 (size: 10.1 KiB, free: 912.2 MiB)
21/02/17 01:42:09 INFO SparkContext: Created broadcast 34 from broadcast at DAGScheduler.scala:1200
21/02/17 01:42:09 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 31 (MapPartitionsRDD[109] at sql at <unknown>:0) (first 15 tasks are for partitions Vector(0))
21/02/17 01:42:09 INFO TaskSchedulerImpl: Adding task set 31.0 with 1 tasks
21/02/17 01:42:09 INFO TaskSetManager: Starting task 0.0 in stage 31.0 (TID 33, localhost, executor driver, partition 0, PROCESS_LOCAL, 7746 bytes)
21/02/17 01:42:09 INFO Executor: Running task 0.0 in stage 31.0 (TID 33)
21/02/17 01:42:09 INFO FileScanRDD: Reading File path: file:///tmp/RtmpzND6YJ/file230be61cffde9/metadata/part-00000, range: 0-306, partition values: [empty row]
21/02/17 01:42:09 INFO CodeGenerator: Code generated in 9.443332 ms
21/02/17 01:42:09 INFO MemoryStore: Block rdd_105_0 stored as values in memory (estimated size 1296.0 B, free 911.3 MiB)
21/02/17 01:42:09 INFO BlockManagerInfo: Added rdd_105_0 in memory on localhost:42591 (size: 1296.0 B, free: 912.1 MiB)
21/02/17 01:42:09 INFO CodeGenerator: Code generated in 11.620652 ms
21/02/17 01:42:09 INFO Executor: Finished task 0.0 in stage 31.0 (TID 33). 2067 bytes result sent to driver
21/02/17 01:42:09 INFO TaskSetManager: Finished task 0.0 in stage 31.0 (TID 33) in 57 ms on localhost (executor driver) (1/1)
21/02/17 01:42:09 INFO TaskSchedulerImpl: Removed TaskSet 31.0, whose tasks have all completed, from pool 
21/02/17 01:42:09 INFO DAGScheduler: ShuffleMapStage 31 (sql at <unknown>:0) finished in 0.066 s
21/02/17 01:42:09 INFO DAGScheduler: looking for newly runnable stages
21/02/17 01:42:09 INFO DAGScheduler: running: Set()
21/02/17 01:42:09 INFO DAGScheduler: waiting: Set(ResultStage 32)
21/02/17 01:42:09 INFO DAGScheduler: failed: Set()
21/02/17 01:42:09 INFO DAGScheduler: Submitting ResultStage 32 (MapPartitionsRDD[112] at sql at <unknown>:0), which has no missing parents
21/02/17 01:42:09 INFO MemoryStore: Block broadcast_35 stored as values in memory (estimated size 10.1 KiB, free 911.3 MiB)
21/02/17 01:42:09 INFO MemoryStore: Block broadcast_35_piece0 stored as bytes in memory (estimated size 5.0 KiB, free 911.3 MiB)
21/02/17 01:42:09 INFO BlockManagerInfo: Added broadcast_35_piece0 in memory on localhost:42591 (size: 5.0 KiB, free: 912.1 MiB)
21/02/17 01:42:09 INFO SparkContext: Created broadcast 35 from broadcast at DAGScheduler.scala:1200
21/02/17 01:42:09 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 32 (MapPartitionsRDD[112] at sql at <unknown>:0) (first 15 tasks are for partitions Vector(0))
21/02/17 01:42:09 INFO TaskSchedulerImpl: Adding task set 32.0 with 1 tasks
21/02/17 01:42:09 INFO TaskSetManager: Starting task 0.0 in stage 32.0 (TID 34, localhost, executor driver, partition 0, NODE_LOCAL, 7325 bytes)
21/02/17 01:42:09 INFO Executor: Running task 0.0 in stage 32.0 (TID 34)
21/02/17 01:42:09 INFO ShuffleBlockFetcherIterator: Getting 1 (60.0 B) non-empty blocks including 1 (60.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
21/02/17 01:42:09 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
21/02/17 01:42:09 INFO Executor: Finished task 0.0 in stage 32.0 (TID 34). 2648 bytes result sent to driver
21/02/17 01:42:09 INFO TaskSetManager: Finished task 0.0 in stage 32.0 (TID 34) in 4 ms on localhost (executor driver) (1/1)
21/02/17 01:42:09 INFO TaskSchedulerImpl: Removed TaskSet 32.0, whose tasks have all completed, from pool 
21/02/17 01:42:09 INFO DAGScheduler: ResultStage 32 (sql at <unknown>:0) finished in 0.009 s
21/02/17 01:42:09 INFO DAGScheduler: Job 24 is finished. Cancelling potential speculative or zombie tasks for this job
21/02/17 01:42:09 INFO TaskSchedulerImpl: Killing all running tasks in stage 32: Stage finished
21/02/17 01:42:09 INFO DAGScheduler: Job 24 finished: sql at <unknown>:0, took 0.078475 s
21/02/17 01:42:09 INFO SparkContext: Starting job: collect at utils.scala:137
21/02/17 01:42:09 INFO DAGScheduler: Registering RDD 116 (collect at utils.scala:137) as input to shuffle 9
21/02/17 01:42:09 INFO DAGScheduler: Got job 25 (collect at utils.scala:137) with 1 output partitions
21/02/17 01:42:09 INFO DAGScheduler: Final stage: ResultStage 34 (collect at utils.scala:137)
21/02/17 01:42:09 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 33)
21/02/17 01:42:09 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 33)
21/02/17 01:42:09 INFO DAGScheduler: Submitting ShuffleMapStage 33 (MapPartitionsRDD[116] at collect at utils.scala:137), which has no missing parents
21/02/17 01:42:09 INFO MemoryStore: Block broadcast_36 stored as values in memory (estimated size 21.5 KiB, free 911.3 MiB)
21/02/17 01:42:09 INFO MemoryStore: Block broadcast_36_piece0 stored as bytes in memory (estimated size 10.1 KiB, free 911.3 MiB)
21/02/17 01:42:09 INFO BlockManagerInfo: Added broadcast_36_piece0 in memory on localhost:42591 (size: 10.1 KiB, free: 912.1 MiB)
21/02/17 01:42:09 INFO SparkContext: Created broadcast 36 from broadcast at DAGScheduler.scala:1200
21/02/17 01:42:09 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 33 (MapPartitionsRDD[116] at collect at utils.scala:137) (first 15 tasks are for partitions Vector(0))
21/02/17 01:42:09 INFO TaskSchedulerImpl: Adding task set 33.0 with 1 tasks
21/02/17 01:42:09 INFO TaskSetManager: Starting task 0.0 in stage 33.0 (TID 35, localhost, executor driver, partition 0, PROCESS_LOCAL, 7746 bytes)
21/02/17 01:42:09 INFO Executor: Running task 0.0 in stage 33.0 (TID 35)
21/02/17 01:42:09 INFO BlockManager: Found block rdd_105_0 locally
21/02/17 01:42:09 INFO Executor: Finished task 0.0 in stage 33.0 (TID 35). 2067 bytes result sent to driver
21/02/17 01:42:09 INFO TaskSetManager: Finished task 0.0 in stage 33.0 (TID 35) in 9 ms on localhost (executor driver) (1/1)
21/02/17 01:42:09 INFO TaskSchedulerImpl: Removed TaskSet 33.0, whose tasks have all completed, from pool 
21/02/17 01:42:09 INFO DAGScheduler: ShuffleMapStage 33 (collect at utils.scala:137) finished in 0.015 s
21/02/17 01:42:09 INFO DAGScheduler: looking for newly runnable stages
21/02/17 01:42:09 INFO DAGScheduler: running: Set()
21/02/17 01:42:09 INFO DAGScheduler: waiting: Set(ResultStage 34)
21/02/17 01:42:09 INFO DAGScheduler: failed: Set()
21/02/17 01:42:09 INFO DAGScheduler: Submitting ResultStage 34 (MapPartitionsRDD[119] at collect at utils.scala:137), which has no missing parents
21/02/17 01:42:09 INFO MemoryStore: Block broadcast_37 stored as values in memory (estimated size 10.1 KiB, free 911.2 MiB)
21/02/17 01:42:09 INFO MemoryStore: Block broadcast_37_piece0 stored as bytes in memory (estimated size 5.0 KiB, free 911.2 MiB)
21/02/17 01:42:09 INFO BlockManagerInfo: Added broadcast_37_piece0 in memory on localhost:42591 (size: 5.0 KiB, free: 912.1 MiB)
21/02/17 01:42:09 INFO SparkContext: Created broadcast 37 from broadcast at DAGScheduler.scala:1200
21/02/17 01:42:09 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 34 (MapPartitionsRDD[119] at collect at utils.scala:137) (first 15 tasks are for partitions Vector(0))
21/02/17 01:42:09 INFO TaskSchedulerImpl: Adding task set 34.0 with 1 tasks
21/02/17 01:42:09 INFO TaskSetManager: Starting task 0.0 in stage 34.0 (TID 36, localhost, executor driver, partition 0, NODE_LOCAL, 7325 bytes)
21/02/17 01:42:09 INFO Executor: Running task 0.0 in stage 34.0 (TID 36)
21/02/17 01:42:09 INFO ShuffleBlockFetcherIterator: Getting 1 (60.0 B) non-empty blocks including 1 (60.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
21/02/17 01:42:09 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
21/02/17 01:42:09 INFO Executor: Finished task 0.0 in stage 34.0 (TID 36). 2648 bytes result sent to driver
21/02/17 01:42:09 INFO TaskSetManager: Finished task 0.0 in stage 34.0 (TID 36) in 6 ms on localhost (executor driver) (1/1)
21/02/17 01:42:09 INFO TaskSchedulerImpl: Removed TaskSet 34.0, whose tasks have all completed, from pool 
21/02/17 01:42:09 INFO DAGScheduler: ResultStage 34 (collect at utils.scala:137) finished in 0.010 s
21/02/17 01:42:09 INFO DAGScheduler: Job 25 is finished. Cancelling potential speculative or zombie tasks for this job
21/02/17 01:42:09 INFO TaskSchedulerImpl: Killing all running tasks in stage 34: Stage finished
21/02/17 01:42:09 INFO DAGScheduler: Job 25 finished: collect at utils.scala:137, took 0.028805 s
21/02/17 01:42:09 INFO CodeGenerator: Code generated in 5.30451 ms
21/02/17 01:42:09 INFO CodeGenerator: Code generated in 8.098106 ms
21/02/17 01:42:10 INFO CodeGenerator: Code generated in 5.039882 ms
21/02/17 01:42:10 INFO SparkContext: Starting job: count at utils.scala:135
21/02/17 01:42:10 INFO DAGScheduler: Registering RDD 123 (count at utils.scala:135) as input to shuffle 10
21/02/17 01:42:10 INFO DAGScheduler: Got job 26 (count at utils.scala:135) with 1 output partitions
21/02/17 01:42:10 INFO DAGScheduler: Final stage: ResultStage 36 (count at utils.scala:135)
21/02/17 01:42:10 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 35)
21/02/17 01:42:10 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 35)
21/02/17 01:42:10 INFO DAGScheduler: Submitting ShuffleMapStage 35 (MapPartitionsRDD[123] at count at utils.scala:135), which has no missing parents
21/02/17 01:42:10 INFO MemoryStore: Block broadcast_38 stored as values in memory (estimated size 20.9 KiB, free 911.2 MiB)
21/02/17 01:42:10 INFO MemoryStore: Block broadcast_38_piece0 stored as bytes in memory (estimated size 9.9 KiB, free 911.2 MiB)
21/02/17 01:42:10 INFO BlockManagerInfo: Added broadcast_38_piece0 in memory on localhost:42591 (size: 9.9 KiB, free: 912.1 MiB)
21/02/17 01:42:10 INFO SparkContext: Created broadcast 38 from broadcast at DAGScheduler.scala:1200
21/02/17 01:42:10 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 35 (MapPartitionsRDD[123] at count at utils.scala:135) (first 15 tasks are for partitions Vector(0))
21/02/17 01:42:10 INFO TaskSchedulerImpl: Adding task set 35.0 with 1 tasks
21/02/17 01:42:10 INFO TaskSetManager: Starting task 0.0 in stage 35.0 (TID 37, localhost, executor driver, partition 0, PROCESS_LOCAL, 7746 bytes)
21/02/17 01:42:10 INFO Executor: Running task 0.0 in stage 35.0 (TID 37)
21/02/17 01:42:10 INFO BlockManager: Found block rdd_105_0 locally
21/02/17 01:42:10 INFO Executor: Finished task 0.0 in stage 35.0 (TID 37). 2067 bytes result sent to driver
21/02/17 01:42:10 INFO TaskSetManager: Finished task 0.0 in stage 35.0 (TID 37) in 10 ms on localhost (executor driver) (1/1)
21/02/17 01:42:10 INFO TaskSchedulerImpl: Removed TaskSet 35.0, whose tasks have all completed, from pool 
21/02/17 01:42:10 INFO DAGScheduler: ShuffleMapStage 35 (count at utils.scala:135) finished in 0.014 s
21/02/17 01:42:10 INFO DAGScheduler: looking for newly runnable stages
21/02/17 01:42:10 INFO DAGScheduler: running: Set()
21/02/17 01:42:10 INFO DAGScheduler: waiting: Set(ResultStage 36)
21/02/17 01:42:10 INFO DAGScheduler: failed: Set()
21/02/17 01:42:10 INFO DAGScheduler: Submitting ResultStage 36 (MapPartitionsRDD[126] at count at utils.scala:135), which has no missing parents
21/02/17 01:42:10 INFO MemoryStore: Block broadcast_39 stored as values in memory (estimated size 12.1 KiB, free 911.2 MiB)
21/02/17 01:42:10 INFO MemoryStore: Block broadcast_39_piece0 stored as bytes in memory (estimated size 5.3 KiB, free 911.2 MiB)
21/02/17 01:42:10 INFO BlockManagerInfo: Added broadcast_39_piece0 in memory on localhost:42591 (size: 5.3 KiB, free: 912.1 MiB)
21/02/17 01:42:10 INFO SparkContext: Created broadcast 39 from broadcast at DAGScheduler.scala:1200
21/02/17 01:42:10 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 36 (MapPartitionsRDD[126] at count at utils.scala:135) (first 15 tasks are for partitions Vector(0))
21/02/17 01:42:10 INFO TaskSchedulerImpl: Adding task set 36.0 with 1 tasks
21/02/17 01:42:10 INFO TaskSetManager: Starting task 0.0 in stage 36.0 (TID 38, localhost, executor driver, partition 0, NODE_LOCAL, 7325 bytes)
21/02/17 01:42:10 INFO Executor: Running task 0.0 in stage 36.0 (TID 38)
21/02/17 01:42:10 INFO ShuffleBlockFetcherIterator: Getting 1 (49.0 B) non-empty blocks including 1 (49.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
21/02/17 01:42:10 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
21/02/17 01:42:10 INFO Executor: Finished task 0.0 in stage 36.0 (TID 38). 2896 bytes result sent to driver
21/02/17 01:42:10 INFO TaskSetManager: Finished task 0.0 in stage 36.0 (TID 38) in 8 ms on localhost (executor driver) (1/1)
21/02/17 01:42:10 INFO TaskSchedulerImpl: Removed TaskSet 36.0, whose tasks have all completed, from pool 
21/02/17 01:42:10 INFO DAGScheduler: ResultStage 36 (count at utils.scala:135) finished in 0.013 s
21/02/17 01:42:10 INFO DAGScheduler: Job 26 is finished. Cancelling potential speculative or zombie tasks for this job
21/02/17 01:42:10 INFO TaskSchedulerImpl: Killing all running tasks in stage 36: Stage finished
21/02/17 01:42:10 INFO DAGScheduler: Job 26 finished: count at utils.scala:135, took 0.030774 s
21/02/17 01:42:10 INFO SparkContext: Starting job: collect at utils.scala:137
21/02/17 01:42:10 INFO DAGScheduler: Got job 27 (collect at utils.scala:137) with 1 output partitions
21/02/17 01:42:10 INFO DAGScheduler: Final stage: ResultStage 37 (collect at utils.scala:137)
21/02/17 01:42:10 INFO DAGScheduler: Parents of final stage: List()
21/02/17 01:42:10 INFO DAGScheduler: Missing parents: List()
21/02/17 01:42:10 INFO DAGScheduler: Submitting ResultStage 37 (MapPartitionsRDD[128] at collect at utils.scala:137), which has no missing parents
21/02/17 01:42:10 INFO MemoryStore: Block broadcast_40 stored as values in memory (estimated size 7.2 KiB, free 911.2 MiB)
21/02/17 01:42:10 INFO MemoryStore: Block broadcast_40_piece0 stored as bytes in memory (estimated size 3.7 KiB, free 911.2 MiB)
21/02/17 01:42:10 INFO BlockManagerInfo: Added broadcast_40_piece0 in memory on localhost:42591 (size: 3.7 KiB, free: 912.1 MiB)
21/02/17 01:42:10 INFO SparkContext: Created broadcast 40 from broadcast at DAGScheduler.scala:1200
21/02/17 01:42:10 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 37 (MapPartitionsRDD[128] at collect at utils.scala:137) (first 15 tasks are for partitions Vector(0))
21/02/17 01:42:10 INFO TaskSchedulerImpl: Adding task set 37.0 with 1 tasks
21/02/17 01:42:10 INFO TaskSetManager: Starting task 0.0 in stage 37.0 (TID 39, localhost, executor driver, partition 0, PROCESS_LOCAL, 7561 bytes)
21/02/17 01:42:10 INFO Executor: Running task 0.0 in stage 37.0 (TID 39)
21/02/17 01:42:10 INFO Executor: Finished task 0.0 in stage 37.0 (TID 39). 1354 bytes result sent to driver
21/02/17 01:42:10 INFO TaskSetManager: Finished task 0.0 in stage 37.0 (TID 39) in 4 ms on localhost (executor driver) (1/1)
21/02/17 01:42:10 INFO TaskSchedulerImpl: Removed TaskSet 37.0, whose tasks have all completed, from pool 
21/02/17 01:42:10 INFO DAGScheduler: ResultStage 37 (collect at utils.scala:137) finished in 0.009 s
21/02/17 01:42:10 INFO DAGScheduler: Job 27 is finished. Cancelling potential speculative or zombie tasks for this job
21/02/17 01:42:10 INFO TaskSchedulerImpl: Killing all running tasks in stage 37: Stage finished
21/02/17 01:42:10 INFO DAGScheduler: Job 27 finished: collect at utils.scala:137, took 0.010692 s
21/02/17 01:42:10 INFO SparkContext: Starting job: count at utils.scala:135
21/02/17 01:42:10 INFO BlockManagerInfo: Removed broadcast_35_piece0 on localhost:42591 in memory (size: 5.0 KiB, free: 912.1 MiB)
21/02/17 01:42:10 INFO DAGScheduler: Registering RDD 130 (count at utils.scala:135) as input to shuffle 11
21/02/17 01:42:10 INFO DAGScheduler: Got job 28 (count at utils.scala:135) with 1 output partitions
21/02/17 01:42:10 INFO DAGScheduler: Final stage: ResultStage 39 (count at utils.scala:135)
21/02/17 01:42:10 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 38)
21/02/17 01:42:10 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 38)
21/02/17 01:42:10 INFO DAGScheduler: Submitting ShuffleMapStage 38 (MapPartitionsRDD[130] at count at utils.scala:135), which has no missing parents
21/02/17 01:42:10 INFO BlockManagerInfo: Removed broadcast_38_piece0 on localhost:42591 in memory (size: 9.9 KiB, free: 912.1 MiB)
21/02/17 01:42:10 INFO MemoryStore: Block broadcast_41 stored as values in memory (estimated size 10.0 KiB, free 911.2 MiB)
21/02/17 01:42:10 INFO BlockManagerInfo: Removed broadcast_37_piece0 on localhost:42591 in memory (size: 5.0 KiB, free: 912.1 MiB)
21/02/17 01:42:10 INFO MemoryStore: Block broadcast_41_piece0 stored as bytes in memory (estimated size 5.2 KiB, free 911.2 MiB)
21/02/17 01:42:10 INFO BlockManagerInfo: Added broadcast_41_piece0 in memory on localhost:42591 (size: 5.2 KiB, free: 912.1 MiB)
21/02/17 01:42:10 INFO SparkContext: Created broadcast 41 from broadcast at DAGScheduler.scala:1200
21/02/17 01:42:10 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 38 (MapPartitionsRDD[130] at count at utils.scala:135) (first 15 tasks are for partitions Vector(0))
21/02/17 01:42:10 INFO TaskSchedulerImpl: Adding task set 38.0 with 1 tasks
21/02/17 01:42:10 INFO BlockManagerInfo: Removed broadcast_31_piece0 on localhost:42591 in memory (size: 5.3 KiB, free: 912.1 MiB)
21/02/17 01:42:10 INFO TaskSetManager: Starting task 0.0 in stage 38.0 (TID 40, localhost, executor driver, partition 0, PROCESS_LOCAL, 7550 bytes)
21/02/17 01:42:10 INFO Executor: Running task 0.0 in stage 38.0 (TID 40)
21/02/17 01:42:10 INFO BlockManagerInfo: Removed broadcast_39_piece0 on localhost:42591 in memory (size: 5.3 KiB, free: 912.1 MiB)
21/02/17 01:42:10 INFO BlockManagerInfo: Removed broadcast_30_piece0 on localhost:42591 in memory (size: 7.0 KiB, free: 912.1 MiB)
21/02/17 01:42:10 INFO Executor: Finished task 0.0 in stage 38.0 (TID 40). 1833 bytes result sent to driver
21/02/17 01:42:10 INFO TaskSetManager: Finished task 0.0 in stage 38.0 (TID 40) in 6 ms on localhost (executor driver) (1/1)
21/02/17 01:42:10 INFO TaskSchedulerImpl: Removed TaskSet 38.0, whose tasks have all completed, from pool 
21/02/17 01:42:10 INFO DAGScheduler: ShuffleMapStage 38 (count at utils.scala:135) finished in 0.016 s
21/02/17 01:42:10 INFO DAGScheduler: looking for newly runnable stages
21/02/17 01:42:10 INFO DAGScheduler: running: Set()
21/02/17 01:42:10 INFO DAGScheduler: waiting: Set(ResultStage 39)
21/02/17 01:42:10 INFO BlockManagerInfo: Removed broadcast_34_piece0 on localhost:42591 in memory (size: 10.1 KiB, free: 912.2 MiB)
21/02/17 01:42:10 INFO DAGScheduler: failed: Set()
21/02/17 01:42:10 INFO DAGScheduler: Submitting ResultStage 39 (MapPartitionsRDD[133] at count at utils.scala:135), which has no missing parents
21/02/17 01:42:10 INFO BlockManagerInfo: Removed broadcast_29_piece0 on localhost:42591 in memory (size: 28.9 KiB, free: 912.2 MiB)
21/02/17 01:42:10 INFO MemoryStore: Block broadcast_42 stored as values in memory (estimated size 10.1 KiB, free 911.6 MiB)
21/02/17 01:42:10 INFO BlockManagerInfo: Removed broadcast_32_piece0 on localhost:42591 in memory (size: 5.0 KiB, free: 912.2 MiB)
21/02/17 01:42:10 INFO MemoryStore: Block broadcast_42_piece0 stored as bytes in memory (estimated size 5.0 KiB, free 911.7 MiB)
21/02/17 01:42:10 INFO BlockManagerInfo: Added broadcast_42_piece0 in memory on localhost:42591 (size: 5.0 KiB, free: 912.2 MiB)
21/02/17 01:42:10 INFO BlockManagerInfo: Removed broadcast_36_piece0 on localhost:42591 in memory (size: 10.1 KiB, free: 912.2 MiB)
21/02/17 01:42:10 INFO SparkContext: Created broadcast 42 from broadcast at DAGScheduler.scala:1200
21/02/17 01:42:10 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 39 (MapPartitionsRDD[133] at count at utils.scala:135) (first 15 tasks are for partitions Vector(0))
21/02/17 01:42:10 INFO TaskSchedulerImpl: Adding task set 39.0 with 1 tasks
21/02/17 01:42:10 INFO BlockManagerInfo: Removed broadcast_40_piece0 on localhost:42591 in memory (size: 3.7 KiB, free: 912.2 MiB)
21/02/17 01:42:10 INFO TaskSetManager: Starting task 0.0 in stage 39.0 (TID 41, localhost, executor driver, partition 0, NODE_LOCAL, 7325 bytes)
21/02/17 01:42:10 INFO Executor: Running task 0.0 in stage 39.0 (TID 41)
21/02/17 01:42:10 INFO ShuffleBlockFetcherIterator: Getting 1 (60.0 B) non-empty blocks including 1 (60.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
21/02/17 01:42:10 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
21/02/17 01:42:10 INFO Executor: Finished task 0.0 in stage 39.0 (TID 41). 2648 bytes result sent to driver
21/02/17 01:42:10 INFO TaskSetManager: Finished task 0.0 in stage 39.0 (TID 41) in 4 ms on localhost (executor driver) (1/1)
21/02/17 01:42:10 INFO TaskSchedulerImpl: Removed TaskSet 39.0, whose tasks have all completed, from pool 
21/02/17 01:42:10 INFO DAGScheduler: ResultStage 39 (count at utils.scala:135) finished in 0.012 s
21/02/17 01:42:10 INFO DAGScheduler: Job 28 is finished. Cancelling potential speculative or zombie tasks for this job
21/02/17 01:42:10 INFO TaskSchedulerImpl: Killing all running tasks in stage 39: Stage finished
21/02/17 01:42:10 INFO DAGScheduler: Job 28 finished: count at utils.scala:135, took 0.032352 s
21/02/17 01:42:10 INFO SparkContext: Starting job: collect at utils.scala:137
21/02/17 01:42:10 INFO DAGScheduler: Got job 29 (collect at utils.scala:137) with 1 output partitions
21/02/17 01:42:10 INFO DAGScheduler: Final stage: ResultStage 40 (collect at utils.scala:137)
21/02/17 01:42:10 INFO DAGScheduler: Parents of final stage: List()
21/02/17 01:42:10 INFO DAGScheduler: Missing parents: List()
21/02/17 01:42:10 INFO DAGScheduler: Submitting ResultStage 40 (MapPartitionsRDD[136] at collect at utils.scala:137), which has no missing parents
21/02/17 01:42:10 INFO MemoryStore: Block broadcast_43 stored as values in memory (estimated size 16.7 KiB, free 911.7 MiB)
21/02/17 01:42:10 INFO MemoryStore: Block broadcast_43_piece0 stored as bytes in memory (estimated size 8.0 KiB, free 911.7 MiB)
21/02/17 01:42:10 INFO BlockManagerInfo: Added broadcast_43_piece0 in memory on localhost:42591 (size: 8.0 KiB, free: 912.2 MiB)
21/02/17 01:42:10 INFO SparkContext: Created broadcast 43 from broadcast at DAGScheduler.scala:1200
21/02/17 01:42:10 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 40 (MapPartitionsRDD[136] at collect at utils.scala:137) (first 15 tasks are for partitions Vector(0))
21/02/17 01:42:10 INFO TaskSchedulerImpl: Adding task set 40.0 with 1 tasks
21/02/17 01:42:10 INFO TaskSetManager: Starting task 0.0 in stage 40.0 (TID 42, localhost, executor driver, partition 0, PROCESS_LOCAL, 7757 bytes)
21/02/17 01:42:10 INFO Executor: Running task 0.0 in stage 40.0 (TID 42)
21/02/17 01:42:10 INFO BlockManager: Found block rdd_105_0 locally
21/02/17 01:42:10 INFO CodeGenerator: Code generated in 11.861101 ms
21/02/17 01:42:10 INFO Executor: Finished task 0.0 in stage 40.0 (TID 42). 1606 bytes result sent to driver
21/02/17 01:42:10 INFO TaskSetManager: Finished task 0.0 in stage 40.0 (TID 42) in 20 ms on localhost (executor driver) (1/1)
21/02/17 01:42:10 INFO TaskSchedulerImpl: Removed TaskSet 40.0, whose tasks have all completed, from pool 
21/02/17 01:42:10 INFO DAGScheduler: ResultStage 40 (collect at utils.scala:137) finished in 0.025 s
21/02/17 01:42:10 INFO DAGScheduler: Job 29 is finished. Cancelling potential speculative or zombie tasks for this job
21/02/17 01:42:10 INFO TaskSchedulerImpl: Killing all running tasks in stage 40: Stage finished
21/02/17 01:42:10 INFO DAGScheduler: Job 29 finished: collect at utils.scala:137, took 0.026612 s
21/02/17 01:42:10 INFO CodeGenerator: Code generated in 5.108969 ms
21/02/17 01:42:10 INFO SparkContext: Starting job: count at utils.scala:135
21/02/17 01:42:10 INFO DAGScheduler: Registering RDD 140 (count at utils.scala:135) as input to shuffle 12
21/02/17 01:42:10 INFO DAGScheduler: Got job 30 (count at utils.scala:135) with 1 output partitions
21/02/17 01:42:10 INFO DAGScheduler: Final stage: ResultStage 42 (count at utils.scala:135)
21/02/17 01:42:10 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 41)
21/02/17 01:42:10 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 41)
21/02/17 01:42:10 INFO DAGScheduler: Submitting ShuffleMapStage 41 (MapPartitionsRDD[140] at count at utils.scala:135), which has no missing parents
21/02/17 01:42:10 INFO MemoryStore: Block broadcast_44 stored as values in memory (estimated size 21.5 KiB, free 911.6 MiB)
21/02/17 01:42:10 INFO MemoryStore: Block broadcast_44_piece0 stored as bytes in memory (estimated size 10.1 KiB, free 911.6 MiB)
21/02/17 01:42:10 INFO BlockManagerInfo: Added broadcast_44_piece0 in memory on localhost:42591 (size: 10.1 KiB, free: 912.2 MiB)
21/02/17 01:42:10 INFO SparkContext: Created broadcast 44 from broadcast at DAGScheduler.scala:1200
21/02/17 01:42:10 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 41 (MapPartitionsRDD[140] at count at utils.scala:135) (first 15 tasks are for partitions Vector(0))
21/02/17 01:42:10 INFO TaskSchedulerImpl: Adding task set 41.0 with 1 tasks
21/02/17 01:42:10 INFO TaskSetManager: Starting task 0.0 in stage 41.0 (TID 43, localhost, executor driver, partition 0, PROCESS_LOCAL, 7746 bytes)
21/02/17 01:42:10 INFO Executor: Running task 0.0 in stage 41.0 (TID 43)
21/02/17 01:42:10 INFO BlockManager: Found block rdd_105_0 locally
21/02/17 01:42:10 INFO Executor: Finished task 0.0 in stage 41.0 (TID 43). 2067 bytes result sent to driver
21/02/17 01:42:10 INFO TaskSetManager: Finished task 0.0 in stage 41.0 (TID 43) in 7 ms on localhost (executor driver) (1/1)
21/02/17 01:42:10 INFO TaskSchedulerImpl: Removed TaskSet 41.0, whose tasks have all completed, from pool 
21/02/17 01:42:10 INFO DAGScheduler: ShuffleMapStage 41 (count at utils.scala:135) finished in 0.012 s
21/02/17 01:42:10 INFO DAGScheduler: looking for newly runnable stages
21/02/17 01:42:10 INFO DAGScheduler: running: Set()
21/02/17 01:42:10 INFO DAGScheduler: waiting: Set(ResultStage 42)
21/02/17 01:42:10 INFO DAGScheduler: failed: Set()
21/02/17 01:42:10 INFO DAGScheduler: Submitting ResultStage 42 (MapPartitionsRDD[143] at count at utils.scala:135), which has no missing parents
21/02/17 01:42:10 INFO MemoryStore: Block broadcast_45 stored as values in memory (estimated size 10.1 KiB, free 911.6 MiB)
21/02/17 01:42:10 INFO MemoryStore: Block broadcast_45_piece0 stored as bytes in memory (estimated size 5.0 KiB, free 911.6 MiB)
21/02/17 01:42:10 INFO BlockManagerInfo: Added broadcast_45_piece0 in memory on localhost:42591 (size: 5.0 KiB, free: 912.2 MiB)
21/02/17 01:42:10 INFO SparkContext: Created broadcast 45 from broadcast at DAGScheduler.scala:1200
21/02/17 01:42:10 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 42 (MapPartitionsRDD[143] at count at utils.scala:135) (first 15 tasks are for partitions Vector(0))
21/02/17 01:42:10 INFO TaskSchedulerImpl: Adding task set 42.0 with 1 tasks
21/02/17 01:42:10 INFO TaskSetManager: Starting task 0.0 in stage 42.0 (TID 44, localhost, executor driver, partition 0, NODE_LOCAL, 7325 bytes)
21/02/17 01:42:10 INFO Executor: Running task 0.0 in stage 42.0 (TID 44)
21/02/17 01:42:10 INFO ShuffleBlockFetcherIterator: Getting 1 (60.0 B) non-empty blocks including 1 (60.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
21/02/17 01:42:10 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
21/02/17 01:42:10 INFO Executor: Finished task 0.0 in stage 42.0 (TID 44). 2648 bytes result sent to driver
21/02/17 01:42:10 INFO TaskSetManager: Finished task 0.0 in stage 42.0 (TID 44) in 5 ms on localhost (executor driver) (1/1)
21/02/17 01:42:10 INFO TaskSchedulerImpl: Removed TaskSet 42.0, whose tasks have all completed, from pool 
21/02/17 01:42:10 INFO DAGScheduler: ResultStage 42 (count at utils.scala:135) finished in 0.009 s
21/02/17 01:42:10 INFO DAGScheduler: Job 30 is finished. Cancelling potential speculative or zombie tasks for this job
21/02/17 01:42:10 INFO TaskSchedulerImpl: Killing all running tasks in stage 42: Stage finished
21/02/17 01:42:10 INFO DAGScheduler: Job 30 finished: count at utils.scala:135, took 0.024209 s
21/02/17 01:42:10 INFO MapPartitionsRDD: Removing RDD 105 from persistence list
21/02/17 01:42:10 INFO BlockManager: Removing RDD 105
21/02/17 01:42:10 INFO MemoryStore: Block broadcast_46 stored as values in memory (estimated size 294.6 KiB, free 911.3 MiB)
21/02/17 01:42:10 INFO MemoryStore: Block broadcast_46_piece0 stored as bytes in memory (estimated size 27.2 KiB, free 911.3 MiB)
21/02/17 01:42:10 INFO BlockManagerInfo: Added broadcast_46_piece0 in memory on localhost:42591 (size: 27.2 KiB, free: 912.1 MiB)
21/02/17 01:42:10 INFO SparkContext: Created broadcast 46 from textFile at ReadWrite.scala:587
21/02/17 01:42:10 INFO FileInputFormat: Total input files to process : 1
21/02/17 01:42:10 INFO SparkContext: Starting job: first at ReadWrite.scala:587
21/02/17 01:42:10 INFO DAGScheduler: Got job 31 (first at ReadWrite.scala:587) with 1 output partitions
21/02/17 01:42:10 INFO DAGScheduler: Final stage: ResultStage 43 (first at ReadWrite.scala:587)
21/02/17 01:42:10 INFO DAGScheduler: Parents of final stage: List()
21/02/17 01:42:10 INFO DAGScheduler: Missing parents: List()
21/02/17 01:42:10 INFO DAGScheduler: Submitting ResultStage 43 (/tmp/RtmpzND6YJ/file230be61cffde9/metadata MapPartitionsRDD[145] at textFile at ReadWrite.scala:587), which has no missing parents
21/02/17 01:42:10 INFO MemoryStore: Block broadcast_47 stored as values in memory (estimated size 4.1 KiB, free 911.3 MiB)
21/02/17 01:42:10 INFO MemoryStore: Block broadcast_47_piece0 stored as bytes in memory (estimated size 2.4 KiB, free 911.3 MiB)
21/02/17 01:42:10 INFO BlockManagerInfo: Added broadcast_47_piece0 in memory on localhost:42591 (size: 2.4 KiB, free: 912.1 MiB)
21/02/17 01:42:10 INFO SparkContext: Created broadcast 47 from broadcast at DAGScheduler.scala:1200
21/02/17 01:42:10 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 43 (/tmp/RtmpzND6YJ/file230be61cffde9/metadata MapPartitionsRDD[145] at textFile at ReadWrite.scala:587) (first 15 tasks are for partitions Vector(0))
21/02/17 01:42:10 INFO TaskSchedulerImpl: Adding task set 43.0 with 1 tasks
21/02/17 01:42:10 INFO TaskSetManager: Starting task 0.0 in stage 43.0 (TID 45, localhost, executor driver, partition 0, PROCESS_LOCAL, 7399 bytes)
21/02/17 01:42:10 INFO Executor: Running task 0.0 in stage 43.0 (TID 45)
21/02/17 01:42:10 INFO HadoopRDD: Input split: file:/tmp/RtmpzND6YJ/file230be61cffde9/metadata/part-00000:0+306
21/02/17 01:42:10 INFO Executor: Finished task 0.0 in stage 43.0 (TID 45). 1234 bytes result sent to driver
21/02/17 01:42:10 INFO TaskSetManager: Finished task 0.0 in stage 43.0 (TID 45) in 19 ms on localhost (executor driver) (1/1)
21/02/17 01:42:10 INFO TaskSchedulerImpl: Removed TaskSet 43.0, whose tasks have all completed, from pool 
21/02/17 01:42:10 INFO DAGScheduler: ResultStage 43 (first at ReadWrite.scala:587) finished in 0.023 s
21/02/17 01:42:10 INFO DAGScheduler: Job 31 is finished. Cancelling potential speculative or zombie tasks for this job
21/02/17 01:42:10 INFO TaskSchedulerImpl: Killing all running tasks in stage 43: Stage finished
21/02/17 01:42:10 INFO DAGScheduler: Job 31 finished: first at ReadWrite.scala:587, took 0.026316 s
21/02/17 01:42:10 INFO MemoryStore: Block broadcast_48 stored as values in memory (estimated size 294.6 KiB, free 911.0 MiB)
21/02/17 01:42:10 INFO MemoryStore: Block broadcast_48_piece0 stored as bytes in memory (estimated size 27.2 KiB, free 911.0 MiB)
21/02/17 01:42:10 INFO BlockManagerInfo: Added broadcast_48_piece0 in memory on localhost:42591 (size: 27.2 KiB, free: 912.1 MiB)
21/02/17 01:42:10 INFO SparkContext: Created broadcast 48 from textFile at ReadWrite.scala:587
21/02/17 01:42:10 INFO FileInputFormat: Total input files to process : 1
21/02/17 01:42:10 INFO SparkContext: Starting job: first at ReadWrite.scala:587
21/02/17 01:42:10 INFO DAGScheduler: Got job 32 (first at ReadWrite.scala:587) with 1 output partitions
21/02/17 01:42:10 INFO DAGScheduler: Final stage: ResultStage 44 (first at ReadWrite.scala:587)
21/02/17 01:42:10 INFO DAGScheduler: Parents of final stage: List()
21/02/17 01:42:10 INFO DAGScheduler: Missing parents: List()
21/02/17 01:42:10 INFO DAGScheduler: Submitting ResultStage 44 (/tmp/RtmpzND6YJ/file230be61cffde9/stages/0_r_formula__ae8e0faf_6bf9_456d_bc45_2aca30f7aea4/metadata MapPartitionsRDD[147] at textFile at ReadWrite.scala:587), which has no missing parents
21/02/17 01:42:10 INFO MemoryStore: Block broadcast_49 stored as values in memory (estimated size 4.2 KiB, free 911.0 MiB)
21/02/17 01:42:10 INFO MemoryStore: Block broadcast_49_piece0 stored as bytes in memory (estimated size 2.5 KiB, free 911.0 MiB)
21/02/17 01:42:10 INFO BlockManagerInfo: Added broadcast_49_piece0 in memory on localhost:42591 (size: 2.5 KiB, free: 912.1 MiB)
21/02/17 01:42:10 INFO SparkContext: Created broadcast 49 from broadcast at DAGScheduler.scala:1200
21/02/17 01:42:10 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 44 (/tmp/RtmpzND6YJ/file230be61cffde9/stages/0_r_formula__ae8e0faf_6bf9_456d_bc45_2aca30f7aea4/metadata MapPartitionsRDD[147] at textFile at ReadWrite.scala:587) (first 15 tasks are for partitions Vector(0))
21/02/17 01:42:10 INFO TaskSchedulerImpl: Adding task set 44.0 with 1 tasks
21/02/17 01:42:10 INFO TaskSetManager: Starting task 0.0 in stage 44.0 (TID 46, localhost, executor driver, partition 0, PROCESS_LOCAL, 7456 bytes)
21/02/17 01:42:10 INFO Executor: Running task 0.0 in stage 44.0 (TID 46)
21/02/17 01:42:10 INFO HadoopRDD: Input split: file:/tmp/RtmpzND6YJ/file230be61cffde9/stages/0_r_formula__ae8e0faf_6bf9_456d_bc45_2aca30f7aea4/metadata/part-00000:0+447
21/02/17 01:42:10 INFO Executor: Finished task 0.0 in stage 44.0 (TID 46). 1375 bytes result sent to driver
21/02/17 01:42:10 INFO TaskSetManager: Finished task 0.0 in stage 44.0 (TID 46) in 4 ms on localhost (executor driver) (1/1)
21/02/17 01:42:10 INFO TaskSchedulerImpl: Removed TaskSet 44.0, whose tasks have all completed, from pool 
21/02/17 01:42:10 INFO DAGScheduler: ResultStage 44 (first at ReadWrite.scala:587) finished in 0.007 s
21/02/17 01:42:10 INFO DAGScheduler: Job 32 is finished. Cancelling potential speculative or zombie tasks for this job
21/02/17 01:42:10 INFO TaskSchedulerImpl: Killing all running tasks in stage 44: Stage finished
21/02/17 01:42:10 INFO DAGScheduler: Job 32 finished: first at ReadWrite.scala:587, took 0.009397 s
21/02/17 01:42:10 INFO MemoryStore: Block broadcast_50 stored as values in memory (estimated size 294.6 KiB, free 910.7 MiB)
21/02/17 01:42:10 INFO MemoryStore: Block broadcast_50_piece0 stored as bytes in memory (estimated size 27.2 KiB, free 910.7 MiB)
21/02/17 01:42:10 INFO BlockManagerInfo: Added broadcast_50_piece0 in memory on localhost:42591 (size: 27.2 KiB, free: 912.1 MiB)
21/02/17 01:42:10 INFO SparkContext: Created broadcast 50 from textFile at ReadWrite.scala:587
21/02/17 01:42:10 INFO FileInputFormat: Total input files to process : 1
21/02/17 01:42:10 INFO SparkContext: Starting job: first at ReadWrite.scala:587
21/02/17 01:42:10 INFO DAGScheduler: Got job 33 (first at ReadWrite.scala:587) with 1 output partitions
21/02/17 01:42:10 INFO DAGScheduler: Final stage: ResultStage 45 (first at ReadWrite.scala:587)
21/02/17 01:42:10 INFO DAGScheduler: Parents of final stage: List()
21/02/17 01:42:10 INFO DAGScheduler: Missing parents: List()
21/02/17 01:42:10 INFO DAGScheduler: Submitting ResultStage 45 (/tmp/RtmpzND6YJ/file230be61cffde9/stages/0_r_formula__ae8e0faf_6bf9_456d_bc45_2aca30f7aea4/metadata MapPartitionsRDD[149] at textFile at ReadWrite.scala:587), which has no missing parents
21/02/17 01:42:10 INFO MemoryStore: Block broadcast_51 stored as values in memory (estimated size 4.2 KiB, free 910.7 MiB)
21/02/17 01:42:10 INFO MemoryStore: Block broadcast_51_piece0 stored as bytes in memory (estimated size 2.5 KiB, free 910.7 MiB)
21/02/17 01:42:10 INFO BlockManagerInfo: Added broadcast_51_piece0 in memory on localhost:42591 (size: 2.5 KiB, free: 912.1 MiB)
21/02/17 01:42:10 INFO SparkContext: Created broadcast 51 from broadcast at DAGScheduler.scala:1200
21/02/17 01:42:10 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 45 (/tmp/RtmpzND6YJ/file230be61cffde9/stages/0_r_formula__ae8e0faf_6bf9_456d_bc45_2aca30f7aea4/metadata MapPartitionsRDD[149] at textFile at ReadWrite.scala:587) (first 15 tasks are for partitions Vector(0))
21/02/17 01:42:10 INFO TaskSchedulerImpl: Adding task set 45.0 with 1 tasks
21/02/17 01:42:10 INFO TaskSetManager: Starting task 0.0 in stage 45.0 (TID 47, localhost, executor driver, partition 0, PROCESS_LOCAL, 7456 bytes)
21/02/17 01:42:10 INFO Executor: Running task 0.0 in stage 45.0 (TID 47)
21/02/17 01:42:10 INFO HadoopRDD: Input split: file:/tmp/RtmpzND6YJ/file230be61cffde9/stages/0_r_formula__ae8e0faf_6bf9_456d_bc45_2aca30f7aea4/metadata/part-00000:0+447
21/02/17 01:42:10 INFO Executor: Finished task 0.0 in stage 45.0 (TID 47). 1375 bytes result sent to driver
21/02/17 01:42:10 INFO TaskSetManager: Finished task 0.0 in stage 45.0 (TID 47) in 4 ms on localhost (executor driver) (1/1)
21/02/17 01:42:10 INFO TaskSchedulerImpl: Removed TaskSet 45.0, whose tasks have all completed, from pool 
21/02/17 01:42:10 INFO DAGScheduler: ResultStage 45 (first at ReadWrite.scala:587) finished in 0.008 s
21/02/17 01:42:10 INFO DAGScheduler: Job 33 is finished. Cancelling potential speculative or zombie tasks for this job
21/02/17 01:42:10 INFO TaskSchedulerImpl: Killing all running tasks in stage 45: Stage finished
21/02/17 01:42:10 INFO DAGScheduler: Job 33 finished: first at ReadWrite.scala:587, took 0.009714 s
21/02/17 01:42:10 INFO InMemoryFileIndex: It took 0 ms to list leaf files for 1 paths.
21/02/17 01:42:10 INFO SparkContext: Starting job: parquet at RFormula.scala:450
21/02/17 01:42:10 INFO DAGScheduler: Got job 34 (parquet at RFormula.scala:450) with 1 output partitions
21/02/17 01:42:10 INFO DAGScheduler: Final stage: ResultStage 46 (parquet at RFormula.scala:450)
21/02/17 01:42:10 INFO DAGScheduler: Parents of final stage: List()
21/02/17 01:42:10 INFO DAGScheduler: Missing parents: List()
21/02/17 01:42:10 INFO DAGScheduler: Submitting ResultStage 46 (MapPartitionsRDD[151] at parquet at RFormula.scala:450), which has no missing parents
21/02/17 01:42:10 INFO MemoryStore: Block broadcast_52 stored as values in memory (estimated size 87.9 KiB, free 910.6 MiB)
21/02/17 01:42:10 INFO MemoryStore: Block broadcast_52_piece0 stored as bytes in memory (estimated size 31.1 KiB, free 910.5 MiB)
21/02/17 01:42:10 INFO BlockManagerInfo: Added broadcast_52_piece0 in memory on localhost:42591 (size: 31.1 KiB, free: 912.1 MiB)
21/02/17 01:42:10 INFO SparkContext: Created broadcast 52 from broadcast at DAGScheduler.scala:1200
21/02/17 01:42:10 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 46 (MapPartitionsRDD[151] at parquet at RFormula.scala:450) (first 15 tasks are for partitions Vector(0))
21/02/17 01:42:10 INFO TaskSchedulerImpl: Adding task set 46.0 with 1 tasks
21/02/17 01:42:10 INFO TaskSetManager: Starting task 0.0 in stage 46.0 (TID 48, localhost, executor driver, partition 0, PROCESS_LOCAL, 7616 bytes)
21/02/17 01:42:10 INFO Executor: Running task 0.0 in stage 46.0 (TID 48)
21/02/17 01:42:10 INFO Executor: Finished task 0.0 in stage 46.0 (TID 48). 1835 bytes result sent to driver
21/02/17 01:42:10 INFO TaskSetManager: Finished task 0.0 in stage 46.0 (TID 48) in 35 ms on localhost (executor driver) (1/1)
21/02/17 01:42:10 INFO TaskSchedulerImpl: Removed TaskSet 46.0, whose tasks have all completed, from pool 
21/02/17 01:42:10 INFO DAGScheduler: ResultStage 46 (parquet at RFormula.scala:450) finished in 0.046 s
21/02/17 01:42:10 INFO DAGScheduler: Job 34 is finished. Cancelling potential speculative or zombie tasks for this job
21/02/17 01:42:10 INFO TaskSchedulerImpl: Killing all running tasks in stage 46: Stage finished
21/02/17 01:42:10 INFO DAGScheduler: Job 34 finished: parquet at RFormula.scala:450, took 0.047868 s
21/02/17 01:42:10 INFO FileSourceStrategy: Pruning directories with: 
21/02/17 01:42:10 INFO FileSourceStrategy: Pushed Filters: 
21/02/17 01:42:10 INFO FileSourceStrategy: Post-Scan Filters: 
21/02/17 01:42:10 INFO FileSourceStrategy: Output Data Schema: struct<label: string, terms: array<array<string>>, hasIntercept: boolean ... 1 more fields>
21/02/17 01:42:10 INFO MemoryStore: Block broadcast_53 stored as values in memory (estimated size 321.5 KiB, free 910.2 MiB)
21/02/17 01:42:10 INFO MemoryStore: Block broadcast_53_piece0 stored as bytes in memory (estimated size 29.6 KiB, free 910.2 MiB)
21/02/17 01:42:10 INFO BlockManagerInfo: Added broadcast_53_piece0 in memory on localhost:42591 (size: 29.6 KiB, free: 912.0 MiB)
21/02/17 01:42:10 INFO SparkContext: Created broadcast 53 from head at RFormula.scala:450
21/02/17 01:42:10 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
21/02/17 01:42:10 INFO SparkContext: Starting job: head at RFormula.scala:450
21/02/17 01:42:10 INFO DAGScheduler: Got job 35 (head at RFormula.scala:450) with 1 output partitions
21/02/17 01:42:10 INFO DAGScheduler: Final stage: ResultStage 47 (head at RFormula.scala:450)
21/02/17 01:42:10 INFO DAGScheduler: Parents of final stage: List()
21/02/17 01:42:10 INFO DAGScheduler: Missing parents: List()
21/02/17 01:42:10 INFO DAGScheduler: Submitting ResultStage 47 (MapPartitionsRDD[154] at head at RFormula.scala:450), which has no missing parents
21/02/17 01:42:10 INFO MemoryStore: Block broadcast_54 stored as values in memory (estimated size 9.1 KiB, free 910.2 MiB)
21/02/17 01:42:10 INFO MemoryStore: Block broadcast_54_piece0 stored as bytes in memory (estimated size 4.9 KiB, free 910.2 MiB)
21/02/17 01:42:10 INFO BlockManagerInfo: Added broadcast_54_piece0 in memory on localhost:42591 (size: 4.9 KiB, free: 912.0 MiB)
21/02/17 01:42:10 INFO SparkContext: Created broadcast 54 from broadcast at DAGScheduler.scala:1200
21/02/17 01:42:10 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 47 (MapPartitionsRDD[154] at head at RFormula.scala:450) (first 15 tasks are for partitions Vector(0))
21/02/17 01:42:10 INFO TaskSchedulerImpl: Adding task set 47.0 with 1 tasks
21/02/17 01:42:10 INFO TaskSetManager: Starting task 0.0 in stage 47.0 (TID 49, localhost, executor driver, partition 0, PROCESS_LOCAL, 7867 bytes)
21/02/17 01:42:10 INFO Executor: Running task 0.0 in stage 47.0 (TID 49)
21/02/17 01:42:10 INFO CodeGenerator: Code generated in 7.152882 ms
21/02/17 01:42:10 INFO FileScanRDD: Reading File path: file:///tmp/RtmpzND6YJ/file230be61cffde9/stages/0_r_formula__ae8e0faf_6bf9_456d_bc45_2aca30f7aea4/data/part-00000-94d701a8-96ec-431a-bc90-6c3048d4e726-c000.snappy.parquet, range: 0-1140, partition values: [empty row]
21/02/17 01:42:10 INFO CodecPool: Got brand-new decompressor [.snappy]
21/02/17 01:42:10 INFO Executor: Finished task 0.0 in stage 47.0 (TID 49). 1790 bytes result sent to driver
21/02/17 01:42:10 INFO TaskSetManager: Finished task 0.0 in stage 47.0 (TID 49) in 86 ms on localhost (executor driver) (1/1)
21/02/17 01:42:10 INFO TaskSchedulerImpl: Removed TaskSet 47.0, whose tasks have all completed, from pool 
21/02/17 01:42:10 INFO DAGScheduler: ResultStage 47 (head at RFormula.scala:450) finished in 0.094 s
21/02/17 01:42:10 INFO DAGScheduler: Job 35 is finished. Cancelling potential speculative or zombie tasks for this job
21/02/17 01:42:10 INFO TaskSchedulerImpl: Killing all running tasks in stage 47: Stage finished
21/02/17 01:42:10 INFO DAGScheduler: Job 35 finished: head at RFormula.scala:450, took 0.096436 s
21/02/17 01:42:10 INFO CodeGenerator: Code generated in 14.345924 ms
21/02/17 01:42:10 INFO MemoryStore: Block broadcast_55 stored as values in memory (estimated size 294.6 KiB, free 909.9 MiB)
21/02/17 01:42:10 INFO MemoryStore: Block broadcast_55_piece0 stored as bytes in memory (estimated size 27.2 KiB, free 909.9 MiB)
21/02/17 01:42:10 INFO BlockManagerInfo: Added broadcast_55_piece0 in memory on localhost:42591 (size: 27.2 KiB, free: 912.0 MiB)
21/02/17 01:42:10 INFO SparkContext: Created broadcast 55 from textFile at ReadWrite.scala:587
21/02/17 01:42:10 INFO FileInputFormat: Total input files to process : 1
21/02/17 01:42:10 INFO SparkContext: Starting job: first at ReadWrite.scala:587
21/02/17 01:42:10 INFO DAGScheduler: Got job 36 (first at ReadWrite.scala:587) with 1 output partitions
21/02/17 01:42:10 INFO DAGScheduler: Final stage: ResultStage 48 (first at ReadWrite.scala:587)
21/02/17 01:42:10 INFO DAGScheduler: Parents of final stage: List()
21/02/17 01:42:10 INFO DAGScheduler: Missing parents: List()
21/02/17 01:42:10 INFO DAGScheduler: Submitting ResultStage 48 (/tmp/RtmpzND6YJ/file230be61cffde9/stages/0_r_formula__ae8e0faf_6bf9_456d_bc45_2aca30f7aea4/pipelineModel/metadata MapPartitionsRDD[156] at textFile at ReadWrite.scala:587), which has no missing parents
21/02/17 01:42:10 INFO MemoryStore: Block broadcast_56 stored as values in memory (estimated size 4.2 KiB, free 909.9 MiB)
21/02/17 01:42:10 INFO MemoryStore: Block broadcast_56_piece0 stored as bytes in memory (estimated size 2.5 KiB, free 909.9 MiB)
21/02/17 01:42:11 INFO BlockManagerInfo: Added broadcast_56_piece0 in memory on localhost:42591 (size: 2.5 KiB, free: 912.0 MiB)
21/02/17 01:42:11 INFO SparkContext: Created broadcast 56 from broadcast at DAGScheduler.scala:1200
21/02/17 01:42:11 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 48 (/tmp/RtmpzND6YJ/file230be61cffde9/stages/0_r_formula__ae8e0faf_6bf9_456d_bc45_2aca30f7aea4/pipelineModel/metadata MapPartitionsRDD[156] at textFile at ReadWrite.scala:587) (first 15 tasks are for partitions Vector(0))
21/02/17 01:42:11 INFO TaskSchedulerImpl: Adding task set 48.0 with 1 tasks
21/02/17 01:42:11 INFO TaskSetManager: Starting task 0.0 in stage 48.0 (TID 50, localhost, executor driver, partition 0, PROCESS_LOCAL, 7471 bytes)
21/02/17 01:42:11 INFO Executor: Running task 0.0 in stage 48.0 (TID 50)
21/02/17 01:42:11 INFO HadoopRDD: Input split: file:/tmp/RtmpzND6YJ/file230be61cffde9/stages/0_r_formula__ae8e0faf_6bf9_456d_bc45_2aca30f7aea4/pipelineModel/metadata/part-00000:0+311
21/02/17 01:42:11 INFO Executor: Finished task 0.0 in stage 48.0 (TID 50). 1239 bytes result sent to driver
21/02/17 01:42:11 INFO TaskSetManager: Finished task 0.0 in stage 48.0 (TID 50) in 4 ms on localhost (executor driver) (1/1)
21/02/17 01:42:11 INFO TaskSchedulerImpl: Removed TaskSet 48.0, whose tasks have all completed, from pool 
21/02/17 01:42:11 INFO DAGScheduler: ResultStage 48 (first at ReadWrite.scala:587) finished in 0.007 s
21/02/17 01:42:11 INFO DAGScheduler: Job 36 is finished. Cancelling potential speculative or zombie tasks for this job
21/02/17 01:42:11 INFO TaskSchedulerImpl: Killing all running tasks in stage 48: Stage finished
21/02/17 01:42:11 INFO DAGScheduler: Job 36 finished: first at ReadWrite.scala:587, took 0.009050 s
21/02/17 01:42:11 INFO MemoryStore: Block broadcast_57 stored as values in memory (estimated size 294.6 KiB, free 909.6 MiB)
21/02/17 01:42:11 INFO MemoryStore: Block broadcast_57_piece0 stored as bytes in memory (estimated size 27.2 KiB, free 909.6 MiB)
21/02/17 01:42:11 INFO BlockManagerInfo: Added broadcast_57_piece0 in memory on localhost:42591 (size: 27.2 KiB, free: 912.0 MiB)
21/02/17 01:42:11 INFO SparkContext: Created broadcast 57 from textFile at ReadWrite.scala:587
21/02/17 01:42:11 INFO FileInputFormat: Total input files to process : 1
21/02/17 01:42:11 INFO SparkContext: Starting job: first at ReadWrite.scala:587
21/02/17 01:42:11 INFO DAGScheduler: Got job 37 (first at ReadWrite.scala:587) with 1 output partitions
21/02/17 01:42:11 INFO DAGScheduler: Final stage: ResultStage 49 (first at ReadWrite.scala:587)
21/02/17 01:42:11 INFO DAGScheduler: Parents of final stage: List()
21/02/17 01:42:11 INFO DAGScheduler: Missing parents: List()
21/02/17 01:42:11 INFO DAGScheduler: Submitting ResultStage 49 (/tmp/RtmpzND6YJ/file230be61cffde9/stages/0_r_formula__ae8e0faf_6bf9_456d_bc45_2aca30f7aea4/pipelineModel/stages/0_r_formula__ae8e0faf_6bf9_456d_bc45_2aca30f7aea4/metadata MapPartitionsRDD[158] at textFile at ReadWrite.scala:587), which has no missing parents
21/02/17 01:42:11 INFO MemoryStore: Block broadcast_58 stored as values in memory (estimated size 4.3 KiB, free 909.5 MiB)
21/02/17 01:42:11 INFO MemoryStore: Block broadcast_58_piece0 stored as bytes in memory (estimated size 2.5 KiB, free 909.5 MiB)
21/02/17 01:42:11 INFO BlockManagerInfo: Added broadcast_58_piece0 in memory on localhost:42591 (size: 2.5 KiB, free: 912.0 MiB)
21/02/17 01:42:11 INFO SparkContext: Created broadcast 58 from broadcast at DAGScheduler.scala:1200
21/02/17 01:42:11 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 49 (/tmp/RtmpzND6YJ/file230be61cffde9/stages/0_r_formula__ae8e0faf_6bf9_456d_bc45_2aca30f7aea4/pipelineModel/stages/0_r_formula__ae8e0faf_6bf9_456d_bc45_2aca30f7aea4/metadata MapPartitionsRDD[158] at textFile at ReadWrite.scala:587) (first 15 tasks are for partitions Vector(0))
21/02/17 01:42:11 INFO TaskSchedulerImpl: Adding task set 49.0 with 1 tasks
21/02/17 01:42:11 INFO TaskSetManager: Starting task 0.0 in stage 49.0 (TID 51, localhost, executor driver, partition 0, PROCESS_LOCAL, 7531 bytes)
21/02/17 01:42:11 INFO Executor: Running task 0.0 in stage 49.0 (TID 51)
21/02/17 01:42:11 INFO HadoopRDD: Input split: file:/tmp/RtmpzND6YJ/file230be61cffde9/stages/0_r_formula__ae8e0faf_6bf9_456d_bc45_2aca30f7aea4/pipelineModel/stages/0_r_formula__ae8e0faf_6bf9_456d_bc45_2aca30f7aea4/metadata/part-00000:0+378
21/02/17 01:42:11 INFO Executor: Finished task 0.0 in stage 49.0 (TID 51). 1306 bytes result sent to driver
21/02/17 01:42:11 INFO TaskSetManager: Finished task 0.0 in stage 49.0 (TID 51) in 4 ms on localhost (executor driver) (1/1)
21/02/17 01:42:11 INFO TaskSchedulerImpl: Removed TaskSet 49.0, whose tasks have all completed, from pool 
21/02/17 01:42:11 INFO DAGScheduler: ResultStage 49 (first at ReadWrite.scala:587) finished in 0.008 s
21/02/17 01:42:11 INFO DAGScheduler: Job 37 is finished. Cancelling potential speculative or zombie tasks for this job
21/02/17 01:42:11 INFO TaskSchedulerImpl: Killing all running tasks in stage 49: Stage finished
21/02/17 01:42:11 INFO DAGScheduler: Job 37 finished: first at ReadWrite.scala:587, took 0.009562 s
21/02/17 01:42:11 INFO MemoryStore: Block broadcast_59 stored as values in memory (estimated size 294.6 KiB, free 909.3 MiB)
21/02/17 01:42:11 INFO MemoryStore: Block broadcast_59_piece0 stored as bytes in memory (estimated size 27.2 KiB, free 909.2 MiB)
21/02/17 01:42:11 INFO BlockManagerInfo: Added broadcast_59_piece0 in memory on localhost:42591 (size: 27.2 KiB, free: 911.9 MiB)
21/02/17 01:42:11 INFO SparkContext: Created broadcast 59 from textFile at ReadWrite.scala:587
21/02/17 01:42:11 INFO FileInputFormat: Total input files to process : 1
21/02/17 01:42:11 INFO SparkContext: Starting job: first at ReadWrite.scala:587
21/02/17 01:42:11 INFO DAGScheduler: Got job 38 (first at ReadWrite.scala:587) with 1 output partitions
21/02/17 01:42:11 INFO DAGScheduler: Final stage: ResultStage 50 (first at ReadWrite.scala:587)
21/02/17 01:42:11 INFO DAGScheduler: Parents of final stage: List()
21/02/17 01:42:11 INFO DAGScheduler: Missing parents: List()
21/02/17 01:42:11 INFO DAGScheduler: Submitting ResultStage 50 (/tmp/RtmpzND6YJ/file230be61cffde9/stages/0_r_formula__ae8e0faf_6bf9_456d_bc45_2aca30f7aea4/pipelineModel/stages/0_r_formula__ae8e0faf_6bf9_456d_bc45_2aca30f7aea4/metadata MapPartitionsRDD[160] at textFile at ReadWrite.scala:587), which has no missing parents
21/02/17 01:42:11 INFO MemoryStore: Block broadcast_60 stored as values in memory (estimated size 4.3 KiB, free 909.2 MiB)
21/02/17 01:42:11 INFO MemoryStore: Block broadcast_60_piece0 stored as bytes in memory (estimated size 2.5 KiB, free 909.2 MiB)
21/02/17 01:42:11 INFO BlockManagerInfo: Added broadcast_60_piece0 in memory on localhost:42591 (size: 2.5 KiB, free: 911.9 MiB)
21/02/17 01:42:11 INFO SparkContext: Created broadcast 60 from broadcast at DAGScheduler.scala:1200
21/02/17 01:42:11 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 50 (/tmp/RtmpzND6YJ/file230be61cffde9/stages/0_r_formula__ae8e0faf_6bf9_456d_bc45_2aca30f7aea4/pipelineModel/stages/0_r_formula__ae8e0faf_6bf9_456d_bc45_2aca30f7aea4/metadata MapPartitionsRDD[160] at textFile at ReadWrite.scala:587) (first 15 tasks are for partitions Vector(0))
21/02/17 01:42:11 INFO TaskSchedulerImpl: Adding task set 50.0 with 1 tasks
21/02/17 01:42:11 INFO TaskSetManager: Starting task 0.0 in stage 50.0 (TID 52, localhost, executor driver, partition 0, PROCESS_LOCAL, 7531 bytes)
21/02/17 01:42:11 INFO Executor: Running task 0.0 in stage 50.0 (TID 52)
21/02/17 01:42:11 INFO HadoopRDD: Input split: file:/tmp/RtmpzND6YJ/file230be61cffde9/stages/0_r_formula__ae8e0faf_6bf9_456d_bc45_2aca30f7aea4/pipelineModel/stages/0_r_formula__ae8e0faf_6bf9_456d_bc45_2aca30f7aea4/metadata/part-00000:0+378
21/02/17 01:42:11 INFO Executor: Finished task 0.0 in stage 50.0 (TID 52). 1306 bytes result sent to driver
21/02/17 01:42:11 INFO TaskSetManager: Finished task 0.0 in stage 50.0 (TID 52) in 4 ms on localhost (executor driver) (1/1)
21/02/17 01:42:11 INFO TaskSchedulerImpl: Removed TaskSet 50.0, whose tasks have all completed, from pool 
21/02/17 01:42:11 INFO DAGScheduler: ResultStage 50 (first at ReadWrite.scala:587) finished in 0.009 s
21/02/17 01:42:11 INFO DAGScheduler: Job 38 is finished. Cancelling potential speculative or zombie tasks for this job
21/02/17 01:42:11 INFO TaskSchedulerImpl: Killing all running tasks in stage 50: Stage finished
21/02/17 01:42:11 INFO DAGScheduler: Job 38 finished: first at ReadWrite.scala:587, took 0.010231 s
21/02/17 01:42:11 INFO MemoryStore: Block broadcast_61 stored as values in memory (estimated size 294.6 KiB, free 908.9 MiB)
21/02/17 01:42:11 INFO MemoryStore: Block broadcast_61_piece0 stored as bytes in memory (estimated size 27.2 KiB, free 908.9 MiB)
21/02/17 01:42:11 INFO BlockManagerInfo: Added broadcast_61_piece0 in memory on localhost:42591 (size: 27.2 KiB, free: 911.9 MiB)
21/02/17 01:42:11 INFO SparkContext: Created broadcast 61 from textFile at ReadWrite.scala:587
21/02/17 01:42:11 INFO FileInputFormat: Total input files to process : 1
21/02/17 01:42:11 INFO SparkContext: Starting job: first at ReadWrite.scala:587
21/02/17 01:42:11 INFO DAGScheduler: Got job 39 (first at ReadWrite.scala:587) with 1 output partitions
21/02/17 01:42:11 INFO DAGScheduler: Final stage: ResultStage 51 (first at ReadWrite.scala:587)
21/02/17 01:42:11 INFO DAGScheduler: Parents of final stage: List()
21/02/17 01:42:11 INFO DAGScheduler: Missing parents: List()
21/02/17 01:42:11 INFO DAGScheduler: Submitting ResultStage 51 (/tmp/RtmpzND6YJ/file230be61cffde9/stages/0_r_formula__ae8e0faf_6bf9_456d_bc45_2aca30f7aea4/pipelineModel/stages/1_vectorAttrRewriter_20c63bd9776a/metadata MapPartitionsRDD[162] at textFile at ReadWrite.scala:587), which has no missing parents
21/02/17 01:42:11 INFO MemoryStore: Block broadcast_62 stored as values in memory (estimated size 4.2 KiB, free 908.9 MiB)
21/02/17 01:42:11 INFO BlockManagerInfo: Removed broadcast_59_piece0 on localhost:42591 in memory (size: 27.2 KiB, free: 911.9 MiB)
21/02/17 01:42:11 INFO MemoryStore: Block broadcast_62_piece0 stored as bytes in memory (estimated size 2.5 KiB, free 909.2 MiB)
21/02/17 01:42:11 INFO BlockManagerInfo: Added broadcast_62_piece0 in memory on localhost:42591 (size: 2.5 KiB, free: 911.9 MiB)
21/02/17 01:42:11 INFO SparkContext: Created broadcast 62 from broadcast at DAGScheduler.scala:1200
21/02/17 01:42:11 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 51 (/tmp/RtmpzND6YJ/file230be61cffde9/stages/0_r_formula__ae8e0faf_6bf9_456d_bc45_2aca30f7aea4/pipelineModel/stages/1_vectorAttrRewriter_20c63bd9776a/metadata MapPartitionsRDD[162] at textFile at ReadWrite.scala:587) (first 15 tasks are for partitions Vector(0))
21/02/17 01:42:11 INFO TaskSchedulerImpl: Adding task set 51.0 with 1 tasks
21/02/17 01:42:11 INFO BlockManagerInfo: Removed broadcast_50_piece0 on localhost:42591 in memory (size: 27.2 KiB, free: 912.0 MiB)
21/02/17 01:42:11 INFO TaskSetManager: Starting task 0.0 in stage 51.0 (TID 53, localhost, executor driver, partition 0, PROCESS_LOCAL, 7515 bytes)
21/02/17 01:42:11 INFO Executor: Running task 0.0 in stage 51.0 (TID 53)
21/02/17 01:42:11 INFO BlockManagerInfo: Removed broadcast_44_piece0 on localhost:42591 in memory (size: 10.1 KiB, free: 912.0 MiB)
21/02/17 01:42:11 INFO BlockManagerInfo: Removed broadcast_48_piece0 on localhost:42591 in memory (size: 27.2 KiB, free: 912.0 MiB)
21/02/17 01:42:11 INFO HadoopRDD: Input split: file:/tmp/RtmpzND6YJ/file230be61cffde9/stages/0_r_formula__ae8e0faf_6bf9_456d_bc45_2aca30f7aea4/pipelineModel/stages/1_vectorAttrRewriter_20c63bd9776a/metadata/part-00000:0+188
21/02/17 01:42:11 INFO BlockManagerInfo: Removed broadcast_54_piece0 on localhost:42591 in memory (size: 4.9 KiB, free: 912.0 MiB)
21/02/17 01:42:11 INFO BlockManagerInfo: Removed broadcast_42_piece0 on localhost:42591 in memory (size: 5.0 KiB, free: 912.0 MiB)
21/02/17 01:42:11 INFO Executor: Finished task 0.0 in stage 51.0 (TID 53). 1113 bytes result sent to driver
21/02/17 01:42:11 INFO BlockManagerInfo: Removed broadcast_57_piece0 on localhost:42591 in memory (size: 27.2 KiB, free: 912.0 MiB)
21/02/17 01:42:11 INFO TaskSetManager: Finished task 0.0 in stage 51.0 (TID 53) in 6 ms on localhost (executor driver) (1/1)
21/02/17 01:42:11 INFO TaskSchedulerImpl: Removed TaskSet 51.0, whose tasks have all completed, from pool 
21/02/17 01:42:11 INFO DAGScheduler: ResultStage 51 (first at ReadWrite.scala:587) finished in 0.012 s
21/02/17 01:42:11 INFO DAGScheduler: Job 39 is finished. Cancelling potential speculative or zombie tasks for this job
21/02/17 01:42:11 INFO TaskSchedulerImpl: Killing all running tasks in stage 51: Stage finished
21/02/17 01:42:11 INFO BlockManagerInfo: Removed broadcast_53_piece0 on localhost:42591 in memory (size: 29.6 KiB, free: 912.1 MiB)
21/02/17 01:42:11 INFO DAGScheduler: Job 39 finished: first at ReadWrite.scala:587, took 0.013518 s
21/02/17 01:42:11 INFO BlockManager: Removing RDD 105
21/02/17 01:42:11 INFO BlockManagerInfo: Removed broadcast_60_piece0 on localhost:42591 in memory (size: 2.5 KiB, free: 912.1 MiB)
21/02/17 01:42:11 INFO BlockManagerInfo: Removed broadcast_56_piece0 on localhost:42591 in memory (size: 2.5 KiB, free: 912.1 MiB)
21/02/17 01:42:11 INFO BlockManagerInfo: Removed broadcast_46_piece0 on localhost:42591 in memory (size: 27.2 KiB, free: 912.1 MiB)
21/02/17 01:42:11 INFO MemoryStore: Block broadcast_63 stored as values in memory (estimated size 294.6 KiB, free 910.7 MiB)
21/02/17 01:42:11 INFO BlockManagerInfo: Removed broadcast_52_piece0 on localhost:42591 in memory (size: 31.1 KiB, free: 912.1 MiB)
21/02/17 01:42:11 INFO BlockManagerInfo: Removed broadcast_55_piece0 on localhost:42591 in memory (size: 27.2 KiB, free: 912.1 MiB)
21/02/17 01:42:11 INFO BlockManagerInfo: Removed broadcast_43_piece0 on localhost:42591 in memory (size: 8.0 KiB, free: 912.2 MiB)
21/02/17 01:42:11 INFO BlockManagerInfo: Removed broadcast_58_piece0 on localhost:42591 in memory (size: 2.5 KiB, free: 912.2 MiB)
21/02/17 01:42:11 INFO BlockManagerInfo: Removed broadcast_33_piece0 on localhost:42591 in memory (size: 28.9 KiB, free: 912.2 MiB)
21/02/17 01:42:11 INFO BlockManagerInfo: Removed broadcast_45_piece0 on localhost:42591 in memory (size: 5.0 KiB, free: 912.2 MiB)
21/02/17 01:42:11 INFO BlockManagerInfo: Removed broadcast_47_piece0 on localhost:42591 in memory (size: 2.4 KiB, free: 912.2 MiB)
21/02/17 01:42:11 INFO BlockManagerInfo: Removed broadcast_49_piece0 on localhost:42591 in memory (size: 2.5 KiB, free: 912.2 MiB)
21/02/17 01:42:11 INFO BlockManagerInfo: Removed broadcast_41_piece0 on localhost:42591 in memory (size: 5.2 KiB, free: 912.2 MiB)
21/02/17 01:42:11 INFO BlockManagerInfo: Removed broadcast_51_piece0 on localhost:42591 in memory (size: 2.5 KiB, free: 912.2 MiB)
21/02/17 01:42:11 INFO MemoryStore: Block broadcast_63_piece0 stored as bytes in memory (estimated size 27.2 KiB, free 911.4 MiB)
21/02/17 01:42:11 INFO BlockManagerInfo: Added broadcast_63_piece0 in memory on localhost:42591 (size: 27.2 KiB, free: 912.2 MiB)
21/02/17 01:42:11 INFO SparkContext: Created broadcast 63 from textFile at ReadWrite.scala:587
21/02/17 01:42:11 INFO FileInputFormat: Total input files to process : 1
21/02/17 01:42:11 INFO SparkContext: Starting job: first at ReadWrite.scala:587
21/02/17 01:42:11 INFO DAGScheduler: Got job 40 (first at ReadWrite.scala:587) with 1 output partitions
21/02/17 01:42:11 INFO DAGScheduler: Final stage: ResultStage 52 (first at ReadWrite.scala:587)
21/02/17 01:42:11 INFO DAGScheduler: Parents of final stage: List()
21/02/17 01:42:11 INFO DAGScheduler: Missing parents: List()
21/02/17 01:42:11 INFO DAGScheduler: Submitting ResultStage 52 (/tmp/RtmpzND6YJ/file230be61cffde9/stages/0_r_formula__ae8e0faf_6bf9_456d_bc45_2aca30f7aea4/pipelineModel/stages/1_vectorAttrRewriter_20c63bd9776a/metadata MapPartitionsRDD[164] at textFile at ReadWrite.scala:587), which has no missing parents
21/02/17 01:42:11 INFO MemoryStore: Block broadcast_64 stored as values in memory (estimated size 4.2 KiB, free 911.4 MiB)
21/02/17 01:42:11 INFO MemoryStore: Block broadcast_64_piece0 stored as bytes in memory (estimated size 2.5 KiB, free 911.4 MiB)
21/02/17 01:42:11 INFO BlockManagerInfo: Added broadcast_64_piece0 in memory on localhost:42591 (size: 2.5 KiB, free: 912.2 MiB)
21/02/17 01:42:11 INFO SparkContext: Created broadcast 64 from broadcast at DAGScheduler.scala:1200
21/02/17 01:42:11 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 52 (/tmp/RtmpzND6YJ/file230be61cffde9/stages/0_r_formula__ae8e0faf_6bf9_456d_bc45_2aca30f7aea4/pipelineModel/stages/1_vectorAttrRewriter_20c63bd9776a/metadata MapPartitionsRDD[164] at textFile at ReadWrite.scala:587) (first 15 tasks are for partitions Vector(0))
21/02/17 01:42:11 INFO TaskSchedulerImpl: Adding task set 52.0 with 1 tasks
21/02/17 01:42:11 INFO TaskSetManager: Starting task 0.0 in stage 52.0 (TID 54, localhost, executor driver, partition 0, PROCESS_LOCAL, 7515 bytes)
21/02/17 01:42:11 INFO Executor: Running task 0.0 in stage 52.0 (TID 54)
21/02/17 01:42:11 INFO HadoopRDD: Input split: file:/tmp/RtmpzND6YJ/file230be61cffde9/stages/0_r_formula__ae8e0faf_6bf9_456d_bc45_2aca30f7aea4/pipelineModel/stages/1_vectorAttrRewriter_20c63bd9776a/metadata/part-00000:0+188
21/02/17 01:42:11 INFO Executor: Finished task 0.0 in stage 52.0 (TID 54). 1113 bytes result sent to driver
21/02/17 01:42:11 INFO TaskSetManager: Finished task 0.0 in stage 52.0 (TID 54) in 3 ms on localhost (executor driver) (1/1)
21/02/17 01:42:11 INFO TaskSchedulerImpl: Removed TaskSet 52.0, whose tasks have all completed, from pool 
21/02/17 01:42:11 INFO DAGScheduler: ResultStage 52 (first at ReadWrite.scala:587) finished in 0.007 s
21/02/17 01:42:11 INFO DAGScheduler: Job 40 is finished. Cancelling potential speculative or zombie tasks for this job
21/02/17 01:42:11 INFO TaskSchedulerImpl: Killing all running tasks in stage 52: Stage finished
21/02/17 01:42:11 INFO DAGScheduler: Job 40 finished: first at ReadWrite.scala:587, took 0.008443 s
21/02/17 01:42:11 INFO InMemoryFileIndex: It took 1 ms to list leaf files for 1 paths.
21/02/17 01:42:11 INFO SparkContext: Starting job: parquet at RFormula.scala:612
21/02/17 01:42:11 INFO DAGScheduler: Got job 41 (parquet at RFormula.scala:612) with 1 output partitions
21/02/17 01:42:11 INFO DAGScheduler: Final stage: ResultStage 53 (parquet at RFormula.scala:612)
21/02/17 01:42:11 INFO DAGScheduler: Parents of final stage: List()
21/02/17 01:42:11 INFO DAGScheduler: Missing parents: List()
21/02/17 01:42:11 INFO DAGScheduler: Submitting ResultStage 53 (MapPartitionsRDD[166] at parquet at RFormula.scala:612), which has no missing parents
21/02/17 01:42:11 INFO MemoryStore: Block broadcast_65 stored as values in memory (estimated size 87.9 KiB, free 911.3 MiB)
21/02/17 01:42:11 INFO MemoryStore: Block broadcast_65_piece0 stored as bytes in memory (estimated size 31.1 KiB, free 911.3 MiB)
21/02/17 01:42:11 INFO BlockManagerInfo: Added broadcast_65_piece0 in memory on localhost:42591 (size: 31.1 KiB, free: 912.1 MiB)
21/02/17 01:42:11 INFO SparkContext: Created broadcast 65 from broadcast at DAGScheduler.scala:1200
21/02/17 01:42:11 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 53 (MapPartitionsRDD[166] at parquet at RFormula.scala:612) (first 15 tasks are for partitions Vector(0))
21/02/17 01:42:11 INFO TaskSchedulerImpl: Adding task set 53.0 with 1 tasks
21/02/17 01:42:11 INFO TaskSetManager: Starting task 0.0 in stage 53.0 (TID 55, localhost, executor driver, partition 0, PROCESS_LOCAL, 7671 bytes)
21/02/17 01:42:11 INFO Executor: Running task 0.0 in stage 53.0 (TID 55)
21/02/17 01:42:11 INFO Executor: Finished task 0.0 in stage 53.0 (TID 55). 1769 bytes result sent to driver
21/02/17 01:42:11 INFO TaskSetManager: Finished task 0.0 in stage 53.0 (TID 55) in 8 ms on localhost (executor driver) (1/1)
21/02/17 01:42:11 INFO TaskSchedulerImpl: Removed TaskSet 53.0, whose tasks have all completed, from pool 
21/02/17 01:42:11 INFO DAGScheduler: ResultStage 53 (parquet at RFormula.scala:612) finished in 0.015 s
21/02/17 01:42:11 INFO DAGScheduler: Job 41 is finished. Cancelling potential speculative or zombie tasks for this job
21/02/17 01:42:11 INFO TaskSchedulerImpl: Killing all running tasks in stage 53: Stage finished
21/02/17 01:42:11 INFO DAGScheduler: Job 41 finished: parquet at RFormula.scala:612, took 0.016961 s
21/02/17 01:42:11 INFO FileSourceStrategy: Pruning directories with: 
21/02/17 01:42:11 INFO FileSourceStrategy: Pushed Filters: 
21/02/17 01:42:11 INFO FileSourceStrategy: Post-Scan Filters: 
21/02/17 01:42:11 INFO FileSourceStrategy: Output Data Schema: struct<vectorCol: string, prefixesToRewrite: map<string,string>>
21/02/17 01:42:11 INFO MemoryStore: Block broadcast_66 stored as values in memory (estimated size 321.1 KiB, free 911.0 MiB)
21/02/17 01:42:11 INFO MemoryStore: Block broadcast_66_piece0 stored as bytes in memory (estimated size 29.6 KiB, free 911.0 MiB)
21/02/17 01:42:11 INFO BlockManagerInfo: Added broadcast_66_piece0 in memory on localhost:42591 (size: 29.6 KiB, free: 912.1 MiB)
21/02/17 01:42:11 INFO SparkContext: Created broadcast 66 from head at RFormula.scala:612
21/02/17 01:42:11 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
21/02/17 01:42:11 INFO SparkContext: Starting job: head at RFormula.scala:612
21/02/17 01:42:11 INFO DAGScheduler: Got job 42 (head at RFormula.scala:612) with 1 output partitions
21/02/17 01:42:11 INFO DAGScheduler: Final stage: ResultStage 54 (head at RFormula.scala:612)
21/02/17 01:42:11 INFO DAGScheduler: Parents of final stage: List()
21/02/17 01:42:11 INFO DAGScheduler: Missing parents: List()
21/02/17 01:42:11 INFO DAGScheduler: Submitting ResultStage 54 (MapPartitionsRDD[169] at head at RFormula.scala:612), which has no missing parents
21/02/17 01:42:11 INFO MemoryStore: Block broadcast_67 stored as values in memory (estimated size 9.1 KiB, free 911.0 MiB)
21/02/17 01:42:11 INFO MemoryStore: Block broadcast_67_piece0 stored as bytes in memory (estimated size 4.8 KiB, free 910.9 MiB)
21/02/17 01:42:11 INFO BlockManagerInfo: Added broadcast_67_piece0 in memory on localhost:42591 (size: 4.8 KiB, free: 912.1 MiB)
21/02/17 01:42:11 INFO SparkContext: Created broadcast 67 from broadcast at DAGScheduler.scala:1200
21/02/17 01:42:11 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 54 (MapPartitionsRDD[169] at head at RFormula.scala:612) (first 15 tasks are for partitions Vector(0))
21/02/17 01:42:11 INFO TaskSchedulerImpl: Adding task set 54.0 with 1 tasks
21/02/17 01:42:11 INFO TaskSetManager: Starting task 0.0 in stage 54.0 (TID 56, localhost, executor driver, partition 0, PROCESS_LOCAL, 7922 bytes)
21/02/17 01:42:11 INFO Executor: Running task 0.0 in stage 54.0 (TID 56)
21/02/17 01:42:11 INFO FileScanRDD: Reading File path: file:///tmp/RtmpzND6YJ/file230be61cffde9/stages/0_r_formula__ae8e0faf_6bf9_456d_bc45_2aca30f7aea4/pipelineModel/stages/1_vectorAttrRewriter_20c63bd9776a/data/part-00000-feeef133-b351-45f1-b9f0-b75e09a1ad27-c000.snappy.parquet, range: 0-927, partition values: [empty row]
21/02/17 01:42:11 INFO Executor: Finished task 0.0 in stage 54.0 (TID 56). 1728 bytes result sent to driver
21/02/17 01:42:11 INFO TaskSetManager: Finished task 0.0 in stage 54.0 (TID 56) in 13 ms on localhost (executor driver) (1/1)
21/02/17 01:42:11 INFO TaskSchedulerImpl: Removed TaskSet 54.0, whose tasks have all completed, from pool 
21/02/17 01:42:11 INFO DAGScheduler: ResultStage 54 (head at RFormula.scala:612) finished in 0.016 s
21/02/17 01:42:11 INFO DAGScheduler: Job 42 is finished. Cancelling potential speculative or zombie tasks for this job
21/02/17 01:42:11 INFO TaskSchedulerImpl: Killing all running tasks in stage 54: Stage finished
21/02/17 01:42:11 INFO DAGScheduler: Job 42 finished: head at RFormula.scala:612, took 0.017750 s
21/02/17 01:42:11 INFO CodeGenerator: Code generated in 14.669217 ms
21/02/17 01:42:11 INFO MemoryStore: Block broadcast_68 stored as values in memory (estimated size 294.6 KiB, free 910.7 MiB)
21/02/17 01:42:11 INFO MemoryStore: Block broadcast_68_piece0 stored as bytes in memory (estimated size 27.2 KiB, free 910.6 MiB)
21/02/17 01:42:11 INFO BlockManagerInfo: Added broadcast_68_piece0 in memory on localhost:42591 (size: 27.2 KiB, free: 912.1 MiB)
21/02/17 01:42:11 INFO SparkContext: Created broadcast 68 from textFile at ReadWrite.scala:587
21/02/17 01:42:11 INFO FileInputFormat: Total input files to process : 1
21/02/17 01:42:11 INFO SparkContext: Starting job: first at ReadWrite.scala:587
21/02/17 01:42:11 INFO DAGScheduler: Got job 43 (first at ReadWrite.scala:587) with 1 output partitions
21/02/17 01:42:11 INFO DAGScheduler: Final stage: ResultStage 55 (first at ReadWrite.scala:587)
21/02/17 01:42:11 INFO DAGScheduler: Parents of final stage: List()
21/02/17 01:42:11 INFO DAGScheduler: Missing parents: List()
21/02/17 01:42:11 INFO DAGScheduler: Submitting ResultStage 55 (/tmp/RtmpzND6YJ/file230be61cffde9/stages/0_r_formula__ae8e0faf_6bf9_456d_bc45_2aca30f7aea4/pipelineModel/stages/2_columnPruner_78c00bc6a66f/metadata MapPartitionsRDD[171] at textFile at ReadWrite.scala:587), which has no missing parents
21/02/17 01:42:11 INFO MemoryStore: Block broadcast_69 stored as values in memory (estimated size 4.2 KiB, free 910.6 MiB)
21/02/17 01:42:11 INFO MemoryStore: Block broadcast_69_piece0 stored as bytes in memory (estimated size 2.5 KiB, free 910.6 MiB)
21/02/17 01:42:11 INFO BlockManagerInfo: Added broadcast_69_piece0 in memory on localhost:42591 (size: 2.5 KiB, free: 912.1 MiB)
21/02/17 01:42:11 INFO SparkContext: Created broadcast 69 from broadcast at DAGScheduler.scala:1200
21/02/17 01:42:11 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 55 (/tmp/RtmpzND6YJ/file230be61cffde9/stages/0_r_formula__ae8e0faf_6bf9_456d_bc45_2aca30f7aea4/pipelineModel/stages/2_columnPruner_78c00bc6a66f/metadata MapPartitionsRDD[171] at textFile at ReadWrite.scala:587) (first 15 tasks are for partitions Vector(0))
21/02/17 01:42:11 INFO TaskSchedulerImpl: Adding task set 55.0 with 1 tasks
21/02/17 01:42:11 INFO TaskSetManager: Starting task 0.0 in stage 55.0 (TID 57, localhost, executor driver, partition 0, PROCESS_LOCAL, 7506 bytes)
21/02/17 01:42:11 INFO Executor: Running task 0.0 in stage 55.0 (TID 57)
21/02/17 01:42:11 INFO HadoopRDD: Input split: file:/tmp/RtmpzND6YJ/file230be61cffde9/stages/0_r_formula__ae8e0faf_6bf9_456d_bc45_2aca30f7aea4/pipelineModel/stages/2_columnPruner_78c00bc6a66f/metadata/part-00000:0+171
21/02/17 01:42:11 INFO Executor: Finished task 0.0 in stage 55.0 (TID 57). 1096 bytes result sent to driver
21/02/17 01:42:11 INFO TaskSetManager: Finished task 0.0 in stage 55.0 (TID 57) in 4 ms on localhost (executor driver) (1/1)
21/02/17 01:42:11 INFO TaskSchedulerImpl: Removed TaskSet 55.0, whose tasks have all completed, from pool 
21/02/17 01:42:11 INFO DAGScheduler: ResultStage 55 (first at ReadWrite.scala:587) finished in 0.008 s
21/02/17 01:42:11 INFO DAGScheduler: Job 43 is finished. Cancelling potential speculative or zombie tasks for this job
21/02/17 01:42:11 INFO TaskSchedulerImpl: Killing all running tasks in stage 55: Stage finished
21/02/17 01:42:11 INFO DAGScheduler: Job 43 finished: first at ReadWrite.scala:587, took 0.009183 s
21/02/17 01:42:11 INFO MemoryStore: Block broadcast_70 stored as values in memory (estimated size 294.6 KiB, free 910.3 MiB)
21/02/17 01:42:11 INFO MemoryStore: Block broadcast_70_piece0 stored as bytes in memory (estimated size 27.2 KiB, free 910.3 MiB)
21/02/17 01:42:11 INFO BlockManagerInfo: Added broadcast_70_piece0 in memory on localhost:42591 (size: 27.2 KiB, free: 912.1 MiB)
21/02/17 01:42:11 INFO SparkContext: Created broadcast 70 from textFile at ReadWrite.scala:587
21/02/17 01:42:11 INFO FileInputFormat: Total input files to process : 1
21/02/17 01:42:11 INFO SparkContext: Starting job: first at ReadWrite.scala:587
21/02/17 01:42:11 INFO DAGScheduler: Got job 44 (first at ReadWrite.scala:587) with 1 output partitions
21/02/17 01:42:11 INFO DAGScheduler: Final stage: ResultStage 56 (first at ReadWrite.scala:587)
21/02/17 01:42:11 INFO DAGScheduler: Parents of final stage: List()
21/02/17 01:42:11 INFO DAGScheduler: Missing parents: List()
21/02/17 01:42:11 INFO DAGScheduler: Submitting ResultStage 56 (/tmp/RtmpzND6YJ/file230be61cffde9/stages/0_r_formula__ae8e0faf_6bf9_456d_bc45_2aca30f7aea4/pipelineModel/stages/2_columnPruner_78c00bc6a66f/metadata MapPartitionsRDD[173] at textFile at ReadWrite.scala:587), which has no missing parents
21/02/17 01:42:11 INFO MemoryStore: Block broadcast_71 stored as values in memory (estimated size 4.2 KiB, free 910.3 MiB)
21/02/17 01:42:11 INFO MemoryStore: Block broadcast_71_piece0 stored as bytes in memory (estimated size 2.5 KiB, free 910.3 MiB)
21/02/17 01:42:11 INFO BlockManagerInfo: Added broadcast_71_piece0 in memory on localhost:42591 (size: 2.5 KiB, free: 912.1 MiB)
21/02/17 01:42:11 INFO SparkContext: Created broadcast 71 from broadcast at DAGScheduler.scala:1200
21/02/17 01:42:11 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 56 (/tmp/RtmpzND6YJ/file230be61cffde9/stages/0_r_formula__ae8e0faf_6bf9_456d_bc45_2aca30f7aea4/pipelineModel/stages/2_columnPruner_78c00bc6a66f/metadata MapPartitionsRDD[173] at textFile at ReadWrite.scala:587) (first 15 tasks are for partitions Vector(0))
21/02/17 01:42:11 INFO TaskSchedulerImpl: Adding task set 56.0 with 1 tasks
21/02/17 01:42:11 INFO TaskSetManager: Starting task 0.0 in stage 56.0 (TID 58, localhost, executor driver, partition 0, PROCESS_LOCAL, 7506 bytes)
21/02/17 01:42:11 INFO Executor: Running task 0.0 in stage 56.0 (TID 58)
21/02/17 01:42:11 INFO HadoopRDD: Input split: file:/tmp/RtmpzND6YJ/file230be61cffde9/stages/0_r_formula__ae8e0faf_6bf9_456d_bc45_2aca30f7aea4/pipelineModel/stages/2_columnPruner_78c00bc6a66f/metadata/part-00000:0+171
21/02/17 01:42:11 INFO Executor: Finished task 0.0 in stage 56.0 (TID 58). 1053 bytes result sent to driver
21/02/17 01:42:11 INFO TaskSetManager: Finished task 0.0 in stage 56.0 (TID 58) in 3 ms on localhost (executor driver) (1/1)
21/02/17 01:42:11 INFO TaskSchedulerImpl: Removed TaskSet 56.0, whose tasks have all completed, from pool 
21/02/17 01:42:11 INFO DAGScheduler: ResultStage 56 (first at ReadWrite.scala:587) finished in 0.007 s
21/02/17 01:42:11 INFO DAGScheduler: Job 44 is finished. Cancelling potential speculative or zombie tasks for this job
21/02/17 01:42:11 INFO TaskSchedulerImpl: Killing all running tasks in stage 56: Stage finished
21/02/17 01:42:11 INFO DAGScheduler: Job 44 finished: first at ReadWrite.scala:587, took 0.008246 s
21/02/17 01:42:11 INFO InMemoryFileIndex: It took 0 ms to list leaf files for 1 paths.
21/02/17 01:42:11 INFO SparkContext: Starting job: parquet at RFormula.scala:521
21/02/17 01:42:11 INFO DAGScheduler: Got job 45 (parquet at RFormula.scala:521) with 1 output partitions
21/02/17 01:42:11 INFO DAGScheduler: Final stage: ResultStage 57 (parquet at RFormula.scala:521)
21/02/17 01:42:11 INFO DAGScheduler: Parents of final stage: List()
21/02/17 01:42:11 INFO DAGScheduler: Missing parents: List()
21/02/17 01:42:11 INFO DAGScheduler: Submitting ResultStage 57 (MapPartitionsRDD[175] at parquet at RFormula.scala:521), which has no missing parents
21/02/17 01:42:11 INFO MemoryStore: Block broadcast_72 stored as values in memory (estimated size 87.9 KiB, free 910.2 MiB)
21/02/17 01:42:11 INFO MemoryStore: Block broadcast_72_piece0 stored as bytes in memory (estimated size 31.1 KiB, free 910.2 MiB)
21/02/17 01:42:11 INFO BlockManagerInfo: Added broadcast_72_piece0 in memory on localhost:42591 (size: 31.1 KiB, free: 912.0 MiB)
21/02/17 01:42:11 INFO SparkContext: Created broadcast 72 from broadcast at DAGScheduler.scala:1200
21/02/17 01:42:11 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 57 (MapPartitionsRDD[175] at parquet at RFormula.scala:521) (first 15 tasks are for partitions Vector(0))
21/02/17 01:42:11 INFO TaskSchedulerImpl: Adding task set 57.0 with 1 tasks
21/02/17 01:42:11 INFO TaskSetManager: Starting task 0.0 in stage 57.0 (TID 59, localhost, executor driver, partition 0, PROCESS_LOCAL, 7665 bytes)
21/02/17 01:42:11 INFO Executor: Running task 0.0 in stage 57.0 (TID 59)
21/02/17 01:42:11 INFO Executor: Finished task 0.0 in stage 57.0 (TID 59). 1705 bytes result sent to driver
21/02/17 01:42:11 INFO TaskSetManager: Finished task 0.0 in stage 57.0 (TID 59) in 8 ms on localhost (executor driver) (1/1)
21/02/17 01:42:11 INFO TaskSchedulerImpl: Removed TaskSet 57.0, whose tasks have all completed, from pool 
21/02/17 01:42:11 INFO DAGScheduler: ResultStage 57 (parquet at RFormula.scala:521) finished in 0.016 s
21/02/17 01:42:11 INFO DAGScheduler: Job 45 is finished. Cancelling potential speculative or zombie tasks for this job
21/02/17 01:42:11 INFO TaskSchedulerImpl: Killing all running tasks in stage 57: Stage finished
21/02/17 01:42:11 INFO DAGScheduler: Job 45 finished: parquet at RFormula.scala:521, took 0.018079 s
21/02/17 01:42:11 INFO FileSourceStrategy: Pruning directories with: 
21/02/17 01:42:11 INFO FileSourceStrategy: Pushed Filters: 
21/02/17 01:42:11 INFO FileSourceStrategy: Post-Scan Filters: 
21/02/17 01:42:11 INFO FileSourceStrategy: Output Data Schema: struct<columnsToPrune: array<string>>
21/02/17 01:42:11 INFO MemoryStore: Block broadcast_73 stored as values in memory (estimated size 320.8 KiB, free 909.9 MiB)
21/02/17 01:42:11 INFO MemoryStore: Block broadcast_73_piece0 stored as bytes in memory (estimated size 29.6 KiB, free 909.8 MiB)
21/02/17 01:42:11 INFO BlockManagerInfo: Added broadcast_73_piece0 in memory on localhost:42591 (size: 29.6 KiB, free: 912.0 MiB)
21/02/17 01:42:11 INFO SparkContext: Created broadcast 73 from head at RFormula.scala:521
21/02/17 01:42:11 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
21/02/17 01:42:11 INFO SparkContext: Starting job: head at RFormula.scala:521
21/02/17 01:42:11 INFO DAGScheduler: Got job 46 (head at RFormula.scala:521) with 1 output partitions
21/02/17 01:42:11 INFO DAGScheduler: Final stage: ResultStage 58 (head at RFormula.scala:521)
21/02/17 01:42:11 INFO DAGScheduler: Parents of final stage: List()
21/02/17 01:42:11 INFO DAGScheduler: Missing parents: List()
21/02/17 01:42:11 INFO DAGScheduler: Submitting ResultStage 58 (MapPartitionsRDD[178] at head at RFormula.scala:521), which has no missing parents
21/02/17 01:42:11 INFO MemoryStore: Block broadcast_74 stored as values in memory (estimated size 8.9 KiB, free 909.8 MiB)
21/02/17 01:42:11 INFO MemoryStore: Block broadcast_74_piece0 stored as bytes in memory (estimated size 4.8 KiB, free 909.8 MiB)
21/02/17 01:42:11 INFO BlockManagerInfo: Added broadcast_74_piece0 in memory on localhost:42591 (size: 4.8 KiB, free: 912.0 MiB)
21/02/17 01:42:11 INFO SparkContext: Created broadcast 74 from broadcast at DAGScheduler.scala:1200
21/02/17 01:42:11 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 58 (MapPartitionsRDD[178] at head at RFormula.scala:521) (first 15 tasks are for partitions Vector(0))
21/02/17 01:42:11 INFO TaskSchedulerImpl: Adding task set 58.0 with 1 tasks
21/02/17 01:42:11 INFO TaskSetManager: Starting task 0.0 in stage 58.0 (TID 60, localhost, executor driver, partition 0, PROCESS_LOCAL, 7916 bytes)
21/02/17 01:42:11 INFO Executor: Running task 0.0 in stage 58.0 (TID 60)
21/02/17 01:42:11 INFO FileScanRDD: Reading File path: file:///tmp/RtmpzND6YJ/file230be61cffde9/stages/0_r_formula__ae8e0faf_6bf9_456d_bc45_2aca30f7aea4/pipelineModel/stages/2_columnPruner_78c00bc6a66f/data/part-00000-cc166540-0b76-46e5-903d-3a13bd34d0bf-c000.snappy.parquet, range: 0-510, partition values: [empty row]
21/02/17 01:42:11 INFO Executor: Finished task 0.0 in stage 58.0 (TID 60). 1709 bytes result sent to driver
21/02/17 01:42:11 INFO TaskSetManager: Finished task 0.0 in stage 58.0 (TID 60) in 8 ms on localhost (executor driver) (1/1)
21/02/17 01:42:11 INFO TaskSchedulerImpl: Removed TaskSet 58.0, whose tasks have all completed, from pool 
21/02/17 01:42:11 INFO DAGScheduler: ResultStage 58 (head at RFormula.scala:521) finished in 0.012 s
21/02/17 01:42:11 INFO DAGScheduler: Job 46 is finished. Cancelling potential speculative or zombie tasks for this job
21/02/17 01:42:11 INFO TaskSchedulerImpl: Killing all running tasks in stage 58: Stage finished
21/02/17 01:42:11 INFO DAGScheduler: Job 46 finished: head at RFormula.scala:521, took 0.013040 s
21/02/17 01:42:11 INFO CodeGenerator: Code generated in 9.945695 ms
21/02/17 01:42:11 INFO Instrumentation: [bad0a4b6] training finished
21/02/17 01:42:11 INFO Instrumentation: [e6d91297] training finished
21/02/17 01:42:11 INFO MemoryStore: Block broadcast_75 stored as values in memory (estimated size 294.6 KiB, free 909.5 MiB)
21/02/17 01:42:11 INFO MemoryStore: Block broadcast_75_piece0 stored as bytes in memory (estimated size 27.2 KiB, free 909.5 MiB)
21/02/17 01:42:11 INFO BlockManagerInfo: Added broadcast_75_piece0 in memory on localhost:42591 (size: 27.2 KiB, free: 912.0 MiB)
21/02/17 01:42:11 INFO SparkContext: Created broadcast 75 from textFile at ReadWrite.scala:587
21/02/17 01:42:11 INFO FileInputFormat: Total input files to process : 1
21/02/17 01:42:11 INFO SparkContext: Starting job: first at ReadWrite.scala:587
21/02/17 01:42:11 INFO DAGScheduler: Got job 47 (first at ReadWrite.scala:587) with 1 output partitions
21/02/17 01:42:11 INFO DAGScheduler: Final stage: ResultStage 59 (first at ReadWrite.scala:587)
21/02/17 01:42:11 INFO DAGScheduler: Parents of final stage: List()
21/02/17 01:42:11 INFO DAGScheduler: Missing parents: List()
21/02/17 01:42:11 INFO DAGScheduler: Submitting ResultStage 59 (/tmp/RtmpzND6YJ/file230be61cffde9/stages/1_xgboost_regressor__540d2dbb_07f3_4ca0_b88c_803ab842d259/metadata MapPartitionsRDD[180] at textFile at ReadWrite.scala:587), which has no missing parents
21/02/17 01:42:11 INFO MemoryStore: Block broadcast_76 stored as values in memory (estimated size 4.2 KiB, free 909.5 MiB)
21/02/17 01:42:11 INFO MemoryStore: Block broadcast_76_piece0 stored as bytes in memory (estimated size 2.5 KiB, free 909.5 MiB)
21/02/17 01:42:11 INFO BlockManagerInfo: Added broadcast_76_piece0 in memory on localhost:42591 (size: 2.5 KiB, free: 912.0 MiB)
21/02/17 01:42:11 INFO SparkContext: Created broadcast 76 from broadcast at DAGScheduler.scala:1200
21/02/17 01:42:11 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 59 (/tmp/RtmpzND6YJ/file230be61cffde9/stages/1_xgboost_regressor__540d2dbb_07f3_4ca0_b88c_803ab842d259/metadata MapPartitionsRDD[180] at textFile at ReadWrite.scala:587) (first 15 tasks are for partitions Vector(0))
21/02/17 01:42:11 INFO TaskSchedulerImpl: Adding task set 59.0 with 1 tasks
21/02/17 01:42:11 INFO TaskSetManager: Starting task 0.0 in stage 59.0 (TID 61, localhost, executor driver, partition 0, PROCESS_LOCAL, 7464 bytes)
21/02/17 01:42:11 INFO Executor: Running task 0.0 in stage 59.0 (TID 61)
21/02/17 01:42:11 INFO HadoopRDD: Input split: file:/tmp/RtmpzND6YJ/file230be61cffde9/stages/1_xgboost_regressor__540d2dbb_07f3_4ca0_b88c_803ab842d259/metadata/part-00000:0+1284
21/02/17 01:42:11 INFO Executor: Finished task 0.0 in stage 59.0 (TID 61). 2217 bytes result sent to driver
21/02/17 01:42:11 INFO TaskSetManager: Finished task 0.0 in stage 59.0 (TID 61) in 5 ms on localhost (executor driver) (1/1)
21/02/17 01:42:11 INFO TaskSchedulerImpl: Removed TaskSet 59.0, whose tasks have all completed, from pool 
21/02/17 01:42:11 INFO DAGScheduler: ResultStage 59 (first at ReadWrite.scala:587) finished in 0.008 s
21/02/17 01:42:11 INFO DAGScheduler: Job 47 is finished. Cancelling potential speculative or zombie tasks for this job
21/02/17 01:42:11 INFO TaskSchedulerImpl: Killing all running tasks in stage 59: Stage finished
21/02/17 01:42:11 INFO DAGScheduler: Job 47 finished: first at ReadWrite.scala:587, took 0.009692 s
21/02/17 01:42:11 INFO MemoryStore: Block broadcast_77 stored as values in memory (estimated size 294.6 KiB, free 909.2 MiB)
21/02/17 01:42:11 INFO MemoryStore: Block broadcast_77_piece0 stored as bytes in memory (estimated size 27.2 KiB, free 909.2 MiB)
21/02/17 01:42:11 INFO BlockManagerInfo: Added broadcast_77_piece0 in memory on localhost:42591 (size: 27.2 KiB, free: 911.9 MiB)
21/02/17 01:42:11 INFO SparkContext: Created broadcast 77 from textFile at DefaultXGBoostParamsReader.scala:82
21/02/17 01:42:11 INFO FileInputFormat: Total input files to process : 1
21/02/17 01:42:11 INFO SparkContext: Starting job: first at DefaultXGBoostParamsReader.scala:82
21/02/17 01:42:11 INFO DAGScheduler: Got job 48 (first at DefaultXGBoostParamsReader.scala:82) with 1 output partitions
21/02/17 01:42:11 INFO DAGScheduler: Final stage: ResultStage 60 (first at DefaultXGBoostParamsReader.scala:82)
21/02/17 01:42:11 INFO DAGScheduler: Parents of final stage: List()
21/02/17 01:42:11 INFO DAGScheduler: Missing parents: List()
21/02/17 01:42:11 INFO DAGScheduler: Submitting ResultStage 60 (/tmp/RtmpzND6YJ/file230be61cffde9/stages/1_xgboost_regressor__540d2dbb_07f3_4ca0_b88c_803ab842d259/metadata MapPartitionsRDD[182] at textFile at DefaultXGBoostParamsReader.scala:82), which has no missing parents
21/02/17 01:42:11 INFO MemoryStore: Block broadcast_78 stored as values in memory (estimated size 4.2 KiB, free 909.2 MiB)
21/02/17 01:42:11 INFO MemoryStore: Block broadcast_78_piece0 stored as bytes in memory (estimated size 2.5 KiB, free 909.2 MiB)
21/02/17 01:42:11 INFO BlockManagerInfo: Added broadcast_78_piece0 in memory on localhost:42591 (size: 2.5 KiB, free: 911.9 MiB)
21/02/17 01:42:11 INFO SparkContext: Created broadcast 78 from broadcast at DAGScheduler.scala:1200
21/02/17 01:42:11 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 60 (/tmp/RtmpzND6YJ/file230be61cffde9/stages/1_xgboost_regressor__540d2dbb_07f3_4ca0_b88c_803ab842d259/metadata MapPartitionsRDD[182] at textFile at DefaultXGBoostParamsReader.scala:82) (first 15 tasks are for partitions Vector(0))
21/02/17 01:42:11 INFO TaskSchedulerImpl: Adding task set 60.0 with 1 tasks
21/02/17 01:42:11 INFO TaskSetManager: Starting task 0.0 in stage 60.0 (TID 62, localhost, executor driver, partition 0, PROCESS_LOCAL, 7464 bytes)
21/02/17 01:42:11 INFO Executor: Running task 0.0 in stage 60.0 (TID 62)
21/02/17 01:42:11 INFO HadoopRDD: Input split: file:/tmp/RtmpzND6YJ/file230be61cffde9/stages/1_xgboost_regressor__540d2dbb_07f3_4ca0_b88c_803ab842d259/metadata/part-00000:0+1284
21/02/17 01:42:11 INFO Executor: Finished task 0.0 in stage 60.0 (TID 62). 2217 bytes result sent to driver
21/02/17 01:42:11 INFO TaskSetManager: Finished task 0.0 in stage 60.0 (TID 62) in 4 ms on localhost (executor driver) (1/1)
21/02/17 01:42:11 INFO TaskSchedulerImpl: Removed TaskSet 60.0, whose tasks have all completed, from pool 
21/02/17 01:42:11 INFO DAGScheduler: ResultStage 60 (first at DefaultXGBoostParamsReader.scala:82) finished in 0.006 s
21/02/17 01:42:11 INFO DAGScheduler: Job 48 is finished. Cancelling potential speculative or zombie tasks for this job
21/02/17 01:42:11 INFO TaskSchedulerImpl: Killing all running tasks in stage 60: Stage finished
21/02/17 01:42:11 INFO DAGScheduler: Job 48 finished: first at DefaultXGBoostParamsReader.scala:82, took 0.008089 s
21/02/17 01:42:11 INFO Instrumentation: [5d84cd68] training finished
21/02/17 01:42:11 INFO Instrumentation: [10f2eb58] training finished
21/02/17 01:42:11 INFO Instrumentation: [41dfbc3e] training finished
21/02/17 01:42:11 INFO MemoryStore: Block broadcast_79 stored as values in memory (estimated size 64.0 B, free 909.2 MiB)
21/02/17 01:42:11 INFO MemoryStore: Block broadcast_79_piece0 stored as bytes in memory (estimated size 515.0 B, free 909.2 MiB)
21/02/17 01:42:11 INFO BlockManagerInfo: Added broadcast_79_piece0 in memory on localhost:42591 (size: 515.0 B, free: 911.9 MiB)
21/02/17 01:42:11 INFO SparkContext: Created broadcast 79 from broadcast at XGBoostRegressor.scala:279
21/02/17 01:42:11 INFO Instrumentation: [c369be55] training finished
21/02/17 01:42:11 INFO SparkContext: Starting job: collect at utils.scala:137
21/02/17 01:42:11 INFO DAGScheduler: Got job 49 (collect at utils.scala:137) with 1 output partitions
21/02/17 01:42:11 INFO DAGScheduler: Final stage: ResultStage 61 (collect at utils.scala:137)
21/02/17 01:42:11 INFO DAGScheduler: Parents of final stage: List()
21/02/17 01:42:11 INFO DAGScheduler: Missing parents: List()
21/02/17 01:42:11 INFO DAGScheduler: Submitting ResultStage 61 (MapPartitionsRDD[192] at collect at utils.scala:137), which has no missing parents
21/02/17 01:42:11 INFO MemoryStore: Block broadcast_80 stored as values in memory (estimated size 7.3 KiB, free 909.2 MiB)
21/02/17 01:42:11 INFO MemoryStore: Block broadcast_80_piece0 stored as bytes in memory (estimated size 3.7 KiB, free 909.2 MiB)
21/02/17 01:42:11 INFO BlockManagerInfo: Added broadcast_80_piece0 in memory on localhost:42591 (size: 3.7 KiB, free: 911.9 MiB)
21/02/17 01:42:11 INFO SparkContext: Created broadcast 80 from broadcast at DAGScheduler.scala:1200
21/02/17 01:42:11 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 61 (MapPartitionsRDD[192] at collect at utils.scala:137) (first 15 tasks are for partitions Vector(0))
21/02/17 01:42:11 INFO TaskSchedulerImpl: Adding task set 61.0 with 1 tasks
21/02/17 01:42:11 INFO TaskSetManager: Starting task 0.0 in stage 61.0 (TID 63, localhost, executor driver, partition 0, PROCESS_LOCAL, 7561 bytes)
21/02/17 01:42:11 INFO Executor: Running task 0.0 in stage 61.0 (TID 63)
21/02/17 01:42:11 INFO Executor: Finished task 0.0 in stage 61.0 (TID 63). 1354 bytes result sent to driver
21/02/17 01:42:11 INFO TaskSetManager: Finished task 0.0 in stage 61.0 (TID 63) in 4 ms on localhost (executor driver) (1/1)
21/02/17 01:42:11 INFO TaskSchedulerImpl: Removed TaskSet 61.0, whose tasks have all completed, from pool 
21/02/17 01:42:11 INFO DAGScheduler: ResultStage 61 (collect at utils.scala:137) finished in 0.020 s
21/02/17 01:42:11 INFO DAGScheduler: Job 49 is finished. Cancelling potential speculative or zombie tasks for this job
21/02/17 01:42:11 INFO TaskSchedulerImpl: Killing all running tasks in stage 61: Stage finished
21/02/17 01:42:11 INFO DAGScheduler: Job 49 finished: collect at utils.scala:137, took 0.021198 s
21/02/17 01:42:11 INFO BlockManagerInfo: Removed broadcast_70_piece0 on localhost:42591 in memory (size: 27.2 KiB, free: 912.0 MiB)
21/02/17 01:42:11 INFO BlockManagerInfo: Removed broadcast_74_piece0 on localhost:42591 in memory (size: 4.8 KiB, free: 912.0 MiB)
21/02/17 01:42:11 INFO BlockManagerInfo: Removed broadcast_67_piece0 on localhost:42591 in memory (size: 4.8 KiB, free: 912.0 MiB)
21/02/17 01:42:11 INFO BlockManagerInfo: Removed broadcast_78_piece0 on localhost:42591 in memory (size: 2.5 KiB, free: 912.0 MiB)
21/02/17 01:42:11 INFO BlockManagerInfo: Removed broadcast_65_piece0 on localhost:42591 in memory (size: 31.1 KiB, free: 912.0 MiB)
21/02/17 01:42:11 INFO BlockManagerInfo: Removed broadcast_71_piece0 on localhost:42591 in memory (size: 2.5 KiB, free: 912.0 MiB)
21/02/17 01:42:11 INFO BlockManagerInfo: Removed broadcast_63_piece0 on localhost:42591 in memory (size: 27.2 KiB, free: 912.0 MiB)
21/02/17 01:42:11 INFO BlockManagerInfo: Removed broadcast_75_piece0 on localhost:42591 in memory (size: 27.2 KiB, free: 912.1 MiB)
21/02/17 01:42:11 INFO BlockManagerInfo: Removed broadcast_73_piece0 on localhost:42591 in memory (size: 29.6 KiB, free: 912.1 MiB)
21/02/17 01:42:11 INFO BlockManagerInfo: Removed broadcast_68_piece0 on localhost:42591 in memory (size: 27.2 KiB, free: 912.1 MiB)
21/02/17 01:42:11 INFO BlockManagerInfo: Removed broadcast_77_piece0 on localhost:42591 in memory (size: 27.2 KiB, free: 912.1 MiB)
21/02/17 01:42:11 INFO BlockManagerInfo: Removed broadcast_62_piece0 on localhost:42591 in memory (size: 2.5 KiB, free: 912.1 MiB)
21/02/17 01:42:11 INFO BlockManagerInfo: Removed broadcast_69_piece0 on localhost:42591 in memory (size: 2.5 KiB, free: 912.1 MiB)
21/02/17 01:42:11 INFO BlockManagerInfo: Removed broadcast_76_piece0 on localhost:42591 in memory (size: 2.5 KiB, free: 912.1 MiB)
21/02/17 01:42:11 INFO BlockManagerInfo: Removed broadcast_72_piece0 on localhost:42591 in memory (size: 31.1 KiB, free: 912.2 MiB)
21/02/17 01:42:11 INFO BlockManagerInfo: Removed broadcast_64_piece0 on localhost:42591 in memory (size: 2.5 KiB, free: 912.2 MiB)
21/02/17 01:42:11 INFO BlockManagerInfo: Removed broadcast_66_piece0 on localhost:42591 in memory (size: 29.6 KiB, free: 912.2 MiB)
21/02/17 01:42:11 INFO BlockManagerInfo: Removed broadcast_61_piece0 on localhost:42591 in memory (size: 27.2 KiB, free: 912.2 MiB)
21/02/17 01:42:11 INFO SparkContext: Starting job: count at utils.scala:135
21/02/17 01:42:11 INFO DAGScheduler: Registering RDD 194 (count at utils.scala:135) as input to shuffle 13
21/02/17 01:42:11 INFO DAGScheduler: Got job 50 (count at utils.scala:135) with 1 output partitions
21/02/17 01:42:11 INFO DAGScheduler: Final stage: ResultStage 63 (count at utils.scala:135)
21/02/17 01:42:11 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 62)
21/02/17 01:42:11 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 62)
21/02/17 01:42:11 INFO DAGScheduler: Submitting ShuffleMapStage 62 (MapPartitionsRDD[194] at count at utils.scala:135), which has no missing parents
21/02/17 01:42:11 INFO MemoryStore: Block broadcast_81 stored as values in memory (estimated size 10.0 KiB, free 912.0 MiB)
21/02/17 01:42:11 INFO MemoryStore: Block broadcast_81_piece0 stored as bytes in memory (estimated size 5.2 KiB, free 912.0 MiB)
21/02/17 01:42:11 INFO BlockManagerInfo: Added broadcast_81_piece0 in memory on localhost:42591 (size: 5.2 KiB, free: 912.2 MiB)
21/02/17 01:42:11 INFO SparkContext: Created broadcast 81 from broadcast at DAGScheduler.scala:1200
21/02/17 01:42:11 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 62 (MapPartitionsRDD[194] at count at utils.scala:135) (first 15 tasks are for partitions Vector(0))
21/02/17 01:42:11 INFO TaskSchedulerImpl: Adding task set 62.0 with 1 tasks
21/02/17 01:42:11 INFO TaskSetManager: Starting task 0.0 in stage 62.0 (TID 64, localhost, executor driver, partition 0, PROCESS_LOCAL, 7550 bytes)
21/02/17 01:42:11 INFO Executor: Running task 0.0 in stage 62.0 (TID 64)
21/02/17 01:42:11 INFO Executor: Finished task 0.0 in stage 62.0 (TID 64). 1833 bytes result sent to driver
21/02/17 01:42:11 INFO TaskSetManager: Finished task 0.0 in stage 62.0 (TID 64) in 4 ms on localhost (executor driver) (1/1)
21/02/17 01:42:11 INFO TaskSchedulerImpl: Removed TaskSet 62.0, whose tasks have all completed, from pool 
21/02/17 01:42:11 INFO DAGScheduler: ShuffleMapStage 62 (count at utils.scala:135) finished in 0.008 s
21/02/17 01:42:11 INFO DAGScheduler: looking for newly runnable stages
21/02/17 01:42:11 INFO DAGScheduler: running: Set()
21/02/17 01:42:11 INFO DAGScheduler: waiting: Set(ResultStage 63)
21/02/17 01:42:11 INFO DAGScheduler: failed: Set()
21/02/17 01:42:11 INFO DAGScheduler: Submitting ResultStage 63 (MapPartitionsRDD[197] at count at utils.scala:135), which has no missing parents
21/02/17 01:42:11 INFO MemoryStore: Block broadcast_82 stored as values in memory (estimated size 10.1 KiB, free 912.0 MiB)
21/02/17 01:42:11 INFO MemoryStore: Block broadcast_82_piece0 stored as bytes in memory (estimated size 5.0 KiB, free 912.0 MiB)
21/02/17 01:42:11 INFO BlockManagerInfo: Added broadcast_82_piece0 in memory on localhost:42591 (size: 5.0 KiB, free: 912.2 MiB)
21/02/17 01:42:11 INFO SparkContext: Created broadcast 82 from broadcast at DAGScheduler.scala:1200
21/02/17 01:42:11 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 63 (MapPartitionsRDD[197] at count at utils.scala:135) (first 15 tasks are for partitions Vector(0))
21/02/17 01:42:11 INFO TaskSchedulerImpl: Adding task set 63.0 with 1 tasks
21/02/17 01:42:11 INFO TaskSetManager: Starting task 0.0 in stage 63.0 (TID 65, localhost, executor driver, partition 0, NODE_LOCAL, 7325 bytes)
21/02/17 01:42:11 INFO Executor: Running task 0.0 in stage 63.0 (TID 65)
21/02/17 01:42:11 INFO ShuffleBlockFetcherIterator: Getting 1 (60.0 B) non-empty blocks including 1 (60.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
21/02/17 01:42:11 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
21/02/17 01:42:11 INFO Executor: Finished task 0.0 in stage 63.0 (TID 65). 2648 bytes result sent to driver
21/02/17 01:42:11 INFO TaskSetManager: Finished task 0.0 in stage 63.0 (TID 65) in 4 ms on localhost (executor driver) (1/1)
21/02/17 01:42:11 INFO TaskSchedulerImpl: Removed TaskSet 63.0, whose tasks have all completed, from pool 
21/02/17 01:42:11 INFO DAGScheduler: ResultStage 63 (count at utils.scala:135) finished in 0.008 s
21/02/17 01:42:11 INFO DAGScheduler: Job 50 is finished. Cancelling potential speculative or zombie tasks for this job
21/02/17 01:42:11 INFO TaskSchedulerImpl: Killing all running tasks in stage 63: Stage finished
21/02/17 01:42:11 INFO DAGScheduler: Job 50 finished: count at utils.scala:135, took 0.019833 s
21/02/17 01:42:12 INFO SparkContext: Starting job: collect at utils.scala:137
21/02/17 01:42:12 INFO DAGScheduler: Got job 51 (collect at utils.scala:137) with 1 output partitions
21/02/17 01:42:12 INFO DAGScheduler: Final stage: ResultStage 64 (collect at utils.scala:137)
21/02/17 01:42:12 INFO DAGScheduler: Parents of final stage: List()
21/02/17 01:42:12 INFO DAGScheduler: Missing parents: List()
21/02/17 01:42:12 INFO DAGScheduler: Submitting ResultStage 64 (MapPartitionsRDD[199] at collect at utils.scala:137), which has no missing parents
21/02/17 01:42:12 INFO MemoryStore: Block broadcast_83 stored as values in memory (estimated size 72.4 KiB, free 911.9 MiB)
21/02/17 01:42:12 INFO MemoryStore: Block broadcast_83_piece0 stored as bytes in memory (estimated size 28.6 KiB, free 911.9 MiB)
21/02/17 01:42:12 INFO BlockManagerInfo: Added broadcast_83_piece0 in memory on localhost:42591 (size: 28.6 KiB, free: 912.2 MiB)
21/02/17 01:42:12 INFO SparkContext: Created broadcast 83 from broadcast at DAGScheduler.scala:1200
21/02/17 01:42:12 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 64 (MapPartitionsRDD[199] at collect at utils.scala:137) (first 15 tasks are for partitions Vector(0))
21/02/17 01:42:12 INFO TaskSchedulerImpl: Adding task set 64.0 with 1 tasks
21/02/17 01:42:12 INFO TaskSetManager: Starting task 0.0 in stage 64.0 (TID 66, localhost, executor driver, partition 0, PROCESS_LOCAL, 18492 bytes)
21/02/17 01:42:12 INFO Executor: Running task 0.0 in stage 64.0 (TID 66)
21/02/17 01:42:12 INFO BlockManager: Found block rdd_23_0 locally
21/02/17 01:42:12 INFO Executor: Finished task 0.0 in stage 64.0 (TID 66). 1912 bytes result sent to driver
21/02/17 01:42:12 INFO TaskSetManager: Finished task 0.0 in stage 64.0 (TID 66) in 31 ms on localhost (executor driver) (1/1)
21/02/17 01:42:12 INFO TaskSchedulerImpl: Removed TaskSet 64.0, whose tasks have all completed, from pool 
21/02/17 01:42:12 INFO DAGScheduler: ResultStage 64 (collect at utils.scala:137) finished in 0.037 s
21/02/17 01:42:12 INFO DAGScheduler: Job 51 is finished. Cancelling potential speculative or zombie tasks for this job
21/02/17 01:42:12 INFO TaskSchedulerImpl: Killing all running tasks in stage 64: Stage finished
21/02/17 01:42:12 INFO DAGScheduler: Job 51 finished: collect at utils.scala:137, took 0.038615 s
21/02/17 01:42:12 INFO SparkContext: Starting job: count at utils.scala:135
21/02/17 01:42:12 INFO DAGScheduler: Registering RDD 201 (count at utils.scala:135) as input to shuffle 14
21/02/17 01:42:12 INFO DAGScheduler: Got job 52 (count at utils.scala:135) with 1 output partitions
21/02/17 01:42:12 INFO DAGScheduler: Final stage: ResultStage 66 (count at utils.scala:135)
21/02/17 01:42:12 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 65)
21/02/17 01:42:12 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 65)
21/02/17 01:42:12 INFO DAGScheduler: Submitting ShuffleMapStage 65 (MapPartitionsRDD[201] at count at utils.scala:135), which has no missing parents
21/02/17 01:42:12 INFO MemoryStore: Block broadcast_84 stored as values in memory (estimated size 73.9 KiB, free 911.8 MiB)
21/02/17 01:42:12 INFO MemoryStore: Block broadcast_84_piece0 stored as bytes in memory (estimated size 29.2 KiB, free 911.8 MiB)
21/02/17 01:42:12 INFO BlockManagerInfo: Added broadcast_84_piece0 in memory on localhost:42591 (size: 29.2 KiB, free: 912.2 MiB)
21/02/17 01:42:12 INFO SparkContext: Created broadcast 84 from broadcast at DAGScheduler.scala:1200
21/02/17 01:42:12 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 65 (MapPartitionsRDD[201] at count at utils.scala:135) (first 15 tasks are for partitions Vector(0))
21/02/17 01:42:12 INFO TaskSchedulerImpl: Adding task set 65.0 with 1 tasks
21/02/17 01:42:12 INFO TaskSetManager: Starting task 0.0 in stage 65.0 (TID 67, localhost, executor driver, partition 0, PROCESS_LOCAL, 18481 bytes)
21/02/17 01:42:12 INFO Executor: Running task 0.0 in stage 65.0 (TID 67)
21/02/17 01:42:12 INFO BlockManager: Found block rdd_23_0 locally
21/02/17 01:42:12 INFO Executor: Finished task 0.0 in stage 65.0 (TID 67). 2253 bytes result sent to driver
21/02/17 01:42:12 INFO TaskSetManager: Finished task 0.0 in stage 65.0 (TID 67) in 31 ms on localhost (executor driver) (1/1)
21/02/17 01:42:12 INFO TaskSchedulerImpl: Removed TaskSet 65.0, whose tasks have all completed, from pool 
21/02/17 01:42:12 INFO DAGScheduler: ShuffleMapStage 65 (count at utils.scala:135) finished in 0.035 s
21/02/17 01:42:12 INFO DAGScheduler: looking for newly runnable stages
21/02/17 01:42:12 INFO DAGScheduler: running: Set()
21/02/17 01:42:12 INFO DAGScheduler: waiting: Set(ResultStage 66)
21/02/17 01:42:12 INFO DAGScheduler: failed: Set()
21/02/17 01:42:12 INFO DAGScheduler: Submitting ResultStage 66 (MapPartitionsRDD[204] at count at utils.scala:135), which has no missing parents
21/02/17 01:42:12 INFO MemoryStore: Block broadcast_85 stored as values in memory (estimated size 10.1 KiB, free 911.8 MiB)
21/02/17 01:42:12 INFO MemoryStore: Block broadcast_85_piece0 stored as bytes in memory (estimated size 5.0 KiB, free 911.8 MiB)
21/02/17 01:42:12 INFO BlockManagerInfo: Added broadcast_85_piece0 in memory on localhost:42591 (size: 5.0 KiB, free: 912.2 MiB)
21/02/17 01:42:12 INFO SparkContext: Created broadcast 85 from broadcast at DAGScheduler.scala:1200
21/02/17 01:42:12 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 66 (MapPartitionsRDD[204] at count at utils.scala:135) (first 15 tasks are for partitions Vector(0))
21/02/17 01:42:12 INFO TaskSchedulerImpl: Adding task set 66.0 with 1 tasks
21/02/17 01:42:12 INFO TaskSetManager: Starting task 0.0 in stage 66.0 (TID 68, localhost, executor driver, partition 0, NODE_LOCAL, 7325 bytes)
21/02/17 01:42:12 INFO Executor: Running task 0.0 in stage 66.0 (TID 68)
21/02/17 01:42:12 INFO ShuffleBlockFetcherIterator: Getting 1 (60.0 B) non-empty blocks including 1 (60.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
21/02/17 01:42:12 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
21/02/17 01:42:12 INFO Executor: Finished task 0.0 in stage 66.0 (TID 68). 2648 bytes result sent to driver
21/02/17 01:42:12 INFO TaskSetManager: Finished task 0.0 in stage 66.0 (TID 68) in 4 ms on localhost (executor driver) (1/1)
21/02/17 01:42:12 INFO TaskSchedulerImpl: Removed TaskSet 66.0, whose tasks have all completed, from pool 
21/02/17 01:42:12 INFO DAGScheduler: ResultStage 66 (count at utils.scala:135) finished in 0.007 s
21/02/17 01:42:12 INFO DAGScheduler: Job 52 is finished. Cancelling potential speculative or zombie tasks for this job
21/02/17 01:42:12 INFO TaskSchedulerImpl: Killing all running tasks in stage 66: Stage finished
21/02/17 01:42:12 INFO DAGScheduler: Job 52 finished: count at utils.scala:135, took 0.045645 s
21/02/17 01:42:14 INFO SparkContext: Invoking stop() from shutdown hook
21/02/17 01:42:14 INFO SparkUI: Stopped Spark web UI at http://localhost:4040
21/02/17 01:42:14 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!
21/02/17 01:42:14 INFO MemoryStore: MemoryStore cleared
21/02/17 01:42:14 INFO BlockManager: BlockManager stopped
21/02/17 01:42:14 INFO BlockManagerMaster: BlockManagerMaster stopped
21/02/17 01:42:14 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!
21/02/17 01:42:14 INFO SparkContext: Successfully stopped SparkContext
21/02/17 01:42:14 INFO ShutdownHookManager: Shutdown hook called
21/02/17 01:42:14 INFO ShutdownHookManager: Deleting directory /tmp/spark-bbe23a7c-c2f5-4350-85a2-2bc24b5cc347
21/02/17 01:42:14 INFO ShutdownHookManager: Deleting directory /tmp/spark-e4d01697-77d8-438c-adea-d54815b81a46
